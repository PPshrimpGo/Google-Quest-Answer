,Unnamed: 0,qa_id,question_title,question_body,question_user_name,question_user_page,answer,answer_user_name,answer_user_page,url,category,host,question_asker_intent_understanding,question_body_critical,question_conversational,question_expect_short_answer,question_fact_seeking,question_has_commonly_accepted_answer,question_interestingness_others,question_interestingness_self,question_multi_intent,question_not_really_a_question,question_opinion_seeking,question_type_choice,question_type_compare,question_type_consequence,question_type_definition,question_type_entity,question_type_instructions,question_type_procedure,question_type_reason_explanation,question_type_spelling,question_well_written,answer_helpful,answer_level_of_information,answer_plausible,answer_relevance,answer_satisfaction,answer_type_instructions,answer_type_procedure,answer_type_reason_explanation,answer_well_written,t_aug,q_aug,a_aug
453,453,706,Extending Magento API with customer login,"I followed a lot of tutorials about how to extend Magento API but I didn't figure it out why I always get ""Invalid api path."" My goal is to extend Mage_Customer_Model_Customer_Api in order to add a new method to login a customer in site. I don't know if something like that is possible, but I need at least to be able to add a new method which just returns a message.


Can someone provide me a link where I can find a working module
which extends Magento API?
Is it possible what I want to achieve?
Thank you,


Yeee..I figured out ""Invalid api path."" error. Instead of calling 

$result = $client-&gt;call($session_id, 'gw_base_order.createandcapture');


it has to be

$result = $client-&gt;call($session_id, 'resource_name.createandcapture');


Wrong tuturial: Extending Magento API and others like this. 

I still need an answer for the second question.
",Denisa,https://magento.stackexchange.com/users/4749,"The functionality of logging users in to access their data from a mobile app for example is more a case for OAuth. 
You can read more about OAuth in Magento here and about the configuration here.

The API's are more meant to exchange information not tied to a specific user.
",Sander Mangel,https://magento.stackexchange.com/users/50,http://magento.stackexchange.com/questions/13261/extending-magento-api-with-customer-login,TECHNOLOGY,magento.stackexchange.com,1.0,0.5555555555555556,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.6666666666666666,0.0,1.0,1.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.6666666666666666,1.0,0.5555555555555556,1.0,1.0,0.8,0.3333333333333333,0.0,1.0,1.0,Extend Magento API with customer login,"I followed a lot of tutorials about how to extend Magento API but I didn't figure it out why I always get ""Invalid api path."" My goal is to extend Mage_Customer_Model_Customer_Api in order to add a new method to login a customer in site. I don't know if something like that is possible, but I need at least to be able to add a new method which just returns a message.


Can someone provide me a link where I can find a working module
which extends Magento API?
Is it possible what I want to achieve?
Thank you,


Yeee..I figured out ""Invalid api path."" error. Instead of calling 

$result = $client-&gt;call($session_id, 'gw_base_order.createandcapture');


it has to be

$result = $client-&gt;call($session_id, 'resource_name.createandcapture');


Wrong tuturial: Extending Magento API and others like this. 

I still need an answer for the second question.
","The functionality of logging users in to access their data from a mobile app for example is more a case for OAuth. 
You can read more about OAuth in Magento here and about the configuration here.

The API's are more meant to exchange information not tied to a specific user.
"
2544,2544,4050,glsl demo suggestions?,"In a lot of places I interviewed recently, I have been asked many a times if I have worked with shaders. Even though, I have read and understand the pipeline, the answer to that question has been no. Recently, one of the places asked me if I can send them a sample of 'something' that is ""visually polished"".

So, I decided to take the plunge and wrote some simple shader in GLSL(with opengl).I now have a basic setup where I can use vbos with glsl shaders.

I have a very short window left to send something to them and I was wondering if someone  with experience, could suggest an idea that is interesting enough to grab someone's attention.

Thanks
",brainydexter,https://gamedev.stackexchange.com/users/4638,"How about metaballs ? They make for a pretty interesting demo and there is a lot you can do with shading like point lights, reflection, refraction and so on.
There is also the classic terrain + water demo, in which you can have texturing, shades, displacement mapping (for the water), reflection...
",dotminic,https://gamedev.stackexchange.com/users/2469,http://gamedev.stackexchange.com/questions/8654/glsl-demo-suggestions,TECHNOLOGY,gamedev.stackexchange.com,1.0,0.4444444444444444,0.6666666666666666,1.0,0.3333333333333333,0.0,1.0,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,0.0,1.0,Glsl presentation suggestions?,"In a lot of places I interviewed recently, I have been asked many a times if I have worked with shaders. Even though, I have read and understand the pipeline, the answer to that question has been no. Recently, one of the places asked me if I can send them a sample of 'something' that is ""visually polished"".

So, I decided to take the plunge and wrote some simple shader in GLSL(with opengl).I now have a basic setup where I can use vbos with glsl shaders.

I have a very short window left to send something to them and I was wondering if someone  with experience, could suggest an idea that is interesting enough to grab someone's attention.

Thanks
","How about metaballs ? They make for a pretty interesting demo and there is a lot you can do with shading like point lights, reflection, refraction and so on.
There is also the classic terrain + water demo, in which you can have texturing, shades, displacement mapping (for the water), reflection...
"
5089,5089,8096,"Plot has red 'film', no error message","I am encountering really strange behavior: I wrote a function that plots values some data. After executing the code the resulting plot has the red 'error' colour, but only momentarily (maybe 0.1 sec). There is no error message, so the plot seems fine. However, when I export the graphic, the red colour is exported too. There seems no way to get the graphic without the red.

I am (in this case) not interested in what caused the error message but want to export the graphic without te red colour. Does anyone know how to do this?
I tried using Quiet[] but that did not help.



My code:

 PlotBetaCI[whole_,everyminute_]:=
        Module[
        {len,linearmodels,betas,lows,highs},

        len=Length[everyminute];

        linearmodels=Quiet@LinearModelFit[Transpose[{#,whole}],x,x]&amp;/@everyminute;

        betas=Transpose[{Range[len],#[""ParameterConfidenceIntervalTableEntries""][[2,1]]&amp;/@linearmodels}];

        lows=Transpose[{Range[len],#[""ParameterConfidenceIntervalTableEntries""][[2,3,1]]&amp;/@linearmodels}];

        highs=Transpose[{Range[len],#[""ParameterConfidenceIntervalTableEntries""][[2,3,2]]&amp;/@linearmodels}];

        ListPlot[{betas,Sequence@@Transpose[{lows,highs}]},Joined-&gt;{False,Sequence@@ConstantArray[True,len]},PlotStyle-&gt;Black,PlotMarkers-&gt;{Graphics[{Line[{{-1,-1},{1,1}}],Line[{{-1,1},{1,-1}}]},ImageSize-&gt;10],Sequence@@ConstantArray[Graphics[{Line[{{0,0},{0.04,0}}]},ImageSize-&gt;10],len]},ImageSize-&gt;Large,PlotRange-&gt;{Automatic,{Automatic,1.5}}]
    ]


The command to actually plot is (this produces the plot I am talking about)

PlotBetaCI[rmssd, everyminutermssd]


rmssd is a list of values. everyminutermssd has the same length, but depth 10.
",Aart Goossens,https://mathematica.stackexchange.com/users/1032,"The pink box shows a formatting error. You can disable highlighting of formatting errors for a specific object using Style:

Style[
 Graphics[{Disk[], garbage}],
 AutoStyleOptions -&gt; {""HighlightFormattingErrors"" -&gt; False}]




You can also change the setting globally using the Preferences dialog (Edit - Preferences - Messages - Formatting error indications), or just for the current session using:

SetOptions[$FrontEndSession,  AutoStyleOptions -&gt; {""HighlightFormattingErrors"" -&gt; False}]

",Simon Woods,https://mathematica.stackexchange.com/users/862,http://mathematica.stackexchange.com/questions/51335/plot-has-red-film-no-error-message,TECHNOLOGY,mathematica.stackexchange.com,0.8888888888888888,0.4444444444444444,0.0,1.0,0.6666666666666666,1.0,0.6666666666666666,0.4444444444444444,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.6666666666666666,0.8888888888888888,"Plot has red ""film"", no error message","I am encountering really strange behavior: I wrote a function that plots values some data. After executing the code the resulting plot has the red 'error' colour, but only momentarily (maybe 0.1 sec). There is no error message, so the plot seems fine. However, when I export the graphic, the red colour is exported too. There seems no way to get the graphic without the red.

I am (in this case) not interested in what caused the error message but want to export the graphic without te red colour. Does anyone know how to do this?
I tried using Quiet[] but that did not help.



My code:

 PlotBetaCI[whole_,everyminute_]:=
        Module[
        {len,linearmodels,betas,lows,highs},

        len=Length[everyminute];

        linearmodels=Quiet@LinearModelFit[Transpose[{#,whole}],x,x]&amp;/@everyminute;

        betas=Transpose[{Range[len],#[""ParameterConfidenceIntervalTableEntries""][[2,1]]&amp;/@linearmodels}];

        lows=Transpose[{Range[len],#[""ParameterConfidenceIntervalTableEntries""][[2,3,1]]&amp;/@linearmodels}];

        highs=Transpose[{Range[len],#[""ParameterConfidenceIntervalTableEntries""][[2,3,2]]&amp;/@linearmodels}];

        ListPlot[{betas,Sequence@@Transpose[{lows,highs}]},Joined-&gt;{False,Sequence@@ConstantArray[True,len]},PlotStyle-&gt;Black,PlotMarkers-&gt;{Graphics[{Line[{{-1,-1},{1,1}}],Line[{{-1,1},{1,-1}}]},ImageSize-&gt;10],Sequence@@ConstantArray[Graphics[{Line[{{0,0},{0.04,0}}]},ImageSize-&gt;10],len]},ImageSize-&gt;Large,PlotRange-&gt;{Automatic,{Automatic,1.5}}]
    ]


The command to actually plot is (this produces the plot I am talking about)

PlotBetaCI[rmssd, everyminutermssd]


rmssd is a list of values. everyminutermssd has the same length, but depth 10.
","The pink box shows a formatting error. You can disable highlighting of formatting errors for a specific object using Style:

Style[
 Graphics[{Disk[], garbage}],
 AutoStyleOptions -&gt; {""HighlightFormattingErrors"" -&gt; False}]




You can also change the setting globally using the Preferences dialog (Edit - Preferences - Messages - Formatting error indications), or just for the current session using:

SetOptions[$FrontEndSession,  AutoStyleOptions -&gt; {""HighlightFormattingErrors"" -&gt; False}]

"
3771,3771,6004,"Can the term ""jack/jerk off"" be used for female masturbation?","I apologize for this potentially obscene question.

Can the terms jack off or jerk off be used for female masturbation? If not (which is my intuition), what would be the not too poetic vulgar slang equivalent? By too poetic I refer to expressions such as spank the monkey, choke the chicken, etc.

I checked online dictionaries, and most of them don't expand on the usage, and some of the definitions in the Urban Dictionary imply that jack off primarily refers to male masturbation, but do not provide the female counterpart. 
",Armen Ծիրունյան,https://english.stackexchange.com/users/11268,"I vote for touching oneself. (Best political party ever?)

I assume there’s some particular reason you want to avoid the word masturbate—too clinical, perhaps. If you’re looking for a euphemism that isn’t ostentatiously vulgar, I think touching oneself fits the bill, without sounding terribly childish. If you’re working on erotic fiction, masturbation does sound oddly forward; touching, rubbing, fingering, and other literal actions are all common, cromulent alternatives.

And for the love of all that is good in literature, never, ever call a vulva a sex. It’s not cute.
",Jon Purdy,https://english.stackexchange.com/users/1506,http://english.stackexchange.com/questions/60900/can-the-term-jack-jerk-off-be-used-for-female-masturbation,CULTURE,english.stackexchange.com,1.0,0.7777777777777778,0.0,1.0,1.0,0.3333333333333333,0.6666666666666666,0.4444444444444444,0.3333333333333333,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,1.0,1.0,0.8888888888888888,1.0,1.0,0.8,0.0,0.0,1.0,0.8888888888888888,"Can the word ""Jack"" be used for female masturbation?","I apologize for this potentially obscene question.

Can the terms jack off or jerk off be used for female masturbation? If not (which is my intuition), what would be the not too poetic vulgar slang equivalent? By too poetic I refer to expressions such as spank the monkey, choke the chicken, etc.

I checked online dictionaries, and most of them don't expand on the usage, and some of the definitions in the Urban Dictionary imply that jack off primarily refers to male masturbation, but do not provide the female counterpart. 
","I vote for touching oneself. (Best political party ever?)

I assume there’s some particular reason you want to avoid the word masturbate—too clinical, perhaps. If you’re looking for a euphemism that isn’t ostentatiously vulgar, I think touching oneself fits the bill, without sounding terribly childish. If you’re working on erotic fiction, masturbation does sound oddly forward; touching, rubbing, fingering, and other literal actions are all common, cromulent alternatives.

And for the love of all that is good in literature, never, ever call a vulva a sex. It’s not cute.
"
5714,5714,9054,iMac wakes up without any noticeable reason,"I have a iMac 27"" late 2012, OS X 10.8.4 and last night it woke up from sleep-mode while I was 3 meters away from it. Nobody but me was in the room. The login-Screen was visible. After some seconds the main screen went black again, but the screen of the second monitor (from LG, connected via a thunderbolt-adapter) kept glowing in a dark gray light. So I hit a key on the keyboard, the mac woke up again, and I sent it to sleep by pressing the power-button. Now both screen was black and I went to bed.  

I did google that today and I found the command pmset -g log which prints out a hybernate-log, and in this log I found evidence for even more strange wake-up-events. This is a part of this log:

Time stamp                Domain                Message                                                                     Duration    Delay     
==========                ======                =======                                                                     ========    =====     
UUID: EBB08E57-0FC8-4724-AD4B-30629C0130BE
2013-08-10 18:49:57 MESZ Sleep                  Power Button Sleep Sleep: Using AC                                          4204 secs 
2013-08-10 18:49:57 MESZ Assertions             PID 182(apsd) Released ApplePushServiceTask ""com.apple.apsd-waitingformessages-push.apple.com"" 00:16:58  id:0xc00000d3d Aggregate:0x1040    
2013-08-10 18:49:57 MESZ WakeRequests           Clients requested wake events: None                                         
2013-08-10 20:00:01 MESZ DarkWake               DarkWake due to EC.SleepTimer/SleepTimer: Using AC                          0 secs    
2013-08-10 20:00:01 MESZ HibernateStats         hibmode=0 standbydelay=4200                                                             rd=662 ms   
2013-08-10 20:00:01 MESZ Sleep                  Maintenance Sleep Sleep: Using AC                                           10250 secs
2013-08-10 20:00:04 MESZ Assertions             PID 13(UserEventAgent) Created BackgroundTask ""Checking for Software Updates (com.apple.SoftwareUpdate.DarkWakeFire)"" 00:00:04  id:0xc00000d86 Aggregate:0x1040 
2013-08-10 20:00:04 MESZ Assertions             PID 1979(SoftwareUpdateC) Created BackgroundTask ""Checking for Software Updates (com.apple.SoftwareUpdate.BackgroundDownload)"" 00:00:04  id:0xc00000d88 Aggregate:0x1040    
2013-08-10 20:00:06 MESZ Assertions             PID 1979(SoftwareUpdateC) Released BackgroundTask ""Checking for Software Updates (com.apple.SoftwareUpdate.BackgroundDownload)"" 00:00:06  id:0xc00000d88 Aggregate:0x1040   
2013-08-10 20:00:06 MESZ Assertions             PID 13(UserEventAgent) Released BackgroundTask ""Checking for Software Updates (com.apple.SoftwareUpdate.DarkWakeFire)"" 00:00:06  id:0xc00000d86 Aggregate:0x1040    
2013-08-10 20:00:17 MESZ SlowResponse           PMConnection: Response from mDNSResponder is slow (powercaps:0x0)                       15994 ms    
2013-08-10 20:00:17 MESZ WakeRequests           Clients requested wake events: None                                         
2013-08-10 22:50:51 MESZ Wake                   Wake from Standby due to EC.SleepTimer/SleepTimer: Using AC                 39 secs   
2013-08-10 22:50:51 MESZ HibernateStats         hibmode=0 standbydelay=4200                                                             rd=654 ms   
2013-08-10 22:50:59 MESZ Assertions             PID 182(apsd) Created ApplePushServiceTask ""com.apple.apsd-waitingformessages-push.apple.com"" 00:00:05  id:0xc00000dca Aggregate:0x1040 
2013-08-10 22:51:13 MESZ Assertions             PID 182(apsd) TimedOut ApplePushServiceTask ""com.apple.apsd-waitingformessages-push.apple.com"" 00:00:19  id:0xc00000dca Aggregate:0x1040    
2013-08-10 22:51:13 MESZ Assertions             Summary- Aggregate:0x40 Using AC                                            
Sleep/Wakes since boot:27   Dark Wake Count in this sleep cycle:1

Time stamp                Domain                Message                                                                     Duration    Delay     
==========                ======                =======                                                                     ========    =====     
UUID: 5CD9A4D4-6924-4423-A3FF-D2DCC23BAD4F
2013-08-10 22:51:30 MESZ Sleep                  Power Button Sleep Sleep: Using AC                                          4205 secs 
2013-08-10 22:51:30 MESZ SlowResponse           Kernel: Response from powerd is slow                                                    15997 ms    
2013-08-10 22:51:30 MESZ Assertions             PID 182(apsd) Released ApplePushServiceTask ""com.apple.apsd-waitingformessages-push.apple.com"" 00:00:37  id:0xc00000dca Aggregate:0x1040    
2013-08-10 22:51:30 MESZ WakeRequests           Clients requested wake events: None                                         
2013-08-11 00:01:35 MESZ DarkWake               DarkWake due to EC.SleepTimer/SleepTimer: Using AC                          0 secs    
2013-08-11 00:01:35 MESZ HibernateStats         hibmode=0 standbydelay=4200                                                             rd=654 ms   
2013-08-11 00:01:35 MESZ Sleep                  Maintenance Sleep Sleep: Using AC                                           10240 secs
2013-08-11 00:01:40 MESZ Assertions             PID 144(UserEventAgent) Created BackgroundTask ""Checking for Software Updates (com.apple.SoftwareUpdate.DarkWakeFire)"" 00:00:04  id:0xc00000de6 Aggregate:0x1040    
2013-08-11 00:01:44 MESZ Assertions             PID 144(UserEventAgent) Released BackgroundTask ""Checking for Software Updates (com.apple.SoftwareUpdate.DarkWakeFire)"" 00:00:09  id:0xc00000de6 Aggregate:0x40 
2013-08-11 00:01:51 MESZ SlowResponse           PMConnection: Response from mDNSResponder is slow (powercaps:0x0)                       16002 ms    
2013-08-11 00:01:51 MESZ WakeRequests           Clients requested wake events: None                                         
2013-08-11 02:52:04 MESZ Assertions             PID 2005(helpd) Created BackgroundTask ""com.apple.helpd.sdmbuilding"" 00:00:07  id:0xc00000df9 Aggregate:0x1040  
2013-08-11 02:52:15 MESZ Wake                   Wake from Standby due to EC.SleepTimer/SleepTimer: Using AC                 313 secs  
2013-08-11 02:52:15 MESZ HibernateStats         hibmode=0 standbydelay=4200                                                             rd=717 ms   
2013-08-11 02:52:25 MESZ Assertions             PID 182(apsd) Created ApplePushServiceTask ""com.apple.apsd-waitingformessages-push.apple.com"" 00:00:08  id:0xc00000e23 Aggregate:0x1040 
2013-08-11 02:52:37 MESZ Assertions             PID 182(apsd) TimedOut ApplePushServiceTask ""com.apple.apsd-waitingformessages-push.apple.com"" 00:00:20  id:0xc00000e23 Aggregate:0x1040    
2013-08-11 02:52:37 MESZ Assertions             Summary- Aggregate:0x1040 Using AC                                          
2013-08-11 02:53:17 MESZ Assertions             PID 2016(SubmitDiagInfo) Created PreventSystemSleep ""com.apple.SubmitDiagInfo.run"" 00:00:00  id:0x800000e35 Aggregate:0x11140   
2013-08-11 02:53:18 MESZ Assertions             PID 2016(SubmitDiagInfo) Released PreventSystemSleep ""com.apple.SubmitDiagInfo.run"" 00:00:00  id:0x800000e35 Aggregate:0x1040   
2013-08-11 02:57:28 MESZ Assertions             PID 2005(helpd) Released BackgroundTask ""com.apple.helpd.sdmbuilding"" 00:05:32  id:0xc00000df9 Aggregate:0x40   
Sleep/Wakes since boot:29   Dark Wake Count in this sleep cycle:1

Time stamp                Domain                Message                                                                     Duration    Delay     
==========                ======                =======                                                                     ========    =====     
UUID: B5690C9E-7E6A-4FC8-9C71-D561FC8CD702
2013-08-11 02:57:28 MESZ Sleep                  Idle Sleep Sleep: Using AC                                                  4204 secs 
2013-08-11 02:57:28 MESZ SlowResponse           Kernel: Response from powerd is slow                                                    15998 ms    
2013-08-11 02:57:28 MESZ Assertions             PID 182(apsd) Released ApplePushServiceTask ""com.apple.apsd-waitingformessages-push.apple.com"" 00:05:11  id:0xc00000e23 Aggregate:0x1040    
2013-08-11 02:57:28 MESZ WakeRequests           Clients requested wake events: None                                         
2013-08-11 04:07:32 MESZ DarkWake               DarkWake due to EC.SleepTimer/SleepTimer: Using AC                          0 secs    
2013-08-11 04:07:32 MESZ HibernateStats         hibmode=0 standbydelay=4200                                                             rd=717 ms   
2013-08-11 04:07:32 MESZ Sleep                  Maintenance Sleep Sleep: Using AC                                           5314 secs 
2013-08-11 04:07:38 MESZ Assertions             PID 144(UserEventAgent) Created BackgroundTask ""Checking for Software Updates (com.apple.SoftwareUpdate.DarkWakeFire)"" 00:00:05  id:0xc00000e4a Aggregate:0x1040    
2013-08-11 04:07:42 MESZ Assertions             PID 144(UserEventAgent) Released BackgroundTask ""Checking for Software Updates (com.apple.SoftwareUpdate.DarkWakeFire)"" 00:00:09  id:0xc00000e4a Aggregate:0x40 
2013-08-11 04:07:48 MESZ SlowResponse           PMConnection: Response from mDNSResponder is slow (powercaps:0x0)                       15995 ms    
2013-08-11 04:07:48 MESZ WakeRequests           Clients requested wake events: None                                         
2013-08-11 05:36:06 MESZ Wake                   Wake from Standby due to EHC1/: Using AC                                    1786 secs 
2013-08-11 05:36:06 MESZ HibernateStats         hibmode=0 standbydelay=4200                                                             rd=807 ms   
2013-08-11 05:36:14 MESZ Assertions             PID 182(apsd) Created ApplePushServiceTask ""com.apple.apsd-waitingformessages-push.apple.com"" 00:00:06  id:0xc00000e6e Aggregate:0x1040 
2013-08-11 05:36:28 MESZ Assertions             PID 182(apsd) TimedOut ApplePushServiceTask ""com.apple.apsd-waitingformessages-push.apple.com"" 00:00:20  id:0xc00000e6e Aggregate:0x1040    
2013-08-11 05:36:28 MESZ Assertions             Summary- Aggregate:0x40 Using AC                                            
2013-08-11 05:36:53 MESZ Assertions             PID 124(coreaudiod) Created NoIdleSleepAssertion ""com.apple.audio.'AppleHDAEngineOutput:1B,0,1,2:0'.noidlesleep"" 00:00:08  id:0x100000e7d Aggregate:0x42    
2013-08-11 05:37:31 MESZ Assertions             PID 124(coreaudiod) Released NoIdleSleepAssertion ""com.apple.audio.'AppleHDAEngineOutput:1B,0,1,2:0'.noidlesleep"" 00:00:45  id:0x100000e7d Aggregate:0x40   
2013-08-11 05:38:01 MESZ Assertions             PID 124(coreaudiod) Created NoIdleSleepAssertion ""com.apple.audio.'AppleHDAEngineOutput:1B,0,1,2:0'.noidlesleep"" 00:00:07  id:0x100000e82 Aggregate:0x42    
2013-08-11 05:40:44 MESZ Assertions             PID 124(coreaudiod) Released NoIdleSleepAssertion ""com.apple.audio.'AppleHDAEngineOutput:1B,0,1,2:0'.noidlesleep"" 00:02:50  id:0x100000e82 Aggregate:0x40   
2013-08-11 05:42:05 MESZ Assertions             PID 124(coreaudiod) Created NoIdleSleepAssertion ""com.apple.audio.'AppleHDAEngineOutput:1B,0,1,2:0'.noidlesleep"" 00:00:07  id:0x100000e8a Aggregate:0x42    
2013-08-11 05:47:15 MESZ Assertions             PID 124(coreaudiod) Released NoIdleSleepAssertion ""com.apple.audio.'AppleHDAEngineOutput:1B,0,1,2:0'.noidlesleep"" 00:05:17  id:0x100000e8a Aggregate:0x40   
2013-08-11 05:57:31 MESZ Assertions             PID 124(coreaudiod) Created NoIdleSleepAssertion ""com.apple.audio.'AppleHDAEngineOutput:1B,0,1,2:0'.noidlesleep"" 00:00:07  id:0x100000e9b Aggregate:0x42    
2013-08-11 05:58:25 MESZ Assertions             PID 124(coreaudiod) Released NoIdleSleepAssertion ""com.apple.audio.'AppleHDAEngineOutput:1B,0,1,2:0'.noidlesleep"" 00:01:01  id:0x100000e9b Aggregate:0x40   
2013-08-11 05:58:57 MESZ Assertions             PID 124(coreaudiod) Created NoIdleSleepAssertion ""com.apple.audio.'AppleHDAEngineOutput:1B,0,1,2:0'.noidlesleep"" 00:00:07  id:0x100000e9d Aggregate:0x42    
2013-08-11 05:59:18 MESZ Assertions             PID 124(coreaudiod) Released NoIdleSleepAssertion ""com.apple.audio.'AppleHDAEngineOutput:1B,0,1,2:0'.noidlesleep"" 00:00:28  id:0x100000e9d Aggregate:0x40   
2013-08-11 06:00:08 MESZ Assertions             PID 124(coreaudiod) Created NoIdleSleepAssertion ""com.apple.audio.'AppleHDAEngineOutput:1B,0,1,2:0'.noidlesleep"" 00:00:07  id:0x100000e9e Aggregate:0x42    
2013-08-11 06:05:41 MESZ Assertions             PID 124(coreaudiod) Released NoIdleSleepAssertion ""com.apple.audio.'AppleHDAEngineOutput:1B,0,1,2:0'.noidlesleep"" 00:05:40  id:0x100000e9e Aggregate:0x40   
Sleep/Wakes since boot:31   Dark Wake Count in this sleep cycle:1


The spooky wake-up-event I was watching was at 2013-08-10 22:50:51
But the logfile shows even more activities while I was sleeping in my bed:

2013-08-11 00:01:35
2013-08-11 02:52:04
2013-08-11 04:07:32  

The next wake-up was initiated by me: 2013-08-11 04:07:32
But what are the reasons for those events in the middle of the night? Why did my iMac wake up?

UPDATE

syslog |grep -i ""Wake reason""

Aug 10 20:00:00 huberts-imac kernel[0] &lt;Debug&gt;: Wake reason: EC.SleepTimer (SleepTimer)
Aug 10 22:50:31 huberts-imac kernel[0] &lt;Debug&gt;: Wake reason: EC.SleepTimer (SleepTimer)
Aug 11 00:01:34 huberts-imac kernel[0] &lt;Debug&gt;: Wake reason: EC.SleepTimer (SleepTimer)
Aug 11 02:51:55 huberts-imac kernel[0] &lt;Debug&gt;: Wake reason: EC.SleepTimer (SleepTimer)
Aug 11 04:07:31 huberts-imac kernel[0] &lt;Debug&gt;: Wake reason: EC.SleepTimer (SleepTimer)
Aug 11 05:35:46 huberts-imac kernel[0] &lt;Debug&gt;: Wake reason: EHC1
Aug 11 07:15:55 huberts-imac kernel[0] &lt;Debug&gt;: Wake reason: EC.SleepTimer (SleepTimer)
Aug 11 09:15:54 huberts-imac kernel[0] &lt;Debug&gt;: Wake reason: EHC1
Aug 11 11:14:09 huberts-imac kernel[0] &lt;Debug&gt;: Wake reason: EC.SleepTimer (SleepTimer)
Aug 11 12:40:27 huberts-imac kernel[0] &lt;Debug&gt;: Wake reason: EHC1
Aug 11 13:11:04 huberts-imac kernel[0] &lt;Debug&gt;: Wake reason: EHC1
Aug 11 15:08:25 huberts-imac kernel[0] &lt;Debug&gt;: Wake reason: EC.SleepTimer (SleepTimer)
Aug 11 17:23:56 huberts-imac kernel[0] &lt;Debug&gt;: Wake reason: EHC1


EHC1 corresponds with the times when I did wake up the machine.
EC.SleepTimer are wake-ups that happened without my interaction.
What are EHC1 and EC.SleepTimer?
",Hubert Schölnast,https://apple.stackexchange.com/users/25938,"Check your log messages by typing following in Terminal while looking for the time stamp for when it occurred.

syslog |grep -i ""Wake reason""


which will give you a comprehensive report only for wake up reasons.

UPDATE:

Looking at your log now, it all looks normal. 

Be aware that the only time your computer can do some housekeeping is during the sleep time. That is intended by design. 

However, to prevent unwanted wake ups disable the wake for wifi network access.
",Buscar웃,https://apple.stackexchange.com/users/46541,http://apple.stackexchange.com/questions/98606/imac-wakes-up-without-any-noticeable-reason,TECHNOLOGY,apple.stackexchange.com,1.0,0.3333333333333333,0.0,0.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,1.0,IMac wakes up for no obvious reason,"I have a iMac 27"" late 2012, OS X 10.8.4 and last night it woke up from sleep-mode while I was 3 meters away from it. Nobody but me was in the room. The login-Screen was visible. After some seconds the main screen went black again, but the screen of the second monitor (from LG, connected via a thunderbolt-adapter) kept glowing in a dark gray light. So I hit a key on the keyboard, the mac woke up again, and I sent it to sleep by pressing the power-button. Now both screen was black and I went to bed.  

I did google that today and I found the command pmset -g log which prints out a hybernate-log, and in this log I found evidence for even more strange wake-up-events. This is a part of this log:

Time stamp                Domain                Message                                                                     Duration    Delay     
==========                ======                =======                                                                     ========    =====     
UUID: EBB08E57-0FC8-4724-AD4B-30629C0130BE
2013-08-10 18:49:57 MESZ Sleep                  Power Button Sleep Sleep: Using AC                                          4204 secs 
2013-08-10 18:49:57 MESZ Assertions             PID 182(apsd) Released ApplePushServiceTask ""com.apple.apsd-waitingformessages-push.apple.com"" 00:16:58  id:0xc00000d3d Aggregate:0x1040    
2013-08-10 18:49:57 MESZ WakeRequests           Clients requested wake events: None                                         
2013-08-10 20:00:01 MESZ DarkWake               DarkWake due to EC.SleepTimer/SleepTimer: Using AC                          0 secs    
2013-08-10 20:00:01 MESZ HibernateStats         hibmode=0 standbydelay=4200                                                             rd=662 ms   
2013-08-10 20:00:01 MESZ Sleep                  Maintenance Sleep Sleep: Using AC                                           10250 secs
2013-08-10 20:00:04 MESZ Assertions             PID 13(UserEventAgent) Created BackgroundTask ""Checking for Software Updates (com.apple.SoftwareUpdate.DarkWakeFire)"" 00:00:04  id:0xc00000d86 Aggregate:0x1040 
2013-08-10 20:00:04 MESZ Assertions             PID 1979(SoftwareUpdateC) Created BackgroundTask ""Checking for Software Updates (com.apple.SoftwareUpdate.BackgroundDownload)"" 00:00:04  id:0xc00000d88 Aggregate:0x1040    
2013-08-10 20:00:06 MESZ Assertions             PID 1979(SoftwareUpdateC) Released BackgroundTask ""Checking for Software Updates (com.apple.SoftwareUpdate.BackgroundDownload)"" 00:00:06  id:0xc00000d88 Aggregate:0x1040   
2013-08-10 20:00:06 MESZ Assertions             PID 13(UserEventAgent) Released BackgroundTask ""Checking for Software Updates (com.apple.SoftwareUpdate.DarkWakeFire)"" 00:00:06  id:0xc00000d86 Aggregate:0x1040    
2013-08-10 20:00:17 MESZ SlowResponse           PMConnection: Response from mDNSResponder is slow (powercaps:0x0)                       15994 ms    
2013-08-10 20:00:17 MESZ WakeRequests           Clients requested wake events: None                                         
2013-08-10 22:50:51 MESZ Wake                   Wake from Standby due to EC.SleepTimer/SleepTimer: Using AC                 39 secs   
2013-08-10 22:50:51 MESZ HibernateStats         hibmode=0 standbydelay=4200                                                             rd=654 ms   
2013-08-10 22:50:59 MESZ Assertions             PID 182(apsd) Created ApplePushServiceTask ""com.apple.apsd-waitingformessages-push.apple.com"" 00:00:05  id:0xc00000dca Aggregate:0x1040 
2013-08-10 22:51:13 MESZ Assertions             PID 182(apsd) TimedOut ApplePushServiceTask ""com.apple.apsd-waitingformessages-push.apple.com"" 00:00:19  id:0xc00000dca Aggregate:0x1040    
2013-08-10 22:51:13 MESZ Assertions             Summary- Aggregate:0x40 Using AC                                            
Sleep/Wakes since boot:27   Dark Wake Count in this sleep cycle:1

Time stamp                Domain                Message                                                                     Duration    Delay     
==========                ======                =======                                                                     ========    =====     
UUID: 5CD9A4D4-6924-4423-A3FF-D2DCC23BAD4F
2013-08-10 22:51:30 MESZ Sleep                  Power Button Sleep Sleep: Using AC                                          4205 secs 
2013-08-10 22:51:30 MESZ SlowResponse           Kernel: Response from powerd is slow                                                    15997 ms    
2013-08-10 22:51:30 MESZ Assertions             PID 182(apsd) Released ApplePushServiceTask ""com.apple.apsd-waitingformessages-push.apple.com"" 00:00:37  id:0xc00000dca Aggregate:0x1040    
2013-08-10 22:51:30 MESZ WakeRequests           Clients requested wake events: None                                         
2013-08-11 00:01:35 MESZ DarkWake               DarkWake due to EC.SleepTimer/SleepTimer: Using AC                          0 secs    
2013-08-11 00:01:35 MESZ HibernateStats         hibmode=0 standbydelay=4200                                                             rd=654 ms   
2013-08-11 00:01:35 MESZ Sleep                  Maintenance Sleep Sleep: Using AC                                           10240 secs
2013-08-11 00:01:40 MESZ Assertions             PID 144(UserEventAgent) Created BackgroundTask ""Checking for Software Updates (com.apple.SoftwareUpdate.DarkWakeFire)"" 00:00:04  id:0xc00000de6 Aggregate:0x1040    
2013-08-11 00:01:44 MESZ Assertions             PID 144(UserEventAgent) Released BackgroundTask ""Checking for Software Updates (com.apple.SoftwareUpdate.DarkWakeFire)"" 00:00:09  id:0xc00000de6 Aggregate:0x40 
2013-08-11 00:01:51 MESZ SlowResponse           PMConnection: Response from mDNSResponder is slow (powercaps:0x0)                       16002 ms    
2013-08-11 00:01:51 MESZ WakeRequests           Clients requested wake events: None                                         
2013-08-11 02:52:04 MESZ Assertions             PID 2005(helpd) Created BackgroundTask ""com.apple.helpd.sdmbuilding"" 00:00:07  id:0xc00000df9 Aggregate:0x1040  
2013-08-11 02:52:15 MESZ Wake                   Wake from Standby due to EC.SleepTimer/SleepTimer: Using AC                 313 secs  
2013-08-11 02:52:15 MESZ HibernateStats         hibmode=0 standbydelay=4200                                                             rd=717 ms   
2013-08-11 02:52:25 MESZ Assertions             PID 182(apsd) Created ApplePushServiceTask ""com.apple.apsd-waitingformessages-push.apple.com"" 00:00:08  id:0xc00000e23 Aggregate:0x1040 
2013-08-11 02:52:37 MESZ Assertions             PID 182(apsd) TimedOut ApplePushServiceTask ""com.apple.apsd-waitingformessages-push.apple.com"" 00:00:20  id:0xc00000e23 Aggregate:0x1040    
2013-08-11 02:52:37 MESZ Assertions             Summary- Aggregate:0x1040 Using AC                                          
2013-08-11 02:53:17 MESZ Assertions             PID 2016(SubmitDiagInfo) Created PreventSystemSleep ""com.apple.SubmitDiagInfo.run"" 00:00:00  id:0x800000e35 Aggregate:0x11140   
2013-08-11 02:53:18 MESZ Assertions             PID 2016(SubmitDiagInfo) Released PreventSystemSleep ""com.apple.SubmitDiagInfo.run"" 00:00:00  id:0x800000e35 Aggregate:0x1040   
2013-08-11 02:57:28 MESZ Assertions             PID 2005(helpd) Released BackgroundTask ""com.apple.helpd.sdmbuilding"" 00:05:32  id:0xc00000df9 Aggregate:0x40   
Sleep/Wakes since boot:29   Dark Wake Count in this sleep cycle:1

Time stamp                Domain                Message                                                                     Duration    Delay     
==========                ======                =======                                                                     ========    =====     
UUID: B5690C9E-7E6A-4FC8-9C71-D561FC8CD702
2013-08-11 02:57:28 MESZ Sleep                  Idle Sleep Sleep: Using AC                                                  4204 secs 
2013-08-11 02:57:28 MESZ SlowResponse           Kernel: Response from powerd is slow                                                    15998 ms    
2013-08-11 02:57:28 MESZ Assertions             PID 182(apsd) Released ApplePushServiceTask ""com.apple.apsd-waitingformessages-push.apple.com"" 00:05:11  id:0xc00000e23 Aggregate:0x1040    
2013-08-11 02:57:28 MESZ WakeRequests           Clients requested wake events: None                                         
2013-08-11 04:07:32 MESZ DarkWake               DarkWake due to EC.SleepTimer/SleepTimer: Using AC                          0 secs    
2013-08-11 04:07:32 MESZ HibernateStats         hibmode=0 standbydelay=4200                                                             rd=717 ms   
2013-08-11 04:07:32 MESZ Sleep                  Maintenance Sleep Sleep: Using AC                                           5314 secs 
2013-08-11 04:07:38 MESZ Assertions             PID 144(UserEventAgent) Created BackgroundTask ""Checking for Software Updates (com.apple.SoftwareUpdate.DarkWakeFire)"" 00:00:05  id:0xc00000e4a Aggregate:0x1040    
2013-08-11 04:07:42 MESZ Assertions             PID 144(UserEventAgent) Released BackgroundTask ""Checking for Software Updates (com.apple.SoftwareUpdate.DarkWakeFire)"" 00:00:09  id:0xc00000e4a Aggregate:0x40 
2013-08-11 04:07:48 MESZ SlowResponse           PMConnection: Response from mDNSResponder is slow (powercaps:0x0)                       15995 ms    
2013-08-11 04:07:48 MESZ WakeRequests           Clients requested wake events: None                                         
2013-08-11 05:36:06 MESZ Wake                   Wake from Standby due to EHC1/: Using AC                                    1786 secs 
2013-08-11 05:36:06 MESZ HibernateStats         hibmode=0 standbydelay=4200                                                             rd=807 ms   
2013-08-11 05:36:14 MESZ Assertions             PID 182(apsd) Created ApplePushServiceTask ""com.apple.apsd-waitingformessages-push.apple.com"" 00:00:06  id:0xc00000e6e Aggregate:0x1040 
2013-08-11 05:36:28 MESZ Assertions             PID 182(apsd) TimedOut ApplePushServiceTask ""com.apple.apsd-waitingformessages-push.apple.com"" 00:00:20  id:0xc00000e6e Aggregate:0x1040    
2013-08-11 05:36:28 MESZ Assertions             Summary- Aggregate:0x40 Using AC                                            
2013-08-11 05:36:53 MESZ Assertions             PID 124(coreaudiod) Created NoIdleSleepAssertion ""com.apple.audio.'AppleHDAEngineOutput:1B,0,1,2:0'.noidlesleep"" 00:00:08  id:0x100000e7d Aggregate:0x42    
2013-08-11 05:37:31 MESZ Assertions             PID 124(coreaudiod) Released NoIdleSleepAssertion ""com.apple.audio.'AppleHDAEngineOutput:1B,0,1,2:0'.noidlesleep"" 00:00:45  id:0x100000e7d Aggregate:0x40   
2013-08-11 05:38:01 MESZ Assertions             PID 124(coreaudiod) Created NoIdleSleepAssertion ""com.apple.audio.'AppleHDAEngineOutput:1B,0,1,2:0'.noidlesleep"" 00:00:07  id:0x100000e82 Aggregate:0x42    
2013-08-11 05:40:44 MESZ Assertions             PID 124(coreaudiod) Released NoIdleSleepAssertion ""com.apple.audio.'AppleHDAEngineOutput:1B,0,1,2:0'.noidlesleep"" 00:02:50  id:0x100000e82 Aggregate:0x40   
2013-08-11 05:42:05 MESZ Assertions             PID 124(coreaudiod) Created NoIdleSleepAssertion ""com.apple.audio.'AppleHDAEngineOutput:1B,0,1,2:0'.noidlesleep"" 00:00:07  id:0x100000e8a Aggregate:0x42    
2013-08-11 05:47:15 MESZ Assertions             PID 124(coreaudiod) Released NoIdleSleepAssertion ""com.apple.audio.'AppleHDAEngineOutput:1B,0,1,2:0'.noidlesleep"" 00:05:17  id:0x100000e8a Aggregate:0x40   
2013-08-11 05:57:31 MESZ Assertions             PID 124(coreaudiod) Created NoIdleSleepAssertion ""com.apple.audio.'AppleHDAEngineOutput:1B,0,1,2:0'.noidlesleep"" 00:00:07  id:0x100000e9b Aggregate:0x42    
2013-08-11 05:58:25 MESZ Assertions             PID 124(coreaudiod) Released NoIdleSleepAssertion ""com.apple.audio.'AppleHDAEngineOutput:1B,0,1,2:0'.noidlesleep"" 00:01:01  id:0x100000e9b Aggregate:0x40   
2013-08-11 05:58:57 MESZ Assertions             PID 124(coreaudiod) Created NoIdleSleepAssertion ""com.apple.audio.'AppleHDAEngineOutput:1B,0,1,2:0'.noidlesleep"" 00:00:07  id:0x100000e9d Aggregate:0x42    
2013-08-11 05:59:18 MESZ Assertions             PID 124(coreaudiod) Released NoIdleSleepAssertion ""com.apple.audio.'AppleHDAEngineOutput:1B,0,1,2:0'.noidlesleep"" 00:00:28  id:0x100000e9d Aggregate:0x40   
2013-08-11 06:00:08 MESZ Assertions             PID 124(coreaudiod) Created NoIdleSleepAssertion ""com.apple.audio.'AppleHDAEngineOutput:1B,0,1,2:0'.noidlesleep"" 00:00:07  id:0x100000e9e Aggregate:0x42    
2013-08-11 06:05:41 MESZ Assertions             PID 124(coreaudiod) Released NoIdleSleepAssertion ""com.apple.audio.'AppleHDAEngineOutput:1B,0,1,2:0'.noidlesleep"" 00:05:40  id:0x100000e9e Aggregate:0x40   
Sleep/Wakes since boot:31   Dark Wake Count in this sleep cycle:1


The spooky wake-up-event I was watching was at 2013-08-10 22:50:51
But the logfile shows even more activities while I was sleeping in my bed:

2013-08-11 00:01:35
2013-08-11 02:52:04
2013-08-11 04:07:32  

The next wake-up was initiated by me: 2013-08-11 04:07:32
But what are the reasons for those events in the middle of the night? Why did my iMac wake up?

UPDATE

syslog |grep -i ""Wake reason""

Aug 10 20:00:00 huberts-imac kernel[0] &lt;Debug&gt;: Wake reason: EC.SleepTimer (SleepTimer)
Aug 10 22:50:31 huberts-imac kernel[0] &lt;Debug&gt;: Wake reason: EC.SleepTimer (SleepTimer)
Aug 11 00:01:34 huberts-imac kernel[0] &lt;Debug&gt;: Wake reason: EC.SleepTimer (SleepTimer)
Aug 11 02:51:55 huberts-imac kernel[0] &lt;Debug&gt;: Wake reason: EC.SleepTimer (SleepTimer)
Aug 11 04:07:31 huberts-imac kernel[0] &lt;Debug&gt;: Wake reason: EC.SleepTimer (SleepTimer)
Aug 11 05:35:46 huberts-imac kernel[0] &lt;Debug&gt;: Wake reason: EHC1
Aug 11 07:15:55 huberts-imac kernel[0] &lt;Debug&gt;: Wake reason: EC.SleepTimer (SleepTimer)
Aug 11 09:15:54 huberts-imac kernel[0] &lt;Debug&gt;: Wake reason: EHC1
Aug 11 11:14:09 huberts-imac kernel[0] &lt;Debug&gt;: Wake reason: EC.SleepTimer (SleepTimer)
Aug 11 12:40:27 huberts-imac kernel[0] &lt;Debug&gt;: Wake reason: EHC1
Aug 11 13:11:04 huberts-imac kernel[0] &lt;Debug&gt;: Wake reason: EHC1
Aug 11 15:08:25 huberts-imac kernel[0] &lt;Debug&gt;: Wake reason: EC.SleepTimer (SleepTimer)
Aug 11 17:23:56 huberts-imac kernel[0] &lt;Debug&gt;: Wake reason: EHC1


EHC1 corresponds with the times when I did wake up the machine.
EC.SleepTimer are wake-ups that happened without my interaction.
What are EHC1 and EC.SleepTimer?
","Check your log messages by typing following in Terminal while looking for the time stamp for when it occurred.

syslog |grep -i ""Wake reason""


which will give you a comprehensive report only for wake up reasons.

UPDATE:

Looking at your log now, it all looks normal. 

Be aware that the only time your computer can do some housekeeping is during the sleep time. That is intended by design. 

However, to prevent unwanted wake ups disable the wake for wifi network access.
"
5973,5973,9471,Is it better for a beginner to start with black and white photography?,"I'm quite a beginner in photography with no real experience in visual art. I became interested in it about 10 months ago. 

I inferred from the literature to avoid color photography for 2 to 3 years, or until I have a strong feeling for composition. 

It seems reasonable that first you should know to spot your interest in subject and express it on final print, a task in which colors may confuse a beginner. Besides I'm afraid that with no skill of actual seeing and analyzing I may end up with ugly oversaturated and dull images. Is there a professional opinion on subject, or I'm just inventing limitations of my own?
",J-unior,https://photo.stackexchange.com/users/28106,"I think the opposite question could also be posed: should a beginner start with color photography? B&amp;W requires knowledge and experience of how differently colors will render in gray. Reds, for example, will always appear as dark gray/black. Turning your question around (without actually changing it), with no skill of seeing and analyzing you may end up with ugly oversaturated and dull images.

It's probably best to accept that your first images are not going to be particularly great, no matter what. But that shouldn't discourage you! Photography is a learning process. If you're interested to learn B&amp;W, then you should do just that.
",Dan Wolfgang,https://photo.stackexchange.com/users/8473,http://photo.stackexchange.com/questions/56566/is-it-better-for-a-beginner-to-start-with-black-and-white-photography,LIFE_ARTS,photo.stackexchange.com,1.0,1.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.8888888888888888,0.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.4444444444444444,1.0,1.0,0.9333333333333332,0.0,0.0,0.0,1.0,Is it better for beginners to start with black-and-white photography?,"I'm quite a beginner in photography with no real experience in visual art. I became interested in it about 10 months ago. 

I inferred from the literature to avoid color photography for 2 to 3 years, or until I have a strong feeling for composition. 

It seems reasonable that first you should know to spot your interest in subject and express it on final print, a task in which colors may confuse a beginner. Besides I'm afraid that with no skill of actual seeing and analyzing I may end up with ugly oversaturated and dull images. Is there a professional opinion on subject, or I'm just inventing limitations of my own?
","I think we can also ask the opposite question: should beginners start with color photography? Black and white require knowledge and experience of how different colors will be rendered into gray. For example, red is always shown as dark gray / black. Turn your problem around (without actually changing it), without the skill of observation and analysis, you may get ugly oversaturated and boring images."
4004,4004,6394,Why do marshmallows poof up so huge when put in the microwave?,"As anyone who's put marshmallows in the microwave knows, they expand a ton! Sometimes they puff up to literally more than twice their original size (YouTube video for those who haven't seen it).

So, why?
At first I assumed it was because they had a lot of air in them, but that doesn't make sense. There's no way that amount of air can puff up that much from the heat!

What makes marshmallows poof up so much when they are microwaved?
",Nathan G.,https://cooking.stackexchange.com/users/6549,"Marshmallows expand so much because the water in them becomes steam, and gas takes up a LOT more volume than liquid. Specifically, 1 mL of water becomes ~1.36 LITERS of vapor, before it gets heated further.  That's 1000-fold expansion, before you add additional expansion as the gas is heated.  

Marshmallows don't have all that much water content, but when it's trapped in a stretchy gelatin matrix that holds gas readily, it only takes a bit to blow the whole thing up like a balloon.

You are correct that the gas expansion on its own is insufficient; unless I've badly muddled my calculations, gas expansion from 20C to ~150C (caramelization temperature) will increase the gas volume by under 50%.
",BobMcGee,https://cooking.stackexchange.com/users/6345,http://cooking.stackexchange.com/questions/16042/why-do-marshmallows-poof-up-so-huge-when-put-in-the-microwave,LIFE_ARTS,cooking.stackexchange.com,1.0,1.0,0.0,0.6666666666666666,1.0,0.3333333333333333,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.8888888888888888,1.0,1.0,1.0,0.0,0.0,1.0,1.0,Why does marshmallow spit so much in the microwave?,"As anyone who's put marshmallows in the microwave knows, they expand a ton! Sometimes they puff up to literally more than twice their original size (YouTube video for those who haven't seen it).

So, why?
At first I assumed it was because they had a lot of air in them, but that doesn't make sense. There's no way that amount of air can puff up that much from the heat!

What makes marshmallows poof up so much when they are microwaved?
","Marshmallows expand so much because the water in them becomes steam, and gas takes up a LOT more volume than liquid. Specifically, 1 mL of water becomes ~1.36 LITERS of vapor, before it gets heated further.  That's 1000-fold expansion, before you add additional expansion as the gas is heated.  

Marshmallows don't have all that much water content, but when it's trapped in a stretchy gelatin matrix that holds gas readily, it only takes a bit to blow the whole thing up like a balloon.

You are correct that the gas expansion on its own is insufficient; unless I've badly muddled my calculations, gas expansion from 20C to ~150C (caramelization temperature) will increase the gas volume by under 50%.
"
3161,3161,5032,How can I add a director name in line with author name in beamer?,"I would like to write director name in line with author name in a beamer like:

\author{Made by:\\Author name}
\director{Directed by:\\Director name}


but if I try to define director:

\def\director#1{\def\Director{#1}}\director{Director's Name}


Then it writes on the top of the first frame. Any suggestions?
",Peter,https://tex.stackexchange.com/users/15142,"You can adopt an approach based on columns environment:

\documentclass{beamer}
\usepackage[T1]{fontenc}

\usetheme{CambridgeUS}
\title{My title}
\institute{My institute}
\author[Author name]{Made by:\\Author name} %&lt;= used the short author name [] for the footline
\newcommand{\director}{Directed by:\\Director name}

% re-definition of the title page
\setbeamertemplate{title page}{
\centering
\begin{beamercolorbox}[rounded=true,shadow=true,sep=8pt,center]{title}
\inserttitle \par
\end{beamercolorbox}
\vfill
\begin{beamercolorbox}[leftskip=8cm,center,wd=0.7\textwidth]{author}
\begin{columns}[T]
\begin{column}{.49\textwidth}%
\centering
\insertauthor
\end{column}
\begin{column}{.49\textwidth}%
\centering
\director
\end{column}
\end{columns}
\end{beamercolorbox}
\vfill
\usebeamerfont{institute}\insertinstitute \par
\vfill
\centering
\insertdate\par
\vfill
}

\begin{document}
\begin{frame}
\titlepage
\end{frame}

\begin{frame}{Title}
example text
\end{frame}
\end{document}


which gives you:





Notice that I adopted the short name for the author to not display in the footline the string Made by:.
",Claudio Fiandrino,https://tex.stackexchange.com/users/13304,http://tex.stackexchange.com/questions/57977/how-can-i-add-a-director-name-in-line-with-author-name-in-beamer,TECHNOLOGY,tex.stackexchange.com,1.0,0.7777777777777778,0.0,1.0,1.0,1.0,0.5555555555555556,0.5555555555555556,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,0.7777777777777778,1.0,0.8666666666666666,1.0,0.0,0.0,0.8888888888888888,How to add a director's name consistent with the author's name in beamer?,"I would like to write director name in line with author name in a beamer like:

\author{Made by:\\Author name}
\director{Directed by:\\Director name}


but if I try to define director:

\def\director#1{\def\Director{#1}}\director{Director's Name}


Then it writes on the top of the first frame. Any suggestions?
","You can adopt an approach based on columns environment:

\documentclass{beamer}
\usepackage[T1]{fontenc}

\usetheme{CambridgeUS}
\title{My title}
\institute{My institute}
\author[Author name]{Made by:\\Author name} %&lt;= used the short author name [] for the footline
\newcommand{\director}{Directed by:\\Director name}

% re-definition of the title page
\setbeamertemplate{title page}{
\centering
\begin{beamercolorbox}[rounded=true,shadow=true,sep=8pt,center]{title}
\inserttitle \par
\end{beamercolorbox}
\vfill
\begin{beamercolorbox}[leftskip=8cm,center,wd=0.7\textwidth]{author}
\begin{columns}[T]
\begin{column}{.49\textwidth}%
\centering
\insertauthor
\end{column}
\begin{column}{.49\textwidth}%
\centering
\director
\end{column}
\end{columns}
\end{beamercolorbox}
\vfill
\usebeamerfont{institute}\insertinstitute \par
\vfill
\centering
\insertdate\par
\vfill
}

\begin{document}
\begin{frame}
\titlepage
\end{frame}

\begin{frame}{Title}
example text
\end{frame}
\end{document}


which gives you:





Notice that I adopted the short name for the author to not display in the footline the string Made by:.
"
4024,4024,6424,My thesis advisor is absent in my final stage of completing my Ph.D. programme,"I am a mathematics Ph.D. student who are in my final stage of completing my Ph.D. programme. My advisor is visiting an institute for a few months. The institute that he is visiting is in another country; because of the visa requirements and many other practical reasons, I cannot go there with him.

Now my progress is, I have all the main results ready (most of them have been written down) and I need to finish writing my thesis in about three weeks. My advisor has guided my through all the mathematical difficulties; now he left me behind to write the thesis all by my own. Furthermore, he has clearly indicated that he will NOT help me with the writing process. 

Now I need to figure out many things all by myself, from LaTeX to the organization, from the usage of languages to drawing pictures, etc. Also I need to verify the correctness and validity of all the results; he mentioned that he will not carefully read my draft. And I do not have much time to finish everything. I am feeling somewhat stressed and overwhelming. 

In this situation, should I seek assistance from other professors/lecturers who do research in a similar field, or should I try to figure everything out by myself? Should I hire someone to proofread my thesis when the draft is finished? 
",Zuriel,https://academia.stackexchange.com/users/24832,"Now that you have number of weeks left for the submission deadline; you have two options: 

Write up and Submit the Thesis: Finish the thesis as soon as possible. At this stage you should be able to write your Ph.D. thesis; without any supervision guidelines. Don't fall into 'what if' scenarios. At the end of the day the thesis and your defense on that day will grant you a Ph.D.  

Possible Extension: Don't submit a very poor thesis if your thesis lacks the required material. You will put the examiners at the very difficult and unpleasant situation; because if the required material is not there you be more likely failing your defense. I suggest you to print out your latest version of your thesis and discuss the extension issue with an academic. You can send an email to your supervisor and ask for a name of an academic to discuss this issue. 
",Dave Rose,https://academia.stackexchange.com/users/21552,http://academia.stackexchange.com/questions/38143/my-thesis-advisor-is-absent-in-my-final-stage-of-completing-my-ph-d-programme,LIFE_ARTS,academia.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,1.0,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.8,0.0,1.0,0.0,1.0,"At the end of my doctoral program, my thesis tutor was not available","I am a mathematics Ph.D. student who are in my final stage of completing my Ph.D. programme. My advisor is visiting an institute for a few months. The institute that he is visiting is in another country; because of the visa requirements and many other practical reasons, I cannot go there with him.

Now my progress is, I have all the main results ready (most of them have been written down) and I need to finish writing my thesis in about three weeks. My advisor has guided my through all the mathematical difficulties; now he left me behind to write the thesis all by my own. Furthermore, he has clearly indicated that he will NOT help me with the writing process. 

Now I need to figure out many things all by myself, from LaTeX to the organization, from the usage of languages to drawing pictures, etc. Also I need to verify the correctness and validity of all the results; he mentioned that he will not carefully read my draft. And I do not have much time to finish everything. I am feeling somewhat stressed and overwhelming. 

In this situation, should I seek assistance from other professors/lecturers who do research in a similar field, or should I try to figure everything out by myself? Should I hire someone to proofread my thesis when the draft is finished? 
","Now that you have number of weeks left for the submission deadline; you have two options: 

Write up and Submit the Thesis: Finish the thesis as soon as possible. At this stage you should be able to write your Ph.D. thesis; without any supervision guidelines. Don't fall into 'what if' scenarios. At the end of the day the thesis and your defense on that day will grant you a Ph.D.  

Possible Extension: Don't submit a very poor thesis if your thesis lacks the required material. You will put the examiners at the very difficult and unpleasant situation; because if the required material is not there you be more likely failing your defense. I suggest you to print out your latest version of your thesis and discuss the extension issue with an academic. You can send an email to your supervisor and ask for a name of an academic to discuss this issue. 
"
4306,4306,6861,Highlight a column in equation or math environment,"While explaining the idea product of two negative numbers I wanted to highlight a vertical part of the display to emphasize on the factors that are being multiplied by:

\documentclass[letterpaper]{article}
\usepackage{fullpage}
\usepackage{amsmath,amssymb,amsthm,enumitem}
\newcommand{\red}[1]{%
{\color{OrangeRed}#1}}
\begin{document}
    \begin{equation*}
    \left.\begin{array}{cc}
      -2\cdot \red{2}=&amp; -4 \\
      -2\cdot \red{1}=&amp; -2 \\
      -2\cdot \red{0}=&amp; 0
    \end{array}\right\} \text{\small Product increases by 2 each time.}
    \end{equation*}
\end{document}


This gives:


So I chose to use a color but then I had also wanted to achieve something like the following:


I am not interested in the yellow red bordered box. What am looking for is an arrow pointing on the red numbers with a vertical border around  them as shown and the possibility of adding a node with text in the same format shown aligned with the word ""Product"".


  Edit


Can I use this method to achieve this:

",azetina,https://tex.stackexchange.com/users/10898,"To accomplish this task you can make use of the tikzmark macro. This solution allows to get:



The code:

\documentclass[letterpaper]{article}
\usepackage{fullpage}
\usepackage{amsmath,amssymb,amsthm,enumitem}
\usepackage{xcolor}
\newcommand{\red}[1]{%
{\color{red}#1}}

\usepackage{tikz}

% to change colors
\newcommand{\fillcol}{white}
\newcommand{\bordercol}{red}

%% code by Andrew Stacey 
% http://tex.stackexchange.com/questions/51582/background-coloring-with-overlay-specification-in-algorithm2e-beamer-package#51582

\makeatletter
\tikzset{%
     remember picture with id/.style={%
       remember picture,
       overlay,
       draw=\bordercol,
       save picture id=#1,
     },
     save picture id/.code={%
       \edef\pgf@temp{#1}%
       \immediate\write\pgfutil@auxout{%
         \noexpand\savepointas{\pgf@temp}{\pgfpictureid}}%
     },
     if picture id/.code args={#1#2#3}{%
       \@ifundefined{save@pt@#1}{%
         \pgfkeysalso{#3}%
       }{
         \pgfkeysalso{#2}%
       }
     }
   }

   \def\savepointas#1#2{%
  \expandafter\gdef\csname save@pt@#1\endcsname{#2}%
}

\def\tmk@labeldef#1,#2\@nil{%
  \def\tmk@label{#1}%
  \def\tmk@def{#2}%
}

\tikzdeclarecoordinatesystem{pic}{%
  \pgfutil@in@,{#1}%
  \ifpgfutil@in@%
    \tmk@labeldef#1\@nil
  \else
    \tmk@labeldef#1,(0pt,0pt)\@nil
  \fi
  \@ifundefined{save@pt@\tmk@label}{%
    \tikz@scan@one@point\pgfutil@firstofone\tmk@def
  }{%
  \pgfsys@getposition{\csname save@pt@\tmk@label\endcsname}\save@orig@pic%
  \pgfsys@getposition{\pgfpictureid}\save@this@pic%
  \pgf@process{\pgfpointorigin\save@this@pic}%
  \pgf@xa=\pgf@x
  \pgf@ya=\pgf@y
  \pgf@process{\pgfpointorigin\save@orig@pic}%
  \advance\pgf@x by -\pgf@xa
  \advance\pgf@y by -\pgf@ya
  }%
}
\makeatother

\newcommand{\tikzmarkin}[1]{%
      \tikz[remember picture with id=#1]
      \draw[line width=1pt,rectangle,rounded corners,fill=\fillcol]
      (pic cs:#1) ++(0.065,-0.15) rectangle (-0.05,0.32)
      ;}

\newcommand\tikzmarkend[2][]{%
\tikz[remember picture with id=#2] #1;}


\begin{document}
    \begin{equation*}
    \left.\begin{array}{cc}
      -2\cdot \tikzmarkin{a}\red{2}=&amp; -4 \\
      -2\cdot \red{1}=&amp; -2 \\
      -2\cdot \red{0}\tikzmarkend{a}=&amp; 0
    \end{array}\right\} \text{\small Product increases by 2 each time.}
    \end{equation*}
\end{document}


Notice that you need to compile twice.


  Explanation


Inside the tikzset there is the definition of the style of the picture to be drawn (remember picture with id) then the definition and the writing on the the .aux of the id and position of the mark. Anyway, to get a better explanation, you can refer to http://tex.stackexchange.com/a/50054/13304. Finally, the commands that you need to use inside your document, \tikzmarkin and \tikzmarkend are defined. 


  EDIT: insertion of the annotation


For this purpose I adopted the same trick of Mark a pseudocode block and insert comments near it: the insertion of an anchor inside the \tikzmarkin macro to subsequently used it as reference to insert the annotation. What changes in the previous MWE? 

In the preamble you should add:

\usetikzlibrary{calc} % &lt;= needed for some computations

\usepackage{lipsum} % &lt;= needed to insert some text later


The \tikzmarkin should be improved as:

\newcommand{\tikzmarkin}[1]{%
      \tikz[remember picture with id=#1]
      \draw[line width=1pt,rectangle,rounded corners,fill=\fillcol]
      (pic cs:#1) ++(0.065,-0.15) rectangle (-0.05,0.32) node [anchor=base] (#1){}
      ;}


where the relevant new part is just node [anchor=base] (#1){}. 

Finally, the document:

\begin{document}
    \begin{equation*}
    \left.\begin{array}{cc}
      -2\cdot \tikzmarkin{a}\red{2}=&amp; -4 \\
      -2\cdot \red{1}=&amp; -2 \\
      -2\cdot \red{0}\tikzmarkend{a}=&amp; 0
    \end{array}\right\} \text{\small Product increases by 2 each time.}
    \end{equation*}

    % To insert the annotation
    \begin{tikzpicture}[remember picture,overlay]
        \coordinate (aa) at ($(a)+(1.825,-1.65)$); % &lt;= adjust this parameter to move the position of the annotation 
        \node[align=left,right] at (aa) {\small{Annotation}};
        \path[-latex,red,draw] (aa) -| ($(a)+(0.15,-1.3)$);
    \end{tikzpicture}
    \linebreak

    \lipsum[1]

\end{document}


The last part is the one needed to insert the annotation: first I defined a coordinate where to insert it based on the anchor previously saved (to accomplish this, it is important that the tikzpicture has as options remember picture,overlay). The last command:

\path[-latex,red,draw] (aa) -| ($(a)+(0.15,-1.3)$);


draws the arrow: the starting point is the coordinate of the annotation and the final point should be computed knowing that the reference anchor a is placed on the top left of the red rectangle.

This will lead to:



One final remark: I think should be better to insert a \linebreak after the tikzpicture to avoid that the annotation will be placed too nearly the subsequent text.
",Claudio Fiandrino,https://tex.stackexchange.com/users/13304,http://tex.stackexchange.com/questions/57101/highlight-a-column-in-equation-or-math-environment,TECHNOLOGY,tex.stackexchange.com,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.3333333333333333,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,1.0,Highlight columns in a formula or math environment,"While explaining the idea product of two negative numbers I wanted to highlight a vertical part of the display to emphasize on the factors that are being multiplied by:

\documentclass[letterpaper]{article}
\usepackage{fullpage}
\usepackage{amsmath,amssymb,amsthm,enumitem}
\newcommand{\red}[1]{%
{\color{OrangeRed}#1}}
\begin{document}
    \begin{equation*}
    \left.\begin{array}{cc}
      -2\cdot \red{2}=&amp; -4 \\
      -2\cdot \red{1}=&amp; -2 \\
      -2\cdot \red{0}=&amp; 0
    \end{array}\right\} \text{\small Product increases by 2 each time.}
    \end{equation*}
\end{document}


This gives:


So I chose to use a color but then I had also wanted to achieve something like the following:


I am not interested in the yellow red bordered box. What am looking for is an arrow pointing on the red numbers with a vertical border around  them as shown and the possibility of adding a node with text in the same format shown aligned with the word ""Product"".


  Edit


Can I use this method to achieve this:

","To accomplish this task you can make use of the tikzmark macro. This solution allows to get:



The code:

\documentclass[letterpaper]{article}
\usepackage{fullpage}
\usepackage{amsmath,amssymb,amsthm,enumitem}
\usepackage{xcolor}
\newcommand{\red}[1]{%
{\color{red}#1}}

\usepackage{tikz}

% to change colors
\newcommand{\fillcol}{white}
\newcommand{\bordercol}{red}

%% code by Andrew Stacey 
% http://tex.stackexchange.com/questions/51582/background-coloring-with-overlay-specification-in-algorithm2e-beamer-package#51582

\makeatletter
\tikzset{%
     remember picture with id/.style={%
       remember picture,
       overlay,
       draw=\bordercol,
       save picture id=#1,
     },
     save picture id/.code={%
       \edef\pgf@temp{#1}%
       \immediate\write\pgfutil@auxout{%
         \noexpand\savepointas{\pgf@temp}{\pgfpictureid}}%
     },
     if picture id/.code args={#1#2#3}{%
       \@ifundefined{save@pt@#1}{%
         \pgfkeysalso{#3}%
       }{
         \pgfkeysalso{#2}%
       }
     }
   }

   \def\savepointas#1#2{%
  \expandafter\gdef\csname save@pt@#1\endcsname{#2}%
}

\def\tmk@labeldef#1,#2\@nil{%
  \def\tmk@label{#1}%
  \def\tmk@def{#2}%
}

\tikzdeclarecoordinatesystem{pic}{%
  \pgfutil@in@,{#1}%
  \ifpgfutil@in@%
    \tmk@labeldef#1\@nil
  \else
    \tmk@labeldef#1,(0pt,0pt)\@nil
  \fi
  \@ifundefined{save@pt@\tmk@label}{%
    \tikz@scan@one@point\pgfutil@firstofone\tmk@def
  }{%
  \pgfsys@getposition{\csname save@pt@\tmk@label\endcsname}\save@orig@pic%
  \pgfsys@getposition{\pgfpictureid}\save@this@pic%
  \pgf@process{\pgfpointorigin\save@this@pic}%
  \pgf@xa=\pgf@x
  \pgf@ya=\pgf@y
  \pgf@process{\pgfpointorigin\save@orig@pic}%
  \advance\pgf@x by -\pgf@xa
  \advance\pgf@y by -\pgf@ya
  }%
}
\makeatother

\newcommand{\tikzmarkin}[1]{%
      \tikz[remember picture with id=#1]
      \draw[line width=1pt,rectangle,rounded corners,fill=\fillcol]
      (pic cs:#1) ++(0.065,-0.15) rectangle (-0.05,0.32)
      ;}

\newcommand\tikzmarkend[2][]{%
\tikz[remember picture with id=#2] #1;}


\begin{document}
    \begin{equation*}
    \left.\begin{array}{cc}
      -2\cdot \tikzmarkin{a}\red{2}=&amp; -4 \\
      -2\cdot \red{1}=&amp; -2 \\
      -2\cdot \red{0}\tikzmarkend{a}=&amp; 0
    \end{array}\right\} \text{\small Product increases by 2 each time.}
    \end{equation*}
\end{document}


Notice that you need to compile twice.


  Explanation


Inside the tikzset there is the definition of the style of the picture to be drawn (remember picture with id) then the definition and the writing on the the .aux of the id and position of the mark. Anyway, to get a better explanation, you can refer to http://tex.stackexchange.com/a/50054/13304. Finally, the commands that you need to use inside your document, \tikzmarkin and \tikzmarkend are defined. 


  EDIT: insertion of the annotation


For this purpose I adopted the same trick of Mark a pseudocode block and insert comments near it: the insertion of an anchor inside the \tikzmarkin macro to subsequently used it as reference to insert the annotation. What changes in the previous MWE? 

In the preamble you should add:

\usetikzlibrary{calc} % &lt;= needed for some computations

\usepackage{lipsum} % &lt;= needed to insert some text later


The \tikzmarkin should be improved as:

\newcommand{\tikzmarkin}[1]{%
      \tikz[remember picture with id=#1]
      \draw[line width=1pt,rectangle,rounded corners,fill=\fillcol]
      (pic cs:#1) ++(0.065,-0.15) rectangle (-0.05,0.32) node [anchor=base] (#1){}
      ;}


where the relevant new part is just node [anchor=base] (#1){}. 

Finally, the document:

\begin{document}
    \begin{equation*}
    \left.\begin{array}{cc}
      -2\cdot \tikzmarkin{a}\red{2}=&amp; -4 \\
      -2\cdot \red{1}=&amp; -2 \\
      -2\cdot \red{0}\tikzmarkend{a}=&amp; 0
    \end{array}\right\} \text{\small Product increases by 2 each time.}
    \end{equation*}

    % To insert the annotation
    \begin{tikzpicture}[remember picture,overlay]
        \coordinate (aa) at ($(a)+(1.825,-1.65)$); % &lt;= adjust this parameter to move the position of the annotation 
        \node[align=left,right] at (aa) {\small{Annotation}};
        \path[-latex,red,draw] (aa) -| ($(a)+(0.15,-1.3)$);
    \end{tikzpicture}
    \linebreak

    \lipsum[1]

\end{document}


The last part is the one needed to insert the annotation: first I defined a coordinate where to insert it based on the anchor previously saved (to accomplish this, it is important that the tikzpicture has as options remember picture,overlay). The last command:

\path[-latex,red,draw] (aa) -| ($(a)+(0.15,-1.3)$);


draws the arrow: the starting point is the coordinate of the annotation and the final point should be computed knowing that the reference anchor a is placed on the top left of the red rectangle.

This will lead to:



One final remark: I think should be better to insert a \linebreak after the tikzpicture to avoid that the annotation will be placed too nearly the subsequent text.
"
3540,3540,5647,Is it copyright infringement by US copyright law if someone else modifies and uses my design?,"My company is in a small town and there are not any graphic designers but we have enough business in the town and the surrounding area to support us.  But because of the small town nature some business owners do not know all the laws.  And since I am starting this from a career in architecture I am not quite clear on copyrights.  So here is my problem.  

I created a sign that has an oval with scrolls and flowers in different colors on a field of turquoise.  The client did not want to spend the money on a logo design so I said that I will  just retain the rights so that she would have to come to me for the approval to use the logo on anything else.  So anyway everything seems to be fine, I do her business cards and now all of a sudden I see a sign at the street.  I quoted her on this job figuring in using the logo.  Apparently this company did for much less and you can tell by the quality.

But here is my problem.  She had a jpeg that I allowed her to have so she could create her own fliers and I was ok with that since it would not have made me much if any money.  Well I am looking at the sign that the other person did and all that was done is they made a longer oval since this sign is more rectangle and used a different font.  And put this over the design that I did.  To me this is copyright infringement since the client did not want to buy all the rights.  But who do I address?  The client or the person that did the sign?
",user15955,https://graphicdesign.stackexchange.com/users/15955,"Truth is, in the US, the artist retains all rights unless they are specifically given away. You can't even ""accidentally"" give rights away. There are only 10 reasons why an artist would lose the rights to things they create (Not counting a written agreement to give rights away). If you aren't an employee, then there are only 9. If it's not a motion picture, only 8. If it's not a test or related to a test, only 5....

See here:
 
The items on the left are the 9 reasons an independent contractor would not retain rights to a creation by default

William Fisher has provided a quite lengthy series of lectures on YouTube regarding US copyright law.

While the question is design related, any direct answers would need to be legally based, so..... you need to speak with an attorney.
",Scott,https://graphicdesign.stackexchange.com/users/3270,http://graphicdesign.stackexchange.com/questions/21905/is-it-copyright-infringement-by-us-copyright-law-if-someone-else-modifies-and-us,LIFE_ARTS,graphicdesign.stackexchange.com,1.0,0.3333333333333333,0.0,1.0,1.0,1.0,0.6666666666666666,0.5555555555555556,0.3333333333333333,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,1.0,"If someone modifies and uses my design, does it violate American copyright law?","My company is in a small town and there are not any graphic designers but we have enough business in the town and the surrounding area to support us.  But because of the small town nature some business owners do not know all the laws.  And since I am starting this from a career in architecture I am not quite clear on copyrights.  So here is my problem.  

I created a sign that has an oval with scrolls and flowers in different colors on a field of turquoise.  The client did not want to spend the money on a logo design so I said that I will  just retain the rights so that she would have to come to me for the approval to use the logo on anything else.  So anyway everything seems to be fine, I do her business cards and now all of a sudden I see a sign at the street.  I quoted her on this job figuring in using the logo.  Apparently this company did for much less and you can tell by the quality.

But here is my problem.  She had a jpeg that I allowed her to have so she could create her own fliers and I was ok with that since it would not have made me much if any money.  Well I am looking at the sign that the other person did and all that was done is they made a longer oval since this sign is more rectangle and used a different font.  And put this over the design that I did.  To me this is copyright infringement since the client did not want to buy all the rights.  But who do I address?  The client or the person that did the sign?
","Truth is, in the US, the artist retains all rights unless they are specifically given away. You can't even ""accidentally"" give rights away. There are only 10 reasons why an artist would lose the rights to things they create (Not counting a written agreement to give rights away). If you aren't an employee, then there are only 9. If it's not a motion picture, only 8. If it's not a test or related to a test, only 5....

See here:
 
The items on the left are the 9 reasons an independent contractor would not retain rights to a creation by default

William Fisher has provided a quite lengthy series of lectures on YouTube regarding US copyright law.

While the question is design related, any direct answers would need to be legally based, so..... you need to speak with an attorney.
"
1136,1136,1780,How do I build lengthwise multi-platform stations?,"In OpenTTD, it's possible to build multi-platform train stations side-by-side (pictured below as Parnpool Mines), and they would work as expected, allowing two trains to load/unload at that station at the same time. 

However, sometimes due to space constraints it would be more desirable to to build the two platforms lengthwise as shown below in Parnpool West. The signal-station combination pictured below, however, does not work, and I have not found one that does.


",Private Pansy,https://gaming.stackexchange.com/users/3936,"Instead of 2 stations side my side or 1 in front of another station you can split them up by more tiles. Since industries rarely (or never) are adjacent to each other it should be possible to build a station on each side of the industry linking them with the CTRL placement you did with Parnpool west. Like the setup in the picture you attached, but all grouped as one station. One or two tracks on the left and one or two tracks on the right, scenario's where this cannot be done are extremely rare. There is always the bulldoze tool for cities too :) 

I'm not sure what the  max size of a station is by default but i never changed it and rarely get that message and i usually build huge hub stations on cramped spaces.

You really should not have any problem putting stations side by side with space, towns or industries in between them. If you do i'd like to see a screenshot of that scenario and i can probably help you out with the placement.
",Madmenyo,https://gaming.stackexchange.com/users/48810,http://gaming.stackexchange.com/questions/19786/how-do-i-build-lengthwise-multi-platform-stations,CULTURE,gaming.stackexchange.com,1.0,0.6666666666666666,0.0,1.0,0.6666666666666666,1.0,0.6666666666666666,0.4444444444444444,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.3333333333333333,0.7777777777777778,How to establish a vertical multi platform platform?,"In OpenTTD, it's possible to build multi-platform train stations side-by-side (pictured below as Parnpool Mines), and they would work as expected, allowing two trains to load/unload at that station at the same time. 

However, sometimes due to space constraints it would be more desirable to to build the two platforms lengthwise as shown below in Parnpool West. The signal-station combination pictured below, however, does not work, and I have not found one that does.


","Instead of 2 stations side my side or 1 in front of another station you can split them up by more tiles. Since industries rarely (or never) are adjacent to each other it should be possible to build a station on each side of the industry linking them with the CTRL placement you did with Parnpool west. Like the setup in the picture you attached, but all grouped as one station. One or two tracks on the left and one or two tracks on the right, scenario's where this cannot be done are extremely rare. There is always the bulldoze tool for cities too :) 

I'm not sure what the  max size of a station is by default but i never changed it and rarely get that message and i usually build huge hub stations on cramped spaces.

You really should not have any problem putting stations side by side with space, towns or industries in between them. If you do i'd like to see a screenshot of that scenario and i can probably help you out with the placement.
"
3322,3322,5302,Why did Voldemort assume that no-one knew about Room of Hidden Things?,"Voldemort hid one of his Horcruxes inside Hogwarts. It seemed to be relying on security through obscurity as far as protecting it. But as we know, it ended up not being so secure because it wasn't so obscure - Harry Potter knew about the Room of Hidden Things.

My question is, the way Rowling describes this hints at the fact that Riddle had an assumption that very few people would ever stumble upon that room. *WHY???



First, let's show Harry's theory on what Voldemort was thinking, how and why:

Here's Harry understanding Voldemort's thinking in HP7 once he figured out where the Diadem was (bold emphasis mine):


  Tom Riddle, who confided in no one and operated alone, might have been arrogant
  enough to assume that he, and only he, had penetrated the deepest mysteries of
  Hogwarts Castle. Of course, Dumbledore and Flitwick, those model pupils, had never
  set foot in that particular place, but he, Harry, had strayed off the beaten track in his
  time at school – here at least was a secret area he and Voldemort knew, that
  Dumbledore had never discovered –


...and later on, with Harry explains the location to Ron/Hermione:


  “He hid it exactly where I had my old Potions book, where everyone’s been hiding stuff for centuries. He thought he was the only one to find it. Come on.”
  
  “And he never realized anyone could get in?” said Ron, his voice echoing in the silence.
  “He thought he was the only one,” said Harry.


.



Yet, from available evidence, that seems to be a completely wrong assumption, even at Voldemort's time. 

Let's examine that last quote again, with emphasis on other info available:


  “He hid it exactly where I had my old Potions book, where everyone’s been hiding stuff for centuries.” ...
  
  ...
  
  “And he never realized anyone could get in?” said Ron, his voice echoing in the silence.
  “He thought he was the only one,” said Harry. “Too bad for him I’ve had to hide stuff in
  my time... this way,” he added. “I think it’s down here... “ 
  
  They sped off up adjacent aisles; Harry could hear the others’ footsteps echoing through the towering piles of junk, of bottles, hats, crates, chairs, books, weapons, broomsticks, bats...


.

OK, so if there's a truckload (or train-load, by the description) of stuff in that room, isn't the only reasonable conclusion: ""the room is a fairly popular destination with plenty of people who've found their way there in the past, and therefore, likely, plenty who will in the future""? 

Doesn't matter what your arrogance level is, the evidence seems to point to only one conclusion - it's quite fine as a place to temporarily bury your dirt so teachers won't tag you for your misdeeds, but this is NOT the place to hide something that you want permanently safe! 

So why did Voldemort make such a moronic mistake?
",DVK-on-Ahch-To,https://scifi.stackexchange.com/users/976,"It's the room of requirement. Voldemort required a room to hide his item in. Where better to hide a small, reasonably nondescript item than in a pile of junk? If not then it's possible when he hid it it wasn't full of junk; Harry required a room full of all of the small, nondescript items that may have been the diadem. Yes he knew what it was but maybe not specifically enough to single it out.

The room also has a habit of overdoing things, like when Dumbledore needs the loo and finds tens of chamberpots there, when one would do: 


  ""Only this morning, for instance, I took a wrong turning on the way to the bathroom and found myself in a beautifully proportioned room I have never seen before, containing a really rather magnificent collection of chamber pots. When I went back to investigate more closely, I discovered that the room had vanished. But I must keep an eye out for it. Possibly it is only accessible at five-thirty in the morning. Or it may only appear at the quarter moon - or when the seeker has an exceptionally full bladder."" 


~Christmas Ball, Goblet of Fire,
",AncientSwordRage,https://scifi.stackexchange.com/users/3804,http://scifi.stackexchange.com/questions/8734/why-did-voldemort-assume-that-no-one-knew-about-room-of-hidden-things,LIFE_ARTS,scifi.stackexchange.com,1.0,0.6666666666666666,1.0,1.0,0.3333333333333333,0.5,0.7777777777777778,0.7777777777777778,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.8888888888888888,0.8333333333333334,0.8888888888888888,1.0,0.9,0.0,0.0,1.0,1.0,Why does Voldemort think no one knows what's hidden?,"Voldemort hid one of his Horcruxes inside Hogwarts. It seemed to be relying on security through obscurity as far as protecting it. But as we know, it ended up not being so secure because it wasn't so obscure - Harry Potter knew about the Room of Hidden Things.

My question is, the way Rowling describes this hints at the fact that Riddle had an assumption that very few people would ever stumble upon that room. *WHY???



First, let's show Harry's theory on what Voldemort was thinking, how and why:

Here's Harry understanding Voldemort's thinking in HP7 once he figured out where the Diadem was (bold emphasis mine):


  Tom Riddle, who confided in no one and operated alone, might have been arrogant
  enough to assume that he, and only he, had penetrated the deepest mysteries of
  Hogwarts Castle. Of course, Dumbledore and Flitwick, those model pupils, had never
  set foot in that particular place, but he, Harry, had strayed off the beaten track in his
  time at school – here at least was a secret area he and Voldemort knew, that
  Dumbledore had never discovered –


...and later on, with Harry explains the location to Ron/Hermione:


  “He hid it exactly where I had my old Potions book, where everyone’s been hiding stuff for centuries. He thought he was the only one to find it. Come on.”
  
  “And he never realized anyone could get in?” said Ron, his voice echoing in the silence.
  “He thought he was the only one,” said Harry.


.



Yet, from available evidence, that seems to be a completely wrong assumption, even at Voldemort's time. 

Let's examine that last quote again, with emphasis on other info available:


  “He hid it exactly where I had my old Potions book, where everyone’s been hiding stuff for centuries.” ...
  
  ...
  
  “And he never realized anyone could get in?” said Ron, his voice echoing in the silence.
  “He thought he was the only one,” said Harry. “Too bad for him I’ve had to hide stuff in
  my time... this way,” he added. “I think it’s down here... “ 
  
  They sped off up adjacent aisles; Harry could hear the others’ footsteps echoing through the towering piles of junk, of bottles, hats, crates, chairs, books, weapons, broomsticks, bats...


.

OK, so if there's a truckload (or train-load, by the description) of stuff in that room, isn't the only reasonable conclusion: ""the room is a fairly popular destination with plenty of people who've found their way there in the past, and therefore, likely, plenty who will in the future""? 

Doesn't matter what your arrogance level is, the evidence seems to point to only one conclusion - it's quite fine as a place to temporarily bury your dirt so teachers won't tag you for your misdeeds, but this is NOT the place to hide something that you want permanently safe! 

So why did Voldemort make such a moronic mistake?
","It's the room of requirement. Voldemort required a room to hide his item in. Where better to hide a small, reasonably nondescript item than in a pile of junk? If not then it's possible when he hid it it wasn't full of junk; Harry required a room full of all of the small, nondescript items that may have been the diadem. Yes he knew what it was but maybe not specifically enough to single it out.

The room also has a habit of overdoing things, like when Dumbledore needs the loo and finds tens of chamberpots there, when one would do: 


  ""Only this morning, for instance, I took a wrong turning on the way to the bathroom and found myself in a beautifully proportioned room I have never seen before, containing a really rather magnificent collection of chamber pots. When I went back to investigate more closely, I discovered that the room had vanished. But I must keep an eye out for it. Possibly it is only accessible at five-thirty in the morning. Or it may only appear at the quarter moon - or when the seeker has an exceptionally full bladder."" 


~Christmas Ball, Goblet of Fire,
"
3496,3496,5577,ASP.net Website want debug to == false on IIS,"Have tried adding this to web.config 

&lt;compilation debug=""false"" targetFramework=""4.0""&gt;
&lt;/compilation&gt;


but website still executes code in #if DEBUG when it shouldn't

*Wierdly the inline statement &lt;% #if DEBUG %> on aspx files works but require also for .cs code. 

NB development and live website on same box
",user3231982,https://stackoverflow.com/users/3231982,"compilation debug element is not the same thing as DEBUG preprocessor directive.
You need to re-compile your website in Release mode.


  What about binaries compiled with debug symbols?
  
  One scenario that several people find very useful is to
  compile/pre-compile an application or associated class libraries with
  debug symbols so that more detailed stack trace and line error
  messages can be retrieved from it when errors occur. 
  
  The good news is that you can do this without having the have the
   switch enabled in production. 
  Specifically, you can use either a web deployment project or a web
  application project to pre-compile the code for your site with debug
  symbols, and then change the  switch to
  false right before you deploy the application on the server. 
  
  The debug symbols and metadata in the compiled assemblies will
  increase the memory footprint of the application, but this can
  sometimes be an ok trade-off for more detailed error messages.


http://weblogs.asp.net/scottgu/archive/2006/04/11/Don_1920_t-run-production-ASP.NET-Applications-with-debug_3D001D20_true_1D20_-enabled.aspx
",Jakub Konecki,https://stackoverflow.com/users/449906,http://stackoverflow.com/questions/21438703/asp-net-website-want-debug-to-false-on-iis,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.3333333333333333,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.6666666666666666,0.3333333333333333,0.6666666666666666,1.0,Asp.net website wants to debug on IIS as = false,"Have tried adding this to web.config 

&lt;compilation debug=""false"" targetFramework=""4.0""&gt;
&lt;/compilation&gt;


but website still executes code in #if DEBUG when it shouldn't

*Wierdly the inline statement &lt;% #if DEBUG %> on aspx files works but require also for .cs code. 

NB development and live website on same box
","compilation debug element is not the same thing as DEBUG preprocessor directive.
You need to re-compile your website in Release mode.


  What about binaries compiled with debug symbols?
  
  One scenario that several people find very useful is to
  compile/pre-compile an application or associated class libraries with
  debug symbols so that more detailed stack trace and line error
  messages can be retrieved from it when errors occur. 
  
  The good news is that you can do this without having the have the
   switch enabled in production. 
  Specifically, you can use either a web deployment project or a web
  application project to pre-compile the code for your site with debug
  symbols, and then change the  switch to
  false right before you deploy the application on the server. 
  
  The debug symbols and metadata in the compiled assemblies will
  increase the memory footprint of the application, but this can
  sometimes be an ok trade-off for more detailed error messages.


http://weblogs.asp.net/scottgu/archive/2006/04/11/Don_1920_t-run-production-ASP.NET-Applications-with-debug_3D001D20_true_1D20_-enabled.aspx
"
4021,4021,6419,Is Cyrus the Messiah?,"What are the actual words used for Isaiah 44:28 to describe his anointed? Why do most Bible translation translate that as shepherd? I've heard the Masoretic Text uses ""messiah"" and the Septuagint uses ""Christ"".  The English translation uses the word ""shepherd,"" which seems like lying or filtering.  Why the discrepancy?

I stumbled upon some atheist sites and found this. Translating a word like Christ into shepherd seems very misleading.

I also came across this discussion about this on the web.
",J. Chang,https://christianity.stackexchange.com/users/933,"Take this answer as a complement. As Waggers said, the word being used is  רֹעִי (ro·'i) and it means shepherd. (This is in Isaiah 44:28)

But the Jewish commentary sheds light on this issue, because Rashi comments that shepherd is used as a metaphor for king. 

On Isaiah 45:1, it is said that Cyrus is the anointed:


  This is what the LORD says to his anointed, to Cyrus [...]


The words used are לִמְשִׁיחוֹ לְכוֹרֶשׁ, which according to Strong's concordance is ""anointed"" or ""messiah""; but in general it refers to a consecrated person with a special mission.  In this case it is being said that Cyrus will be an instrument of God to facilitate the return to Zion. 

And again, Rashi's commentary complements it remembering how the word anointed is used as a title:


  Every title of greatness is called anointing. Comp. (Num. 18:8) “To
  you I have given them for greatness (לְמָשְׁחָה).” [greatness=portion (NIV); greatness=by the reason of the anointing (KJV); pro oficio sacerdotali legitima (vulgate)]

",deps_stats,https://christianity.stackexchange.com/users/149,http://christianity.stackexchange.com/questions/4345/is-cyrus-the-messiah,CULTURE,christianity.stackexchange.com,1.0,0.4444444444444444,0.0,1.0,1.0,1.0,0.5555555555555556,0.4444444444444444,0.6666666666666666,0.0,0.3333333333333333,1.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.6666666666666666,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8,0.0,0.0,1.0,1.0,Is Cyrus the Messiah?,"What does Isaiah 44:28 say about the anointed? Why do most Bible translations translate it into shepherds? I've heard that the messianic scriptures use ""Messiah"", while the seventh scriptures use ""Christ"". The English translation uses the word shepherd, which looks like lying or filtering. Why not?","Take this answer as a complement. As Waggers said, the word being used is  רֹעִי (ro·'i) and it means shepherd. (This is in Isaiah 44:28)

But the Jewish commentary sheds light on this issue, because Rashi comments that shepherd is used as a metaphor for king. 

On Isaiah 45:1, it is said that Cyrus is the anointed:


  This is what the LORD says to his anointed, to Cyrus [...]


The words used are לִמְשִׁיחוֹ לְכוֹרֶשׁ, which according to Strong's concordance is ""anointed"" or ""messiah""; but in general it refers to a consecrated person with a special mission.  In this case it is being said that Cyrus will be an instrument of God to facilitate the return to Zion. 

And again, Rashi's commentary complements it remembering how the word anointed is used as a title:


  Every title of greatness is called anointing. Comp. (Num. 18:8) “To
  you I have given them for greatness (לְמָשְׁחָה).” [greatness=portion (NIV); greatness=by the reason of the anointing (KJV); pro oficio sacerdotali legitima (vulgate)]

"
6017,6017,9550,The Discrete Logarithm problem,"I am puzzled with the following discrete logarithm problem:

Given positive integers b, c, m where (b &lt; m) is True it is to find a positive integer e such that

(b**e % m == c) is True


where two stars is exponentiation (e.g. in Ruby, Python or ^ in some other languages) and % is modulo operation. Using general math symbols it looks like:($b^e \equiv c (\mod m)$). 

What is the most effective algorithm (with the lowest big-O complexity) to solve it ?

Example:
Given b=5; c=8; m=13 this algorithm must find e=7 because 5**7%13 = 8

Thank you in advance!
",psihodelia,https://mathoverflow.net/users/2266,"The question is not phrased to our taste at mathoverflow, but the user has a point that this particular Wikipedia page is under-developed.  As David Speyer suggests, it is a very different problem for very large primes than for small ones.  For small primes the simplest algorithms described in Wikipedia are probably the most appropriate.  If the question is instead about the theoretical time complexity, see this review article.
",Greg Kuperberg,https://mathoverflow.net/users/1450,http://mathoverflow.net/questions/7624,SCIENCE,mathoverflow.net,1.0,0.3333333333333333,0.0,1.0,1.0,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.7777777777777778,0.7777777777777778,0.6,1.0,0.0,0.0,1.0,Discrete logarithm problem,"I am puzzled with the following discrete logarithm problem:

Given positive integers b, c, m where (b &lt; m) is True it is to find a positive integer e such that

(b**e % m == c) is True


where two stars is exponentiation (e.g. in Ruby, Python or ^ in some other languages) and % is modulo operation. Using general math symbols it looks like:($b^e \equiv c (\mod m)$). 

What is the most effective algorithm (with the lowest big-O complexity) to solve it ?

Example:
Given b=5; c=8; m=13 this algorithm must find e=7 because 5**7%13 = 8

Thank you in advance!
","The wording of this question is not in line with our taste in mathover flow, but users have a point of view that this particular Wikipedia page is under developed. As David Speyer said, this is a very different problem for very large prime numbers. For small prime numbers, the simplest algorithm described in Wikipedia may be the most appropriate. If the question is about the time complexity of the theory, see this review."
2785,2785,4436,How do I chose a good camera for texture hunting?,"Texture hunting is the photography of walls, surfaces, artefacts, etc, typically outdoors, with the intention of using the photos in a computer game.  The photo could be of a brick or concrete wall, a chain link face, a door / window, or whatever.  It is also possible to photograph a white wall that has been damaged or stained in some way, process it in various ways, and use this as a mask on top of other textures, in order to get a new damaged variant.

Textures are typically lighting-neutral and extremely sharp.  The computer game will compute its own lighting and shadows.  One must avoid having a shadow across the subject, as this will only have to be removed in post-processing.  Typically, texture hunting is done on cloudy days where there is a uniform soft light from the sky.

1024×1024 is a reasonable size of the final texture, but it's usually photographed at a higher res, photoshopped considerably, and then sized down.  The subject of the photo could be something like 5 metres × 5 metres.  The idea is that every pixel is being used to the fullest effect to convey the character of the surface.  Textures are often photoshopped to become seamless so they can be repeated across a large surface in game.

Textures are usually shot perpendicular to the wall as much as possible, otherwise distortion correction is required.  Sometimes you can take a photo from further away and zoom in to get a better view of a high wall.

It is often quite hard to find a surface in the real world that has an interesting texture and is easy to photograph from the right angle.  In particular, taking photos of the floor is challenging because you need to be several metres above it, looking down.  Leaning out of windows / over bridges, or holding up a tripod are solutions.

One thing that concerns me is that some cameras do image processing on the digital image.  Really, the artist has to be doing all of the image processing offline, in photoshop or similar.  I often see digital camera photos with edge enhancement artefacts in high contrast areas.  Perhaps raw shooting mode is the answer to this?

Shooting digital photos with greater colour depth than ""8 bit per channel"" might also be useful to avoid banding when increasing contrast during post-processing.

Another thing is lens distortion — since we need to photograph flat surfaces.  Either the camera has to be good at it, or it should be possible to turn it off so the processing can be done manually by an artist.

How do I find a camera which meets these requirements?
",Spark,https://photo.stackexchange.com/users/6311,"While the camera and lens are obviously going to have an impact on your success, I have to think that a good solid grasp on lighting techniques is going to have more impact on shooting textures than the camera will.

Just about any current DSLR (or even high-end P&amp;S), ideally with a low-distortion prime lens, should give you plenty of technology to get started.  The full-frame suggestion is absolutely right for optimum results, and certainly gives the advantage of a ton of resolution that you can crop to size, but it's going to be fairly expensive.  If money is no object, go for the full-frame camera, but if you're on a budget, get a more modest camera and save some money for lighting equipment -- I think you'll produce better results with an entry-level DSLR and great lighting than you will with a full-frame camera and no lighting equipment.

If you're not familiar with the sort of impact lighting can have on your photos, check out strobist.com or some of the other communities that specialize in lighting techniques.  I think you'll start to see how lighting is going to make the highlights and shadows in your textures really pop.
",D. Lambert,https://photo.stackexchange.com/users/269,http://photo.stackexchange.com/questions/14871/how-do-i-chose-a-good-camera-for-texture-hunting,LIFE_ARTS,photo.stackexchange.com,0.8888888888888888,1.0,0.0,1.0,0.6666666666666666,1.0,0.5555555555555556,0.6666666666666666,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.6666666666666666,1.0,0.3333333333333333,0.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.3333333333333333,0.0,1.0,1.0,How to choose a good camera for texture search?,"Texture hunting is the photography of walls, surfaces, artefacts, etc, typically outdoors, with the intention of using the photos in a computer game.  The photo could be of a brick or concrete wall, a chain link face, a door / window, or whatever.  It is also possible to photograph a white wall that has been damaged or stained in some way, process it in various ways, and use this as a mask on top of other textures, in order to get a new damaged variant.

Textures are typically lighting-neutral and extremely sharp.  The computer game will compute its own lighting and shadows.  One must avoid having a shadow across the subject, as this will only have to be removed in post-processing.  Typically, texture hunting is done on cloudy days where there is a uniform soft light from the sky.

1024×1024 is a reasonable size of the final texture, but it's usually photographed at a higher res, photoshopped considerably, and then sized down.  The subject of the photo could be something like 5 metres × 5 metres.  The idea is that every pixel is being used to the fullest effect to convey the character of the surface.  Textures are often photoshopped to become seamless so they can be repeated across a large surface in game.

Textures are usually shot perpendicular to the wall as much as possible, otherwise distortion correction is required.  Sometimes you can take a photo from further away and zoom in to get a better view of a high wall.

It is often quite hard to find a surface in the real world that has an interesting texture and is easy to photograph from the right angle.  In particular, taking photos of the floor is challenging because you need to be several metres above it, looking down.  Leaning out of windows / over bridges, or holding up a tripod are solutions.

One thing that concerns me is that some cameras do image processing on the digital image.  Really, the artist has to be doing all of the image processing offline, in photoshop or similar.  I often see digital camera photos with edge enhancement artefacts in high contrast areas.  Perhaps raw shooting mode is the answer to this?

Shooting digital photos with greater colour depth than ""8 bit per channel"" might also be useful to avoid banding when increasing contrast during post-processing.

Another thing is lens distortion — since we need to photograph flat surfaces.  Either the camera has to be good at it, or it should be possible to turn it off so the processing can be done manually by an artist.

How do I find a camera which meets these requirements?
","While the camera and lens are obviously going to have an impact on your success, I have to think that a good solid grasp on lighting techniques is going to have more impact on shooting textures than the camera will.

Just about any current DSLR (or even high-end P&amp;S), ideally with a low-distortion prime lens, should give you plenty of technology to get started.  The full-frame suggestion is absolutely right for optimum results, and certainly gives the advantage of a ton of resolution that you can crop to size, but it's going to be fairly expensive.  If money is no object, go for the full-frame camera, but if you're on a budget, get a more modest camera and save some money for lighting equipment -- I think you'll produce better results with an entry-level DSLR and great lighting than you will with a full-frame camera and no lighting equipment.

If you're not familiar with the sort of impact lighting can have on your photos, check out strobist.com or some of the other communities that specialize in lighting techniques.  I think you'll start to see how lighting is going to make the highlights and shadows in your textures really pop.
"
5524,5524,8763,Visual Studio keeps changing resx files,"I'm working on a VB.Net project and using SVN. I noticed that every time I open my main form, Visual studio slightly modifies my .resx file, which means that I keep having to re-commit it, which is quite annoying.

Has anybody experienced such problems? A diff file demonstrating the problem can be seen at http://synchronicity.svn.sourceforge.net/viewvc/synchronicity/trunk/Create%20Synchronicity/MainForm.resx?r1=272&amp;r2=359&amp;pathrev=359

Thanks,
CFP.
",Clément,https://stackoverflow.com/users/695591,"Definitely not normal behaviour (at least in 2008). Is it possible that you've got some addins or something that might be changing things automatically?
",Hans Olsson,https://stackoverflow.com/users/306651,http://stackoverflow.com/questions/2682682/visual-studio-keeps-changing-resx-files,STACKOVERFLOW,stackoverflow.com,1.0,0.6666666666666666,0.0,0.5,1.0,1.0,0.6666666666666666,0.5,0.5,0.0,1.0,0.5,0.0,0.0,0.0,0.0,1.0,1.0,1.0,0.0,1.0,0.6666666666666666,0.3333333333333333,0.8333333333333334,0.8333333333333334,0.4,0.0,0.0,1.0,1.0,Visual studio constantly changes resx files,"I'm working on a VB.Net project and using SVN. I noticed that every time I open my main form, Visual studio slightly modifies my .resx file, which means that I keep having to re-commit it, which is quite annoying.

Has anybody experienced such problems? A diff file demonstrating the problem can be seen at http://synchronicity.svn.sourceforge.net/viewvc/synchronicity/trunk/Create%20Synchronicity/MainForm.resx?r1=272&amp;r2=359&amp;pathrev=359

Thanks,
CFP.
",Definitely not normal behavior (at least in 2008). Is it possible that you have some add ons or something that might change automatically?
4242,4242,6763,Why is Misato Tachibana always shooting Koujirou Sasahara?,"Whenever Sasahara does something mildly inappropriate in Tachibana's presence, such as playing video games under the desk or reading a manga while he's supposed to be working on some sort of school assignment, Tachibana reacts out of proportion and unleashes a barrage of deadly firepower, but he doesn't even react to that. What's this supposed to mean?

    
   
",Hakase,https://anime.stackexchange.com/users/191,"That is because Tachibana is a Tsundere, she even got her own slang term of it due to her extreme tsundere attitude, called GUNdere.


  Misato Tachibana is a peach haired high school girl who generally acts cold towards Koujirou whenever he does anything that reminds her of how she likes him, or simply doing anything at all. She is a member of the Kendo club.
  
  Misato's feelings usually materialize as assault with various guns and heavy weaponry that come out of nowhere, which Koujirou miraculously survives despite being injured, and just turns white with the dust. In reality Misato has feelings for Koujirou, but due to her tsundere attitude, she constantly denies her feelings and shoots Koujirou. She somehow manages to always trace everything back to Koujirou in conversations, even when he wasn't involved in it, leading her to wildly deny accusations, such as marriage and children, that nobody said. - Wiki

",Dimitri mx,https://anime.stackexchange.com/users/1458,http://anime.stackexchange.com/questions/8857/why-is-misato-tachibana-always-shooting-koujirou-sasahara,CULTURE,anime.stackexchange.com,1.0,1.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.8888888888888888,0.7777777777777778,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,1.0,Why does Misato Tachibana always shoot koujirou Sasahara?,"Whenever Sasha Hara does something slightly inappropriate in front of dagibana, such as playing video games under his desk, or reading cartoons when he should have finished some school work, dagibana will react disproportionately and release deadly fire, but he has not even responded to it. What's the meaning of this?","That is because Tachibana is a Tsundere, she even got her own slang term of it due to her extreme tsundere attitude, called GUNdere.


  Misato Tachibana is a peach haired high school girl who generally acts cold towards Koujirou whenever he does anything that reminds her of how she likes him, or simply doing anything at all. She is a member of the Kendo club.
  
  Misato's feelings usually materialize as assault with various guns and heavy weaponry that come out of nowhere, which Koujirou miraculously survives despite being injured, and just turns white with the dust. In reality Misato has feelings for Koujirou, but due to her tsundere attitude, she constantly denies her feelings and shoots Koujirou. She somehow manages to always trace everything back to Koujirou in conversations, even when he wasn't involved in it, leading her to wildly deny accusations, such as marriage and children, that nobody said. - Wiki

"
2833,2833,4508,Can you make a hash out of a stream cipher?,"A comment on another question made me wonder about something:


  Assume you're on a rather constrained platform &mdash; say, a low-end embedded device &mdash; with no built-in crypto capabilities, but you do have access to a simple stream cipher; say, RC4 or one of the eSTREAM ciphers.  What other crypto primitives can you build out of that stream cipher?  In particular, are there any practical ways to build a cryptographic hash function and/or a MAC out of just a stream cipher?


We already have questions about turning a hash into a stream cipher and about turning a stream cipher into a block cipher, but this particular transformation doesn't seem to have been covered yet.

Obviously, if the platform constraints permit it, one could ignore the stream cipher and just implement a standard hash function from the ground up.  What I'm wondering is whether having the stream cipher available might let one do better than that in terms of code size, memory usage and/or speed.

While a construction that treats the stream cipher as a black box would be nice, schemes that only use parts of the stream cipher (like RC4-Hash, which, alas, has practical collision attacks) would be interesting too, at least if they're simple enough.
",Ilmari Karonen,https://crypto.stackexchange.com/users/598,"A Pseudo Random Generator (PRG) and a hash function are both Pseudo Random Functions (PRFs), but they have different security considerations. (At least, historically they do. Moving forward some of them may be more closely aligned.) Due to this, building a hash from an existing PRG designed under older security constraints probably isn't a good idea for the intuitive construction of using the plaintext as the key to the PRG and the PRG output as the hash. See this nice summary: Why stream ciphers shouldn’t be used for hashing.
",B-Con,https://crypto.stackexchange.com/users/593,http://crypto.stackexchange.com/questions/2214/can-you-make-a-hash-out-of-a-stream-cipher,TECHNOLOGY,crypto.stackexchange.com,0.6666666666666666,0.6666666666666666,0.0,0.6666666666666666,1.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.0,0.0,0.6666666666666666,0.0,0.3333333333333333,0.6666666666666666,0.0,1.0,0.3333333333333333,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9,0.6666666666666666,1.0,0.0,0.8888888888888888,Can you make a hash with a stream password?,"A comment on another question made me wonder about something:


  Assume you're on a rather constrained platform &mdash; say, a low-end embedded device &mdash; with no built-in crypto capabilities, but you do have access to a simple stream cipher; say, RC4 or one of the eSTREAM ciphers.  What other crypto primitives can you build out of that stream cipher?  In particular, are there any practical ways to build a cryptographic hash function and/or a MAC out of just a stream cipher?


We already have questions about turning a hash into a stream cipher and about turning a stream cipher into a block cipher, but this particular transformation doesn't seem to have been covered yet.

Obviously, if the platform constraints permit it, one could ignore the stream cipher and just implement a standard hash function from the ground up.  What I'm wondering is whether having the stream cipher available might let one do better than that in terms of code size, memory usage and/or speed.

While a construction that treats the stream cipher as a black box would be nice, schemes that only use parts of the stream cipher (like RC4-Hash, which, alas, has practical collision attacks) would be interesting too, at least if they're simple enough.
","A Pseudo Random Generator (PRG) and a hash function are both Pseudo Random Functions (PRFs), but they have different security considerations. (At least, historically they do. Moving forward some of them may be more closely aligned.) Due to this, building a hash from an existing PRG designed under older security constraints probably isn't a good idea for the intuitive construction of using the plaintext as the key to the PRG and the PRG output as the hash. See this nice summary: Why stream ciphers shouldn’t be used for hashing.
"
2310,2310,3686,Making integrals look prettier with negative spacing for publication,"How should I write definite integrals for publication?

Examples:



or



or



I am not sure about how to write the limits correctly.

How should I write definite integrals for publication?
",Léo Léopold Hertz 준영,https://tex.stackexchange.com/users/13173,"Let's look at some examples:

\documentclass{article}
\usepackage{amsmath}

\newcommand{\diff}{\mathop{}\!d}

\begin{document}
\begin{gather*}
\int_{-\infty}^{+\infty}               e^{-i2\pi xt}f(x)\diff x   \\
\int_{-\infty}^{+\infty}  \!           e^{-i2\pi xt}f(x)\diff x   \\
\int_{-\infty}^{+\infty}  \! \!        e^{-i2\pi xt}f(x)\diff x   \\
\int_{-\infty}^{+\infty}  \! \! \!     e^{-i2\pi xt}f(x)\diff x   \\
\int_{-\infty}^{+\infty}  \! \! \! \!  e^{-i2\pi xt}f(x)\diff x
\end{gather*}
\end{document}




The first and the second lines seem right; perhaps, due to the low ‘e’ a negative shift is good, so the second line could be preferred.

In no case should the integrand go below the integration bounds. So, starting from the third line the result are on the worse side.
",egreg,https://tex.stackexchange.com/users/4427,http://tex.stackexchange.com/questions/142062/making-integrals-look-prettier-with-negative-spacing-for-publication,TECHNOLOGY,tex.stackexchange.com,0.7777777777777778,0.5555555555555556,0.3333333333333333,1.0,0.6666666666666666,1.0,0.7777777777777778,0.4444444444444444,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.6666666666666666,0.8888888888888888,Using negative spacing to make the integral look more beautiful,"How should I write definite integrals for publication?

Examples:



or



or



I am not sure about how to write the limits correctly.

How should I write definite integrals for publication?
","Let's look at some examples:

\documentclass{article}
\usepackage{amsmath}

\newcommand{\diff}{\mathop{}\!d}

\begin{document}
\begin{gather*}
\int_{-\infty}^{+\infty}               e^{-i2\pi xt}f(x)\diff x   \\
\int_{-\infty}^{+\infty}  \!           e^{-i2\pi xt}f(x)\diff x   \\
\int_{-\infty}^{+\infty}  \! \!        e^{-i2\pi xt}f(x)\diff x   \\
\int_{-\infty}^{+\infty}  \! \! \!     e^{-i2\pi xt}f(x)\diff x   \\
\int_{-\infty}^{+\infty}  \! \! \! \!  e^{-i2\pi xt}f(x)\diff x
\end{gather*}
\end{document}




The first and the second lines seem right; perhaps, due to the low ‘e’ a negative shift is good, so the second line could be preferred.

In no case should the integrand go below the integration bounds. So, starting from the third line the result are on the worse side.
"
4477,4477,7100,"Is possible to remote mount an image, that can boot and install itself?","I have a remote server, which runs Linux. I would like to install remotely the OS image, in case that it gets corrupted (this has already happened twice while I am experimenting with the OS).

So far, the only way that I have, is to physically go to the machine location and use a USB disk to mount the OS and the BIOS see it, so it can boot from it.

Is there any way to basically connect to the machine via ssh, attach this image and have it act like it would be on a virtual drive on Windows (like daemon tools for example), so it would persist to a reboot and allow me to install remotely the OS?

I was looking at solutions on Google, but I found something mentioning PXE boot....which sounds complicated, since you need a server and such, and it is not as simple as mounting an image and being done with it.

Beyond that, I found nothing useful, so I am quite short on options....does anyone know how to accomplish this?
",rataplan,https://unix.stackexchange.com/users/119523,"Here's a hypothetical situation which I consider might be plausible:


The targeted machine is EFI.
grub is either never installed on the target or has been utterly wiped from the system.


it can only ever interfere and offers nothing of value otherwise.



So what we might do in the above case is configure a boot option for a small installation/rescue image we keep on our /esp or EFI system partition.

If anything were ever to go wrong with our current installation, then, for so long as we can at least access the EFI system partition by some means, then we can interface our firmware and set the machine to boot to our recovery image on next reboot. In that case all we would have to do is change a text file or two, cross our fingers and run reboot now.

Here is a basic set of commands for a minimally configured Arch Linux (because it's what I use) system which could still do as I describe.


First, we'll make a work directory and download some files.


I use aria2c here. I recommend it, but use whatever works.
I unzip rEFInd with 7za but the same
tool preference is yours in all cases here.
If you're not reading this within a few hours/days of my posting it, then there is a very good chance that the links used below are not current.

mkdir /tmp/work &amp;&amp; cd /tmp/work || exit
aria2c  'magnet:?xt=urn:btih:331c7fac2e13c251d77521d2dc61976b6fc4a033&amp;dn=archlinux-2015.06.01-dual.iso&amp;tr=udp://tracker.archlinux.org:6969&amp;tr=http://tracker.archlinux.org:6969/announce' \
        'http://iweb.dl.sourceforge.net/project/refind/0.8.7/refind-cd-0.8.7.zip'
7za x ref*.zip; rm ref*zip


Next I'll make an image disk.


I use a file here with loop devices, but you may want to use an actual disk if you want to boot to this from firmware.
In the case of an actual device the fallocate and losetup stuff can be ignored and the actual device names will far more likely
correspond to /dev/sda[12] than /dev/loop0p[12]

fallocate -l4G img


Now I'll partition that disk with the gdisk utility and assign it to a loop device.


This is a scripted shortcut for the options you'd want to feed the program interactively. It will create a GUID partition table and a partition of type EFI-system that spans the first available 750Mib of the target disk and another linux default partition spanning the rest of the disk.


These partitions will be /dev/sda1 and /dev/sda2 respectively if you're using a real disk, which will be /dev/sda rather than ./img. It is usually desirable to add more than one partition for a linux root, which is assumed to be the purpose of /dev/sda2.

printf script or no, the gdisk program is easy to use - and so you might do better to go at it interactively instead. The target disk should not be mounted when it is run, and you'll probably need root rights to write the changes.
As a general rule you can do pretty much whatever you want in that program without any effect until you write - so be sure when you do.
I'll be putting my $TGT in a shell variable. Except for its definition here, which you may want to tailor as necessary, where I use it so can you.

printf %s\\n o y n 1 '' +750M ef00 \
                 n 2 '' '' '' '' w y |
gdisk ./img     &gt;/dev/null
TGT=$(sudo losetup --show -Pf img)p


We'll need a filesystem on the esp, too. It must be FAT.


I give mine the fs label VESP. You should call yours whatever you want.
We'll use the label later in /etc/fstab and another config file - so definitely make it something.
In my opinion you should always label all disks.
If you install an OS to ${TGT}2 now you will of course need a filesystem for it as well.

sudo mkfs.vfat -nVESP ""$TGT""1


And we'll make some mount directories and start extracting the relevant files.

   set     ref     ref*iso         \
        arch    arch*iso        \
        efi     arch/EFI/archiso/efiboot.img
while   [ ""$#"" -gt 0 ]
do      mkdir ""$1"" || exit
        sudo mount ""$2"" ""$1""
        shift 2
done;   mkdir esp

Install rEFInd...


rEFInd is a boot manager - which mostly just offers and populates boot menus.
rEFInd will put its config files on the esp and these can be edited at any time and anyway you like.

sudo ref/install.sh --usedefault ""$TGT""1 &amp;&amp;
sudo umount ref  &amp;&amp; rm -rf ref*


Now we'll mount our esp and get the needed files off of the Arch install disk to get our own live bootable rescue disk.


Most live disks implement a sort of ugly hack to make the flat, unpartitioned iso filesystem look like an acceptable boot device to a UEFI system while still maintaining backwards compatibility w/ BIOS systems.
Arch Linux is no exception.
This ugly hack is that efiboot.img currently mounted on ./efi. It's where we'll find our kernel and initramfs image file. The other ones on the disk (in ./arch/arch/boot) will not work for EFI systems.

sudo sh -ec    &lt;&lt;CONF '
     mount    ""$1"" esp
     cp -ar    efi/EFI/archiso esp/EFI
     cp -ar    arch/arch/*x86* esp/EFI/archiso
     mkdir     esp/EFI/archiso/cow
     xargs   &gt; esp/EFI/archiso/refind_linux.conf
     umount    efi arch
     rm -rf    efi arch*' -- ""$TGT""1
\""arch_iso\"" \""archisobasedir=EFI/archiso    \
               archisolabel=VESP             \
               copytoram                     \
               cow_label=VESP                \
               cow_directory=/EFI/archiso/cow\
               cow_persistence=P             \
               cow_spacesize=384M            \
               initrd=EFI/archiso/archiso.img\""
CONF




You have essentially just installed - from the ground up - a pre-boot rescue environment with a persistent copy-on-write save file (so you might, for example systemctl enable sshd_socket now and the setting would persist in the live system's next boot). The Arch Linux live install media now resides on your system's boot partition and can be called from the boot menu at any time. Of course, you also installed the boot menu manager.


A couple of things about the above should stand out to you:


I use *x86* because I have a 64-bit machine and that glob gets what I need. For a 32-bit installation (but why?) use *686* instead.


What I need, by the way, is a total of only 7 files and approximately 300M.
The live-system's rootfs is the squashed image in esp/EFI/archiso/x86_64/airootfs.sfs.

I specify the disk by label. There are no hints or other such nonsense - the disk is named and so it is easily found. You'll need to substitute in whatever you chose for an esp label instead of VESP.
The copytoram kernel parameter instructs the Arch Linux live init system to copy its rootfs image into a tmpfs before loopmounting it - which frees you actually to access the esp when working in that environment. Most live install systems offer similarly arranged constructs.



Where EFI shines is in its ability to handle a filesystem. On modern computers there is absolutely no need to pack some raw binary and wedge it in between your disk partitions. It astounds me that people still do, when, instead, they could manage and configure their boot environment with simple text files arranged in a regular, everyday directory tree. Above I put the kernel and initramfs in their own named folder in a central tree structure. The EFI - which will take its cues from rEFInd in this case for convenience - will invoke that at boot by pathname because it mounts the esp.

Now all that is left to do is to ensure you understand how to select the system which will actually boot when you need to. Understand - you can boot this right now. You can do it in a virtual machine w/ qemu (you'll need OVMF -pflash firmware) or you can reboot your computer and rEFInd will detect the kernel and pass its pathname to the firmware which will load and execute the Arch Linux live system. When you install a more permanent system on the disk - or several (which you can do right now if you so choose by rebooting to the live disk and performing the installation) - you'll want to keep its kernel and initramfs in the same structure. This is very easily arranged.


If, for example, you were to install a system on a root partition named, for lack of an imagination, root, you'd want to set it up something like this:


mount --bind its particular boot folder over the root /boot path in /etc/fstab.
You'll need two lines in /etc/fstab and to create a mount point in /esp to handle this.

sudo sh -c          &lt;&lt;\FSTAB     '
     [ -d /esp ]    || mkdir /esp
     findmnt   /esp || mount -L ESP /esp
     mkdir -p  /esp/EFI/root
     cp        /boot/kernel binary   \
               /boot/initramfs.img   \
               /esp/EFI/root
     mount -B  /esp/EFI/root /boot
     cat   &gt;&gt;  /etc/fstab
     echo ""$1""&gt;/boot/refind_linux.conf
' -- '""new_menu_item"" ""root=LABEL=root""'
LABEL=ESP       /esp    vfat    defaults        0 2
/esp/EFI/root   /boot   none    bind,defaults   0 0
FSTAB




You only ever have to do anything like that once per installation - and that is assuming you didn't set it up that way in the first place - which is easier because the kernel and initramfs will already be where they belong. Once you've got those lines in /etc/fstab and a minimal config file in /boot/refind_linux.conf you're set for good. You can support as many installations as you like on the same system with the same /esp device and centralize all bootable binaries in the same tree just like that. Different
systems will do things a little differently - Windows takes a little more cajoling to get it to conform, for example - but they will all work.


Ok, the last thing you need to know, as I said before, is how choose the  next booting installation from the filesystem. This is configured in the  file /esp/EFI/BOOT/refind.conf.


You should read this file - it's probably 99% comment and will  tell you all about what you might do with it.
Of course, you don't really have to do anything - by default rEFInd will boot the most recently updated kernel in its scan tree.
But I usually wind up setting the following options:

&lt;&lt;\DEF sudo tee \
       /esp/EFI/BOOT/refind.conf.def
### refind.conf.def
### when renamed to refind.conf this file
### will cause refind to select by default
### the menu item called ""new_menu_item""
### in its /boot/refind_linux.conf
default_selection new_menu_item
### this file will also set the menu timeout
### to only 5 seconds at every boot
timeout 5
### END
DEF

And the rescue file...

&lt;&lt;\RES sudo tee \
       /esp/EFI/BOOT/refind.conf.res
### refind.conf.res
### this one will default to selecting
### the entry named ""arch_iso"" with a
### 10 second timeout
default_selection arch_iso
timeout 10
### END
RES



And so now you can just move them around.
For example, to make the rescue environment definitely boot after you do reboot now...




sudo cp /esp/EFI/BOOT/refind.conf.res \
        /esp/EFI/BOOT/refind.conf



And substitute .def for the .res used above, of course, to go back to default root.



",mikeserv,https://unix.stackexchange.com/users/52934,http://unix.stackexchange.com/questions/212757/is-possible-to-remote-mount-an-image-that-can-boot-and-install-itself,TECHNOLOGY,unix.stackexchange.com,0.8888888888888888,0.7777777777777778,0.0,0.3333333333333333,1.0,0.3333333333333333,0.5555555555555556,0.3333333333333333,0.6666666666666666,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,1.0,1.0,0.8333333333333334,1.0,1.0,0.8,0.6666666666666666,0.6666666666666666,0.3333333333333333,1.0,"Can I install an image remotely, which can boot and install itself?","I have a remote server, which runs Linux. I would like to install remotely the OS image, in case that it gets corrupted (this has already happened twice while I am experimenting with the OS).

So far, the only way that I have, is to physically go to the machine location and use a USB disk to mount the OS and the BIOS see it, so it can boot from it.

Is there any way to basically connect to the machine via ssh, attach this image and have it act like it would be on a virtual drive on Windows (like daemon tools for example), so it would persist to a reboot and allow me to install remotely the OS?

I was looking at solutions on Google, but I found something mentioning PXE boot....which sounds complicated, since you need a server and such, and it is not as simple as mounting an image and being done with it.

Beyond that, I found nothing useful, so I am quite short on options....does anyone know how to accomplish this?
","Here's a hypothetical situation which I consider might be plausible:


The targeted machine is EFI.
grub is either never installed on the target or has been utterly wiped from the system.


it can only ever interfere and offers nothing of value otherwise.



So what we might do in the above case is configure a boot option for a small installation/rescue image we keep on our /esp or EFI system partition.

If anything were ever to go wrong with our current installation, then, for so long as we can at least access the EFI system partition by some means, then we can interface our firmware and set the machine to boot to our recovery image on next reboot. In that case all we would have to do is change a text file or two, cross our fingers and run reboot now.

Here is a basic set of commands for a minimally configured Arch Linux (because it's what I use) system which could still do as I describe.


First, we'll make a work directory and download some files.


I use aria2c here. I recommend it, but use whatever works.
I unzip rEFInd with 7za but the same
tool preference is yours in all cases here.
If you're not reading this within a few hours/days of my posting it, then there is a very good chance that the links used below are not current.

mkdir /tmp/work &amp;&amp; cd /tmp/work || exit
aria2c  'magnet:?xt=urn:btih:331c7fac2e13c251d77521d2dc61976b6fc4a033&amp;dn=archlinux-2015.06.01-dual.iso&amp;tr=udp://tracker.archlinux.org:6969&amp;tr=http://tracker.archlinux.org:6969/announce' \
        'http://iweb.dl.sourceforge.net/project/refind/0.8.7/refind-cd-0.8.7.zip'
7za x ref*.zip; rm ref*zip


Next I'll make an image disk.


I use a file here with loop devices, but you may want to use an actual disk if you want to boot to this from firmware.
In the case of an actual device the fallocate and losetup stuff can be ignored and the actual device names will far more likely
correspond to /dev/sda[12] than /dev/loop0p[12]

fallocate -l4G img


Now I'll partition that disk with the gdisk utility and assign it to a loop device.


This is a scripted shortcut for the options you'd want to feed the program interactively. It will create a GUID partition table and a partition of type EFI-system that spans the first available 750Mib of the target disk and another linux default partition spanning the rest of the disk.


These partitions will be /dev/sda1 and /dev/sda2 respectively if you're using a real disk, which will be /dev/sda rather than ./img. It is usually desirable to add more than one partition for a linux root, which is assumed to be the purpose of /dev/sda2.

printf script or no, the gdisk program is easy to use - and so you might do better to go at it interactively instead. The target disk should not be mounted when it is run, and you'll probably need root rights to write the changes.
As a general rule you can do pretty much whatever you want in that program without any effect until you write - so be sure when you do.
I'll be putting my $TGT in a shell variable. Except for its definition here, which you may want to tailor as necessary, where I use it so can you.

printf %s\\n o y n 1 '' +750M ef00 \
                 n 2 '' '' '' '' w y |
gdisk ./img     &gt;/dev/null
TGT=$(sudo losetup --show -Pf img)p


We'll need a filesystem on the esp, too. It must be FAT.


I give mine the fs label VESP. You should call yours whatever you want.
We'll use the label later in /etc/fstab and another config file - so definitely make it something.
In my opinion you should always label all disks.
If you install an OS to ${TGT}2 now you will of course need a filesystem for it as well.

sudo mkfs.vfat -nVESP ""$TGT""1


And we'll make some mount directories and start extracting the relevant files.

   set     ref     ref*iso         \
        arch    arch*iso        \
        efi     arch/EFI/archiso/efiboot.img
while   [ ""$#"" -gt 0 ]
do      mkdir ""$1"" || exit
        sudo mount ""$2"" ""$1""
        shift 2
done;   mkdir esp

Install rEFInd...


rEFInd is a boot manager - which mostly just offers and populates boot menus.
rEFInd will put its config files on the esp and these can be edited at any time and anyway you like.

sudo ref/install.sh --usedefault ""$TGT""1 &amp;&amp;
sudo umount ref  &amp;&amp; rm -rf ref*


Now we'll mount our esp and get the needed files off of the Arch install disk to get our own live bootable rescue disk.


Most live disks implement a sort of ugly hack to make the flat, unpartitioned iso filesystem look like an acceptable boot device to a UEFI system while still maintaining backwards compatibility w/ BIOS systems.
Arch Linux is no exception.
This ugly hack is that efiboot.img currently mounted on ./efi. It's where we'll find our kernel and initramfs image file. The other ones on the disk (in ./arch/arch/boot) will not work for EFI systems.

sudo sh -ec    &lt;&lt;CONF '
     mount    ""$1"" esp
     cp -ar    efi/EFI/archiso esp/EFI
     cp -ar    arch/arch/*x86* esp/EFI/archiso
     mkdir     esp/EFI/archiso/cow
     xargs   &gt; esp/EFI/archiso/refind_linux.conf
     umount    efi arch
     rm -rf    efi arch*' -- ""$TGT""1
\""arch_iso\"" \""archisobasedir=EFI/archiso    \
               archisolabel=VESP             \
               copytoram                     \
               cow_label=VESP                \
               cow_directory=/EFI/archiso/cow\
               cow_persistence=P             \
               cow_spacesize=384M            \
               initrd=EFI/archiso/archiso.img\""
CONF




You have essentially just installed - from the ground up - a pre-boot rescue environment with a persistent copy-on-write save file (so you might, for example systemctl enable sshd_socket now and the setting would persist in the live system's next boot). The Arch Linux live install media now resides on your system's boot partition and can be called from the boot menu at any time. Of course, you also installed the boot menu manager.


A couple of things about the above should stand out to you:


I use *x86* because I have a 64-bit machine and that glob gets what I need. For a 32-bit installation (but why?) use *686* instead.


What I need, by the way, is a total of only 7 files and approximately 300M.
The live-system's rootfs is the squashed image in esp/EFI/archiso/x86_64/airootfs.sfs.

I specify the disk by label. There are no hints or other such nonsense - the disk is named and so it is easily found. You'll need to substitute in whatever you chose for an esp label instead of VESP.
The copytoram kernel parameter instructs the Arch Linux live init system to copy its rootfs image into a tmpfs before loopmounting it - which frees you actually to access the esp when working in that environment. Most live install systems offer similarly arranged constructs.



Where EFI shines is in its ability to handle a filesystem. On modern computers there is absolutely no need to pack some raw binary and wedge it in between your disk partitions. It astounds me that people still do, when, instead, they could manage and configure their boot environment with simple text files arranged in a regular, everyday directory tree. Above I put the kernel and initramfs in their own named folder in a central tree structure. The EFI - which will take its cues from rEFInd in this case for convenience - will invoke that at boot by pathname because it mounts the esp.

Now all that is left to do is to ensure you understand how to select the system which will actually boot when you need to. Understand - you can boot this right now. You can do it in a virtual machine w/ qemu (you'll need OVMF -pflash firmware) or you can reboot your computer and rEFInd will detect the kernel and pass its pathname to the firmware which will load and execute the Arch Linux live system. When you install a more permanent system on the disk - or several (which you can do right now if you so choose by rebooting to the live disk and performing the installation) - you'll want to keep its kernel and initramfs in the same structure. This is very easily arranged.


If, for example, you were to install a system on a root partition named, for lack of an imagination, root, you'd want to set it up something like this:


mount --bind its particular boot folder over the root /boot path in /etc/fstab.
You'll need two lines in /etc/fstab and to create a mount point in /esp to handle this.

sudo sh -c          &lt;&lt;\FSTAB     '
     [ -d /esp ]    || mkdir /esp
     findmnt   /esp || mount -L ESP /esp
     mkdir -p  /esp/EFI/root
     cp        /boot/kernel binary   \
               /boot/initramfs.img   \
               /esp/EFI/root
     mount -B  /esp/EFI/root /boot
     cat   &gt;&gt;  /etc/fstab
     echo ""$1""&gt;/boot/refind_linux.conf
' -- '""new_menu_item"" ""root=LABEL=root""'
LABEL=ESP       /esp    vfat    defaults        0 2
/esp/EFI/root   /boot   none    bind,defaults   0 0
FSTAB




You only ever have to do anything like that once per installation - and that is assuming you didn't set it up that way in the first place - which is easier because the kernel and initramfs will already be where they belong. Once you've got those lines in /etc/fstab and a minimal config file in /boot/refind_linux.conf you're set for good. You can support as many installations as you like on the same system with the same /esp device and centralize all bootable binaries in the same tree just like that. Different
systems will do things a little differently - Windows takes a little more cajoling to get it to conform, for example - but they will all work.


Ok, the last thing you need to know, as I said before, is how choose the  next booting installation from the filesystem. This is configured in the  file /esp/EFI/BOOT/refind.conf.


You should read this file - it's probably 99% comment and will  tell you all about what you might do with it.
Of course, you don't really have to do anything - by default rEFInd will boot the most recently updated kernel in its scan tree.
But I usually wind up setting the following options:

&lt;&lt;\DEF sudo tee \
       /esp/EFI/BOOT/refind.conf.def
### refind.conf.def
### when renamed to refind.conf this file
### will cause refind to select by default
### the menu item called ""new_menu_item""
### in its /boot/refind_linux.conf
default_selection new_menu_item
### this file will also set the menu timeout
### to only 5 seconds at every boot
timeout 5
### END
DEF

And the rescue file...

&lt;&lt;\RES sudo tee \
       /esp/EFI/BOOT/refind.conf.res
### refind.conf.res
### this one will default to selecting
### the entry named ""arch_iso"" with a
### 10 second timeout
default_selection arch_iso
timeout 10
### END
RES



And so now you can just move them around.
For example, to make the rescue environment definitely boot after you do reboot now...




sudo cp /esp/EFI/BOOT/refind.conf.res \
        /esp/EFI/BOOT/refind.conf



And substitute .def for the .res used above, of course, to go back to default root.



"
1438,1438,2265,Sharepoint 2010. Add custom background and frame for content editor webpart,"I need to create custom webpart with complex (few divs, or other html elements) background and borders. 

How can i use default sharepoint content editor and just add predefined background and frame!?

Thanks.
",Evgeny,https://stackoverflow.com/users/508330,"You tagged your question with Sharepoint 2007 and 2010, the content editors are different though. This answer is for SP2010:

You can just add CSS to a custom CSS file. background-image for .ms-rte-layoutzone-inner-editable will do the image trick. If you want to add a ""frame"" as in border, you can add border attributes to .ms-rte-layoutzone-outer and make it e.g. red.

An example for a background image:

.ms-rte-layoutzone-inner-editable {
    border-image: url(/PublishingImages/Mylogo.gif);
}


But please do your users a favor and don't include anything blinking or distracting to the content editor's background - if you wanna go for some very light grey or something like that it's OK.

For MOSS2007 you need to check the specific styles you can override.
",Dennis G,https://stackoverflow.com/users/266453,http://stackoverflow.com/questions/7500376/sharepoint-2010-add-custom-background-and-frame-for-content-editor-webpart,STACKOVERFLOW,stackoverflow.com,1.0,0.7777777777777778,0.0,0.0,1.0,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.8888888888888888,Sharepoint 2010。 Add custom backgrounds and frames for content editor Web Parts,I need to create custom web parts with complex backgrounds and borders (few divs or other HTML elements).,"You tagged your question with Sharepoint 2007 and 2010, the content editors are different though. This answer is for SP2010:

You can just add CSS to a custom CSS file. background-image for .ms-rte-layoutzone-inner-editable will do the image trick. If you want to add a ""frame"" as in border, you can add border attributes to .ms-rte-layoutzone-outer and make it e.g. red.

An example for a background image:

.ms-rte-layoutzone-inner-editable {
    border-image: url(/PublishingImages/Mylogo.gif);
}


But please do your users a favor and don't include anything blinking or distracting to the content editor's background - if you wanna go for some very light grey or something like that it's OK.

For MOSS2007 you need to check the specific styles you can override.
"
4264,4264,6798,Images give 404 after changing default domain,"Never encountered this issue before. So I've just moved a site for a client to another server and for some reason all images give me a 404 when I change the default domain in the database (siteurl and home). CSS, JS and other files are linked correctly - it seems there's something affecting the uploads folder but I can't pinpoint what it is. Any ideas?
",Staffan Estberg,https://wordpress.stackexchange.com/users/67844,"You must update the URLs in the database. Here is a tool that you can use https://interconnectit.com/products/search-and-replace-for-wordpress-databases/

You can download it, unzip and upload it to your server where you have to replace URLs and then you can run it.

It's pretty simple. You have to enter old and new base URLs. You can also perform a dry run, check the changes and then go for live run.
",WisdmLabs,https://wordpress.stackexchange.com/users/26523,http://wordpress.stackexchange.com/questions/178742/images-give-404-after-changing-default-domain,TECHNOLOGY,wordpress.stackexchange.com,0.8888888888888888,0.7777777777777778,0.0,0.6666666666666666,1.0,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,1.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,0.8888888888888888,0.9333333333333332,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.8888888888888888,Image display 404 after changing the default domain,"This problem has never been encountered before. So I just moved one client's site to another server, and for some reason, when I changed the default domain (siteurl and home) in the database, all the images would show 404. CSS, JS, and other files are linked correctly - something seems to affect the uploads folder, but I'm not sure what it is. Do you have any ideas?","You must update the URLs in the database. Here is a tool that you can use https://interconnectit.com/products/search-and-replace-for-wordpress-databases/

You can download it, unzip and upload it to your server where you have to replace URLs and then you can run it.

It's pretty simple. You have to enter old and new base URLs. You can also perform a dry run, check the changes and then go for live run.
"
4961,4961,7900,"When we talk about an 88/76/etc Key piano, does that include all keys or just white notes?","I have an old cheap keyboard which spans 5 octaves plus one extra C, so it goes from C2-C7 (I think).

Does that make this a 41 (5 x 8 +1) key or a 61 (5 x 12 + 1) keyboard?

When we talk about a standard 88-key piano is that the total number of white and black notes, meaning it covers just over 7 octaves?

While I'm here, what are the standard keyboard configurations if any other than a traditional piano can be said to be standard?
",Mr. Boy,https://music.stackexchange.com/users/15313,"It is not hard to work out a number of keys when avoiding remembering this by heart.

A full piano has:


4 full octaves up from the middle C (C3)
3 full octaves down also from the middle C
plus 3 additional keys at left next to C0.


An octave (e.g. from C3 to B3) contains 12 keys. 

The number of keys:


3 extra keys at the left
3 octaves at the left, excluding the middle C, 12*3 = 36
the middle C (C3)
4 octaves up make, excluding the middle C, 12*4 = 48


All together: 3 + 36 + 1 + 48 = 88
",Celdor,https://music.stackexchange.com/users/15681,http://music.stackexchange.com/questions/26880/when-we-talk-about-an-88-76-etc-key-piano-does-that-include-all-keys-or-just-wh,LIFE_ARTS,music.stackexchange.com,1.0,0.4444444444444444,0.0,0.6666666666666666,1.0,1.0,0.5555555555555556,0.6666666666666666,0.6666666666666666,0.0,0.0,1.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.6666666666666666,0.0,0.8888888888888888,0.8888888888888888,0.5555555555555556,1.0,0.8888888888888888,0.7333333333333333,0.0,0.0,1.0,0.8888888888888888,"When we talk about the 88 / 76 / etc key piano, does it include all keys or just white notes?","I have an old cheap keyboard which spans 5 octaves plus one extra C, so it goes from C2-C7 (I think).

Does that make this a 41 (5 x 8 +1) key or a 61 (5 x 12 + 1) keyboard?

When we talk about a standard 88-key piano is that the total number of white and black notes, meaning it covers just over 7 octaves?

While I'm here, what are the standard keyboard configurations if any other than a traditional piano can be said to be standard?
","It is not hard to work out a number of keys when avoiding remembering this by heart.

A full piano has:


4 full octaves up from the middle C (C3)
3 full octaves down also from the middle C
plus 3 additional keys at left next to C0.


An octave (e.g. from C3 to B3) contains 12 keys. 

The number of keys:


3 extra keys at the left
3 octaves at the left, excluding the middle C, 12*3 = 36
the middle C (C3)
4 octaves up make, excluding the middle C, 12*4 = 48


All together: 3 + 36 + 1 + 48 = 88
"
202,202,325,Arriving very late at hotels in Athens,"This September, I will be flying into Athens at 10:45 PM.  I'll be leaving to Santorini, then arriving back towards the end of the week via Piraeus at 11:45 PM.  

Will arriving that late in town pose any problem traveling to Athenian Callirhoe Exclusiv near the  Parthenon?  Will checkin be a problem?

I see that the hotel is near a metro stop and a bus stop, so hopefully one of those will work.
",lfrandom,https://travel.stackexchange.com/users/8064,"The last Line 1 metro leaves Piraeus at 00:15, so you're cutting it awfully close even if your ferry arrives precisely on time, and it doesn't pass very close to your hotel anyway (you'd need to transfer to Line 2).

Bus 040 from the port to Syntagma (near your hotel) runs every 30 min through the night, so it's probably a better bet.

As for the hotel, you should get in touch with them and make sure they understand you will be arriving very late, so they need to keep your room.
",jpatokal,https://travel.stackexchange.com/users/1893,http://travel.stackexchange.com/questions/19920/arriving-very-late-at-hotels-in-athens,CULTURE,travel.stackexchange.com,1.0,0.4444444444444444,0.3333333333333333,1.0,1.0,1.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,1.0,0.6666666666666666,0.8888888888888888,1.0,0.9333333333333332,0.6666666666666666,0.3333333333333333,0.3333333333333333,1.0,Late arrival at Athens Hotel,"This September, I will be flying into Athens at 10:45 PM.  I'll be leaving to Santorini, then arriving back towards the end of the week via Piraeus at 11:45 PM.  

Will arriving that late in town pose any problem traveling to Athenian Callirhoe Exclusiv near the  Parthenon?  Will checkin be a problem?

I see that the hotel is near a metro stop and a bus stop, so hopefully one of those will work.
","The last Line 1 metro leaves Piraeus at 00:15, so you're cutting it awfully close even if your ferry arrives precisely on time, and it doesn't pass very close to your hotel anyway (you'd need to transfer to Line 2).

Bus 040 from the port to Syntagma (near your hotel) runs every 30 min through the night, so it's probably a better bet.

As for the hotel, you should get in touch with them and make sure they understand you will be arriving very late, so they need to keep your room.
"
1568,1568,2463,Why did Voldemort assume that no-one knew about Room of Hidden Things?,"Voldemort hid one of his Horcruxes inside Hogwarts. It seemed to be relying on security through obscurity as far as protecting it. But as we know, it ended up not being so secure because it wasn't so obscure - Harry Potter knew about the Room of Hidden Things.

My question is, the way Rowling describes this hints at the fact that Riddle had an assumption that very few people would ever stumble upon that room. *WHY???



First, let's show Harry's theory on what Voldemort was thinking, how and why:

Here's Harry understanding Voldemort's thinking in HP7 once he figured out where the Diadem was (bold emphasis mine):


  Tom Riddle, who confided in no one and operated alone, might have been arrogant
  enough to assume that he, and only he, had penetrated the deepest mysteries of
  Hogwarts Castle. Of course, Dumbledore and Flitwick, those model pupils, had never
  set foot in that particular place, but he, Harry, had strayed off the beaten track in his
  time at school – here at least was a secret area he and Voldemort knew, that
  Dumbledore had never discovered –


...and later on, with Harry explains the location to Ron/Hermione:


  “He hid it exactly where I had my old Potions book, where everyone’s been hiding stuff for centuries. He thought he was the only one to find it. Come on.”
  
  “And he never realized anyone could get in?” said Ron, his voice echoing in the silence.
  “He thought he was the only one,” said Harry.


.



Yet, from available evidence, that seems to be a completely wrong assumption, even at Voldemort's time. 

Let's examine that last quote again, with emphasis on other info available:


  “He hid it exactly where I had my old Potions book, where everyone’s been hiding stuff for centuries.” ...
  
  ...
  
  “And he never realized anyone could get in?” said Ron, his voice echoing in the silence.
  “He thought he was the only one,” said Harry. “Too bad for him I’ve had to hide stuff in
  my time... this way,” he added. “I think it’s down here... “ 
  
  They sped off up adjacent aisles; Harry could hear the others’ footsteps echoing through the towering piles of junk, of bottles, hats, crates, chairs, books, weapons, broomsticks, bats...


.

OK, so if there's a truckload (or train-load, by the description) of stuff in that room, isn't the only reasonable conclusion: ""the room is a fairly popular destination with plenty of people who've found their way there in the past, and therefore, likely, plenty who will in the future""? 

Doesn't matter what your arrogance level is, the evidence seems to point to only one conclusion - it's quite fine as a place to temporarily bury your dirt so teachers won't tag you for your misdeeds, but this is NOT the place to hide something that you want permanently safe! 

So why did Voldemort make such a moronic mistake?
",DVK-on-Ahch-To,https://scifi.stackexchange.com/users/976,"It is a pebble-on-the-beach approach - how many people are going to find the room, know that there is a diadem in there that is significant (and know what a diadem is, for that matter), be able to find it, and destroy it? Voldemort was relying on the anser being no-one, at least until such a time as he was powerful enough to not be bothered.

And remember that finding the Room of Requirement is not the same as finding the Room of Hidden Things. Finding the RoR is one challenge, but finding as the RoHT - reliably, so that you can come back to it - was a one in a million chance.

And @OghmaOsiris - the fact that three schoolchildren thwarted Voldemort several times is one of the suspensions of disbelief required for the series.
",Schroedingers Cat,https://scifi.stackexchange.com/users/3074,http://scifi.stackexchange.com/questions/8734/why-did-voldemort-assume-that-no-one-knew-about-room-of-hidden-things,LIFE_ARTS,scifi.stackexchange.com,1.0,0.7777777777777778,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.7777777777777778,0.8888888888888888,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.3333333333333333,1.0,0.8888888888888888,Why does Voldemort think no one knows what's hidden?,"Voldemort hid one of his Horcruxes inside Hogwarts. It seemed to be relying on security through obscurity as far as protecting it. But as we know, it ended up not being so secure because it wasn't so obscure - Harry Potter knew about the Room of Hidden Things.

My question is, the way Rowling describes this hints at the fact that Riddle had an assumption that very few people would ever stumble upon that room. *WHY???



First, let's show Harry's theory on what Voldemort was thinking, how and why:

Here's Harry understanding Voldemort's thinking in HP7 once he figured out where the Diadem was (bold emphasis mine):


  Tom Riddle, who confided in no one and operated alone, might have been arrogant
  enough to assume that he, and only he, had penetrated the deepest mysteries of
  Hogwarts Castle. Of course, Dumbledore and Flitwick, those model pupils, had never
  set foot in that particular place, but he, Harry, had strayed off the beaten track in his
  time at school – here at least was a secret area he and Voldemort knew, that
  Dumbledore had never discovered –


...and later on, with Harry explains the location to Ron/Hermione:


  “He hid it exactly where I had my old Potions book, where everyone’s been hiding stuff for centuries. He thought he was the only one to find it. Come on.”
  
  “And he never realized anyone could get in?” said Ron, his voice echoing in the silence.
  “He thought he was the only one,” said Harry.


.



Yet, from available evidence, that seems to be a completely wrong assumption, even at Voldemort's time. 

Let's examine that last quote again, with emphasis on other info available:


  “He hid it exactly where I had my old Potions book, where everyone’s been hiding stuff for centuries.” ...
  
  ...
  
  “And he never realized anyone could get in?” said Ron, his voice echoing in the silence.
  “He thought he was the only one,” said Harry. “Too bad for him I’ve had to hide stuff in
  my time... this way,” he added. “I think it’s down here... “ 
  
  They sped off up adjacent aisles; Harry could hear the others’ footsteps echoing through the towering piles of junk, of bottles, hats, crates, chairs, books, weapons, broomsticks, bats...


.

OK, so if there's a truckload (or train-load, by the description) of stuff in that room, isn't the only reasonable conclusion: ""the room is a fairly popular destination with plenty of people who've found their way there in the past, and therefore, likely, plenty who will in the future""? 

Doesn't matter what your arrogance level is, the evidence seems to point to only one conclusion - it's quite fine as a place to temporarily bury your dirt so teachers won't tag you for your misdeeds, but this is NOT the place to hide something that you want permanently safe! 

So why did Voldemort make such a moronic mistake?
","It is a pebble-on-the-beach approach - how many people are going to find the room, know that there is a diadem in there that is significant (and know what a diadem is, for that matter), be able to find it, and destroy it? Voldemort was relying on the anser being no-one, at least until such a time as he was powerful enough to not be bothered.

And remember that finding the Room of Requirement is not the same as finding the Room of Hidden Things. Finding the RoR is one challenge, but finding as the RoHT - reliably, so that you can come back to it - was a one in a million chance.

And @OghmaOsiris - the fact that three schoolchildren thwarted Voldemort several times is one of the suspensions of disbelief required for the series.
"
1059,1059,1666,When should a supervisor be a co-author?,"What are people's views on this?  To be specific: suppose a PhD student has produced a piece of original mathematical research. Suppose that student's supervisor suggested the problem, and gave a few helpful comments, but otherwise did not contribute to the work.  Should that supervisor still be named as a co-author, or would an acknowledgment suffice?

I am interested in two aspects of this. Firstly the moral/etiquette aspect: do you consider it bad form for a student not to name their supervisor?  Or does it depend on that supervisor's input?  And secondly, the practical, career-advancing aspect: which is better, for a student to have a well-known name on his or her paper (and hence more chance of it being noticed/published), or to have a sole-authored piece of work under their belt to hopefully increase their chances of being offered a good post-doc position?

[To clarify: original question asked by MrB ]
",MrB,https://mathoverflow.net/users/2189,"One anecdote ... Serving on a university-wide committee, I found that in one field (I think zoology?) the norm is having the advisor as co-author; and when the advisor does not appear as co-author it is taken as a sign that the advisor has a low opinion of the thesis.  

During my career, there are only two Ph.D. theses that were published with me as co-author.   

One case (Yuri Dimitrov):  After the degree was completed, the thesis had to be abridged for publication.  Dr Dimitrov would come to my office once or twice a week and show me his progress (much as he had done before the degree was completed).  In the end he suggested joint authorship for the paper.  Subsequently, we wrote another joint paper extending the work.

Another case (Jeff Golds):  This guy, upon completion of his degree, was raring to begin his career in the software industry.  It was clear he would never publish the work, but I thought it deserved publication.  So I wrote it up for publication, and it appeared as a joint paper.
",Gerald Edgar,https://mathoverflow.net/users/454,http://mathoverflow.net/questions/57337,SCIENCE,mathoverflow.net,0.8888888888888888,0.7777777777777778,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.6666666666666666,0.0,1.0,0.0,0.0,0.3333333333333333,0.0,0.3333333333333333,0.3333333333333333,0.0,0.3333333333333333,0.0,0.8888888888888888,0.6666666666666666,0.5555555555555556,0.7777777777777778,0.7777777777777778,0.5333333333333333,0.3333333333333333,0.0,0.3333333333333333,0.6666666666666666,When should a supervisor become a coauthor?,"What are people's views on this?  To be specific: suppose a PhD student has produced a piece of original mathematical research. Suppose that student's supervisor suggested the problem, and gave a few helpful comments, but otherwise did not contribute to the work.  Should that supervisor still be named as a co-author, or would an acknowledgment suffice?

I am interested in two aspects of this. Firstly the moral/etiquette aspect: do you consider it bad form for a student not to name their supervisor?  Or does it depend on that supervisor's input?  And secondly, the practical, career-advancing aspect: which is better, for a student to have a well-known name on his or her paper (and hence more chance of it being noticed/published), or to have a sole-authored piece of work under their belt to hopefully increase their chances of being offered a good post-doc position?

[To clarify: original question asked by MrB ]
","One anecdote ... Serving on a university-wide committee, I found that in one field (I think zoology?) the norm is having the advisor as co-author; and when the advisor does not appear as co-author it is taken as a sign that the advisor has a low opinion of the thesis.  

During my career, there are only two Ph.D. theses that were published with me as co-author.   

One case (Yuri Dimitrov):  After the degree was completed, the thesis had to be abridged for publication.  Dr Dimitrov would come to my office once or twice a week and show me his progress (much as he had done before the degree was completed).  In the end he suggested joint authorship for the paper.  Subsequently, we wrote another joint paper extending the work.

Another case (Jeff Golds):  This guy, upon completion of his degree, was raring to begin his career in the software industry.  It was clear he would never publish the work, but I thought it deserved publication.  So I wrote it up for publication, and it appeared as a joint paper.
"
812,812,1285,Could Apple and Microsoft allow the GPLv3 on their locked-down devices?,"It seems that both Apple and Microsoft prohibit GPLv3-licensed software in the app stores for their locked-down devices (i.e. iOS, Windows Phone and the Metro part of Windows). I have heard various explanations for this. However: Would they even be able to allow this license in their app stores if they wanted to, or does the GPL's anti-tivoization clause already prohibit this?
",Erik,https://programmers.stackexchange.com/users/55048,"Apple effectively ban any GPL because they only allow redistribution through the store and by registered developers. So if you distribute the GPL to your users they cannot abide by it.

Apple could simply allow any GPL app to be redistributed by any user through a free section of the site - but chose not to. Ironically OSX is based on a free BSD Unix kernel.

Microsoft have an historical objection to ""the cancer of open source"" and their licence explicitly bans any open source licenced app that requires redistribution of source (ie GPL). This is their right, it's a business decision -  just like banning sales in a particular country. As their position in the market becomes less dominant they might change their mind
",Martin Beckett,https://programmers.stackexchange.com/users/2021,http://programmers.stackexchange.com/questions/167797/could-apple-and-microsoft-allow-the-gplv3-on-their-locked-down-devices,TECHNOLOGY,programmers.stackexchange.com,1.0,0.8888888888888888,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,0.8888888888888888,Can apple and Microsoft use GPLv3 on their locked in devices?,"Both apple and Microsoft seem to ban GPLv3 licensed software for devices locked in the app store (that is, IOS, Windows Phone, and the Metro part of windows). I have heard various explanations for this. However: if they want, can they even allow this license in their app store, or is GPL's anti activity clause banned?","Apple effectively ban any GPL because they only allow redistribution through the store and by registered developers. So if you distribute the GPL to your users they cannot abide by it.

Apple could simply allow any GPL app to be redistributed by any user through a free section of the site - but chose not to. Ironically OSX is based on a free BSD Unix kernel.

Microsoft have an historical objection to ""the cancer of open source"" and their licence explicitly bans any open source licenced app that requires redistribution of source (ie GPL). This is their right, it's a business decision -  just like banning sales in a particular country. As their position in the market becomes less dominant they might change their mind
"
3236,3236,5159,So gravity turns things round,"It makes sense, since gravity tends to push the surface of a body towards it's center. Unless I'm mistaken, everything with mass has it's own gravity, every atom and for instance, our own bodies should also have their own gravity. The question is: how strong is our own gravitational pull? I know it must be extremely weak, but is there actually anything at all that gets attracted to us, like maybe, bacteria or molecules?

And finally (this will sound ridiculous, but I'd really want to get an answer or at least a way of calculating it myself): What size would a human body have to reach in order for it to collapse into a sphere?
",Pancho Saavedra,https://physics.stackexchange.com/users/22398,"
  It makes sense, since gravity tends to push the surface of a body towards it's center


Yes, gravity tends to pull towards the center of mass. I think you're comparing human body to celestial bodies - for instance, stars. Stars collapse within themselves after their lifetime because, their internal (thermal) pressure is not sufficient enough to sustain the gravitational collapse.


  How strong is our own gravitational pull? I know it must be extremely weak, but is there actually anything at all that gets attracted to us, like, maybe, bacteria or molecules?


Yes, it's extremely weak. The constant $G$ is already making the situation very weak. When you mention bacteria or molecule, you are actually reducing the effect further due to their mass. Gravity doesn't depend upon the size. Only MASS matters here. As nitrogen is around us mostly, you can calculate the force between you and a single nitrogen molecule at a distance of an angstrom, which is barely about $F\simeq 10^{-15}\text N$.


  What size would a human body have to reach in order for him to collapse into a sphere?


Wiki has a nice quote on gravitational collapse:


  Because gravity is comparatively weak compared to other fundamental forces, gravitational collapse is usually associated with very massive bodies or collections of bodies, such as stars (including collapsed stars such as supernovae, neutron stars and black holes) and massive collections of stars such as globular clusters and galaxies.


Human body is very small compared to any celestial object (just like the size of an atom in a large city). So, you'd probably need the size of some bigger (massive) celestial object to have a significant effect on the gravitational collapse.
",Waffle's Crazy Peanut,https://physics.stackexchange.com/users/11062,http://physics.stackexchange.com/questions/58023/so-gravity-turns-things-round,SCIENCE,physics.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,0.3333333333333333,0.6666666666666666,1.0,0.5555555555555556,0.4444444444444444,1.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.4444444444444444,0.8888888888888888,0.6666666666666666,1.0,0.8888888888888888,0.8666666666666666,0.0,0.0,1.0,0.8888888888888888,So gravity will change things,"This makes sense because gravity tends to push the surface of an object toward its center. Unless I'm wrong, everything with mass has its own gravity. Every atom, for example, our own body should have its own gravity. The question is: how strong is our own gravity? I know it must be weak, but is there anything that attracts us, such as bacteria or molecules?","
  It makes sense, since gravity tends to push the surface of a body towards it's center


Yes, gravity tends to pull towards the center of mass. I think you're comparing human body to celestial bodies - for instance, stars. Stars collapse within themselves after their lifetime because, their internal (thermal) pressure is not sufficient enough to sustain the gravitational collapse.


  How strong is our own gravitational pull? I know it must be extremely weak, but is there actually anything at all that gets attracted to us, like, maybe, bacteria or molecules?


Yes, it's extremely weak. The constant $G$ is already making the situation very weak. When you mention bacteria or molecule, you are actually reducing the effect further due to their mass. Gravity doesn't depend upon the size. Only MASS matters here. As nitrogen is around us mostly, you can calculate the force between you and a single nitrogen molecule at a distance of an angstrom, which is barely about $F\simeq 10^{-15}\text N$.


  What size would a human body have to reach in order for him to collapse into a sphere?


Wiki has a nice quote on gravitational collapse:


  Because gravity is comparatively weak compared to other fundamental forces, gravitational collapse is usually associated with very massive bodies or collections of bodies, such as stars (including collapsed stars such as supernovae, neutron stars and black holes) and massive collections of stars such as globular clusters and galaxies.


Human body is very small compared to any celestial object (just like the size of an atom in a large city). So, you'd probably need the size of some bigger (massive) celestial object to have a significant effect on the gravitational collapse.
"
313,313,502,How can I typeset the following symbol for beep in multimeter (code)?,"How can I typeset the following symbol for beep in multimeter?
",Miguel,https://tex.stackexchange.com/users/78418,"If you just need some circular waves, you may want to use expanding waves here:

% arara: pdflatex

\documentclass{article}
\usepackage{tikz}
\usetikzlibrary{decorations.pathreplacing}
\tikzset{radiation/.style={decorate,decoration={expanding waves,segment length=3pt},thick}}

\begin{document}
Beep: \tikz[baseline=-.5ex]{\draw[radiation,decoration={angle=30}] (0,0) -- (.5,0);} 
\end{document}



",LaRiFaRi,https://tex.stackexchange.com/users/32245,http://tex.stackexchange.com/questions/245553/how-can-i-typeset-the-following-symbol-for-beep-in-multimeter-code,TECHNOLOGY,tex.stackexchange.com,1.0,0.5555555555555556,0.0,1.0,1.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9,1.0,0.0,0.0,0.8888888888888888,How to type the following beep symbols (codes) into the multimeter?,How do I type the following beep symbols into the multimeter?,"If you just need some circular waves, you may want to use expanding waves here:

% arara: pdflatex

\documentclass{article}
\usepackage{tikz}
\usetikzlibrary{decorations.pathreplacing}
\tikzset{radiation/.style={decorate,decoration={expanding waves,segment length=3pt},thick}}

\begin{document}
Beep: \tikz[baseline=-.5ex]{\draw[radiation,decoration={angle=30}] (0,0) -- (.5,0);} 
\end{document}



"
1094,1094,1724,Law of Multiple Proportions: What is the significance of small whole numbers?,"I'm new to Chemistry and in my textbook, it describes the Law of Definite Proportions and then goes on to describe the Law of Multiple Proportions.

The example they give is carbon monoxide and carbon dioxide, where the mass ratio of oxygen to carbon in carbon dioxide is 2.67:1 and the mass ratio of oxygen to carbon in carbon monoxide is 1.33:1.

I understand the above example, and I understand that when you compare them in the following way:

2.67g (proportion of oxygen to 1g carbon in carbon dioxide)/ 1.33g (proportion of oxygen to 1g carbon in carbon monoxide) = 2.00, a small whole number.

$\frac{Mass~oxygen~to~1g~carbon~in~carbon~dioxide}{Mass~oxygen~to~1g~carbon~in~carbon~monoxide}$ = $\frac{2.67g}{1.33g}$ = 2.00

My textbook doesn't describe what a small whole number is, or what it means... just that, in this example, 2.00 is a small whole number.

What is the significance of the 2.00?

I understand that carbon dioxide has double the oxygen. Is this where the 2.00 plays a role?
",Melanie Shebel,https://chemistry.stackexchange.com/users/402,"There's no universally accepted hard cut-off, as far as I'm aware, which determines the range of numbers that would constitute ""small"" mass ratios. Generally, all textbook examples select compounds that yield single-digit mass ratios. The significance of the ratios being small (as well as their constancy and the limited number of different mass ratios for binary compounds actually found in nature) is that they allow for reliable conclusions to made about the stoichiometric proportions in which elements combine based on crude empirical data alone, as well as leading to conjectures about the number of possible configurations, bond arrangements, and oxidation states yielding said combinations.

The law is valid for a large variety of binary compounds simply by virtue of the fact that there is typically a limited number of permutations in which two given elements can be combined to yield a stable compound. For example, C and O have only two, N and O have only four, metals have a limited number of oxidation states, therefore giving rise to relatively few possibly formulas for binary ionic compounds, etc. The law breaks down for cases in which two elements can combine to form long chains or complex molecules (e.g., large hydrocarbons and [mostly hypothetical] silicon analogues), when the mass ratios can sometimes become quite large.
",Greg E.,https://chemistry.stackexchange.com/users/305,http://chemistry.stackexchange.com/questions/3975/law-of-multiple-proportions-what-is-the-significance-of-small-whole-numbers,SCIENCE,chemistry.stackexchange.com,0.7777777777777778,0.6666666666666666,0.0,1.0,1.0,1.0,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.3333333333333333,1.0,0.8888888888888888,Law of multiple proportions: what is the meaning of small integers?,"I'm new to Chemistry and in my textbook, it describes the Law of Definite Proportions and then goes on to describe the Law of Multiple Proportions.

The example they give is carbon monoxide and carbon dioxide, where the mass ratio of oxygen to carbon in carbon dioxide is 2.67:1 and the mass ratio of oxygen to carbon in carbon monoxide is 1.33:1.

I understand the above example, and I understand that when you compare them in the following way:

2.67g (proportion of oxygen to 1g carbon in carbon dioxide)/ 1.33g (proportion of oxygen to 1g carbon in carbon monoxide) = 2.00, a small whole number.

$\frac{Mass~oxygen~to~1g~carbon~in~carbon~dioxide}{Mass~oxygen~to~1g~carbon~in~carbon~monoxide}$ = $\frac{2.67g}{1.33g}$ = 2.00

My textbook doesn't describe what a small whole number is, or what it means... just that, in this example, 2.00 is a small whole number.

What is the significance of the 2.00?

I understand that carbon dioxide has double the oxygen. Is this where the 2.00 plays a role?
","There's no universally accepted hard cut-off, as far as I'm aware, which determines the range of numbers that would constitute ""small"" mass ratios. Generally, all textbook examples select compounds that yield single-digit mass ratios. The significance of the ratios being small (as well as their constancy and the limited number of different mass ratios for binary compounds actually found in nature) is that they allow for reliable conclusions to made about the stoichiometric proportions in which elements combine based on crude empirical data alone, as well as leading to conjectures about the number of possible configurations, bond arrangements, and oxidation states yielding said combinations.

The law is valid for a large variety of binary compounds simply by virtue of the fact that there is typically a limited number of permutations in which two given elements can be combined to yield a stable compound. For example, C and O have only two, N and O have only four, metals have a limited number of oxidation states, therefore giving rise to relatively few possibly formulas for binary ionic compounds, etc. The law breaks down for cases in which two elements can combine to form long chains or complex molecules (e.g., large hydrocarbons and [mostly hypothetical] silicon analogues), when the mass ratios can sometimes become quite large.
"
3219,3219,5136,Nikon D3100 Won't Take Photo -- says light is too low,"I've had my Nikon D3100 camera for about 3 years.  I recently accidentally reset my shooting options.

Since I've done that, I'm having a hard time getting the camera to focus and take photos in lower light.  I can hear it (and see it) hunting to focus, but the bottom right flashes the image suggesting I use the flash and it won't let me take a picture.

I've ensured that it's set to AF-C, but I'm still not able to force the photo to be taken.  This happens with multiple lenses, including my prime which is fairly decent in low light.  Often the exposure information on the screen shows me that I am close to perfect exposure (and sometimes just a bit underexposed).

What's going on?  Is there something wrong with the camera?  What other settings can I check?

Some other tidbits, I have it set to Manual, and I'm able to take the photos if I manually focus--but that doesn't work for me since my eyesight isn't great.
",Ashley,https://photo.stackexchange.com/users/25458,"What I try to do in these cases is to shoot in Manual and with manual focus using Live-view to assist. Of course you can always use the flash, that should help.

Have you got the AF light turned on? In alternative, you can use a torchlight or a smartphone flashlight to lit the scene and autofocus before taking the shot.
",clabacchio,https://photo.stackexchange.com/users/7984,http://photo.stackexchange.com/questions/46979/nikon-d3100-wont-take-photo-says-light-is-too-low,LIFE_ARTS,photo.stackexchange.com,0.8888888888888888,0.7777777777777778,0.0,0.3333333333333333,1.0,0.3333333333333333,0.5555555555555556,0.5555555555555556,0.6666666666666666,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,1.0,0.0,1.0,0.7777777777777778,0.5,1.0,1.0,0.8,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.7777777777777778,Nikon D3100 doesn't take pictures - it says the light is too low,"I've had my Nikon D3100 camera for about 3 years.  I recently accidentally reset my shooting options.

Since I've done that, I'm having a hard time getting the camera to focus and take photos in lower light.  I can hear it (and see it) hunting to focus, but the bottom right flashes the image suggesting I use the flash and it won't let me take a picture.

I've ensured that it's set to AF-C, but I'm still not able to force the photo to be taken.  This happens with multiple lenses, including my prime which is fairly decent in low light.  Often the exposure information on the screen shows me that I am close to perfect exposure (and sometimes just a bit underexposed).

What's going on?  Is there something wrong with the camera?  What other settings can I check?

Some other tidbits, I have it set to Manual, and I'm able to take the photos if I manually focus--but that doesn't work for me since my eyesight isn't great.
","What I try to do in these cases is to shoot in Manual and with manual focus using Live-view to assist. Of course you can always use the flash, that should help.

Have you got the AF light turned on? In alternative, you can use a torchlight or a smartphone flashlight to lit the scene and autofocus before taking the shot.
"
425,425,659,Around the Clock,"I want to produce with Mathematica something like this



Or this



12 hours should be arranged in a pleasing (""rotated"") style around / within a rectangle. I don't ask for the hands - depending on numerical input - but only for a Graphics to begin with.


""Have you tried anything ?""
""Sure, but with non-presentable results.""

",eldo,https://mathematica.stackexchange.com/users/14254,"For a constant angular speed watch, if you want some specific figures being placed at the corners, you have to adjust the aspect ratio of the dial rectangle.

A Graphics to begin with:

Manipulate[
    {
                    Dashed, GrayLevel[.7], 
                    InfiniteLine[{0, 0}, Through[{Cos, Sin}[π/6 #]]],
                    Dashing[{}], Black, Thick, 
                    InfiniteLine[{0, 0}, Through[{Cos, Sin}[π/12 + π/6 #]]]
                    } &amp; /@ Range[0, 5] //
        Graphics[{#,
                    EdgeForm[{Black, Thick}], FaceForm[White],
                    Rectangle[##] &amp; @@ (1/
                                2 {{-1, 1}, (Tan[π/6] + ε) {-1, 
                                                1}})
                    },
                PlotRange -&gt; {{-1, 1}, (Tan[π/6] + ε) {-1, 1}},
                Frame -&gt; True, FrameStyle -&gt; Thick, FrameTicks -&gt; None] &amp;,
    {{ε, 0}, -0.5, 10}]




With a proper grid, you can then use the transformation method from other answers to fill in good-looking figures.
",Silvia,https://mathematica.stackexchange.com/users/17,http://mathematica.stackexchange.com/questions/60728/around-the-clock,TECHNOLOGY,mathematica.stackexchange.com,0.6666666666666666,0.3333333333333333,0.0,0.0,1.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,0.8333333333333334,0.9,0.0,1.0,0.0,1.0,All-weather,"I want to produce with Mathematica something like this



Or this



12 hours should be arranged in a pleasing (""rotated"") style around / within a rectangle. I don't ask for the hands - depending on numerical input - but only for a Graphics to begin with.


""Have you tried anything ?""
""Sure, but with non-presentable results.""

","For a constant angular speed watch, if you want some specific figures being placed at the corners, you have to adjust the aspect ratio of the dial rectangle.

A Graphics to begin with:

Manipulate[
    {
                    Dashed, GrayLevel[.7], 
                    InfiniteLine[{0, 0}, Through[{Cos, Sin}[π/6 #]]],
                    Dashing[{}], Black, Thick, 
                    InfiniteLine[{0, 0}, Through[{Cos, Sin}[π/12 + π/6 #]]]
                    } &amp; /@ Range[0, 5] //
        Graphics[{#,
                    EdgeForm[{Black, Thick}], FaceForm[White],
                    Rectangle[##] &amp; @@ (1/
                                2 {{-1, 1}, (Tan[π/6] + ε) {-1, 
                                                1}})
                    },
                PlotRange -&gt; {{-1, 1}, (Tan[π/6] + ε) {-1, 1}},
                Frame -&gt; True, FrameStyle -&gt; Thick, FrameTicks -&gt; None] &amp;,
    {{ε, 0}, -0.5, 10}]




With a proper grid, you can then use the transformation method from other answers to fill in good-looking figures.
"
2992,2992,4770,Quantity based discount for single product in Expresso Store,"I'm using latest build of Expresso Store, 2.3.1. I need to apply quantity based discounts to products, but the discount needs to apply to a single product. For example:

I have 10% off discount for all products in store when you order 10 or more of a single product, but the discount only applies to the particular product. So I order 11 of Product 1, 10 of Product 2 and 5 of Product 3. Products 1 and 2 will get the discount, product 3 will be full price.

As far as I can see this is not possible in Store. If so are there any ways I can handle this in the template? As our discount will likely be pretty simple, with the same discount being applied store wide.

Failing that, what are our options for extending Store to achieve this?

Update: Just to clarify, we are looking to apply this discount at a category or store wide level, rather than updating the pricing of an individual product, as there are thousands of products this would not be viable, in particular as we will likely just have one percentage discount that is the same for all products.
",neekster,https://expressionengine.stackexchange.com/users/587,"Use this bulk discounts add-on, does exactly what you need. Create a new field type and discounts are controlled per product and at definable quantities.

Does need Matrix installed though.
",Peter Lewis,https://expressionengine.stackexchange.com/users/425,http://expressionengine.stackexchange.com/questions/24812/quantity-based-discount-for-single-product-in-expresso-store,TECHNOLOGY,expressionengine.stackexchange.com,0.8888888888888888,0.4444444444444444,0.0,1.0,1.0,1.0,0.7777777777777778,0.4444444444444444,0.6666666666666666,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,0.8888888888888888,Express store quantity discount,"I'm using latest build of Expresso Store, 2.3.1. I need to apply quantity based discounts to products, but the discount needs to apply to a single product. For example:

I have 10% off discount for all products in store when you order 10 or more of a single product, but the discount only applies to the particular product. So I order 11 of Product 1, 10 of Product 2 and 5 of Product 3. Products 1 and 2 will get the discount, product 3 will be full price.

As far as I can see this is not possible in Store. If so are there any ways I can handle this in the template? As our discount will likely be pretty simple, with the same discount being applied store wide.

Failing that, what are our options for extending Store to achieve this?

Update: Just to clarify, we are looking to apply this discount at a category or store wide level, rather than updating the pricing of an individual product, as there are thousands of products this would not be viable, in particular as we will likely just have one percentage discount that is the same for all products.
","Use this bulk discounts add-on, does exactly what you need. Create a new field type and discounts are controlled per product and at definable quantities.

Does need Matrix installed though.
"
1171,1171,1841,Images give 404 after changing default domain,"Never encountered this issue before. So I've just moved a site for a client to another server and for some reason all images give me a 404 when I change the default domain in the database (siteurl and home). CSS, JS and other files are linked correctly - it seems there's something affecting the uploads folder but I can't pinpoint what it is. Any ideas?
",Staffan Estberg,https://wordpress.stackexchange.com/users/67844,"Of course you can do as per some other people gave you to go through the Database and fix it. But it can also break it if not done properly.

Before going into Database mode, I would suggest one thing that happened to me.

First make sure that you go in the settings of WordPress and make sure that the URLs are good... EVEN if they are good SAVE SETTINGS once more to make sure the settings is reflected everywhere.

By using plugins to move sites around those settings don't seems to reflect everywhere even if this information here is good.

Also I would suggest to go through most of your Settings (For example Permalinks) and Plugin Settings (For Example Polylang I had a problem with it since there is PATH information in it) and see if there is any relations with ""PATH"" if there is make sure they have the good information and SAVE THEM AGAIN even if they have the proper information.

Sometime to make sure the change takes effect... I put a wrong information save and add the proper information again and save again... The reason why I do that, I know some programmers that do no ""save"" the information if it was the same before and after editing this way your are sure the information is transferred properly.
",pSyToR,https://wordpress.stackexchange.com/users/66412,http://wordpress.stackexchange.com/questions/178742/images-give-404-after-changing-default-domain,TECHNOLOGY,wordpress.stackexchange.com,1.0,0.7777777777777778,0.0,0.3333333333333333,1.0,0.6666666666666666,0.6666666666666666,0.4444444444444444,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,1.0,0.0,0.8888888888888888,0.7777777777777778,0.6666666666666666,0.8888888888888888,0.8888888888888888,0.8,0.3333333333333333,0.6666666666666666,1.0,0.7777777777777778,Image display 404 after changing the default domain,"This problem has never been encountered before. So I just moved one client's site to another server, and for some reason, when I changed the default domain (siteurl and home) in the database, all the images would show 404. CSS, JS, and other files are linked correctly - something seems to affect the uploads folder, but I'm not sure what it is. Do you have any ideas?","Of course you can do as per some other people gave you to go through the Database and fix it. But it can also break it if not done properly.

Before going into Database mode, I would suggest one thing that happened to me.

First make sure that you go in the settings of WordPress and make sure that the URLs are good... EVEN if they are good SAVE SETTINGS once more to make sure the settings is reflected everywhere.

By using plugins to move sites around those settings don't seems to reflect everywhere even if this information here is good.

Also I would suggest to go through most of your Settings (For example Permalinks) and Plugin Settings (For Example Polylang I had a problem with it since there is PATH information in it) and see if there is any relations with ""PATH"" if there is make sure they have the good information and SAVE THEM AGAIN even if they have the proper information.

Sometime to make sure the change takes effect... I put a wrong information save and add the proper information again and save again... The reason why I do that, I know some programmers that do no ""save"" the information if it was the same before and after editing this way your are sure the information is transferred properly.
"
1556,1556,2441,Can IEnumerable be an alternative to Params[]?,"Can IEnumerable be a possible alternative to params[]?

Because Ive been hearing some articles that params is not good, but I seem to doubt it because it is syntactically straightforward and is very useful.

ex.

public void testMeth(IEnumerable&lt;object&gt; testerEnum){
    //Code here
}

",Reyn,https://stackoverflow.com/users/5068255,"Using the params keyword importantly allows callers of your method not to wrap the arguments into a collection at all.

With:

public bool testMeth(params object[] input){
    // ... things
    return purity &gt;= REQUIRED_PURITY; //this is how to test meth, right?
}


The caller can call  

var is_good = testMeth(""apples"", new object(), 7);


with no need to make their own array.
",moreON,https://stackoverflow.com/users/4809143,http://stackoverflow.com/questions/31306688/can-ienumerable-be-an-alternative-to-params,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.8888888888888888,0.3333333333333333,1.0,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,0.3333333333333333,1.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.0,1.0,0.8888888888888888,IEnumerable can replace params []?,"Can IEnumerable be a possible alternative to params[]?

Because Ive been hearing some articles that params is not good, but I seem to doubt it because it is syntactically straightforward and is very useful.

ex.

public void testMeth(IEnumerable&lt;object&gt; testerEnum){
    //Code here
}

","Using the params keyword importantly allows callers of your method not to wrap the arguments into a collection at all.

With:

public bool testMeth(params object[] input){
    // ... things
    return purity &gt;= REQUIRED_PURITY; //this is how to test meth, right?
}


The caller can call  

var is_good = testMeth(""apples"", new object(), 7);


with no need to make their own array.
"
918,918,1455,Add targeting when posting to a page using Facebook API,"I'm trying to post to a page on facebook using the facebook API. But I want to customize the post target. 

When I post to a page on facebook I get these results  :



You get Shared with : (languages...) and News feed targeting : (languages...)

But when I post to a page on my custom website using the facebook api I get these results : 



I only get the News feed targeting and not the shared with...

Does anybody knows what to use to get the Shared with options using the facebook API?

To get the News feed targeting I'm using :

var feed_targeting = {
      'locales': [""1001"", ""1"", ""2"", ""4"", ""9""],
};


But I want to know what to use for the Shared with option....

Thanks 
",Robbert Wolfs,https://stackoverflow.com/users/1763223,"Have a look at https://developers.facebook.com/docs/graph-api/reference/v2.1/page/feed/#pubfields – there’s feed_targeting and targeting, those are two different things.


  targeting: Object that limits the audience for this content. Anyone not in these demographics will not be able to view this content.

",CBroe,https://stackoverflow.com/users/1427878,http://stackoverflow.com/questions/24801130/add-targeting-when-posting-to-a-page-using-facebook-api,STACKOVERFLOW,stackoverflow.com,1.0,0.3333333333333333,0.0,0.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.8333333333333334,0.8333333333333334,0.3333333333333333,0.8333333333333334,0.6666666666666666,0.6,0.0,1.0,0.0,0.8333333333333334,Add target when publishing to page using Facebook API,"I'm trying to post to a page on facebook using the facebook API. But I want to customize the post target. 

When I post to a page on facebook I get these results  :



You get Shared with : (languages...) and News feed targeting : (languages...)

But when I post to a page on my custom website using the facebook api I get these results : 



I only get the News feed targeting and not the shared with...

Does anybody knows what to use to get the Shared with options using the facebook API?

To get the News feed targeting I'm using :

var feed_targeting = {
      'locales': [""1001"", ""1"", ""2"", ""4"", ""9""],
};


But I want to know what to use for the Shared with option....

Thanks 
","Have a look at https://developers.facebook.com/docs/graph-api/reference/v2.1/page/feed/#pubfields – there’s feed_targeting and targeting, those are two different things.


  targeting: Object that limits the audience for this content. Anyone not in these demographics will not be able to view this content.

"
3202,3202,5103,Multiple orders in a single list,"I have a problem with a ranking system I am using.

Scenario:

An online game with around 10k players calculates a real time ranking of points when a certain event occurs. Events don't occur that often, around 1 time per minute. This ranking is kept in the cache for quick calculations, sorting and access.

Now players can form groups and play against each other, but the scoring system is the same, only the ranking is based for the players in that group.

At first I created for every group a separate ranking, effectively having the same scores as the complete ranking, but with different positions in the ranking.

This is trivial because there are over 1.000 groups and every time an event occurs all the groups would have to be updated.

So what I did now is when the group ranking is requested take only the players that are in that group from the complete ranking and show them. The positions would have to be re-counted.

That re-counting is where the problem is. Because the sub-list is by-reference from the complete ranking list I cannot change the position of the player in the sub-ranking without updating it in the complete ranking, because it's just a reference.

I came up with two solutions:


Create a copy from the record every time it is requested and do some output caching (not very desirable because the rankings are live)
Create a copy and store this in a cache which is reset when an event occurs.
Create a sub-list with just the positions which is updated when an event occurs.


And the last solution: do the position counting in the output instead in the business side. This would be the best solution, only problem is that on some pages this text appears: ""You are on position # in the ranking"" where # is your ranking position. This number would be tedious to get then.

Does anybody have any suggestions to this problem?
",YesMan85,https://programmers.stackexchange.com/users/24248,"There may be minor performance considerations involved with it, but this sounds like the sort of thing LINQ is very useful for. The basic idea is this:

var enormousList = new List&lt;record&gt;();

//var enormousList = ... (over 5 million records)
var subList = enormousList.Where(onerecord =&gt; onerecord.clanName == ""RAGIN CAJUN"");

// At this point in the program, NO filtration has occurred just yet and little processing
// power has been used.

// This enumerates the list once for the ""ragin cajun"" filter, so this may take a while.
var sublistCount = subList.Count(); //take note that Count is a function here, not a property. 
var pageSize = 50;
var hudDisplayPage = enormousList.Take(pageSize).Select((record, idx) =&gt;
{
    return new HudPage(idx, record.clanName, record.playerName);
});
// for those who couldn't keep track; hudDisplayPage is now an IEnumerable (which you can use for-each on) containing
// 50 records of the list fitting the description. These are dynamic constructs; even now, hudDisplayPage hasn't
// yet been evaluated. If you want to cache one of these values so you're not doing the processing again later...
var saved = hudDisplayPage.ToArray();


This sort of system should make it relatively easy to take slices out of your data, and precache whichever ones are likely to be needed many times.
Also, take note of this handy tip (but ONLY for queries that end up being a performance hit)

var saved = hudDisplayPage.AsParallel().ToArray();


That line should essentially multithread your filtration process, so that all cores of your processor are on it.

I can't say I know enough about your problem to write out its solution in code; but it seems like your issue is mainly in figuring out the list processing, against a single list you don't want to modify or copy. Hope I haven't misunderstood your issue!
",Katana314,https://programmers.stackexchange.com/users/90889,http://programmers.stackexchange.com/questions/198803/multiple-orders-in-a-single-list,TECHNOLOGY,programmers.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,0.5,0.6666666666666666,0.5,0.6666666666666666,0.5,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,0.7777777777777778,0.8333333333333334,0.7,0.6666666666666666,0.0,0.6666666666666666,1.0,Multiple orders in a list,"I have a problem with a ranking system I am using.

Scenario:

An online game with around 10k players calculates a real time ranking of points when a certain event occurs. Events don't occur that often, around 1 time per minute. This ranking is kept in the cache for quick calculations, sorting and access.

Now players can form groups and play against each other, but the scoring system is the same, only the ranking is based for the players in that group.

At first I created for every group a separate ranking, effectively having the same scores as the complete ranking, but with different positions in the ranking.

This is trivial because there are over 1.000 groups and every time an event occurs all the groups would have to be updated.

So what I did now is when the group ranking is requested take only the players that are in that group from the complete ranking and show them. The positions would have to be re-counted.

That re-counting is where the problem is. Because the sub-list is by-reference from the complete ranking list I cannot change the position of the player in the sub-ranking without updating it in the complete ranking, because it's just a reference.

I came up with two solutions:


Create a copy from the record every time it is requested and do some output caching (not very desirable because the rankings are live)
Create a copy and store this in a cache which is reset when an event occurs.
Create a sub-list with just the positions which is updated when an event occurs.


And the last solution: do the position counting in the output instead in the business side. This would be the best solution, only problem is that on some pages this text appears: ""You are on position # in the ranking"" where # is your ranking position. This number would be tedious to get then.

Does anybody have any suggestions to this problem?
","There may be minor performance considerations involved with it, but this sounds like the sort of thing LINQ is very useful for. The basic idea is this:

var enormousList = new List&lt;record&gt;();

//var enormousList = ... (over 5 million records)
var subList = enormousList.Where(onerecord =&gt; onerecord.clanName == ""RAGIN CAJUN"");

// At this point in the program, NO filtration has occurred just yet and little processing
// power has been used.

// This enumerates the list once for the ""ragin cajun"" filter, so this may take a while.
var sublistCount = subList.Count(); //take note that Count is a function here, not a property. 
var pageSize = 50;
var hudDisplayPage = enormousList.Take(pageSize).Select((record, idx) =&gt;
{
    return new HudPage(idx, record.clanName, record.playerName);
});
// for those who couldn't keep track; hudDisplayPage is now an IEnumerable (which you can use for-each on) containing
// 50 records of the list fitting the description. These are dynamic constructs; even now, hudDisplayPage hasn't
// yet been evaluated. If you want to cache one of these values so you're not doing the processing again later...
var saved = hudDisplayPage.ToArray();


This sort of system should make it relatively easy to take slices out of your data, and precache whichever ones are likely to be needed many times.
Also, take note of this handy tip (but ONLY for queries that end up being a performance hit)

var saved = hudDisplayPage.AsParallel().ToArray();


That line should essentially multithread your filtration process, so that all cores of your processor are on it.

I can't say I know enough about your problem to write out its solution in code; but it seems like your issue is mainly in figuring out the list processing, against a single list you don't want to modify or copy. Hope I haven't misunderstood your issue!
"
5612,5612,8904,Why use a small aperture when trying to see sensor dust?,"Here and there I read of people who set their lens to a small aperture while testing their sensor cleanness, supposedly to get the best image of dust speckles. However, the image of the on-sensor dust particles should not, to my understanding, be affected by the sharpness induced by the lens settings. Same is true for dust particle on the lens elements themselves. It makes me wonder - do these people misunderstand the theory of how the optical system work, or am I missing something?
",ysap,https://photo.stackexchange.com/users/1024,"If I understand your question correctly, stopping the aperture down to its narrowest ensures that light is focused as tightly as possible. If you take a photograph at a wider aperture, excess non-incident light will still make it to the sensor, and mitigate the effects of sensor dust.

To put that in more precise technical terms...with a narrow aperture, the light that strikes the sensor is from as narrow a field as possible, and as close to perpendicular as possible (90° to sensor plane). That causes dust particles to create a ""sharp shadow"" on the sensor. At a wider aperture, the light that strikes the sensor is from a wide field of view, and light may not always be perpendicular (could be anywhere from 90° to say 70°), since the entire lens surface plays a role in focusing light. Those off-axis rays of light cause dust particles to create a ""soft shadow"" on the sensor.



You could demonstrate the effect at a macro scale, if you need a visual exemplar. Hold your hand up a foot or two from your wall, and point a bright but narrow beam of light at it...say from a flashlight about 10 feet away. The shadow from your hand should be clear and sharp. Perform the same experiment again, however this time, set up several shaded lamps that emit light in a broad field in a line parallel to the wall about 10 feet away. The shadow from your hand should be soft and dim, if visible at all (except under closer scrutiny.) Narrowing your aperture is akin to using the flashlight, while widening it is akin to setting up a wider row of lights.
",jrista,https://photo.stackexchange.com/users/124,http://photo.stackexchange.com/questions/12087/why-use-a-small-aperture-when-trying-to-see-sensor-dust,LIFE_ARTS,photo.stackexchange.com,1.0,0.7777777777777778,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.0,1.0,0.8888888888888888,Why use small apertures when trying to see sensor dust?,"I read from time to time that some people adjust their lens to a small aperture when testing the cleanliness of the sensor, which is said to get the best image of dust spots. However, as far as I know, the image of dust particles on the sensor should not be affected by the sharpness caused by the lens setting. The same is true of the dust particles on the lens element itself. It makes me wonder - have these people misunderstood how the optical system works, or have I missed something?","If I understand your question correctly, stopping the aperture down to its narrowest ensures that light is focused as tightly as possible. If you take a photograph at a wider aperture, excess non-incident light will still make it to the sensor, and mitigate the effects of sensor dust.

To put that in more precise technical terms...with a narrow aperture, the light that strikes the sensor is from as narrow a field as possible, and as close to perpendicular as possible (90° to sensor plane). That causes dust particles to create a ""sharp shadow"" on the sensor. At a wider aperture, the light that strikes the sensor is from a wide field of view, and light may not always be perpendicular (could be anywhere from 90° to say 70°), since the entire lens surface plays a role in focusing light. Those off-axis rays of light cause dust particles to create a ""soft shadow"" on the sensor.



You could demonstrate the effect at a macro scale, if you need a visual exemplar. Hold your hand up a foot or two from your wall, and point a bright but narrow beam of light at it...say from a flashlight about 10 feet away. The shadow from your hand should be clear and sharp. Perform the same experiment again, however this time, set up several shaded lamps that emit light in a broad field in a line parallel to the wall about 10 feet away. The shadow from your hand should be soft and dim, if visible at all (except under closer scrutiny.) Narrowing your aperture is akin to using the flashlight, while widening it is akin to setting up a wider row of lights.
"
1996,1996,3189,Is there a limit to how fast one can harvest minerals and gas?,"
  Possible Duplicate:
  What&#39;s the correct number of workers to put on gathering vespene and minerals in StarCraft 2?  




Is there a point where any additional workers won't speed up the harvesting process of minerals or gas from a certain mineral field or refinery?
",Speldosa,https://gaming.stackexchange.com/users/13642,"Your third worker will gather at a reduced rate. Your fourth worker will not produce additional income.

Please note that MULEs can gather over workers, but not over other MULEs.

This results in a limit of 16 workers at full rate, an additional 8 workers at a reduced rate totaling in 24 workers per 8 mineral patches. Please note that this is a full page at the bottom of the screem, as each row is 8 units long. It is however advised that if you have less than 16 workers at an expansion that you transfer those of an expansion with more than 16 workers.

As for MULEs, you can have up to 8 MULEs per 8 mineral patches. The fastest income of a single base you can get is by 24 workers and 8 MULEs on a gold expansion.

For gas, it depends on the distance to the gas geyser. In some cases, full saturation is reached on your third worker, in other cases (diagonal placement) the full saturation is reached with a fourth worker. However, the difference between the third and fourth worker is minimal and probably only matters when you are at a high grand master level. And even then, there are probably other more important things to focus on. You don't need a graph for this, when you see a worker waiting outside the gas geyser for long enough you simply have reached saturation...

Here is a graph for gathering minerals with workers:


(Click to enlarge)

&mdash; Source: TeamLiquid Wiki - Mining Minerals
",Tom Wijsman,https://gaming.stackexchange.com/users/998,http://gaming.stackexchange.com/questions/35380/is-there-a-limit-to-how-fast-one-can-harvest-minerals-and-gas,CULTURE,gaming.stackexchange.com,0.8888888888888888,0.6666666666666666,0.3333333333333333,1.0,1.0,1.0,0.6666666666666666,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,1.0,1.0,1.0,0.8888888888888888,1.0,1.0,0.0,0.3333333333333333,1.0,1.0,Is there a limit to the rate of exploitation of minerals and natural gas?,"
  Possible Duplicate:
  What&#39;s the correct number of workers to put on gathering vespene and minerals in StarCraft 2?  




Is there a point where any additional workers won't speed up the harvesting process of minerals or gas from a certain mineral field or refinery?
","Your third worker will gather at a reduced rate. Your fourth worker will not produce additional income.

Please note that MULEs can gather over workers, but not over other MULEs.

This results in a limit of 16 workers at full rate, an additional 8 workers at a reduced rate totaling in 24 workers per 8 mineral patches. Please note that this is a full page at the bottom of the screem, as each row is 8 units long. It is however advised that if you have less than 16 workers at an expansion that you transfer those of an expansion with more than 16 workers.

As for MULEs, you can have up to 8 MULEs per 8 mineral patches. The fastest income of a single base you can get is by 24 workers and 8 MULEs on a gold expansion.

For gas, it depends on the distance to the gas geyser. In some cases, full saturation is reached on your third worker, in other cases (diagonal placement) the full saturation is reached with a fourth worker. However, the difference between the third and fourth worker is minimal and probably only matters when you are at a high grand master level. And even then, there are probably other more important things to focus on. You don't need a graph for this, when you see a worker waiting outside the gas geyser for long enough you simply have reached saturation...

Here is a graph for gathering minerals with workers:


(Click to enlarge)

&mdash; Source: TeamLiquid Wiki - Mining Minerals
"
5789,5789,9173,"Can one meet criteria, or satisfy requirements?","I usually see 'satisfy the criteria' and 'meet the requirements', but is it acceptable to use 'meet the criteria', or 'satisfy the requirements'?
",Superstringcheese,https://english.stackexchange.com/users/8909,"The Oxford Collocations Dictionary says the following:

VERB+criterion: fit, fulfill, meet, satisfy. The Macmillan Collocations Dictionary gives one more verb, ""match"".

VERB+requirement: comply with, fit, fulfill, match, meet, satisfy, suit. The Macmillan Collocations Dictionary gives three more verbs, ""achieve"", ""adhere to"", ""conform to"".
",Alex B.,https://english.stackexchange.com/users/19046,http://english.stackexchange.com/questions/67349/can-one-meet-criteria-or-satisfy-requirements,CULTURE,english.stackexchange.com,0.7777777777777778,0.7777777777777778,0.0,1.0,0.6666666666666666,0.5,0.6666666666666666,0.6666666666666666,0.0,0.0,0.3333333333333333,1.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.7333333333333333,0.3333333333333333,0.0,0.0,0.7777777777777778,Can one meet the standard or the requirement?,"I usually see ""meet standards"" and ""meet requirements"", but is it acceptable to use ""meet standards"" or ""meet requirements""?","The Oxford Collocations Dictionary says the following:

VERB+criterion: fit, fulfill, meet, satisfy. The Macmillan Collocations Dictionary gives one more verb, ""match"".

VERB+requirement: comply with, fit, fulfill, match, meet, satisfy, suit. The Macmillan Collocations Dictionary gives three more verbs, ""achieve"", ""adhere to"", ""conform to"".
"
1186,1186,1862,Move Box2d object on touch of button?,"I have a player box2d object on screen, who should be controlled by two buttons, one left, and one right. When you press the right button, the player should move right, but when you press the left button, the player should immediatly stop moving right and move left. This should also happen vice versa.
I tried to do this to move right,
 b2Vec2 impulse(4, 0);
 body->ApplyLinearImpulse(impulse, body->GetWorldCenter());

and this to move left
b2Vec2 impulse(4, 0);
 body->ApplyLinearImpulse(impulse, body->GetWorldCenter());

This works, but when I press right and then left, the player doesn't immediatly go left, but continues right for a while, and then goes left. How do I make sure this doesn't happen?
",maor10,https://stackoverflow.com/users/1005978,"set the body's linearVelocity to b2Vec2_zero before applying the new force – LearnCocos2D yesterday
",maor10,https://stackoverflow.com/users/1005978,http://stackoverflow.com/questions/12662291,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.4444444444444444,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,0.8888888888888888,Press the button once to move the box2d object?,"I have a player box2d object on screen, who should be controlled by two buttons, one left, and one right. When you press the right button, the player should move right, but when you press the left button, the player should immediatly stop moving right and move left. This should also happen vice versa.
I tried to do this to move right,
 b2Vec2 impulse(4, 0);
 body->ApplyLinearImpulse(impulse, body->GetWorldCenter());

and this to move left
b2Vec2 impulse(4, 0);
 body->ApplyLinearImpulse(impulse, body->GetWorldCenter());

This works, but when I press right and then left, the player doesn't immediatly go left, but continues right for a while, and then goes left. How do I make sure this doesn't happen?
","set the body's linearVelocity to b2Vec2_zero before applying the new force – LearnCocos2D yesterday
"
3156,3156,5027,Better dropdown fieldtype to handle long lists?,"Does anyone know of a better fieldtype to handle long lists in a dropdown than the default dropdown list fieldtype?

I need to 


work within Grid
field must be searchable in front end (via ee or low search)
be able to add items within the list at times
handle thousands of items in the list (maybe 5,000 - 20,000)
hopefully offer an improved way of choosing the item


(I considered using a second channel and a Relationship in the Grid, but the problem is searching isn't a possibility for Relationships in a Grid. That would be ideal in that I can change/add to the items in the second channel, but the search issue is a deal breaker.)
",Romans-8---31-39,https://expressionengine.stackexchange.com/users/1326,"You can use the low_search_update_index hook in Low Search to index relationship fields inside Grid fields - I've done this before.

There's a ready-made extension available which does this for standalone relationship fields ... it doesn't do Grid fields, but it would be easy to modify the query inside the extension to do so.

So, stick with the relationship inside the Grid, since it meets all your other requirements, and the search bit is solvable.
",Derek Hogue,https://expressionengine.stackexchange.com/users/55,http://expressionengine.stackexchange.com/questions/21124/better-dropdown-fieldtype-to-handle-long-lists,TECHNOLOGY,expressionengine.stackexchange.com,1.0,0.6666666666666666,0.0,0.6666666666666666,1.0,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.6666666666666666,1.0,0.3333333333333333,0.3333333333333333,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.3333333333333333,0.3333333333333333,1.0,Better drop-down field types to handle long lists?,"Does anyone know of a better fieldtype to handle long lists in a dropdown than the default dropdown list fieldtype?

I need to 


work within Grid
field must be searchable in front end (via ee or low search)
be able to add items within the list at times
handle thousands of items in the list (maybe 5,000 - 20,000)
hopefully offer an improved way of choosing the item


(I considered using a second channel and a Relationship in the Grid, but the problem is searching isn't a possibility for Relationships in a Grid. That would be ideal in that I can change/add to the items in the second channel, but the search issue is a deal breaker.)
","You can use the low_search_update_index hook in Low Search to index relationship fields inside Grid fields - I've done this before.

There's a ready-made extension available which does this for standalone relationship fields ... it doesn't do Grid fields, but it would be easy to modify the query inside the extension to do so.

So, stick with the relationship inside the Grid, since it meets all your other requirements, and the search bit is solvable.
"
617,617,967,Using PHP to dynamically create pages from a template,"I'm creating a blog for a website I am building. The main blog page obviously has each blog listed as it should. But I want each blog to also have it's own individual page on the website. I want this page to be generated on creation of the blog post.

My question is, what would be the best method of creating this page. If I use the php file functions to create it, I would need to fill up a $data variable with hundreds of lines of HTML for the page. Which I guess is feasible, IF I am also able to dynamically change the variable to work for the new content that needs to be posted on said page.

Is there better methods? Would PHP work for this? Any suggestions would help.
",Josh,https://stackoverflow.com/users/2476769,"Its possible to create individual page for each blog dynamically. Here are the steps you can follow.


Create one master template. Add some special tags where you want dynamic content.
While adding new post, Read the content from that master template, replace appropriate special tags with actual values
Write finally generated content into new file and save it to associated location.
You are ready to access that page.

",Hitesh,https://stackoverflow.com/users/606518,http://stackoverflow.com/questions/17463350/using-php-to-dynamically-create-pages-from-a-template,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.4444444444444444,0.0,0.5,1.0,1.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.0,0.8888888888888888,1.0,0.5555555555555556,0.8888888888888888,1.0,0.8,0.6666666666666666,0.3333333333333333,0.0,0.8888888888888888,Using PHP to dynamically create pages from templates,"I'm creating a blog for a website I am building. The main blog page obviously has each blog listed as it should. But I want each blog to also have it's own individual page on the website. I want this page to be generated on creation of the blog post.

My question is, what would be the best method of creating this page. If I use the php file functions to create it, I would need to fill up a $data variable with hundreds of lines of HTML for the page. Which I guess is feasible, IF I am also able to dynamically change the variable to work for the new content that needs to be posted on said page.

Is there better methods? Would PHP work for this? Any suggestions would help.
","Its possible to create individual page for each blog dynamically. Here are the steps you can follow.


Create one master template. Add some special tags where you want dynamic content.
While adding new post, Read the content from that master template, replace appropriate special tags with actual values
Write finally generated content into new file and save it to associated location.
You are ready to access that page.

"
149,149,236,Why did Voldemort assume that no-one knew about Room of Hidden Things?,"Voldemort hid one of his Horcruxes inside Hogwarts. It seemed to be relying on security through obscurity as far as protecting it. But as we know, it ended up not being so secure because it wasn't so obscure - Harry Potter knew about the Room of Hidden Things.

My question is, the way Rowling describes this hints at the fact that Riddle had an assumption that very few people would ever stumble upon that room. *WHY???



First, let's show Harry's theory on what Voldemort was thinking, how and why:

Here's Harry understanding Voldemort's thinking in HP7 once he figured out where the Diadem was (bold emphasis mine):


  Tom Riddle, who confided in no one and operated alone, might have been arrogant
  enough to assume that he, and only he, had penetrated the deepest mysteries of
  Hogwarts Castle. Of course, Dumbledore and Flitwick, those model pupils, had never
  set foot in that particular place, but he, Harry, had strayed off the beaten track in his
  time at school – here at least was a secret area he and Voldemort knew, that
  Dumbledore had never discovered –


...and later on, with Harry explains the location to Ron/Hermione:


  “He hid it exactly where I had my old Potions book, where everyone’s been hiding stuff for centuries. He thought he was the only one to find it. Come on.”
  
  “And he never realized anyone could get in?” said Ron, his voice echoing in the silence.
  “He thought he was the only one,” said Harry.


.



Yet, from available evidence, that seems to be a completely wrong assumption, even at Voldemort's time. 

Let's examine that last quote again, with emphasis on other info available:


  “He hid it exactly where I had my old Potions book, where everyone’s been hiding stuff for centuries.” ...
  
  ...
  
  “And he never realized anyone could get in?” said Ron, his voice echoing in the silence.
  “He thought he was the only one,” said Harry. “Too bad for him I’ve had to hide stuff in
  my time... this way,” he added. “I think it’s down here... “ 
  
  They sped off up adjacent aisles; Harry could hear the others’ footsteps echoing through the towering piles of junk, of bottles, hats, crates, chairs, books, weapons, broomsticks, bats...


.

OK, so if there's a truckload (or train-load, by the description) of stuff in that room, isn't the only reasonable conclusion: ""the room is a fairly popular destination with plenty of people who've found their way there in the past, and therefore, likely, plenty who will in the future""? 

Doesn't matter what your arrogance level is, the evidence seems to point to only one conclusion - it's quite fine as a place to temporarily bury your dirt so teachers won't tag you for your misdeeds, but this is NOT the place to hide something that you want permanently safe! 

So why did Voldemort make such a moronic mistake?
",DVK-on-Ahch-To,https://scifi.stackexchange.com/users/976,"Voldemort knew other people knew about the room, he must have, considering it is written in the book the history of Hogwarts, which Hermione points out. He knew this, and so used the room to hide the horcrux. Like someone said earlier, how many people are going to accidentally find the room of requirement, accidentally find the diadem and accidentally destroy it? Not many, I'm guessing.

Also, as Cho points out, the diadem has been lost for centuries, and no living person has seen it (which isn't technically correct, as Voldemort had seen it, but anyway...). This means that even if someone saw it, they wouldn't think it was the lost diadem.

The 'truck load' of stuff in the room may not have necessarily been hidden by students. Someone needs a place to hide their stuff, you are hardly going to be shown a plain room, with nothing to hide the object in. All the other items have probably been created by the room to help the student hide the item.
",Katy,https://scifi.stackexchange.com/users/4218,http://scifi.stackexchange.com/questions/8734/why-did-voldemort-assume-that-no-one-knew-about-room-of-hidden-things,LIFE_ARTS,scifi.stackexchange.com,1.0,1.0,0.0,1.0,1.0,0.0,0.6666666666666666,0.8333333333333334,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,1.0,Why does Voldemort think no one knows what's hidden?,"Voldemort hid one of his Horcruxes inside Hogwarts. It seemed to be relying on security through obscurity as far as protecting it. But as we know, it ended up not being so secure because it wasn't so obscure - Harry Potter knew about the Room of Hidden Things.

My question is, the way Rowling describes this hints at the fact that Riddle had an assumption that very few people would ever stumble upon that room. *WHY???



First, let's show Harry's theory on what Voldemort was thinking, how and why:

Here's Harry understanding Voldemort's thinking in HP7 once he figured out where the Diadem was (bold emphasis mine):


  Tom Riddle, who confided in no one and operated alone, might have been arrogant
  enough to assume that he, and only he, had penetrated the deepest mysteries of
  Hogwarts Castle. Of course, Dumbledore and Flitwick, those model pupils, had never
  set foot in that particular place, but he, Harry, had strayed off the beaten track in his
  time at school – here at least was a secret area he and Voldemort knew, that
  Dumbledore had never discovered –


...and later on, with Harry explains the location to Ron/Hermione:


  “He hid it exactly where I had my old Potions book, where everyone’s been hiding stuff for centuries. He thought he was the only one to find it. Come on.”
  
  “And he never realized anyone could get in?” said Ron, his voice echoing in the silence.
  “He thought he was the only one,” said Harry.


.



Yet, from available evidence, that seems to be a completely wrong assumption, even at Voldemort's time. 

Let's examine that last quote again, with emphasis on other info available:


  “He hid it exactly where I had my old Potions book, where everyone’s been hiding stuff for centuries.” ...
  
  ...
  
  “And he never realized anyone could get in?” said Ron, his voice echoing in the silence.
  “He thought he was the only one,” said Harry. “Too bad for him I’ve had to hide stuff in
  my time... this way,” he added. “I think it’s down here... “ 
  
  They sped off up adjacent aisles; Harry could hear the others’ footsteps echoing through the towering piles of junk, of bottles, hats, crates, chairs, books, weapons, broomsticks, bats...


.

OK, so if there's a truckload (or train-load, by the description) of stuff in that room, isn't the only reasonable conclusion: ""the room is a fairly popular destination with plenty of people who've found their way there in the past, and therefore, likely, plenty who will in the future""? 

Doesn't matter what your arrogance level is, the evidence seems to point to only one conclusion - it's quite fine as a place to temporarily bury your dirt so teachers won't tag you for your misdeeds, but this is NOT the place to hide something that you want permanently safe! 

So why did Voldemort make such a moronic mistake?
","Voldemort knew other people knew about the room, he must have, considering it is written in the book the history of Hogwarts, which Hermione points out. He knew this, and so used the room to hide the horcrux. Like someone said earlier, how many people are going to accidentally find the room of requirement, accidentally find the diadem and accidentally destroy it? Not many, I'm guessing.

Also, as Cho points out, the diadem has been lost for centuries, and no living person has seen it (which isn't technically correct, as Voldemort had seen it, but anyway...). This means that even if someone saw it, they wouldn't think it was the lost diadem.

The 'truck load' of stuff in the room may not have necessarily been hidden by students. Someone needs a place to hide their stuff, you are hardly going to be shown a plain room, with nothing to hide the object in. All the other items have probably been created by the room to help the student hide the item.
"
2264,2264,3608,Keep rainmeter from minimizing,"HI!

Just been playing around with Rainmeter and I notice that if I want to go look at my desktop and I click on the bottom right square in win7 that minimizes to the desktop, the rainmeter ""gadget"" gets minimized as well, not letting me read what I want to see. Is there something I can configure to make it stay up? Thanks!
",thegreyspot,https://superuser.com/users/13655,"Try right clicking on the gadget and choosing ""always on top"", whilst it means it goes on all windows, it does mean that it will stay there when you click the button to go to desktop or hover on it.

Apart from this, gadgets should always be visible when the desktop is shown even if the ""always on top"" option is not selected, so if it is not visible - it is probably an error in the gadget.
",William Hilsum,https://superuser.com/users/4386,http://superuser.com/questions/73971,TECHNOLOGY,superuser.com,1.0,0.6666666666666666,0.0,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,0.0,0.6666666666666666,Prevent rain gauge minimization,"HI!

Just been playing around with Rainmeter and I notice that if I want to go look at my desktop and I click on the bottom right square in win7 that minimizes to the desktop, the rainmeter ""gadget"" gets minimized as well, not letting me read what I want to see. Is there something I can configure to make it stay up? Thanks!
","Try right clicking on the gadget and choosing ""always on top"", whilst it means it goes on all windows, it does mean that it will stay there when you click the button to go to desktop or hover on it.

Apart from this, gadgets should always be visible when the desktop is shown even if the ""always on top"" option is not selected, so if it is not visible - it is probably an error in the gadget.
"
3104,3104,4943,What kind of gasoline additives will help maintain the engine efficiency/life?,"Aside from the traditional maintenance of oil changes, and keeping fluid levels correct - what else will help prolong the engine's life?

I recall a few years back gasoline additives were the thing to go with - what's the best/recommended one currently? If any.

Edit: I recall reading about each gasoline brand having their own set of additives at one point, where it was suggested to cycle between a few different brands every X amount of km/miles. The reason behind switching was so that the next brand would cleanup any sediments left by the previous brand. How likely is this in today's world? And better yet, how important is it?
",Jesse,https://mechanics.stackexchange.com/users/2890,"You should without a doubt make sure to handle any issues as they ""pop up"". Yes, there are times where money isn't the easiest thing to come by (Trust me. I know), when this is the case just make sure to handle it as soon as you can.

Also it's vital that you keep up with your vehicles service intervals as described in your vehicles manuals. In my opinion there is no real science to to it. It's more or less logic and common sense. If something doesn't feel right then have it looked at by a professional that you trust as soon as possible.

Waiting on repairs only puts more wear on the other components that work with it. This usually brings repair bills through the roof and customers into ""panic"" mode. Usually ending with the customer saying ""I'll just drive it till it dies"". Which then makes their driving environment much more dangerous not only for them, but for everyone around them. I have supplied two links that will provide online (.pdf) version of the service manuals for the vehicles that you have listed.

I hope this helps.

2005 Toyota Tacoma

2013 Nissan Rogue 
",cinelli,https://mechanics.stackexchange.com/users/2881,http://mechanics.stackexchange.com/questions/5729/what-kind-of-gasoline-additives-will-help-maintain-the-engine-efficiency-life,SCIENCE,mechanics.stackexchange.com,1.0,0.4444444444444444,0.0,0.5,1.0,1.0,0.6666666666666666,0.5555555555555556,0.6666666666666666,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.0,0.8888888888888888,0.4444444444444444,0.3333333333333333,0.6666666666666666,0.3333333333333333,0.26666666666666666,0.6666666666666666,0.0,0.3333333333333333,0.8888888888888888,Which gasoline additive helps maintain engine efficiency / life?,"Aside from the traditional maintenance of oil changes, and keeping fluid levels correct - what else will help prolong the engine's life?

I recall a few years back gasoline additives were the thing to go with - what's the best/recommended one currently? If any.

Edit: I recall reading about each gasoline brand having their own set of additives at one point, where it was suggested to cycle between a few different brands every X amount of km/miles. The reason behind switching was so that the next brand would cleanup any sediments left by the previous brand. How likely is this in today's world? And better yet, how important is it?
","You should without a doubt make sure to handle any issues as they ""pop up"". Yes, there are times where money isn't the easiest thing to come by (Trust me. I know), when this is the case just make sure to handle it as soon as you can.

Also it's vital that you keep up with your vehicles service intervals as described in your vehicles manuals. In my opinion there is no real science to to it. It's more or less logic and common sense. If something doesn't feel right then have it looked at by a professional that you trust as soon as possible.

Waiting on repairs only puts more wear on the other components that work with it. This usually brings repair bills through the roof and customers into ""panic"" mode. Usually ending with the customer saying ""I'll just drive it till it dies"". Which then makes their driving environment much more dangerous not only for them, but for everyone around them. I have supplied two links that will provide online (.pdf) version of the service manuals for the vehicles that you have listed.

I hope this helps.

2005 Toyota Tacoma

2013 Nissan Rogue 
"
4471,4471,7094,"Multiple-prime RSA; how many primes can I use, for a 2048-bit modulus?","In standard RSA, the modulus $n=p_1 p_2$ is a product of two primes $p_1,p_2$ of the same size.  Suppose we construct the modulus as a product of multiple primes $p_1,\dots,p_k$, i.e., $n=p_1 p_2 \cdots p_k$, where all the primes are of about the same size.  I'm wondering how much this reduces the security of RSA, for typical modulus sizes.

Let me be more concrete.  I want security comparable to that obtained with standard RSA with a 2048-bit modulus.  Can I use $k=3$ (three primes) without significant loss of security?  $k=4$?  What's the largest number of primes $k$ that I can use, without significant loss of security?  Assume that each prime is $2048/k$ bits long, so all the prime factors are of equal length.

Related: see also Who first published the interest of more than two prime factors in RSA?, which asks about the inventor of this technique.  I'm asking something slightly different; in this question, I'm not asking about its inventor; I'm asking about concrete security levels.
",D.W.,https://crypto.stackexchange.com/users/351,"For a 2048-bit modulus, based on current knowledge of attacks: you can use up to $k=3$ primes without any loss in security.  Using $k=4$ primes apparently causes some loss in security (it's not clear to me exactly how much loss it causes, though).

I've found two sources that support this conclusion:


The blog post Multi-prime RSA trade offs analyzes the security of a 2048-bit $k$-prime modulus against the NFS and ECM factoring algorithms.  For $k=2$ and $k=3$, the security level is 107 bits (NFS is the best attack).  For $k=4$, the article claims that the security level is 106 bits (ECM is slightly faster than NFS for four primes), so we've lost about one bit of security, though this estimate seems like it might over-simplify.
Table 3 of the paper Unbelievable Security: Matching AES security using public key systems also addresses this issue.  It suggests that, for a 2048-bit modulus, $k=3$ primes offers no measurable loss of security.  Starting in 2030, $k=4$ primes will offer no loss in security (it changes over time because NFS factoring speeds up faster than ECM factoring).  Here is Table 3:



",D.W.,https://crypto.stackexchange.com/users/351,http://crypto.stackexchange.com/questions/15823/multiple-prime-rsa-how-many-primes-can-i-use-for-a-2048-bit-modulus,TECHNOLOGY,crypto.stackexchange.com,0.3333333333333333,0.6666666666666666,0.0,0.0,1.0,1.0,0.6666666666666666,0.3333333333333333,1.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,1.0,1.0,0.0,0.0,1.0,1.0,Multiple prime RSA; how many prime numbers can 2048 bit modules use?,"In standard RSA, the modulus $n=p_1 p_2$ is a product of two primes $p_1,p_2$ of the same size.  Suppose we construct the modulus as a product of multiple primes $p_1,\dots,p_k$, i.e., $n=p_1 p_2 \cdots p_k$, where all the primes are of about the same size.  I'm wondering how much this reduces the security of RSA, for typical modulus sizes.

Let me be more concrete.  I want security comparable to that obtained with standard RSA with a 2048-bit modulus.  Can I use $k=3$ (three primes) without significant loss of security?  $k=4$?  What's the largest number of primes $k$ that I can use, without significant loss of security?  Assume that each prime is $2048/k$ bits long, so all the prime factors are of equal length.

Related: see also Who first published the interest of more than two prime factors in RSA?, which asks about the inventor of this technique.  I'm asking something slightly different; in this question, I'm not asking about its inventor; I'm asking about concrete security levels.
","For a 2048-bit modulus, based on current knowledge of attacks: you can use up to $k=3$ primes without any loss in security.  Using $k=4$ primes apparently causes some loss in security (it's not clear to me exactly how much loss it causes, though).

I've found two sources that support this conclusion:


The blog post Multi-prime RSA trade offs analyzes the security of a 2048-bit $k$-prime modulus against the NFS and ECM factoring algorithms.  For $k=2$ and $k=3$, the security level is 107 bits (NFS is the best attack).  For $k=4$, the article claims that the security level is 106 bits (ECM is slightly faster than NFS for four primes), so we've lost about one bit of security, though this estimate seems like it might over-simplify.
Table 3 of the paper Unbelievable Security: Matching AES security using public key systems also addresses this issue.  It suggests that, for a 2048-bit modulus, $k=3$ primes offers no measurable loss of security.  Starting in 2030, $k=4$ primes will offer no loss in security (it changes over time because NFS factoring speeds up faster than ECM factoring).  Here is Table 3:



"
303,303,489,Why do we use singular verb with third person after gerund?,"Why do we use singular verb in sentences like this:

Just sitting here and watching the world go by. (not goes)

Just sitting here and watching paint dry. (not dries)

The world goes, doesn't it?
",Dmitry,https://ell.stackexchange.com/users/6944,"Because the world and the paint aren't the subjects of the sentences, which means there's not a fixed point in time when the world goes or the paint dries. Consider this sentence:


  The clock ticks


The clock is the subject, so we conjugate ""to tick"" into the present simple. However if the clock is not the subject, then the verb ""to tick"" doesn't get conjugated:


  Electricity makes the clock tick


This is because the ticking doesn't just happen in the present tense, the electricity gives the clock the ability to tick, which is why we use the infinitive.
",Mark,https://ell.stackexchange.com/users/15703,http://ell.stackexchange.com/questions/54932/why-do-we-use-singular-verb-with-third-person-after-gerund,CULTURE,ell.stackexchange.com,1.0,0.6666666666666666,0.0,1.0,1.0,1.0,0.7777777777777778,0.8888888888888888,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,1.0,Why do we use singular verbs and third person after gerund?,"Why do we use singular verb in sentences like this:

Just sitting here and watching the world go by. (not goes)

Just sitting here and watching paint dry. (not dries)

The world goes, doesn't it?
","Because the world and the paint aren't the subjects of the sentences, which means there's not a fixed point in time when the world goes or the paint dries. Consider this sentence:


  The clock ticks


The clock is the subject, so we conjugate ""to tick"" into the present simple. However if the clock is not the subject, then the verb ""to tick"" doesn't get conjugated:


  Electricity makes the clock tick


This is because the ticking doesn't just happen in the present tense, the electricity gives the clock the ability to tick, which is why we use the infinitive.
"
5829,5829,9235,"Anybody knows if there is a counterpart for CTR+w , that deletes immediate words after cursor","I mean when the cursor is on the left side of the words ,I would like to remove the words on the immediate right side of it . CTR+k remove everything on the right side, i only want one word to be removed. 
",Eric,https://serverfault.com/users/67065,"Bash tends to use libreadline for commandline input, so you can create an inputrc file that lets you control what keystrokes do what.  man readline 3 should explain the format, you can also find this in the READLINE section of bash's manpage (the specific command you want is kill-word)

zsh doesn't use libreadline apparently, but it seems they've mimicked a lot of the functionality.  It looks like there are some options to mimic bash's word matching, but you'll need to bind them to a key.
",DerfK,https://serverfault.com/users/56830,http://serverfault.com/questions/226679,TECHNOLOGY,serverfault.com,0.8888888888888888,0.8888888888888888,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,0.3333333333333333,0.7777777777777778,"Anyone knows if CTR + W has a corresponding item, that is, delete the direct word after the cursor","I mean when the cursor is on the left side of the word, I want to delete the word on the right. CTR + K delete everything on the right, I just want to delete one word.","Bash tends to use libreadline as command-line input, so you can create an inputc file that allows you to control what keystrokes do. Man readLine 3 should explain the format. You can also find it in the readLine section of the bash man page (the specific command you need is kill word)"
4249,4249,6776,Is it an absolute must that we ignore/delete all compiled files before committing?,"I am working on a Drupal theme. I am going to be using ""intermediary"" languages to develop it, ie Stylus for styles, and CoffeeScript for some of the front-end scripts.

I am going to be using a git hosting service to be able to share the code among colleges. I am also going to be using it to update the code locally and then push onto hosting service, to be later pulled by the live drupal site.

This makes things really elegant.

However, I have noticed that a lot of developers tend to .gitignore all compiled code.

If it were a good practice, I would've loved to follow it, if and only if there wasn't this one issue: recompiling all the code that is needed in order for the theme to work out correctly.

This means that when I do a pull, I will have to recompile all the CSS and JavaScript code. Now, if I were to do a pull on the live site, there's a risk that a user goes to the site right at the moment I do the pull. No styles and scripts will be loaded on the user's end, so long as the code hasn't compiled.

Of course, compiling takes about a second, and the user might probably think to him/herself ""meh, it was just my internet connection.""

But there is also the issue that the server doesn't have the compilers installed to begin with. So now, I would do a pull, but there will be no styles, and no scripts.

Is it an absolute must that I delete all compiled code, or can I go ahead and include them in the commit?
",skizeey,https://programmers.stackexchange.com/users/17183,"Yes, you must delete all compiled code. Source control is for, well, the source code, not the compiled files. The worst scenario is when developers commit the compiled binaries. Your case is not the same, since you're not committing large binaries which are diff-unfriendly, but still, keep your source control free of everything you don't need to run the application.

What seems wrong in your case is the deployment process. Instead of pushing the code to the production server directly from the source control, you should rather, in the simplest case:


Load the source code,
Compile and/or optimize it,
Push the compiled version to the server.


If your website has lots of visits, you may need a more complicated flow, using two servers, for example:


Load the source code,
Compile and/or optimize it,
Push the compiled version to the staging server,
Run a bunch of tests to ensure that the website is working on staging server,
Forward all the requests to the production server 2,
Once the production server 1 doesn't have any requests, push the compiled version to it,
Forward all the requests to the production server 1,
Once the production server 2 doesn't have any requests, push the complied version to it,
Use server 1 and server 2 again.

",Arseni Mourzenko,https://programmers.stackexchange.com/users/6605,http://programmers.stackexchange.com/questions/146820/is-it-an-absolute-must-that-we-ignore-delete-all-compiled-files-before-committin,TECHNOLOGY,programmers.stackexchange.com,1.0,0.7777777777777778,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.6666666666666666,0.0,0.6666666666666666,0.8888888888888888,Must all compiled files be ignored / deleted before submission?,"I am working on a Drupal theme. I am going to be using ""intermediary"" languages to develop it, ie Stylus for styles, and CoffeeScript for some of the front-end scripts.

I am going to be using a git hosting service to be able to share the code among colleges. I am also going to be using it to update the code locally and then push onto hosting service, to be later pulled by the live drupal site.

This makes things really elegant.

However, I have noticed that a lot of developers tend to .gitignore all compiled code.

If it were a good practice, I would've loved to follow it, if and only if there wasn't this one issue: recompiling all the code that is needed in order for the theme to work out correctly.

This means that when I do a pull, I will have to recompile all the CSS and JavaScript code. Now, if I were to do a pull on the live site, there's a risk that a user goes to the site right at the moment I do the pull. No styles and scripts will be loaded on the user's end, so long as the code hasn't compiled.

Of course, compiling takes about a second, and the user might probably think to him/herself ""meh, it was just my internet connection.""

But there is also the issue that the server doesn't have the compilers installed to begin with. So now, I would do a pull, but there will be no styles, and no scripts.

Is it an absolute must that I delete all compiled code, or can I go ahead and include them in the commit?
","Yes, you must delete all compiled code. Source control is for, well, the source code, not the compiled files. The worst scenario is when developers commit the compiled binaries. Your case is not the same, since you're not committing large binaries which are diff-unfriendly, but still, keep your source control free of everything you don't need to run the application.

What seems wrong in your case is the deployment process. Instead of pushing the code to the production server directly from the source control, you should rather, in the simplest case:


Load the source code,
Compile and/or optimize it,
Push the compiled version to the server.


If your website has lots of visits, you may need a more complicated flow, using two servers, for example:


Load the source code,
Compile and/or optimize it,
Push the compiled version to the staging server,
Run a bunch of tests to ensure that the website is working on staging server,
Forward all the requests to the production server 2,
Once the production server 1 doesn't have any requests, push the compiled version to it,
Forward all the requests to the production server 1,
Once the production server 2 doesn't have any requests, push the complied version to it,
Use server 1 and server 2 again.

"
486,486,758,how to display a message box for a user in Java,"I want to display a message box to show some message in Java, and the box should have three buttons that the user can press such that the program can get value when user presses the button.
",MagicConch,https://stackoverflow.com/users/1957202,"I think this is what you are looking for

//Custom button text
Object[] options = {""Yes, please"",
                ""No, thanks"",
                ""No eggs, no ham!""};
int n = JOptionPane.showOptionDialog(frame,
""Would you like some green eggs to go ""
+ ""with that ham?"",
""A Silly Question"",
JOptionPane.YES_NO_CANCEL_OPTION,
JOptionPane.QUESTION_MESSAGE,
null,
options,
options[2]);


Please refer to oracle documentation here
",Bhushan,https://stackoverflow.com/users/1551233,http://stackoverflow.com/questions/14209908/how-to-display-a-message-box-for-a-user-in-java,STACKOVERFLOW,stackoverflow.com,1.0,0.5555555555555556,0.0,0.6666666666666666,0.6666666666666666,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,0.8888888888888888,How to display the user's message box in Java,"I want to display a message box that uses Java to display some messages. This box should have three buttons that users can press, so that when users press the button, the program can get the value.","I think this is what you are looking for

//Custom button text
Object[] options = {""Yes, please"",
                ""No, thanks"",
                ""No eggs, no ham!""};
int n = JOptionPane.showOptionDialog(frame,
""Would you like some green eggs to go ""
+ ""with that ham?"",
""A Silly Question"",
JOptionPane.YES_NO_CANCEL_OPTION,
JOptionPane.QUESTION_MESSAGE,
null,
options,
options[2]);


Please refer to oracle documentation here
"
4494,4494,7126,IgA complement activation,"Recently, I have been reading Janeway's immunobiology and had a question on immunoglobin A. I read that IgA activates the complement pathway using the Fab fragment of the IgA. How does IgA do that? I can't seem to find an information on that in  the book or online.
",TanMath,https://biology.stackexchange.com/users/10401,"I found some reports on it (like reference 1) but there is an oddly little amount of publications on this topic. then I found this review in Mucosal Immunology (reference 2, interesting to read) which doubts this activation. It says:


  Interaction with complement
  
  IgA lacks the residues identified in the Fc regions of IgG or IgM that
  bind to C1q, and consequently IgA does not activate the classical
  complement pathway. Although several papers have reported activation
  of the alternate pathway by heat-aggregated, denatured, or
  recombinantly generated IgA, this seems to be essentially artifactual,
  and intact native IgA antibodies complexed with antigen inhibit
  complement activation induced by IgG or IgM antibodies. This
  effect is also replicated by Fabα fragments generated by cleavage of
  IgA1 antibodies with IgA1 protease. It is telling that mixed
  aggregates of heat-denatured IgG and IgA activate the alternate
  pathway in proportion to the content of IgG, and that C3b becomes
  covalently linked to the IgG heavy chains, not to IgA. Intriguing
  reports that IgA antibodies promote complement-dependent lysis or
  opsonization of encapsulated bacteria probably also arise from
  facilitation of alternate pathway activation by bacterial
  polysaccharides


It names three papers to underline this (which are number 45-47 in the reference list of the article), which can be found as references 3-5. So the question here is not only how the mechanism looks like, but also if this is real or an artefact.

References:


Activation of complement by human serum IgA, secretory IgA and IgA1
fragments.
Structure and function relationships in IgA
Anti-inflammatory activity of human IgA antibodies and their Fabα
fragments: inhibition of IgG-mediated complement activation
IgA blocks IgM and IgG-initiated immune lysis by separate molecular
mechanisms.
Activity of human IgG and IgA subclasses in immune defense against
Neisseria meningitidis serogroup B.

",Chris,https://biology.stackexchange.com/users/5144,http://biology.stackexchange.com/questions/26315/iga-complement-activation,SCIENCE,biology.stackexchange.com,1.0,0.4444444444444444,0.0,0.0,1.0,0.3333333333333333,0.8888888888888888,0.8888888888888888,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,1.0,IgA complement activation,"Recently, I read about Jennifer's immunobiology. There is a question about immunoglobulin A. I read that IGA uses the Fab fragment of IgA to activate the complement pathway. What shall I do? I can't seem to find any information about it in books or on the Internet.","I found some reports on it (like reference 1) but there is an oddly little amount of publications on this topic. then I found this review in Mucosal Immunology (reference 2, interesting to read) which doubts this activation. It says:


  Interaction with complement
  
  IgA lacks the residues identified in the Fc regions of IgG or IgM that
  bind to C1q, and consequently IgA does not activate the classical
  complement pathway. Although several papers have reported activation
  of the alternate pathway by heat-aggregated, denatured, or
  recombinantly generated IgA, this seems to be essentially artifactual,
  and intact native IgA antibodies complexed with antigen inhibit
  complement activation induced by IgG or IgM antibodies. This
  effect is also replicated by Fabα fragments generated by cleavage of
  IgA1 antibodies with IgA1 protease. It is telling that mixed
  aggregates of heat-denatured IgG and IgA activate the alternate
  pathway in proportion to the content of IgG, and that C3b becomes
  covalently linked to the IgG heavy chains, not to IgA. Intriguing
  reports that IgA antibodies promote complement-dependent lysis or
  opsonization of encapsulated bacteria probably also arise from
  facilitation of alternate pathway activation by bacterial
  polysaccharides


It names three papers to underline this (which are number 45-47 in the reference list of the article), which can be found as references 3-5. So the question here is not only how the mechanism looks like, but also if this is real or an artefact.

References:


Activation of complement by human serum IgA, secretory IgA and IgA1
fragments.
Structure and function relationships in IgA
Anti-inflammatory activity of human IgA antibodies and their Fabα
fragments: inhibition of IgG-mediated complement activation
IgA blocks IgM and IgG-initiated immune lysis by separate molecular
mechanisms.
Activity of human IgG and IgA subclasses in immune defense against
Neisseria meningitidis serogroup B.

"
4055,4055,6473,Crosstalk vs interference,"I don't even clear about the differences between crosstalk and interference. Could you explain me please?

I just know that cross talk is the leakage power from other sources, whereas interference is the aliasing signal.

Could you tell me any other differences?
",Ny sokunthea,https://electronics.stackexchange.com/users/59555,"Crosstalk is a type of interference.  Interference can come from just about anywhere - e.g. RF interference from all sorts of things emitting radio waves (including, but not limited to, radio transmitters).  Interference can also come from coupling from other devices.  In the case of a phone system, this could be hearing humming from a power line or music from the local AM radio station on the phone line.  Generally crosstalk refers to interference from an 'adjacent' signal - be it in a wire, radio channel, etc - leaking into the 'victim' signal.  In the case of a phone system, this could be in the form of being able to hear your neighbor's phone calls on your line because the two lines are routed next to each other on the telephone pole.  
",alex.forencich,https://electronics.stackexchange.com/users/31018,http://electronics.stackexchange.com/questions/141271/crosstalk-vs-interference,SCIENCE,electronics.stackexchange.com,1.0,0.5555555555555556,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.0,0.6666666666666666,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,1.0,Crosstalk and interference,"I don't even clear about the differences between crosstalk and interference. Could you explain me please?

I just know that cross talk is the leakage power from other sources, whereas interference is the aliasing signal.

Could you tell me any other differences?
","Crosstalk is a type of interference.  Interference can come from just about anywhere - e.g. RF interference from all sorts of things emitting radio waves (including, but not limited to, radio transmitters).  Interference can also come from coupling from other devices.  In the case of a phone system, this could be hearing humming from a power line or music from the local AM radio station on the phone line.  Generally crosstalk refers to interference from an 'adjacent' signal - be it in a wire, radio channel, etc - leaking into the 'victim' signal.  In the case of a phone system, this could be in the form of being able to hear your neighbor's phone calls on your line because the two lines are routed next to each other on the telephone pole.  
"
5475,5475,8693,Why use a small aperture when trying to see sensor dust?,"Here and there I read of people who set their lens to a small aperture while testing their sensor cleanness, supposedly to get the best image of dust speckles. However, the image of the on-sensor dust particles should not, to my understanding, be affected by the sharpness induced by the lens settings. Same is true for dust particle on the lens elements themselves. It makes me wonder - do these people misunderstand the theory of how the optical system work, or am I missing something?
",ysap,https://photo.stackexchange.com/users/1024,"If the dust was really on the sensor proper, you'd be absolutely correct.

At least in the normal case, it's virtually impossible for dust to get on the surface of the sensor itself, because there's a couple millimeters or so of filters directly in front of the sensor. The front-most of these is (at least in the usual case) the AA filer.

The important thing is that all of this transparent glass. Therefore, with a wider aperture, there's more light coming at the sensor from various angles. Since the light can travel at whatever angle through those filters (because they're all at least mostly-transparent glass), the dust spots won't normally block all the light. With a smaller aperture, the light comes nearly straight back from the small aperture, so the edges of any dust spots are clearly defined.

In practice, the difference is pretty obvious. Here's a shot at f/1.7, then shot taken a few moments later at f/22 (same camera, same lens, etc. -- all that's changed is the aperture and shutter speed):

f/1.7:


f/22:


Like usual for this situation, I've also boosted the contrast to make the dust more visible -- since it's a plain, low-contrast subject, the histogram starts out like this:



To make the dust more apparent, you adjust the levels something like this:



If you apply it to the f/1.7 picture (as I did above, to keep things fair), that will also overemphasize the light falloff at the corners of the picture. Though there is some anyway, it's not normally even close to as bad as it looks in the first shot above.

Note that this is a pretty rigorous test. This sensor is clean enough that on typical shots, there's no sign of dust on the sensor at all. Between the total lack of contrast/detail in the subject, tiny aperture, and extreme boost of contrast, we're seeing quite a bit that we'd never see in any normal picture (not to mention that the two worst spots here are near the bottom of the frame, where there's nearly always at least a little detail to hide these problems anyway). If you test this on your own camera, don't be too surprised if it looks (quite possibly a lot) worse than the ones above. From what I've seen, I'd guess that most dSLRs (and a pretty fair number of P&amp;S cameras too) are at least a little, and often a lot, worse than this.
",Jerry Coffin,https://photo.stackexchange.com/users/603,http://photo.stackexchange.com/questions/12087/why-use-a-small-aperture-when-trying-to-see-sensor-dust,LIFE_ARTS,photo.stackexchange.com,0.7777777777777778,0.7777777777777778,0.0,0.6666666666666666,0.6666666666666666,1.0,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,0.8888888888888888,Why use small apertures when trying to see sensor dust?,"I read from time to time that some people adjust their lens to a small aperture when testing the cleanliness of the sensor, which is said to get the best image of dust spots. However, as far as I know, the image of dust particles on the sensor should not be affected by the sharpness caused by the lens setting. The same is true of the dust particles on the lens element itself. It makes me wonder - have these people misunderstood how the optical system works, or have I missed something?","If the dust was really on the sensor proper, you'd be absolutely correct.

At least in the normal case, it's virtually impossible for dust to get on the surface of the sensor itself, because there's a couple millimeters or so of filters directly in front of the sensor. The front-most of these is (at least in the usual case) the AA filer.

The important thing is that all of this transparent glass. Therefore, with a wider aperture, there's more light coming at the sensor from various angles. Since the light can travel at whatever angle through those filters (because they're all at least mostly-transparent glass), the dust spots won't normally block all the light. With a smaller aperture, the light comes nearly straight back from the small aperture, so the edges of any dust spots are clearly defined.

In practice, the difference is pretty obvious. Here's a shot at f/1.7, then shot taken a few moments later at f/22 (same camera, same lens, etc. -- all that's changed is the aperture and shutter speed):

f/1.7:


f/22:


Like usual for this situation, I've also boosted the contrast to make the dust more visible -- since it's a plain, low-contrast subject, the histogram starts out like this:



To make the dust more apparent, you adjust the levels something like this:



If you apply it to the f/1.7 picture (as I did above, to keep things fair), that will also overemphasize the light falloff at the corners of the picture. Though there is some anyway, it's not normally even close to as bad as it looks in the first shot above.

Note that this is a pretty rigorous test. This sensor is clean enough that on typical shots, there's no sign of dust on the sensor at all. Between the total lack of contrast/detail in the subject, tiny aperture, and extreme boost of contrast, we're seeing quite a bit that we'd never see in any normal picture (not to mention that the two worst spots here are near the bottom of the frame, where there's nearly always at least a little detail to hide these problems anyway). If you test this on your own camera, don't be too surprised if it looks (quite possibly a lot) worse than the ones above. From what I've seen, I'd guess that most dSLRs (and a pretty fair number of P&amp;S cameras too) are at least a little, and often a lot, worse than this.
"
2086,2086,3323,Using PHP to dynamically create pages from a template,"I'm creating a blog for a website I am building. The main blog page obviously has each blog listed as it should. But I want each blog to also have it's own individual page on the website. I want this page to be generated on creation of the blog post.

My question is, what would be the best method of creating this page. If I use the php file functions to create it, I would need to fill up a $data variable with hundreds of lines of HTML for the page. Which I guess is feasible, IF I am also able to dynamically change the variable to work for the new content that needs to be posted on said page.

Is there better methods? Would PHP work for this? Any suggestions would help.
",Josh,https://stackoverflow.com/users/2476769,"In general, I would do it more or less like this:

1. Create a 'Blogs' SQL database table.
Create an 'id' column (primary key), and columns for fields like 'blog_date', 'title', 'author', and 'html_content'.

2. Create a 'Blog' class using php.
Create properties which correspond to the SQL fields in your 'Blogs' table, including 'id'.

3. Create public 'loadFromDB()' and 'saveToDB()' methods
These methods should load and save the SQL values of a row in 'Blogs' (selected by id) to and from the class properties.

4. Create a public 'view()' method for the 'Blog' class
This is simply an HTML view/template of a single blog entry displaying date, title, author, etc.

5. Create an 'index.php' blog page in a folder on the server
You want to use this page to display a single blog entry.
Use a blog's SQL id when calling this page from links in your main blogs page, for example via http GET: 'http://www.yoursite.com/blogs/blog/index.php?id=30'.  In your php code inside index.php, where you want the entry to appear, do something like this:  

$id_default = 27;  // the blog entry which must appear when there is no query parameter
$id = empty($_GET['id']) ? $id_default : $_GET['id'];
$B = new Blog($id);
$B-&gt;loadFromDB();
$html = $B-&gt;view();
echo $html;


In this way, you don't have to create an HTML page for EVERY blog entry, or put ALL the entries on one page.  You can just use one page created dynamically with a GET parameter instead.

Obviously there is more you can/must do, such as creating commenting displays and forms and a 'Comments' SQL table, etc.  But this should give you some ideas.
",Stefan,https://stackoverflow.com/users/888177,http://stackoverflow.com/questions/17463350/using-php-to-dynamically-create-pages-from-a-template,STACKOVERFLOW,stackoverflow.com,0.6666666666666666,0.6666666666666666,0.0,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,0.0,1.0,Using PHP to dynamically create pages from templates,"I'm creating a blog for a website I am building. The main blog page obviously has each blog listed as it should. But I want each blog to also have it's own individual page on the website. I want this page to be generated on creation of the blog post.

My question is, what would be the best method of creating this page. If I use the php file functions to create it, I would need to fill up a $data variable with hundreds of lines of HTML for the page. Which I guess is feasible, IF I am also able to dynamically change the variable to work for the new content that needs to be posted on said page.

Is there better methods? Would PHP work for this? Any suggestions would help.
","In general, I would do it more or less like this:

1. Create a 'Blogs' SQL database table.
Create an 'id' column (primary key), and columns for fields like 'blog_date', 'title', 'author', and 'html_content'.

2. Create a 'Blog' class using php.
Create properties which correspond to the SQL fields in your 'Blogs' table, including 'id'.

3. Create public 'loadFromDB()' and 'saveToDB()' methods
These methods should load and save the SQL values of a row in 'Blogs' (selected by id) to and from the class properties.

4. Create a public 'view()' method for the 'Blog' class
This is simply an HTML view/template of a single blog entry displaying date, title, author, etc.

5. Create an 'index.php' blog page in a folder on the server
You want to use this page to display a single blog entry.
Use a blog's SQL id when calling this page from links in your main blogs page, for example via http GET: 'http://www.yoursite.com/blogs/blog/index.php?id=30'.  In your php code inside index.php, where you want the entry to appear, do something like this:  

$id_default = 27;  // the blog entry which must appear when there is no query parameter
$id = empty($_GET['id']) ? $id_default : $_GET['id'];
$B = new Blog($id);
$B-&gt;loadFromDB();
$html = $B-&gt;view();
echo $html;


In this way, you don't have to create an HTML page for EVERY blog entry, or put ALL the entries on one page.  You can just use one page created dynamically with a GET parameter instead.

Obviously there is more you can/must do, such as creating commenting displays and forms and a 'Comments' SQL table, etc.  But this should give you some ideas.
"
5597,5597,8883,What exactly is computation?,"I know what computation is in some vague sense (it is the thing computers do), but I would like a more rigorous definition. 

Dictionary.com's definitions of computation, computing, calculate, and compute are circular, so it doesn't help. 

Wikipedia defines computation to be ""any type of calculation that follows a well-defined model."" 
It defines calculation as ""the deliberate process that transforms one or more inputs into one or more results, with variable change."" But it seems this definition includes many actions as computations even though they aren't typically thought of as computation. 

For example, wouldn't this entail that, say, a bomb exploding is a computation, with the input being the fuse being lighted and the output being the explosion?

So, what exactly is computation?
",Kelmikra,https://cs.stackexchange.com/users/24518,"Perhaps the problem here is looking a for a highly specific definition of a very general concept. I don't see the problem of viewing virtually everything as a computation. Although we don't think about it, everything we do is expressible in terms of the Physics of the component parts, down to at least quarks buzzing about. We have the same situation with computation. There's inputs, outputs and a process (all of which could be trivial). Whether they're interesting or useful as computations or models of computation is a very different question.

The strongest working definition we have comes via the (strong) Church-Turing Thesis, which states that every possible physically realizable model of computation is no more powerful than a Turing Machine. If you believe that this is true, then although we may have lots of way to express things, ultimately we can reduce every computation to a Turing Machine, hence giving a definition of computation as ""anything we can reduce to a Turing Machine"".

In this model, the exploding bomb is a computation. It's not a widely applicable one (we hope ;) ), but we can model in some fashion with a Turing Machine (though there is an argument here about the nature of the output and the equivalence with the TM's output). It's also not a good model of computation in general, in that it seems unlikely that the exploding bomb model is Turing complete.
",Luke Mathieson,https://cs.stackexchange.com/users/1636,http://cs.stackexchange.com/questions/43938/what-exactly-is-computation,SCIENCE,cs.stackexchange.com,1.0,0.6666666666666666,0.0,1.0,1.0,1.0,0.6666666666666666,0.8888888888888888,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,0.8888888888888888,1.0,0.8888888888888888,1.0,0.9,0.0,0.0,1.0,1.0,What is computation?,"I know what computation is in some vague sense (it is the thing computers do), but I would like a more rigorous definition. 

Dictionary.com's definitions of computation, computing, calculate, and compute are circular, so it doesn't help. 

Wikipedia defines computation to be ""any type of calculation that follows a well-defined model."" 
It defines calculation as ""the deliberate process that transforms one or more inputs into one or more results, with variable change."" But it seems this definition includes many actions as computations even though they aren't typically thought of as computation. 

For example, wouldn't this entail that, say, a bomb exploding is a computation, with the input being the fuse being lighted and the output being the explosion?

So, what exactly is computation?
","Perhaps the problem here is looking a for a highly specific definition of a very general concept. I don't see the problem of viewing virtually everything as a computation. Although we don't think about it, everything we do is expressible in terms of the Physics of the component parts, down to at least quarks buzzing about. We have the same situation with computation. There's inputs, outputs and a process (all of which could be trivial). Whether they're interesting or useful as computations or models of computation is a very different question.

The strongest working definition we have comes via the (strong) Church-Turing Thesis, which states that every possible physically realizable model of computation is no more powerful than a Turing Machine. If you believe that this is true, then although we may have lots of way to express things, ultimately we can reduce every computation to a Turing Machine, hence giving a definition of computation as ""anything we can reduce to a Turing Machine"".

In this model, the exploding bomb is a computation. It's not a widely applicable one (we hope ;) ), but we can model in some fashion with a Turing Machine (though there is an argument here about the nature of the output and the equivalence with the TM's output). It's also not a good model of computation in general, in that it seems unlikely that the exploding bomb model is Turing complete.
"
2300,2300,3664,How to remove Libre.fm from Rhythmbox?,"As I do not use Libre.fm, I'd like to remove it from the sidepane in Rhythmbox (Ubuntu Precise). I did it some time ago on of my machines. But now I cannot recall how I did it. :-( 
I could not find a plugin to deactivate, or a package to uninstall. 
",Andre,https://askubuntu.com/users/6232,"Libre.fm is part of the LastFM plugin



Choose Edit - plugins and click of the Last.fm plugin.  You then will have the preferences button visible.  From the popup-dialog you can hide/show both services.
",fossfreedom,https://askubuntu.com/users/14356,http://askubuntu.com/questions/290264/how-to-remove-libre-fm-from-rhythmbox,TECHNOLOGY,askubuntu.com,1.0,0.8888888888888888,0.0,1.0,0.3333333333333333,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,1.0,How do I remove libre.fm from rhythmbox?,"Since I don't use libre.fm, I want to remove it from the dashboard of rhythmbox (Ubuntu precision). I've done it on my machine before. But now I can't remember how I did it. - - (","Libre.fm is part of the LastFM plugin



Choose Edit - plugins and click of the Last.fm plugin.  You then will have the preferences button visible.  From the popup-dialog you can hide/show both services.
"
5633,5633,8930,"Google Fonts loading on desktop, but not on mobile?","Per Google PageSpeed's recommendation, I inlined much of my CSS. Previously, I had minified all of my CSS through W3 Total Cache, but now I inlined much of my CSS, plus all of the CSS that controls Google Fonts. 

Now Google Fonts aren't appearing on mobile devices, but they do appear on desktops. Any reason why this is the case? The mobile screen cap here shows the fonts not loading.

&lt;style&gt;@font-face{font-family:'Pathway Gothic One';font-style:normal;font-weight:400;src:local('Pathway Gothic One'),local(PathwayGothicOne-Regular),url(https://fonts.gstatic.com/s/pathwaygothicone/v4/Lqv9ztoTUV8Q0FmQZzPqaA6LSHyyJAN5JIFgwWnj0Az3rGVtsTkPsbDajuO5ueQw.woff2) format(""woff2"");unicode-range:U+0100-024F,U+1E00-1EFF,U+20A0-20AB,U+20AD-20CF,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Pathway Gothic One';font-style:normal;font-weight:400;src:local('Pathway Gothic One'),local(PathwayGothicOne-Regular),url(https://fonts.gstatic.com/s/pathwaygothicone/v4/Lqv9ztoTUV8Q0FmQZzPqaHT0-GP0evTJPrdxn7U7ioo.woff2) format(""woff2"");unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2212,U+2215,U+E0FF,U+EFFD,U+F000}@font-face{font-family:'Quicksand';font-style:normal;font-weight:400;src:local('Quicksand Regular'),local(Quicksand-Regular),url(https://fonts.gstatic.com/s/quicksand/v5/sKd0EMYPAh5PYCRKSryvW5Bw1xU1rKptJj_0jans920.woff2) format(""woff2"");unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2212,U+2215,U+E0FF,U+EFFD,U+F000}@font-face{font-family:'Roboto Condensed';font-style:normal;font-weight:400;src:local('Roboto Condensed'),local(RobotoCondensed-Regular),url(https://fonts.gstatic.com/s/robotocondensed/v13/Zd2E9abXLFGSr9G3YK2MsIPxuqWfQuZGbz5Rz4Zu1gk.woff2) format(""woff2"");unicode-range:U+0460-052F,U+20B4,U+2DE0-2DFF,U+A640-A69F}@font-face{font-family:'Roboto Condensed';font-style:normal;font-weight:400;src:local('Roboto Condensed'),local(RobotoCondensed-Regular),url(https://fonts.gstatic.com/s/robotocondensed/v13/Zd2E9abXLFGSr9G3YK2MsENRpQQ4njX3CLaCqI4awdk.woff2) format(""woff2"");unicode-range:U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Roboto Condensed';font-style:normal;font-weight:400;src:local('Roboto Condensed'),local(RobotoCondensed-Regular),url(https://fonts.gstatic.com/s/robotocondensed/v13/Zd2E9abXLFGSr9G3YK2MsET2KMEyTWEzJqg9U8VS8XM.woff2) format(""woff2"");unicode-range:U+1F00-1FFF}@font-face{font-family:'Roboto Condensed';font-style:normal;font-weight:400;src:local('Roboto Condensed'),local(RobotoCondensed-Regular),url(https://fonts.gstatic.com/s/robotocondensed/v13/Zd2E9abXLFGSr9G3YK2MsMH5J2QbmuFthYTFOnnSRco.woff2) format(""woff2"");unicode-range:U+0370-03FF}@font-face{font-family:'Roboto Condensed';font-style:normal;font-weight:400;src:local('Roboto Condensed'),local(RobotoCondensed-Regular),url(https://fonts.gstatic.com/s/robotocondensed/v13/Zd2E9abXLFGSr9G3YK2MsDcCYxVKuOcslAgPRMZ8RJE.woff2) format(""woff2"");unicode-range:U+0102-0103,U+1EA0-1EF1,U+20AB}@font-face{font-family:'Roboto Condensed';font-style:normal;font-weight:400;src:local('Roboto Condensed'),local(RobotoCondensed-Regular),url(https://fonts.gstatic.com/s/robotocondensed/v13/Zd2E9abXLFGSr9G3YK2MsNKDSU5nPdoBdru70FiVyb0.woff2) format(""woff2"");unicode-range:U+0100-024F,U+1E00-1EFF,U+20A0-20AB,U+20AD-20CF,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Roboto Condensed';font-style:normal;font-weight:400;src:local('Roboto Condensed'),local(RobotoCondensed-Regular),url(https://fonts.gstatic.com/s/robotocondensed/v13/Zd2E9abXLFGSr9G3YK2MsH4vxAoi6d67T_UKWi0EoHQ.woff2) format(""woff2"");unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2212,U+2215,U+E0FF,U+EFFD,U+F000}@font-face{font-family:'Roboto Condensed';font-style:normal;font-weight:700;src:local('Roboto Condensed Bold'),local(RobotoCondensed-Bold),url(https://fonts.gstatic.com/s/robotocondensed/v13/b9QBgL0iMZfDSpmcXcE8nBYyuMfI6pbvLqniwcbLofP2Ot9t5h1GRSTIE78Whtoh.woff2) format(""woff2"");unicode-range:U+0460-052F,U+20B4,U+2DE0-2DFF,U+A640-A69F}@font-face{font-family:'Roboto Condensed';font-style:normal;font-weight:700;src:local('Roboto Condensed Bold'),local(RobotoCondensed-Bold),url(https://fonts.gstatic.com/s/robotocondensed/v13/b9QBgL0iMZfDSpmcXcE8nIT75Viso9fCesWUO0IzDUX2Ot9t5h1GRSTIE78Whtoh.woff2) format(""woff2"");unicode-range:U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Roboto Condensed';font-style:normal;font-weight:700;src:local('Roboto Condensed Bold'),local(RobotoCondensed-Bold),url(https://fonts.gstatic.com/s/robotocondensed/v13/b9QBgL0iMZfDSpmcXcE8nL8EBb1YR1F8PhofwHtObrz2Ot9t5h1GRSTIE78Whtoh.woff2) format(""woff2"");unicode-range:U+1F00-1FFF}@font-face{font-family:'Roboto Condensed';font-style:normal;font-weight:700;src:local('Roboto Condensed Bold'),local(RobotoCondensed-Bold),url(https://fonts.gstatic.com/s/robotocondensed/v13/b9QBgL0iMZfDSpmcXcE8nAro84VToOve-uw23YSmBS72Ot9t5h1GRSTIE78Whtoh.woff2) format(""woff2"");unicode-range:U+0370-03FF}@font-face{font-family:'Roboto Condensed';font-style:normal;font-weight:700;src:local('Roboto Condensed Bold'),local(RobotoCondensed-Bold),url(https://fonts.gstatic.com/s/robotocondensed/v13/b9QBgL0iMZfDSpmcXcE8nACS0ZgDg4kY8EFPTGlvyHP2Ot9t5h1GRSTIE78Whtoh.woff2) format(""woff2"");unicode-range:U+0102-0103,U+1EA0-1EF1,U+20AB}@font-face{font-family:'Roboto Condensed';font-style:normal;font-weight:700;src:local('Roboto Condensed Bold'),local(RobotoCondensed-Bold),url(https://fonts.gstatic.com/s/robotocondensed/v13/b9QBgL0iMZfDSpmcXcE8nGPMCwzADhgEiQ8LZ-01G1L2Ot9t5h1GRSTIE78Whtoh.woff2) format(""woff2"");unicode-range:U+0100-024F,U+1E00-1EFF,U+20A0-20AB,U+20AD-20CF,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Roboto Condensed';font-style:normal;font-weight:700;src:local('Roboto Condensed Bold'),local(RobotoCondensed-Bold),url(https://fonts.gstatic.com/s/robotocondensed/v13/b9QBgL0iMZfDSpmcXcE8nPX2or14QGUHgbhSBV1Go0E.woff2) format(""woff2"");unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2212,U+2215,U+E0FF,U+EFFD,U+F000}&lt;/style&gt;


Can be seen here.
",eclipsis,https://stackoverflow.com/users/1350424,"You only have definitions for woff2. This probably will not only not work on mobile but as well not in many other Desktop browsers. For example, Internet Explorer requires eot, Safari requires ttf. I think only Chrome uses woff2. Depending on which mobile browser you use you need a different font format. I believe Safari on IOS even uses svg!

I think what you did is, you opened the CSS file Google Fonts gave you and simply copied the content. The problem is, this CSS depends on the User Agent. It has different content with the correct font format for the Browser which requested.

You could use a tool like http://localfont.com to generate the correct CSS with all font formats. They have different formats for downloading fonts as well only generating CSS for inline use.
",udondan,https://stackoverflow.com/users/2753241,http://stackoverflow.com/questions/28490837/google-fonts-loading-on-desktop-but-not-on-mobile,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.7777777777777778,0.0,0.6666666666666666,1.0,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,0.8888888888888888,0.9333333333333332,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.7777777777777778,"Google fonts loaded on the desktop, not mobile?","Per Google PageSpeed's recommendation, I inlined much of my CSS. Previously, I had minified all of my CSS through W3 Total Cache, but now I inlined much of my CSS, plus all of the CSS that controls Google Fonts. 

Now Google Fonts aren't appearing on mobile devices, but they do appear on desktops. Any reason why this is the case? The mobile screen cap here shows the fonts not loading.

&lt;style&gt;@font-face{font-family:'Pathway Gothic One';font-style:normal;font-weight:400;src:local('Pathway Gothic One'),local(PathwayGothicOne-Regular),url(https://fonts.gstatic.com/s/pathwaygothicone/v4/Lqv9ztoTUV8Q0FmQZzPqaA6LSHyyJAN5JIFgwWnj0Az3rGVtsTkPsbDajuO5ueQw.woff2) format(""woff2"");unicode-range:U+0100-024F,U+1E00-1EFF,U+20A0-20AB,U+20AD-20CF,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Pathway Gothic One';font-style:normal;font-weight:400;src:local('Pathway Gothic One'),local(PathwayGothicOne-Regular),url(https://fonts.gstatic.com/s/pathwaygothicone/v4/Lqv9ztoTUV8Q0FmQZzPqaHT0-GP0evTJPrdxn7U7ioo.woff2) format(""woff2"");unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2212,U+2215,U+E0FF,U+EFFD,U+F000}@font-face{font-family:'Quicksand';font-style:normal;font-weight:400;src:local('Quicksand Regular'),local(Quicksand-Regular),url(https://fonts.gstatic.com/s/quicksand/v5/sKd0EMYPAh5PYCRKSryvW5Bw1xU1rKptJj_0jans920.woff2) format(""woff2"");unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2212,U+2215,U+E0FF,U+EFFD,U+F000}@font-face{font-family:'Roboto Condensed';font-style:normal;font-weight:400;src:local('Roboto Condensed'),local(RobotoCondensed-Regular),url(https://fonts.gstatic.com/s/robotocondensed/v13/Zd2E9abXLFGSr9G3YK2MsIPxuqWfQuZGbz5Rz4Zu1gk.woff2) format(""woff2"");unicode-range:U+0460-052F,U+20B4,U+2DE0-2DFF,U+A640-A69F}@font-face{font-family:'Roboto Condensed';font-style:normal;font-weight:400;src:local('Roboto Condensed'),local(RobotoCondensed-Regular),url(https://fonts.gstatic.com/s/robotocondensed/v13/Zd2E9abXLFGSr9G3YK2MsENRpQQ4njX3CLaCqI4awdk.woff2) format(""woff2"");unicode-range:U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Roboto Condensed';font-style:normal;font-weight:400;src:local('Roboto Condensed'),local(RobotoCondensed-Regular),url(https://fonts.gstatic.com/s/robotocondensed/v13/Zd2E9abXLFGSr9G3YK2MsET2KMEyTWEzJqg9U8VS8XM.woff2) format(""woff2"");unicode-range:U+1F00-1FFF}@font-face{font-family:'Roboto Condensed';font-style:normal;font-weight:400;src:local('Roboto Condensed'),local(RobotoCondensed-Regular),url(https://fonts.gstatic.com/s/robotocondensed/v13/Zd2E9abXLFGSr9G3YK2MsMH5J2QbmuFthYTFOnnSRco.woff2) format(""woff2"");unicode-range:U+0370-03FF}@font-face{font-family:'Roboto Condensed';font-style:normal;font-weight:400;src:local('Roboto Condensed'),local(RobotoCondensed-Regular),url(https://fonts.gstatic.com/s/robotocondensed/v13/Zd2E9abXLFGSr9G3YK2MsDcCYxVKuOcslAgPRMZ8RJE.woff2) format(""woff2"");unicode-range:U+0102-0103,U+1EA0-1EF1,U+20AB}@font-face{font-family:'Roboto Condensed';font-style:normal;font-weight:400;src:local('Roboto Condensed'),local(RobotoCondensed-Regular),url(https://fonts.gstatic.com/s/robotocondensed/v13/Zd2E9abXLFGSr9G3YK2MsNKDSU5nPdoBdru70FiVyb0.woff2) format(""woff2"");unicode-range:U+0100-024F,U+1E00-1EFF,U+20A0-20AB,U+20AD-20CF,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Roboto Condensed';font-style:normal;font-weight:400;src:local('Roboto Condensed'),local(RobotoCondensed-Regular),url(https://fonts.gstatic.com/s/robotocondensed/v13/Zd2E9abXLFGSr9G3YK2MsH4vxAoi6d67T_UKWi0EoHQ.woff2) format(""woff2"");unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2212,U+2215,U+E0FF,U+EFFD,U+F000}@font-face{font-family:'Roboto Condensed';font-style:normal;font-weight:700;src:local('Roboto Condensed Bold'),local(RobotoCondensed-Bold),url(https://fonts.gstatic.com/s/robotocondensed/v13/b9QBgL0iMZfDSpmcXcE8nBYyuMfI6pbvLqniwcbLofP2Ot9t5h1GRSTIE78Whtoh.woff2) format(""woff2"");unicode-range:U+0460-052F,U+20B4,U+2DE0-2DFF,U+A640-A69F}@font-face{font-family:'Roboto Condensed';font-style:normal;font-weight:700;src:local('Roboto Condensed Bold'),local(RobotoCondensed-Bold),url(https://fonts.gstatic.com/s/robotocondensed/v13/b9QBgL0iMZfDSpmcXcE8nIT75Viso9fCesWUO0IzDUX2Ot9t5h1GRSTIE78Whtoh.woff2) format(""woff2"");unicode-range:U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Roboto Condensed';font-style:normal;font-weight:700;src:local('Roboto Condensed Bold'),local(RobotoCondensed-Bold),url(https://fonts.gstatic.com/s/robotocondensed/v13/b9QBgL0iMZfDSpmcXcE8nL8EBb1YR1F8PhofwHtObrz2Ot9t5h1GRSTIE78Whtoh.woff2) format(""woff2"");unicode-range:U+1F00-1FFF}@font-face{font-family:'Roboto Condensed';font-style:normal;font-weight:700;src:local('Roboto Condensed Bold'),local(RobotoCondensed-Bold),url(https://fonts.gstatic.com/s/robotocondensed/v13/b9QBgL0iMZfDSpmcXcE8nAro84VToOve-uw23YSmBS72Ot9t5h1GRSTIE78Whtoh.woff2) format(""woff2"");unicode-range:U+0370-03FF}@font-face{font-family:'Roboto Condensed';font-style:normal;font-weight:700;src:local('Roboto Condensed Bold'),local(RobotoCondensed-Bold),url(https://fonts.gstatic.com/s/robotocondensed/v13/b9QBgL0iMZfDSpmcXcE8nACS0ZgDg4kY8EFPTGlvyHP2Ot9t5h1GRSTIE78Whtoh.woff2) format(""woff2"");unicode-range:U+0102-0103,U+1EA0-1EF1,U+20AB}@font-face{font-family:'Roboto Condensed';font-style:normal;font-weight:700;src:local('Roboto Condensed Bold'),local(RobotoCondensed-Bold),url(https://fonts.gstatic.com/s/robotocondensed/v13/b9QBgL0iMZfDSpmcXcE8nGPMCwzADhgEiQ8LZ-01G1L2Ot9t5h1GRSTIE78Whtoh.woff2) format(""woff2"");unicode-range:U+0100-024F,U+1E00-1EFF,U+20A0-20AB,U+20AD-20CF,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Roboto Condensed';font-style:normal;font-weight:700;src:local('Roboto Condensed Bold'),local(RobotoCondensed-Bold),url(https://fonts.gstatic.com/s/robotocondensed/v13/b9QBgL0iMZfDSpmcXcE8nPX2or14QGUHgbhSBV1Go0E.woff2) format(""woff2"");unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2212,U+2215,U+E0FF,U+EFFD,U+F000}&lt;/style&gt;


Can be seen here.
","You only have definitions for woff2. This probably will not only not work on mobile but as well not in many other Desktop browsers. For example, Internet Explorer requires eot, Safari requires ttf. I think only Chrome uses woff2. Depending on which mobile browser you use you need a different font format. I believe Safari on IOS even uses svg!

I think what you did is, you opened the CSS file Google Fonts gave you and simply copied the content. The problem is, this CSS depends on the User Agent. It has different content with the correct font format for the Browser which requested.

You could use a tool like http://localfont.com to generate the correct CSS with all font formats. They have different formats for downloading fonts as well only generating CSS for inline use.
"
186,186,294,When should a supervisor be a co-author?,"What are people's views on this?  To be specific: suppose a PhD student has produced a piece of original mathematical research. Suppose that student's supervisor suggested the problem, and gave a few helpful comments, but otherwise did not contribute to the work.  Should that supervisor still be named as a co-author, or would an acknowledgment suffice?

I am interested in two aspects of this. Firstly the moral/etiquette aspect: do you consider it bad form for a student not to name their supervisor?  Or does it depend on that supervisor's input?  And secondly, the practical, career-advancing aspect: which is better, for a student to have a well-known name on his or her paper (and hence more chance of it being noticed/published), or to have a sole-authored piece of work under their belt to hopefully increase their chances of being offered a good post-doc position?

[To clarify: original question asked by MrB ]
",MrB,https://mathoverflow.net/users/2189,"First of all, this question must be decided by the adviser, not by the student.
The student must accept any decision if his/her adviser.

Most advisers that I know (mathematicians) will not co-author a paper with a student, if
the contribution of a student is substantial. But this depends on a person of course,
in particular on the adviser's own experience when s/he was a student.

For example, the first paper of Ahlfors was not written by himself (though the main idea was his). As a result, Ahlfors established a rule to never co-author his PhD student paper.
(He mentions this is his comments to his first paper in his Collected papers).

Myself, I try to follow this rule, but exceptions are possible.
",Alexandre Eremenko,https://mathoverflow.net/users/25510,http://mathoverflow.net/questions/57337,SCIENCE,mathoverflow.net,0.8888888888888888,0.3333333333333333,0.3333333333333333,1.0,0.6666666666666666,0.0,0.6666666666666666,0.5,1.0,0.0,1.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.6666666666666666,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,0.8333333333333334,0.7,0.3333333333333333,0.0,1.0,0.6666666666666666,When should a supervisor become a coauthor?,"What are people's views on this?  To be specific: suppose a PhD student has produced a piece of original mathematical research. Suppose that student's supervisor suggested the problem, and gave a few helpful comments, but otherwise did not contribute to the work.  Should that supervisor still be named as a co-author, or would an acknowledgment suffice?

I am interested in two aspects of this. Firstly the moral/etiquette aspect: do you consider it bad form for a student not to name their supervisor?  Or does it depend on that supervisor's input?  And secondly, the practical, career-advancing aspect: which is better, for a student to have a well-known name on his or her paper (and hence more chance of it being noticed/published), or to have a sole-authored piece of work under their belt to hopefully increase their chances of being offered a good post-doc position?

[To clarify: original question asked by MrB ]
","First of all, this question must be decided by the adviser, not by the student.
The student must accept any decision if his/her adviser.

Most advisers that I know (mathematicians) will not co-author a paper with a student, if
the contribution of a student is substantial. But this depends on a person of course,
in particular on the adviser's own experience when s/he was a student.

For example, the first paper of Ahlfors was not written by himself (though the main idea was his). As a result, Ahlfors established a rule to never co-author his PhD student paper.
(He mentions this is his comments to his first paper in his Collected papers).

Myself, I try to follow this rule, but exceptions are possible.
"
2162,2162,3447,Encoding of Umlauts while importing into R tables,"I need to join two tables on the colum name. They come from different excel spreadsheets which I didn't create. I imported both sheets into R tables using the function read.xls from the gdata package.

Sometimes the names contains umlauts and other accents. They appear identical within the excel sheets but when I import them into R they are not the same. Hence my join doesn't join. I join using the sqldf function.

As an example : I see Lück in the two spreadsheets. In table1 of R this appears as L\374ck whereas in table2 it appears as L\303\274ck.

How can I best solve this problem? Is there a way to force an encoding when data is imported? Or should one try to force the comparison of strings in a different way?
",Geoff,https://stackoverflow.com/users/1154853,"It is an encoding problem.
For example :

 x1=  ""L\374ck""
 x2 = ""L\303\274ck""
 identical(iconv(x2,""UTF-8"",""UTF-8""),x1)
 [1] ""TRUE""


So you can try this for example before applying merge : 

 df2name &lt;- iconv(df2$name,'UTF-8','UTF-8')

",agstudy,https://stackoverflow.com/users/1838509,http://stackoverflow.com/questions/27676458/encoding-of-umlauts-while-importing-into-r-tables,STACKOVERFLOW,stackoverflow.com,1.0,0.3333333333333333,0.0,1.0,1.0,1.0,0.5,0.6666666666666666,1.0,0.0,0.5,1.0,0.0,0.0,0.0,0.0,0.5,0.5,0.0,0.0,1.0,0.8333333333333334,0.6666666666666666,1.0,1.0,0.9,1.0,0.0,0.5,0.8333333333333334,Vowel diacritic code when importing r table,"I need to join two tables on the colum name. They come from different excel spreadsheets which I didn't create. I imported both sheets into R tables using the function read.xls from the gdata package.

Sometimes the names contains umlauts and other accents. They appear identical within the excel sheets but when I import them into R they are not the same. Hence my join doesn't join. I join using the sqldf function.

As an example : I see Lück in the two spreadsheets. In table1 of R this appears as L\374ck whereas in table2 it appears as L\303\274ck.

How can I best solve this problem? Is there a way to force an encoding when data is imported? Or should one try to force the comparison of strings in a different way?
","It is an encoding problem.
For example :

 x1=  ""L\374ck""
 x2 = ""L\303\274ck""
 identical(iconv(x2,""UTF-8"",""UTF-8""),x1)
 [1] ""TRUE""


So you can try this for example before applying merge : 

 df2name &lt;- iconv(df2$name,'UTF-8','UTF-8')

"
4049,4049,6463,Is there a list of punctuation commands for iPad dictation?,"I'm sure Apple has published something similar for Siri, but now that the iPad dictation is out, where can I find a list of commands for dictation? Can I do things like hit the enter key, or type symbols? I'm obviously able to enter periods and question mark's, but beyond that I'm not so sure. So, how can I type out the words question mark Without actually getting a question mark?
",Moshe,https://apple.stackexchange.com/users/638,"Siri dictation is never going to be 100% accurate and the easiest way to get the result you want may be to edit the text by hand after you've dictated the body of the message.

Jim Rhoades provides a useful list of Siri dictation commands.
",jaberg,https://apple.stackexchange.com/users/11791,http://apple.stackexchange.com/questions/44555/is-there-a-list-of-punctuation-commands-for-ipad-dictation,TECHNOLOGY,apple.stackexchange.com,1.0,0.6666666666666666,0.0,0.6666666666666666,1.0,1.0,0.5555555555555556,0.6666666666666666,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,1.0,0.8888888888888888,0.9,0.6666666666666666,0.3333333333333333,0.3333333333333333,1.0,Is there a list of punctuation commands for iPad dictation?,"I believe Apple has released some similar Siri versions, but now iPad dictation has been released, where can I find a list of dictation commands? Can I press enter or type a symbol? Obviously I can get into full stop and question mark, but I'm not sure. So, how can I type a question mark without getting a question mark?","Siri dictation is never going to be 100% accurate and the easiest way to get the result you want may be to edit the text by hand after you've dictated the body of the message.

Jim Rhoades provides a useful list of Siri dictation commands.
"
1842,1842,2923,"If hydrogen bonding in water was weaker, what happens to H+ ion concentration?","
  Water ionization becomes much less evident if the hydrogen bonds are just a few percent stronger but pure water contains considerably more $\ce{H+}$ ions if they are few percent weaker.


I found this line in some article. You can even copy/paste this line on search bar of Google. I didn't understood the latter part of this statement which is ""but pure water contains considerably more $\ce{H+}$ ions if they are few percent weaker"". The author is indicating to which of the following three situations?


only $\ce{H+}$ ion concentration will increase 
both $\ce{H+}$ and $\ce{OH-}$ will increase 
$\ce{H+}$ will increase and $\ce{OH-}$ will decrease that is the equilibrium constant remains same. 

",DSinghvi,https://chemistry.stackexchange.com/users/5424,"The article http://arxiv.org/ftp/arxiv/papers/0706/0706.1355.pdf (no evidence of peer review) is discussing how changes to the properties of water would alter life.  

If the hydrogen bonding in water was stronger, there would be less ionization (less H+ and less OH-).

If the hydrogen bonding in water was weaker, there would be more ionization (more H+ and more OH-).
",DavePhD,https://chemistry.stackexchange.com/users/5160,http://chemistry.stackexchange.com/questions/22446/if-hydrogen-bonding-in-water-was-weaker-what-happens-to-h-ion-concentration,SCIENCE,chemistry.stackexchange.com,1.0,0.8888888888888888,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.5555555555555556,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8,0.3333333333333333,0.0,1.0,1.0,"If the hydrogen bond in water is weak, what is the hydrogen ion concentration?","
  Water ionization becomes much less evident if the hydrogen bonds are just a few percent stronger but pure water contains considerably more $\ce{H+}$ ions if they are few percent weaker.


I found this line in some article. You can even copy/paste this line on search bar of Google. I didn't understood the latter part of this statement which is ""but pure water contains considerably more $\ce{H+}$ ions if they are few percent weaker"". The author is indicating to which of the following three situations?


only $\ce{H+}$ ion concentration will increase 
both $\ce{H+}$ and $\ce{OH-}$ will increase 
$\ce{H+}$ will increase and $\ce{OH-}$ will decrease that is the equilibrium constant remains same. 

","The article http://arxiv.org/ftp/arxiv/papers/0706/0706.1355.pdf (no evidence of peer review) is discussing how changes to the properties of water would alter life.  

If the hydrogen bonding in water was stronger, there would be less ionization (less H+ and less OH-).

If the hydrogen bonding in water was weaker, there would be more ionization (more H+ and more OH-).
"
2252,2252,3590,Can the update manager download only a single package at a time?,"I need the update manager to only download a single package at a time and not try to download multiple packages at once.

My slow internet cannot handle multiple connections; slows the download to a crawl and some packages will reset themselves halfway through when they time-out.

EDIT

When using apt-get update multiple repositories get checked:


When using apt-get upgrade multiple packages are downloaded:

",SaultDon,https://askubuntu.com/users/22554,"You have two options here. 

1- Use the Queue-Mode configuration option. The default, ""host"", creates one outgoing connection for each host. If you set it to ""access"" it will create one connection per URI type (which I understand to mean, one for http, one for ftp, and so on - since most connections are http, this means it'll access each server sequentially).

One way to do this that will also apply to update-manager is to:

echo 'Acquire::Queue-Mode ""access"";' &gt;/etc/apt/apt.conf.d/75download


if you want to try it with apt-get once to see if it helps:

apt-get -o Acquire::Queue-mode=access update


2- Use the Acquire::http::Dl-Limit option, this is similarly to reduce the bandwidth used to something your connection can handle (and as per the manpage, ""this option implicit deactivates the download from multiple servers at the same time"").

echo 'Acquire::http::Dl-Limit ""70"";' &gt;/etc/apt/apt.conf.d/75download


or

apt-get -o Acquire::http::Dl-Limit=70 update

",roadmr,https://askubuntu.com/users/30589,http://askubuntu.com/questions/88731/can-the-update-manager-download-only-a-single-package-at-a-time,TECHNOLOGY,askubuntu.com,1.0,0.8888888888888888,0.0,1.0,1.0,1.0,0.7777777777777778,0.4444444444444444,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,0.8888888888888888,Can update manager download only one package at a time?,"I need the update manager to only download a single package at a time and not try to download multiple packages at once.

My slow internet cannot handle multiple connections; slows the download to a crawl and some packages will reset themselves halfway through when they time-out.

EDIT

When using apt-get update multiple repositories get checked:


When using apt-get upgrade multiple packages are downloaded:

","You have two options here. 

1- Use the Queue-Mode configuration option. The default, ""host"", creates one outgoing connection for each host. If you set it to ""access"" it will create one connection per URI type (which I understand to mean, one for http, one for ftp, and so on - since most connections are http, this means it'll access each server sequentially).

One way to do this that will also apply to update-manager is to:

echo 'Acquire::Queue-Mode ""access"";' &gt;/etc/apt/apt.conf.d/75download


if you want to try it with apt-get once to see if it helps:

apt-get -o Acquire::Queue-mode=access update


2- Use the Acquire::http::Dl-Limit option, this is similarly to reduce the bandwidth used to something your connection can handle (and as per the manpage, ""this option implicit deactivates the download from multiple servers at the same time"").

echo 'Acquire::http::Dl-Limit ""70"";' &gt;/etc/apt/apt.conf.d/75download


or

apt-get -o Acquire::http::Dl-Limit=70 update

"
2551,2551,4062,How to identify if sentence is passive Voice or Indicative sentence?,"Examples: 


  ""One car was parked outside of the gate."" 
  ""Your work volume is increased or not""
  ""He was arrested""
  ""She was raped""
  ""After accident he was taken to hospital""
  ""He was informed about this""
  “My heart was broken”


All above statements can be in the stative form if we do not mentioned the agent.
But if we use the agent i.e. By Driver, By Boss,  By Police, By  boyfriend, By  friend, By  father, By  husband respectively, then sentence become as passive voice.

My questions are 
a) How to quickly make out whether a sentence is in the passive voice or just a simple sentence (Stative)?

B) If i use had been in above sentence does it mean the same?
",user4084,https://ell.stackexchange.com/users/4084,"You said ""if we use the agent, the sentence becomes passive voice"".  I have to disagree.  In every one of your examples, the subject of the verb is the patient of the action.  Regardless of whether the agent is mentioned, those statements employ the passive voice.

You're asking how to distinguish something that doesn't need to be distinguished.  The question of passive vs. active voice is completely different than the question of stative vs. dynamic verbs -- in the same way that the question of how curly your hair is happens to be completely different than the question of how dark your hair is.

In an active voice construction, the subject causes the action.  In a passive voice construction, the subject receives the action.  It's easy to see that all of your sentences are passive voice constructions because its easy to find the active voice equivalents:

Someone parked the car. 
Something increased your work volume. 
Someone arrested him.


and so on.

Although the stative vs. dynamic distinction exists in English semantics, it isn't present in English grammar.  One rule of thumb is that stative verbs do not work well when employing the continuous aspect.  For example, ""I am knowing the answer"" is a poorly-formed sentence because the verb to know is stative.  It seems that every one of your passive voice examples uses a dynamic verb.

One car was being parked outside the gate when I left.
Your work volume is being increased during the holidays.
He was being arrested while I calmly walked away.


and so on.

A stative verb can be used in either the active or the passive voice:

My manager knows me to be an excellent employee.
I am known to be an excellent employee.


A dynamic verb can be used in either the active or the passive voice:

I parked the car outside the gate.
The car was parked outside the gate.


So, how do you distinguish between passive and stative?  You don't.  You distinguish between active and passive.  You distinguish between dynamic and stative.  You do those two things separately.  They are not related to each other.

&nbsp;



Now, as to your follow-up question, let's use the dynamic verb to park in the passive voice and indicative mode:

The car was parked -- past tense, indefinite aspect
The car is parked -- present tense, indefinite aspect
The car will be parked -- future tense, indefinite aspect

The car had been parked -- past tense, perfect aspect
The car has been parked -- present tense, perfect aspect
The car will have been parked -- future tense, perfect aspect


Does the meaning change?  Yes.  Aspect carries a different kind of meaning than tense, but both aspect and tense carry meaning.  Tense has to do with location in time.  Aspect has to do with a relationship with time.  Often tense and aspect are taught as a single, combined thing, but I find them easier to understand when they are examined as separate properties.

Changing the aspect does not change the tense.  Changing the aspect does not change the voice.  Changing the aspect does not change the nature of the verb, whether stative or dynamic.  

Because the perfect aspect has an explicit relationship with time, it makes the most sense when the time frame is also made explicit, as in ""The car has been parked there for several weeks"" or ""The car had been parked there for a month before anyone noticed it.""

&nbsp;

Whether a verb is stative or dynamic has very little impact on English grammar.  Certain verb forms don't make sense for stative verbs, and that's about it.  The properties of voice, tense, aspect and mode have a great deal of impact.  Changing any one of those requires changing something about the verb's form.



Let me see if I can clearly summarize all of that.


Which of the example sentences are passive voice?  All of them. 
Which of them are indicative sentences?  All of them. 
Which can be interpreted as having a participial subject complement?  All of them.
Which are stative?  None of them.   


Most of those are unrelated items. One pair is an identity.  The passive voice construction is a subset of the participial subject complement construction.
",Gary Botnovcan,https://ell.stackexchange.com/users/12283,http://ell.stackexchange.com/questions/39139/how-to-identify-if-sentence-is-passive-voice-or-indicative-sentence,CULTURE,ell.stackexchange.com,0.8888888888888888,0.7777777777777778,0.3333333333333333,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.8888888888888888,0.3333333333333333,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,0.0,0.8888888888888888,0.7777777777777778,0.8333333333333334,1.0,0.8888888888888888,1.0,0.3333333333333333,0.0,1.0,1.0,How to recognize whether a sentence is a passive sentence or an indicative sentence?,"Examples: 


  ""One car was parked outside of the gate."" 
  ""Your work volume is increased or not""
  ""He was arrested""
  ""She was raped""
  ""After accident he was taken to hospital""
  ""He was informed about this""
  “My heart was broken”


All above statements can be in the stative form if we do not mentioned the agent.
But if we use the agent i.e. By Driver, By Boss,  By Police, By  boyfriend, By  friend, By  father, By  husband respectively, then sentence become as passive voice.

My questions are 
a) How to quickly make out whether a sentence is in the passive voice or just a simple sentence (Stative)?

B) If i use had been in above sentence does it mean the same?
","You said ""if we use the agent, the sentence becomes passive voice"".  I have to disagree.  In every one of your examples, the subject of the verb is the patient of the action.  Regardless of whether the agent is mentioned, those statements employ the passive voice.

You're asking how to distinguish something that doesn't need to be distinguished.  The question of passive vs. active voice is completely different than the question of stative vs. dynamic verbs -- in the same way that the question of how curly your hair is happens to be completely different than the question of how dark your hair is.

In an active voice construction, the subject causes the action.  In a passive voice construction, the subject receives the action.  It's easy to see that all of your sentences are passive voice constructions because its easy to find the active voice equivalents:

Someone parked the car. 
Something increased your work volume. 
Someone arrested him.


and so on.

Although the stative vs. dynamic distinction exists in English semantics, it isn't present in English grammar.  One rule of thumb is that stative verbs do not work well when employing the continuous aspect.  For example, ""I am knowing the answer"" is a poorly-formed sentence because the verb to know is stative.  It seems that every one of your passive voice examples uses a dynamic verb.

One car was being parked outside the gate when I left.
Your work volume is being increased during the holidays.
He was being arrested while I calmly walked away.


and so on.

A stative verb can be used in either the active or the passive voice:

My manager knows me to be an excellent employee.
I am known to be an excellent employee.


A dynamic verb can be used in either the active or the passive voice:

I parked the car outside the gate.
The car was parked outside the gate.


So, how do you distinguish between passive and stative?  You don't.  You distinguish between active and passive.  You distinguish between dynamic and stative.  You do those two things separately.  They are not related to each other.

&nbsp;



Now, as to your follow-up question, let's use the dynamic verb to park in the passive voice and indicative mode:

The car was parked -- past tense, indefinite aspect
The car is parked -- present tense, indefinite aspect
The car will be parked -- future tense, indefinite aspect

The car had been parked -- past tense, perfect aspect
The car has been parked -- present tense, perfect aspect
The car will have been parked -- future tense, perfect aspect


Does the meaning change?  Yes.  Aspect carries a different kind of meaning than tense, but both aspect and tense carry meaning.  Tense has to do with location in time.  Aspect has to do with a relationship with time.  Often tense and aspect are taught as a single, combined thing, but I find them easier to understand when they are examined as separate properties.

Changing the aspect does not change the tense.  Changing the aspect does not change the voice.  Changing the aspect does not change the nature of the verb, whether stative or dynamic.  

Because the perfect aspect has an explicit relationship with time, it makes the most sense when the time frame is also made explicit, as in ""The car has been parked there for several weeks"" or ""The car had been parked there for a month before anyone noticed it.""

&nbsp;

Whether a verb is stative or dynamic has very little impact on English grammar.  Certain verb forms don't make sense for stative verbs, and that's about it.  The properties of voice, tense, aspect and mode have a great deal of impact.  Changing any one of those requires changing something about the verb's form.



Let me see if I can clearly summarize all of that.


Which of the example sentences are passive voice?  All of them. 
Which of them are indicative sentences?  All of them. 
Which can be interpreted as having a participial subject complement?  All of them.
Which are stative?  None of them.   


Most of those are unrelated items. One pair is an identity.  The passive voice construction is a subset of the participial subject complement construction.
"
447,447,697,Java read pptx file,"Can someone help me how to read pptx file in java?i would prefer if this can be read with apache POI, i have been searched this tutorial but i can't find it.I've been successfully read the ppt file with this code :

try {
    FileInputStream fis = new FileInputStream(file);
    fs = new POIFSFileSystem(fis);
    HSLFSlideShow show = new HSLFSlideShow(fs);
    SlideShow ss = new SlideShow(show);
    Slide[] slides=ss.getSlides();
    for (int x = 0; x &lt; slides.length; x++) {
        System.out.println(""Slide = "" + (x + 1) + "" :"" + slides[x].getTitle());

        TextRun[] runs = slides[x].getTextRuns();
        for (int i = 0; i &lt; runs.length; i++) {
            TextRun run = runs[i];
            if (run.getRunType() == TextHeaderAtom.TITLE_TYPE) {
                System.out.println(""Slide title "" + (i + 1) + "": "" + run.getText());
            } else {
                System.out.println(""Slide text run "" + (i + 1) + "": ""  + run.getRunType() + "" : "" + run.getText());
            }
        }
    }
} catch (IOException ioe) {
    ioe.printStackTrace();
}


Can someone tell me what part of this code must be modified to read pptx file?
",user1290932,https://stackoverflow.com/users/1290932,"According to http://poi.apache.org/slideshow/index.html you need to use a separate set of classes to read OOXML .pptx files. There's example code in the cookbook: http://poi.apache.org/slideshow/xslf-cookbook.html
",Arne de Bruijn,https://stackoverflow.com/users/275998,http://stackoverflow.com/questions/10684526/java-read-pptx-file,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.4444444444444444,0.0,0.6666666666666666,1.0,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.6666666666666666,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,1.0,0.5555555555555556,1.0,1.0,0.7333333333333333,1.0,0.3333333333333333,0.3333333333333333,1.0,Java reading pptx file,"Can someone help me how to read pptx file in java?i would prefer if this can be read with apache POI, i have been searched this tutorial but i can't find it.I've been successfully read the ppt file with this code :

try {
    FileInputStream fis = new FileInputStream(file);
    fs = new POIFSFileSystem(fis);
    HSLFSlideShow show = new HSLFSlideShow(fs);
    SlideShow ss = new SlideShow(show);
    Slide[] slides=ss.getSlides();
    for (int x = 0; x &lt; slides.length; x++) {
        System.out.println(""Slide = "" + (x + 1) + "" :"" + slides[x].getTitle());

        TextRun[] runs = slides[x].getTextRuns();
        for (int i = 0; i &lt; runs.length; i++) {
            TextRun run = runs[i];
            if (run.getRunType() == TextHeaderAtom.TITLE_TYPE) {
                System.out.println(""Slide title "" + (i + 1) + "": "" + run.getText());
            } else {
                System.out.println(""Slide text run "" + (i + 1) + "": ""  + run.getRunType() + "" : "" + run.getText());
            }
        }
    }
} catch (IOException ioe) {
    ioe.printStackTrace();
}


Can someone tell me what part of this code must be modified to read pptx file?
","According to http://poi.apache.org/slideshow/index.html you need to use a separate set of classes to read OOXML .pptx files. There's example code in the cookbook: http://poi.apache.org/slideshow/xslf-cookbook.html
"
5491,5491,8714,What is the difference between drought resistant non-succulent plants and plants that cannot be allowed to dry out?,"What features make one plant able to withstand dry spells better than another with relatively similar structure? For instance, one of my Rudbeckias is wilting from drought at the moment, and an Oenothera next to it is not yet showing signs of dryness.

Or like jewelweed (Impatiens capensis), which wilts even while the soil is damp, in full sun, and ragweed (Ambrosia artemisiifolia), which will grow in very dry locations without being phased.

Is it caused by a faster transpiration rate in some plants than in others?
",J. Musser,https://biology.stackexchange.com/users/338,"Plants in drier conditions usually have reduced surface area, thick waxy cuticle covering the epidermis, reduced number of stomata, and water storage tissues that presides in its roots and leaves.

This means that even if the plants are similar, one of them might express more of one of the features shown above.
",user46725,https://biology.stackexchange.com/users/8279,http://biology.stackexchange.com/questions/19545/what-is-the-difference-between-drought-resistant-non-succulent-plants-and-plants,SCIENCE,biology.stackexchange.com,1.0,0.6666666666666666,0.0,1.0,1.0,1.0,0.5555555555555556,0.5555555555555556,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,0.8888888888888888,What's the difference between drought tolerant non fleshy plants and dry plants?,"What features make one plant able to withstand dry spells better than another with relatively similar structure? For instance, one of my Rudbeckias is wilting from drought at the moment, and an Oenothera next to it is not yet showing signs of dryness.

Or like jewelweed (Impatiens capensis), which wilts even while the soil is damp, in full sun, and ragweed (Ambrosia artemisiifolia), which will grow in very dry locations without being phased.

Is it caused by a faster transpiration rate in some plants than in others?
","Plants in dry conditions usually have a small surface area, a thick waxy cuticle covering the epidermis, a reduced number of pores, and water storage tissues that host their roots and leaves."
3986,3986,6364,Weren't there originally going to be nine Star Wars films?,"I seem to remember reading that there were going to be three trilogies originally in Star Wars, i.e. they would add episodes 7 - 9.

Was that ever the case? What happened to that plan?

Update: looks like that original plan might be back after all!
",Wikis,https://scifi.stackexchange.com/users/143,"Some fantastic answers here, but I thought I'd just add a little more detail, that I don't think has been included in any of the others. Firstly, as has already been said, STAR WARS was only ever one film. Vader wasn't Luke's father, Leia wasn't Luke's sister, no further films were planned.

Even the original 1977 opening crawl looked like this:



That's right. No ""Episode IV : A New Hope"".

It's difficult to remember now, but STAR WARS was HUGE. I mean TITANIC big. Adjusted for inflation it's actually still the second highest grossing movie of all-time (AVATAR is only number 14).

So Lucas and his friends set to work on expanding the universe, much like the Wachowski's did with THE MATRIX. Lucas's ""second in command"", from the beginning of his Hollywood career, was a man called Gary Kurtz. Kurtz produced Lucas's first ""Hollywood"" feature, AMERICAN GRAFITTI, which in itself was a big success (currently 44 on the highest grossing films of all time list), STAR WARS, and THE EMPIRE STRIKES BACK.

Lucas worked with Kurtz (and many others) on producing a rough outlines for approximately 8 more movies, making 9 in total. The EMPIRE STRIKES BACK was made according to this plan.

After the success of RAIDERS OF THE LOST ARK (the project Lucas put together with Steven Spielberg), Lucas decided that cinema-goers wanted more of a rollercoaster action movie, and so changed the 9 movie plan.

Kurtz and Lucas were at logger-heads over a lot of things. Some of them technical, some of them artistic. According to Kurtz they agreed they should go their separate ways before RETURN OF THE JEDI began, with Kurtz taking the opportunity to work with Jim Henson on THE DARK CRYSTAL.

However, since Kurtz was so intricately involved in the evolution of STAR WARS into something bigger, he's a great source. According to him, the outlines for the nine movies went like something this:


  
  EPISODE 1: Was to focus on the origins of the Jedi Knights and how they are initiated and trained
  EPISODE 2: Introduction and development of Obi-Wan Kenobi
  EPISODE 3: Introduction and life of Vader
  EPISODE 4: There were seven different drafts of the film. At one point, they pursued buying the rights to Hidden Fortress because of the strong similarities. At one point, Luke was a female, Han was Luke's brother, Luke's father was the one in prison (interesting point for some debates) and the film featured 40 wookies
  EPISODE 5: Once written, the screenplay of Empire is almost exactly what is seen on screen. The only cut scenes were those involving wampas in the rebel base (cut because of time and unsolved technical glitches) and about two minutes of Luke/Yoda Jedi training with no real dialog.
  EPISODE 6: Leia was to be elected ""Queen of her people"" leaving her isolated. Han was to die. Luke confronted Vader and went on with his life alone. Leia was not to be Luke's sister.
  EPISODE 7: Third trilogy was to focus on Luke's life as a Jedi, with very few details planned out.
  EPISODE 8: Luke's sister (not Leia) appears from another part of the galaxy.
  EPISODE 9: First appearance of the Emperor.
  


(I believe he went into greater detail in an issue of SFX magazine, but I've been unable to find a copy of the text on the internet... I bet it's there somewhere!)

There's also a great interview with Kurtz here, where he goes into a bit more detail:


  The one story thread [in Return of the Jedi] that got totally tossed out the window, which was really pretty important I think, was the one of Vader trying to convince Luke to join him to overthrow the Emperor. That together they had enough power that they could do that, and it wasn’t him saying I want to take over the world and be the evil leader, it was that transition. It was Vader saying, “I’m looking again at what I’ve done and where my life has gone and who I’ve served and, very much in the Samurai tradition, and saying if I can join forces with my son, who is just as strong as I am, that maybe we can make some amends.” So there was all of that going on in Jedi as well, that was supposed to go on. So the story was quite a bit more poignant and the ending was the coronation of Leia as the queen of what was left of her people, to take over the royal symbol. That meant she was then isolated from all of the rest and Luke went off then by himself. It was basically a kind of bittersweet ending. She’s not his sister that dropped in to wrap up everything neatly. His sister was someone else way over on the other side of the galaxy and she wasn’t going to show up until the next episode.


Read more: http://www.filmthreat.com/interviews/8/#ixzz2Fcy0psgB
",Django Reinhardt,https://scifi.stackexchange.com/users/4380,http://scifi.stackexchange.com/questions/1207/werent-there-originally-going-to-be-nine-star-wars-films,LIFE_ARTS,scifi.stackexchange.com,1.0,0.8888888888888888,0.0,1.0,1.0,1.0,0.8888888888888888,0.6666666666666666,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,1.0,0.0,1.0,0.7777777777777778,1.0,0.8888888888888888,1.0,1.0,0.0,0.0,1.0,1.0,Didn't there start with nine Star Wars movies?,"I seem to remember reading that there were going to be three trilogies originally in Star Wars, i.e. they would add episodes 7 - 9.

Was that ever the case? What happened to that plan?

Update: looks like that original plan might be back after all!
","Some fantastic answers here, but I thought I'd just add a little more detail, that I don't think has been included in any of the others. Firstly, as has already been said, STAR WARS was only ever one film. Vader wasn't Luke's father, Leia wasn't Luke's sister, no further films were planned.

Even the original 1977 opening crawl looked like this:



That's right. No ""Episode IV : A New Hope"".

It's difficult to remember now, but STAR WARS was HUGE. I mean TITANIC big. Adjusted for inflation it's actually still the second highest grossing movie of all-time (AVATAR is only number 14).

So Lucas and his friends set to work on expanding the universe, much like the Wachowski's did with THE MATRIX. Lucas's ""second in command"", from the beginning of his Hollywood career, was a man called Gary Kurtz. Kurtz produced Lucas's first ""Hollywood"" feature, AMERICAN GRAFITTI, which in itself was a big success (currently 44 on the highest grossing films of all time list), STAR WARS, and THE EMPIRE STRIKES BACK.

Lucas worked with Kurtz (and many others) on producing a rough outlines for approximately 8 more movies, making 9 in total. The EMPIRE STRIKES BACK was made according to this plan.

After the success of RAIDERS OF THE LOST ARK (the project Lucas put together with Steven Spielberg), Lucas decided that cinema-goers wanted more of a rollercoaster action movie, and so changed the 9 movie plan.

Kurtz and Lucas were at logger-heads over a lot of things. Some of them technical, some of them artistic. According to Kurtz they agreed they should go their separate ways before RETURN OF THE JEDI began, with Kurtz taking the opportunity to work with Jim Henson on THE DARK CRYSTAL.

However, since Kurtz was so intricately involved in the evolution of STAR WARS into something bigger, he's a great source. According to him, the outlines for the nine movies went like something this:


  
  EPISODE 1: Was to focus on the origins of the Jedi Knights and how they are initiated and trained
  EPISODE 2: Introduction and development of Obi-Wan Kenobi
  EPISODE 3: Introduction and life of Vader
  EPISODE 4: There were seven different drafts of the film. At one point, they pursued buying the rights to Hidden Fortress because of the strong similarities. At one point, Luke was a female, Han was Luke's brother, Luke's father was the one in prison (interesting point for some debates) and the film featured 40 wookies
  EPISODE 5: Once written, the screenplay of Empire is almost exactly what is seen on screen. The only cut scenes were those involving wampas in the rebel base (cut because of time and unsolved technical glitches) and about two minutes of Luke/Yoda Jedi training with no real dialog.
  EPISODE 6: Leia was to be elected ""Queen of her people"" leaving her isolated. Han was to die. Luke confronted Vader and went on with his life alone. Leia was not to be Luke's sister.
  EPISODE 7: Third trilogy was to focus on Luke's life as a Jedi, with very few details planned out.
  EPISODE 8: Luke's sister (not Leia) appears from another part of the galaxy.
  EPISODE 9: First appearance of the Emperor.
  


(I believe he went into greater detail in an issue of SFX magazine, but I've been unable to find a copy of the text on the internet... I bet it's there somewhere!)

There's also a great interview with Kurtz here, where he goes into a bit more detail:


  The one story thread [in Return of the Jedi] that got totally tossed out the window, which was really pretty important I think, was the one of Vader trying to convince Luke to join him to overthrow the Emperor. That together they had enough power that they could do that, and it wasn’t him saying I want to take over the world and be the evil leader, it was that transition. It was Vader saying, “I’m looking again at what I’ve done and where my life has gone and who I’ve served and, very much in the Samurai tradition, and saying if I can join forces with my son, who is just as strong as I am, that maybe we can make some amends.” So there was all of that going on in Jedi as well, that was supposed to go on. So the story was quite a bit more poignant and the ending was the coronation of Leia as the queen of what was left of her people, to take over the royal symbol. That meant she was then isolated from all of the rest and Luke went off then by himself. It was basically a kind of bittersweet ending. She’s not his sister that dropped in to wrap up everything neatly. His sister was someone else way over on the other side of the galaxy and she wasn’t going to show up until the next episode.


Read more: http://www.filmthreat.com/interviews/8/#ixzz2Fcy0psgB
"
2453,2453,3915,How svn checkout and checkin maven multimodule project,"im having a problem configuring my eclipse + maven + m2e + svn setup.

Lets assume i have project checked in svn trunk with this structure:

- Project-parent
- pom.xml
-- ModuleA
--- pom.xml (module A)
-- ModuleB
--- pom.xml (module B)


In my eclipse installation i have:

eclipse 3.7.2 64bit Java EE
subversive and svn connector for svn 1.6
m2e 1.1 from marketplace
m2e-subversive 0.13 (installed from alternative url)


My problem begins when i want to add new module to project. So i checkout project and modules by ""Import -> Check out Maven projects from SCM"". I create it with standard m2e 'Create new maven module' and after completing attributes my workspace looks like this:

- Project-parent (in trunk)
- pom.xml (in trunk)
-- ModuleA (in trunk)
--- pom.xml (in trunk)
-- ModuleB (in trunk)
--- pom.xml (in trunk)
-- ModuleC
--- pom.xml


Project builds with ""mvn clean install"". So I want to check it ModuleC in into svn but there is no option with functionality ""Share module into svn"".

Finally my questions:


How do you check in your new modules into existing repository? Is it through eclipse 'Share project' or external tool like Tortoise?
If its through Eclipse, do you automatically have 'connection' between module project and svn (by connection i mean annotation on project about svn url and current revision)
When you have 'connection' in your case, can you chage something in commited ModuleC and see 'dirty' svn marker on Project-parent?
How to achieve such connection manually? The only way i could do it is through deleting all projects and again performing ""Check out Maven projects from SCM"" and picking all projects again.
When you create submodule sceleton in different location than workspace and then check it into svn, how to import it back to workspace and to m2e from svn?

",ljader,https://stackoverflow.com/users/498096,"You must also mount the main project in eclipse, the parent of the module. Then, use this project to check in the new module as you are doing for any change set. This project is only used for SVN synchronization purpose. For your developments, use the module projects.

For your last question, this is a maven constraint to have its sub module below the parent project. You won't be able (at least not easily) to create a module somewhere, check it in below the parent and then checkout the whole project with the new module.

Try to keep it simple. 

Use the parent project when you want to synchronize new modules.

HIH
M.
",poussma,https://stackoverflow.com/users/1517816,http://stackoverflow.com/questions/11629993/how-svn-checkout-and-checkin-maven-multimodule-project,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.6666666666666666,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.0,0.3333333333333333,0.8888888888888888,How SVN checks in Maven multimodal projects,"im having a problem configuring my eclipse + maven + m2e + svn setup.

Lets assume i have project checked in svn trunk with this structure:

- Project-parent
- pom.xml
-- ModuleA
--- pom.xml (module A)
-- ModuleB
--- pom.xml (module B)


In my eclipse installation i have:

eclipse 3.7.2 64bit Java EE
subversive and svn connector for svn 1.6
m2e 1.1 from marketplace
m2e-subversive 0.13 (installed from alternative url)


My problem begins when i want to add new module to project. So i checkout project and modules by ""Import -> Check out Maven projects from SCM"". I create it with standard m2e 'Create new maven module' and after completing attributes my workspace looks like this:

- Project-parent (in trunk)
- pom.xml (in trunk)
-- ModuleA (in trunk)
--- pom.xml (in trunk)
-- ModuleB (in trunk)
--- pom.xml (in trunk)
-- ModuleC
--- pom.xml


Project builds with ""mvn clean install"". So I want to check it ModuleC in into svn but there is no option with functionality ""Share module into svn"".

Finally my questions:


How do you check in your new modules into existing repository? Is it through eclipse 'Share project' or external tool like Tortoise?
If its through Eclipse, do you automatically have 'connection' between module project and svn (by connection i mean annotation on project about svn url and current revision)
When you have 'connection' in your case, can you chage something in commited ModuleC and see 'dirty' svn marker on Project-parent?
How to achieve such connection manually? The only way i could do it is through deleting all projects and again performing ""Check out Maven projects from SCM"" and picking all projects again.
When you create submodule sceleton in different location than workspace and then check it into svn, how to import it back to workspace and to m2e from svn?

","You must also mount the main project in eclipse, the parent of the module. Then, use this project to check in the new module as you are doing for any change set. This project is only used for SVN synchronization purpose. For your developments, use the module projects.

For your last question, this is a maven constraint to have its sub module below the parent project. You won't be able (at least not easily) to create a module somewhere, check it in below the parent and then checkout the whole project with the new module.

Try to keep it simple. 

Use the parent project when you want to synchronize new modules.

HIH
M.
"
2411,2411,3847,Instrinsic definition of concave and convex polyhedron,"Is it possible to distinguish a concave polyhedron from a convex one by mesurements made only on its surface, without a reference to the 3d space around it?
",Leos Ondra,https://math.stackexchange.com/users/96188,"No.  Consider (a) a pyramid atop a cube (convex), and (b) a cube with a pyramidal piece cut out of one face (not convex).  As intrinsic surfaces, these are isometric.


",Robert Israel,https://math.stackexchange.com/users/8508,http://math.stackexchange.com/questions/509726/instrinsic-definition-of-concave-and-convex-polyhedron,SCIENCE,math.stackexchange.com,1.0,0.3333333333333333,0.0,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,1.0,0.0,0.0,0.3333333333333333,0.0,0.3333333333333333,0.0,0.3333333333333333,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,0.8888888888888888,Inner definition of concave convex polyhedron,"Is it possible to distinguish a concave polyhedron from a convex polyhedron by measuring only on its surface, without reference to the three-dimensional space around it?","No.  Consider (a) a pyramid atop a cube (convex), and (b) a cube with a pyramidal piece cut out of one face (not convex).  As intrinsic surfaces, these are isometric.


"
4747,4747,7532,Another instructor is pushing me out of the classroom right after my class ends,"I am a graduate student in math in my final year, and for several years have been teaching at my department as a lecturer. This semester, in the same lecture hall there is another lecture that starts 20 minutes after my class ends. It's taught by another instructor from my department. I usually have many students coming to office hours and there are also students asking questions immediately after lecture. Due to other activities, I cannot have office hours right after the lecture this semester and can only stay for about 15 minutes to answer questions.

Many times in the past I had a similar situation and never had any issues with it. This semester the instructor who is teaching right after often arrives 20-15 minutes before her class starts and tells me immediately that I have to go with my students somewhere else. 

I make sure to leave the blackboard clean and take all my stuff away from the instructor's desk before she arrives, but I do believe that I have a right to stay in the classroom after my lecture for at least 5-10 minutes. There is no vacant classroom around, and I don't have time to go with students to my office, which is in a different building.

Last time the instructor told me in front of my students that I don't understand ""simple things"" and that I am ""playing games"". When I was talking to one of my students, she stood very close to us and clearly demonstrated that she wanted us out. I tried to explain her that I couldn't go anywhere else due to my time constraints, but she didn't want to listen to me. I really don't understand what ""simple"" things she meant and what ""games"" I am playing. 

We leave the board clean. She doesn't need to set up a projector. She can still talk to her students before her class starts, if she wants to (even though it seems like her students don't ask her any questions before their class). So, I don't see how I cause any disruption. 

I had met this woman many times before this semester, but we never talked. I didn't see her talking to other instructors/students much, and she seems to be quite reserved and a bit neurotic. She doesn't want to have any conversation with me regarding the issue.

I felt really offended after last class when she said those things to me in front of my students. What would you do in my case? 

Added later: There are no official rules regarding classroom occupancy between classes. Instructors are supposed to use common sense and be reasonable. For me using 50% of the break time seems reasonable to answer questions after lecture seems reasonable. I agree that for some people it may not.

I don't block the entrance to the classroom. A few students from the next class who come earlier always go ahead and take their seats as soon as my students start leaving the room. I also had one of the students from the next class listening to my explanation to one of those after-class questions and asking me further questions before their class (which is the same class as I am teaching, just a different section). Maybe the instructor got jealous, I don't know.

The entrance to the classroom is from its front (not back), so I do stay in the front. But it is a big lecture hall, and there is a plenty of space in front of the room (the board itself consists of 8 huge panels).

Also, during my career as a grad.student who is also teaching for the department, I have had several observations from experienced professors who are considered to be great teachers at the department and are in charge of undergraduate teaching policy. In my evaluations the fact that there are always several students approaching me with questions after class considered as very positive, meaning that students find me approachable. 

Thank you everyone for answers. 
",Lidd88,https://academia.stackexchange.com/users/31345,"You should first find out what is the standard convention for when you have to vacate the room.  Since the other instructor is in your department, you can take this up at the department level: talk to your advisor and/or a trusted faculty mentor about it.  

In my experience though this is often left a little fungible and people need to be reasonable about it.  In my opinion it is reasonable to expect to have access to the room five minutes before your class begins.  Ideally the previous instructor will have vacated the room at that point; if not, s/he should be occupying the room in a way which doesn't interfere with your own use of it.  (For instance, a lot of times students will not enter a room if an instructor is still writing on the blackboard.  It can be annoying to come to your class a few minutes before you want to start and find everyone waiting out in the hall.)

In the absence of a clear directive about how to split the time, it seems reasonable for the departing instructor to take half of the time, as long as they leave at least five minutes for the other instructor.  In your case 20 minutes is a very nice cushion (in my university it's 15 minutes), to the extent that I find it a little strange that the other instructor is arriving 15-20 minutes early.  What is she doing with that time?  Do more than a few students arrive that early?  If you are using the time to talk to your students and she's using the time for nothing, then I think you are morally in the right and should push back on it a bit.  You should be able to stay for the first half of the 20 minute break.

How should you do that?  As above, I would find out what other people do.  If the standard convention is that you can take those 10 minutes, then talk to the department head (or other departmental authority figure; e.g. whoever schedules the teaching) about it and get their support.  (You don't need to phrase it as a grievance or even identify the other instructor by name.)  Assuming you get backed, then you should pay a visit to the instructor in her office and explain that you looked into the matter, that you have a clear instructional purpose for how to use the time, and that the head (or whoever) has confirmed that this is a standard practice.  Definitely do this outside of the classroom so that you two can have the conversation you need to have not in front of the students and so that there is not a direct confrontation to be resolved.

In my opinion it is probably not worth trying to seek redress for your poor treatment by this instructor.  We are not obligated to be nice to each other; it's just better if we are.  If you respond to the treatment in a professional way and show that you are neither going to get pushed around nor retaliate in any personal or emotional way, then you're basically just rising above.  What some random person who you're only going to see for one more semester thinks of you isn't really so important, is it?  Especially if you're confident that you're in the right? 
",Pete L. Clark,https://academia.stackexchange.com/users/938,http://academia.stackexchange.com/questions/41133/another-instructor-is-pushing-me-out-of-the-classroom-right-after-my-class-ends,LIFE_ARTS,academia.stackexchange.com,1.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.8888888888888888,1.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,1.0,0.8888888888888888,0.7777777777777778,1.0,1.0,0.9333333333333332,0.0,1.0,0.0,1.0,No sooner had I finished class than another teacher kicked me out of the classroom,"I am a graduate student in math in my final year, and for several years have been teaching at my department as a lecturer. This semester, in the same lecture hall there is another lecture that starts 20 minutes after my class ends. It's taught by another instructor from my department. I usually have many students coming to office hours and there are also students asking questions immediately after lecture. Due to other activities, I cannot have office hours right after the lecture this semester and can only stay for about 15 minutes to answer questions.

Many times in the past I had a similar situation and never had any issues with it. This semester the instructor who is teaching right after often arrives 20-15 minutes before her class starts and tells me immediately that I have to go with my students somewhere else. 

I make sure to leave the blackboard clean and take all my stuff away from the instructor's desk before she arrives, but I do believe that I have a right to stay in the classroom after my lecture for at least 5-10 minutes. There is no vacant classroom around, and I don't have time to go with students to my office, which is in a different building.

Last time the instructor told me in front of my students that I don't understand ""simple things"" and that I am ""playing games"". When I was talking to one of my students, she stood very close to us and clearly demonstrated that she wanted us out. I tried to explain her that I couldn't go anywhere else due to my time constraints, but she didn't want to listen to me. I really don't understand what ""simple"" things she meant and what ""games"" I am playing. 

We leave the board clean. She doesn't need to set up a projector. She can still talk to her students before her class starts, if she wants to (even though it seems like her students don't ask her any questions before their class). So, I don't see how I cause any disruption. 

I had met this woman many times before this semester, but we never talked. I didn't see her talking to other instructors/students much, and she seems to be quite reserved and a bit neurotic. She doesn't want to have any conversation with me regarding the issue.

I felt really offended after last class when she said those things to me in front of my students. What would you do in my case? 

Added later: There are no official rules regarding classroom occupancy between classes. Instructors are supposed to use common sense and be reasonable. For me using 50% of the break time seems reasonable to answer questions after lecture seems reasonable. I agree that for some people it may not.

I don't block the entrance to the classroom. A few students from the next class who come earlier always go ahead and take their seats as soon as my students start leaving the room. I also had one of the students from the next class listening to my explanation to one of those after-class questions and asking me further questions before their class (which is the same class as I am teaching, just a different section). Maybe the instructor got jealous, I don't know.

The entrance to the classroom is from its front (not back), so I do stay in the front. But it is a big lecture hall, and there is a plenty of space in front of the room (the board itself consists of 8 huge panels).

Also, during my career as a grad.student who is also teaching for the department, I have had several observations from experienced professors who are considered to be great teachers at the department and are in charge of undergraduate teaching policy. In my evaluations the fact that there are always several students approaching me with questions after class considered as very positive, meaning that students find me approachable. 

Thank you everyone for answers. 
","You should first find out what is the standard convention for when you have to vacate the room.  Since the other instructor is in your department, you can take this up at the department level: talk to your advisor and/or a trusted faculty mentor about it.  

In my experience though this is often left a little fungible and people need to be reasonable about it.  In my opinion it is reasonable to expect to have access to the room five minutes before your class begins.  Ideally the previous instructor will have vacated the room at that point; if not, s/he should be occupying the room in a way which doesn't interfere with your own use of it.  (For instance, a lot of times students will not enter a room if an instructor is still writing on the blackboard.  It can be annoying to come to your class a few minutes before you want to start and find everyone waiting out in the hall.)

In the absence of a clear directive about how to split the time, it seems reasonable for the departing instructor to take half of the time, as long as they leave at least five minutes for the other instructor.  In your case 20 minutes is a very nice cushion (in my university it's 15 minutes), to the extent that I find it a little strange that the other instructor is arriving 15-20 minutes early.  What is she doing with that time?  Do more than a few students arrive that early?  If you are using the time to talk to your students and she's using the time for nothing, then I think you are morally in the right and should push back on it a bit.  You should be able to stay for the first half of the 20 minute break.

How should you do that?  As above, I would find out what other people do.  If the standard convention is that you can take those 10 minutes, then talk to the department head (or other departmental authority figure; e.g. whoever schedules the teaching) about it and get their support.  (You don't need to phrase it as a grievance or even identify the other instructor by name.)  Assuming you get backed, then you should pay a visit to the instructor in her office and explain that you looked into the matter, that you have a clear instructional purpose for how to use the time, and that the head (or whoever) has confirmed that this is a standard practice.  Definitely do this outside of the classroom so that you two can have the conversation you need to have not in front of the students and so that there is not a direct confrontation to be resolved.

In my opinion it is probably not worth trying to seek redress for your poor treatment by this instructor.  We are not obligated to be nice to each other; it's just better if we are.  If you respond to the treatment in a professional way and show that you are neither going to get pushed around nor retaliate in any personal or emotional way, then you're basically just rising above.  What some random person who you're only going to see for one more semester thinks of you isn't really so important, is it?  Especially if you're confident that you're in the right? 
"
5366,5366,8523,How to use t() function with node_load in custom drupal module?,"I am using a custom module for my site, and I am using node_load to get the field value of type ""long text"" field and field of value of type ""text"".

Something like this 

$com_types = """".$ucom->node_title."""";

How should I translate $ucom->node_title ?

t() function does not translate variables.

Thanks
",Mohit Wadhwa,https://drupal.stackexchange.com/users/39260,"Node translation should be done at the node level.  the t() function is for labeling elements of the interface and theme things. 

You should look at multi-language node translation modules,  this link is helpful

You'd first want to use something like this:  https://api.drupal.org/api/drupal/modules!translation!translation.module/function/translation_node_get_translations/7

It'll let you get the NIDs of the translated versions of the node you want,  then you can use node_load() to get the translated version.
",user5482,https://drupal.stackexchange.com/users/41303,http://drupal.stackexchange.com/questions/149691/how-to-use-t-function-with-node-load-in-custom-drupal-module,TECHNOLOGY,drupal.stackexchange.com,0.7777777777777778,0.8888888888888888,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,1.0,0.8888888888888888,0.8,1.0,0.3333333333333333,0.3333333333333333,0.7777777777777778,How to use the t() function with node loading in the custom Drupal module?,"I'm using a custom module for my site, and I'm using node [load] to get the field value of the ""long text"" field type and the value field of the ""text"" field type.","Node translation should be done at the node level.  the t() function is for labeling elements of the interface and theme things. 

You should look at multi-language node translation modules,  this link is helpful

You'd first want to use something like this:  https://api.drupal.org/api/drupal/modules!translation!translation.module/function/translation_node_get_translations/7

It'll let you get the NIDs of the translated versions of the node you want,  then you can use node_load() to get the translated version.
"
3893,3893,6200,When should a supervisor be a co-author?,"What are people's views on this?  To be specific: suppose a PhD student has produced a piece of original mathematical research. Suppose that student's supervisor suggested the problem, and gave a few helpful comments, but otherwise did not contribute to the work.  Should that supervisor still be named as a co-author, or would an acknowledgment suffice?

I am interested in two aspects of this. Firstly the moral/etiquette aspect: do you consider it bad form for a student not to name their supervisor?  Or does it depend on that supervisor's input?  And secondly, the practical, career-advancing aspect: which is better, for a student to have a well-known name on his or her paper (and hence more chance of it being noticed/published), or to have a sole-authored piece of work under their belt to hopefully increase their chances of being offered a good post-doc position?

[To clarify: original question asked by MrB ]
",MrB,https://mathoverflow.net/users/2189,"I fail to see the difference between a supervisor and anyone else. To decide whether a supervisor should be a co-author, you should apply the same rules you would have applied in any other case.

I generally prefer to be inclusive and if someone was involved in the project, then I think they should be offered to be co-author (unless it is obvious that their contribution is very minor). It is up to them to decide whether to accept or reject the offer. If you do not like their answer, next time do not talk to them about your work.

Also we are moving to a world where academic work in measured and rewarded very precisely by criteria which are very narrow. For example, in the UK the REF, which measure the performance of departments, in the individual level looks mainly on the quality of papers. So there is little incentive to individuals to supervise students (department as a whole do have some incentive). Now, in most cases supervisors put a lot of work into the supervision. So morally and to encourage people to keep supervising students I see no justification not to give supervisors credit when they deserve it. 
",Yiftach Barnea,https://mathoverflow.net/users/5034,http://mathoverflow.net/questions/57337,SCIENCE,mathoverflow.net,1.0,0.7777777777777778,0.3333333333333333,0.6666666666666666,0.0,0.0,0.5555555555555556,0.6666666666666666,1.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.0,1.0,0.8888888888888888,When should a supervisor become a coauthor?,"What are people's views on this?  To be specific: suppose a PhD student has produced a piece of original mathematical research. Suppose that student's supervisor suggested the problem, and gave a few helpful comments, but otherwise did not contribute to the work.  Should that supervisor still be named as a co-author, or would an acknowledgment suffice?

I am interested in two aspects of this. Firstly the moral/etiquette aspect: do you consider it bad form for a student not to name their supervisor?  Or does it depend on that supervisor's input?  And secondly, the practical, career-advancing aspect: which is better, for a student to have a well-known name on his or her paper (and hence more chance of it being noticed/published), or to have a sole-authored piece of work under their belt to hopefully increase their chances of being offered a good post-doc position?

[To clarify: original question asked by MrB ]
","I fail to see the difference between a supervisor and anyone else. To decide whether a supervisor should be a co-author, you should apply the same rules you would have applied in any other case.

I generally prefer to be inclusive and if someone was involved in the project, then I think they should be offered to be co-author (unless it is obvious that their contribution is very minor). It is up to them to decide whether to accept or reject the offer. If you do not like their answer, next time do not talk to them about your work.

Also we are moving to a world where academic work in measured and rewarded very precisely by criteria which are very narrow. For example, in the UK the REF, which measure the performance of departments, in the individual level looks mainly on the quality of papers. So there is little incentive to individuals to supervise students (department as a whole do have some incentive). Now, in most cases supervisors put a lot of work into the supervision. So morally and to encourage people to keep supervising students I see no justification not to give supervisors credit when they deserve it. 
"
4193,4193,6686,Eliyahu HaNavi and bris,"Someone once told me that when Eliyahu HaNavi comes to a baby's bris, everyone who is presently there is forgiven for their sins. 

Does anyone know the source for this?
",Chiddushei Torah,https://judaism.stackexchange.com/users/6633,"Bnai Yissaschar Tishrei 4:2:7 mentions regarding all those attending a Bris receiving forgiveness for their sins in the name of a Medrash, however he says he has not seen where this Medrash is.


  כך שמעתי שיש באיזה מדרש ולא ראיתיו

",Gershon Gold,https://judaism.stackexchange.com/users/200,http://judaism.stackexchange.com/questions/51063/eliyahu-hanavi-and-bris,CULTURE,judaism.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,1.0,1.0,1.0,0.4444444444444444,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.3333333333333333,0.0,0.8888888888888888,0.7777777777777778,0.6666666666666666,0.7777777777777778,1.0,0.8666666666666666,0.0,0.0,1.0,1.0,Eliahu hanawi and bris,"I was once told that when ilyahu hanawi came into the baby's arms, everyone present would be forgiven for their sins.","2 Tim 4:2:7 and it was mentioned that all those who took part in bris were forgiven for their sins in the name of the drug eruption, but he said, he did not see where the drug eruption was."
4297,4297,6849,"How to construct a closed, filled, path made of semi-circles and attach annotations to it with TikZ?","I have very limited LaTeX knowledge. I am trying to plot the following figure using ""tikz"" and I appreciate if anyone can help me to finish plotting my figure. I did the following so far:

\documentclass{article}
\usepackage{tikz}
\begin{document}

\begin{tikzpicture}

\draw (0,0) arc (0:180:6);
\draw   (-12,0)  - -(0,0);
\draw (-8,0) arc (0:180:2);
\draw (0,0) arc (0:180:4);
\draw (-6,-0.1) - - (-6,0.1);

\end{tikzpicture}

\end{document}


There is a BIG semi-circle and two inner SMALL semi-circles. I want to label the right endpoint of the BIG semi-circle by ""A"" and  the left endpoint of the BIG semi-circle by ""B"". I want to label the center of the BIG semi-circle by ""O"", and I want to label the point where the two SMALL semicircles meet by ""P"". I also want to shade the area inside the BIG semi-circle and outside the two SMALL semi-circles. I also want to mention on the figure that the radius of the big circle is: 6. and the distance between the point ""O"" and the point ""P"" is ""x""

Any help is much appreciated
",Pat_Ho,https://tex.stackexchange.com/users/60077,"You can also draw that path at one go so you don't need to fill white to restrict the fill if you have something else underneath it. And while you are at it you can also place the labels and coordinates too.

\documentclass[tikz,border=5mm]{standalone}
\usetikzlibrary{decorations.pathreplacing}
\begin{document}
\begin{tikzpicture}
\filldraw[fill=blue] (0,0) 
               coordinate[label=-90:$B$] (B)
               arc (180:0:3cm) 
               coordinate[label=-90:$A$] (A)
               arc (0:180:2cm)
               coordinate[label=-90:$P$] (P)
               arc (0:180:1cm);
\draw (B)--(A) coordinate[midway,label=-90:$O$] (O);
\draw[decoration={brace,raise=5mm},decorate] (A) -- (O) 
                   node [midway,yshift=-6mm,below] (R) {$6$};
\draw[decoration={brace,raise=5mm},decorate] (O) -- (P)
                   node [midway,yshift=-6mm,below] (r) {$x$};
\end{tikzpicture}
\end{document}



",percusse,https://tex.stackexchange.com/users/3235,http://tex.stackexchange.com/questions/194381/how-to-construct-a-closed-filled-path-made-of-semi-circles-and-attach-annotati,TECHNOLOGY,tex.stackexchange.com,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,1.0,0.6666666666666666,0.8333333333333334,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,1.0,"How to construct a closed, filled, semi-circular path and attach annotations to the path with tikz?","I have very limited LaTeX knowledge. I am trying to plot the following figure using ""tikz"" and I appreciate if anyone can help me to finish plotting my figure. I did the following so far:

\documentclass{article}
\usepackage{tikz}
\begin{document}

\begin{tikzpicture}

\draw (0,0) arc (0:180:6);
\draw   (-12,0)  - -(0,0);
\draw (-8,0) arc (0:180:2);
\draw (0,0) arc (0:180:4);
\draw (-6,-0.1) - - (-6,0.1);

\end{tikzpicture}

\end{document}


There is a BIG semi-circle and two inner SMALL semi-circles. I want to label the right endpoint of the BIG semi-circle by ""A"" and  the left endpoint of the BIG semi-circle by ""B"". I want to label the center of the BIG semi-circle by ""O"", and I want to label the point where the two SMALL semicircles meet by ""P"". I also want to shade the area inside the BIG semi-circle and outside the two SMALL semi-circles. I also want to mention on the figure that the radius of the big circle is: 6. and the distance between the point ""O"" and the point ""P"" is ""x""

Any help is much appreciated
","You can also draw that path at one go so you don't need to fill white to restrict the fill if you have something else underneath it. And while you are at it you can also place the labels and coordinates too.

\documentclass[tikz,border=5mm]{standalone}
\usetikzlibrary{decorations.pathreplacing}
\begin{document}
\begin{tikzpicture}
\filldraw[fill=blue] (0,0) 
               coordinate[label=-90:$B$] (B)
               arc (180:0:3cm) 
               coordinate[label=-90:$A$] (A)
               arc (0:180:2cm)
               coordinate[label=-90:$P$] (P)
               arc (0:180:1cm);
\draw (B)--(A) coordinate[midway,label=-90:$O$] (O);
\draw[decoration={brace,raise=5mm},decorate] (A) -- (O) 
                   node [midway,yshift=-6mm,below] (R) {$6$};
\draw[decoration={brace,raise=5mm},decorate] (O) -- (P)
                   node [midway,yshift=-6mm,below] (r) {$x$};
\end{tikzpicture}
\end{document}



"
993,993,1569,change Domain MX,"I have a windows server and I set my domain name servers to this server. now I want send email from another server, really my web application and mail server aren't on a same server. the mail server is Linux CentOS. and there are many mail accounts available on it. so it has no problem. now I want to to send and receive emails from the linux server and my website be on the windows server. so I changed MX record of my domain to Linux server. but when I send mail from the mail server to gmail.com it's response is:

 Client host rejected: cannot find your reverse hostname


what is wrong? I searched for this problem but I couldn't solve this problem. I want to ask you what is the steps to change mail server? did I forget some Steps?
",m.Khaki,https://serverfault.com/users/270419,"Based upon the error message it would appear that you need to configure reverse DNS lookups for the host. This is normally done with a PTR record. For example you might have a host mail.example.com

mail.example.com IN A 192.0.2.1


and a PTR record

1.2.0.192.in-addr.arpa. IN PTR mail.example.com

",Iain,https://serverfault.com/users/9517,http://serverfault.com/questions/667604,TECHNOLOGY,serverfault.com,0.7777777777777778,0.3333333333333333,0.0,1.0,0.6666666666666666,1.0,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.3333333333333333,0.0,1.0,1.0,Change domain MX,"I have a Windows Server, which I set up as my domain name server. Now I want to send e-mail from another server, in fact my web application and mail server are not on the same server. The mail server is Linux CentOS. There are many email accounts on it. So no problem. Now I want to send and receive email from Linux server. My website is on Windows Server. So I changed the MX record of the domain to a Linux server. But when I send mail from the mail server to gmail.com, its response is:","Based upon the error message it would appear that you need to configure reverse DNS lookups for the host. This is normally done with a PTR record. For example you might have a host mail.example.com

mail.example.com IN A 192.0.2.1


and a PTR record

1.2.0.192.in-addr.arpa. IN PTR mail.example.com

"
4608,4608,7307,Performance of SQL query with condition vs. without where clause,"Which SQL-query will be executed with less time — query with WHERE-clause or without, when:


WHERE-clause deals with indexed field (e.g. primary key field)
WHERE-clause deals with non-indexed field


I suppose when we're working with indexed fields, thus query with WHERE will be faster.
Am I right?

Thanks!
",Mike B.,https://stackoverflow.com/users/462347,"As has been mentioned there is no fixed answer to this. It all depends on the particular context. But just for the sake of an answer. Take this simple query:

 SELECT first_name FROM people WHERE last_name = 'Smith';


To process this query without an index, every column, last_name must be checked for every row in the table (full table scan). 

With an index, you could just follow a B-tree data structure until 'Smith' was found.

With a non index the worst case looks linear (n), whereas with a B-tree it would be log n, hence computationally less expensive.
",Science_Fiction,https://stackoverflow.com/users/1213473,http://stackoverflow.com/questions/11802884/performance-of-sql-query-with-condition-vs-without-where-clause,STACKOVERFLOW,stackoverflow.com,0.6666666666666666,0.5555555555555556,0.0,0.5,1.0,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.0,0.3333333333333333,0.0,0.7777777777777778,0.7777777777777778,0.6666666666666666,0.8888888888888888,0.8333333333333334,0.8,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.7777777777777778,Performance comparison of SQL query with and without where clause,"Which SQL-query will be executed with less time — query with WHERE-clause or without, when:


WHERE-clause deals with indexed field (e.g. primary key field)
WHERE-clause deals with non-indexed field


I suppose when we're working with indexed fields, thus query with WHERE will be faster.
Am I right?

Thanks!
","As has been mentioned there is no fixed answer to this. It all depends on the particular context. But just for the sake of an answer. Take this simple query:

 SELECT first_name FROM people WHERE last_name = 'Smith';


To process this query without an index, every column, last_name must be checked for every row in the table (full table scan). 

With an index, you could just follow a B-tree data structure until 'Smith' was found.

With a non index the worst case looks linear (n), whereas with a B-tree it would be log n, hence computationally less expensive.
"
3264,3264,5202,prevent menustrip from being selected by pressing alt,"I would like to have some shortcuts with alt but when I press alt the menustrip gets selected. How can I disable this behaviour?
",DaVinci,https://stackoverflow.com/users/97702,"I know this thread is old, but I am running into the same problem.

One partial solution is to use the ""SendKeys.Send"" function to simulate a second press of the alt key. For example, to simulate the user pressing ""alt-0"":

sendkeys.send(""%0"")

This works because pressing the Alt-key once activates the menu strip, but pressing it a second time deactivates it.

The only problem is, this also tricks the software into thinking that the user let go of the Alt- key. So it doesn't work if you want to be able to press and hold the Alt-key while pressing some other keys.

Since the Alt-key triggers the menustrip.activate event, it seems there should be someway to trigger the menustrip.deactivate event in code without the hack of simulating another Alt-key press, but I can't figure out how to do that... 
",GeoBarry,https://stackoverflow.com/users/2730932,http://stackoverflow.com/questions/4537794/prevent-menustrip-from-being-selected-by-pressing-alt,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.7777777777777778,0.0,1.0,1.0,1.0,0.7777777777777778,0.5555555555555556,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,1.0,0.6666666666666666,0.4444444444444444,0.8888888888888888,0.8888888888888888,0.5333333333333333,0.6666666666666666,0.3333333333333333,0.3333333333333333,1.0,Press ALT key to prevent MenuStrip from being selected,"I would like to have some shortcuts with ALT, but when I press ALT the menu is selected. How can I stop this?","I know this thread is old, but I am running into the same problem.

One partial solution is to use the ""SendKeys.Send"" function to simulate a second press of the alt key. For example, to simulate the user pressing ""alt-0"":

sendkeys.send(""%0"")

This works because pressing the Alt-key once activates the menu strip, but pressing it a second time deactivates it.

The only problem is, this also tricks the software into thinking that the user let go of the Alt- key. So it doesn't work if you want to be able to press and hold the Alt-key while pressing some other keys.

Since the Alt-key triggers the menustrip.activate event, it seems there should be someway to trigger the menustrip.deactivate event in code without the hack of simulating another Alt-key press, but I can't figure out how to do that... 
"
4142,4142,6609,Ajax file upload in codeigniter not working,"File uploading is working well in my program but it is by page refreshing.Why my page is refreshing?Any idea where i got problem?Any help is appreciated.I cant see a good tutorial for ajax upload in codeigniter.

&lt;html&gt;
&lt;head&gt;
&lt;script src=""http://code.jquery.com/jquery-1.9.1.js""&gt;&lt;/script&gt;
&lt;script type=""text/javascript"" src=""&lt;?php echo base_url()?&gt;Assets/Scripts/ajaxfileupload.js""&gt;&lt;/script&gt;
    &lt;script type=""text/javascript""&gt;
    function ajaxFileUpload()
    {
        $(""#loading"")
        .ajaxStart(function(){

            $(this).show();
        })
        .ajaxComplete(function(){
            $(this).hide();
        });
        $.ajaxFileUpload
        (
            {
                url:'&lt;?php echo site_url()?&gt;/welcome/doupload',
                secureuri:false,
                fileElementId:'fileToUpload',
                dataType: 'json',
                success: function (data, status)
                {
                    if(typeof(data.error) != 'undefined')
                    {
                        if(data.error != '')
                        {
                            $(""#info"").html(data.error);
                        }else
                        {
                            $(""#info"").html(data.msg);
                        }
                    }
                },
                error: function (data, status, e)
                {
                    $(""#info"").html(e);
                }
            }
        )
        return false;
    }
    &lt;/script&gt;
    &lt;/head&gt;

    &lt;body&gt;

        &lt;form name=""form"" action="""" method=""POST"" enctype=""multipart/form-data""&gt;

               &lt;input id=""fileToUpload"" type=""file"" size=""45"" name=""fileToUpload"" class=""input""&gt;

                    &lt;button class=""button"" id=""buttonUpload"" onclick=""return ajaxFileUpload();""&gt;Upload&lt;/button&gt;

        &lt;/form&gt;
        &lt;/body&gt;
        &lt;/html&gt;


Controller

public function doupload()
    {
$error = """";
   $msg = """";
  $config['upload_path'] = './Assets/';
  $config['allowed_types'] = 'doc|xls|ppt|pdf|rar|jpg';
  $config['max_size'] = '1000';
  $this-&gt;load-&gt;library('upload', $config);
  $this-&gt;upload-&gt;display_errors('','');
  if ( ! $this-&gt;upload-&gt;do_upload(""fileToUpload""))
  {
       $error = $this-&gt;upload-&gt;display_errors();
  }
  else

  {
        $msg = ""Success"";
  }
  echo ""{"";
   echo    ""error: '"" . $error . ""',n"";
   echo    ""msg: '"" . $msg . ""'n"";
   echo ""}"";
    }

",user3300195,https://stackoverflow.com/users/3300195,"I don't think Codeigniter is the problem here.

My guess is that buttons are of ""submit"" type by default when in a form tag.

Try to set the type to ""button"" : 

&lt;button type=""button"" class=""button"" id=""buttonUpload"" onclick=""return ajaxFileUpload();""&gt;Upload&lt;/button&gt;

",Christian Bonato,https://stackoverflow.com/users/418974,http://stackoverflow.com/questions/23970066/ajax-file-upload-in-codeigniter-not-working,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.4444444444444444,0.0,1.0,0.6666666666666666,1.0,0.4444444444444444,0.4444444444444444,0.3333333333333333,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,1.0,0.0,0.4444444444444444,0.8888888888888888,0.6666666666666666,1.0,1.0,0.9,0.6666666666666666,0.3333333333333333,0.6666666666666666,1.0,Ajax file upload in CodeIgniter does not work,"File uploading is working well in my program but it is by page refreshing.Why my page is refreshing?Any idea where i got problem?Any help is appreciated.I cant see a good tutorial for ajax upload in codeigniter.

&lt;html&gt;
&lt;head&gt;
&lt;script src=""http://code.jquery.com/jquery-1.9.1.js""&gt;&lt;/script&gt;
&lt;script type=""text/javascript"" src=""&lt;?php echo base_url()?&gt;Assets/Scripts/ajaxfileupload.js""&gt;&lt;/script&gt;
    &lt;script type=""text/javascript""&gt;
    function ajaxFileUpload()
    {
        $(""#loading"")
        .ajaxStart(function(){

            $(this).show();
        })
        .ajaxComplete(function(){
            $(this).hide();
        });
        $.ajaxFileUpload
        (
            {
                url:'&lt;?php echo site_url()?&gt;/welcome/doupload',
                secureuri:false,
                fileElementId:'fileToUpload',
                dataType: 'json',
                success: function (data, status)
                {
                    if(typeof(data.error) != 'undefined')
                    {
                        if(data.error != '')
                        {
                            $(""#info"").html(data.error);
                        }else
                        {
                            $(""#info"").html(data.msg);
                        }
                    }
                },
                error: function (data, status, e)
                {
                    $(""#info"").html(e);
                }
            }
        )
        return false;
    }
    &lt;/script&gt;
    &lt;/head&gt;

    &lt;body&gt;

        &lt;form name=""form"" action="""" method=""POST"" enctype=""multipart/form-data""&gt;

               &lt;input id=""fileToUpload"" type=""file"" size=""45"" name=""fileToUpload"" class=""input""&gt;

                    &lt;button class=""button"" id=""buttonUpload"" onclick=""return ajaxFileUpload();""&gt;Upload&lt;/button&gt;

        &lt;/form&gt;
        &lt;/body&gt;
        &lt;/html&gt;


Controller

public function doupload()
    {
$error = """";
   $msg = """";
  $config['upload_path'] = './Assets/';
  $config['allowed_types'] = 'doc|xls|ppt|pdf|rar|jpg';
  $config['max_size'] = '1000';
  $this-&gt;load-&gt;library('upload', $config);
  $this-&gt;upload-&gt;display_errors('','');
  if ( ! $this-&gt;upload-&gt;do_upload(""fileToUpload""))
  {
       $error = $this-&gt;upload-&gt;display_errors();
  }
  else

  {
        $msg = ""Success"";
  }
  echo ""{"";
   echo    ""error: '"" . $error . ""',n"";
   echo    ""msg: '"" . $msg . ""'n"";
   echo ""}"";
    }

","I don't think Codeigniter is the problem here.

My guess is that buttons are of ""submit"" type by default when in a form tag.

Try to set the type to ""button"" : 

&lt;button type=""button"" class=""button"" id=""buttonUpload"" onclick=""return ajaxFileUpload();""&gt;Upload&lt;/button&gt;

"
3001,3001,4783,Should I write a recommendation letter for a student at a previous job/institution?,"I receive requests for recommendation many times, but I have received one from a student belonging at a previous affiliation of mine, asking for a favourable letter in view of their achievements.

I am aware of the fact that if I comment on the performance of the student, it could be used against me, since it is good practice to ""erase"" all the material, marks, personal information of the students and staff relationship at a previous job. So I am hesitant to go in that direction. On the other hand, I could comment only very generally on the skills of the student, which could backfire their application to a new job

Differently from this question I am not looking for a recommendation, but giving one...
",ElCid,https://academia.stackexchange.com/users/1520,"You may want to ask the student to send you any material that you need for writing your reference, for example grade sheets and a CV. Bringing in your personal experiences with the student in addition shouldn't be a problem at all. After writing the reference letter, you should erase all confidential material that the student sent you... :)
",silvado,https://academia.stackexchange.com/users/3890,http://academia.stackexchange.com/questions/5047/should-i-write-a-recommendation-letter-for-a-student-at-a-previous-job-instituti,LIFE_ARTS,academia.stackexchange.com,1.0,0.7777777777777778,0.3333333333333333,0.5,0.0,0.5,0.6666666666666666,0.6666666666666666,0.0,0.0,1.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.8888888888888888,Should I write a letter of recommendation for a former work / institution student?,"I receive requests for recommendation many times, but I have received one from a student belonging at a previous affiliation of mine, asking for a favourable letter in view of their achievements.

I am aware of the fact that if I comment on the performance of the student, it could be used against me, since it is good practice to ""erase"" all the material, marks, personal information of the students and staff relationship at a previous job. So I am hesitant to go in that direction. On the other hand, I could comment only very generally on the skills of the student, which could backfire their application to a new job

Differently from this question I am not looking for a recommendation, but giving one...
","You may want to ask the student to send you any material that you need for writing your reference, for example grade sheets and a CV. Bringing in your personal experiences with the student in addition shouldn't be a problem at all. After writing the reference letter, you should erase all confidential material that the student sent you... :)
"
4348,4348,6923,Long Haul flight with 9 month old with potential no Bassinet,"I will be flying with my wife and daughter to the US and back again from New Zealand. Going there should be no issue, we should be able to use a bassinet but there is no guarantee we will get one on the flight back. We are flying Air New Zealand and they state that babies over 8 months could get a bassinet but if there are babies under 8 months they take priority, even if you request one well in advance.

So we won't know until we get to the airport whether we get a bassinet or not which will cause us an issue. An additional infant ticket is quite a lot and there is no guarantee there will be a free seat in case we get no bassinet.

So, what is the best way to handle this?

Bite the bullet and purchase a seat (we will have a car seat with us anyway) or hope there is a bassinet available?

Is there a third option where we have no additional seat and no bassinet? 13 hours on the lap is probably out of the question.

Thanks
",aqwert,https://travel.stackexchange.com/users/26167,"I don't know where you are flying and therefore which plane you will be on. If you look at your ticket it might say which plane you will be flying. With this information, you can check on seatguru the details of the plane that Air New Zealand will operate.

Looking at the different planes Air New Zealand uses (777 or 767 a priori on your route), there seems to be a minimum of 3 bassinets and up to 6, so I suppose you will likely have one - unless New Zealanders make way more babies than I have seen on flights in general.

Checking in early would probably help as you would get priority over other passengers for these seats.
",Vince,https://travel.stackexchange.com/users/3044,http://travel.stackexchange.com/questions/44339/long-haul-flight-with-9-month-old-with-potential-no-bassinet,CULTURE,travel.stackexchange.com,1.0,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.0,1.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.0,0.5555555555555556,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.8888888888888888,"9-month-old long-distance flight, probably without cradle","I will be flying with my wife and daughter to the US and back again from New Zealand. Going there should be no issue, we should be able to use a bassinet but there is no guarantee we will get one on the flight back. We are flying Air New Zealand and they state that babies over 8 months could get a bassinet but if there are babies under 8 months they take priority, even if you request one well in advance.

So we won't know until we get to the airport whether we get a bassinet or not which will cause us an issue. An additional infant ticket is quite a lot and there is no guarantee there will be a free seat in case we get no bassinet.

So, what is the best way to handle this?

Bite the bullet and purchase a seat (we will have a car seat with us anyway) or hope there is a bassinet available?

Is there a third option where we have no additional seat and no bassinet? 13 hours on the lap is probably out of the question.

Thanks
","I don't know where you are flying and therefore which plane you will be on. If you look at your ticket it might say which plane you will be flying. With this information, you can check on seatguru the details of the plane that Air New Zealand will operate.

Looking at the different planes Air New Zealand uses (777 or 767 a priori on your route), there seems to be a minimum of 3 bassinets and up to 6, so I suppose you will likely have one - unless New Zealanders make way more babies than I have seen on flights in general.

Checking in early would probably help as you would get priority over other passengers for these seats.
"
4779,4779,7588,"PCB design cost for 0.4mm pitch bga, 0.1mm drill hole, 4-layer routing using via-in-pad","I am doing a development board for a IC with 36 WLCSP package. My PCB layout has 16 via over pads, minimum 0.1mm drill holes, 4-layers. I need to fabricate my PCB. And I could not find a exact pricing for PCBs in the required design quality. I sent sample Gerber file for some PCB manufacturers. And they replied with extreme high prices and I can't afford their pricing (eg: 200$ for 10 boards with 2.5cm * 2.5cm). And most of manufactures are not willing to share their pricing strategy to optimize my design.

My target is to deliver my demo board for the lowest price (to make it lower than 10$, while component cost around 6.5$) . So I need to keep the PCB cost lower than 2$ with the minimum area of 2cm * 2cm. 



Could I achieve that much lower PCB cost?
what are the possible PCB fabricators with lower cost with required technology?
What would be the unit PCB cost if fabricate at least 500 boards?
Feasibility of my project to make it under 10$?


Thank you
",user3478108,https://electronics.stackexchange.com/users/77308,"As others have said, the drill size is what is killing you, but also the via-in-pad.

Remove those two things, the price will plummet; your design probably doesn't need them at all.
",trayres,https://electronics.stackexchange.com/users/8245,http://electronics.stackexchange.com/questions/172345/pcb-design-cost-for-0-4mm-pitch-bga-0-1mm-drill-hole-4-layer-routing-using-via,TECHNOLOGY,electronics.stackexchange.com,1.0,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,1.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,1.0,0.0,0.3333333333333333,0.0,0.5555555555555556,1.0,0.5555555555555556,1.0,1.0,0.7333333333333333,1.0,0.0,0.6666666666666666,0.8888888888888888,"PCB design cost of 0.4mm BGA, 0.1mm drilling, 4-layer wiring (via in PAD)","I am making a 36 WLCSP integrated circuit development board. My PCB layout has 16 through-hole pads with a minimum of 0.1mm drilled holes and 4 layers. I need to make my PCB. I also couldn't find a precise price for PCBs in the required design quality. I sent samples of Gerber documents to some PCB manufacturers. They replied to me at a very high price, and I couldn't afford their price (for example: 2.5cm * 2.5cm, 10 boards, 200 dollars). And most vendors are reluctant to share their pricing strategies to optimize my design.","As others have said, the drill size is what is killing you, but also the via-in-pad.

Remove those two things, the price will plummet; your design probably doesn't need them at all.
"
1561,1561,2449,"Any connection between akimbo, askance and atremble?","I came across akimbo and askance today and wondered if they were related, with the opening 'a' signifying something. Apparently not:


Akimbo — to stand ""with hands on hips and elbows projecting outwards"", from the C15 in kenebowe, ""literally: in keen bow, that is, in a sharp curve""
Askance — to look sideways, obliquely, especially with suspicion or doubt; origin obscure.


Other words take an 'a' prefix meaning a negative:





  a- or an- [Greek a- and an- un-, non-] 
  Negative, not (abiotic,
  acaulescent, acephalia, aphasia, asexual, atrophy, anorexia).
  
  But 'a' is also used as a prefix in words that are not negative, for example his knees were all atremble. What is the meaning of 'a-' here? Could it have connections with akimbo and askance?

",Mynamite,https://english.stackexchange.com/users/33153,"This is actually a matter of general reference that should be easily explained by consulting any dictionary worthy of being called such — and certainly can be found in The Dictionary, if one would but look.

But I will explain it anyway. :)

English has at least 6 different prefixes, a-. This, however, is not one of those six.  Rather, the one you see in knees all a-tremble is actually an old preposition that we no longer use, just as it is in here we come a-wassailing, in nine lords a leaping,  and in twice a day.  

It was a variant of the preposition on that lost its -n.  The OED explains in a prep. (which is just the 8th entry in the Dictionary):


  Variant of on prep. with loss of the final consonant -n, reflecting an unstressed pronunciation of the word in proclitic use; compare an, variant of on prep., and also o, variant of on prep.  Compare a- prefix3, away adv., aright adv.
  
  The loss of final -n  in this word occurs early in terms of the developments described at N n.  and perhaps began in fixed idioms where the word was felt to be almost a prefix; compare the parallel development represented by a- prefix3. A following consonant favoured the loss of final -n  (compare discussion at N n.) and so until the 17th cent. the word was often found in complementary distribution with an, variant of on prep., which was common before vowels (with variation between the two before following h-).
  
  The separate preposition a ceased to be used in standard English after about 1700, being replaced by the full on, in, or the various prepositions which represent them in modern idiom, surviving only in a few set uses from branch  II., such as to go a begging, to set a going  (occasionally, before a vowel or h-, in form an, after an, prevocalic variant of a adj.; compare quots. 1759, 1780 at sense 11b), and in temporal distributive phrases, as twice a day, once a year, where it had been early identified with the indefinite article (see a adj.4). It also survived in a large number of combinations, where it was treated as a prefix to the governed word, and the whole as a compound adverb. 


As I said, it’s in the Dictionary.

Were you to look there, you would also see that although there is some connection between askew and askance, and several other, less common words besides, the actual origin is obscure.  The Dictionary says of askance adv.2:


  There is a whole group of words of more or less obscure origin in ask-, containing askance, askant, askew, askie, askile, askoye, askoyne, (with which compare asklent adv., aslant adv., asquint adv.,) which are more or less closely connected in sense, and seem to have influenced one another in form. They appear mostly in the 16th or end of the 15th cent., and none of them can be certainly traced up to Old English; though they can nearly all be paralleled by words in various languages, evidence is wanting as to their actual origin and their relations to one another.

",tchrist,https://english.stackexchange.com/users/2085,http://english.stackexchange.com/questions/111659/any-connection-between-akimbo-askance-and-atremble,CULTURE,english.stackexchange.com,1.0,0.5555555555555556,0.0,0.3333333333333333,1.0,1.0,0.6666666666666666,0.5555555555555556,0.6666666666666666,0.0,0.0,1.0,0.3333333333333333,0.0,0.3333333333333333,0.0,0.0,0.0,1.0,0.3333333333333333,1.0,0.8888888888888888,0.8888888888888888,1.0,1.0,1.0,0.0,0.0,1.0,1.0,"What's the connection between akimbo, ascans and atambur?","I came across akimbo and askance today and wondered if they were related, with the opening 'a' signifying something. Apparently not:


Akimbo — to stand ""with hands on hips and elbows projecting outwards"", from the C15 in kenebowe, ""literally: in keen bow, that is, in a sharp curve""
Askance — to look sideways, obliquely, especially with suspicion or doubt; origin obscure.


Other words take an 'a' prefix meaning a negative:





  a- or an- [Greek a- and an- un-, non-] 
  Negative, not (abiotic,
  acaulescent, acephalia, aphasia, asexual, atrophy, anorexia).
  
  But 'a' is also used as a prefix in words that are not negative, for example his knees were all atremble. What is the meaning of 'a-' here? Could it have connections with akimbo and askance?

","This is actually a matter of general reference that should be easily explained by consulting any dictionary worthy of being called such — and certainly can be found in The Dictionary, if one would but look.

But I will explain it anyway. :)

English has at least 6 different prefixes, a-. This, however, is not one of those six.  Rather, the one you see in knees all a-tremble is actually an old preposition that we no longer use, just as it is in here we come a-wassailing, in nine lords a leaping,  and in twice a day.  

It was a variant of the preposition on that lost its -n.  The OED explains in a prep. (which is just the 8th entry in the Dictionary):


  Variant of on prep. with loss of the final consonant -n, reflecting an unstressed pronunciation of the word in proclitic use; compare an, variant of on prep., and also o, variant of on prep.  Compare a- prefix3, away adv., aright adv.
  
  The loss of final -n  in this word occurs early in terms of the developments described at N n.  and perhaps began in fixed idioms where the word was felt to be almost a prefix; compare the parallel development represented by a- prefix3. A following consonant favoured the loss of final -n  (compare discussion at N n.) and so until the 17th cent. the word was often found in complementary distribution with an, variant of on prep., which was common before vowels (with variation between the two before following h-).
  
  The separate preposition a ceased to be used in standard English after about 1700, being replaced by the full on, in, or the various prepositions which represent them in modern idiom, surviving only in a few set uses from branch  II., such as to go a begging, to set a going  (occasionally, before a vowel or h-, in form an, after an, prevocalic variant of a adj.; compare quots. 1759, 1780 at sense 11b), and in temporal distributive phrases, as twice a day, once a year, where it had been early identified with the indefinite article (see a adj.4). It also survived in a large number of combinations, where it was treated as a prefix to the governed word, and the whole as a compound adverb. 


As I said, it’s in the Dictionary.

Were you to look there, you would also see that although there is some connection between askew and askance, and several other, less common words besides, the actual origin is obscure.  The Dictionary says of askance adv.2:


  There is a whole group of words of more or less obscure origin in ask-, containing askance, askant, askew, askie, askile, askoye, askoyne, (with which compare asklent adv., aslant adv., asquint adv.,) which are more or less closely connected in sense, and seem to have influenced one another in form. They appear mostly in the 16th or end of the 15th cent., and none of them can be certainly traced up to Old English; though they can nearly all be paralleled by words in various languages, evidence is wanting as to their actual origin and their relations to one another.

"
4555,4555,7215,Offline WordPress post editor/creator,"I have a WordPress site hosted on my personal server. I will be unavailable by Internet for a little while, and I'd like to write up some posts for my blog.

Normally, you need to be connected to WordPress to start writing the blog, and it will do offline-saving automatically. But this is limited to one entry, per tab. I could use Notepad, but it doesn't have spell check built in. I could use Microsoft Word, but the ""Paste from Word"" leaves a lot to be desired.

What I'm looking for is a program that does the following:


Start a new post while offline
Lets me edit posts I created already with the program
Spell check
Uploads new posts when I reconnect
Has the same features as the online editor (i.e. toolbars, WYSIWYG and code editor)
Free (as in beer)
Works on either Windows or Mac OSX


Bonus features:


Edit posts currently on the website (with an offline copy)

",Canadian Luke,https://softwarerecs.stackexchange.com/users/258,"StackEdit is a very nice Markdown web app editor that works off-line. I can publish as HTML, but adding a WordPress plugin to work with Markdown is an option. 


Start a new post while offline
As it works offline, you can create any number of documents and update/upload when online
Lets me edit posts I created already with the program
You'll copy the post content in a new SE document and publish it against the same post ID
Spell check
IMHO, that's browser territory
Uploads new posts when I reconnect
After reconnecting, just hit the publish button and it goes live
Has the same features as the online editor (i.e. toolbars, WYSIWYG and code editor)
Just basic features for the editor
Free (as in beer)
Yes.
Works on either Windows or Mac OSX
Yes.
Edit posts currently on the website (with an offline copy)
See Upload when reconnected






  StackEdit.io
  
  StackEdit is a full-featured, open-source Markdown editor based on PageDown, the Markdown library used by Stack Overflow and the other Stack Exchange sites.
  https://github.com/benweet/stackedit/
  
  Features:
  
  
  Real-time HTML preview with Scroll Link feature to bind editor and preview scrollbars
  Markdown Extra/GitHub Flavored Markdown support and Prettify/Highlight.js syntax highlighting
  LaTeX mathematical expressions using MathJax
  WYSIWYG control buttons
  Online synchronization using Google Drive (multi-accounts) and Dropbox
  One click publish on Blogger, Dropbox, Gist, GitHub, Google Drive, SSH server, Tumblr, WordPress
  



",brasofilo,https://softwarerecs.stackexchange.com/users/4720,http://softwarerecs.stackexchange.com/questions/2696/offline-wordpress-post-editor-creator,SCIENCE,softwarerecs.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,1.0,1.0,1.0,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,1.0,0.8888888888888888,0.9333333333333332,0.3333333333333333,0.0,0.3333333333333333,0.7777777777777778,Offline WordPress article editor / creator,"I have a WordPress site hosted on my personal server. I will be unavailable by Internet for a little while, and I'd like to write up some posts for my blog.

Normally, you need to be connected to WordPress to start writing the blog, and it will do offline-saving automatically. But this is limited to one entry, per tab. I could use Notepad, but it doesn't have spell check built in. I could use Microsoft Word, but the ""Paste from Word"" leaves a lot to be desired.

What I'm looking for is a program that does the following:


Start a new post while offline
Lets me edit posts I created already with the program
Spell check
Uploads new posts when I reconnect
Has the same features as the online editor (i.e. toolbars, WYSIWYG and code editor)
Free (as in beer)
Works on either Windows or Mac OSX


Bonus features:


Edit posts currently on the website (with an offline copy)

","StackEdit is a very nice Markdown web app editor that works off-line. I can publish as HTML, but adding a WordPress plugin to work with Markdown is an option. 


Start a new post while offline
As it works offline, you can create any number of documents and update/upload when online
Lets me edit posts I created already with the program
You'll copy the post content in a new SE document and publish it against the same post ID
Spell check
IMHO, that's browser territory
Uploads new posts when I reconnect
After reconnecting, just hit the publish button and it goes live
Has the same features as the online editor (i.e. toolbars, WYSIWYG and code editor)
Just basic features for the editor
Free (as in beer)
Yes.
Works on either Windows or Mac OSX
Yes.
Edit posts currently on the website (with an offline copy)
See Upload when reconnected






  StackEdit.io
  
  StackEdit is a full-featured, open-source Markdown editor based on PageDown, the Markdown library used by Stack Overflow and the other Stack Exchange sites.
  https://github.com/benweet/stackedit/
  
  Features:
  
  
  Real-time HTML preview with Scroll Link feature to bind editor and preview scrollbars
  Markdown Extra/GitHub Flavored Markdown support and Prettify/Highlight.js syntax highlighting
  LaTeX mathematical expressions using MathJax
  WYSIWYG control buttons
  Online synchronization using Google Drive (multi-accounts) and Dropbox
  One click publish on Blogger, Dropbox, Gist, GitHub, Google Drive, SSH server, Tumblr, WordPress
  



"
3268,3268,5207,Finding columns that do not match existing primary key,"I'm trying to add a Foreign Key to a table, but database, Sql Server 2005, does not like it.

It says that columns do not match an existing primary key or unique constraint. 

How can I find the columns in question so I can delete/change them and add the foreign key?
",Chin,https://stackoverflow.com/users/135687,"So you have TableA with a column X, and TableB with column Y. And you want to make Y a foreign key, such that all values of TableB.Y are values in TableA.X, correct?

To do so, TableA.X needs to have either a primary key or a unique constraint on it. It sounds like that is not the case. Make TableA.X unique first, then define your FK from TableB.Y referencing TableA.X
",Shannon Severance,https://stackoverflow.com/users/121544,http://stackoverflow.com/questions/1178377/finding-columns-that-do-not-match-existing-primary-key,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.5555555555555556,0.0,0.3333333333333333,1.0,0.6666666666666666,0.6666666666666666,0.4444444444444444,0.3333333333333333,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.8,1.0,0.3333333333333333,0.6666666666666666,0.8888888888888888,Find columns that do not match the existing primary key,"I'm trying to add a Foreign Key to a table, but database, Sql Server 2005, does not like it.

It says that columns do not match an existing primary key or unique constraint. 

How can I find the columns in question so I can delete/change them and add the foreign key?
","So you have TableA with a column X, and TableB with column Y. And you want to make Y a foreign key, such that all values of TableB.Y are values in TableA.X, correct?

To do so, TableA.X needs to have either a primary key or a unique constraint on it. It sounds like that is not the case. Make TableA.X unique first, then define your FK from TableB.Y referencing TableA.X
"
2956,2956,4703,Manually adding 's' to 'http',"I did a Wireshark capture of my login into a drupal-based website. The website does not use https. And so, quite obviously, I was able to capture my username and password in plain text by simply  using the http.request.method==POST filter in Wireshark. 

Then, I tried to access the same web page by manually adding a s to http in the url. Quite naturally, my browser showed this:



Then I went ahead and did my login again, and did the Wireshark capture again. 

To my surprise, I do not have the any captures corresponding to the http.request.method==POST filter. 

So, my questions:


When I am not really using https, why wasn't I able to capture login id and password in plain text?
What effect did manually adding s to http have?

",pnp,https://security.stackexchange.com/users/9778,"That your browser crosses out the https and turns it red, is because the server could not be verified. You might be talking to an attacker's server as well as your own because you don't have a trusted certificate.

However, that the server is not verified does not mean it doesn't encrypt the connection. All traffic is still encrypted, only the browser can't make sure the ""password"" sent to him by the server (a.k.a. the ""public key"") was really from your server. When you try to use https and the browser can't setup an encrypted channel, it would simply have rejected connecting, giving you one of the errors @ewanm89 mentioned.

So Wireshark has no idea what's going on over this https connection. Because it's port 443, Wireshark can do a guess that it's encrypted HTTP traffic, but it can't actually tell.

To learn more about SSL (the technique behind https), see this question: How does SSL work?
",Luc,https://security.stackexchange.com/users/10863,http://security.stackexchange.com/questions/21509/manually-adding-s-to-http,TECHNOLOGY,security.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,0.5,1.0,1.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.8,0.0,0.0,1.0,0.8888888888888888,"Manually add ""s"" to ""HTTP""","I did a Wireshark capture of my login into a drupal-based website. The website does not use https. And so, quite obviously, I was able to capture my username and password in plain text by simply  using the http.request.method==POST filter in Wireshark. 

Then, I tried to access the same web page by manually adding a s to http in the url. Quite naturally, my browser showed this:



Then I went ahead and did my login again, and did the Wireshark capture again. 

To my surprise, I do not have the any captures corresponding to the http.request.method==POST filter. 

So, my questions:


When I am not really using https, why wasn't I able to capture login id and password in plain text?
What effect did manually adding s to http have?

","That your browser crosses out the https and turns it red, is because the server could not be verified. You might be talking to an attacker's server as well as your own because you don't have a trusted certificate.

However, that the server is not verified does not mean it doesn't encrypt the connection. All traffic is still encrypted, only the browser can't make sure the ""password"" sent to him by the server (a.k.a. the ""public key"") was really from your server. When you try to use https and the browser can't setup an encrypted channel, it would simply have rejected connecting, giving you one of the errors @ewanm89 mentioned.

So Wireshark has no idea what's going on over this https connection. Because it's port 443, Wireshark can do a guess that it's encrypted HTTP traffic, but it can't actually tell.

To learn more about SSL (the technique behind https), see this question: How does SSL work?
"
4618,4618,7320,What types of sauces would pair well with boiled pork knuckles?,"I'm going to be boiling some pork knuckles. What type of sauce would be a good pairing?

I am guessing that because pork knuckles are fatty, the sauce should tend to be sour or pepper-ish to balance out the fatty taste?
",KMC,https://cooking.stackexchange.com/users/8434,"One traditional accompaniment for pork is apple sauce. This follows the convention that a fruity sauce cuts through the fattiness of meat - duck a l'orange is another example.

Apple sauce is easy to make - just taking a cooking apple, chop it up, stew it down with a little water, then stir in some sugar and butter to taste.
",ElendilTheTall,https://cooking.stackexchange.com/users/4194,http://cooking.stackexchange.com/questions/19918/what-types-of-sauces-would-pair-well-with-boiled-pork-knuckles,LIFE_ARTS,cooking.stackexchange.com,1.0,1.0,0.3333333333333333,1.0,0.0,0.0,0.6666666666666666,0.5555555555555556,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,1.0,1.0,0.7777777777777778,1.0,1.0,0.8666666666666666,0.6666666666666666,0.0,0.0,0.8888888888888888,Which kind of sauce is the best for pig hand cooking?,"I'm going to be boiling some pork knuckles. What type of sauce would be a good pairing?

I am guessing that because pork knuckles are fatty, the sauce should tend to be sour or pepper-ish to balance out the fatty taste?
","One traditional accompaniment for pork is apple sauce. This follows the convention that a fruity sauce cuts through the fattiness of meat - duck a l'orange is another example.

Apple sauce is easy to make - just taking a cooking apple, chop it up, stew it down with a little water, then stir in some sugar and butter to taste.
"
220,220,352,Generating all keypad possibilities,"I ran into this question on Stack Overflow. It looked like a really cool thing to try myself, being that I haven't done any recursion for ages (read at least 2 years).

var keypadPossibilities = (function()
{
    var keypad_mapping = [
        [],
        ['a','b','c'],
        ['d','e','f'],
        ['g','h','i'],
        ['j','k','l'],
        ['m','n','o'],
        ['p','q','r','s'],
        ['t','u','v'],
        ['w','x','y','z']
    ];

    function getPosibilities(keypad_mapping_indexes)
    {
        //if only 1 keypad mapping index: simply return the characters
        if ( keypad_mapping_indexes.length === 1)
        {
            return keypad_mapping[keypad_mapping_indexes.shift()];
        }

        //still multiple keypad mapping index left. lets do some magic
        var currentIndex = keypad_mapping_indexes.shift(), posibilities = [],
            characters = keypad_mapping[currentIndex];

        var charactersToGlueAtEnd = getPosibilities(keypad_mapping_indexes);

        for ( var i in characters )
        {
            for ( var j in charactersToGlueAtEnd )
            {
                posibilities.push(characters[i]+charactersToGlueAtEnd[j]);
            }
        }

        return posibilities;
    }

    return function(pressed_keys)
    {
        return getPosibilities(pressed_keys);
    }

})();


Usage would be:

keypadPossibilities([1,2,3]);


It works, so thats nice (no debugging required, that was a first). So, shoot, code remarks, performance remakrs, ... You can go full package. Everything to learn new cool stuff about JS.
",Pinoniq,https://codereview.stackexchange.com/users/26276,"Overall, I'd say recursion is a good way to go. Good use of an IIFE to keep things tidy as well. I do however have some concerns.

Input checking

Firstly, if I pass an empty array, I get a stack overflow, since you only check for a length of 1 - not for a length &lt; 1. I am technically passing the correct type (an array) to the function, so it should handle it (if I pass something that's not an array, then it's my own fault).

Also, if I pass [9] (or [31415]) I just get undefined back, though an empty array would probably be more fitting.

shift() is destructive

Be careful with shift()! You're modifying the array that's been passed to the function, even though it doesn't really ""belong to you"". The caller might still have a use for it.

For instance,

var numbers = [1, 2, 3];
var words = keypadPossibilities(numbers);
console.log(""You typed "" + numbers.length + "" digits, producing "" + words.length + "" possible words"");


will print

You typed 0 digits, producing 27 possible words

Wait, zero digits? Thing is, numbers is suddenly empty; everything's been shifted out by passing it to keypadPossibilities.

This of course also happens when the function recurses, which could spell trouble. Luckily, in your case, you don't use the input array for anything after having recursed, but if you did you'd find that the recursion had truncated it down to empty.

Don't use for...in for arrays

for...in will iterate properties of an object, and with no guaranteed order. It usually works for arrays, but it's not a sure thing. It's semantically different from iterating the actual, indexed elements in the array. So use either a regular ol' for loop, or - if you're targeting modern runtimes, maybe a forEach().

However, you could also use map() and reduce() in this case (see below).

Other stuff

This function-wrapper around a call to getPosibilities is unnecessary:

return function(pressed_keys)
{
    return getPosibilities(pressed_keys);
}


(Oh, and there's a typo: getPosibilities is missing an extra ""s"". I'll just use the corrected name from hereon out)

You could simply replace the above with just:

return getPossibilities;


and done.

However, with the point about shift() in mind, the easiest thing to do would probably be something like

return function(pressed_keys)
{
    return getPossibilities(pressed_keys.slice());
}


Now, pressed_keys gets sliced (duplicated) before it's passed to getPossibilities.

You could also do the slicing in getPossibilities (and do the direct return, shown above), but - as the code's already proved - you don't really need it there. But in the interest of being thorough, it'd look something like:

var currentIndex = keypad_mapping_indexes[0]
// ... snip ...
var charactersToGlueAtEnd = getPossibilities(digits.slice(1)); // duplicate array from index 1 and up


A few notes on style

In terms of style, I'm not a fan of brace-on-new-line in JavaScript. Yes, it works, but it can bite you, since JS will sometimes do automatic semicolon insertion at newlines and break your code. So the convention is to use brace-on-same-line style.

Also by convention, all names in JS should be camelCase. You're using a bit of both; aim for consistency.



Here's a possible version incorporating the points above

var keypadPossibilities = (function() {
  var keypadMapping = [
    null,
    ['a','b','c'],
    ['d','e','f'],
    ['g','h','i'],
    ['j','k','l'],
    ['m','n','o'],
    ['p','q','r','s'],
    ['t','u','v'],
    ['w','x','y','z']
  ];

  function getPossibilities(digits) {
    var characters = keypadMapping[digits.shift()],
        charactersToGlueAtEnd;

    if(!digits.length) {
      return characters || [];
    }

    charactersToGlueAtEnd = getPossibilities(digits);

    return characters.reduce(function (memo, character) {
      var words = charactersToGlueAtEnd.map(function (string) { return character + string; });
      return memo.concat(words);
    }, []);
  }

  return function (digits) {
    return getPossibilities(digits.slice()); // make sure we work on a copy of the input array
  };
})();

",Flambino,https://codereview.stackexchange.com/users/14370,http://codereview.stackexchange.com/questions/57305/generating-all-keypad-possibilities,TECHNOLOGY,codereview.stackexchange.com,0.8888888888888888,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.3333333333333333,0.0,0.4444444444444444,1.0,0.7777777777777778,1.0,1.0,0.9333333333333332,0.6666666666666666,0.0,0.3333333333333333,0.8888888888888888,Generate all keyboard possibilities,"I ran into this question on Stack Overflow. It looked like a really cool thing to try myself, being that I haven't done any recursion for ages (read at least 2 years).

var keypadPossibilities = (function()
{
    var keypad_mapping = [
        [],
        ['a','b','c'],
        ['d','e','f'],
        ['g','h','i'],
        ['j','k','l'],
        ['m','n','o'],
        ['p','q','r','s'],
        ['t','u','v'],
        ['w','x','y','z']
    ];

    function getPosibilities(keypad_mapping_indexes)
    {
        //if only 1 keypad mapping index: simply return the characters
        if ( keypad_mapping_indexes.length === 1)
        {
            return keypad_mapping[keypad_mapping_indexes.shift()];
        }

        //still multiple keypad mapping index left. lets do some magic
        var currentIndex = keypad_mapping_indexes.shift(), posibilities = [],
            characters = keypad_mapping[currentIndex];

        var charactersToGlueAtEnd = getPosibilities(keypad_mapping_indexes);

        for ( var i in characters )
        {
            for ( var j in charactersToGlueAtEnd )
            {
                posibilities.push(characters[i]+charactersToGlueAtEnd[j]);
            }
        }

        return posibilities;
    }

    return function(pressed_keys)
    {
        return getPosibilities(pressed_keys);
    }

})();


Usage would be:

keypadPossibilities([1,2,3]);


It works, so thats nice (no debugging required, that was a first). So, shoot, code remarks, performance remakrs, ... You can go full package. Everything to learn new cool stuff about JS.
","Overall, I'd say recursion is a good way to go. Good use of an IIFE to keep things tidy as well. I do however have some concerns.

Input checking

Firstly, if I pass an empty array, I get a stack overflow, since you only check for a length of 1 - not for a length &lt; 1. I am technically passing the correct type (an array) to the function, so it should handle it (if I pass something that's not an array, then it's my own fault).

Also, if I pass [9] (or [31415]) I just get undefined back, though an empty array would probably be more fitting.

shift() is destructive

Be careful with shift()! You're modifying the array that's been passed to the function, even though it doesn't really ""belong to you"". The caller might still have a use for it.

For instance,

var numbers = [1, 2, 3];
var words = keypadPossibilities(numbers);
console.log(""You typed "" + numbers.length + "" digits, producing "" + words.length + "" possible words"");


will print

You typed 0 digits, producing 27 possible words

Wait, zero digits? Thing is, numbers is suddenly empty; everything's been shifted out by passing it to keypadPossibilities.

This of course also happens when the function recurses, which could spell trouble. Luckily, in your case, you don't use the input array for anything after having recursed, but if you did you'd find that the recursion had truncated it down to empty.

Don't use for...in for arrays

for...in will iterate properties of an object, and with no guaranteed order. It usually works for arrays, but it's not a sure thing. It's semantically different from iterating the actual, indexed elements in the array. So use either a regular ol' for loop, or - if you're targeting modern runtimes, maybe a forEach().

However, you could also use map() and reduce() in this case (see below).

Other stuff

This function-wrapper around a call to getPosibilities is unnecessary:

return function(pressed_keys)
{
    return getPosibilities(pressed_keys);
}


(Oh, and there's a typo: getPosibilities is missing an extra ""s"". I'll just use the corrected name from hereon out)

You could simply replace the above with just:

return getPossibilities;


and done.

However, with the point about shift() in mind, the easiest thing to do would probably be something like

return function(pressed_keys)
{
    return getPossibilities(pressed_keys.slice());
}


Now, pressed_keys gets sliced (duplicated) before it's passed to getPossibilities.

You could also do the slicing in getPossibilities (and do the direct return, shown above), but - as the code's already proved - you don't really need it there. But in the interest of being thorough, it'd look something like:

var currentIndex = keypad_mapping_indexes[0]
// ... snip ...
var charactersToGlueAtEnd = getPossibilities(digits.slice(1)); // duplicate array from index 1 and up


A few notes on style

In terms of style, I'm not a fan of brace-on-new-line in JavaScript. Yes, it works, but it can bite you, since JS will sometimes do automatic semicolon insertion at newlines and break your code. So the convention is to use brace-on-same-line style.

Also by convention, all names in JS should be camelCase. You're using a bit of both; aim for consistency.



Here's a possible version incorporating the points above

var keypadPossibilities = (function() {
  var keypadMapping = [
    null,
    ['a','b','c'],
    ['d','e','f'],
    ['g','h','i'],
    ['j','k','l'],
    ['m','n','o'],
    ['p','q','r','s'],
    ['t','u','v'],
    ['w','x','y','z']
  ];

  function getPossibilities(digits) {
    var characters = keypadMapping[digits.shift()],
        charactersToGlueAtEnd;

    if(!digits.length) {
      return characters || [];
    }

    charactersToGlueAtEnd = getPossibilities(digits);

    return characters.reduce(function (memo, character) {
      var words = charactersToGlueAtEnd.map(function (string) { return character + string; });
      return memo.concat(words);
    }, []);
  }

  return function (digits) {
    return getPossibilities(digits.slice()); // make sure we work on a copy of the input array
  };
})();

"
4467,4467,7089,"What is the difference between unicast, anycast, broadcast and multicast traffic?","I have never had the privilege of working in an environment that required complicated routing or if it did require it, it was handled upstream of me. I've always used very simple static routing configurations and never needed to do any multipath routing -- hence my general confusion regarding this subject. I would like to understand multicasting and anycasting better. 


What is the difference between unicast, anycast, broadcast and multicast traffic?
What situations are they generally used in and why (e.g., what applications use which method)?
How do you calculate how much broadcast traffic is too much for a given network segment or broadcast domain?
What are the security implications of allowing broadcast and multicast traffic?

",kce,https://serverfault.com/users/62491,"Simply put:

------------------------------------------------------------
| TYPE      | ASSOCIATIONS     | SCOPE           | EXAMPLE |
------------------------------------------------------------
| Unicast   | 1 to 1           | Whole network   | HTTP    | 
------------------------------------------------------------
| Broadcast | 1 to Many        | Subnet          | ARP     |
------------------------------------------------------------
| Multicast | One/Many to Many | Defined horizon | SLP     |
------------------------------------------------------------
| Anycast   | Many to Few      | Whole network   | 6to4    |
------------------------------------------------------------


Unicast is used when two network nodes need to talk to each other. This is pretty straight forward, so I'm not going to spend much time on it. TCP by definition is a Unicast protocol, except when there is Anycast involved (more on that below).

When you need to have more than two nodes see the traffic, you have options. 

If all of the nodes are on the same subnet, then broadcast becomes a viable solution. All nodes on the subnet will see all traffic. There is no TCP-like connection state maintained. Broadcast is a layer 2 feature in the Ethernet protocol, and also a layer 3 feature in IPv4.

Multicast is like a broadcast that can cross subnets, but unlike broadcast does not touch all nodes. Nodes have to subscribe to a multicast group to receive information. Multicast protocols are usually UDP protocols, since by definition no connection-state can be maintained. Nodes transmitting data to a multicast group do not know what nodes are receiving. By default, Internet routers do not pass Multicast traffic. For internal use, though, it is perfectly allowed; thus, ""Defined horizon"" in the above chart. Multicast is a layer 3 feature of IPv4 &amp; IPv6.

To use anycast you advertise the same network in multiple spots of the Internet, and rely on shortest-path calculations to funnel clients to your multiple locations. As far the network nodes themselves are concerned, they're using a unicast connection to talk to your anycasted nodes. For more on Anycast, try: What is &quot;anycast&quot; and how is it helpful?. Anycast is also a layer 3 feature, but is a function of how route-coalescing happens.



Examples

Some examples of how the non-Unicast methods are used in the real Internet.

BroadcastARP is a broadcast protocol, and is used by TCP/IP stacks to determine how to send traffic to other nodes on the network. If the destination is on the same subnet, ARP is used to figure out the MAC address that goes to the stated IP address. This is a Level 2 (Ethernet) broadcast, to the reserved FF:FF:FF:FF:FF:FF MAC address.

Also, Microsoft's machine browsing protocol is famously broadcast based. Work-arounds like WINS were created to allow cross-subnet browsing. This involves a Level 3 (IP) broadcast, which is an IP packet with the Destination address listed as the broadcast address of the subnet (in 192.168.101.0/24, the broadcast address would be 192.168.101.255).

The NTP protocol allows a broadcast method for announcing time sources.

MulticastInside a corporate network, Multicast can deliver live video to multiple nodes without having to have massive bandwidth on the part of the server delivering the video feed. This way you can have a video server feeding a 720p stream on only a 100Mb connection, and yet still serve that feed to 3000 clients. 

When Novell moved away from IPX and to IP, they had to pick a service-advertising protocol to replace the SAP protocol in IPX. In IPX, the Service Advertising Protocol, did a network-wide announcement every time it announced a service was available. As TCP/IP lacked such a global announcement protocol, Novell chose to use a Multicast based protocol instead: the Service Location Protocol. New servers announce their services on the SLP multicast group. Clients looking for specific types of services announce their need to the multicast group and listen for unicasted replies. 

HP printers announce their presence on a multicast group by default. With the right tools, it makes it real easy to learn what printers are available on your network.

The NTP protocol also allows a multicast method (IP 224.0.1.1) for announcing time sources to areas beyond just the one subnet. 

Anycast
Anycast is a bit special since Unicast layers on top of it. Anycast is announcing the same network in different parts of the network, in order to decrease the network hops needed to get to that network. 

The 6to4 IPv6 transition protocol uses Anycast. 6to4 gateways announce their presence on a specific IP, 192.88.99.1. Clients looking to use a 6to4 gateway send traffic to 192.88.99.1 and trust the network to deliver the connection request to a 6to4 router.

NTP services for especially popular NTP hosts may very well be anycasted, but I don't have proof of this. There is nothing in the protocol to prevent it.

Other services use Anycast to improve data locality to end users. Google does Anycast with its search pages in some places (and geo-IP in others). The Root DNS servers use Anycast for similar reasons. ServerFault itself just might go there, they do have datacenters in New York and Oregon, but hasn't gone there yet.



Network concerns

Excessive broadcast traffic can rob all nodes in that subnet of bandwidth. This is less of a concern these days with full-duplex GigE ports, but back in the half-duplex 10Mb days a broadcast storm could bring a network to a halt real fast. Those half-duplex networks with one big collision domain across all nodes were especially vulnerable to broadcast storms, which is why networking books, especially older ones, say to keep an eye on broadcast traffic. Switched/Full-Duplex networks are a lot harder to bring to a halt with a broadcast storm, but it can still happen. Broadcast is required for correct functioning of IP networks. 

Multicast has the same possibility for abuse. If one node on the multicast group starts sending huge amounts of traffic to that group, all subscribed nodes will see all of that traffic. As with broadcast, excessive Mcast traffic can increase the possibilities of collisions on such connections where that is a problem. 

Multicast is an optional feature with IPv4, but required for IPv6. The IPv4 broadcast is replaced by multicast in IPv6 (See also: Why can&#39;t IPv6 send broadcasts?). It is frequently turned off on IPv4 networks. Not coincidentally, enabling multicast is one of the many reasons network-engineers are leery of moving to IPv6 before they have to do it.

Calculating how much traffic is too much traffic depends on a few things


Half vs Full Duplex: Half-duplex networks have much lower tolerances for bcast/mcast traffic.
Speed of network ports: The faster your network, the less of an issue this becomes. In the 10Mb ethernet days 5-10% of traffic on a port could be bcast traffic, if not more, but on GigE less than 1% (probably way less) is more likely. 
Number of nodes on the network: The more nodes you have, the more unavoidable broadcast traffic you'll incur (ARP). If you have broadcast specific protocols in use, Windows browsing or other things like cluster heartbeats, where problems start will change. 
Network technology: Wired Ethernet is fast enough that so long as you have modern gear driving it, bcast/mcast isn't likely to cause you problems. Wireless, on the other hand, can suffer from excessive broadcast traffic as it is a shared medium amongst all nodes and therefore in a single collision domain.


In the end, Bcast and Mcast traffic rob ports of bandwidth off the top. When you start to worry is highly dependent on your individual network and tolerance for variable performance. In general, network-node counts haven't scaled as fast as network speeds so the overall broadcast percentage-as-traffic number has been dropping over time. 

Some networks disallow Multicast for specific reasons, and others have never taken the time to set it up. There are some multicast protocols that can reveal interesting information (SLP is one such) to anyone listening for the right things. Personally, I don't mind minor multicast traffic as the biggest annoyance I've seen with it is polluted network captures when I'm doing some network analysis; and for that there are filters.
",sysadmin1138,https://serverfault.com/users/3038,http://serverfault.com/questions/279482,TECHNOLOGY,serverfault.com,1.0,0.8888888888888888,0.0,0.0,1.0,0.6666666666666666,0.5555555555555556,0.3333333333333333,1.0,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,0.0,0.3333333333333333,0.0,0.6666666666666666,0.0,0.8888888888888888,0.7777777777777778,0.7777777777777778,0.7777777777777778,1.0,1.0,0.0,0.0,1.0,1.0,"What's the difference between unicast, anycast, broadcast and multicast communication?","I have never had the privilege of working in an environment that required complicated routing or if it did require it, it was handled upstream of me. I've always used very simple static routing configurations and never needed to do any multipath routing -- hence my general confusion regarding this subject. I would like to understand multicasting and anycasting better. 


What is the difference between unicast, anycast, broadcast and multicast traffic?
What situations are they generally used in and why (e.g., what applications use which method)?
How do you calculate how much broadcast traffic is too much for a given network segment or broadcast domain?
What are the security implications of allowing broadcast and multicast traffic?

","Simply put:

------------------------------------------------------------
| TYPE      | ASSOCIATIONS     | SCOPE           | EXAMPLE |
------------------------------------------------------------
| Unicast   | 1 to 1           | Whole network   | HTTP    | 
------------------------------------------------------------
| Broadcast | 1 to Many        | Subnet          | ARP     |
------------------------------------------------------------
| Multicast | One/Many to Many | Defined horizon | SLP     |
------------------------------------------------------------
| Anycast   | Many to Few      | Whole network   | 6to4    |
------------------------------------------------------------


Unicast is used when two network nodes need to talk to each other. This is pretty straight forward, so I'm not going to spend much time on it. TCP by definition is a Unicast protocol, except when there is Anycast involved (more on that below).

When you need to have more than two nodes see the traffic, you have options. 

If all of the nodes are on the same subnet, then broadcast becomes a viable solution. All nodes on the subnet will see all traffic. There is no TCP-like connection state maintained. Broadcast is a layer 2 feature in the Ethernet protocol, and also a layer 3 feature in IPv4.

Multicast is like a broadcast that can cross subnets, but unlike broadcast does not touch all nodes. Nodes have to subscribe to a multicast group to receive information. Multicast protocols are usually UDP protocols, since by definition no connection-state can be maintained. Nodes transmitting data to a multicast group do not know what nodes are receiving. By default, Internet routers do not pass Multicast traffic. For internal use, though, it is perfectly allowed; thus, ""Defined horizon"" in the above chart. Multicast is a layer 3 feature of IPv4 &amp; IPv6.

To use anycast you advertise the same network in multiple spots of the Internet, and rely on shortest-path calculations to funnel clients to your multiple locations. As far the network nodes themselves are concerned, they're using a unicast connection to talk to your anycasted nodes. For more on Anycast, try: What is &quot;anycast&quot; and how is it helpful?. Anycast is also a layer 3 feature, but is a function of how route-coalescing happens.



Examples

Some examples of how the non-Unicast methods are used in the real Internet.

BroadcastARP is a broadcast protocol, and is used by TCP/IP stacks to determine how to send traffic to other nodes on the network. If the destination is on the same subnet, ARP is used to figure out the MAC address that goes to the stated IP address. This is a Level 2 (Ethernet) broadcast, to the reserved FF:FF:FF:FF:FF:FF MAC address.

Also, Microsoft's machine browsing protocol is famously broadcast based. Work-arounds like WINS were created to allow cross-subnet browsing. This involves a Level 3 (IP) broadcast, which is an IP packet with the Destination address listed as the broadcast address of the subnet (in 192.168.101.0/24, the broadcast address would be 192.168.101.255).

The NTP protocol allows a broadcast method for announcing time sources.

MulticastInside a corporate network, Multicast can deliver live video to multiple nodes without having to have massive bandwidth on the part of the server delivering the video feed. This way you can have a video server feeding a 720p stream on only a 100Mb connection, and yet still serve that feed to 3000 clients. 

When Novell moved away from IPX and to IP, they had to pick a service-advertising protocol to replace the SAP protocol in IPX. In IPX, the Service Advertising Protocol, did a network-wide announcement every time it announced a service was available. As TCP/IP lacked such a global announcement protocol, Novell chose to use a Multicast based protocol instead: the Service Location Protocol. New servers announce their services on the SLP multicast group. Clients looking for specific types of services announce their need to the multicast group and listen for unicasted replies. 

HP printers announce their presence on a multicast group by default. With the right tools, it makes it real easy to learn what printers are available on your network.

The NTP protocol also allows a multicast method (IP 224.0.1.1) for announcing time sources to areas beyond just the one subnet. 

Anycast
Anycast is a bit special since Unicast layers on top of it. Anycast is announcing the same network in different parts of the network, in order to decrease the network hops needed to get to that network. 

The 6to4 IPv6 transition protocol uses Anycast. 6to4 gateways announce their presence on a specific IP, 192.88.99.1. Clients looking to use a 6to4 gateway send traffic to 192.88.99.1 and trust the network to deliver the connection request to a 6to4 router.

NTP services for especially popular NTP hosts may very well be anycasted, but I don't have proof of this. There is nothing in the protocol to prevent it.

Other services use Anycast to improve data locality to end users. Google does Anycast with its search pages in some places (and geo-IP in others). The Root DNS servers use Anycast for similar reasons. ServerFault itself just might go there, they do have datacenters in New York and Oregon, but hasn't gone there yet.



Network concerns

Excessive broadcast traffic can rob all nodes in that subnet of bandwidth. This is less of a concern these days with full-duplex GigE ports, but back in the half-duplex 10Mb days a broadcast storm could bring a network to a halt real fast. Those half-duplex networks with one big collision domain across all nodes were especially vulnerable to broadcast storms, which is why networking books, especially older ones, say to keep an eye on broadcast traffic. Switched/Full-Duplex networks are a lot harder to bring to a halt with a broadcast storm, but it can still happen. Broadcast is required for correct functioning of IP networks. 

Multicast has the same possibility for abuse. If one node on the multicast group starts sending huge amounts of traffic to that group, all subscribed nodes will see all of that traffic. As with broadcast, excessive Mcast traffic can increase the possibilities of collisions on such connections where that is a problem. 

Multicast is an optional feature with IPv4, but required for IPv6. The IPv4 broadcast is replaced by multicast in IPv6 (See also: Why can&#39;t IPv6 send broadcasts?). It is frequently turned off on IPv4 networks. Not coincidentally, enabling multicast is one of the many reasons network-engineers are leery of moving to IPv6 before they have to do it.

Calculating how much traffic is too much traffic depends on a few things


Half vs Full Duplex: Half-duplex networks have much lower tolerances for bcast/mcast traffic.
Speed of network ports: The faster your network, the less of an issue this becomes. In the 10Mb ethernet days 5-10% of traffic on a port could be bcast traffic, if not more, but on GigE less than 1% (probably way less) is more likely. 
Number of nodes on the network: The more nodes you have, the more unavoidable broadcast traffic you'll incur (ARP). If you have broadcast specific protocols in use, Windows browsing or other things like cluster heartbeats, where problems start will change. 
Network technology: Wired Ethernet is fast enough that so long as you have modern gear driving it, bcast/mcast isn't likely to cause you problems. Wireless, on the other hand, can suffer from excessive broadcast traffic as it is a shared medium amongst all nodes and therefore in a single collision domain.


In the end, Bcast and Mcast traffic rob ports of bandwidth off the top. When you start to worry is highly dependent on your individual network and tolerance for variable performance. In general, network-node counts haven't scaled as fast as network speeds so the overall broadcast percentage-as-traffic number has been dropping over time. 

Some networks disallow Multicast for specific reasons, and others have never taken the time to set it up. There are some multicast protocols that can reveal interesting information (SLP is one such) to anyone listening for the right things. Personally, I don't mind minor multicast traffic as the biggest annoyance I've seen with it is polluted network captures when I'm doing some network analysis; and for that there are filters.
"
3859,3859,6142,Is there a list of Mitzvot and their corresponding body parts?,"The Talmud (Makkot 23B)and the Zohar (1:170B - unverified English translation here) say that the 248 positive commandments correspond to the 248 limbs of the human body. (The Mishna (Ohalot 1:8) lists the 248 Halachic limbs). The Talmud also says that the 365 Negative commandments correspond to the days of the year.

The Zohar adds that the 365 negative commandments also correspond to the 365 sinews in the human body (See Yonatan Ben Uziel Bereshit 1:27), and connects them to the days of the year.

R' Chaim Vital, in Shaar HaKavanot (Shaar 1, Part 1) says that ""Each of the 248 spiritual limbs gets its nourishment from a particular mitzvah that corresponds to that limb. When a person fails to perform that particular mitzvah, the corresponding limb will lack its proper nourishment..."" (translation from here)

Is there any source which tells us which limb (and/or sinew) each Mitzvah corresponds to?

As an example, the Zohar referenced above (1:170B), connects Gid Hanasheh (sciatic nerve), one of the 365 sinews, to the prohibition of eating on Tisha B'av.
",Menachem,https://judaism.stackexchange.com/users/603,"The classic Sefer Chareidim by R' Elazar Azikri (d.1600) catalogs all the mitzvos according to body parts. (R' Elazar Azikri was also the author of the poem, Yedid Nefesh.) An abbreviated version, Kitzur Sefer Chareidim, was written by R' Avraham Danzig, author of the Chayei Adam. The sefer does not attempt to establish a precise one-for-one match for each limb and sinew. It lists the limbs only in a very broad sense, eyes, arms, legs, and so on, and then lists the various mitzvos (Biblical and Rabbinic) that are performed with that part of the body.

Sefer Chareidim happens to be one of my favorite seforim. I can't recommend it highly enough.
",LazerA,https://judaism.stackexchange.com/users/1216,http://judaism.stackexchange.com/questions/10406/is-there-a-list-of-mitzvot-and-their-corresponding-body-parts,CULTURE,judaism.stackexchange.com,1.0,0.6666666666666666,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.4444444444444444,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.8888888888888888,0.8888888888888888,0.5555555555555556,1.0,1.0,0.8666666666666666,0.0,0.0,1.0,0.8888888888888888,Do you have a list of rite of passage and corresponding body parts?,"The Talmud (Makkot 23B)and the Zohar (1:170B - unverified English translation here) say that the 248 positive commandments correspond to the 248 limbs of the human body. (The Mishna (Ohalot 1:8) lists the 248 Halachic limbs). The Talmud also says that the 365 Negative commandments correspond to the days of the year.

The Zohar adds that the 365 negative commandments also correspond to the 365 sinews in the human body (See Yonatan Ben Uziel Bereshit 1:27), and connects them to the days of the year.

R' Chaim Vital, in Shaar HaKavanot (Shaar 1, Part 1) says that ""Each of the 248 spiritual limbs gets its nourishment from a particular mitzvah that corresponds to that limb. When a person fails to perform that particular mitzvah, the corresponding limb will lack its proper nourishment..."" (translation from here)

Is there any source which tells us which limb (and/or sinew) each Mitzvah corresponds to?

As an example, the Zohar referenced above (1:170B), connects Gid Hanasheh (sciatic nerve), one of the 365 sinews, to the prohibition of eating on Tisha B'av.
","The classic Sefer Chareidim by R' Elazar Azikri (d.1600) catalogs all the mitzvos according to body parts. (R' Elazar Azikri was also the author of the poem, Yedid Nefesh.) An abbreviated version, Kitzur Sefer Chareidim, was written by R' Avraham Danzig, author of the Chayei Adam. The sefer does not attempt to establish a precise one-for-one match for each limb and sinew. It lists the limbs only in a very broad sense, eyes, arms, legs, and so on, and then lists the various mitzvos (Biblical and Rabbinic) that are performed with that part of the body.

Sefer Chareidim happens to be one of my favorite seforim. I can't recommend it highly enough.
"
3647,3647,5819,beamer + lstlistings + overlay -> wrong numbering in caption,"In my tex file I have the following code. It results in the Listing being numbered with an increasing index. Is there a way to prevent this from happening? (see screenshot: the second slide should say ""Listing 1: Function"" too)

\documentclass{beamer}
\usetheme{Goettingen}
%\usecolortheme{whale}

\setbeamertemplate{frametitle continuation}[from second] % (cont.) from second slide
\setbeamertemplate{bibliography item}{[\theenumiv]} % numbers instead of silly pictures
\setbeamertemplate{footline}[frame number]
\beamertemplatenavigationsymbolsempty % remove navigationbar

\usepackage[font=bf,skip=\baselineskip]{caption}
\captionsetup[lstlisting]{font={footnotesize}}

\usepackage{color}
\definecolor{light-gray}{gray}{0.85}
\definecolor{darkgreen}{rgb}{0.0, 0.5, 0.0} % for green colour in code
\usepackage{listings}
\usepackage[T1]{fontenc}
\lstset{
    basicstyle=\tiny,
    escapeinside={&lt;@}{@&gt;},
    numbers=left, 
    language=C, 
    morekeywords={throw, assert},
    frame=single,
    captionpos=b,
    commentstyle=\color{darkgreen}}


\begin{document}
\begin{frame}[fragile,containsverbatim]{Example}
    \begin{lstlisting}[caption={Function}]
functionA(x){
  a = functionB(x)
  return a
}

functionB(x){
  b =  &lt;@\only&lt;1&gt;{GLOBAL\_VAR}\only&lt;2&gt;{\textcolor{darkgreen}{GLOBAL\_VAR}}@&gt;
  b++
  return b
}
    \end{lstlisting}
\end{frame}

\end{document}

",stklik,https://tex.stackexchange.com/users/70862,"What you need is

\resetcounteronoverlays{lstlisting}


to prevent the counter from incrementing when using overlays. The complete code:

\documentclass{beamer}
\usetheme{Goettingen}
%\usecolortheme{whale}

\setbeamertemplate{frametitle continuation}[from second] % (cont.) from second slide
\setbeamertemplate{bibliography item}{[\theenumiv]} % numbers instead of silly pictures
\setbeamertemplate{footline}[frame number]
\beamertemplatenavigationsymbolsempty % remove navigationbar

\usepackage[font=bf,skip=\baselineskip]{caption}
\captionsetup[lstlisting]{font={footnotesize}}

\usepackage{color}
\definecolor{light-gray}{gray}{0.85}
\definecolor{darkgreen}{rgb}{0.0, 0.5, 0.0} % for green colour in code
\usepackage{listings}
\usepackage[T1]{fontenc}
\lstset{
    basicstyle=\tiny,
    escapeinside={&lt;@}{@&gt;},
    numbers=left, 
    language=C, 
    morekeywords={throw, assert},
    frame=single,
    captionpos=b,
    commentstyle=\color{darkgreen}}

\resetcounteronoverlays{lstlisting}

\begin{document}
\begin{frame}[fragile,containsverbatim]{Example}
    \begin{lstlisting}[caption={Function}]
functionA(x){
  a = functionB(x)
  return a
}

functionB(x){
  b =  &lt;@\only&lt;1&gt;{GLOBAL\_VAR}\only&lt;2&gt;{\textcolor{darkgreen}{GLOBAL\_VAR}}@&gt;
  b++
  return b
}
    \end{lstlisting}
\end{frame}

\end{document}


The result:


",Gonzalo Medina,https://tex.stackexchange.com/users/3954,http://tex.stackexchange.com/questions/258090/beamer-lstlistings-overlay-wrong-numbering-in-caption,TECHNOLOGY,tex.stackexchange.com,1.0,0.3333333333333333,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.8888888888888888,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.0,0.0,0.8888888888888888,beamer + lstlistings + overlay -> wrong numbering in caption,"In my tex file I have the following code. It results in the Listing being numbered with an increasing index. Is there a way to prevent this from happening? (see screenshot: the second slide should say ""Listing 1: Function"" too)

\documentclass{beamer}
\usetheme{Goettingen}
%\usecolortheme{whale}

\setbeamertemplate{frametitle continuation}[from second] % (cont.) from second slide
\setbeamertemplate{bibliography item}{[\theenumiv]} % numbers instead of silly pictures
\setbeamertemplate{footline}[frame number]
\beamertemplatenavigationsymbolsempty % remove navigationbar

\usepackage[font=bf,skip=\baselineskip]{caption}
\captionsetup[lstlisting]{font={footnotesize}}

\usepackage{color}
\definecolor{light-gray}{gray}{0.85}
\definecolor{darkgreen}{rgb}{0.0, 0.5, 0.0} % for green colour in code
\usepackage{listings}
\usepackage[T1]{fontenc}
\lstset{
    basicstyle=\tiny,
    escapeinside={&lt;@}{@&gt;},
    numbers=left, 
    language=C, 
    morekeywords={throw, assert},
    frame=single,
    captionpos=b,
    commentstyle=\color{darkgreen}}


\begin{document}
\begin{frame}[fragile,containsverbatim]{Example}
    \begin{lstlisting}[caption={Function}]
functionA(x){
  a = functionB(x)
  return a
}

functionB(x){
  b =  &lt;@\only&lt;1&gt;{GLOBAL\_VAR}\only&lt;2&gt;{\textcolor{darkgreen}{GLOBAL\_VAR}}@&gt;
  b++
  return b
}
    \end{lstlisting}
\end{frame}

\end{document}

","What you need is

\resetcounteronoverlays{lstlisting}


to prevent the counter from incrementing when using overlays. The complete code:

\documentclass{beamer}
\usetheme{Goettingen}
%\usecolortheme{whale}

\setbeamertemplate{frametitle continuation}[from second] % (cont.) from second slide
\setbeamertemplate{bibliography item}{[\theenumiv]} % numbers instead of silly pictures
\setbeamertemplate{footline}[frame number]
\beamertemplatenavigationsymbolsempty % remove navigationbar

\usepackage[font=bf,skip=\baselineskip]{caption}
\captionsetup[lstlisting]{font={footnotesize}}

\usepackage{color}
\definecolor{light-gray}{gray}{0.85}
\definecolor{darkgreen}{rgb}{0.0, 0.5, 0.0} % for green colour in code
\usepackage{listings}
\usepackage[T1]{fontenc}
\lstset{
    basicstyle=\tiny,
    escapeinside={&lt;@}{@&gt;},
    numbers=left, 
    language=C, 
    morekeywords={throw, assert},
    frame=single,
    captionpos=b,
    commentstyle=\color{darkgreen}}

\resetcounteronoverlays{lstlisting}

\begin{document}
\begin{frame}[fragile,containsverbatim]{Example}
    \begin{lstlisting}[caption={Function}]
functionA(x){
  a = functionB(x)
  return a
}

functionB(x){
  b =  &lt;@\only&lt;1&gt;{GLOBAL\_VAR}\only&lt;2&gt;{\textcolor{darkgreen}{GLOBAL\_VAR}}@&gt;
  b++
  return b
}
    \end{lstlisting}
\end{frame}

\end{document}


The result:


"
533,533,838,Weren't there originally going to be nine Star Wars films?,"I seem to remember reading that there were going to be three trilogies originally in Star Wars, i.e. they would add episodes 7 - 9.

Was that ever the case? What happened to that plan?

Update: looks like that original plan might be back after all!
",Wikis,https://scifi.stackexchange.com/users/143,"Depending on his plans at the time and when you asked him, George Lucas has variously said there would be one film, three films, six films, nine films or 12 films.

A trilogy of trilogies

It was widely reported in 1980 that there would be nine films: a trilogy of trilogies.

Al Walentis wrote in the May 25, 1980 Reading Eagle:


  Lucas originally envisioned ""Star Wars"" as a single feature, but his 200-page screenplay proved too unwieldy. He then began tinkering with his story line, cutting it apart, sorting our all the various subplots. The script finally was pieced together as three distinct trilogies. 
  
  ""There are essentially nine films,"" Lucas said. ""The first trilogy is about the young Ben Kenobi and the early life of Luke Skywalker's father when Luke was a young boy. The first trilogy takes place some 20 years before the second. About a year elapses between each story of the first trilogy. The whole adventure - encompassing the three trilogies - spans about 40 years.""


Irvin Kershner, director of The Empire Strikes Back (1980), was also on-script with the nine-film plan. Tom Buckley of the N.Y. Times wrote on May 25, 1980's The Spokesman-Review:


  ""I told George I didn't want to do a sequel,"" Kershner said.""He said, 'I don't blame you. Neither would I, but this isn't. It's the second act of the second trilogy of nine films I plan to make in this theme. I want it to be better than mine.' ...""


On the same page of the same paper, Richard Freeman of Newhouse News wrote:


  Three years ago, Hamill signed up for three ""Star Wars"" films, of which ""The Empire Strikes Back"" is the second. The third - still in the planning stage - will be called ""The revenge of the Jedi,"" and Hamill worries that these titles will suggest the various Pink Panther sequels to audiences.
  
  If things work out, these three movies will eventually constitute only a third of the projected nine-movie ""Star Wars"" saga, but Hamill doesn't plan to be in any of the others.


On the following page of the same paper, Aljean Harmetz of the New York Times wrote:


  The ""Star Wars"" George Lucas has created in his mind will take nine movies to tell. ""Star Wars"" is actually ""Star Wars, Episode IV: A New Hope,"" the first movie of the second trilogy. ""The Empire Strikes Back"" is ""Star Wars, Episode V,"" while ""The Return of the Jedi' is episode VI. The first trilogy deals with the young Darth Vader and the young Ben Kenobi. At the end of the first trilogy, Luke Skywalker is four years old. Only the robots - R2D2 and C-3PO - will be characters in all the movies.
  
  He chose to start in the middle because the first trilogy is, he says, ""more plot-oriented, more soap-operaish."" He adds that the ""central core problem"" of ""Star Wars"" hasn't even been stated yet. Although he originally saw Star Wars as six movies, his ""dream"" was only for ""Star Wars"" to do well enough so that he could finish the three movies in the second trilogy. ""If people had laughed 'Star Wars' off the screen, I'd have been less surprised than I was at what did happen,"" he says. ""Until the day it opened, I felt it would do $16 million and, if I pushed hard, I could make 'Empire.'""


An interview with Harrison Ford in Lakeland Ledger of July 4, 1980:


  Like Mark Hamill (Luke Skywalker) and Carrie Fisher (Princess Leia), Ford has already signed up for the third ""Star Wars"" film, which is tentatively entitled ""The Revenge of the Jedi."" This will conclude the middle trilogy of the nine-part series, and Ford does not know whether it signals the end of Han Solo. It is up to George Lucas, the creator of the saga.
  
  ""He has an idea of doing one (involving what happened to Solo) about 15 years from now, when I'll be 53. That's something I'd like to do.""


The Phoenix of June 21, 1980 also mentions the three trilogies spanning 40 years, and:


  Thereafter, Lucas will go back to the first trilogy, starting with a story so far back that it does not include Darth Vader.
  
  If interest sustains, Star Wars could be in production well into the 1990s. David Prowse figures he'll get killed off (by Luke Skywalker?) in the seventh or eighth story.


At least one trilogy

And it seems at least one trilogy was planned from the start. One week after Star Wars came out, The Leader-Post of June 3, 1977 says:


  [Mark] Hamill said he believes Lucas plans a Star Wars trilogy because all the actors are under contract for two more films.


Reporting on the film's record-breaking success, an AP story in May 26, 1978's Schenectady Gazette says:


  Lucas had originally conceived of ""Star Wars"" as a trilogy. Work on the first sequel is well under way...


12 films

An article by Charles Champlin of the Los Angeles Times, printed in The Tuscaloosa News of June 15, 1979, quotes The Empire Strikes Back producer Gary Kurtz:


  Kurtz says that there are on paper the makings of a grand design of 12 films, including three stories that would historically precede the Skywalker takes (prequels, as they are dreadfully know these days).


A May 5, 1980 article quotes David Prowse as saying ""They plan to do 12 movies.""

13 movies

Finally, this 1979 promo advert for Kenner Star Wars claims:


  ""That's right, Star Wars is forever. George Lucas and 20th Century Fox have plans for twelve more block-busting chapters to the Star Wars story.


So does that make 13?

15 and more

Lucas is selling Lucasfilm and the Star Wars rights to the Walt Disney Company who according to CNN (October 31, 2012) will make at least three sequel films, and then another film every two years (which might might not be sequels), and also possibly a television series:


  ""It's now time for me to pass Star Wars on to a new generation of filmmakers,"" George Lucas said in a written statement. ""I've always believed that Star Wars could live beyond me, and I thought it was important to set up the transition during my lifetime.""
  
  Lucas said he will work as a creative consultant on Star Wars Episode 7, the first of a planned new trilogy of live-action Star Wars movies. It is targeted for release in 2015, Disney said.
  
  Disney hopes to essentially relaunch the Star Wars film franchise, which had its last installment in 2005 with Revenge of the Sith. Following the three planned sequels, the company envisions releasing even more Star Wars movies at a rate of a new film every two to three years.
  
  Future movies may not be sequels but movies that focus on fringe characters. Disney also believes there is potential for a television series.

",Hugo,https://scifi.stackexchange.com/users/6041,http://scifi.stackexchange.com/questions/1207/werent-there-originally-going-to-be-nine-star-wars-films,LIFE_ARTS,scifi.stackexchange.com,1.0,0.8888888888888888,0.0,1.0,1.0,1.0,0.7777777777777778,0.7777777777777778,0.6666666666666666,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,0.8888888888888888,1.0,1.0,1.0,0.9333333333333332,0.0,0.0,0.3333333333333333,1.0,Didn't there start with nine Star Wars movies?,"I seem to remember reading that there were going to be three trilogies originally in Star Wars, i.e. they would add episodes 7 - 9.

Was that ever the case? What happened to that plan?

Update: looks like that original plan might be back after all!
","Depending on his plans at the time and when you asked him, George Lucas has variously said there would be one film, three films, six films, nine films or 12 films.

A trilogy of trilogies

It was widely reported in 1980 that there would be nine films: a trilogy of trilogies.

Al Walentis wrote in the May 25, 1980 Reading Eagle:


  Lucas originally envisioned ""Star Wars"" as a single feature, but his 200-page screenplay proved too unwieldy. He then began tinkering with his story line, cutting it apart, sorting our all the various subplots. The script finally was pieced together as three distinct trilogies. 
  
  ""There are essentially nine films,"" Lucas said. ""The first trilogy is about the young Ben Kenobi and the early life of Luke Skywalker's father when Luke was a young boy. The first trilogy takes place some 20 years before the second. About a year elapses between each story of the first trilogy. The whole adventure - encompassing the three trilogies - spans about 40 years.""


Irvin Kershner, director of The Empire Strikes Back (1980), was also on-script with the nine-film plan. Tom Buckley of the N.Y. Times wrote on May 25, 1980's The Spokesman-Review:


  ""I told George I didn't want to do a sequel,"" Kershner said.""He said, 'I don't blame you. Neither would I, but this isn't. It's the second act of the second trilogy of nine films I plan to make in this theme. I want it to be better than mine.' ...""


On the same page of the same paper, Richard Freeman of Newhouse News wrote:


  Three years ago, Hamill signed up for three ""Star Wars"" films, of which ""The Empire Strikes Back"" is the second. The third - still in the planning stage - will be called ""The revenge of the Jedi,"" and Hamill worries that these titles will suggest the various Pink Panther sequels to audiences.
  
  If things work out, these three movies will eventually constitute only a third of the projected nine-movie ""Star Wars"" saga, but Hamill doesn't plan to be in any of the others.


On the following page of the same paper, Aljean Harmetz of the New York Times wrote:


  The ""Star Wars"" George Lucas has created in his mind will take nine movies to tell. ""Star Wars"" is actually ""Star Wars, Episode IV: A New Hope,"" the first movie of the second trilogy. ""The Empire Strikes Back"" is ""Star Wars, Episode V,"" while ""The Return of the Jedi' is episode VI. The first trilogy deals with the young Darth Vader and the young Ben Kenobi. At the end of the first trilogy, Luke Skywalker is four years old. Only the robots - R2D2 and C-3PO - will be characters in all the movies.
  
  He chose to start in the middle because the first trilogy is, he says, ""more plot-oriented, more soap-operaish."" He adds that the ""central core problem"" of ""Star Wars"" hasn't even been stated yet. Although he originally saw Star Wars as six movies, his ""dream"" was only for ""Star Wars"" to do well enough so that he could finish the three movies in the second trilogy. ""If people had laughed 'Star Wars' off the screen, I'd have been less surprised than I was at what did happen,"" he says. ""Until the day it opened, I felt it would do $16 million and, if I pushed hard, I could make 'Empire.'""


An interview with Harrison Ford in Lakeland Ledger of July 4, 1980:


  Like Mark Hamill (Luke Skywalker) and Carrie Fisher (Princess Leia), Ford has already signed up for the third ""Star Wars"" film, which is tentatively entitled ""The Revenge of the Jedi."" This will conclude the middle trilogy of the nine-part series, and Ford does not know whether it signals the end of Han Solo. It is up to George Lucas, the creator of the saga.
  
  ""He has an idea of doing one (involving what happened to Solo) about 15 years from now, when I'll be 53. That's something I'd like to do.""


The Phoenix of June 21, 1980 also mentions the three trilogies spanning 40 years, and:


  Thereafter, Lucas will go back to the first trilogy, starting with a story so far back that it does not include Darth Vader.
  
  If interest sustains, Star Wars could be in production well into the 1990s. David Prowse figures he'll get killed off (by Luke Skywalker?) in the seventh or eighth story.


At least one trilogy

And it seems at least one trilogy was planned from the start. One week after Star Wars came out, The Leader-Post of June 3, 1977 says:


  [Mark] Hamill said he believes Lucas plans a Star Wars trilogy because all the actors are under contract for two more films.


Reporting on the film's record-breaking success, an AP story in May 26, 1978's Schenectady Gazette says:


  Lucas had originally conceived of ""Star Wars"" as a trilogy. Work on the first sequel is well under way...


12 films

An article by Charles Champlin of the Los Angeles Times, printed in The Tuscaloosa News of June 15, 1979, quotes The Empire Strikes Back producer Gary Kurtz:


  Kurtz says that there are on paper the makings of a grand design of 12 films, including three stories that would historically precede the Skywalker takes (prequels, as they are dreadfully know these days).


A May 5, 1980 article quotes David Prowse as saying ""They plan to do 12 movies.""

13 movies

Finally, this 1979 promo advert for Kenner Star Wars claims:


  ""That's right, Star Wars is forever. George Lucas and 20th Century Fox have plans for twelve more block-busting chapters to the Star Wars story.


So does that make 13?

15 and more

Lucas is selling Lucasfilm and the Star Wars rights to the Walt Disney Company who according to CNN (October 31, 2012) will make at least three sequel films, and then another film every two years (which might might not be sequels), and also possibly a television series:


  ""It's now time for me to pass Star Wars on to a new generation of filmmakers,"" George Lucas said in a written statement. ""I've always believed that Star Wars could live beyond me, and I thought it was important to set up the transition during my lifetime.""
  
  Lucas said he will work as a creative consultant on Star Wars Episode 7, the first of a planned new trilogy of live-action Star Wars movies. It is targeted for release in 2015, Disney said.
  
  Disney hopes to essentially relaunch the Star Wars film franchise, which had its last installment in 2005 with Revenge of the Sith. Following the three planned sequels, the company envisions releasing even more Star Wars movies at a rate of a new film every two to three years.
  
  Future movies may not be sequels but movies that focus on fringe characters. Disney also believes there is potential for a television series.

"
2387,2387,3807,Get phones on all members in a customer group,"I am working on a custom Magento extension.
I am working around the Adminhtml part and i've created a custom form there. 

Here is the form code:

&lt;?php

class VivasIndustries_SmsNotification_Block_Adminhtml_Sms_Sendmass_Edit_Form extends Mage_Adminhtml_Block_Widget_Form
    {

        public function _prepareLayout() 
           {
              $ExtensionPath = Mage::getModuleDir('js', 'VivasIndustries_SmsNotification'); 
              $head = $this-&gt;getLayout()-&gt;getBlock('head');
              $head-&gt;addJs('jquery.js');
              $head-&gt;addJs('vivas.js');

              return parent::_prepareLayout();
           }

        protected function _prepareForm()
            {
            $form = new Varien_Data_Form(array(
                                    'id' =&gt; 'edit_form',
                                    'action' =&gt; $this-&gt;getUrl('*/*/save', array('id' =&gt; $this-&gt;getRequest()-&gt;getParam('id'))),
                                    'method' =&gt; 'post',
                                 ));

                $fieldset = $form-&gt;addFieldset('edit_form', array('legend'=&gt;Mage::helper('smsnotification')-&gt;__('SMS Information')));

                $CustomerGroups = Mage::getResourceModel('customer/group_collection')-&gt;toOptionArray();

                $smsprice_value = Mage::getStoreConfig('vivas/smsprice/smsprice_value');
                $smsprice_tag = Mage::getStoreConfig('vivas/smsprice/smsprice_tag');

                $customerArray=array();
                foreach($CustomerGroups as $each){

                     $count=Mage::getResourceModel('customer/customer_collection')
                                -&gt;addAttributeToFilter('group_id',$each['value'])-&gt;getSize();
                $SMSPrice = $count * $smsprice_value;               
                     $customerArray[]=array('value'=&gt; $each['value'],'label'=&gt; $each['label'].' - ('.$count.' Members) - ('.$SMSPrice.' '.$smsprice_tag.')');

                }

                $CustomerGroups = array_merge(array('' =&gt; ''), $customerArray);

                $fieldset-&gt;addField('customergroups', 'select',
                        array(
                            'name'      =&gt; 'customergroups',
                            'label'     =&gt; Mage::helper('smsnotification')-&gt;__('Customer Group'),
                            'class'     =&gt; 'required-entry',
                            'after_element_html' =&gt; '&lt;br&gt;&lt;small&gt;If customer group is not selected the SMS will be sended&lt;br&gt; to all store members!&lt;/small&gt;',
                            'values'    =&gt; $CustomerGroups
                        )
                    );


                $fieldset-&gt;addField('smstext', 'textarea', array(
                          'label'     =&gt; Mage::helper('smsnotification')-&gt;__('SMS Text'),
                          'class'     =&gt; 'required-entry',
                          'required'  =&gt; true,
                          'name'      =&gt; 'smstext',
                          'onclick' =&gt; """",
                          'onkeyup' =&gt; ""CheckLetterSize(this)"",
                          'after_element_html' =&gt; '&lt;br&gt;&lt;b style=""color:brown;""&gt;&lt;span id=""charNum""&gt;&lt;/span&gt;&lt;span id=""charNum1""&gt;&lt;/span&gt;&lt;/b&gt;&lt;br&gt;&lt;small&gt;SMS text must &lt;b&gt;NOT&lt;/b&gt; be longer then 160 characters!&lt;/small&gt;',
                          'tabindex' =&gt; 1
                        ));






                if ( Mage::getSingleton('adminhtml/session')-&gt;getsmsnotificationData() )
                    {
                        $form-&gt;setValues(Mage::getSingleton('adminhtml/session')-&gt;getsmsnotificationData());
                        Mage::getSingleton('adminhtml/session')-&gt;setsmsnotificationData(null);
                    } elseif ( Mage::registry('smsnotification_data') ) {
                        $form-&gt;setValues(Mage::registry('smsnotification_data')-&gt;getData());
                    }
                // Add these two lines


                $form-&gt;setUseContainer(true);
                $this-&gt;setForm($form);

                ////

                return parent::_prepareForm();
            }
    }


Here is the code that i have in my save action:

$groupId = $this-&gt;getRequest()-&gt;getPost('customergroups', '');
if (!empty($groupId)) {
    //Get customers from a group
    $customers = Mage::getModel('customer/customer')
                        -&gt;getCollection()
                        -&gt;addAttributeToSelect('*')
                        -&gt;addFieldToFilter('group_id', $groupId);
} else {
    //Get all customers
    $customers = Mage::getModel('customer/customer')
                        -&gt;getCollection()
                        -&gt;addAttributeToSelect('*');
}


This code is supposed to give me the group id when i press the submit button. 
But i have to get all the phones of these members in array like that:

$phones = array($phone);


How can i get all the phone numbers and make them in array?
",Tony Stark,https://magento.stackexchange.com/users/15344,"this code is give you collection of customer in this group.. you can get by this code.    

$customers = Mage::getModel('customer/customer')
                            -&gt;getCollection()
                            -&gt;addAttributeToSelect('*')
                            -&gt;addFieldToFilter('group_id', $groupId);

    $phone=array();
    foreach($customers ans $customer)
    {
       $phone[]=$customer-&gt;getTelephone();
    }

",Qaisar Satti,https://magento.stackexchange.com/users/24541,http://magento.stackexchange.com/questions/70040/get-phones-on-all-members-in-a-customer-group,TECHNOLOGY,magento.stackexchange.com,0.6666666666666666,0.6666666666666666,0.0,1.0,1.0,1.0,0.6666666666666666,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.5,0.0,0.0,0.5,0.8333333333333334,0.6666666666666666,0.8333333333333334,1.0,1.0,1.0,0.0,0.0,0.5,Get calls for all members of the customer group,"I am working on a custom Magento extension.
I am working around the Adminhtml part and i've created a custom form there. 

Here is the form code:

&lt;?php

class VivasIndustries_SmsNotification_Block_Adminhtml_Sms_Sendmass_Edit_Form extends Mage_Adminhtml_Block_Widget_Form
    {

        public function _prepareLayout() 
           {
              $ExtensionPath = Mage::getModuleDir('js', 'VivasIndustries_SmsNotification'); 
              $head = $this-&gt;getLayout()-&gt;getBlock('head');
              $head-&gt;addJs('jquery.js');
              $head-&gt;addJs('vivas.js');

              return parent::_prepareLayout();
           }

        protected function _prepareForm()
            {
            $form = new Varien_Data_Form(array(
                                    'id' =&gt; 'edit_form',
                                    'action' =&gt; $this-&gt;getUrl('*/*/save', array('id' =&gt; $this-&gt;getRequest()-&gt;getParam('id'))),
                                    'method' =&gt; 'post',
                                 ));

                $fieldset = $form-&gt;addFieldset('edit_form', array('legend'=&gt;Mage::helper('smsnotification')-&gt;__('SMS Information')));

                $CustomerGroups = Mage::getResourceModel('customer/group_collection')-&gt;toOptionArray();

                $smsprice_value = Mage::getStoreConfig('vivas/smsprice/smsprice_value');
                $smsprice_tag = Mage::getStoreConfig('vivas/smsprice/smsprice_tag');

                $customerArray=array();
                foreach($CustomerGroups as $each){

                     $count=Mage::getResourceModel('customer/customer_collection')
                                -&gt;addAttributeToFilter('group_id',$each['value'])-&gt;getSize();
                $SMSPrice = $count * $smsprice_value;               
                     $customerArray[]=array('value'=&gt; $each['value'],'label'=&gt; $each['label'].' - ('.$count.' Members) - ('.$SMSPrice.' '.$smsprice_tag.')');

                }

                $CustomerGroups = array_merge(array('' =&gt; ''), $customerArray);

                $fieldset-&gt;addField('customergroups', 'select',
                        array(
                            'name'      =&gt; 'customergroups',
                            'label'     =&gt; Mage::helper('smsnotification')-&gt;__('Customer Group'),
                            'class'     =&gt; 'required-entry',
                            'after_element_html' =&gt; '&lt;br&gt;&lt;small&gt;If customer group is not selected the SMS will be sended&lt;br&gt; to all store members!&lt;/small&gt;',
                            'values'    =&gt; $CustomerGroups
                        )
                    );


                $fieldset-&gt;addField('smstext', 'textarea', array(
                          'label'     =&gt; Mage::helper('smsnotification')-&gt;__('SMS Text'),
                          'class'     =&gt; 'required-entry',
                          'required'  =&gt; true,
                          'name'      =&gt; 'smstext',
                          'onclick' =&gt; """",
                          'onkeyup' =&gt; ""CheckLetterSize(this)"",
                          'after_element_html' =&gt; '&lt;br&gt;&lt;b style=""color:brown;""&gt;&lt;span id=""charNum""&gt;&lt;/span&gt;&lt;span id=""charNum1""&gt;&lt;/span&gt;&lt;/b&gt;&lt;br&gt;&lt;small&gt;SMS text must &lt;b&gt;NOT&lt;/b&gt; be longer then 160 characters!&lt;/small&gt;',
                          'tabindex' =&gt; 1
                        ));






                if ( Mage::getSingleton('adminhtml/session')-&gt;getsmsnotificationData() )
                    {
                        $form-&gt;setValues(Mage::getSingleton('adminhtml/session')-&gt;getsmsnotificationData());
                        Mage::getSingleton('adminhtml/session')-&gt;setsmsnotificationData(null);
                    } elseif ( Mage::registry('smsnotification_data') ) {
                        $form-&gt;setValues(Mage::registry('smsnotification_data')-&gt;getData());
                    }
                // Add these two lines


                $form-&gt;setUseContainer(true);
                $this-&gt;setForm($form);

                ////

                return parent::_prepareForm();
            }
    }


Here is the code that i have in my save action:

$groupId = $this-&gt;getRequest()-&gt;getPost('customergroups', '');
if (!empty($groupId)) {
    //Get customers from a group
    $customers = Mage::getModel('customer/customer')
                        -&gt;getCollection()
                        -&gt;addAttributeToSelect('*')
                        -&gt;addFieldToFilter('group_id', $groupId);
} else {
    //Get all customers
    $customers = Mage::getModel('customer/customer')
                        -&gt;getCollection()
                        -&gt;addAttributeToSelect('*');
}


This code is supposed to give me the group id when i press the submit button. 
But i have to get all the phones of these members in array like that:

$phones = array($phone);


How can i get all the phone numbers and make them in array?
","this code is give you collection of customer in this group.. you can get by this code.    

$customers = Mage::getModel('customer/customer')
                            -&gt;getCollection()
                            -&gt;addAttributeToSelect('*')
                            -&gt;addFieldToFilter('group_id', $groupId);

    $phone=array();
    foreach($customers ans $customer)
    {
       $phone[]=$customer-&gt;getTelephone();
    }

"
4105,4105,6551,Create post thumbnails from images stored outside of uploads directory,"I am redoing some of my older blogs and I noticed with the new themes most of them take advantage of featured images which is fine.  The problem is a lot of my older posts that was never set either because I did not use it or because it didn't exist.

Now I know of the featured thumbnail plugin the regenerates your posts and it grabs the images from your post and makes a thumbnail which is great and that works, but I have some posts where the images were not stored in the uploads folder where the plugin seems to be looking and those posts fail.  

Any thoughts on how I can get these featured images without going through every single post manually?
",David,https://wordpress.stackexchange.com/users/32783,"You need to first download those external images then you can attach and set them as the post thumbnail.

To download and attach you can use the media_handle_sideload() function.

I wrote a plugin that will search through all your posts and pages and download and attach any external image into the media library.  It also has the option of setting the first image as the featured image.

http://wordpress.org/extend/plugins/media-tools
",Chris_O,https://wordpress.stackexchange.com/users/251,http://wordpress.stackexchange.com/questions/99280/create-post-thumbnails-from-images-stored-outside-of-uploads-directory,TECHNOLOGY,wordpress.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,0.6666666666666666,0.6666666666666666,1.0,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.7777777777777778,1.0,0.7777777777777778,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,1.0,Create a post thumbnail from an image stored outside the uploads directory,"I am redoing some of my older blogs and I noticed with the new themes most of them take advantage of featured images which is fine.  The problem is a lot of my older posts that was never set either because I did not use it or because it didn't exist.

Now I know of the featured thumbnail plugin the regenerates your posts and it grabs the images from your post and makes a thumbnail which is great and that works, but I have some posts where the images were not stored in the uploads folder where the plugin seems to be looking and those posts fail.  

Any thoughts on how I can get these featured images without going through every single post manually?
","You need to first download those external images then you can attach and set them as the post thumbnail.

To download and attach you can use the media_handle_sideload() function.

I wrote a plugin that will search through all your posts and pages and download and attach any external image into the media library.  It also has the option of setting the first image as the featured image.

http://wordpress.org/extend/plugins/media-tools
"
3956,3956,6312,Equitably distributed curve on a sphere,"Let $\gamma=\gamma(L)$ be a
simple (non-self-intersecting) closed curve of length $L$
on the unit-radius sphere $S$.
So if $L=2\pi$, $\gamma$ could be a great circle.

I am seeking the most equitably distributed
$\gamma(L)$, distributed in the sense that
the length of $\gamma$ within any disk is minimized.
This is something like placing repelling electrons on a sphere,
but here the curve self-repels.
So there should be no ""clots"" of $\gamma$ anywhere on $S$.
I am especially interested in large $L$.
A possible $\gamma$ is shown below, surely not optimal for its length:

&nbsp;
&nbsp;
&nbsp;
&nbsp;
&nbsp;
&nbsp;




Here is an attempt to capture more formally ""equitably distributed.""
I find this an awkward definition, and perhaps there is a more
natural definition.

Around a point $c \in S$, measure the $r$-density
of $\gamma$ as the total length within an $r$-disk:
$$d_\gamma(c,r) = | \gamma \cap D(c,r)|$$
where $D(c,r)$ is the disk of geodesic radius $r$
centered on $c$.
Then define $d_\gamma(r)$ as the maximum of $d_\gamma(c,r)$ over
all $c \in S$.

Finally, we can say that, for two curves $\gamma_1$ and
$\gamma_2$ of the same length $L$, that
$\gamma_1 \le \gamma_2$
if $d_{\gamma_1}(r) \le d_{\gamma_2}(r)$
for all $r \in (0,\pi)$, i.e.,
$\gamma_1$ is less concentrated than $\gamma_2$ for all $r$
up to a hemisphere.

This definition provides a partial order on curves of a given length $L$.
One version of my question is:


  Q. What do the minimal elements of this poset
  look like, especially as $L$ gets large?


These minimal curves are in some sense nowhere densely clotted.

Update. Acknowledging Gerhard Paseman's remark, I thought I would include
this attractive image of a space-filling curve on a sphere:

&nbsp;


&nbsp;
(Image from this website).

But notice it is certainly not equidistributed in any sense, crowding near the northpole.
",Joseph O'Rourke,https://mathoverflow.net/users/6094,"to me the best possible solution seems to be the sequence of closed Hilbert curves on the Cubed Sphere;
that curve consists of six ordinary Hilbert Curves, one for each face of a cube, which, when appropriately connected, yield a space-filling Jordan Curve for the cube's surface.
Then centrally projecting those curves onto a cocentric sphere yields a solution without crowding, albeit a slightly higher density around the projections of the cube's corners.

A further improvement may result from rounding away the corners in a similar fashion as is used for tennis balls, which is the rounding applied to your example.  

Yet another, maybe even better, bet would be Hamilton Cycles of Hamiltonian Fullerene Graphs (cf e.g. http://arxiv.org/pdf/0801.3854.pdf for a discussion); that bet is based on the honeycomb conjecture (cf e.g. http://en.wikipedia.org/wiki/Honeycomb_conjecture) and on the fact, that Fullerene graphs are the closest one can get to a hexagonal tiling of the sphere (there are twelve inevitable pentagons).
Examples of Hamiltonian Fullerene graphs are depicted here: http://www.academia.edu/4269519/On_the_Hamiltonicity_of_Fullerenes.
",Manfred Weis,https://mathoverflow.net/users/31310,http://mathoverflow.net/questions/188173,SCIENCE,mathoverflow.net,0.5,0.3333333333333333,0.0,0.0,1.0,0.5,0.5,0.5,1.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,1.0,0.5,0.0,0.0,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,1.0,0.8,1.0,0.5,1.0,0.6666666666666666,Uniformly distributed curve on sphere,"Let $\gamma=\gamma(L)$ be a
simple (non-self-intersecting) closed curve of length $L$
on the unit-radius sphere $S$.
So if $L=2\pi$, $\gamma$ could be a great circle.

I am seeking the most equitably distributed
$\gamma(L)$, distributed in the sense that
the length of $\gamma$ within any disk is minimized.
This is something like placing repelling electrons on a sphere,
but here the curve self-repels.
So there should be no ""clots"" of $\gamma$ anywhere on $S$.
I am especially interested in large $L$.
A possible $\gamma$ is shown below, surely not optimal for its length:

&nbsp;
&nbsp;
&nbsp;
&nbsp;
&nbsp;
&nbsp;




Here is an attempt to capture more formally ""equitably distributed.""
I find this an awkward definition, and perhaps there is a more
natural definition.

Around a point $c \in S$, measure the $r$-density
of $\gamma$ as the total length within an $r$-disk:
$$d_\gamma(c,r) = | \gamma \cap D(c,r)|$$
where $D(c,r)$ is the disk of geodesic radius $r$
centered on $c$.
Then define $d_\gamma(r)$ as the maximum of $d_\gamma(c,r)$ over
all $c \in S$.

Finally, we can say that, for two curves $\gamma_1$ and
$\gamma_2$ of the same length $L$, that
$\gamma_1 \le \gamma_2$
if $d_{\gamma_1}(r) \le d_{\gamma_2}(r)$
for all $r \in (0,\pi)$, i.e.,
$\gamma_1$ is less concentrated than $\gamma_2$ for all $r$
up to a hemisphere.

This definition provides a partial order on curves of a given length $L$.
One version of my question is:


  Q. What do the minimal elements of this poset
  look like, especially as $L$ gets large?


These minimal curves are in some sense nowhere densely clotted.

Update. Acknowledging Gerhard Paseman's remark, I thought I would include
this attractive image of a space-filling curve on a sphere:

&nbsp;


&nbsp;
(Image from this website).

But notice it is certainly not equidistributed in any sense, crowding near the northpole.
","to me the best possible solution seems to be the sequence of closed Hilbert curves on the Cubed Sphere;
that curve consists of six ordinary Hilbert Curves, one for each face of a cube, which, when appropriately connected, yield a space-filling Jordan Curve for the cube's surface.
Then centrally projecting those curves onto a cocentric sphere yields a solution without crowding, albeit a slightly higher density around the projections of the cube's corners.

A further improvement may result from rounding away the corners in a similar fashion as is used for tennis balls, which is the rounding applied to your example.  

Yet another, maybe even better, bet would be Hamilton Cycles of Hamiltonian Fullerene Graphs (cf e.g. http://arxiv.org/pdf/0801.3854.pdf for a discussion); that bet is based on the honeycomb conjecture (cf e.g. http://en.wikipedia.org/wiki/Honeycomb_conjecture) and on the fact, that Fullerene graphs are the closest one can get to a hexagonal tiling of the sphere (there are twelve inevitable pentagons).
Examples of Hamiltonian Fullerene graphs are depicted here: http://www.academia.edu/4269519/On_the_Hamiltonicity_of_Fullerenes.
"
4070,4070,6497,Get REQUEST_URI and don't overwrite,"I tried storing the REQUEST_URI in a session with the code below. I need to store the very first REQUEST_URI when a visitor lands on a page on our site and not have it overwritten when they begin browsing pages. This isn't working as I browse the site i'm seeing a new URI displayed by the echo.

session_start();
if ( !isset( $_SESSION['theuri'] ) ) {
    if ( !empty( $_SERVER['REQUEST_URI'] ) ) {
        $_SESSION['theuri'] = $_SERVER['REQUEST_URI'];
    }
}

echo $_SESSION['theuri'];

",Anagio,https://stackoverflow.com/users/804087,"You might try this hack:

if(session_id() == '') 
     session_start();


Should help if WP tries to start session for you.
",Bjørne Malmanger,https://stackoverflow.com/users/1227030,http://stackoverflow.com/questions/14636716/get-request-uri-and-dont-overwrite,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.3333333333333333,0.0,0.5,1.0,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,1.0,0.0,0.7777777777777778,0.6666666666666666,0.5555555555555556,0.7777777777777778,1.0,0.7,1.0,0.3333333333333333,0.0,0.7777777777777778,Get request URI and do not overwrite,"I try to store the request URI in the session with the following code. When visitors log on to a page of our website, I need to store the first request URI and do not overwrite it when they start browsing the page. This doesn't work because I'm browsing the site and I see an echo of a new URI display.","You might try this hack:

if(session_id() == '') 
     session_start();


Should help if WP tries to start session for you.
"
1643,1643,2583,Electric guitar trapezoid inlay protruding from fretboard,"I have a Gibson SG Standard that I've had for about 8 years. The trapezoid inlay in the third fret is starting to protrude from the fretboard. I felt it when I fretted a note on the third fret one day. What are the steps to making the inlay level with the fretboard again? Should I even attempt this myself or should I take it to a repair shop and let a professional handle it? Or, even better, does Gibson have some type of guarantee where they'll fix it for free?
",hgwhittle,https://music.stackexchange.com/users/6832,"After 8 years you will not find any manufacturer guarantee, so getting a free repair for inlay damage is not going to happen.

If you are not 100% confident, take it to a luthier, but this is actually a straightforward repair.


Take off the strings.
Carefully remove the inlay
Remove the glue from underneath the inlay and from the slot it was in. You can often pick it off, or carefully use a solvent for the pieces you can't pick off
Apply a thin layer of fresh wood glue
Press the inlay back into it's slot, and wipe off any glue that presses out
Use a g-clamp with a protective pad or cloth to hold the inlay until the glue dries

",Dr Mayhem,https://music.stackexchange.com/users/104,http://music.stackexchange.com/questions/14564/electric-guitar-trapezoid-inlay-protruding-from-fretboard,LIFE_ARTS,music.stackexchange.com,1.0,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,1.0,0.5555555555555556,0.6666666666666666,0.6666666666666666,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,0.8888888888888888,Protruding decorative plate of electric guitar trapezoid insert,"I have a Gibson SG standard. I've had it for eight years. The trapezoid embedded in the third fretting plate starts to protrude from the fretting plate. One day, when I was fidgeting with a note on the third worry, I felt it. How to make the inlay flush with the lining plate again? Should I try it on my own or should I take it to the repair shop for professionals to handle it? Or, better yet, does Gibson have some form of assurance about where they can fix it for free?","After 8 years you will not find any manufacturer guarantee, so getting a free repair for inlay damage is not going to happen.

If you are not 100% confident, take it to a luthier, but this is actually a straightforward repair.


Take off the strings.
Carefully remove the inlay
Remove the glue from underneath the inlay and from the slot it was in. You can often pick it off, or carefully use a solvent for the pieces you can't pick off
Apply a thin layer of fresh wood glue
Press the inlay back into it's slot, and wipe off any glue that presses out
Use a g-clamp with a protective pad or cloth to hold the inlay until the glue dries

"
4559,4559,7223,How do you decide when a paladin has fallen from grace in DnD 5e?,"There does not seem to be a clear-cut way to determine when a paladin's actions have become egregious enough to justify them breaking their oath. Do a lot of minor slights eventually add up and cause an oath to be broken? Do they get some sort of warning like losing their laying on of hands ability? 
",adclark09,https://rpg.stackexchange.com/users/22899,"First and foremost, the only clear-cut answer one might obtain on this subject would be from the DM running the specific campaign in question.  The classification of actions as lawful, chaotic, good, or evil and the relative magnitude of the action relative to the classification (i.e., the action is evil, but just how evil?) is based entirely on the ethos of the particular religion, culture, details of the outer plane which is the source of the alignment, etc.  That said, detailed knowledge of these things is generally not necessary.

More important is understanding why ‘falling from grace’ is included in the rules in the first place.  Like most other character restrictions and limitations in the rules, this one is included to help enforce balance between the character classes.  Paladins are granted a number of special abilities that are of significant advantage.  Immunity to fear and disease alone are high order advantages.  These advantages are offset by a number of equally strict limitations such as the single lawful good alignment.  One might fancy a Paladin views (or should view) strict discretion and application of great power to be as much a measure of ‘power’ as the effects of its use.

The methodology behind the mechanics, however, must always be balanced against the reason for playing the game in the first place; to have a fun and meaningful game play experience.  The Paladin’s ‘fall from grace’ restriction/consequence is purposefully left vague and is intended more as a threat or failsafe than as a rule to be implemented.  That said, use it as such.  Certainly actions deemed as utterly evil should be met with immediate expulsion from the ranks of the chosen.  However, assuming the player is attempting to stay in the spirit of the game, such blasphemy will be very rare.  Most potentially ‘damning’ acts fall into a gray area of lesser sin.  Continuing onward with the assumption of a well-intentioned player, a good dm should ‘guide’ the paladin in such a way as to bring clarity to the ‘correct’ path of behavior when deviation has or is about to occur.

There are several typical methods to impart this ‘wisdom’ upon the character and these are often most effective when used in combination. Providing a simple verbal warning of a sort is the more kind of these tactics.  This may be a direct ‘dm to player’ dialogue or something a bit more subtle and ‘in-game’.  “You are suddenly blinded by an intense light.  A moment later the glare from the noon sun striking the surface of the lake ahead subsides with the passing of a cloud, but you can’t seem to shake the feeling you have been given a sign…”  Alternatively, a post-action penance of some sort may be mandated by a high authority local theocrat, or demanded from a brief encounter with an ‘angel’ or other minor servant of the cause.  A quest to find some sacred artifact and a hefty tithe to the local order will often curb even the most ignorant of players.  The severity should fit the score so to speak, but a few of these instances are usually enough to make the point.  Ultimately, the actual act of stripping the character of Paladin status should only be undertaken when multiple warnings and/or penalties are ignored or as a last resort of sorts in any case.
",Starrdaark,https://rpg.stackexchange.com/users/23373,http://rpg.stackexchange.com/questions/62167/how-do-you-decide-when-a-paladin-has-fallen-from-grace-in-dnd-5e,CULTURE,rpg.stackexchange.com,0.7777777777777778,0.6666666666666666,0.3333333333333333,0.3333333333333333,1.0,0.6666666666666666,0.7777777777777778,0.6666666666666666,0.6666666666666666,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.3333333333333333,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.7777777777777778,0.8888888888888888,0.7777777777777778,0.8888888888888888,1.0,0.8666666666666666,0.0,0.3333333333333333,1.0,0.8888888888888888,How do you decide when a paladin will fall out of favor in dnd5e?,"There doesn't seem to be a clear way to determine when the Knights' behavior has become too much to prove that they have broken the oath. Will a lot of slight contempt eventually lead to the breaking of vows? Do they get some kind of warning, such as losing the ability to start?","First and foremost, the only clear-cut answer one might obtain on this subject would be from the DM running the specific campaign in question.  The classification of actions as lawful, chaotic, good, or evil and the relative magnitude of the action relative to the classification (i.e., the action is evil, but just how evil?) is based entirely on the ethos of the particular religion, culture, details of the outer plane which is the source of the alignment, etc.  That said, detailed knowledge of these things is generally not necessary.

More important is understanding why ‘falling from grace’ is included in the rules in the first place.  Like most other character restrictions and limitations in the rules, this one is included to help enforce balance between the character classes.  Paladins are granted a number of special abilities that are of significant advantage.  Immunity to fear and disease alone are high order advantages.  These advantages are offset by a number of equally strict limitations such as the single lawful good alignment.  One might fancy a Paladin views (or should view) strict discretion and application of great power to be as much a measure of ‘power’ as the effects of its use.

The methodology behind the mechanics, however, must always be balanced against the reason for playing the game in the first place; to have a fun and meaningful game play experience.  The Paladin’s ‘fall from grace’ restriction/consequence is purposefully left vague and is intended more as a threat or failsafe than as a rule to be implemented.  That said, use it as such.  Certainly actions deemed as utterly evil should be met with immediate expulsion from the ranks of the chosen.  However, assuming the player is attempting to stay in the spirit of the game, such blasphemy will be very rare.  Most potentially ‘damning’ acts fall into a gray area of lesser sin.  Continuing onward with the assumption of a well-intentioned player, a good dm should ‘guide’ the paladin in such a way as to bring clarity to the ‘correct’ path of behavior when deviation has or is about to occur.

There are several typical methods to impart this ‘wisdom’ upon the character and these are often most effective when used in combination. Providing a simple verbal warning of a sort is the more kind of these tactics.  This may be a direct ‘dm to player’ dialogue or something a bit more subtle and ‘in-game’.  “You are suddenly blinded by an intense light.  A moment later the glare from the noon sun striking the surface of the lake ahead subsides with the passing of a cloud, but you can’t seem to shake the feeling you have been given a sign…”  Alternatively, a post-action penance of some sort may be mandated by a high authority local theocrat, or demanded from a brief encounter with an ‘angel’ or other minor servant of the cause.  A quest to find some sacred artifact and a hefty tithe to the local order will often curb even the most ignorant of players.  The severity should fit the score so to speak, but a few of these instances are usually enough to make the point.  Ultimately, the actual act of stripping the character of Paladin status should only be undertaken when multiple warnings and/or penalties are ignored or as a last resort of sorts in any case.
"
2536,2536,4041,Most effective way to increase programmer salary besides just doing your job?,"If you have the time and resources, what would be the most effective way to increase your salary as a full-time programmer, outside of just doing your job? 

By ""salary"" here, I mean salary (adjusted for location cost-of-living) coming from a single programming job. 
",T. Webster,https://programmers.stackexchange.com/users/19936,"If you want to raise your salary, raise your value to your employer/customer.  Continuously align yourself with your company's goals (answer: how am I bringing aiding in bringing in more revenue?) and your client's goals (answer: how am I making the customer's life easier?).  At times you will need to go to bat for yourself to remind those with the checkbook of how you can answer those questions above.  

And as @bleakcabal stated, you've got to play the social aspect of your job.  That will open more opportunities to increase your value to employeer and customers.
",jayraynet,https://programmers.stackexchange.com/users/25019,http://programmers.stackexchange.com/questions/76254/most-effective-way-to-increase-programmer-salary-besides-just-doing-your-job,TECHNOLOGY,programmers.stackexchange.com,0.8888888888888888,0.7777777777777778,0.3333333333333333,1.0,0.3333333333333333,0.0,0.7777777777777778,0.5555555555555556,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,0.6666666666666666,0.0,0.3333333333333333,1.0,"In addition to work, what is the most effective way to raise the salary of programmers?","If you have time and resources, what is the most effective way to increase your salary as a full-time programmer besides doing your job?","If you want to raise your salary, raise your value to your employer/customer.  Continuously align yourself with your company's goals (answer: how am I bringing aiding in bringing in more revenue?) and your client's goals (answer: how am I making the customer's life easier?).  At times you will need to go to bat for yourself to remind those with the checkbook of how you can answer those questions above.  

And as @bleakcabal stated, you've got to play the social aspect of your job.  That will open more opportunities to increase your value to employeer and customers.
"
1753,1753,2777,prevent menustrip from being selected by pressing alt,"I would like to have some shortcuts with alt but when I press alt the menustrip gets selected. How can I disable this behaviour?
",DaVinci,https://stackoverflow.com/users/97702,"This is why, on Windows, you do not use ALT+key shortcuts. You should not attempt to subvert the native system behaviour. The solution is to choose a different shortcut combination.
",David Heffernan,https://stackoverflow.com/users/505088,http://stackoverflow.com/questions/4537794/prevent-menustrip-from-being-selected-by-pressing-alt,STACKOVERFLOW,stackoverflow.com,0.8333333333333334,1.0,0.0,1.0,1.0,1.0,0.6666666666666666,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.5,0.0,0.0,0.8333333333333334,0.8333333333333334,0.6666666666666666,1.0,1.0,0.9,0.5,0.0,1.0,1.0,Press ALT key to prevent MenuStrip from being selected,"I would like to have some shortcuts with ALT, but when I press ALT the menu is selected. How can I stop this?","This is why, on Windows, you do not use ALT+key shortcuts. You should not attempt to subvert the native system behaviour. The solution is to choose a different shortcut combination.
"
2379,2379,3791,Adjustment to road bike brakes for high grade downhill,"I have a road bike with a front brake that wears a lot of brake pad when I ride downhill every day. I lose 900ft in elevation on steep grades with lots of stop signs and traffic lights. On top of that, it rains a decent amount and the rim brakes are terrible in that weather. I don't trust them downhill in the rain. Sometimes I just walk.

I feather the brakes going downhill, because otherwise I'm too fast to stop quickly for an errant car.

It'd be nice to not constantly replace pads, and have powerful stopping. How can I make this constant downhill more pleasant?

Thanks. 
",ash,https://bicycles.stackexchange.com/users/14519,"Have a look at installing Cantilever brakes- larger pads so you can retain the same stopping power and increase life, at the expense of a few grams of weight.  Cantilever brakes will also help in the wet due large pad (more surface area). These are the preferred brakes for tandems and tourers - you may have trouble getting decent quality ones these days. As I understand, V brakes are not compatible with road bikes without adapters and are not always as successful as you would think. 

Discs would be the ultimate wet weather improvement and provide the stopping power you want, but I would caution against hydraulics for such big downhills. They have been known overheat and boil the fluid - you get instant total failure when it happens. Apart form this, you need new forks and wheel (minimum of a hub), and probably new levers, so the cost may be prohibitive. 
",mattnz,https://bicycles.stackexchange.com/users/3924,http://bicycles.stackexchange.com/questions/25771/adjustment-to-road-bike-brakes-for-high-grade-downhill,CULTURE,bicycles.stackexchange.com,1.0,0.5555555555555556,0.0,0.5,0.6666666666666666,0.5,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.7777777777777778,Adjustment of bicycle brake on high grade downhill road,"I have a road bike with front brakes, which wear a lot of brake pads every day when I go down the hill. I lost 900 feet above sea level on a steep slope, where there were lots of stop signs and traffic lights. Besides, it rained well and the brakes were terrible in that weather. I don't believe they came down in the rain. Sometimes I just walk.","Have a look at installing Cantilever brakes- larger pads so you can retain the same stopping power and increase life, at the expense of a few grams of weight.  Cantilever brakes will also help in the wet due large pad (more surface area). These are the preferred brakes for tandems and tourers - you may have trouble getting decent quality ones these days. As I understand, V brakes are not compatible with road bikes without adapters and are not always as successful as you would think. 

Discs would be the ultimate wet weather improvement and provide the stopping power you want, but I would caution against hydraulics for such big downhills. They have been known overheat and boil the fluid - you get instant total failure when it happens. Apart form this, you need new forks and wheel (minimum of a hub), and probably new levers, so the cost may be prohibitive. 
"
4913,4913,7822,Configuring a tftp server for multiple clients,"I am using a tftp server to hold the boot image for a dev board and the dev board is hard-coded to look at a particular IP address for the server.  This all works fine.  What I want to do now is be able to set up a second dev board to look at the same IP address for the server, but get a different boot image.  I would like to do this by having the tftp server use a different root directory based on the IP address of the client connecting to it.  Is there a way to do this?

I realize there may be some way to do this with iptables, but I have to turn the firewall on the server machine off entirely for other reasons, so that may not be terribly practical.

For reference, I'm using Fedora 15 for the server, but that can be changed if need be.
",JonS,https://unix.stackexchange.com/users/47279,"DHCPD or not?

You don't say but I'm assuming that you have some PXE configuration file that this DEV board is setup to look for. Typically you'd tell the DHCP clients what PXE image to use like so via a DCHP server:

subnet 192.168.0.0 netmask 255.255.255.0 {
        range 192.168.0.10 192.168.0.49;
        option subnet-mask 255.255.255.0;
        option broadcast-address 192.168.0.255;
        option routers 192.168.0.1;
        filename ""pxelinux.0"";
        next-server 192.168.0.100;
}


The TFTP server would be the next-server 192.168.0.100, and the file to load would be filename ""pxelinux.0"". But since you don't have this setup your DEV board is looking for a the ""next-server"" at a specific IP address, I'm going to assume that it's looking for a specific PXE file too.

Using PXELINUX

This solution would assume you have control over pointing the DEV board at a particular ""filename"", in this case I'm suggesting you use PXELINUX, the file would be pxelinux.0.

PXELINUX allows you to have custom images based on a system's MAC address is the more typical way to do it, since system generally don't have an actual IP address assigned to them in a static way, whereas the MAC addresses are static.

Setup

On the TFTP server's root directory you'd then create something like this:

/mybootdir/pxelinux.cfg/01-88-99-aa-bb-cc-dd
/mybootdir/pxelinux.cfg/01-88-99-00-11-22-33
/mybootdir/pxelinux.cfg/default


Each MAC address above is a file with the appropriate boot stanza in it for each system. Here's mine from my Cobbler setup:

$ ls -l /tftpboot/pxelinux.cfg/
total 88
-rw-r--r-- 1 root root 292 Jul  9  2012 01-54-52-00-05-5a-ab
-rw-r--r-- 1 root root 288 Jul  9  2012 01-54-52-00-17-a6-cd


Along with a sample file:

$ more /tftpboot/pxelinux.cfg/01-54-52-00-05-5a-ab
default linux
prompt 0
timeout 1
label linux
        kernel /images/Centos56-x86_64/vmlinuz
        ipappend 2
        append initrd=/images/Centos56-x86_64/initrd.img ksdevice=bootif lang=  console=ttyS0,115200 text serial kssendmac  ks=http://192.168.1.101/cblr/svc
/op/ks/system/server123


The above can be paired down to suit your needs, but should be enough of an example to get you started, there additional examples up on the PXELINUX website as well!
",slm,https://unix.stackexchange.com/users/7453,http://unix.stackexchange.com/questions/118307/configuring-a-tftp-server-for-multiple-clients,TECHNOLOGY,unix.stackexchange.com,0.8888888888888888,0.4444444444444444,0.0,0.6666666666666666,1.0,1.0,0.6666666666666666,0.5555555555555556,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,1.0,1.0,Configuring TFTP servers for multiple clients,"I use the TFTP server to save the boot image of the development board, which is hard coded to view the specific IP address of the server. business as usual. What I want to do now is to be able to set up the second development board to view the same IP address of the server, but get different boot images. I want the TFTP server to use a different root directory based on the IP address of the client connected to it. Is there a way?","DHCPD or not?

You don't say but I'm assuming that you have some PXE configuration file that this DEV board is setup to look for. Typically you'd tell the DHCP clients what PXE image to use like so via a DCHP server:

subnet 192.168.0.0 netmask 255.255.255.0 {
        range 192.168.0.10 192.168.0.49;
        option subnet-mask 255.255.255.0;
        option broadcast-address 192.168.0.255;
        option routers 192.168.0.1;
        filename ""pxelinux.0"";
        next-server 192.168.0.100;
}


The TFTP server would be the next-server 192.168.0.100, and the file to load would be filename ""pxelinux.0"". But since you don't have this setup your DEV board is looking for a the ""next-server"" at a specific IP address, I'm going to assume that it's looking for a specific PXE file too.

Using PXELINUX

This solution would assume you have control over pointing the DEV board at a particular ""filename"", in this case I'm suggesting you use PXELINUX, the file would be pxelinux.0.

PXELINUX allows you to have custom images based on a system's MAC address is the more typical way to do it, since system generally don't have an actual IP address assigned to them in a static way, whereas the MAC addresses are static.

Setup

On the TFTP server's root directory you'd then create something like this:

/mybootdir/pxelinux.cfg/01-88-99-aa-bb-cc-dd
/mybootdir/pxelinux.cfg/01-88-99-00-11-22-33
/mybootdir/pxelinux.cfg/default


Each MAC address above is a file with the appropriate boot stanza in it for each system. Here's mine from my Cobbler setup:

$ ls -l /tftpboot/pxelinux.cfg/
total 88
-rw-r--r-- 1 root root 292 Jul  9  2012 01-54-52-00-05-5a-ab
-rw-r--r-- 1 root root 288 Jul  9  2012 01-54-52-00-17-a6-cd


Along with a sample file:

$ more /tftpboot/pxelinux.cfg/01-54-52-00-05-5a-ab
default linux
prompt 0
timeout 1
label linux
        kernel /images/Centos56-x86_64/vmlinuz
        ipappend 2
        append initrd=/images/Centos56-x86_64/initrd.img ksdevice=bootif lang=  console=ttyS0,115200 text serial kssendmac  ks=http://192.168.1.101/cblr/svc
/op/ks/system/server123


The above can be paired down to suit your needs, but should be enough of an example to get you started, there additional examples up on the PXELINUX website as well!
"
2537,2537,4042,select additional columns not in dup checker query,"In Access, I'm identifying duplicate records based on 28 columns.  I want to also select a non-duplicate column but can't figure it out.  

tbl_1:

bud_line | fund | name      | amt
123      |  ABC |  BOB      | $8
123      |  ABC |  BOB ROSS | $8
321      |  ABC |  BOB      | $8
321      |  AAA |  BOB      | $8
321      |  AAA |  BOB      | $20
321      |  XXX | JOHN      | $10
321      |  XXX | JOHN      | $10

The only lines I want on the output would be:

123 | ABC | BOB      | $8
123 | ABC | BOB ROSS | $8
321 | XXX | JOHN     | $10

I was using a query like:

select bud_line, fund, amt
from tbl_1
group by bud_line, fund, amt
having count(*) &gt; 1


I get my dups, but I don't get the names BOB &amp; BOB ROSS to identify them.

I tried adding name to the select, but it errors because it's not part of the aggregate function.
",user3023480,https://stackoverflow.com/users/3023480,"In Access, you do this by joining back to the original table:

select t.*
from tbl_1 as t inner join
     (select bud_line, fund, amt
      from tbl_1
      group by bud_line, fund, amt
      having count(*) &gt; 1
     ) as tt
     on t.bud_line = tt.bud_line and t.fund = tt.fund and t.amt = tt.amt
order by bud_line, fund, amt;


If you had a unique id on each row, you could do this with an exists clause, which could use an index and be faster:

select t.*
from tbl_1 as t
where exists (select 1
              from tbl_1 as tt
              where t.bud_line = tt.bud_line and t.fund = tt.fund and t.amt = tt.amt and
                    t.id &lt;&gt; tt.id
             );

",Gordon Linoff,https://stackoverflow.com/users/1144035,http://stackoverflow.com/questions/24002879/select-additional-columns-not-in-dup-checker-query,STACKOVERFLOW,stackoverflow.com,0.6666666666666666,0.3333333333333333,0.0,1.0,0.6666666666666666,1.0,0.6666666666666666,0.4444444444444444,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,0.8888888888888888,Select other columns not in the DUP checker query,"In Access, I'm identifying duplicate records based on 28 columns.  I want to also select a non-duplicate column but can't figure it out.  

tbl_1:

bud_line | fund | name      | amt
123      |  ABC |  BOB      | $8
123      |  ABC |  BOB ROSS | $8
321      |  ABC |  BOB      | $8
321      |  AAA |  BOB      | $8
321      |  AAA |  BOB      | $20
321      |  XXX | JOHN      | $10
321      |  XXX | JOHN      | $10

The only lines I want on the output would be:

123 | ABC | BOB      | $8
123 | ABC | BOB ROSS | $8
321 | XXX | JOHN     | $10

I was using a query like:

select bud_line, fund, amt
from tbl_1
group by bud_line, fund, amt
having count(*) &gt; 1


I get my dups, but I don't get the names BOB &amp; BOB ROSS to identify them.

I tried adding name to the select, but it errors because it's not part of the aggregate function.
","In Access, you do this by joining back to the original table:

select t.*
from tbl_1 as t inner join
     (select bud_line, fund, amt
      from tbl_1
      group by bud_line, fund, amt
      having count(*) &gt; 1
     ) as tt
     on t.bud_line = tt.bud_line and t.fund = tt.fund and t.amt = tt.amt
order by bud_line, fund, amt;


If you had a unique id on each row, you could do this with an exists clause, which could use an index and be faster:

select t.*
from tbl_1 as t
where exists (select 1
              from tbl_1 as tt
              where t.bud_line = tt.bud_line and t.fund = tt.fund and t.amt = tt.amt and
                    t.id &lt;&gt; tt.id
             );

"
484,484,754,How to identify if sentence is passive Voice or Indicative sentence?,"Examples: 


  ""One car was parked outside of the gate."" 
  ""Your work volume is increased or not""
  ""He was arrested""
  ""She was raped""
  ""After accident he was taken to hospital""
  ""He was informed about this""
  “My heart was broken”


All above statements can be in the stative form if we do not mentioned the agent.
But if we use the agent i.e. By Driver, By Boss,  By Police, By  boyfriend, By  friend, By  father, By  husband respectively, then sentence become as passive voice.

My questions are 
a) How to quickly make out whether a sentence is in the passive voice or just a simple sentence (Stative)?

B) If i use had been in above sentence does it mean the same?
",user4084,https://ell.stackexchange.com/users/4084,"English ""got"" was long considered substandard, even though it disambiguates these situations efficiently.

The car got parked. The car was parked.

Without such disambiguation, context is required.
",Tᴚoɯɐuo,https://ell.stackexchange.com/users/10264,http://ell.stackexchange.com/questions/39139/how-to-identify-if-sentence-is-passive-voice-or-indicative-sentence,CULTURE,ell.stackexchange.com,0.4444444444444444,1.0,0.0,0.0,1.0,1.0,0.5555555555555556,0.5555555555555556,0.6666666666666666,0.0,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.7777777777777778,0.6666666666666666,0.4666666666666667,0.0,0.0,1.0,0.8888888888888888,How to recognize whether a sentence is a passive sentence or an indicative sentence?,"Examples: 


  ""One car was parked outside of the gate."" 
  ""Your work volume is increased or not""
  ""He was arrested""
  ""She was raped""
  ""After accident he was taken to hospital""
  ""He was informed about this""
  “My heart was broken”


All above statements can be in the stative form if we do not mentioned the agent.
But if we use the agent i.e. By Driver, By Boss,  By Police, By  boyfriend, By  friend, By  father, By  husband respectively, then sentence become as passive voice.

My questions are 
a) How to quickly make out whether a sentence is in the passive voice or just a simple sentence (Stative)?

B) If i use had been in above sentence does it mean the same?
","English ""got"" was long considered substandard, even though it disambiguates these situations efficiently.

The car got parked. The car was parked.

Without such disambiguation, context is required.
"
3966,3966,6330,Connect to Microsoft Access database via Microsoft SQL Server / MySQL,"A client has an Microsoft Access database where they save their products.
To access the database now you have to login via VPN and open Microsoft Office Access.
I need to access this database from a PHP script running on another server.

I've done some research and found that it's not possible to connect to an Access database like a MySQL database.
So what I wonder is if it may be possible to set up an Microsoft SQL Server on the same server that uses the Microsoft Access database. So I can connect to the Microsoft SQL Server with the PHP script. Or if it's possible MySQL.

They are running Microsoft Windows Server 2008 and Microsoft Office Access 2003.
",Patrik,https://dba.stackexchange.com/users/27985,"An access database is not a server, it's just a file.  To access it, your server will need access to the filesystem on which it resides.  Or, if you want to set up an SQL server on the same machine as the access database, it will still need access to the folder in which the file is stored.  

A user logged into a VPN may not have the same drive mappings or file system permissions as a server process running on the same machine, so you will need to reflect this in the path to the file you use in the code.
",david25272,https://dba.stackexchange.com/users/28034,http://dba.stackexchange.com/questions/49492/connect-to-microsoft-access-database-via-microsoft-sql-server-mysql,TECHNOLOGY,dba.stackexchange.com,0.6666666666666666,0.5,0.0,1.0,1.0,1.0,0.6666666666666666,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,1.0,0.5,0.0,0.5,0.6666666666666666,Connect to Microsoft Access database through Microsoft SQL Server / MySQL,"A client has an Microsoft Access database where they save their products.
To access the database now you have to login via VPN and open Microsoft Office Access.
I need to access this database from a PHP script running on another server.

I've done some research and found that it's not possible to connect to an Access database like a MySQL database.
So what I wonder is if it may be possible to set up an Microsoft SQL Server on the same server that uses the Microsoft Access database. So I can connect to the Microsoft SQL Server with the PHP script. Or if it's possible MySQL.

They are running Microsoft Windows Server 2008 and Microsoft Office Access 2003.
","An access database is not a server, it's just a file.  To access it, your server will need access to the filesystem on which it resides.  Or, if you want to set up an SQL server on the same machine as the access database, it will still need access to the folder in which the file is stored.  

A user logged into a VPN may not have the same drive mappings or file system permissions as a server process running on the same machine, so you will need to reflect this in the path to the file you use in the code.
"
2100,2100,3342,Another instructor is pushing me out of the classroom right after my class ends,"I am a graduate student in math in my final year, and for several years have been teaching at my department as a lecturer. This semester, in the same lecture hall there is another lecture that starts 20 minutes after my class ends. It's taught by another instructor from my department. I usually have many students coming to office hours and there are also students asking questions immediately after lecture. Due to other activities, I cannot have office hours right after the lecture this semester and can only stay for about 15 minutes to answer questions.

Many times in the past I had a similar situation and never had any issues with it. This semester the instructor who is teaching right after often arrives 20-15 minutes before her class starts and tells me immediately that I have to go with my students somewhere else. 

I make sure to leave the blackboard clean and take all my stuff away from the instructor's desk before she arrives, but I do believe that I have a right to stay in the classroom after my lecture for at least 5-10 minutes. There is no vacant classroom around, and I don't have time to go with students to my office, which is in a different building.

Last time the instructor told me in front of my students that I don't understand ""simple things"" and that I am ""playing games"". When I was talking to one of my students, she stood very close to us and clearly demonstrated that she wanted us out. I tried to explain her that I couldn't go anywhere else due to my time constraints, but she didn't want to listen to me. I really don't understand what ""simple"" things she meant and what ""games"" I am playing. 

We leave the board clean. She doesn't need to set up a projector. She can still talk to her students before her class starts, if she wants to (even though it seems like her students don't ask her any questions before their class). So, I don't see how I cause any disruption. 

I had met this woman many times before this semester, but we never talked. I didn't see her talking to other instructors/students much, and she seems to be quite reserved and a bit neurotic. She doesn't want to have any conversation with me regarding the issue.

I felt really offended after last class when she said those things to me in front of my students. What would you do in my case? 

Added later: There are no official rules regarding classroom occupancy between classes. Instructors are supposed to use common sense and be reasonable. For me using 50% of the break time seems reasonable to answer questions after lecture seems reasonable. I agree that for some people it may not.

I don't block the entrance to the classroom. A few students from the next class who come earlier always go ahead and take their seats as soon as my students start leaving the room. I also had one of the students from the next class listening to my explanation to one of those after-class questions and asking me further questions before their class (which is the same class as I am teaching, just a different section). Maybe the instructor got jealous, I don't know.

The entrance to the classroom is from its front (not back), so I do stay in the front. But it is a big lecture hall, and there is a plenty of space in front of the room (the board itself consists of 8 huge panels).

Also, during my career as a grad.student who is also teaching for the department, I have had several observations from experienced professors who are considered to be great teachers at the department and are in charge of undergraduate teaching policy. In my evaluations the fact that there are always several students approaching me with questions after class considered as very positive, meaning that students find me approachable. 

Thank you everyone for answers. 
",Lidd88,https://academia.stackexchange.com/users/31345,"I think the logic behind the post is quite confusing. You should tell your students directly that discussion can only happen during office hour, and mention that there is another class afterwards. And you can extend your office hour (in a different day, say) by some period of time or move it if you wish, this can always be discussed with department secretary. 

You suggested that:


  Many times in the past I had a similar situation and never had any
  issues with it.


as well as


  In my evaluations the fact that there are always several students
  approaching me with questions after class considered as very positive,
  meaning that students find me approachable.


and many other reasons claiming your behavior is tolerable and okay by your standards. But these justifications is simply not related to the fact that she finds it uncomfortable because you did not end up the class on time. Since you are aware of that, you should do something concrete to resolve this issue. For example you can cover more background in the lecture time available, and encourage students to come to your office hour for longer 1-1 discussions. 

My impression for after class discussions is totally opposite to yours; the fact students coming after you after class usually means you did not explain the material well enough during class or unclear during the grading process. Your course should be in the format like ""Calculus III, 2:00-3:00pm, Room 31A, Darwin building"". If the description did not mention an extra 15 minutes for afterclass discussion, then it means you do not have it. As what the other instructor does when she comes to your classroom is totally irrelevant. In my experience a student (not even an instructor or dept chair) can knock at your classroom door and friendly to ask you get out without giving any specific reasons. They might need the room for group projects or whatever. The fact you are late should be compelling evidence against you already. 

You also suggested that


  Last time the instructor told me in front of my students that I don't
  understand ""simple things"" and that I am ""playing games"". When I was
  talking to one of my students, she stood very close to us and clearly
  demonstrated that she wanted us out. I tried to explain her that I
  couldn't go anywhere else due to my time constraints, but she didn't
  want to listen to me. I really don't understand what ""simple"" things
  she meant and what ""games"" I am playing.


I think you should think from her point of view, that your class should end up on time. The fact that you have time constraints, etc is irrelevant to her. If you think these are legitimate reasons to justify your behavior, to her you were simply being immature and using poor excuses. You may have your disagreement and ask for support from senior faculty in the department as Prof. Clark suggested, but her position is very clear. If she demonstrated you need to get out, then you need to get out even if this is the final exam. Unless you have a student with disability that needs extra time, etc I think there is no point arguing further on this issue. 
",Bombyx mori,https://academia.stackexchange.com/users/6335,http://academia.stackexchange.com/questions/41133/another-instructor-is-pushing-me-out-of-the-classroom-right-after-my-class-ends,LIFE_ARTS,academia.stackexchange.com,1.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,0.0,1.0,No sooner had I finished class than another teacher kicked me out of the classroom,"I am a graduate student in math in my final year, and for several years have been teaching at my department as a lecturer. This semester, in the same lecture hall there is another lecture that starts 20 minutes after my class ends. It's taught by another instructor from my department. I usually have many students coming to office hours and there are also students asking questions immediately after lecture. Due to other activities, I cannot have office hours right after the lecture this semester and can only stay for about 15 minutes to answer questions.

Many times in the past I had a similar situation and never had any issues with it. This semester the instructor who is teaching right after often arrives 20-15 minutes before her class starts and tells me immediately that I have to go with my students somewhere else. 

I make sure to leave the blackboard clean and take all my stuff away from the instructor's desk before she arrives, but I do believe that I have a right to stay in the classroom after my lecture for at least 5-10 minutes. There is no vacant classroom around, and I don't have time to go with students to my office, which is in a different building.

Last time the instructor told me in front of my students that I don't understand ""simple things"" and that I am ""playing games"". When I was talking to one of my students, she stood very close to us and clearly demonstrated that she wanted us out. I tried to explain her that I couldn't go anywhere else due to my time constraints, but she didn't want to listen to me. I really don't understand what ""simple"" things she meant and what ""games"" I am playing. 

We leave the board clean. She doesn't need to set up a projector. She can still talk to her students before her class starts, if she wants to (even though it seems like her students don't ask her any questions before their class). So, I don't see how I cause any disruption. 

I had met this woman many times before this semester, but we never talked. I didn't see her talking to other instructors/students much, and she seems to be quite reserved and a bit neurotic. She doesn't want to have any conversation with me regarding the issue.

I felt really offended after last class when she said those things to me in front of my students. What would you do in my case? 

Added later: There are no official rules regarding classroom occupancy between classes. Instructors are supposed to use common sense and be reasonable. For me using 50% of the break time seems reasonable to answer questions after lecture seems reasonable. I agree that for some people it may not.

I don't block the entrance to the classroom. A few students from the next class who come earlier always go ahead and take their seats as soon as my students start leaving the room. I also had one of the students from the next class listening to my explanation to one of those after-class questions and asking me further questions before their class (which is the same class as I am teaching, just a different section). Maybe the instructor got jealous, I don't know.

The entrance to the classroom is from its front (not back), so I do stay in the front. But it is a big lecture hall, and there is a plenty of space in front of the room (the board itself consists of 8 huge panels).

Also, during my career as a grad.student who is also teaching for the department, I have had several observations from experienced professors who are considered to be great teachers at the department and are in charge of undergraduate teaching policy. In my evaluations the fact that there are always several students approaching me with questions after class considered as very positive, meaning that students find me approachable. 

Thank you everyone for answers. 
","I think the logic behind the post is quite confusing. You should tell your students directly that discussion can only happen during office hour, and mention that there is another class afterwards. And you can extend your office hour (in a different day, say) by some period of time or move it if you wish, this can always be discussed with department secretary. 

You suggested that:


  Many times in the past I had a similar situation and never had any
  issues with it.


as well as


  In my evaluations the fact that there are always several students
  approaching me with questions after class considered as very positive,
  meaning that students find me approachable.


and many other reasons claiming your behavior is tolerable and okay by your standards. But these justifications is simply not related to the fact that she finds it uncomfortable because you did not end up the class on time. Since you are aware of that, you should do something concrete to resolve this issue. For example you can cover more background in the lecture time available, and encourage students to come to your office hour for longer 1-1 discussions. 

My impression for after class discussions is totally opposite to yours; the fact students coming after you after class usually means you did not explain the material well enough during class or unclear during the grading process. Your course should be in the format like ""Calculus III, 2:00-3:00pm, Room 31A, Darwin building"". If the description did not mention an extra 15 minutes for afterclass discussion, then it means you do not have it. As what the other instructor does when she comes to your classroom is totally irrelevant. In my experience a student (not even an instructor or dept chair) can knock at your classroom door and friendly to ask you get out without giving any specific reasons. They might need the room for group projects or whatever. The fact you are late should be compelling evidence against you already. 

You also suggested that


  Last time the instructor told me in front of my students that I don't
  understand ""simple things"" and that I am ""playing games"". When I was
  talking to one of my students, she stood very close to us and clearly
  demonstrated that she wanted us out. I tried to explain her that I
  couldn't go anywhere else due to my time constraints, but she didn't
  want to listen to me. I really don't understand what ""simple"" things
  she meant and what ""games"" I am playing.


I think you should think from her point of view, that your class should end up on time. The fact that you have time constraints, etc is irrelevant to her. If you think these are legitimate reasons to justify your behavior, to her you were simply being immature and using poor excuses. You may have your disagreement and ask for support from senior faculty in the department as Prof. Clark suggested, but her position is very clear. If she demonstrated you need to get out, then you need to get out even if this is the final exam. Unless you have a student with disability that needs extra time, etc I think there is no point arguing further on this issue. 
"
384,384,605,Integrate a division of polynomials,"Hi I have the following integral:
$$\int \frac{2x}{x^2+6x+3}\, dx$$

I made some changes like:
$$\int \dfrac{2x+6-6}{x^2+6x+3}\, dx$$

then I have: 
$$\int \dfrac{2x+6}{x^2+6x+3}\, dx -\int\dfrac{6}{x^2+6x+3}\, dx$$

and thus: $$\ln(x^2+6x+3)-\int\dfrac{6}{x^2+6x+3}\, dx$$

Ok, I have decomposed $$\frac{2x}{x^2+6x+3} $$  in: $$ \frac{3+\sqrt6}{\sqrt6(x+\sqrt 6+3)} + \frac{3-\sqrt6}{\sqrt6 (-x+\sqrt6-3)}$$

How can I integrate this expressions?
",Luis Armando,https://math.stackexchange.com/users/162185,"$$\frac{2x}{x^2+6x+3}=\frac{A}{x-(-3-\sqrt{6})}+\frac{B}{x-(\sqrt{6}-3)}$$

Find $A$ and $B$ and then:

$$\int \frac{2x}{x^2+6x+3} dx=\int \frac{A}{x-(-3-\sqrt{6})} dx+\int \frac{B}{x-(\sqrt{6}-3)} dx$$
",evinda,https://math.stackexchange.com/users/75843,http://math.stackexchange.com/questions/882692/integrate-a-division-of-polynomials,SCIENCE,math.stackexchange.com,1.0,0.4444444444444444,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.3333333333333333,0.0,1.0,Division of integral polynomials,"Hi I have the following integral:
$$\int \frac{2x}{x^2+6x+3}\, dx$$

I made some changes like:
$$\int \dfrac{2x+6-6}{x^2+6x+3}\, dx$$

then I have: 
$$\int \dfrac{2x+6}{x^2+6x+3}\, dx -\int\dfrac{6}{x^2+6x+3}\, dx$$

and thus: $$\ln(x^2+6x+3)-\int\dfrac{6}{x^2+6x+3}\, dx$$

Ok, I have decomposed $$\frac{2x}{x^2+6x+3} $$  in: $$ \frac{3+\sqrt6}{\sqrt6(x+\sqrt 6+3)} + \frac{3-\sqrt6}{\sqrt6 (-x+\sqrt6-3)}$$

How can I integrate this expressions?
","$$\frac{2x}{x^2+6x+3}=\frac{A}{x-(-3-\sqrt{6})}+\frac{B}{x-(\sqrt{6}-3)}$$

Find $A$ and $B$ and then:

$$\int \frac{2x}{x^2+6x+3} dx=\int \frac{A}{x-(-3-\sqrt{6})} dx+\int \frac{B}{x-(\sqrt{6}-3)} dx$$
"
3154,3154,5024,Weren't there originally going to be nine Star Wars films?,"I seem to remember reading that there were going to be three trilogies originally in Star Wars, i.e. they would add episodes 7 - 9.

Was that ever the case? What happened to that plan?

Update: looks like that original plan might be back after all!
",Wikis,https://scifi.stackexchange.com/users/143,"What is now Episode IV was originally released as simply ""Star Wars"". It was chosen out of all the stories Lucas had come up with in that universe because it was best able to stand alone as a single movie. Had it been only modestly successful as the studio thought it would be (most of the people working on it actually thought it'd bomb), it probably would have been the only Star Wars movie, and Lucas would have either moved on with the Indiana Jones stories he had in the works, or faded into obscurity. As it was, the film was so successful that Lucas could afford to bankroll ESB himself (something not normally done especially at the time, though the model has since been replicated by Spielberg, Cameron and several other prominent screenwriter/directors).
",KeithS,https://scifi.stackexchange.com/users/2834,http://scifi.stackexchange.com/questions/1207/werent-there-originally-going-to-be-nine-star-wars-films,LIFE_ARTS,scifi.stackexchange.com,1.0,1.0,0.0,0.0,1.0,1.0,0.8888888888888888,0.5555555555555556,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.8888888888888888,0.5555555555555556,0.5555555555555556,1.0,0.8888888888888888,0.33333333333333337,0.0,0.0,1.0,0.8888888888888888,Didn't there start with nine Star Wars movies?,"I seem to remember reading that there were going to be three trilogies originally in Star Wars, i.e. they would add episodes 7 - 9.

Was that ever the case? What happened to that plan?

Update: looks like that original plan might be back after all!
","What is now Episode IV was originally released as simply ""Star Wars"". It was chosen out of all the stories Lucas had come up with in that universe because it was best able to stand alone as a single movie. Had it been only modestly successful as the studio thought it would be (most of the people working on it actually thought it'd bomb), it probably would have been the only Star Wars movie, and Lucas would have either moved on with the Indiana Jones stories he had in the works, or faded into obscurity. As it was, the film was so successful that Lucas could afford to bankroll ESB himself (something not normally done especially at the time, though the model has since been replicated by Spielberg, Cameron and several other prominent screenwriter/directors).
"
1095,1095,1726,Demonstrating the effect of aliasing,"How does the signal look when we don't use the Nyquist rate to remove aliasing from a signal during sampling?

Let's suppose the signal is sinusoidal, with a frequency of 500&nbsp;Hz and an amplitude of 2.

signal = 2*cos(2*pi*500*t)


If I sample it, (replacing t=nTs , Ts = sampling period and n represent number of samples) and plotting the sampled signals with a different sampling period using the subplot command in MATLAB, how could I identify the aliasing in a sampled signal?

Here is the example code that plotted two signals, one at the Nyquist rate while the other less than the Nyquist rate:

A = 2;
Fmax = 10;
Fs = 2*Fmax;
n = 0:1/Fs:1;
Cont = A*sin(2*pi*(Fmax/Fs)*n);
Cont1 = A*sin(2*pi*(Fmax/18)*n);
subplot(2,1,1)
stem(n,Cont)
hold on
stem(n,Cont1)


and here is the waveform:



I wasn't able to identify the aliasing. How did it affect the signal when Nyquist rate didn't use?
",Sufiyan Ghori,https://dsp.stackexchange.com/users/1324,"You can't identify aliasing with a simple sinusoid at a specific frequency and that in a way is the whole point about trying to avoid it. You can't know if the sinusoid you are ""looking at"" is $Q$ Hz or $2Fs-Q$Hz.

A single aliased sinusoidal component looks just like a non-aliased sinusoid. If you want to experience aliasing, you have to attempt it with either a more complex waveform or a sinusoid that is changing in time.

One way to ""experience aliasing"" is to undersample a chirp in the following way:

Fs = 8000;t=0:(1./Fs):(5-1./Fs);p=2.*pi.*t; %Sampling Frequency, Time Vector, Phase Vector
y1 = chirp(t,0,5,Fs/2.0); %Create a chirp that goes from DC to Fs/2.0
spectrogram(y1); %Have a look at it through spectrogram, please pay attention at the axis labels. This is basically going to be a ""line"" increasing with time.
soundsc(y1,Fs); %Listen to it...It clearly ""goes up"" in frequency
y2 = chirp(t,0,5,Fs); %Now create a chirp that goes from DC to Fs
spectrogram(y2); %Have a look at it through spectrogram
soundsc(y2,Fs); %Listen to it...Do you ""get"" the folding of the spectrum?


In general, you can think of Sampling as Modulation because this is what is effectively happening at the sample and hold element of an ADC converter. 

This will enable you to understand more easily concepts like undersampling for example (and applications where it is perfectly OK to sample at lower than the Nyquist rates). But also, you can load a WAV file in MATLAB (with 'wavread') containing some more complex signal and prior to listening to it with 'soundsc', simply multiply it with a ""square"" wave* (you might want to lookup function 'square') at some frequency lower than the WAV file's $F_s$. This will effectively introduce the key (unwanted) characteristic of aliasing which is this folding of the spectrum. The result is not very pleasant so you might want to keep your speakers volume down.

I hope this helps.

*EDIT: Obviously, ""square"" returns a square with an amplitude in the interval [-1,1] so prior to multiplying it with your signal it would be better to rescale it as:

aSquareWave = (square(100.*p)+1.0)/2.0 % Where p is the phase vector and here we are producing a square wave at 100Hz (given an Fs of 8kHz as above). aSquareWave's amplitude is now in the interval [0,1]

",A_A,https://dsp.stackexchange.com/users/1212,http://dsp.stackexchange.com/questions/2326/demonstrating-the-effect-of-aliasing,TECHNOLOGY,dsp.stackexchange.com,1.0,0.3333333333333333,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.3333333333333333,0.6666666666666666,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,1.0,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.6666666666666666,0.3333333333333333,1.0,0.8888888888888888,Demonstrate the effect of aliasing,"How does the signal look when we don't use the Nyquist rate to remove aliasing from a signal during sampling?

Let's suppose the signal is sinusoidal, with a frequency of 500&nbsp;Hz and an amplitude of 2.

signal = 2*cos(2*pi*500*t)


If I sample it, (replacing t=nTs , Ts = sampling period and n represent number of samples) and plotting the sampled signals with a different sampling period using the subplot command in MATLAB, how could I identify the aliasing in a sampled signal?

Here is the example code that plotted two signals, one at the Nyquist rate while the other less than the Nyquist rate:

A = 2;
Fmax = 10;
Fs = 2*Fmax;
n = 0:1/Fs:1;
Cont = A*sin(2*pi*(Fmax/Fs)*n);
Cont1 = A*sin(2*pi*(Fmax/18)*n);
subplot(2,1,1)
stem(n,Cont)
hold on
stem(n,Cont1)


and here is the waveform:



I wasn't able to identify the aliasing. How did it affect the signal when Nyquist rate didn't use?
","You can't identify aliasing with a simple sinusoid at a specific frequency and that in a way is the whole point about trying to avoid it. You can't know if the sinusoid you are ""looking at"" is $Q$ Hz or $2Fs-Q$Hz.

A single aliased sinusoidal component looks just like a non-aliased sinusoid. If you want to experience aliasing, you have to attempt it with either a more complex waveform or a sinusoid that is changing in time.

One way to ""experience aliasing"" is to undersample a chirp in the following way:

Fs = 8000;t=0:(1./Fs):(5-1./Fs);p=2.*pi.*t; %Sampling Frequency, Time Vector, Phase Vector
y1 = chirp(t,0,5,Fs/2.0); %Create a chirp that goes from DC to Fs/2.0
spectrogram(y1); %Have a look at it through spectrogram, please pay attention at the axis labels. This is basically going to be a ""line"" increasing with time.
soundsc(y1,Fs); %Listen to it...It clearly ""goes up"" in frequency
y2 = chirp(t,0,5,Fs); %Now create a chirp that goes from DC to Fs
spectrogram(y2); %Have a look at it through spectrogram
soundsc(y2,Fs); %Listen to it...Do you ""get"" the folding of the spectrum?


In general, you can think of Sampling as Modulation because this is what is effectively happening at the sample and hold element of an ADC converter. 

This will enable you to understand more easily concepts like undersampling for example (and applications where it is perfectly OK to sample at lower than the Nyquist rates). But also, you can load a WAV file in MATLAB (with 'wavread') containing some more complex signal and prior to listening to it with 'soundsc', simply multiply it with a ""square"" wave* (you might want to lookup function 'square') at some frequency lower than the WAV file's $F_s$. This will effectively introduce the key (unwanted) characteristic of aliasing which is this folding of the spectrum. The result is not very pleasant so you might want to keep your speakers volume down.

I hope this helps.

*EDIT: Obviously, ""square"" returns a square with an amplitude in the interval [-1,1] so prior to multiplying it with your signal it would be better to rescale it as:

aSquareWave = (square(100.*p)+1.0)/2.0 % Where p is the phase vector and here we are producing a square wave at 100Hz (given an Fs of 8kHz as above). aSquareWave's amplitude is now in the interval [0,1]

"
6047,6047,9596,Another instructor is pushing me out of the classroom right after my class ends,"I am a graduate student in math in my final year, and for several years have been teaching at my department as a lecturer. This semester, in the same lecture hall there is another lecture that starts 20 minutes after my class ends. It's taught by another instructor from my department. I usually have many students coming to office hours and there are also students asking questions immediately after lecture. Due to other activities, I cannot have office hours right after the lecture this semester and can only stay for about 15 minutes to answer questions.

Many times in the past I had a similar situation and never had any issues with it. This semester the instructor who is teaching right after often arrives 20-15 minutes before her class starts and tells me immediately that I have to go with my students somewhere else. 

I make sure to leave the blackboard clean and take all my stuff away from the instructor's desk before she arrives, but I do believe that I have a right to stay in the classroom after my lecture for at least 5-10 minutes. There is no vacant classroom around, and I don't have time to go with students to my office, which is in a different building.

Last time the instructor told me in front of my students that I don't understand ""simple things"" and that I am ""playing games"". When I was talking to one of my students, she stood very close to us and clearly demonstrated that she wanted us out. I tried to explain her that I couldn't go anywhere else due to my time constraints, but she didn't want to listen to me. I really don't understand what ""simple"" things she meant and what ""games"" I am playing. 

We leave the board clean. She doesn't need to set up a projector. She can still talk to her students before her class starts, if she wants to (even though it seems like her students don't ask her any questions before their class). So, I don't see how I cause any disruption. 

I had met this woman many times before this semester, but we never talked. I didn't see her talking to other instructors/students much, and she seems to be quite reserved and a bit neurotic. She doesn't want to have any conversation with me regarding the issue.

I felt really offended after last class when she said those things to me in front of my students. What would you do in my case? 

Added later: There are no official rules regarding classroom occupancy between classes. Instructors are supposed to use common sense and be reasonable. For me using 50% of the break time seems reasonable to answer questions after lecture seems reasonable. I agree that for some people it may not.

I don't block the entrance to the classroom. A few students from the next class who come earlier always go ahead and take their seats as soon as my students start leaving the room. I also had one of the students from the next class listening to my explanation to one of those after-class questions and asking me further questions before their class (which is the same class as I am teaching, just a different section). Maybe the instructor got jealous, I don't know.

The entrance to the classroom is from its front (not back), so I do stay in the front. But it is a big lecture hall, and there is a plenty of space in front of the room (the board itself consists of 8 huge panels).

Also, during my career as a grad.student who is also teaching for the department, I have had several observations from experienced professors who are considered to be great teachers at the department and are in charge of undergraduate teaching policy. In my evaluations the fact that there are always several students approaching me with questions after class considered as very positive, meaning that students find me approachable. 

Thank you everyone for answers. 
",Lidd88,https://academia.stackexchange.com/users/31345,"I would like to provide two suggestions. The first one directly refers to your discussions with students:


  There is no vacant classroom around, and I don't have time to go with students to my office, which is in a different building.


If the questions really need to be answered immediately, you could simply take the discussion outside into the hallway. Surely, most of the students have to or want to leave, anyway, I presume, as they might have to move to different buildings themselves (?)

For anything else, you do not have to ""have office hours right after the lecture"", and you do not have to ""go with students to [your] office"". They are adults. Surely, your students can find out where your office is on their own and come there when you are free.

My second suggestion is related to whether you may stay around in the lecture room after your class:

It generally seems like the most corteous and natural thing to me that once the class has ended, one should try and leave the room as quickly as possible. Unless otherwise regulated by your organisation, I see no basis for the fundamental belief


  I have a right to stay in the classroom after my lecture for at least 5-10 minutes


... unless your departure actually takes that long (e.g. because you have to pack some elaborate experimental setups for a while). At the same time, however, I wouldn't concede the other lecturer any basic right to arrive in the classroom at least 5 - 10 minutes before the next lecture starts, unless some elaborate setup needs to be prepared for that lecture.

In other words: If you are entitled to stay for at least 5 to 10 minutes after your lecture has ended, I would argue that the next lecturer is just as entitled to claim the room for themselves at least 5 to 10 minutes before the next lecture starts.

With that said, it is usually well possible to stay around to answer such questions, though that does neither mean that the room will be reserved for you (the next lecture may already be under preparation), nor are you automatically the ""main party"" (in that you may block the ""lecturer's desk"" or any such central device, rather than cluster your discussion in a corner of the room to give the next people space).
",O. R. Mapper,https://academia.stackexchange.com/users/14017,http://academia.stackexchange.com/questions/41133/another-instructor-is-pushing-me-out-of-the-classroom-right-after-my-class-ends,LIFE_ARTS,academia.stackexchange.com,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.0,0.8888888888888888,0.8888888888888888,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.8888888888888888,0.7777777777777778,0.6666666666666666,0.8888888888888888,1.0,0.7333333333333333,0.0,0.0,0.6666666666666666,0.8888888888888888,No sooner had I finished class than another teacher kicked me out of the classroom,"I am a graduate student in math in my final year, and for several years have been teaching at my department as a lecturer. This semester, in the same lecture hall there is another lecture that starts 20 minutes after my class ends. It's taught by another instructor from my department. I usually have many students coming to office hours and there are also students asking questions immediately after lecture. Due to other activities, I cannot have office hours right after the lecture this semester and can only stay for about 15 minutes to answer questions.

Many times in the past I had a similar situation and never had any issues with it. This semester the instructor who is teaching right after often arrives 20-15 minutes before her class starts and tells me immediately that I have to go with my students somewhere else. 

I make sure to leave the blackboard clean and take all my stuff away from the instructor's desk before she arrives, but I do believe that I have a right to stay in the classroom after my lecture for at least 5-10 minutes. There is no vacant classroom around, and I don't have time to go with students to my office, which is in a different building.

Last time the instructor told me in front of my students that I don't understand ""simple things"" and that I am ""playing games"". When I was talking to one of my students, she stood very close to us and clearly demonstrated that she wanted us out. I tried to explain her that I couldn't go anywhere else due to my time constraints, but she didn't want to listen to me. I really don't understand what ""simple"" things she meant and what ""games"" I am playing. 

We leave the board clean. She doesn't need to set up a projector. She can still talk to her students before her class starts, if she wants to (even though it seems like her students don't ask her any questions before their class). So, I don't see how I cause any disruption. 

I had met this woman many times before this semester, but we never talked. I didn't see her talking to other instructors/students much, and she seems to be quite reserved and a bit neurotic. She doesn't want to have any conversation with me regarding the issue.

I felt really offended after last class when she said those things to me in front of my students. What would you do in my case? 

Added later: There are no official rules regarding classroom occupancy between classes. Instructors are supposed to use common sense and be reasonable. For me using 50% of the break time seems reasonable to answer questions after lecture seems reasonable. I agree that for some people it may not.

I don't block the entrance to the classroom. A few students from the next class who come earlier always go ahead and take their seats as soon as my students start leaving the room. I also had one of the students from the next class listening to my explanation to one of those after-class questions and asking me further questions before their class (which is the same class as I am teaching, just a different section). Maybe the instructor got jealous, I don't know.

The entrance to the classroom is from its front (not back), so I do stay in the front. But it is a big lecture hall, and there is a plenty of space in front of the room (the board itself consists of 8 huge panels).

Also, during my career as a grad.student who is also teaching for the department, I have had several observations from experienced professors who are considered to be great teachers at the department and are in charge of undergraduate teaching policy. In my evaluations the fact that there are always several students approaching me with questions after class considered as very positive, meaning that students find me approachable. 

Thank you everyone for answers. 
","I would like to provide two suggestions. The first one directly refers to your discussions with students:


  There is no vacant classroom around, and I don't have time to go with students to my office, which is in a different building.


If the questions really need to be answered immediately, you could simply take the discussion outside into the hallway. Surely, most of the students have to or want to leave, anyway, I presume, as they might have to move to different buildings themselves (?)

For anything else, you do not have to ""have office hours right after the lecture"", and you do not have to ""go with students to [your] office"". They are adults. Surely, your students can find out where your office is on their own and come there when you are free.

My second suggestion is related to whether you may stay around in the lecture room after your class:

It generally seems like the most corteous and natural thing to me that once the class has ended, one should try and leave the room as quickly as possible. Unless otherwise regulated by your organisation, I see no basis for the fundamental belief


  I have a right to stay in the classroom after my lecture for at least 5-10 minutes


... unless your departure actually takes that long (e.g. because you have to pack some elaborate experimental setups for a while). At the same time, however, I wouldn't concede the other lecturer any basic right to arrive in the classroom at least 5 - 10 minutes before the next lecture starts, unless some elaborate setup needs to be prepared for that lecture.

In other words: If you are entitled to stay for at least 5 to 10 minutes after your lecture has ended, I would argue that the next lecturer is just as entitled to claim the room for themselves at least 5 to 10 minutes before the next lecture starts.

With that said, it is usually well possible to stay around to answer such questions, though that does neither mean that the room will be reserved for you (the next lecture may already be under preparation), nor are you automatically the ""main party"" (in that you may block the ""lecturer's desk"" or any such central device, rather than cluster your discussion in a corner of the room to give the next people space).
"
3206,3206,5110,Is this strengthening of paracompactness known?,"Consider a topological space $X$. What can be said about the following property?


For any open cover $\mathcal U = \{ U_i \}_{ i \in I }$ of $X$,
there exists an open refinement $\mathcal V = \{ V_j \}_{ j \in J }$ such that any set $V \in \mathcal V$ of the refinement intersects only finitely many other sets of $\mathcal V$.


This property is stronger than paracompactness, but is it weaker than compactness?

Does it hold on topological manifolds (which are paracompact and second-countable)?
",shuhalo,https://math.stackexchange.com/users/3557,"This property has been called hypocompactness; it is strictly weaker than compactness and strictly stronger than paracompactness. The Sorgenfrey line is hypocompact but not compact: every open cover has a disjoint clopen refinement. Any hedgehog space $X$ of uncountable spininess is an example of a paracompact space that is not hypocompact. $X$ is metrizable, so it’s paracompact. If $X$ has spininess $\kappa$, $p$ is the centre point of the hedgehog, the points at the ends of the spines are $q_\xi$ for $\xi&lt;\kappa$, and the metric $d$ is as in the linked article, the open cover

$$\left\{B_d\left(p,\frac23\right)\right\}\cup\left\{B_d\left(q_\xi,\frac23\right):\xi&lt;\kappa\right\}$$

has no open refinement that is star-finite at $p$.

Added: Henno reminds me that I forgot to answer the last question. Paracompact Lindelöf spaces are hypocompact, so separable metric spaces are hypocompact.
",Brian M. Scott,https://math.stackexchange.com/users/12042,http://math.stackexchange.com/questions/1124179/is-this-strengthening-of-paracompactness-known,SCIENCE,math.stackexchange.com,0.8888888888888888,0.4444444444444444,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.3333333333333333,1.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.3333333333333333,0.3333333333333333,1.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.3333333333333333,1.0,0.8888888888888888,Is this enhanced paracompact known?,"Consider a topological space $X$. What can be said about the following property?


For any open cover $\mathcal U = \{ U_i \}_{ i \in I }$ of $X$,
there exists an open refinement $\mathcal V = \{ V_j \}_{ j \in J }$ such that any set $V \in \mathcal V$ of the refinement intersects only finitely many other sets of $\mathcal V$.


This property is stronger than paracompactness, but is it weaker than compactness?

Does it hold on topological manifolds (which are paracompact and second-countable)?
","This property has been called hypocompactness; it is strictly weaker than compactness and strictly stronger than paracompactness. The Sorgenfrey line is hypocompact but not compact: every open cover has a disjoint clopen refinement. Any hedgehog space $X$ of uncountable spininess is an example of a paracompact space that is not hypocompact. $X$ is metrizable, so it’s paracompact. If $X$ has spininess $\kappa$, $p$ is the centre point of the hedgehog, the points at the ends of the spines are $q_\xi$ for $\xi&lt;\kappa$, and the metric $d$ is as in the linked article, the open cover

$$\left\{B_d\left(p,\frac23\right)\right\}\cup\left\{B_d\left(q_\xi,\frac23\right):\xi&lt;\kappa\right\}$$

has no open refinement that is star-finite at $p$.

Added: Henno reminds me that I forgot to answer the last question. Paracompact Lindelöf spaces are hypocompact, so separable metric spaces are hypocompact.
"
1650,1650,2600,How can I create and retrieve default billing address programatically?,"Our site imports customers from external data sources. Part of this import is creating a default billing address from external data if none exists.

I have followed advice from other questions, as wells as tutorials, all of which seem to say the same thing for creating/saving a default billing address.
This seems to work at least partially.

// $c is the customer
$data_source  = array(
    'street'   =&gt; '',
    'city'     =&gt; '',
    'postcode' =&gt; '',
);

$a = $c-&gt;getPrimaryBillingAddress();

// Create a new default billing if none found
if (!$a)
{
  $a = Mage::getModel(""customer/address"");
  $a-&gt;setCustomerId($c-&gt;getId())
    -&gt;setIsDefaultBilling('1')
    -&gt;setSaveInAddressBook('1');
}

foreach ($data_source as $k =&gt; $d) $a-&gt;setData($k, $d);

$a-&gt;save();


After this code has been run, the address is visible on the customer's page in the backend and is marked as the default billing.

However, the following time data is fetched from our external source and the code is run,
the address that was saved is not retrieved (getPrimaryBillingAddress returns false).
This results in a new address being created every time this code is run.

The exception is when a customer has a default billing address set by magento.
In this case, getPrimaryBillingAddress correctly finds the address and the address data is updated and saved.

How can I programatically create a default billing address in such a way that I can retrieve it with $customer-&gt;getPrimaryBillingAddress()?

UPDATE

After receiving a possible answer, I have adjusted to code to set customer's default_billing.
The main problem persists with the changes.

$a = $c-&gt;getPrimaryBillingAddress();

// Create a new default billing if none found
if (!$a)
{
  $a = Mage::getModel(""customer/address"");
  $a-&gt;setCustomerId($c-&gt;getId())            // &lt;-- variations of customer/customerID 
    -&gt;setCustomer($c)                       //     don't seem to affect
    -&gt;setIsDefaultBilling('1')
    -&gt;setSaveInAddressBook('1')
    -&gt;save();                               // &lt;--- SAVE SO WE CAN ACCESS ID

  $c-&gt;addAddress($a)                        // &lt;--|
    -&gt;setDefaultBilling($a-&gt;getId())        // &lt;--+ SAVE default_billing IN CUSTOMER
    -&gt;save();                               // &lt;--|

}

foreach ($data_source as $k =&gt; $d) $a-&gt;setData($k, $d);

$a-&gt;save();

// ---------------- SUBSEQUENT RUNS --------------

$c-&gt;getDefaultBilling();                    // null
$c-&gt;getPrimaryBillingAddress();             // false


References

Variations on this method for creating/setting a customer default address were found at these locations:


SO - Magento : Add customer default billing address
Programatically create customer and order in Magento with full blown One Page Checkout process under the hood

",Jon Surrell,https://magento.stackexchange.com/users/13399,"You need to set it the other way around. The default_billing for the customer.

$customerId = 1234; // Customer id
$data = array(); // Address data

$customer = Mage::getModel('customer/customer');

// Load customer
$customer-&gt;load($customerId);

// Get current address
$address = $customer-&gt;getPrimaryBillingAddress();

// Do we add a new address
$isNewAddress = false;
if (!$address) {
    $address = Mage::getModel('customer/address');

    $address-&gt;setCustomer($customer);
    $isNewAddress = true;
}

// Append data
$address-&gt;addData($data);
$address-&gt;save();

if ($isNewAddress) {
    // Add address to customer and save
    $customer-&gt;addAddress($address)
        -&gt;setDefaultBilling($address-&gt;getId())
        -&gt;save();
}

",Jeroen,https://magento.stackexchange.com/users/3156,http://magento.stackexchange.com/questions/60359/how-can-i-create-and-retrieve-default-billing-address-programatically,TECHNOLOGY,magento.stackexchange.com,1.0,0.5555555555555556,0.0,1.0,1.0,1.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.3333333333333333,0.0,0.8888888888888888,How do I programmatically create and retrieve default billing addresses?,"Our site imports customers from external data sources. Part of this import is creating a default billing address from external data if none exists.

I have followed advice from other questions, as wells as tutorials, all of which seem to say the same thing for creating/saving a default billing address.
This seems to work at least partially.

// $c is the customer
$data_source  = array(
    'street'   =&gt; '',
    'city'     =&gt; '',
    'postcode' =&gt; '',
);

$a = $c-&gt;getPrimaryBillingAddress();

// Create a new default billing if none found
if (!$a)
{
  $a = Mage::getModel(""customer/address"");
  $a-&gt;setCustomerId($c-&gt;getId())
    -&gt;setIsDefaultBilling('1')
    -&gt;setSaveInAddressBook('1');
}

foreach ($data_source as $k =&gt; $d) $a-&gt;setData($k, $d);

$a-&gt;save();


After this code has been run, the address is visible on the customer's page in the backend and is marked as the default billing.

However, the following time data is fetched from our external source and the code is run,
the address that was saved is not retrieved (getPrimaryBillingAddress returns false).
This results in a new address being created every time this code is run.

The exception is when a customer has a default billing address set by magento.
In this case, getPrimaryBillingAddress correctly finds the address and the address data is updated and saved.

How can I programatically create a default billing address in such a way that I can retrieve it with $customer-&gt;getPrimaryBillingAddress()?

UPDATE

After receiving a possible answer, I have adjusted to code to set customer's default_billing.
The main problem persists with the changes.

$a = $c-&gt;getPrimaryBillingAddress();

// Create a new default billing if none found
if (!$a)
{
  $a = Mage::getModel(""customer/address"");
  $a-&gt;setCustomerId($c-&gt;getId())            // &lt;-- variations of customer/customerID 
    -&gt;setCustomer($c)                       //     don't seem to affect
    -&gt;setIsDefaultBilling('1')
    -&gt;setSaveInAddressBook('1')
    -&gt;save();                               // &lt;--- SAVE SO WE CAN ACCESS ID

  $c-&gt;addAddress($a)                        // &lt;--|
    -&gt;setDefaultBilling($a-&gt;getId())        // &lt;--+ SAVE default_billing IN CUSTOMER
    -&gt;save();                               // &lt;--|

}

foreach ($data_source as $k =&gt; $d) $a-&gt;setData($k, $d);

$a-&gt;save();

// ---------------- SUBSEQUENT RUNS --------------

$c-&gt;getDefaultBilling();                    // null
$c-&gt;getPrimaryBillingAddress();             // false


References

Variations on this method for creating/setting a customer default address were found at these locations:


SO - Magento : Add customer default billing address
Programatically create customer and order in Magento with full blown One Page Checkout process under the hood

","You need to set it the other way around. The default_billing for the customer.

$customerId = 1234; // Customer id
$data = array(); // Address data

$customer = Mage::getModel('customer/customer');

// Load customer
$customer-&gt;load($customerId);

// Get current address
$address = $customer-&gt;getPrimaryBillingAddress();

// Do we add a new address
$isNewAddress = false;
if (!$address) {
    $address = Mage::getModel('customer/address');

    $address-&gt;setCustomer($customer);
    $isNewAddress = true;
}

// Append data
$address-&gt;addData($data);
$address-&gt;save();

if ($isNewAddress) {
    // Add address to customer and save
    $customer-&gt;addAddress($address)
        -&gt;setDefaultBilling($address-&gt;getId())
        -&gt;save();
}

"
616,616,966,ArcMap 10.1 How to make mass (in bulk) update by attribute value,"I have feature class with 70,000+ records (file geodatabase). 
I want to make in bulk update on an attribute where the value is NULL.
Select by attribute shows that I have 5,000 records like that. Doing it one by one is going to be a pain.

In sql pseudo code it should be something like that:

 UPDATE &lt;MyAttributeName&gt; = 'NewValue'
 WHERE &lt;MyAttributeName&gt; IS NULL


How do I do that with ArcMap 10.1?
",mitaka,https://gis.stackexchange.com/users/17107,"You would select the rows which are NULL (sounds like you have done that) then simply run the calculate field tool.

Right Click the field you want to modify (while objects are selected)
   

Then input your value ""newvalue""

NOTE: 1. if you don't have a selection this will work on ""ALL"" rows in your table!
2. Double quotes in this area on your text/date value. See esri help for examples of vba/python/string/number/codeblock options
3. Must begin edit session to run in FGDB.  
",Hornbydd,https://gis.stackexchange.com/users/934,http://gis.stackexchange.com/questions/70434/making-mass-bulk-update-by-attribute-value-in-arcgis-desktop/70436,TECHNOLOGY,gis.stackexchange.com,1.0,0.6666666666666666,0.0,1.0,1.0,1.0,0.5555555555555556,0.5555555555555556,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.3333333333333333,0.0,0.8888888888888888,How to update mass (batch) by attribute value in ArcMap 10.1,"I have feature class with 70,000+ records (file geodatabase). 
I want to make in bulk update on an attribute where the value is NULL.
Select by attribute shows that I have 5,000 records like that. Doing it one by one is going to be a pain.

In sql pseudo code it should be something like that:

 UPDATE &lt;MyAttributeName&gt; = 'NewValue'
 WHERE &lt;MyAttributeName&gt; IS NULL


How do I do that with ArcMap 10.1?
","You would select the rows which are NULL (sounds like you have done that) then simply run the calculate field tool.

Right Click the field you want to modify (while objects are selected)
   

Then input your value ""newvalue""

NOTE: 1. if you don't have a selection this will work on ""ALL"" rows in your table!
2. Double quotes in this area on your text/date value. See esri help for examples of vba/python/string/number/codeblock options
3. Must begin edit session to run in FGDB.  
"
2306,2306,3677,How do you decide when a paladin has fallen from grace in DnD 5e?,"There does not seem to be a clear-cut way to determine when a paladin's actions have become egregious enough to justify them breaking their oath. Do a lot of minor slights eventually add up and cause an oath to be broken? Do they get some sort of warning like losing their laying on of hands ability? 
",adclark09,https://rpg.stackexchange.com/users/22899,"You're right.  There is no clear cut way.  That's by design.  How this works varies a lot by playstyle:

Some groups have a solid understanding of ethics and jurisprudence and use some limited form of said understanding adjudicate alignment in D&amp;D.  Others use their full understanding of ethics, which cumulates for them into a D&amp;D compatible system, to perform that adjudication.  These groups are very similar except that the first group tends to have less issues adjudicating alignment in difficult situations where the latter group discovers holes in their beliefs about morality.  In both of these cases alignment is adjudicated according to the chosen moral/ethical system, and what constitutes oath-breaking will be adjudicated similarly according to the related principles of jurisprudence. As moral relativism becomes, unfortunately, increasingly popular, objective alignment becomes less and less so, especially amongst simulationist groups, and so these two methods of alignment adjudication are unlikely.

Some groups think alignment is stupid, meaningless, and entirely subjective.  These people are very vocal.  They likely also think that oathbreaking is similarly problematic.  Like alignment-based powers in previous editions, in these groups if you're going to use anything that's based off alignment or alignment-like systems (like the paladin class) you should first check with your DM to find out 1) if it's allowed and 2) what it means in the context of the campaign.  One common solution in the past in these kinds of groups has been just to waive the alignment restriction entirely, for the Paladin class.

Some groups think that obviously alignment is objective, because it's in the rules, but they just don't understand it yet.  These groups will post difficult alignment questions as they come up on online fora.  The outcome of alignment based actions in such groups will be fickle and likely a point of tension.

Some groups try and adjudicate this according to the original inspiration for the alignment system, which is a set of novels written by Michael Moorcock.  This is hard because the novels are novel-y and don't explain exactly what Law and Chaos are in cut and dry terms.  Such groups would probably not adjudicate the oath the same way they do alignment, because Jurisprudence is fundamentally a principle of Balance, not Law, in that system, and there's almost nothing to go on for how something like the 5e paladin oath should be dealt with.

In any case, if you are not the DM, ask your DM how the metaphysics of ethics and jurisprudence are related in their game.  If they are related, seek to focus more on the adjudication of ethics than jurisprudence as the ethical component is probably dominant in most GM adjudications.  If they are not related, ask about Jurisprudence in general, and the adjudication of your class abilities in particular, if necessary, focusing on what an Oath means, what it means to break it, and how reparations might be made if the oath is indeed broken.

If you are the DM, I strongly recommend you consciously decide what philosophical system of justice you will use in your campaign, as all of the other options amount to unconsciously using some system and putting some introspective thought into this choice before you start running the game is likely to make these kinds of decisions much easier and much faster during the game sessions, since you will spend much less time figuring out how to approach each specific case.

If you want a place to start looking at different approaches to the philosophy of oaths, I recommend this paper.
",the dark wanderer,https://rpg.stackexchange.com/users/14848,http://rpg.stackexchange.com/questions/62167/how-do-you-decide-when-a-paladin-has-fallen-from-grace-in-dnd-5e,CULTURE,rpg.stackexchange.com,0.8888888888888888,0.7777777777777778,1.0,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.4444444444444444,1.0,0.0,1.0,0.3333333333333333,0.0,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.0,0.7777777777777778,1.0,0.7777777777777778,1.0,1.0,0.9333333333333332,0.0,0.3333333333333333,1.0,0.7777777777777778,How do you decide when a paladin will fall out of favor in dnd5e?,"There doesn't seem to be a clear way to determine when the Knights' behavior has become too much to prove that they have broken the oath. Will a lot of slight contempt eventually lead to the breaking of vows? Do they get some kind of warning, such as losing the ability to start?","You're right.  There is no clear cut way.  That's by design.  How this works varies a lot by playstyle:

Some groups have a solid understanding of ethics and jurisprudence and use some limited form of said understanding adjudicate alignment in D&amp;D.  Others use their full understanding of ethics, which cumulates for them into a D&amp;D compatible system, to perform that adjudication.  These groups are very similar except that the first group tends to have less issues adjudicating alignment in difficult situations where the latter group discovers holes in their beliefs about morality.  In both of these cases alignment is adjudicated according to the chosen moral/ethical system, and what constitutes oath-breaking will be adjudicated similarly according to the related principles of jurisprudence. As moral relativism becomes, unfortunately, increasingly popular, objective alignment becomes less and less so, especially amongst simulationist groups, and so these two methods of alignment adjudication are unlikely.

Some groups think alignment is stupid, meaningless, and entirely subjective.  These people are very vocal.  They likely also think that oathbreaking is similarly problematic.  Like alignment-based powers in previous editions, in these groups if you're going to use anything that's based off alignment or alignment-like systems (like the paladin class) you should first check with your DM to find out 1) if it's allowed and 2) what it means in the context of the campaign.  One common solution in the past in these kinds of groups has been just to waive the alignment restriction entirely, for the Paladin class.

Some groups think that obviously alignment is objective, because it's in the rules, but they just don't understand it yet.  These groups will post difficult alignment questions as they come up on online fora.  The outcome of alignment based actions in such groups will be fickle and likely a point of tension.

Some groups try and adjudicate this according to the original inspiration for the alignment system, which is a set of novels written by Michael Moorcock.  This is hard because the novels are novel-y and don't explain exactly what Law and Chaos are in cut and dry terms.  Such groups would probably not adjudicate the oath the same way they do alignment, because Jurisprudence is fundamentally a principle of Balance, not Law, in that system, and there's almost nothing to go on for how something like the 5e paladin oath should be dealt with.

In any case, if you are not the DM, ask your DM how the metaphysics of ethics and jurisprudence are related in their game.  If they are related, seek to focus more on the adjudication of ethics than jurisprudence as the ethical component is probably dominant in most GM adjudications.  If they are not related, ask about Jurisprudence in general, and the adjudication of your class abilities in particular, if necessary, focusing on what an Oath means, what it means to break it, and how reparations might be made if the oath is indeed broken.

If you are the DM, I strongly recommend you consciously decide what philosophical system of justice you will use in your campaign, as all of the other options amount to unconsciously using some system and putting some introspective thought into this choice before you start running the game is likely to make these kinds of decisions much easier and much faster during the game sessions, since you will spend much less time figuring out how to approach each specific case.

If you want a place to start looking at different approaches to the philosophy of oaths, I recommend this paper.
"
5744,5744,9094,It's possible change dynamically devise configuration without app restart?,"I'm using devise v.2.2.4 on my Rails 3.2.17 and I need some features related with security policies.

The admin user will change the security policies at any time like show next image:


but I don't know how make it with devise, because devise read configuration of initializers/devise.rb and on production all initializer are loading the first time only.
",kikicarbonell,https://stackoverflow.com/users/896830,"I believe you can pre-seed some table with default preferences data for devise (or any other gem/library) and then get it from the db in your initializer. 
Then add some crud to let admin user change this preferences.
But full restart of app will be needed for update this preferences. 
",ryaz,https://stackoverflow.com/users/951619,http://stackoverflow.com/questions/26932663/its-possible-change-dynamically-devise-configuration-without-app-restart,STACKOVERFLOW,stackoverflow.com,0.6666666666666666,0.6666666666666666,0.0,0.5,1.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.5,0.5,0.0,0.0,0.0,0.0,0.5,0.5,0.0,0.0,0.6666666666666666,0.8333333333333334,0.6666666666666666,1.0,1.0,0.9,0.5,0.5,0.0,0.8333333333333334,Can configuration be designed dynamically without restarting the application?,"I'm using devise v.2.2.4 on my Rails 3.2.17 and I need some features related with security policies.

The admin user will change the security policies at any time like show next image:


but I don't know how make it with devise, because devise read configuration of initializers/devise.rb and on production all initializer are loading the first time only.
","I believe you can pre-seed some table with default preferences data for devise (or any other gem/library) and then get it from the db in your initializer. 
Then add some crud to let admin user change this preferences.
But full restart of app will be needed for update this preferences. 
"
2867,2867,4563,Forward slashes: are they acceptable in Commonwealth English prose?,"In Commonwealth English is it acceptable to write this in a magazine article:


  If there are there any nearby towns/villages …

",Wendy,https://english.stackexchange.com/users/24940,"Using a forward slash is acceptable as a typographical symbol in place of ""or"". Overuse has the unfortunate consequence of reduced flow and/or writer appearing unsure of himself/herself.
",Chris,https://english.stackexchange.com/users/24666,http://english.stackexchange.com/questions/78446/forward-slashes-are-they-acceptable-in-commonwealth-english-prose,CULTURE,english.stackexchange.com,1.0,0.8888888888888888,0.3333333333333333,1.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,1.0,0.0,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8888888888888888,1.0,0.7777777777777778,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,1.0,Slash: is it acceptable in Commonwealth English prose?,Is writing this article in Commonwealth English acceptable in magazines:,"Using a forward slash is acceptable as a typographical symbol in place of ""or"". Overuse has the unfortunate consequence of reduced flow and/or writer appearing unsure of himself/herself.
"
5889,5889,9330,What are the implications of Emmet's autonomous movement?,"During The Lego Movie we learn that the whole LEGO world is actually a universe existing within ours, or to be precise, in the basement of a real human family and that the whole story is actually played out by a little boy named Finn and a way for him to cope with the conflict of his strict and fantasy-inhibiting father. And indeed this is again strengthened when we see that the actions as performed by his father when supposedly ""repairing the mess"" that Finn created are directly represented by Lord Business' micromanagers performing them inside the in-universe viewpoint of the other LEGO figures.

Upto this point that is a reasonable and obvious representation to me and even Emmet's direct witness of the universe behind his, our real world, is nothing but him seeing the strips behind the course of his own universe, however he managed to overcome this boundary between dimensions. But the single-most action that completely shatters this whole viewpoint is the incident, when Emmet manages to move completely on his own, thus directly interfering with our universe on his own and it seems to me that there is no way to bring this in congruence to our own physical reality, not even when accepting the LEGO world and its course as an emanation of Finn's fantasy, since Finn didn't do anything at all.

So what are we to make of this incident? Does it have any deeper implications for the depicted realities? Does this establish the LEGO figures as existent and sentient within our physical reality outside of our mere fantasy? Does it have any further signficance for the meaning of the whole story and actually extend the rather simple and obvious kid's fantasy interpretation of the story in a much more elaborate way I have missed? Or is this just to be brushed off as nothing of relevance?
",Napoleon Wilson,https://movies.stackexchange.com/users/49,"I believe Emmet's movements can be explained in a similar way as in Toy Story.  The toys each have an individual personality and autonomy, but those personalities and autonomous actions are affected by the person playing with the toys.

This would mean that a large portion of the movie consisted of the characters acting in and of themselves.  This makes sense if we consider the people making fun of Emmet, as I don't think that was Finn nor his Father.  Furthermore, if we consider the lore of the world (The vortex, the Kragle), these things would make sense if the characters would autonomous, (If a lego person falls off the table, he'll just pick him up).

While it is definitely possible that a child would imagine this on his own, I think it makes more sense that the legos are autonomous all the time, but given personality from the one playing with them.
",Nathan Merrill,https://movies.stackexchange.com/users/16278,http://movies.stackexchange.com/questions/27924/what-are-the-implications-of-emmets-autonomous-movement,LIFE_ARTS,movies.stackexchange.com,1.0,0.6666666666666666,1.0,0.3333333333333333,0.0,0.0,0.5555555555555556,0.5555555555555556,0.6666666666666666,0.0,1.0,0.3333333333333333,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,0.8888888888888888,What does Emmett's autonomous movement mean?,"During The Lego Movie we learn that the whole LEGO world is actually a universe existing within ours, or to be precise, in the basement of a real human family and that the whole story is actually played out by a little boy named Finn and a way for him to cope with the conflict of his strict and fantasy-inhibiting father. And indeed this is again strengthened when we see that the actions as performed by his father when supposedly ""repairing the mess"" that Finn created are directly represented by Lord Business' micromanagers performing them inside the in-universe viewpoint of the other LEGO figures.

Upto this point that is a reasonable and obvious representation to me and even Emmet's direct witness of the universe behind his, our real world, is nothing but him seeing the strips behind the course of his own universe, however he managed to overcome this boundary between dimensions. But the single-most action that completely shatters this whole viewpoint is the incident, when Emmet manages to move completely on his own, thus directly interfering with our universe on his own and it seems to me that there is no way to bring this in congruence to our own physical reality, not even when accepting the LEGO world and its course as an emanation of Finn's fantasy, since Finn didn't do anything at all.

So what are we to make of this incident? Does it have any deeper implications for the depicted realities? Does this establish the LEGO figures as existent and sentient within our physical reality outside of our mere fantasy? Does it have any further signficance for the meaning of the whole story and actually extend the rather simple and obvious kid's fantasy interpretation of the story in a much more elaborate way I have missed? Or is this just to be brushed off as nothing of relevance?
","I believe Emmet's movements can be explained in a similar way as in Toy Story.  The toys each have an individual personality and autonomy, but those personalities and autonomous actions are affected by the person playing with the toys.

This would mean that a large portion of the movie consisted of the characters acting in and of themselves.  This makes sense if we consider the people making fun of Emmet, as I don't think that was Finn nor his Father.  Furthermore, if we consider the lore of the world (The vortex, the Kragle), these things would make sense if the characters would autonomous, (If a lego person falls off the table, he'll just pick him up).

While it is definitely possible that a child would imagine this on his own, I think it makes more sense that the legos are autonomous all the time, but given personality from the one playing with them.
"
2303,2303,3667,Linux : how to redirect stdout & stderr to logger?,"I have a program I need to run at startup, it has output on stdout and stderr that I want to redirect to the system log using the logger command.  What I have in my startup script is thie:


/home/dirname/application_name -v|logger 2>&1 &


This is redirecting the stdout to syslog just fine but stderr is coming to the console, so I need some help on refining the command.
",fred basset,https://unix.stackexchange.com/users/42163,"You need to combine the output of STDERR and STDOUT prior to piping it to logger. Try this instead:

/home/dirname/application_name -v 2&gt;&amp;1 | logger &amp;


Example

$ echo ""hi"" 2&gt;&amp;1 | logger &amp;
[1] 26818
[1]+  Done                    echo ""hi"" 2&gt;&amp;1 | logger

$ sudo tail /var/log/messages
Apr 12 17:53:57 greeneggs saml: hi


You can use the abbreviated notation here as well, if used cautiously in a actual Bash shell (not to be confused with Dash):

$ echo ""hi"" |&amp; logger &amp;


NOTE: This is equivalent to &lt;cmd1&gt; 2&gt;&amp;1 | &lt;cmd2&gt;. Again only use the above when making use of an actual Bash shell interactively, would be a good way to approach it.

excerpt from ABSG


  # |&amp; was added to Bash 4 as an abbreviation for 2>&amp;1 |.


References


Advanced Bash Scripting Guide - Chapter 20. I/O Redirection

",slm,https://unix.stackexchange.com/users/7453,http://unix.stackexchange.com/questions/124455/linux-how-to-redirect-stdout-stderr-to-logger,TECHNOLOGY,unix.stackexchange.com,1.0,0.7777777777777778,0.0,1.0,1.0,1.0,0.5555555555555556,0.5555555555555556,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.6666666666666666,0.8333333333333334,1.0,0.8,1.0,0.0,0.0,1.0,Linux: how to redirect stdout and stderr to logger?,"I have a program that needs to be run at startup, which has output on stdout and stderr, and I want to redirect to the system log using the logger command. My startup script includes the following:","You need to combine the output of STDERR and STDOUT prior to piping it to logger. Try this instead:

/home/dirname/application_name -v 2&gt;&amp;1 | logger &amp;


Example

$ echo ""hi"" 2&gt;&amp;1 | logger &amp;
[1] 26818
[1]+  Done                    echo ""hi"" 2&gt;&amp;1 | logger

$ sudo tail /var/log/messages
Apr 12 17:53:57 greeneggs saml: hi


You can use the abbreviated notation here as well, if used cautiously in a actual Bash shell (not to be confused with Dash):

$ echo ""hi"" |&amp; logger &amp;


NOTE: This is equivalent to &lt;cmd1&gt; 2&gt;&amp;1 | &lt;cmd2&gt;. Again only use the above when making use of an actual Bash shell interactively, would be a good way to approach it.

excerpt from ABSG


  # |&amp; was added to Bash 4 as an abbreviation for 2>&amp;1 |.


References


Advanced Bash Scripting Guide - Chapter 20. I/O Redirection

"
1990,1990,3172,Is there a comprehensive life science techniques/methods database?,"There are so many techniques/methodologies in the life sciences that we can use to interrogate interesting questions. The thing is, most of us are completely unaware of the available methods we can employ. Rather, we go with the techniques we are familiar with or that are popular in our subdomains at the time. But that's pretty limiting.

So I'm wondering... we have databases for everything else... is there one for life sciences techniques/methods? Something like this could be immensely helpful in experimental planning. In particular, I think a comprehensive database would help scientists break outside of their spheres of familiarity and to employ less known (but potentially illuminating) methods to their questions.

I know there are journals that publish protocols and methods, but they are fragmented and don't encompass everything. 

Does what I'm looking for exist? If not, how might one go about creating such a tool? 
",Alex,https://biology.stackexchange.com/users/1909,"you can use something like https://www.synbiota.com/ where you can store and share your protocols with collaborators. If you make your project open, then anyone in the world can view your protocols.

The nice thing about this is you can reference actual experiments that made use of the protocol (and literature) and this gives better context and understanding about the protocols...
",gent,https://biology.stackexchange.com/users/6478,http://biology.stackexchange.com/questions/7208/is-there-a-comprehensive-life-science-techniques-methods-database,SCIENCE,biology.stackexchange.com,1.0,0.7777777777777778,0.0,0.6666666666666666,1.0,0.3333333333333333,0.5555555555555556,0.5555555555555556,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.3333333333333333,0.0,1.0,0.7777777777777778,0.6666666666666666,0.8888888888888888,0.7777777777777778,0.6666666666666667,0.0,0.0,0.0,0.7777777777777778,Is there a comprehensive database of life science technology / methods?,"There are so many techniques/methodologies in the life sciences that we can use to interrogate interesting questions. The thing is, most of us are completely unaware of the available methods we can employ. Rather, we go with the techniques we are familiar with or that are popular in our subdomains at the time. But that's pretty limiting.

So I'm wondering... we have databases for everything else... is there one for life sciences techniques/methods? Something like this could be immensely helpful in experimental planning. In particular, I think a comprehensive database would help scientists break outside of their spheres of familiarity and to employ less known (but potentially illuminating) methods to their questions.

I know there are journals that publish protocols and methods, but they are fragmented and don't encompass everything. 

Does what I'm looking for exist? If not, how might one go about creating such a tool? 
","you can use something like https://www.synbiota.com/ where you can store and share your protocols with collaborators. If you make your project open, then anyone in the world can view your protocols.

The nice thing about this is you can reference actual experiments that made use of the protocol (and literature) and this gives better context and understanding about the protocols...
"
3621,3621,5784,Get MS SQL Server to release disk space,"A poorly managed database table has grown to be enormous. 48+gigs of orphan records. I am trying to clean it up and put my dangerously full hard drive back to a normal state. I will be deleting approx 400 million records from this table. This is running as I type. I notice that I am not seeing any drop in my hard drive space but I am seeing the memory drop on system table queries, I am running to get table size. The database is using ""Simple Recovery Model"".

There are many questions similar to this with responses saying you need to shrink the database. But they go on to explain how bad/scary this is to do because of fragmented data etc. 


Since the database should not be this size. Is it still bad for me to shrink it?
This is a production database. If I shrink it will it cause downtime or lock the database?
In SQL Server Management Studio you have two options for shrink, database or files. Given my situation what would be the best option?
is there a rule on the percentage of free space a DB should have?


Even reading the tag description of shrink makes me not want to do it. Is there another way?
",jackncoke,https://dba.stackexchange.com/users/66232,"
  I will be deleting approx 400 million records from this table. 


Hopefully, you are doing it in chunks - to avoid bloating transaction log.


  notice that i am not see any drop in my hard drive space


You wont, as you have to explicitly shrink the database file to release space. Just deleting the records, SQL server wont release the space back to the OS.


  
  Since the database should not be this size. Is it still bad for me to shrink it?
  


It is generally a bad practice as databases should be presized properly. If you are 100% sure that your database is NOT going to be again this size, its OK for you to shrink the database (in your scenario).


  
  This is a production Database. If I shrink it will it cause downtime or lock the database?
  


Shrinking a database is a very IO intensive. Its advisable to shrink using DBCC SHRINKFILE during maintenance window or when there is minimal activity.


  
  In management studio you have two options, Database or Files. Given my situation what would be the best option?
  


You should use TSQL to do the shrink. (since you asked, shrinking FILE is the way to go instead of database). You can use shrink database in chunks - tsql script to do the shrink in chunks.

Remember that when you shrink, you are fragmenting your indexes.


  
  is there a rule on the percentage of free space a DB should have?
  


You can refer to Estimating Disk Space Requirements for Databases article. There is no fix rule, you have to take into account of how your database is expected to grow. You also have to take into account, autogrowth of your databases.

References : Why Does the Transaction Log Keep Growing or Run Out of Space?
",Kin,https://dba.stackexchange.com/users/8783,http://dba.stackexchange.com/questions/101211/get-ms-sql-server-to-release-disk-space,TECHNOLOGY,dba.stackexchange.com,1.0,0.3333333333333333,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.6666666666666666,0.0,1.0,1.0,0.0,0.3333333333333333,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,1.0,1.0,Get MS SQL server to free disk space,"A poorly managed database table has grown to be enormous. 48+gigs of orphan records. I am trying to clean it up and put my dangerously full hard drive back to a normal state. I will be deleting approx 400 million records from this table. This is running as I type. I notice that I am not seeing any drop in my hard drive space but I am seeing the memory drop on system table queries, I am running to get table size. The database is using ""Simple Recovery Model"".

There are many questions similar to this with responses saying you need to shrink the database. But they go on to explain how bad/scary this is to do because of fragmented data etc. 


Since the database should not be this size. Is it still bad for me to shrink it?
This is a production database. If I shrink it will it cause downtime or lock the database?
In SQL Server Management Studio you have two options for shrink, database or files. Given my situation what would be the best option?
is there a rule on the percentage of free space a DB should have?


Even reading the tag description of shrink makes me not want to do it. Is there another way?
","
  I will be deleting approx 400 million records from this table. 


Hopefully, you are doing it in chunks - to avoid bloating transaction log.


  notice that i am not see any drop in my hard drive space


You wont, as you have to explicitly shrink the database file to release space. Just deleting the records, SQL server wont release the space back to the OS.


  
  Since the database should not be this size. Is it still bad for me to shrink it?
  


It is generally a bad practice as databases should be presized properly. If you are 100% sure that your database is NOT going to be again this size, its OK for you to shrink the database (in your scenario).


  
  This is a production Database. If I shrink it will it cause downtime or lock the database?
  


Shrinking a database is a very IO intensive. Its advisable to shrink using DBCC SHRINKFILE during maintenance window or when there is minimal activity.


  
  In management studio you have two options, Database or Files. Given my situation what would be the best option?
  


You should use TSQL to do the shrink. (since you asked, shrinking FILE is the way to go instead of database). You can use shrink database in chunks - tsql script to do the shrink in chunks.

Remember that when you shrink, you are fragmenting your indexes.


  
  is there a rule on the percentage of free space a DB should have?
  


You can refer to Estimating Disk Space Requirements for Databases article. There is no fix rule, you have to take into account of how your database is expected to grow. You also have to take into account, autogrowth of your databases.

References : Why Does the Transaction Log Keep Growing or Run Out of Space?
"
2865,2865,4561,Putting Linux processes on certain CPU cores,"
  Possible Duplicate:
  How can I set the processor affinity of a process on Linux?  




Computer CPUs have many cores insde them nowadays.

I have always wondered if there is a way to, when I start a process on the Linux command line, specify which particular core or cores that process might use?

For example, can I start a massive grep task and say ""use ALL of CPU2 for yourself"".

Or could I start a find task and say ""never leave CPU3"".

Or maybe I could start a video decoding task and say ""use whatever is available on CPU1 and CPU2""

OR, is there no way to do this because it is not needed and the OS is doing this kind of stuff intelligently by itself (based on nice levels and general resource usage of the process etc)

IfyouknowwhatImean
",Daniel,https://unix.stackexchange.com/users/23149,"What you are wondering about is CPU Affinity. I found that there was a good explanation of CPU affinity on NixCraft. But note that the Linux kernel is indeed, as you say, already making intelligent choices.
",drumfire,https://unix.stackexchange.com/users/17448,http://unix.stackexchange.com/questions/47704/putting-linux-processes-on-certain-cpu-cores,TECHNOLOGY,unix.stackexchange.com,0.7777777777777778,0.5555555555555556,0.0,0.3333333333333333,1.0,0.6666666666666666,0.6666666666666666,0.4444444444444444,0.6666666666666666,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,1.0,0.6666666666666666,1.0,0.0,0.7777777777777778,0.6666666666666666,0.4444444444444444,1.0,0.7777777777777778,0.5333333333333333,0.3333333333333333,0.0,0.3333333333333333,1.0,Putting Linux processes on some CPU cores,"
  Possible Duplicate:
  How can I set the processor affinity of a process on Linux?  




Computer CPUs have many cores insde them nowadays.

I have always wondered if there is a way to, when I start a process on the Linux command line, specify which particular core or cores that process might use?

For example, can I start a massive grep task and say ""use ALL of CPU2 for yourself"".

Or could I start a find task and say ""never leave CPU3"".

Or maybe I could start a video decoding task and say ""use whatever is available on CPU1 and CPU2""

OR, is there no way to do this because it is not needed and the OS is doing this kind of stuff intelligently by itself (based on nice levels and general resource usage of the process etc)

IfyouknowwhatImean
","What you are wondering about is CPU Affinity. I found that there was a good explanation of CPU affinity on NixCraft. But note that the Linux kernel is indeed, as you say, already making intelligent choices.
"
4697,4697,7447,Performance of SQL query with condition vs. without where clause,"Which SQL-query will be executed with less time — query with WHERE-clause or without, when:


WHERE-clause deals with indexed field (e.g. primary key field)
WHERE-clause deals with non-indexed field


I suppose when we're working with indexed fields, thus query with WHERE will be faster.
Am I right?

Thanks!
",Mike B.,https://stackoverflow.com/users/462347,"There are cases where a where clause on the primary key will be slower.

The simplest is a table with one row.  Using the index requires loading both the index and the data page -- two reads.  No index cuts the work in half.

That is a degenerate case, but it points to the issue -- the proportion of the rows selected.  Or, more accurately, the proportion of pages needed to resolve the query.

When the desired data is on all pages, then using an index slowed things down.  For a non primary key, this can be disastrous, when the table is bigger than the page cache and the accesses are random.

Since pages are ordered by a primary key, the worst case is an additional index scan -- not too bad.

Some databases use statistics on tables to decide when to use an index and when to do a full table scan.  Some don't.

In short, for low selectivity queries, an index will improve performance.  For high selectivity queries, using an index can result in marginally worse performance or dire performance, depending on various factors.
",Gordon Linoff,https://stackoverflow.com/users/1144035,http://stackoverflow.com/questions/11802884/performance-of-sql-query-with-condition-vs-without-where-clause,STACKOVERFLOW,stackoverflow.com,1.0,0.5555555555555556,0.0,1.0,1.0,1.0,0.4444444444444444,0.4444444444444444,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8888888888888888,1.0,0.7777777777777778,1.0,1.0,1.0,0.0,0.0,0.6666666666666666,0.8888888888888888,Performance comparison of SQL query with and without where clause,"Which SQL-query will be executed with less time — query with WHERE-clause or without, when:


WHERE-clause deals with indexed field (e.g. primary key field)
WHERE-clause deals with non-indexed field


I suppose when we're working with indexed fields, thus query with WHERE will be faster.
Am I right?

Thanks!
","There are cases where a where clause on the primary key will be slower.

The simplest is a table with one row.  Using the index requires loading both the index and the data page -- two reads.  No index cuts the work in half.

That is a degenerate case, but it points to the issue -- the proportion of the rows selected.  Or, more accurately, the proportion of pages needed to resolve the query.

When the desired data is on all pages, then using an index slowed things down.  For a non primary key, this can be disastrous, when the table is bigger than the page cache and the accesses are random.

Since pages are ordered by a primary key, the worst case is an additional index scan -- not too bad.

Some databases use statistics on tables to decide when to use an index and when to do a full table scan.  Some don't.

In short, for low selectivity queries, an index will improve performance.  For high selectivity queries, using an index can result in marginally worse performance or dire performance, depending on various factors.
"
1286,1286,2029,"In a ContentByQueryWebPart, how to generate a link to the item's display form?","I'm building a custom Xsl to customize the rendering of a ContentByQueryWebPart. This webpart is targeting pictures

In the results, I would like to generate a link to the corresponding dispform.aspx, in order to show the details of the target picture.

How can I generate such link ?

By now, I have created this piece of Xsl to generate the link in my custom ItemStyle.xsl :

&lt;xsl:variable name=""DispFormUrl""&gt;
    &lt;xsl:value-of
        disable-output-escaping=""yes"" 
        select=""concat($SiteUrl, '/_layouts/listform.aspx?PageType=4&amp;amp;ListId={',@ListId, '}&amp;amp;ID=', @ID)"" 
    /&gt;
&lt;/xsl:variable&gt;


This is working when I work at the root of the site collection. However, this does not works if the results are from another web within the site collection.

How can I correct my xsl to support any location ?
",Steve B,https://sharepoint.stackexchange.com/users/3497,"In order to provide the link to the picture item instead of picture url, 
I recommend to modify SafeLinkUrl variable in ItemStyle.xsl that is used for Item Url: 

 &lt;xsl:variable name=""SafeLinkUrl""&gt;
            &lt;!--xsl:call-template name=""OuterTemplate.GetSafeLink""&gt;
                &lt;xsl:with-param name=""UrlColumnName"" select=""'LinkUrl'""/&gt;
            &lt;/xsl:call-template--&gt;
            &lt;xsl:value-of select=""concat($RootSiteRef,'/_layouts/CopyUtil.aspx?Use=id&amp;amp;Action=dispform&amp;amp;ItemId=',@ID,'&amp;amp;ListId=',@ListId,'&amp;amp;WebId=',@WebId,'&amp;amp;SiteId=',$SiteId,'&amp;amp;Source=',$Source)""/&gt;
        &lt;/xsl:variable&gt;


CopyUtil.aspx page

CopyUtil.aspx page is an application redirect page intended for redirection to the corresponding item or document.

The following parameters could be passed via URL:


Item ID
List ID
Web ID
Site ID
Source
List item
Action
InThisWeb

",Vadim Gremyachev,https://sharepoint.stackexchange.com/users/10610,http://sharepoint.stackexchange.com/questions/66215/in-a-contentbyquerywebpart-how-to-generate-a-link-to-the-items-display-form,TECHNOLOGY,sharepoint.stackexchange.com,1.0,1.0,0.0,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,1.0,0.8,0.0,0.0,0.0,0.6666666666666666,"In contentbyquerywebpart, how to generate a link to the item's display form?","I'm building a custom Xsl to customize the rendering of a ContentByQueryWebPart. This webpart is targeting pictures

In the results, I would like to generate a link to the corresponding dispform.aspx, in order to show the details of the target picture.

How can I generate such link ?

By now, I have created this piece of Xsl to generate the link in my custom ItemStyle.xsl :

&lt;xsl:variable name=""DispFormUrl""&gt;
    &lt;xsl:value-of
        disable-output-escaping=""yes"" 
        select=""concat($SiteUrl, '/_layouts/listform.aspx?PageType=4&amp;amp;ListId={',@ListId, '}&amp;amp;ID=', @ID)"" 
    /&gt;
&lt;/xsl:variable&gt;


This is working when I work at the root of the site collection. However, this does not works if the results are from another web within the site collection.

How can I correct my xsl to support any location ?
","In order to provide the link to the picture item instead of picture url, 
I recommend to modify SafeLinkUrl variable in ItemStyle.xsl that is used for Item Url: 

 &lt;xsl:variable name=""SafeLinkUrl""&gt;
            &lt;!--xsl:call-template name=""OuterTemplate.GetSafeLink""&gt;
                &lt;xsl:with-param name=""UrlColumnName"" select=""'LinkUrl'""/&gt;
            &lt;/xsl:call-template--&gt;
            &lt;xsl:value-of select=""concat($RootSiteRef,'/_layouts/CopyUtil.aspx?Use=id&amp;amp;Action=dispform&amp;amp;ItemId=',@ID,'&amp;amp;ListId=',@ListId,'&amp;amp;WebId=',@WebId,'&amp;amp;SiteId=',$SiteId,'&amp;amp;Source=',$Source)""/&gt;
        &lt;/xsl:variable&gt;


CopyUtil.aspx page

CopyUtil.aspx page is an application redirect page intended for redirection to the corresponding item or document.

The following parameters could be passed via URL:


Item ID
List ID
Web ID
Site ID
Source
List item
Action
InThisWeb

"
3041,3041,4849,Differences in student load at liberal arts colleges vs. research universities,"Do students at liberal arts universities have 'harder' courses than students at research universities? 

Computer Science curricula at large research universities have 5 to 6 courses per semester. The Liberal Arts model dictates roughly 4 courses per semester. If the load on the student is considered to be equivalent, there must be something special to the teaching in the Liberal Arts model.

How is it that a 4 course Liberal Arts semester is as intensive as a 6 course research university semester?

UPDATE: Many of the comments below say the course load I mention above is inaccurate. I have obtained the figures as follows.


The Liberal Arts Computer Science Consortium (LACS) has released 3 LACS curricula in response to ACM/IEEE CS curriculum recommendations. The first in 1986 in response to the 1978 recommendation, next in 1996 in response to the 1991 recommendation and the most recent in 2007 in response to the 2001 recommendation. The 4 year course breakdown in all the LACS recommendations is roughly the same:

4 courses per semester
30-35% CS courses, 10% math, 5% science, and the rest, i.e. 50% or more courses on arts, humanities and social sciences.

A typical graduation requirement at a research university is at least 120 credits, which comes to 5 3-credit courses per semester. Many require more than 120 so 6 course semesters are not uncommon.

",wsaleem,https://academia.stackexchange.com/users/14572,"As with other commenters, I think the premise here is flawed.

I teach at a public liberal arts college which is typical of many. (Certainly our curriculum and requirements are in line with other schools in the COPLAC Council of Public Liberal Arts Colleges.)

Our students are required to complete 120 credits to graduate, which over four years averages to 15 credits a semester, or five 3-credit courses. I don't believe there is any serious difference in student course load when compared to large research universities (but maybe someone will prove me wrong).

The main distinction about teaching at a liberal arts college is that the overall curriculum is broader, and students do not focus on specialization as much as integration of diverse subject areas. Instead of taking 70 or 80 credits of (say) computer science, our students take only 40-45, with the other two-thirds of their degree consisting of courses in other areas. In this way, students build a broad, integrated perspective which incorporates their major into a study of the world at large. The focus at liberal arts colleges is to help students become better critical thinkers, decision makers, and problem solvers, rather than becoming subject matter experts in a narrow discipline.
",user12565,https://academia.stackexchange.com/users/14596,http://academia.stackexchange.com/questions/19846/differences-in-student-load-at-liberal-arts-colleges-vs-research-universities,LIFE_ARTS,academia.stackexchange.com,1.0,0.3333333333333333,0.0,0.0,1.0,1.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,0.6666666666666666,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,1.0,The difference of student load between liberal arts colleges and Research Universities,"Do students at liberal arts universities have 'harder' courses than students at research universities? 

Computer Science curricula at large research universities have 5 to 6 courses per semester. The Liberal Arts model dictates roughly 4 courses per semester. If the load on the student is considered to be equivalent, there must be something special to the teaching in the Liberal Arts model.

How is it that a 4 course Liberal Arts semester is as intensive as a 6 course research university semester?

UPDATE: Many of the comments below say the course load I mention above is inaccurate. I have obtained the figures as follows.


The Liberal Arts Computer Science Consortium (LACS) has released 3 LACS curricula in response to ACM/IEEE CS curriculum recommendations. The first in 1986 in response to the 1978 recommendation, next in 1996 in response to the 1991 recommendation and the most recent in 2007 in response to the 2001 recommendation. The 4 year course breakdown in all the LACS recommendations is roughly the same:

4 courses per semester
30-35% CS courses, 10% math, 5% science, and the rest, i.e. 50% or more courses on arts, humanities and social sciences.

A typical graduation requirement at a research university is at least 120 credits, which comes to 5 3-credit courses per semester. Many require more than 120 so 6 course semesters are not uncommon.

","As with other commenters, I think the premise here is flawed.

I teach at a public liberal arts college which is typical of many. (Certainly our curriculum and requirements are in line with other schools in the COPLAC Council of Public Liberal Arts Colleges.)

Our students are required to complete 120 credits to graduate, which over four years averages to 15 credits a semester, or five 3-credit courses. I don't believe there is any serious difference in student course load when compared to large research universities (but maybe someone will prove me wrong).

The main distinction about teaching at a liberal arts college is that the overall curriculum is broader, and students do not focus on specialization as much as integration of diverse subject areas. Instead of taking 70 or 80 credits of (say) computer science, our students take only 40-45, with the other two-thirds of their degree consisting of courses in other areas. In this way, students build a broad, integrated perspective which incorporates their major into a study of the world at large. The focus at liberal arts colleges is to help students become better critical thinkers, decision makers, and problem solvers, rather than becoming subject matter experts in a narrow discipline.
"
2782,2782,4431,How do I reset the software Mac OS X Update Server,"I somehow managed to miss configured my mac osx update-server and would like to reset it, the problem is that there is no reset button to put the update-server into it's original inactivated state. 

So does someone here know how to reset the update-server completely without leaving traces from the configurations which have been done before?
",elhombre,https://apple.stackexchange.com/users/2336,"You should be able to control this from the Server Admin application. If it's not obvious from the UI or the help, add a comment here and I'll walk you through the UI steps.
",ohmantics,https://apple.stackexchange.com/users/1812,http://apple.stackexchange.com/questions/6033/how-do-i-reset-the-software-mac-os-x-update-server,TECHNOLOGY,apple.stackexchange.com,0.8888888888888888,0.7777777777777778,0.0,1.0,0.6666666666666666,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.8888888888888888,0.8888888888888888,0.4444444444444444,1.0,1.0,0.7333333333333333,1.0,0.0,0.3333333333333333,1.0,How to reset the Software Mac OS X update server,"Somehow, I managed to miss configuring my Mac OSX update server and wanted to reset it. The problem was that there was no reset button to make the update server go into its original inactive state.","You should be able to control this from the Server Admin application. If it's not obvious from the UI or the help, add a comment here and I'll walk you through the UI steps.
"
85,85,141,Insert a Views Block into a node in Drupal 7,"[Drupal 7] 

I have a block I created in Views called ""handy_tips-block_1"".

Now I want to insert it into the body field of my node.

How do I do this?

I found a guide on here, which suggests to use the following code:

&lt;?php
print $block = module_invoke('views', 'block_view', 'handy_tips-block_1');
print render($block['content']['#content']);
?&gt;


However, all what is printed out are the words ""Array"".
(I have enabled the PHP input filter for the body field).

Note: in the posted code, I have also tried substituting 'views' with various items such as ""block"". I have used 'handy_tips-block_1' as the ID, because that is what is displayed on the configuration link of the block administration page. 
",big_smile,https://drupal.stackexchange.com/users/1606,"My favorite way to embed views in template files is with the views_embed_view() function.

It's really easy to use:

&lt;?php print views_embed_view('view-name', 'display-name','arguments'); ?&gt;



The 'display-name' argument corresponds to the type of display in your view, and the number of those types of there are multiple. So if in your view you created two blocks, you could call one or the other by using 'block-1' or 'block-2' in the 'display-name' argument. 
The third argument, 'arguments', is optional, and can be used to pass any contextual filter arguments your view depends on. 

",PJ McCormick,https://drupal.stackexchange.com/users/6637,http://drupal.stackexchange.com/questions/13297/insert-a-views-block-into-a-node-in-drupal-7,TECHNOLOGY,drupal.stackexchange.com,1.0,0.4444444444444444,0.6666666666666666,0.0,1.0,0.0,0.6666666666666666,1.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,1.0,Inserting a view block into a node in Drupal 7,"[Drupal 7] 

I have a block I created in Views called ""handy_tips-block_1"".

Now I want to insert it into the body field of my node.

How do I do this?

I found a guide on here, which suggests to use the following code:

&lt;?php
print $block = module_invoke('views', 'block_view', 'handy_tips-block_1');
print render($block['content']['#content']);
?&gt;


However, all what is printed out are the words ""Array"".
(I have enabled the PHP input filter for the body field).

Note: in the posted code, I have also tried substituting 'views' with various items such as ""block"". I have used 'handy_tips-block_1' as the ID, because that is what is displayed on the configuration link of the block administration page. 
","My favorite way to embed views in template files is with the views_embed_view() function.

It's really easy to use:

&lt;?php print views_embed_view('view-name', 'display-name','arguments'); ?&gt;



The 'display-name' argument corresponds to the type of display in your view, and the number of those types of there are multiple. So if in your view you created two blocks, you could call one or the other by using 'block-1' or 'block-2' in the 'display-name' argument. 
The third argument, 'arguments', is optional, and can be used to pass any contextual filter arguments your view depends on. 

"
5224,5224,8303,Does Clark Kent have a weight problem?,"This question came to mind while watching an overloaded vehicle tilting down the road ahead of me. Are Kryptonians Height &amp; Weight Proportional (H/W/P) to humans? I'm curious to know if Clark has to fly (hover just a little bit) in order to adjust his weight and level load a cars suspension system so he blends in when he travels with earthlings in automobiles. 
",Major Stackings,https://scifi.stackexchange.com/users/4356,"No, Clark Kent doesn't have a weight problem. But he should. Superman has since the late sixties been portrayed as having the height and weight proportions of a normal human male, despite his superhuman strength. 

DC Comics has not bothered to address this issue with Superman in any of the previous iterations of the Man of Steel. He has almost always been listed around 6 to 6.5 feet tall weighing approximately 225 - 250 pounds, sometimes a bit more.


Scientifically speaking Clark Kent, indeed all Kryptonians should weigh, at least a bit  more, and have a greater molecular weight than normal humans. Coming from a world which was supposedly significantly larger, they would have to have been much stronger to maintain their human-like appearance.
His strength, since the Golden Age has not depended on his arrival from a heavy gravity planet, and in many iterations, Krypton is not even considered a heavy gravity world. In those cases, Superman's superhuman strength is strictly a product of his solar-powered infusion/conversion of energy into superhuman strength and his other powers.
No, this has not been portrayed consistently; particularly during periods where Kal-el might lose his powers or during the period as Superman Blue/Red when he had no superhuman strength at all.
In the Marvel Universe, for example, the Asgardians to partially compensate for their superhuman strength (even a normal Asgardian can lift ten tons) have three times the bone, muscle and overall tissue density of normal humans. Yes, in the case of some Asgardians they have even greater strength, but we assume there is a magical component for those who are lifting far in excess of that.


None of this makes strict sense and with multiple versions of Krypton, Superman, writer and editor inconsistency, it is not surprising the details have gotten lost or glossed over. Just look at the modifications for the planet Krypton over the decades:


  
  Krypton and its history has been altered to a great extent from its previous versions. In the post-Crisis Krypton, sexual reproduction was considered obscene, and thus, all children were conceived in birthing matrices. After Infinite Crisis, this was taken out of Kryptonian culture. 
  Also in post-Crisis Krypton, this planet was located in a solar system within the Milky Way galaxy close enough that the radiation from the explosion (traveling only at light speed) was able to reach Earth (Action #600). 
  But after Superman: Birthright it was suggested that the planet Krypton was from an entirely different galaxy. In current continuity however, Krypton has been revised back to its previous position and is confirmed to be in the sector of space that borders that of Earth.
  The Green Lanterns have dubbed Krypton's sector of space 2813 (Earth's being 2814) and was under the protection of Green Lantern Tomar-Re when it was destroyed. Another element to the previous version of Krypton was that all Kryptonians were unable to leave their planet or they would die instantly. This was a result of the Eradicator altering the genetic codes of Kryptonians to keep them planet-bound after a group of them left Krypton to explore and colonize other planets. The Eradicator punished these Kryptonians by altering their genetic codes to be vulnerable to lead, which resulted in the Daxamites.
  Originally, Jor-El had a serum that he invented that would allow a Kryptonian to leave the planet safely; which he gave to his son Kal-El upon leaving for Earth. This was created to maintain the rule of Superman being the only Kryptonian survivor which was the theme of the post-Crisis Superman mythos. 
  This was reversed after 2003 when it was revealed that Superboy (Conner Kent) was half Kryptonian and then in 2004 when Supergirl (Kara Zor-El) arrived on Earth. The Eradicator did not place the planet-bound restrictions on the Krypton of the current DC universe but it still seems to be responsible for the Daxamites' lead vulnerability.
  The Krypton of the current continuity was at one time an expanding empire that conquered other planets for years but was dismantled after the Kryptonian high council decided that their methods were too aggressive. The city of Kandor had a lunar city named after the planet bound city and when the lunar colony was destroyed, Brainiac kidnapped the real Kandor.
  Other multi-ethnic versions of Kryptonians that resemble African-Americans and Asians also make an appearance in current continuity. Though previously, ""black"" Kryptonians were mainly confined within the Kryptonian continent of Vathlo Island. In the New Earth continuity, dark-skinned Kryptonians are more integrated into Kryptonian society than they were in the silver and pre-modern age DC universe. The other racially diverse people of Krypton came from a continent called Twenx. --Wikipedia > Krypton
  

",Thaddeus Howze,https://scifi.stackexchange.com/users/2765,http://scifi.stackexchange.com/questions/22379/does-clark-kent-have-a-weight-problem,LIFE_ARTS,scifi.stackexchange.com,1.0,0.5555555555555556,0.0,1.0,0.3333333333333333,1.0,0.7777777777777778,0.7777777777777778,0.3333333333333333,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,1.0,0.8888888888888888,1.0,1.0,1.0,0.0,0.0,1.0,1.0,Does Clark Kent have a weight problem?,"When I saw an overloaded vehicle incline on the road in front of me, I thought of this problem. Is krypton's height and weight proportional to human beings? I would like to know if Clark needs to fly (hover a little) to adjust his weight and the horizontal load of the car suspension system so that he can integrate into the car travel with the earth people.","No, Clark Kent doesn't have a weight problem. But he should. Superman has since the late sixties been portrayed as having the height and weight proportions of a normal human male, despite his superhuman strength. 

DC Comics has not bothered to address this issue with Superman in any of the previous iterations of the Man of Steel. He has almost always been listed around 6 to 6.5 feet tall weighing approximately 225 - 250 pounds, sometimes a bit more.


Scientifically speaking Clark Kent, indeed all Kryptonians should weigh, at least a bit  more, and have a greater molecular weight than normal humans. Coming from a world which was supposedly significantly larger, they would have to have been much stronger to maintain their human-like appearance.
His strength, since the Golden Age has not depended on his arrival from a heavy gravity planet, and in many iterations, Krypton is not even considered a heavy gravity world. In those cases, Superman's superhuman strength is strictly a product of his solar-powered infusion/conversion of energy into superhuman strength and his other powers.
No, this has not been portrayed consistently; particularly during periods where Kal-el might lose his powers or during the period as Superman Blue/Red when he had no superhuman strength at all.
In the Marvel Universe, for example, the Asgardians to partially compensate for their superhuman strength (even a normal Asgardian can lift ten tons) have three times the bone, muscle and overall tissue density of normal humans. Yes, in the case of some Asgardians they have even greater strength, but we assume there is a magical component for those who are lifting far in excess of that.


None of this makes strict sense and with multiple versions of Krypton, Superman, writer and editor inconsistency, it is not surprising the details have gotten lost or glossed over. Just look at the modifications for the planet Krypton over the decades:


  
  Krypton and its history has been altered to a great extent from its previous versions. In the post-Crisis Krypton, sexual reproduction was considered obscene, and thus, all children were conceived in birthing matrices. After Infinite Crisis, this was taken out of Kryptonian culture. 
  Also in post-Crisis Krypton, this planet was located in a solar system within the Milky Way galaxy close enough that the radiation from the explosion (traveling only at light speed) was able to reach Earth (Action #600). 
  But after Superman: Birthright it was suggested that the planet Krypton was from an entirely different galaxy. In current continuity however, Krypton has been revised back to its previous position and is confirmed to be in the sector of space that borders that of Earth.
  The Green Lanterns have dubbed Krypton's sector of space 2813 (Earth's being 2814) and was under the protection of Green Lantern Tomar-Re when it was destroyed. Another element to the previous version of Krypton was that all Kryptonians were unable to leave their planet or they would die instantly. This was a result of the Eradicator altering the genetic codes of Kryptonians to keep them planet-bound after a group of them left Krypton to explore and colonize other planets. The Eradicator punished these Kryptonians by altering their genetic codes to be vulnerable to lead, which resulted in the Daxamites.
  Originally, Jor-El had a serum that he invented that would allow a Kryptonian to leave the planet safely; which he gave to his son Kal-El upon leaving for Earth. This was created to maintain the rule of Superman being the only Kryptonian survivor which was the theme of the post-Crisis Superman mythos. 
  This was reversed after 2003 when it was revealed that Superboy (Conner Kent) was half Kryptonian and then in 2004 when Supergirl (Kara Zor-El) arrived on Earth. The Eradicator did not place the planet-bound restrictions on the Krypton of the current DC universe but it still seems to be responsible for the Daxamites' lead vulnerability.
  The Krypton of the current continuity was at one time an expanding empire that conquered other planets for years but was dismantled after the Kryptonian high council decided that their methods were too aggressive. The city of Kandor had a lunar city named after the planet bound city and when the lunar colony was destroyed, Brainiac kidnapped the real Kandor.
  Other multi-ethnic versions of Kryptonians that resemble African-Americans and Asians also make an appearance in current continuity. Though previously, ""black"" Kryptonians were mainly confined within the Kryptonian continent of Vathlo Island. In the New Earth continuity, dark-skinned Kryptonians are more integrated into Kryptonian society than they were in the silver and pre-modern age DC universe. The other racially diverse people of Krypton came from a continent called Twenx. --Wikipedia > Krypton
  

"
2694,2694,4296,How to Enable Ports 25 - 28 on a Cisco Catalyst 3750,"I am trying to enable ports 25 - 28 on my 28 port Catalyst 3750. These four ports are my fiber ports. I am using the following command to bring up that interface.

interface range Gi1/0/25 - 28

That works and it dumps me in the config-if-interface prompt. This is where I get stuck. I just want to enable these four ports and have them be in VLAN1 and On just like ports 1 - 24.

How do I do this?
",Jared Brown,https://serverfault.com/users/99915,"First of all, do a show running-config interface GigabitEthernet 1/0/X and have a look at how those interfaces are actually configured.

Then do what is needed:


If they are in shutdown state, issue a no shutdown command.
If they are not in the right VLAN, issue a switchport access vlan X command.
If they are configured for something else than standard access (i.e. trunking), clear their configuration and reconfigure them.

",Massimo,https://serverfault.com/users/6352,http://serverfault.com/questions/130710,TECHNOLOGY,serverfault.com,0.8888888888888888,0.7777777777777778,0.0,0.3333333333333333,1.0,0.6666666666666666,0.6666666666666666,0.4444444444444444,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.3333333333333333,0.3333333333333333,1.0,How to enable ports 25-28 on Cisco catalyst 3750,"I am trying to enable ports 25 - 28 on my 28 port Catalyst 3750. These four ports are my fiber ports. I am using the following command to bring up that interface.

interface range Gi1/0/25 - 28

That works and it dumps me in the config-if-interface prompt. This is where I get stuck. I just want to enable these four ports and have them be in VLAN1 and On just like ports 1 - 24.

How do I do this?
","First of all, do a show running-config interface GigabitEthernet 1/0/X and have a look at how those interfaces are actually configured.

Then do what is needed:


If they are in shutdown state, issue a no shutdown command.
If they are not in the right VLAN, issue a switchport access vlan X command.
If they are configured for something else than standard access (i.e. trunking), clear their configuration and reconfigure them.

"
16,16,22,Create heatmap with PSTricks or TikZ,"I have a huge amount of 2D-coordinates, associated with a value, e.g.:

  x   |   y   | value
27.50   52.15   12.51
61.83   13.32   57.56
36.23   21.83   41.73
40.46   85.67   25.20
...


The data is not tabular and I Want the points between two data-points to be interpolated in some way (which way is not really clear, yet)

I want to preset the data as heatmap like this:


Is there any ready-to-use package for PSTricks or TikZ to do it?
",user2033412,https://tex.stackexchange.com/users/35228,"There is tikzDevice for R which will generate TikZ code for a plot created in R. So, if you use R to create your heat map (say, using ggplot2's geom_density2d()), you also get the TikZ code with little effort. There is a learning curve, though.

However, this kind of image should be included as a (perhaps high-resolution) raster image in your document, as the vector version might take a long time to render. So you can create a TikZ version of the plot, compile it to PDF and then convert to PNG at the required resolution/pixel density.
",krlmlr,https://tex.stackexchange.com/users/8057,http://tex.stackexchange.com/questions/133882/create-heatmap-with-pstricks-or-tikz,TECHNOLOGY,tex.stackexchange.com,1.0,0.7777777777777778,0.0,1.0,1.0,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.7777777777777778,0.5555555555555556,0.7777777777777778,0.7777777777777778,1.0,0.9333333333333332,1.0,0.0,0.0,1.0,Creating a heat map with pstricks or tikz,"I have a huge amount of 2D-coordinates, associated with a value, e.g.:

  x   |   y   | value
27.50   52.15   12.51
61.83   13.32   57.56
36.23   21.83   41.73
40.46   85.67   25.20
...


The data is not tabular and I Want the points between two data-points to be interpolated in some way (which way is not really clear, yet)

I want to preset the data as heatmap like this:


Is there any ready-to-use package for PSTricks or TikZ to do it?
","There is tikzDevice for R which will generate TikZ code for a plot created in R. So, if you use R to create your heat map (say, using ggplot2's geom_density2d()), you also get the TikZ code with little effort. There is a learning curve, though.

However, this kind of image should be included as a (perhaps high-resolution) raster image in your document, as the vector version might take a long time to render. So you can create a TikZ version of the plot, compile it to PDF and then convert to PNG at the required resolution/pixel density.
"
1661,1661,2627,Why all the dice?,"I'm asking more as an outside observer, and not with anyone who has any grievance with how games are played, nor am I judging or criticizing anything.

I've just always wondered, why use all the different types of dice? Why a 4 sided die for one thing, three 6 sided dice for another, and a twenty sided dice for something else? Couldn't you use, just for example, two 10 sided dice to represent a percentage between 1 and 100 (one die is tens and the other is ones, and they're differentiated by colour), and then use that for all instances?

If you needed to decide something was a one in four possibility, you just declare it a 25% chance, and roll the two tens. No matter what kind of possibility you wanted that are currently represented by various combinations of dice, it seems to me you could represent it within a range of one to one hundred. 

Sure, a bag of all different shaped dice looks kind of cool, but is there a reason for them that goes beyond aesthetics? With just two 10 sided dice (or three if you wanted really fine gradients of percentage) wouldn't that make things simpler and more consistent without losing any of the variety of chances taken?

I thought maybe it had to do with probabilistic outcomes. For instance, if you roll two 6 sided dice, I believe that you're more likely to come up with some combination that adds up to 7 than you are with a combination that adds up to 2 or 12. So there's a bell curve of possible outcomes. Nonetheless, maybe I'm just not well versed enough in probabilities enough to see a difference, but I still think you could get the same equivalent likelihoods of an outcome by using a straight percentage, adjusting up or down depending on what you needed.

Again, I'm not trying to be contrarian, I'm just curious. Is there an objective reason for all the different dice?
",Questioner,https://rpg.stackexchange.com/users/10772,"Short answer: Yes, your hunch is right: because probability curves, and easy access to them. 

Sure, you could calculate (for example by using AnyDice) in advance the percentage chances of rolling a 2, a 3, a 4 etc on a 3d6, but mapping and rolling everything so would get messy and totally inconvenient practically in an instant. You want predictably varying distribution, bell curves, etc, and all this at your fingertips without having to use a calculator or other app.

Also, dice are nice. It's great to roll them. Look, how they twist and spin and decide your fate. :D
",OpaCitiZen,https://rpg.stackexchange.com/users/507,http://rpg.stackexchange.com/questions/45454/why-all-the-dice,CULTURE,rpg.stackexchange.com,1.0,0.7777777777777778,1.0,0.0,1.0,0.0,0.6666666666666666,0.7777777777777778,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.5555555555555556,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,1.0,Why all the dice?,"I'm asking more as an outside observer, and not with anyone who has any grievance with how games are played, nor am I judging or criticizing anything.

I've just always wondered, why use all the different types of dice? Why a 4 sided die for one thing, three 6 sided dice for another, and a twenty sided dice for something else? Couldn't you use, just for example, two 10 sided dice to represent a percentage between 1 and 100 (one die is tens and the other is ones, and they're differentiated by colour), and then use that for all instances?

If you needed to decide something was a one in four possibility, you just declare it a 25% chance, and roll the two tens. No matter what kind of possibility you wanted that are currently represented by various combinations of dice, it seems to me you could represent it within a range of one to one hundred. 

Sure, a bag of all different shaped dice looks kind of cool, but is there a reason for them that goes beyond aesthetics? With just two 10 sided dice (or three if you wanted really fine gradients of percentage) wouldn't that make things simpler and more consistent without losing any of the variety of chances taken?

I thought maybe it had to do with probabilistic outcomes. For instance, if you roll two 6 sided dice, I believe that you're more likely to come up with some combination that adds up to 7 than you are with a combination that adds up to 2 or 12. So there's a bell curve of possible outcomes. Nonetheless, maybe I'm just not well versed enough in probabilities enough to see a difference, but I still think you could get the same equivalent likelihoods of an outcome by using a straight percentage, adjusting up or down depending on what you needed.

Again, I'm not trying to be contrarian, I'm just curious. Is there an objective reason for all the different dice?
","Short answer: Yes, your hunch is right: because probability curves, and easy access to them. 

Sure, you could calculate (for example by using AnyDice) in advance the percentage chances of rolling a 2, a 3, a 4 etc on a 3d6, but mapping and rolling everything so would get messy and totally inconvenient practically in an instant. You want predictably varying distribution, bell curves, etc, and all this at your fingertips without having to use a calculator or other app.

Also, dice are nice. It's great to roll them. Look, how they twist and spin and decide your fate. :D
"
5489,5489,8710,Unreachable IP on local subnet,"I have a network printer at 192.168.2.101 that I can reach just fine with other machines on my network (ping and access the printer web server).  For some reason I can't access the printer from my Ubuntu machine--pings return host unreachable.

I'm running Ubuntu 11.04

ifconfig

eth1      Link encap:Ethernet  HWaddr 38:59:f9:c4:52:a9  
          inet addr:192.168.2.11  Bcast:192.168.2.255  Mask:255.255.255.0
          inet6 addr: fe80::3a59:f9ff:fec4:52a9/64 Scope:Link
          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
          RX packets:167828 errors:0 dropped:0 overruns:0 frame:2000398
          TX packets:116132 errors:16 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:1000 
          RX bytes:213283954 (213.2 MB)  TX bytes:15552076 (15.5 MB)
          Interrupt:16

Edited Oct/20/2011

I've added the requested diagnostics below. Any hints in here?

ip route show

$ ip route show
192.168.2.0/24 dev eth1  proto kernel  scope link  src 192.168.2.11  metric 2 
169.254.0.0/16 dev eth1  scope link  metric 1000 
default via 192.168.2.1 dev eth1  proto static 


traceroute

$ ip route show
192.168.2.0/24 dev eth1  proto kernel  scope link  src 192.168.2.11  metric 2 
169.254.0.0/16 dev eth1  scope link  metric 1000 
default via 192.168.2.1 dev eth1  proto static 


netstat

$ netstat -rn
Kernel IP routing table
Destination     Gateway         Genmask         Flags   MSS Window  irtt Iface
192.168.2.0     0.0.0.0         255.255.255.0   U         0 0          0 eth1
169.254.0.0     0.0.0.0         255.255.0.0     U         0 0          0 eth1
0.0.0.0         192.168.2.1     0.0.0.0         UG        0 0          0 eth1

Edited Nov/2/2011

After a bit more digging it appears this might be an issue with MAC address translation.

arp yeilds

$ arp
Address                  HWtype  HWaddress           Flags Mask            Iface
192.168.2.101                    (incomplete)                              eth1
192.168.2.1              ether   00:17:3f:90:cd:93   C                     eth1


I've tried adding a static entry, per this post Add static ARP entries when network is brought up, but the result is the same.

Any thoughts?
",Jason George,https://askubuntu.com/users/29187,"The output of netstat -rn should show something like:

$ netstat -rn
Kernel IP routing table
Destination     Gateway         Genmask         Flags   MSS Window  irtt Iface
0.0.0.0         192.168.100.1   0.0.0.0         UG        0 0          0 eth0
169.254.0.0     0.0.0.0         255.255.0.0     U         0 0          0 eth0
192.168.100.0   0.0.0.0         255.255.255.0   U         0 0          0 eth0


You should have all 3 lines - a default route, a link local route, and a local subnet route.
",waltinator,https://askubuntu.com/users/25618,http://askubuntu.com/questions/69612/unreachable-ip-on-local-subnet,TECHNOLOGY,askubuntu.com,0.8888888888888888,0.3333333333333333,0.0,0.5,1.0,1.0,0.5555555555555556,0.5555555555555556,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.8,1.0,0.0,0.3333333333333333,0.8888888888888888,IP not accessible on local subnet,"I have a network printer at 192.168.2.101 that I can reach just fine with other machines on my network (ping and access the printer web server).  For some reason I can't access the printer from my Ubuntu machine--pings return host unreachable.

I'm running Ubuntu 11.04

ifconfig

eth1      Link encap:Ethernet  HWaddr 38:59:f9:c4:52:a9  
          inet addr:192.168.2.11  Bcast:192.168.2.255  Mask:255.255.255.0
          inet6 addr: fe80::3a59:f9ff:fec4:52a9/64 Scope:Link
          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
          RX packets:167828 errors:0 dropped:0 overruns:0 frame:2000398
          TX packets:116132 errors:16 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:1000 
          RX bytes:213283954 (213.2 MB)  TX bytes:15552076 (15.5 MB)
          Interrupt:16

Edited Oct/20/2011

I've added the requested diagnostics below. Any hints in here?

ip route show

$ ip route show
192.168.2.0/24 dev eth1  proto kernel  scope link  src 192.168.2.11  metric 2 
169.254.0.0/16 dev eth1  scope link  metric 1000 
default via 192.168.2.1 dev eth1  proto static 


traceroute

$ ip route show
192.168.2.0/24 dev eth1  proto kernel  scope link  src 192.168.2.11  metric 2 
169.254.0.0/16 dev eth1  scope link  metric 1000 
default via 192.168.2.1 dev eth1  proto static 


netstat

$ netstat -rn
Kernel IP routing table
Destination     Gateway         Genmask         Flags   MSS Window  irtt Iface
192.168.2.0     0.0.0.0         255.255.255.0   U         0 0          0 eth1
169.254.0.0     0.0.0.0         255.255.0.0     U         0 0          0 eth1
0.0.0.0         192.168.2.1     0.0.0.0         UG        0 0          0 eth1

Edited Nov/2/2011

After a bit more digging it appears this might be an issue with MAC address translation.

arp yeilds

$ arp
Address                  HWtype  HWaddress           Flags Mask            Iface
192.168.2.101                    (incomplete)                              eth1
192.168.2.1              ether   00:17:3f:90:cd:93   C                     eth1


I've tried adding a static entry, per this post Add static ARP entries when network is brought up, but the result is the same.

Any thoughts?
","The output of netstat -rn should show something like:

$ netstat -rn
Kernel IP routing table
Destination     Gateway         Genmask         Flags   MSS Window  irtt Iface
0.0.0.0         192.168.100.1   0.0.0.0         UG        0 0          0 eth0
169.254.0.0     0.0.0.0         255.255.0.0     U         0 0          0 eth0
192.168.100.0   0.0.0.0         255.255.255.0   U         0 0          0 eth0


You should have all 3 lines - a default route, a link local route, and a local subnet route.
"
685,685,1081,Autohotkey: task to copy from browser and paste on text editor,"I'm trying to build a script that uses both a browser and a texteditor. The workflow I can summarize as follows:


Right click on a video for streaming
Click on the option to copy the redirection link
Switch to a text editor (Slickedit in my case)
Paste the copied link
Go back to the browser and await next command.


I want to automate this with a single key press while I am standing on the link with the mouse. This has been
my attempt:

^+!a::
    Click Right, 392, 64     ;execute in browser
    Click Left, 410, 79      ;
    Send, !{Tab}             ;switch to text editor
    Send, ^V                 ;paste in text editor
    Send, !{Tab}             ;switch back to browser
return


The script isn't working correctly because it appears not to be executing the ^V command.
I suspect it's because it is executing it before Slickedit is even active.  How can I syncronize
these KeyPreses so that they are executed at the right times? Also is there a nicer way for me to
switch to Slickedit without relying on the alt-tab?
",Flethuseo,https://stackoverflow.com/users/487980,"There are a few things you could use to make your script better. WinActivate, clipboard, and improved mouse movement seem to be good ones to add. 

^+!a::
    clipboard =                  ; clears clipboard
    Click Right                  ; execute in browser
    MouseMove, 18, 15, 50, R     ; Moves mouse relative to start location
    Click Left     
    ClipWait, 2                  ; Waits 2 seconds for clipboard to contain something
    WinActivate, Slickedit       ; Switch to text editor
    WinWaitActive, Slickedit
    Send % clipboard             ; paste in text editor
    WinActivate, ahk_class Chrome_WidgetWin_1 ; or your browser of choice
Return


Use the included Window Spy to find the correct Window titles or classes to be used in the WinActivate commands.
",Elliot DeNolf,https://stackoverflow.com/users/1717697,http://stackoverflow.com/questions/19547934/autohotkey-task-to-copy-from-browser-and-paste-on-text-editor,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.3333333333333333,0.0,0.3333333333333333,1.0,0.6666666666666666,0.5555555555555556,0.4444444444444444,1.0,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.7,1.0,0.3333333333333333,0.3333333333333333,0.7777777777777778,Auto hotkeys: tasks copied and pasted from the browser to the text editor,"I'm trying to build a script that uses both a browser and a texteditor. The workflow I can summarize as follows:


Right click on a video for streaming
Click on the option to copy the redirection link
Switch to a text editor (Slickedit in my case)
Paste the copied link
Go back to the browser and await next command.


I want to automate this with a single key press while I am standing on the link with the mouse. This has been
my attempt:

^+!a::
    Click Right, 392, 64     ;execute in browser
    Click Left, 410, 79      ;
    Send, !{Tab}             ;switch to text editor
    Send, ^V                 ;paste in text editor
    Send, !{Tab}             ;switch back to browser
return


The script isn't working correctly because it appears not to be executing the ^V command.
I suspect it's because it is executing it before Slickedit is even active.  How can I syncronize
these KeyPreses so that they are executed at the right times? Also is there a nicer way for me to
switch to Slickedit without relying on the alt-tab?
","There are a few things you could use to make your script better. WinActivate, clipboard, and improved mouse movement seem to be good ones to add. 

^+!a::
    clipboard =                  ; clears clipboard
    Click Right                  ; execute in browser
    MouseMove, 18, 15, 50, R     ; Moves mouse relative to start location
    Click Left     
    ClipWait, 2                  ; Waits 2 seconds for clipboard to contain something
    WinActivate, Slickedit       ; Switch to text editor
    WinWaitActive, Slickedit
    Send % clipboard             ; paste in text editor
    WinActivate, ahk_class Chrome_WidgetWin_1 ; or your browser of choice
Return


Use the included Window Spy to find the correct Window titles or classes to be used in the WinActivate commands.
"
473,473,737,What are lightbox / modal window UI best practices for viewing full-sized images in a gallery?,"I'm an artist and amateur web designer.

On my portfolio website, I've grouped my work into projects. Most of my projects contain few (20 or less) images, so I just display them in full size and let the visitor scroll (example) because this is how I prefer to browse other artist's work as well.

For projects containing more images, I use thumbnails which link to the full-sized images, because, again, when I browse other artist's portfolios, if there are lots of images on a page it's kinda cumbersome to load. 

Recently I wrote some jQuery to implement a lightbox effect (modal window overlay) so when you click on a thumbnail, the full-sized image appears (example).

My main reasons for implementing this:


it's much more presentable than having a direct link to the image,
which is what I used to do
if the visitor shares the image on something like tumblr or
Pinterest, the link back will be to the project page instead of a
direct link to the image
if the visitor wants to right-click on the thumbnails to load several
images in several new browser tabs/windows, they can still do so (the
lightbox is triggered on left click)


I did not include a close button because it seems like more work for the visitor to have to look for a close button, than to simply click anywhere to close the lightbox (which is what I did).

What are your thoughts regarding lightbox interface for this particular use?
The goal would be the best way to showcase visual art/design work, and the target audience would be, well, anyone who wants to view the work. The display method, in this case a lightbox interface, should be efficient, useable, and presentable (it should highlight, not detract from, the work).
",Feanne,https://ux.stackexchange.com/users/13655,"One important point is keyboard accessibility: Let the user browse with the ← and → buttons, and make esc work as close button. You may offer further details when the user presses ↑ … but that requires probably some hints.
Mouse users need clickable buttons to navigate images and to close the active one. These buttons can be hidden when the cursor is not over the image, but they should be available.
",fuxia,https://ux.stackexchange.com/users/193,http://ux.stackexchange.com/questions/19527/what-are-lightbox-modal-window-ui-best-practices-for-viewing-full-sized-images,TECHNOLOGY,ux.stackexchange.com,1.0,0.6666666666666666,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,1.0,0.8888888888888888,0.6666666666666666,1.0,1.0,0.7,1.0,0.3333333333333333,0.6666666666666666,1.0,What are the Lightbox / modal window UI best practices for viewing full-size images in the library?,"I'm an artist and amateur web designer.

On my portfolio website, I've grouped my work into projects. Most of my projects contain few (20 or less) images, so I just display them in full size and let the visitor scroll (example) because this is how I prefer to browse other artist's work as well.

For projects containing more images, I use thumbnails which link to the full-sized images, because, again, when I browse other artist's portfolios, if there are lots of images on a page it's kinda cumbersome to load. 

Recently I wrote some jQuery to implement a lightbox effect (modal window overlay) so when you click on a thumbnail, the full-sized image appears (example).

My main reasons for implementing this:


it's much more presentable than having a direct link to the image,
which is what I used to do
if the visitor shares the image on something like tumblr or
Pinterest, the link back will be to the project page instead of a
direct link to the image
if the visitor wants to right-click on the thumbnails to load several
images in several new browser tabs/windows, they can still do so (the
lightbox is triggered on left click)


I did not include a close button because it seems like more work for the visitor to have to look for a close button, than to simply click anywhere to close the lightbox (which is what I did).

What are your thoughts regarding lightbox interface for this particular use?
The goal would be the best way to showcase visual art/design work, and the target audience would be, well, anyone who wants to view the work. The display method, in this case a lightbox interface, should be efficient, useable, and presentable (it should highlight, not detract from, the work).
","One important point is keyboard accessibility: Let the user browse with the ← and → buttons, and make esc work as close button. You may offer further details when the user presses ↑ … but that requires probably some hints.
Mouse users need clickable buttons to navigate images and to close the active one. These buttons can be hidden when the cursor is not over the image, but they should be available.
"
5117,5117,8137,Ethical Disclosure of Professional Knowledge in PhD Dissertation,"I have just completed my PhD. Although my examiners did not raise any concerns, I have been grappling with an ethical issue for the entire duration of my candidature. 

The issue concerns professional knowledge of the field on which my research is based. This is an issue of concern because I am employed in the field and have access to information that is generally not publicly available (but is available to me as an employee) or only found in hard-to-get industry publications (e.g. newsletters). These publications are hard-to-get because of their specialised nature and limited circulation. 

Disclosing this information creates a potential conflict of interest for me (because of reasons associated with commercial-in-confidence, breach of trust etc.). It gets even worse because I am often actively involved in generating this information as part of various negotiations I am required to have with third parties (in my capacity as an employee). As an example, I draft policy speeches for my CEO so this has the effect of quoting my own work in my dissertation (but attributed to my CEO in the citation and bibliography!)  

To resolve this matter, I have declared (categorically) this conflict of interest (several times in my dissertation) (although I don't identify myself as the ghost writer). I have also put whatever information I thought could be ethically disclosed in the relevant context (e.g. cited the publicly available newsletter, where possible). This was to ensure future researchers could benefit from this 'inside' knowledge. I have stated this as one of the contributions to knowledge that my dissertation is making.

I must add that the professional knowledge does not contradict or undermine my research, so I am certainly not withholding the information for this reason. On the contrary, this information enhances the main arguments of my study (so omitting it presents a significant dilemma for me).

i would love to hear how else could this matter be resolved.
",Javeer Baker,https://academia.stackexchange.com/users/4475,"And, as a small point, if one's work is confidential for the reason that it is so extremely useful/important/wonderful (!?!), while one cannot claim this directly, it is usually possible to communicate facts about the situation in a way that will be understood by potential employers. One's letter writers would hopefully/presumably comment on the situation, and possibly gossip will lead the way, besides, if it's really something good.

At least as a starting point, honesty + keeping promises is a good baseline. :)
",paul garrett,https://academia.stackexchange.com/users/980,http://academia.stackexchange.com/questions/6001/ethical-disclosure-of-professional-knowledge-in-phd-dissertation,LIFE_ARTS,academia.stackexchange.com,0.8888888888888888,0.4444444444444444,0.6666666666666666,0.5,0.0,0.0,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,1.0,0.6666666666666666,0.4444444444444444,0.8888888888888888,0.6666666666666666,0.6,0.0,0.0,1.0,0.8888888888888888,Ethical disclosure of professional knowledge of doctoral dissertation,"I have just completed my PhD. Although my examiners did not raise any concerns, I have been grappling with an ethical issue for the entire duration of my candidature. 

The issue concerns professional knowledge of the field on which my research is based. This is an issue of concern because I am employed in the field and have access to information that is generally not publicly available (but is available to me as an employee) or only found in hard-to-get industry publications (e.g. newsletters). These publications are hard-to-get because of their specialised nature and limited circulation. 

Disclosing this information creates a potential conflict of interest for me (because of reasons associated with commercial-in-confidence, breach of trust etc.). It gets even worse because I am often actively involved in generating this information as part of various negotiations I am required to have with third parties (in my capacity as an employee). As an example, I draft policy speeches for my CEO so this has the effect of quoting my own work in my dissertation (but attributed to my CEO in the citation and bibliography!)  

To resolve this matter, I have declared (categorically) this conflict of interest (several times in my dissertation) (although I don't identify myself as the ghost writer). I have also put whatever information I thought could be ethically disclosed in the relevant context (e.g. cited the publicly available newsletter, where possible). This was to ensure future researchers could benefit from this 'inside' knowledge. I have stated this as one of the contributions to knowledge that my dissertation is making.

I must add that the professional knowledge does not contradict or undermine my research, so I am certainly not withholding the information for this reason. On the contrary, this information enhances the main arguments of my study (so omitting it presents a significant dilemma for me).

i would love to hear how else could this matter be resolved.
","Also, as a small problem, if a person's work is confidential, because it is so useful / important / wonderful (! ?!) although people can't claim this directly, they can usually convey the facts of the situation in a way that potential employers can understand. The writer hopes / probably will comment on this situation, and if it's really a good thing, gossip may take the lead."
5891,5891,9332,Unreachable IP on local subnet,"I have a network printer at 192.168.2.101 that I can reach just fine with other machines on my network (ping and access the printer web server).  For some reason I can't access the printer from my Ubuntu machine--pings return host unreachable.

I'm running Ubuntu 11.04

ifconfig

eth1      Link encap:Ethernet  HWaddr 38:59:f9:c4:52:a9  
          inet addr:192.168.2.11  Bcast:192.168.2.255  Mask:255.255.255.0
          inet6 addr: fe80::3a59:f9ff:fec4:52a9/64 Scope:Link
          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
          RX packets:167828 errors:0 dropped:0 overruns:0 frame:2000398
          TX packets:116132 errors:16 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:1000 
          RX bytes:213283954 (213.2 MB)  TX bytes:15552076 (15.5 MB)
          Interrupt:16

Edited Oct/20/2011

I've added the requested diagnostics below. Any hints in here?

ip route show

$ ip route show
192.168.2.0/24 dev eth1  proto kernel  scope link  src 192.168.2.11  metric 2 
169.254.0.0/16 dev eth1  scope link  metric 1000 
default via 192.168.2.1 dev eth1  proto static 


traceroute

$ ip route show
192.168.2.0/24 dev eth1  proto kernel  scope link  src 192.168.2.11  metric 2 
169.254.0.0/16 dev eth1  scope link  metric 1000 
default via 192.168.2.1 dev eth1  proto static 


netstat

$ netstat -rn
Kernel IP routing table
Destination     Gateway         Genmask         Flags   MSS Window  irtt Iface
192.168.2.0     0.0.0.0         255.255.255.0   U         0 0          0 eth1
169.254.0.0     0.0.0.0         255.255.0.0     U         0 0          0 eth1
0.0.0.0         192.168.2.1     0.0.0.0         UG        0 0          0 eth1

Edited Nov/2/2011

After a bit more digging it appears this might be an issue with MAC address translation.

arp yeilds

$ arp
Address                  HWtype  HWaddress           Flags Mask            Iface
192.168.2.101                    (incomplete)                              eth1
192.168.2.1              ether   00:17:3f:90:cd:93   C                     eth1


I've tried adding a static entry, per this post Add static ARP entries when network is brought up, but the result is the same.

Any thoughts?
",Jason George,https://askubuntu.com/users/29187,"I have the same problem today. Check the mac address of your Ubuntu machine and printer, they have a same mac address, so change your Ubuntu mac address to fix this problem.
",BeanYoung,https://askubuntu.com/users/51202,http://askubuntu.com/questions/69612/unreachable-ip-on-local-subnet,TECHNOLOGY,askubuntu.com,1.0,0.3333333333333333,0.0,0.6666666666666666,0.3333333333333333,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.3333333333333333,0.8888888888888888,IP not accessible on local subnet,"I have a network printer at 192.168.2.101 that I can reach just fine with other machines on my network (ping and access the printer web server).  For some reason I can't access the printer from my Ubuntu machine--pings return host unreachable.

I'm running Ubuntu 11.04

ifconfig

eth1      Link encap:Ethernet  HWaddr 38:59:f9:c4:52:a9  
          inet addr:192.168.2.11  Bcast:192.168.2.255  Mask:255.255.255.0
          inet6 addr: fe80::3a59:f9ff:fec4:52a9/64 Scope:Link
          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
          RX packets:167828 errors:0 dropped:0 overruns:0 frame:2000398
          TX packets:116132 errors:16 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:1000 
          RX bytes:213283954 (213.2 MB)  TX bytes:15552076 (15.5 MB)
          Interrupt:16

Edited Oct/20/2011

I've added the requested diagnostics below. Any hints in here?

ip route show

$ ip route show
192.168.2.0/24 dev eth1  proto kernel  scope link  src 192.168.2.11  metric 2 
169.254.0.0/16 dev eth1  scope link  metric 1000 
default via 192.168.2.1 dev eth1  proto static 


traceroute

$ ip route show
192.168.2.0/24 dev eth1  proto kernel  scope link  src 192.168.2.11  metric 2 
169.254.0.0/16 dev eth1  scope link  metric 1000 
default via 192.168.2.1 dev eth1  proto static 


netstat

$ netstat -rn
Kernel IP routing table
Destination     Gateway         Genmask         Flags   MSS Window  irtt Iface
192.168.2.0     0.0.0.0         255.255.255.0   U         0 0          0 eth1
169.254.0.0     0.0.0.0         255.255.0.0     U         0 0          0 eth1
0.0.0.0         192.168.2.1     0.0.0.0         UG        0 0          0 eth1

Edited Nov/2/2011

After a bit more digging it appears this might be an issue with MAC address translation.

arp yeilds

$ arp
Address                  HWtype  HWaddress           Flags Mask            Iface
192.168.2.101                    (incomplete)                              eth1
192.168.2.1              ether   00:17:3f:90:cd:93   C                     eth1


I've tried adding a static entry, per this post Add static ARP entries when network is brought up, but the result is the same.

Any thoughts?
","I have the same problem today. Check the MAC address of your Ubuntu machine and printer, they have the same MAC address, so change your Ubuntu MAC address to solve this problem."
585,585,912,xeCJK and paragraph indentation,"I am using xelatex and want to use the xeCJK package, but without indenting the first paragraph of a section. I tried the setup directive below, which should do the trick. But it does not. The manual is in Chinese ...

\documentclass{article}


\usepackage{xeCJK}
\setCJKmainfont{SimSun}
\xeCJKsetup{indentfirst=false}


\begin{document}

\section{Section 1}

I want to have a paragrpah without indentation.

This one should be indented.

\subsection{Section 2}

Same here.

This one should be indented.


\end{document} 

",Stefan Müller,https://tex.stackexchange.com/users/18561,"In the log file you find this warning:

*************************************************
* xeCJK warning: ""option-invalid""
* 
* The `indentfirst' option only can be set in the optional argument to the
* \usepackage command when xeCJK is being loaded.
* 
* Please do not set it via the \xeCJKsetup command.
*************************************************


which is self-explanatory: do

\usepackage[indentfirst=false]{xeCJK}


Be warned that languages loaded with Polyglossia may revert the setting (Italian, for instance).
",egreg,https://tex.stackexchange.com/users/4427,http://tex.stackexchange.com/questions/98469/xecjk-and-paragraph-indentation,TECHNOLOGY,tex.stackexchange.com,1.0,0.3333333333333333,0.0,1.0,1.0,1.0,0.5,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.5,0.0,0.8333333333333334,1.0,0.6666666666666666,1.0,1.0,0.9,1.0,0.0,0.5,1.0,Xecjk and paragraph indent,"I am using xelatex and want to use the xeCJK package, but without indenting the first paragraph of a section. I tried the setup directive below, which should do the trick. But it does not. The manual is in Chinese ...

\documentclass{article}


\usepackage{xeCJK}
\setCJKmainfont{SimSun}
\xeCJKsetup{indentfirst=false}


\begin{document}

\section{Section 1}

I want to have a paragrpah without indentation.

This one should be indented.

\subsection{Section 2}

Same here.

This one should be indented.


\end{document} 

","In the log file you find this warning:

*************************************************
* xeCJK warning: ""option-invalid""
* 
* The `indentfirst' option only can be set in the optional argument to the
* \usepackage command when xeCJK is being loaded.
* 
* Please do not set it via the \xeCJKsetup command.
*************************************************


which is self-explanatory: do

\usepackage[indentfirst=false]{xeCJK}


Be warned that languages loaded with Polyglossia may revert the setting (Italian, for instance).
"
3341,3341,5332,"Can the word ""facet"" be used in a sentence like this one?","
  
  Leadership skills are also a valued facet in a friend. 
  


Can facet be used in this way?
",Kaylin Brantley,https://english.stackexchange.com/users/88870,"A facet is usually one aspect or 'face' of something. We usually talk about a facet of something. Probably because a facet of something is literally one 'face' of it, we don't about facets in things - think of a diamond with many facets. The facets are the flat surfaces or faces on the diamond.

We often talk about facets of jobs, problems and even people's characters, but we don't talk about people themselves having facets. Your sentence, nonetheless, sounds strangely correct as well as definitely wrong. I think this is because the word facet rhymes with the word asset, which would be perfect in your sentence:


  Leadership skills are also a valued asset in a friend. 


Valuable asset is a very common collocation in English. Asset, as I'm sure you know, means a beneficial or useful thing. Here's the definition from Oxford Dictionaries Online:


  NOUN 1. 
  A useful or valuable thing or person:
  
  
  quick reflexes were his chief assets
  the school is an asset to the community
  


In case you're interested in the etymology of facet, here is the entry from the Online Etymology Dictionary:


  facet (n.)
  1620s, from French facette (12c., Old French facete), diminutive of face (see face (n.)). The diamond-cutting sense is the original one. Related: Faceted; facets. 

",Araucaria,https://english.stackexchange.com/users/76472,http://english.stackexchange.com/questions/192473/can-the-word-facet-be-used-in-a-sentence-like-this-one,CULTURE,english.stackexchange.com,1.0,0.3333333333333333,0.0,1.0,1.0,1.0,0.5555555555555556,0.8888888888888888,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.6666666666666666,0.0,0.7777777777777778,0.7777777777777778,1.0,0.6666666666666666,1.0,0.9333333333333332,0.0,0.0,1.0,0.7777777777777778,"Can the word ""facet"" be used in such a sentence?",Leadership is also an important aspect of friends.,"A facet is usually one aspect or 'face' of something. We usually talk about a facet of something. Probably because a facet of something is literally one 'face' of it, we don't about facets in things - think of a diamond with many facets. The facets are the flat surfaces or faces on the diamond.

We often talk about facets of jobs, problems and even people's characters, but we don't talk about people themselves having facets. Your sentence, nonetheless, sounds strangely correct as well as definitely wrong. I think this is because the word facet rhymes with the word asset, which would be perfect in your sentence:


  Leadership skills are also a valued asset in a friend. 


Valuable asset is a very common collocation in English. Asset, as I'm sure you know, means a beneficial or useful thing. Here's the definition from Oxford Dictionaries Online:


  NOUN 1. 
  A useful or valuable thing or person:
  
  
  quick reflexes were his chief assets
  the school is an asset to the community
  


In case you're interested in the etymology of facet, here is the entry from the Online Etymology Dictionary:


  facet (n.)
  1620s, from French facette (12c., Old French facete), diminutive of face (see face (n.)). The diamond-cutting sense is the original one. Related: Faceted; facets. 

"
763,763,1206,"Are there English equivalents to the Japanese saying, “There’s a god who puts you down as well as a god who picks you up”?","There is an old Japanese saying, “捨てる神あれば、拾う神あり-Suterukami areba hirou kami ari,” meaning “There’s a god who puts you down as well as a god who picks up you.” In other words, “In this world, some people help you, and some people harm you” or “Fortune and misfortune come alternately.”

For example, when you are fired from an IT company, and then hired by its rival company with a higher salary three months later, your peers will say to you “You're a lucky man. There’s a god who throws you away as well as a god who picks you up.”

I’m curious to know if there are similar sayings in English to “Suterukami areba hirou kami ari.” 
",Yoichi Oishi,https://english.stackexchange.com/users/3119,"Sometimes You Eat The Bear, Sometimes The Bear Eats You

(The quote from one great movie to lighten down this solemn thread.)
",oakad,https://english.stackexchange.com/users/55040,http://english.stackexchange.com/questions/169134/are-there-english-equivalents-to-the-japanese-saying-there-s-a-god-who-puts-yo,CULTURE,english.stackexchange.com,1.0,0.8888888888888888,0.0,1.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.7777777777777778,0.0,0.0,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.7777777777777778,0.4444444444444444,0.7777777777777778,0.7777777777777778,0.6,0.0,0.0,0.3333333333333333,0.6666666666666666,"Is there a saying similar to Japanese in English that ""some god put you down and some god picked you up""?","There is an old Japanese saying, “捨てる神あれば、拾う神あり-Suterukami areba hirou kami ari,” meaning “There’s a god who puts you down as well as a god who picks up you.” In other words, “In this world, some people help you, and some people harm you” or “Fortune and misfortune come alternately.”

For example, when you are fired from an IT company, and then hired by its rival company with a higher salary three months later, your peers will say to you “You're a lucky man. There’s a god who throws you away as well as a god who picks you up.”

I’m curious to know if there are similar sayings in English to “Suterukami areba hirou kami ari.” 
","Sometimes You Eat The Bear, Sometimes The Bear Eats You

(The quote from one great movie to lighten down this solemn thread.)
"
2474,2474,3942,How to solve this stochastic integrals?,"how can I solve these two stochastic integrals? 

$$\int_0^T B_t\,dB_t$$
$$\int_0^T f(B_t)\,dB_t$$

where B_t is the BM. 

Thank you very very much!
",Jorko,https://math.stackexchange.com/users/80606,"Since by Ito's lemma you have for $\phi(t,x) \in \mathcal C ^{1,2}$

$$ \phi(t, X_t) = \phi(o,X_0) + \int _0 ^t (\partial_t +b\partial_x +\frac{\sigma^2}{2}\partial^2_{xx})\phi(s,X_s) ~ ds + \int_0^t\partial_x\phi(s,X_s) ~dB_s$$
 if $X$ is a Ito's diffusion

$$ X_t = X_0 + \int _0 ^t b~ ds + \int_0^t\sigma ~dB_s$$

you must search for the simples $\phi$ such that $\partial_x \phi =x $ with $X =B$ ( so $b=0$ and $\sigma =1$) for the first integral and  $\partial_x \phi =f $ for the second one also with $X =B$ .

Indeed, 
$$ \int_0^T B_s ~dB_s=\frac{1}{2}(B^2_T-B^2_0 -T)$$
and 
$$ \int_0^T f(B_s) ~dB_s=F(B_T)-F(B_0) -\frac{1}{2}\int_0^T\partial_x f (B_s) ~ds$$

where $F$ is a primitive of $f$.
",Paul,https://math.stackexchange.com/users/32125,http://math.stackexchange.com/questions/408918/how-to-solve-this-stochastic-integrals,SCIENCE,math.stackexchange.com,0.7777777777777778,0.4444444444444444,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.9,1.0,0.0,0.3333333333333333,0.8888888888888888,How to solve this random integral?,"how can I solve these two stochastic integrals? 

$$\int_0^T B_t\,dB_t$$
$$\int_0^T f(B_t)\,dB_t$$

where B_t is the BM. 

Thank you very very much!
","Since by Ito's lemma you have for $\phi(t,x) \in \mathcal C ^{1,2}$

$$ \phi(t, X_t) = \phi(o,X_0) + \int _0 ^t (\partial_t +b\partial_x +\frac{\sigma^2}{2}\partial^2_{xx})\phi(s,X_s) ~ ds + \int_0^t\partial_x\phi(s,X_s) ~dB_s$$
 if $X$ is a Ito's diffusion

$$ X_t = X_0 + \int _0 ^t b~ ds + \int_0^t\sigma ~dB_s$$

you must search for the simples $\phi$ such that $\partial_x \phi =x $ with $X =B$ ( so $b=0$ and $\sigma =1$) for the first integral and  $\partial_x \phi =f $ for the second one also with $X =B$ .

Indeed, 
$$ \int_0^T B_s ~dB_s=\frac{1}{2}(B^2_T-B^2_0 -T)$$
and 
$$ \int_0^T f(B_s) ~dB_s=F(B_T)-F(B_0) -\frac{1}{2}\int_0^T\partial_x f (B_s) ~ds$$

where $F$ is a primitive of $f$.
"
4367,4367,6946,How to calculate the size of the image circle at infinity focus?,"How can I determine the diameter of the image circle (i.e. the diagonal size of CCD required to fully utilise a telescope's optics) at near-infinity focus? I have looked around online and found this calculator, but I am more interested in how the figure was calculated than knowing the figure itself. 

Background: I am new to astrophotography and recently bought a Celestron Nexstar 130 SLT telescope with a Barlow lens, T-adaptor and T-ring to connect it with my Nikon D80 to take photographs of the night sky in prime focus. The telescope dimensions are 130mm aperture and 650mm focal length. With the 2x Barlow lens (required to diverge the focus enough to mount the camera outside the optical tube assembly) it effectively becomes a telescope with 1300mm focal length. I can measure a picture of an object with known angular size (e.g. the moon) and use crop factors to establish a ratio, but this method doesn't help me understand how a bigger/newer telescope would fare on the same CCD. 

Edit:
Since this question now has a bounty, I would like to emphasize the real question is How to calculate the size of the image circle at infinity focus?, and not the follow-up question of 
Would the image circle size decrease if I was able to ditch the Barlow lens?
",Jono,https://photo.stackexchange.com/users/13946,"You can think of a lens focused at inifinity as simply a pinhole for the purpose of figuring out what gets projected where.  Consider this simplified diagram of a camera:



The box is the camera, the fat line on the left the image plane (where the sensor or film is), and the small hole at right represents the effective point thru which the lens projects the outside view onto the image plane.  In this drawing, F is the focal length and S is the size of some projection onto the image plane.  From basic high school geometry, the tangent of the view angle is S/F:

&nbsp;&nbsp;tan(Ang) = S/F

Therefore obviously

&nbsp;&nbsp;Ang = arctan(S/F)

Yes, it really is that simple.  You didn't say how big the sensor is in your camera, so I'll use a 35mm frame, which is 36x24mm.  The largest circle it can fit is therefore 24mm in diameter or 12mm in radius.  You say your final effective focal length is 1300mm.  Arctan(12mm/1300mm) = 0.529&deg;.  That was the angle from the center to the edge, so double that to make the total view angle of the largest circle on your sensor, which is 1.06&deg;.

To put this in perspective, the view angle of the moon is about 0.5&deg; (it varies, but this is within its variation).  That means for a 1300mm lens and a ""35mm"" sensor, the moon will fill about half the height of the image.

For a cropped sensor, it would appear bigger.  Actually, the projection of the moon onto the sensor is the same regardless of how big the sensor is, but for a smaller sensor it takes up a proportionately bigger portion of the frame.  This would be reflected in the equations above in that the 12mm value would be smaller, since this was the radius of the largest circle that could fit into the sensor frame.

Also note that the simplified geometry of a camera diagrammed above works for the effective focal length.  This will be the actual focal length when the lens is focused at infinity, but can be different when the lens is focused close, depending on the lens design.  However, you are asking about astrophotography, so the focus will always be at infinity and I won't go into that further.
",Olin Lathrop,https://photo.stackexchange.com/users/7603,http://photo.stackexchange.com/questions/30365/how-to-calculate-the-size-of-the-image-circle-at-infinity-focus,LIFE_ARTS,photo.stackexchange.com,1.0,0.5555555555555556,0.0,1.0,1.0,1.0,0.7777777777777778,0.3333333333333333,0.6666666666666666,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.6666666666666666,0.8888888888888888,How to calculate the size of image circle under infinite focal length?,"How can I determine the diameter of the image circle (i.e. the diagonal size of CCD required to fully utilise a telescope's optics) at near-infinity focus? I have looked around online and found this calculator, but I am more interested in how the figure was calculated than knowing the figure itself. 

Background: I am new to astrophotography and recently bought a Celestron Nexstar 130 SLT telescope with a Barlow lens, T-adaptor and T-ring to connect it with my Nikon D80 to take photographs of the night sky in prime focus. The telescope dimensions are 130mm aperture and 650mm focal length. With the 2x Barlow lens (required to diverge the focus enough to mount the camera outside the optical tube assembly) it effectively becomes a telescope with 1300mm focal length. I can measure a picture of an object with known angular size (e.g. the moon) and use crop factors to establish a ratio, but this method doesn't help me understand how a bigger/newer telescope would fare on the same CCD. 

Edit:
Since this question now has a bounty, I would like to emphasize the real question is How to calculate the size of the image circle at infinity focus?, and not the follow-up question of 
Would the image circle size decrease if I was able to ditch the Barlow lens?
","You can think of a lens focused at inifinity as simply a pinhole for the purpose of figuring out what gets projected where.  Consider this simplified diagram of a camera:



The box is the camera, the fat line on the left the image plane (where the sensor or film is), and the small hole at right represents the effective point thru which the lens projects the outside view onto the image plane.  In this drawing, F is the focal length and S is the size of some projection onto the image plane.  From basic high school geometry, the tangent of the view angle is S/F:

&nbsp;&nbsp;tan(Ang) = S/F

Therefore obviously

&nbsp;&nbsp;Ang = arctan(S/F)

Yes, it really is that simple.  You didn't say how big the sensor is in your camera, so I'll use a 35mm frame, which is 36x24mm.  The largest circle it can fit is therefore 24mm in diameter or 12mm in radius.  You say your final effective focal length is 1300mm.  Arctan(12mm/1300mm) = 0.529&deg;.  That was the angle from the center to the edge, so double that to make the total view angle of the largest circle on your sensor, which is 1.06&deg;.

To put this in perspective, the view angle of the moon is about 0.5&deg; (it varies, but this is within its variation).  That means for a 1300mm lens and a ""35mm"" sensor, the moon will fill about half the height of the image.

For a cropped sensor, it would appear bigger.  Actually, the projection of the moon onto the sensor is the same regardless of how big the sensor is, but for a smaller sensor it takes up a proportionately bigger portion of the frame.  This would be reflected in the equations above in that the 12mm value would be smaller, since this was the radius of the largest circle that could fit into the sensor frame.

Also note that the simplified geometry of a camera diagrammed above works for the effective focal length.  This will be the actual focal length when the lens is focused at infinity, but can be different when the lens is focused close, depending on the lens design.  However, you are asking about astrophotography, so the focus will always be at infinity and I won't go into that further.
"
916,916,1452,Most effective way to increase programmer salary besides just doing your job?,"If you have the time and resources, what would be the most effective way to increase your salary as a full-time programmer, outside of just doing your job? 

By ""salary"" here, I mean salary (adjusted for location cost-of-living) coming from a single programming job. 
",T. Webster,https://programmers.stackexchange.com/users/19936,"There is a ceiling that most companies are not willing to go beyond for a straight programmer. You have to take on management/leadership roles if you want to pass that ceiling.
",Michael Brown,https://programmers.stackexchange.com/users/13181,http://programmers.stackexchange.com/questions/76254/most-effective-way-to-increase-programmer-salary-besides-just-doing-your-job,TECHNOLOGY,programmers.stackexchange.com,1.0,1.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.4444444444444444,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.0,1.0,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8666666666666666,0.3333333333333333,0.6666666666666666,1.0,1.0,"In addition to work, what is the most effective way to raise the salary of programmers?","If you have time and resources, what is the most effective way to increase your salary as a full-time programmer besides doing your job?","There is a ceiling that most companies are not willing to go beyond for a straight programmer. You have to take on management/leadership roles if you want to pass that ceiling.
"
2608,2608,4150,How to crop a square at the exact centre of an image in Photoshop?,"Given a square image, how can I crop, at the exact center, of the image?

What if the image is not square itself?

What if I'm using Photoshop CS6 or some older version? 
Is the procedure the same?
",Pippo,https://graphicdesign.stackexchange.com/users/36498,"If your image is not square:


Choose View &gt; New Guide then tick the Vertical option and enter
50% in the box and click OK.
Choose View &gt; New Guide then tick the Horizontal option and
enter 50% in the box and click OK.


This provides a guide intersection at the image center.


Grab the Marquee Selection Tool or the Crop Tool, hold down the
Option/Alt and Shift key and click-drag
starting at that center guide intersection.


This draws a square selection (crop area) at the center of the image.


Then simply choose Image &gt; Crop, or hit the Enter to commit the crop (if using the crop tool)




If the image itself is square...


Choose Select &gt; All from the menu.
Then choose Select &gt; Modify &gt; Contract
Tick the Apply effect from Canvas Bounds box and enter the amount
of offset, from the canvas edge, you want and click OK.
Then simply choose Image &gt; Crop




For versions of Photoshop where ""contract"" may not be available after selecting all, use the first method.
",Scott,https://graphicdesign.stackexchange.com/users/3270,http://graphicdesign.stackexchange.com/questions/45295/how-to-crop-a-square-at-the-exact-centre-of-an-image-in-photoshop,LIFE_ARTS,graphicdesign.stackexchange.com,1.0,0.8888888888888888,0.0,0.6666666666666666,0.6666666666666666,1.0,0.6666666666666666,0.4444444444444444,0.6666666666666666,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,0.8888888888888888,How to cut the square in the center of the image in Photoshop?,"Given a square image, how can I crop, at the exact center, of the image?

What if the image is not square itself?

What if I'm using Photoshop CS6 or some older version? 
Is the procedure the same?
","If your image is not square:


Choose View &gt; New Guide then tick the Vertical option and enter
50% in the box and click OK.
Choose View &gt; New Guide then tick the Horizontal option and
enter 50% in the box and click OK.


This provides a guide intersection at the image center.


Grab the Marquee Selection Tool or the Crop Tool, hold down the
Option/Alt and Shift key and click-drag
starting at that center guide intersection.


This draws a square selection (crop area) at the center of the image.


Then simply choose Image &gt; Crop, or hit the Enter to commit the crop (if using the crop tool)




If the image itself is square...


Choose Select &gt; All from the menu.
Then choose Select &gt; Modify &gt; Contract
Tick the Apply effect from Canvas Bounds box and enter the amount
of offset, from the canvas edge, you want and click OK.
Then simply choose Image &gt; Crop




For versions of Photoshop where ""contract"" may not be available after selecting all, use the first method.
"
2111,2111,3359,Planet orbits: what's the difference between gravity and centripetal force?,"My physics teacher says that centripetal force is caused by gravity. I'm not entirely sure how this works? How can force cause another in space (ie where there's nothing). 

My astronomy teacher says that gravity is (note: not like) a 3D blanket and when you put mass on it, the mass causes a dip/dent in the blanket and so if you put another object with less mass it will roll down the dip onto the bigger mass. Is this true and is this what causes the centripetal force. 
",Jonathan.,https://physics.stackexchange.com/users/4,"cetripital force only exists when you have prescribed motion (due to constraints). Think of a roller coaster car riding on a rail. To keep the car on the rail and tangetial to it's direction a force and moment need to be applied to the car. When the path is circular we call the cetripetal force. In fact, with any path, instanteously it is said to be following a circle and therefore there is always an instanteneous centripetal force (unless in free fall).

Planets and things in orbit do not have a prescribed motion, but are following the free fall path whichever way they need to go. Gauss called this the principle of least action.

I hope this helps.
",ja72,https://physics.stackexchange.com/users/392,http://physics.stackexchange.com/questions/321/planet-orbits-whats-the-difference-between-gravity-and-centripetal-force,SCIENCE,physics.stackexchange.com,1.0,1.0,0.0,0.0,1.0,1.0,0.7777777777777778,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.8888888888888888,0.8888888888888888,0.4,0.0,0.0,0.0,0.5555555555555556,Planetary orbit: what's the difference between gravity and centripetal force?,"My physics teacher says that centripetal force is caused by gravity. I'm not entirely sure how this works? How can force cause another in space (ie where there's nothing). 

My astronomy teacher says that gravity is (note: not like) a 3D blanket and when you put mass on it, the mass causes a dip/dent in the blanket and so if you put another object with less mass it will roll down the dip onto the bigger mass. Is this true and is this what causes the centripetal force. 
","cetripital force only exists when you have prescribed motion (due to constraints). Think of a roller coaster car riding on a rail. To keep the car on the rail and tangetial to it's direction a force and moment need to be applied to the car. When the path is circular we call the cetripetal force. In fact, with any path, instanteously it is said to be following a circle and therefore there is always an instanteneous centripetal force (unless in free fall).

Planets and things in orbit do not have a prescribed motion, but are following the free fall path whichever way they need to go. Gauss called this the principle of least action.

I hope this helps.
"
1989,1989,3169,"How Can I ""Update-Package"" to a Previous Version in the Package Manager Console?","I have a version of a package installed in my project but during testing I have found a problem with it. I tried the obvious thing Update-Package -Id Foo.Bar -Version 1.0.0 -Force but the Update-Package cmdlet doesn't have a -Force parameter, and it doesn't allow updates to an earlier version. How do I downgrade my package dependencies (without taking advantage of source control!)



NOTE: This question is now irrelevant because Update-Package MyPackage -Version [an earlier version] works out of the box in recent versions of NuGet Package Manager. You don't even need a -Force switch.
",Damian Powell,https://stackoverflow.com/users/30321,"https://docs.nuget.org/consume/package-manager-console-powershell-reference


  
    With NuGet 2.8 client or higher, Install-Package can be used to downgrade the existing packages in your project, if necessary. For example, if you had installed a pre-release version of a package to try out new features but would like to go back to a previous stable version you can do so using Install-Package (or Update-Package).
  

",Frol,https://stackoverflow.com/users/1111385,http://stackoverflow.com/questions/9099632/how-can-i-update-package-to-a-previous-version-in-the-package-manager-console,STACKOVERFLOW,stackoverflow.com,0.6666666666666666,0.6666666666666666,0.0,0.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,0.0,0.3333333333333333,"How do I ""update"" a package to a previous version in the package manager console?","I installed a version of the package in my project, but I found a problem during the test. I tried update package ID foo.bar-version 1.0.0-force, but the update package cmdlet does not have the - force parameter and is not allowed to update to an earlier version. How to downgrade package dependencies (without source control!)","https://docs.nuget.org/consume/package-manager-console-powershell-reference


  
    With NuGet 2.8 client or higher, Install-Package can be used to downgrade the existing packages in your project, if necessary. For example, if you had installed a pre-release version of a package to try out new features but would like to go back to a previous stable version you can do so using Install-Package (or Update-Package).
  

"
4244,4244,6765,Roots of this third degree polynomial,"I've got the following polynomial
$$
x^3-6x^2-2x+40
$$
and I want to find its roots. The only option I see at the moment is to compute all the divisors of $40$ and their inverse, and manually check if it's result is $0$. This works, because $4$ is a zero and now we can divide the polynomial by the factor $x-4$, resulting in a second degree polynomial (which is easier to solve).

I was wondering if there's any other method/idea to manually find the roots of this polynomial?
",ABC,https://math.stackexchange.com/users/91270,"Hint: This can give some information about the possible location of roots, to help eliminate what you actually have to test. (Note: everything here refers to real roots and real zeroes.)

Write your polynomial as the function $$p(x) = x^3-6x^2-2x+40$$ and note that its derivative $$p'(x) = 3x^2 -12x-2$$
has exactly two distinct real zeroes $d_0&lt;d_1$ given by $2\pm\frac16\sqrt{42}$. So, moving from left to right, the graph of $p$ rises to the left of $d_0$, falls between $d_0$ and $d_1$, and rises again to the right of $d_1$.

Then the possibilities depend on the values of $y_j \equiv p(d_j)$:


if $y_0&lt;0$, $p$ has exactly one zero (it is to the right of $d_1$);
if $y_0=0$, $p$ has exactly two zeroes ($d_0$, and another to the right of $d_1$);


otherwise $y_0&gt;0$, and we have that


if $y_1&lt;0$, $p$ has three zeroes (one to the left of $d_0$, one between $d_0$ and $d_1$, and one to the right of $d_1$)
if $y_1=0$, $p$ has two zeroes (one to the left of $d_0$, and one at $d_1$;
otherwise $y_1&gt;0$, and $p$ has one zero (it is to the left of $d_0$)

",MPW,https://math.stackexchange.com/users/113214,http://math.stackexchange.com/questions/962303/roots-of-this-third-degree-polynomial,SCIENCE,math.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.6666666666666666,0.3333333333333333,0.6666666666666666,1.0,The root of this cubic polynomial,"I've got the following polynomial
$$
x^3-6x^2-2x+40
$$
and I want to find its roots. The only option I see at the moment is to compute all the divisors of $40$ and their inverse, and manually check if it's result is $0$. This works, because $4$ is a zero and now we can divide the polynomial by the factor $x-4$, resulting in a second degree polynomial (which is easier to solve).

I was wondering if there's any other method/idea to manually find the roots of this polynomial?
","Hint: This can give some information about the possible location of roots, to help eliminate what you actually have to test. (Note: everything here refers to real roots and real zeroes.)

Write your polynomial as the function $$p(x) = x^3-6x^2-2x+40$$ and note that its derivative $$p'(x) = 3x^2 -12x-2$$
has exactly two distinct real zeroes $d_0&lt;d_1$ given by $2\pm\frac16\sqrt{42}$. So, moving from left to right, the graph of $p$ rises to the left of $d_0$, falls between $d_0$ and $d_1$, and rises again to the right of $d_1$.

Then the possibilities depend on the values of $y_j \equiv p(d_j)$:


if $y_0&lt;0$, $p$ has exactly one zero (it is to the right of $d_1$);
if $y_0=0$, $p$ has exactly two zeroes ($d_0$, and another to the right of $d_1$);


otherwise $y_0&gt;0$, and we have that


if $y_1&lt;0$, $p$ has three zeroes (one to the left of $d_0$, one between $d_0$ and $d_1$, and one to the right of $d_1$)
if $y_1=0$, $p$ has two zeroes (one to the left of $d_0$, and one at $d_1$;
otherwise $y_1&gt;0$, and $p$ has one zero (it is to the left of $d_0$)

"
744,744,1179,Why is a precoder necessary for DQPSK and what does it accomplish?,"I've implemented a soft-decoder for DQPSK using the wonderful answers I received here:

How to soft decode DQPSK?

To get the soft-decoder working properly I needed to precode the data I was sending out.  I implemented the precoder mentioned in this paper:

$I_k=\overline{u_k \oplus v_k}*(u_k \oplus I_{k-1})+(u_k \oplus v_k)*(v_k \oplus Q_{k-1})$
$Q_k=\overline{u_k \oplus v_k}*(v_k \oplus Q_{k-1})+(u_k \oplus v_k)*(u_k \oplus I_{k-1})$

I'd like to know why this precoder is necessary -- what does that complicated expression of XORs actually accomplish?  

Here's a table showing what the equation yields.  If ""to_encode"" is 00, the to_send symbol is the same as the previous (""prev"") symbol.  If the ""to_encode"" is 11, the to_send symbol is the previous symbol xor 11.  What is the meaning in other cases?


to_encode prev  to send
[ 0 0 ] [ 0 0 ] [ 0 0 ]
[ 0 1 ] [ 0 0 ] [ 1 0 ]
[ 1 0 ] [ 0 0 ] [ 0 1 ]
[ 1 1 ] [ 0 0 ] [ 1 1 ]
[ 0 0 ] [ 0 1 ] [ 0 1 ]
[ 0 1 ] [ 0 1 ] [ 0 0 ]
[ 1 0 ] [ 0 1 ] [ 1 1 ]
[ 1 1 ] [ 0 1 ] [ 1 0 ]
[ 0 0 ] [ 1 0 ] [ 1 0 ]
[ 0 1 ] [ 1 0 ] [ 1 1 ]
[ 1 0 ] [ 1 0 ] [ 0 0 ]
[ 1 1 ] [ 1 0 ] [ 0 1 ]
[ 0 0 ] [ 1 1 ] [ 1 1 ]
[ 0 1 ] [ 1 1 ] [ 0 1 ]
[ 1 0 ] [ 1 1 ] [ 1 0 ]
[ 1 1 ] [ 1 1 ] [ 0 0 ]

",Dan Sandberg,https://dsp.stackexchange.com/users/3435,"Regard the dibits as Gray code representations of the
integers $0,1,2,3$, more specifically,

$$[0, 0] \leftrightarrow 0, ~~ [0, 1] \leftrightarrow 1, ~~ [1, 1] \leftrightarrow 2, ~~ [1, 0] \leftrightarrow 3.$$

Then, the precoding scheme is nothing but differential encoding for QPSK
with   

to send = prev - to_encode modulo $4$.  

For example the line [ 1 0 ] [ 0 1 ] [ 1 1 ] in the question says that to encode $3 = $ [1 0]  when the previous symbol was $1 = $ [0 1], we send $1-3 = -2 \equiv 2 \bmod 4$ where $2 =$ [1 1].
As stated in the answers and comments
on the previous question, 


  Differential encoding for QPSK is not the same as differential 
  (binary) encoding of the I and Q bit streams separately.


So the precoding scheme is just differential encoding for QPSK.
As to why it is included in the system, it must be that the
channel characteristics and system requirements are such that 
coherent detection of the signal is not thought to be feasible, 
and so the receiver is being implemented 
is a differentially coherent detector for DQPSK (differentially encoded 
QPSK).  Note that coherent detection requires that the receiver
phase lock loop acquire (and track) the incoming carrier in 
both frequency and phase (including resolution of
the four-fold phase ambiguity) while for differentially coherent
detection, frequency acquisition and tracking suffices, so that
the receiver is simpler and more robust, though of course 
for a given SNR, the BER of the differentially coherent
receiver is higher than the BER of the coherent receiver.
",Dilip Sarwate,https://dsp.stackexchange.com/users/235,http://dsp.stackexchange.com/questions/8119/why-is-a-precoder-necessary-for-dqpsk-and-what-does-it-accomplish,TECHNOLOGY,dsp.stackexchange.com,0.8888888888888888,0.7777777777777778,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.3333333333333333,0.3333333333333333,1.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,0.8888888888888888,0.8666666666666666,0.3333333333333333,0.3333333333333333,1.0,0.7777777777777778,Why does DQPSK need precoding? What does it accomplish?,"I've implemented a soft-decoder for DQPSK using the wonderful answers I received here:

How to soft decode DQPSK?

To get the soft-decoder working properly I needed to precode the data I was sending out.  I implemented the precoder mentioned in this paper:

$I_k=\overline{u_k \oplus v_k}*(u_k \oplus I_{k-1})+(u_k \oplus v_k)*(v_k \oplus Q_{k-1})$
$Q_k=\overline{u_k \oplus v_k}*(v_k \oplus Q_{k-1})+(u_k \oplus v_k)*(u_k \oplus I_{k-1})$

I'd like to know why this precoder is necessary -- what does that complicated expression of XORs actually accomplish?  

Here's a table showing what the equation yields.  If ""to_encode"" is 00, the to_send symbol is the same as the previous (""prev"") symbol.  If the ""to_encode"" is 11, the to_send symbol is the previous symbol xor 11.  What is the meaning in other cases?


to_encode prev  to send
[ 0 0 ] [ 0 0 ] [ 0 0 ]
[ 0 1 ] [ 0 0 ] [ 1 0 ]
[ 1 0 ] [ 0 0 ] [ 0 1 ]
[ 1 1 ] [ 0 0 ] [ 1 1 ]
[ 0 0 ] [ 0 1 ] [ 0 1 ]
[ 0 1 ] [ 0 1 ] [ 0 0 ]
[ 1 0 ] [ 0 1 ] [ 1 1 ]
[ 1 1 ] [ 0 1 ] [ 1 0 ]
[ 0 0 ] [ 1 0 ] [ 1 0 ]
[ 0 1 ] [ 1 0 ] [ 1 1 ]
[ 1 0 ] [ 1 0 ] [ 0 0 ]
[ 1 1 ] [ 1 0 ] [ 0 1 ]
[ 0 0 ] [ 1 1 ] [ 1 1 ]
[ 0 1 ] [ 1 1 ] [ 0 1 ]
[ 1 0 ] [ 1 1 ] [ 1 0 ]
[ 1 1 ] [ 1 1 ] [ 0 0 ]

","Regard the dibits as Gray code representations of the
integers $0,1,2,3$, more specifically,

$$[0, 0] \leftrightarrow 0, ~~ [0, 1] \leftrightarrow 1, ~~ [1, 1] \leftrightarrow 2, ~~ [1, 0] \leftrightarrow 3.$$

Then, the precoding scheme is nothing but differential encoding for QPSK
with   

to send = prev - to_encode modulo $4$.  

For example the line [ 1 0 ] [ 0 1 ] [ 1 1 ] in the question says that to encode $3 = $ [1 0]  when the previous symbol was $1 = $ [0 1], we send $1-3 = -2 \equiv 2 \bmod 4$ where $2 =$ [1 1].
As stated in the answers and comments
on the previous question, 


  Differential encoding for QPSK is not the same as differential 
  (binary) encoding of the I and Q bit streams separately.


So the precoding scheme is just differential encoding for QPSK.
As to why it is included in the system, it must be that the
channel characteristics and system requirements are such that 
coherent detection of the signal is not thought to be feasible, 
and so the receiver is being implemented 
is a differentially coherent detector for DQPSK (differentially encoded 
QPSK).  Note that coherent detection requires that the receiver
phase lock loop acquire (and track) the incoming carrier in 
both frequency and phase (including resolution of
the four-fold phase ambiguity) while for differentially coherent
detection, frequency acquisition and tracking suffices, so that
the receiver is simpler and more robust, though of course 
for a given SNR, the BER of the differentially coherent
receiver is higher than the BER of the coherent receiver.
"
3834,3834,6099,Chop out frequencies outside human hearing range,"I have a bunch of audio files all sampled at 44100 Hz sample frequency. I am trying to remove all the frequencies which are outside the human hearing range (I use the following as reference: Frequency Range of Human Hearing, as well as robert.b's answer for determining the frequency value of a given bin: How to get Frequency from FFT result), and my basic approach is:

1. Perform an FFT on the files
2. Convert all frequency bin indices to actual frequencies
3. Remove those which are outside the range (i.e. below 20 and above 20,000 Hz)


Would that be a valid approach, and would it be possible to ""put back"" my signals to a state (using the inverse FFT) where I can play them and check if they still sound ""normal""?
",User3419,https://dsp.stackexchange.com/users/3419,"Yes, it is possible to filter out the frequencies that you don't want using FFT's and inverse FFT's as you describe.  However, I do not recommend that you do it that way for a couple of reasons.


It's tempting to just zero out the frequencies that you don't want.  The problem with that is that it introduces strange artifacts when you transform your data back to the time domain.  There is a way to avoid introducing those artifacts, but it is more complicated than just straightforward time-domain filtering.
Unless you FFT the entire sound clip at once, you will have to use either the overlap-save or overlap-add method to avoid distortions at the points where you break the data up into frames.


Long story short, unless you really care about filtering speed, just do it in the time-domain.
",Jim Clay,https://dsp.stackexchange.com/users/923,http://dsp.stackexchange.com/questions/6200/chop-out-frequencies-outside-human-hearing-range,TECHNOLOGY,dsp.stackexchange.com,0.5,0.5,0.0,0.0,0.5,1.0,0.6666666666666666,0.5,0.5,0.0,0.5,0.5,0.0,0.0,0.0,0.0,0.5,0.0,1.0,0.0,0.8333333333333334,0.6666666666666666,0.8333333333333334,0.6666666666666666,0.8333333333333334,0.8,0.5,0.0,1.0,0.8333333333333334,Cut off frequencies outside the range of human hearing,"I have a bunch of audio files all sampled at 44100 Hz sample frequency. I am trying to remove all the frequencies which are outside the human hearing range (I use the following as reference: Frequency Range of Human Hearing, as well as robert.b's answer for determining the frequency value of a given bin: How to get Frequency from FFT result), and my basic approach is:

1. Perform an FFT on the files
2. Convert all frequency bin indices to actual frequencies
3. Remove those which are outside the range (i.e. below 20 and above 20,000 Hz)


Would that be a valid approach, and would it be possible to ""put back"" my signals to a state (using the inverse FFT) where I can play them and check if they still sound ""normal""?
","Yes, it is possible to filter out the frequencies that you don't want using FFT's and inverse FFT's as you describe.  However, I do not recommend that you do it that way for a couple of reasons.


It's tempting to just zero out the frequencies that you don't want.  The problem with that is that it introduces strange artifacts when you transform your data back to the time domain.  There is a way to avoid introducing those artifacts, but it is more complicated than just straightforward time-domain filtering.
Unless you FFT the entire sound clip at once, you will have to use either the overlap-save or overlap-add method to avoid distortions at the points where you break the data up into frames.


Long story short, unless you really care about filtering speed, just do it in the time-domain.
"
3228,3228,5150,Can I expect my e-mail to be routed securely?,"If I connect to my e-mail server via SSL (SMTP/SSL) and the recipient also only checks his e-mail via SSL (web/https or IMAP/SSL), does this - generally speaking - increase the security for the message content in any way? 

That is, will the communication between my providers e-mail server and the recipients e-mail server be ""secure""(*), or will the e-mail be delivered plain text between the servers? 

(*) Secure in the context of: encrypted throughout it's transit. Not secure in the sense that I'd put any really sensitive info in there.
",Martin,https://security.stackexchange.com/users/3785,"The secure connection on both ends just confirm secure transitions on network channel between User's end and the Mail Server connected to.

End-to-End security also involves security practices adopted by organization for their internal channel.

What I'd suggest is to confirm your mail-level security start using GnuPG or similar utility, where you can send an encrypted mail to user's using their Public Key.

Similar Usage Help Link: http://people.via.ecp.fr/~clem/nist/gpg-enigmail-howto

~~~~~

If your concern is just the integrity of your e-mail content and not the confidentiality, you could just restrain the task to digitally signing the e-mails

Similar Usage Help Link: http://www.cs.washington.edu/lab/services/email/EmailSigningHowTo/
",AbhishekKr,https://security.stackexchange.com/users/5105,http://security.stackexchange.com/questions/8289/can-i-expect-my-e-mail-to-be-routed-securely,TECHNOLOGY,security.stackexchange.com,0.7777777777777778,0.5555555555555556,0.0,1.0,1.0,1.0,0.7777777777777778,0.6666666666666666,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.8888888888888888,1.0,0.7777777777777778,1.0,1.0,0.8,0.6666666666666666,0.0,1.0,0.7777777777777778,Can I count on my email to be delivered safely?,"If I connect to my e-mail server via SSL (SMTP/SSL) and the recipient also only checks his e-mail via SSL (web/https or IMAP/SSL), does this - generally speaking - increase the security for the message content in any way? 

That is, will the communication between my providers e-mail server and the recipients e-mail server be ""secure""(*), or will the e-mail be delivered plain text between the servers? 

(*) Secure in the context of: encrypted throughout it's transit. Not secure in the sense that I'd put any really sensitive info in there.
","The secure connection on both ends just confirm secure transitions on network channel between User's end and the Mail Server connected to.

End-to-End security also involves security practices adopted by organization for their internal channel.

What I'd suggest is to confirm your mail-level security start using GnuPG or similar utility, where you can send an encrypted mail to user's using their Public Key.

Similar Usage Help Link: http://people.via.ecp.fr/~clem/nist/gpg-enigmail-howto

~~~~~

If your concern is just the integrity of your e-mail content and not the confidentiality, you could just restrain the task to digitally signing the e-mails

Similar Usage Help Link: http://www.cs.washington.edu/lab/services/email/EmailSigningHowTo/
"
4577,4577,7257,how to change my hostname?,"My hostname is localhost, reported by hostname command, and terminal prompt root@localhost:~#.

How can i change it to mismis.com with mismis alias? and what is the proper configuration.

I confused after reading some articles on web.

My /etc/hosts:

127.0.0.1       localhost
127.0.1.1       srv345.myweb.com      srv345
178.162.231.61  janstone.mismis.com    janstone
# The following lines are desirable for IPv6 capable hosts
::1     localhost ip6-localhost ip6-loopback
fe00::0 ip6-localnet
ff00::0 ip6-mcastprefix
ff02::1 ip6-allnodes
ff02::2 ip6-allrouters

",pylover,https://askubuntu.com/users/33292,"Try running the following command in a terminal.

sudo sysctl kernel.hostname=mismis.com


/etc/hosts: 

127.0.0.1       localhost
127.0.1.1       mismis.com mismis srv345.myweb.com srv345
178.162.231.61  janstone.mismis.com    janstone

# The following lines are desirable for IPv6 capable hosts
::1     localhost ip6-localhost ip6-loopback
fe00::0 ip6-localnet
ff00::0 ip6-mcastprefix
ff02::1 ip6-allnodes
ff02::2 ip6-allrouters

",Adem Öztaş,https://askubuntu.com/users/113280,http://askubuntu.com/questions/228202/how-to-change-my-hostname,TECHNOLOGY,askubuntu.com,1.0,0.5555555555555556,0.0,0.3333333333333333,1.0,0.6666666666666666,0.6666666666666666,0.4444444444444444,0.3333333333333333,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.5555555555555556,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.8,1.0,0.3333333333333333,0.3333333333333333,0.8888888888888888,How can I change my host name?,"My hostname is localhost, reported by hostname command, and terminal prompt root@localhost:~#.

How can i change it to mismis.com with mismis alias? and what is the proper configuration.

I confused after reading some articles on web.

My /etc/hosts:

127.0.0.1       localhost
127.0.1.1       srv345.myweb.com      srv345
178.162.231.61  janstone.mismis.com    janstone
# The following lines are desirable for IPv6 capable hosts
::1     localhost ip6-localhost ip6-loopback
fe00::0 ip6-localnet
ff00::0 ip6-mcastprefix
ff02::1 ip6-allnodes
ff02::2 ip6-allrouters

","Try running the following command in a terminal.

sudo sysctl kernel.hostname=mismis.com


/etc/hosts: 

127.0.0.1       localhost
127.0.1.1       mismis.com mismis srv345.myweb.com srv345
178.162.231.61  janstone.mismis.com    janstone

# The following lines are desirable for IPv6 capable hosts
::1     localhost ip6-localhost ip6-loopback
fe00::0 ip6-localnet
ff00::0 ip6-mcastprefix
ff02::1 ip6-allnodes
ff02::2 ip6-allrouters

"
3158,3158,5029,Increasing voltage source frequency,"I am trying to simulate a simple circuit using a simulation program like SPICE. In the beginning of the circuit I have a pulse train voltage source, later it is connected to a normal LPF. The voltage source frequency is set as 1 kHz, my question is how to increase this frequency? 

The only options that I have is to change the time of the cycle and the voltage. If I set 1 ms and 5V, the frequency will be 1 kHz.

If I change the time to 0.5 ms, the result will be 5V for 0.5 ms and the rest is 0. (The second cycle will not start after 0.5 ms, so the frequency is same 1 kHz). Strange!

How do I increase the frequency of the voltage source?
",yaya,https://electronics.stackexchange.com/users/53052,"First of all, frequency is not voltage dependent. Secondly, I'm not really sure what you want to achieve. What kind of waveform do you want to have (Pulse, Sinus...)?

If you want to have a pulse voltage output you can use 


  PULSE(0 5 0 0 0 0.5m 1m 100)


which will generate a 5V pulse voltage with a frequency of 1kHz and 50% Duty Cycle. The pulse will be repeated 100 cycles.
",Bommelchen,https://electronics.stackexchange.com/users/51296,http://electronics.stackexchange.com/questions/129410/increasing-voltage-source-frequency,SCIENCE,electronics.stackexchange.com,0.7777777777777778,0.4444444444444444,0.0,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.4444444444444444,0.8888888888888888,0.6666666666666666,1.0,1.0,0.9,1.0,0.0,0.6666666666666666,0.8888888888888888,Increase voltage source frequency,"I am trying to simulate a simple circuit using a simulation program like SPICE. In the beginning of the circuit I have a pulse train voltage source, later it is connected to a normal LPF. The voltage source frequency is set as 1 kHz, my question is how to increase this frequency? 

The only options that I have is to change the time of the cycle and the voltage. If I set 1 ms and 5V, the frequency will be 1 kHz.

If I change the time to 0.5 ms, the result will be 5V for 0.5 ms and the rest is 0. (The second cycle will not start after 0.5 ms, so the frequency is same 1 kHz). Strange!

How do I increase the frequency of the voltage source?
","First of all, frequency is not voltage dependent. Secondly, I'm not really sure what you want to achieve. What kind of waveform do you want to have (Pulse, Sinus...)?

If you want to have a pulse voltage output you can use 


  PULSE(0 5 0 0 0 0.5m 1m 100)


which will generate a 5V pulse voltage with a frequency of 1kHz and 50% Duty Cycle. The pulse will be repeated 100 cycles.
"
1740,1740,2751,\jobname in Gummi,"The command \jobname usually print the file name without the path and extension, so inside a file called foo.tex will print just foo. With pdflatex foo.test or compiling from LaTeXila certainly I obtained this result. But from Gummi what I obtain is .foo.tex  

Does anyone know why Gummi compiles differently and how I could get the usual \jobname behavior in Gummi?

Edit:
Based on helpful answers of @JosephWright and @Herbert
I wonder if it is possible to do the \jobname correction in Gummi only if the source have the .swp extensión or .tex persist in \jobname. 

That is, I would like a solution like:

\makeatletter
\let\JobName\jobname
\ifthenelse{\equal{\detokenize{foo}}{\jobname}}
{}
{
\def\@JobName.#1.#2\@nil{#1}
\def\jobname{\expandafter\@JobName\JobName\@nil}
}
\makeatother


This conditional works to check if the jobname is foo or not, but I want a general solution, independent of the file name (not limited to the string foo). 
",Fran,https://tex.stackexchange.com/users/11604,"use in the preamble:

\makeatletter
\let\JobName\jobname
\def\@JobName.#1.#2\@nil{#1}
\def\jobname{\expandafter\@JobName\JobName\@nil}
\makeatother


then \jobname works as usual. The above is only useful for running a file with gummi.
",Herbert,https://tex.stackexchange.com/users/2478,http://tex.stackexchange.com/questions/69434/jobname-in-gummi,TECHNOLOGY,tex.stackexchange.com,0.6666666666666666,0.3333333333333333,0.0,1.0,0.6666666666666666,1.0,0.6666666666666666,0.4444444444444444,0.6666666666666666,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,0.7777777777777778,\Ganmi's job name,"The command \jobname usually print the file name without the path and extension, so inside a file called foo.tex will print just foo. With pdflatex foo.test or compiling from LaTeXila certainly I obtained this result. But from Gummi what I obtain is .foo.tex  

Does anyone know why Gummi compiles differently and how I could get the usual \jobname behavior in Gummi?

Edit:
Based on helpful answers of @JosephWright and @Herbert
I wonder if it is possible to do the \jobname correction in Gummi only if the source have the .swp extensión or .tex persist in \jobname. 

That is, I would like a solution like:

\makeatletter
\let\JobName\jobname
\ifthenelse{\equal{\detokenize{foo}}{\jobname}}
{}
{
\def\@JobName.#1.#2\@nil{#1}
\def\jobname{\expandafter\@JobName\JobName\@nil}
}
\makeatother


This conditional works to check if the jobname is foo or not, but I want a general solution, independent of the file name (not limited to the string foo). 
","use in the preamble:

\makeatletter
\let\JobName\jobname
\def\@JobName.#1.#2\@nil{#1}
\def\jobname{\expandafter\@JobName\JobName\@nil}
\makeatother


then \jobname works as usual. The above is only useful for running a file with gummi.
"
1228,1228,1924,application/json Content-Type character set,"According to the OWASP Application Security Verification Standard:


  V11.3 Verify that every HTTP response contains a content type header
  specifying a safe character set (e.g., UTF-8).


According to the RFC for the application/json Media Type:


  JSON text SHALL be encoded in Unicode. The default encoding is UTF-8.
  
  Since the first two characters of a JSON text will always be ASCII
  characters [RFC0020], it is possible to determine whether an octet
  stream is UTF-8, UTF-16 (BE or LE), or UTF-32 (BE or LE) by looking
  at the pattern of nulls in the first four octets.


If your encoding is in fact UTF-8, this implies there is no security benefit to setting the Content-Type header to application/json; charset=utf-8 instead of just application/json.

Is it reasonable to make an exception to the OWASP rule for application/json?
",oggmonster,https://security.stackexchange.com/users/69513,"Your biggest risk would be older versions of Internet Explorer that attempt to auto-detect the encoding as UTF-7 - called Codepage Sniffing.

It appears that Internet Explorer will only do this for webpages, and not for AJAX requests. Therefore JSON requests should be safe. Moreover, JSON requests do not cause rendering of content directly to the page - they would need JavaScript processing in order to manipulate the DOM, so this would only be of concern when you were retrieving data that has supposedly been pre-HTML encoded. Therefore if the JSON data is HTML encoded on the client, the encoding of the page should take precedence and would not cause conversion of +ADw- character sequences to angle brackets, which is where the risk lies with UTF-7.

So I would say specifying charset=utf-8 is only necessary for Content-Type: text/html pages.
",SilverlightFox,https://security.stackexchange.com/users/8340,http://security.stackexchange.com/questions/82913/application-json-content-type-character-set,TECHNOLOGY,security.stackexchange.com,0.5555555555555556,0.3333333333333333,0.0,1.0,0.6666666666666666,1.0,0.3333333333333333,0.4444444444444444,0.3333333333333333,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,0.0,0.4444444444444444,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.0,1.0,0.8888888888888888,Application / JSON content type character set,"According to the OWASP Application Security Verification Standard:


  V11.3 Verify that every HTTP response contains a content type header
  specifying a safe character set (e.g., UTF-8).


According to the RFC for the application/json Media Type:


  JSON text SHALL be encoded in Unicode. The default encoding is UTF-8.
  
  Since the first two characters of a JSON text will always be ASCII
  characters [RFC0020], it is possible to determine whether an octet
  stream is UTF-8, UTF-16 (BE or LE), or UTF-32 (BE or LE) by looking
  at the pattern of nulls in the first four octets.


If your encoding is in fact UTF-8, this implies there is no security benefit to setting the Content-Type header to application/json; charset=utf-8 instead of just application/json.

Is it reasonable to make an exception to the OWASP rule for application/json?
","Your biggest risk would be older versions of Internet Explorer that attempt to auto-detect the encoding as UTF-7 - called Codepage Sniffing.

It appears that Internet Explorer will only do this for webpages, and not for AJAX requests. Therefore JSON requests should be safe. Moreover, JSON requests do not cause rendering of content directly to the page - they would need JavaScript processing in order to manipulate the DOM, so this would only be of concern when you were retrieving data that has supposedly been pre-HTML encoded. Therefore if the JSON data is HTML encoded on the client, the encoding of the page should take precedence and would not cause conversion of +ADw- character sequences to angle brackets, which is where the risk lies with UTF-7.

So I would say specifying charset=utf-8 is only necessary for Content-Type: text/html pages.
"
1238,1238,1939,android using async http connection to get image bitmap,"I am trying to use async requests to fetch the images from urls, to prevent the url from hanging. This is the piece of code i am using for this

private void setImg(final ImageView im, String url){
    AsyncHttpClient client = new AsyncHttpClient();
    client.get(url, new AsyncHttpResponseHandler(){
        public void onSuccess(String response){
            try{
                byte[] imageAsBytes = response.getBytes();
                im.setImageBitmap(BitmapFactory.decodeByteArray(imageAsBytes, 0, imageAsBytes.length));
                im.refreshDrawableState();
            } catch(Throwable e){
                e.printStackTrace();
            }
        }
    });
}


This is always showing this warning in logcat

12-29 01:55:33.043: D/skia(14414): --- SkImageDecoder::Factory returned null

I cannot find a proper reason for this. Any help?
",Amit,https://stackoverflow.com/users/409110,"If anyone is still working on this, here's how I am doing it

public static void setImg(final ImageView im, final String url){
    AsyncTask&lt;Void, Void, Bitmap&gt; t = new AsyncTask&lt;Void, Void, Bitmap&gt;(){
        protected Bitmap doInBackground(Void... p) {
            Bitmap bm = null;
            try {
                URL aURL = new URL(url);
                URLConnection conn = aURL.openConnection();
                conn.setUseCaches(true);
                conn.connect(); 
                InputStream is = conn.getInputStream(); 
                BufferedInputStream bis = new BufferedInputStream(is); 
                bm = BitmapFactory.decodeStream(bis);
                bis.close(); 
                is.close();
            } catch (IOException e) { 
                e.printStackTrace(); 
            }
            return bm;
        }

        protected void onPostExecute(Bitmap bm){
            Bitmap output = Bitmap.createBitmap(bm.getWidth(), bm.getHeight(), Config.ARGB_8888);
            Canvas canvas = new Canvas(output);

            final int color = 0xff424242;
            final Paint paint = new Paint();
            final Rect rect = new Rect(0, 0, bm.getWidth(), bm.getHeight());
            final RectF rectF = new RectF(rect);
            final float roundPx = 5;

            paint.setAntiAlias(true);
            canvas.drawARGB(0, 0, 0, 0);
            paint.setColor(color);
            canvas.drawRoundRect(rectF, roundPx, roundPx, paint);

            paint.setXfermode(new PorterDuffXfermode(Mode.SRC_IN));
            canvas.drawBitmap(bm, rect, rect, paint);
            im.setImageBitmap(output);
        }
    };
    t.execute();
}

",Amit,https://stackoverflow.com/users/409110,http://stackoverflow.com/questions/8660885/android-using-async-http-connection-to-get-image-bitmap,STACKOVERFLOW,stackoverflow.com,0.5555555555555556,0.3333333333333333,0.0,0.0,1.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,0.7777777777777778,1.0,0.9333333333333332,1.0,0.0,0.0,0.8888888888888888,Android uses asynchronous HTTP connection to obtain image bitmap,"I am trying to use async requests to fetch the images from urls, to prevent the url from hanging. This is the piece of code i am using for this

private void setImg(final ImageView im, String url){
    AsyncHttpClient client = new AsyncHttpClient();
    client.get(url, new AsyncHttpResponseHandler(){
        public void onSuccess(String response){
            try{
                byte[] imageAsBytes = response.getBytes();
                im.setImageBitmap(BitmapFactory.decodeByteArray(imageAsBytes, 0, imageAsBytes.length));
                im.refreshDrawableState();
            } catch(Throwable e){
                e.printStackTrace();
            }
        }
    });
}


This is always showing this warning in logcat

12-29 01:55:33.043: D/skia(14414): --- SkImageDecoder::Factory returned null

I cannot find a proper reason for this. Any help?
","If anyone is still working on this, here's how I am doing it

public static void setImg(final ImageView im, final String url){
    AsyncTask&lt;Void, Void, Bitmap&gt; t = new AsyncTask&lt;Void, Void, Bitmap&gt;(){
        protected Bitmap doInBackground(Void... p) {
            Bitmap bm = null;
            try {
                URL aURL = new URL(url);
                URLConnection conn = aURL.openConnection();
                conn.setUseCaches(true);
                conn.connect(); 
                InputStream is = conn.getInputStream(); 
                BufferedInputStream bis = new BufferedInputStream(is); 
                bm = BitmapFactory.decodeStream(bis);
                bis.close(); 
                is.close();
            } catch (IOException e) { 
                e.printStackTrace(); 
            }
            return bm;
        }

        protected void onPostExecute(Bitmap bm){
            Bitmap output = Bitmap.createBitmap(bm.getWidth(), bm.getHeight(), Config.ARGB_8888);
            Canvas canvas = new Canvas(output);

            final int color = 0xff424242;
            final Paint paint = new Paint();
            final Rect rect = new Rect(0, 0, bm.getWidth(), bm.getHeight());
            final RectF rectF = new RectF(rect);
            final float roundPx = 5;

            paint.setAntiAlias(true);
            canvas.drawARGB(0, 0, 0, 0);
            paint.setColor(color);
            canvas.drawRoundRect(rectF, roundPx, roundPx, paint);

            paint.setXfermode(new PorterDuffXfermode(Mode.SRC_IN));
            canvas.drawBitmap(bm, rect, rect, paint);
            im.setImageBitmap(output);
        }
    };
    t.execute();
}

"
1743,1743,2755,Will a site URL with repeating keywords get penalized by search engines?,"I have an URL structure like the following:


  sitename.com/cellphone/nokia/galaxy-5678-nokia-cellphone-from-abc/


For more example:


  sitename.com/cellphone/motorolla/new-motorolla-gta800-cellphone-from-zxy/


The directory structure is like the cellphone is the main directory of the module and the words like Motorolla and Nokia are subdirectories which are categories and then comes the title of the cellphone.

Here the word cellphone and Nokia in the first link and cellphone and Motorolla in the second link are repeated.

Is it any kind of keyword stuffing? will it be penalized by Google?
",Jayapal Chandran,https://webmasters.stackexchange.com/users/2185,"It's important to note that there is no official number that is classed as keyword stuffing and every page/site is different. But in your example it's not a matter if its keyword stuffing or not. You should be making your URLs for your visitors and not the search engines. 

Your unnecessary repeating the words, words such as 'new' are stop words and you no need to repeat the manufacturer or cellphone since its mentioned before.

sitename.com/cellphone/motorolla/new-motorolla-gta800-cellphone/


is exactly the same as:

sitename.com/cellphone/motorolla/gta800/


Focus on Keywords and what the page is about. If its a review then you use:

sitename.com/cellphone/motorolla/gta800-review/


If its about 10 reasons why the gta800 sucks then you use something like:

sitename.com/cellphone/motorolla/10-reasons-why-not-to-buy-a-gta800/


Cater for your audience not the search engines. There is no need to repeat it more than once: it doesn't make it any more important. 

Google has many ways of establishing what the page is about, URL is just one indicator of many. As long as you have the main 'KEYWORD' or Keywords you want to rank then the rest don't matter. Use the title, H1 and meta description for more in depth information. Short URLs are preferred, not only because they have higher click rates but also they are better to link.
",Simon Hayter,https://webmasters.stackexchange.com/users/20604,http://webmasters.stackexchange.com/questions/46779/will-a-site-url-with-repeating-keywords-get-penalized-by-search-engines,TECHNOLOGY,webmasters.stackexchange.com,1.0,0.8888888888888888,0.0,1.0,0.6666666666666666,1.0,0.5555555555555556,0.5555555555555556,0.3333333333333333,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,1.0,0.6666666666666666,1.0,0.8888888888888888,0.8,0.3333333333333333,0.0,1.0,0.8888888888888888,Will the URL of a website with duplicate keywords be punished by the search engine?,"I have an URL structure like the following:


  sitename.com/cellphone/nokia/galaxy-5678-nokia-cellphone-from-abc/


For more example:


  sitename.com/cellphone/motorolla/new-motorolla-gta800-cellphone-from-zxy/


The directory structure is like the cellphone is the main directory of the module and the words like Motorolla and Nokia are subdirectories which are categories and then comes the title of the cellphone.

Here the word cellphone and Nokia in the first link and cellphone and Motorolla in the second link are repeated.

Is it any kind of keyword stuffing? will it be penalized by Google?
","It's important to note that there is no official number that is classed as keyword stuffing and every page/site is different. But in your example it's not a matter if its keyword stuffing or not. You should be making your URLs for your visitors and not the search engines. 

Your unnecessary repeating the words, words such as 'new' are stop words and you no need to repeat the manufacturer or cellphone since its mentioned before.

sitename.com/cellphone/motorolla/new-motorolla-gta800-cellphone/


is exactly the same as:

sitename.com/cellphone/motorolla/gta800/


Focus on Keywords and what the page is about. If its a review then you use:

sitename.com/cellphone/motorolla/gta800-review/


If its about 10 reasons why the gta800 sucks then you use something like:

sitename.com/cellphone/motorolla/10-reasons-why-not-to-buy-a-gta800/


Cater for your audience not the search engines. There is no need to repeat it more than once: it doesn't make it any more important. 

Google has many ways of establishing what the page is about, URL is just one indicator of many. As long as you have the main 'KEYWORD' or Keywords you want to rank then the rest don't matter. Use the title, H1 and meta description for more in depth information. Short URLs are preferred, not only because they have higher click rates but also they are better to link.
"
4903,4903,7803,Alternative Date/Time Libraries for Go,"Are there any alternatives to Golang's time package? I can't come to grips with its clunky interface and strange way of doing things. The language overall is great, but this part of it just never clicked with me.

Anyone? A really good, thorough tutorial would work too (I have not managed to find one yet)

What I'm trying to do right now is a goroutine that updates only 10 times per second (or any variable interval that I set it to). I've not yet implemented it, as the package is not playing nice. Here's the psuedo code.

function GoRoutine(updatesPerSecond int) {
    interval = 1000msec / updatesPerSecond

    for {
        if enoughTimeHasPassed {
            doThings()
        }
    }
}

",Jesse Brands,https://stackoverflow.com/users/602272,"Did you read the documentation at http://golang.org/pkg/time/?

You need to use a Ticker:

func Loop(fps int) {
    t := time.NewTicker(time.Second / time.Duration(fps))
    for t := range t.C {
        fmt.Println(""tick"", t)
    }
}
func main() {
    go Loop(60)
    time.Sleep(10 * time.Second)
}


then use it like go Loop(60).
",OneOfOne,https://stackoverflow.com/users/145587,http://stackoverflow.com/questions/25006155/alternative-date-time-libraries-for-go,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.4444444444444444,0.0,1.0,1.0,1.0,0.7777777777777778,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,0.8888888888888888,Alternative date / time base for go,"Are there any alternatives to Golang's time package? I can't come to grips with its clunky interface and strange way of doing things. The language overall is great, but this part of it just never clicked with me.

Anyone? A really good, thorough tutorial would work too (I have not managed to find one yet)

What I'm trying to do right now is a goroutine that updates only 10 times per second (or any variable interval that I set it to). I've not yet implemented it, as the package is not playing nice. Here's the psuedo code.

function GoRoutine(updatesPerSecond int) {
    interval = 1000msec / updatesPerSecond

    for {
        if enoughTimeHasPassed {
            doThings()
        }
    }
}

","Did you read the documentation at http://golang.org/pkg/time/?

You need to use a Ticker:

func Loop(fps int) {
    t := time.NewTicker(time.Second / time.Duration(fps))
    for t := range t.C {
        fmt.Println(""tick"", t)
    }
}
func main() {
    go Loop(60)
    time.Sleep(10 * time.Second)
}


then use it like go Loop(60).
"
5828,5828,9234,Integrate a division of polynomials,"Hi I have the following integral:
$$\int \frac{2x}{x^2+6x+3}\, dx$$

I made some changes like:
$$\int \dfrac{2x+6-6}{x^2+6x+3}\, dx$$

then I have: 
$$\int \dfrac{2x+6}{x^2+6x+3}\, dx -\int\dfrac{6}{x^2+6x+3}\, dx$$

and thus: $$\ln(x^2+6x+3)-\int\dfrac{6}{x^2+6x+3}\, dx$$

Ok, I have decomposed $$\frac{2x}{x^2+6x+3} $$  in: $$ \frac{3+\sqrt6}{\sqrt6(x+\sqrt 6+3)} + \frac{3-\sqrt6}{\sqrt6 (-x+\sqrt6-3)}$$

How can I integrate this expressions?
",Luis Armando,https://math.stackexchange.com/users/162185,"HINT:

As
$\displaystyle x^2+6x+3=(x+3)^2-(\sqrt6)^2,$

using Trigonometric substitution, set $x+3=\sqrt6\sec\theta$

or use $\#1$ of this
",lab bhattacharjee,https://math.stackexchange.com/users/33337,http://math.stackexchange.com/questions/882692/integrate-a-division-of-polynomials,SCIENCE,math.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,0.6666666666666666,1.0,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.5555555555555556,0.7777777777777778,0.5,0.7777777777777778,0.8333333333333334,0.6,0.6666666666666666,0.6666666666666666,0.0,0.7777777777777778,Division of integral polynomials,"Hi I have the following integral:
$$\int \frac{2x}{x^2+6x+3}\, dx$$

I made some changes like:
$$\int \dfrac{2x+6-6}{x^2+6x+3}\, dx$$

then I have: 
$$\int \dfrac{2x+6}{x^2+6x+3}\, dx -\int\dfrac{6}{x^2+6x+3}\, dx$$

and thus: $$\ln(x^2+6x+3)-\int\dfrac{6}{x^2+6x+3}\, dx$$

Ok, I have decomposed $$\frac{2x}{x^2+6x+3} $$  in: $$ \frac{3+\sqrt6}{\sqrt6(x+\sqrt 6+3)} + \frac{3-\sqrt6}{\sqrt6 (-x+\sqrt6-3)}$$

How can I integrate this expressions?
","HINT:

As
$\displaystyle x^2+6x+3=(x+3)^2-(\sqrt6)^2,$

using Trigonometric substitution, set $x+3=\sqrt6\sec\theta$

or use $\#1$ of this
"
2621,2621,4169,Is an old mtb with replaced gear safe to buy?,"I believe this question to be on topic for this site, I want it to be more factual based than opinion, another similar question is this one. If its not feel free to close it.

I am looking at buying an older (10 yrs old) Giant NRS 1 MTB, it has very good reviews for the frame especially, but other parts have been replaced (it has a new front wheel, cables etc.). Should I be worried that other parts will be about to fall off, or are replacements a good thing?

EDIT: Ok so the wheel was replaced due to hitting a stump at night time, the cables were getting old, it has had plenty of action, but was well looked after. The rear sus has a tiny bit of play in the top bush (not enough to realise when riding)

It also has a leaking front fork, not a big issue (probably new seal, or not worry), but makes me wonder if it is worth it, will cost around $400 US ish, do you think it will have other issues?

cheers in advance!
",W1ll1amvl,https://bicycles.stackexchange.com/users/14123,"With a mountain bike parts do wear out. I would be more cautious of a 10 year old bike with original parts unless it had original tires and I could still see the manufacturer 'tags' (i.e. like new) showing it had been ridden only once or twice and been a garage ornament for all but the first 2 weeks of its life.  

If the bike has been ridden regularly you will be wanting a well maintained one. This means parts replaced as they wear out or get damaged.  

I have bough several second hand MTB's - you get a better bike for you money than new. The ones I have always ended up buying have had many parts replaced, as its these bikes that the riders are using regularity and keeping well tuned and maintained.  

With respect to the edits - a leaking front fork could simply need a new seal or it could be a new fork - its a deal breaker for me. 
",mattnz,https://bicycles.stackexchange.com/users/3924,http://bicycles.stackexchange.com/questions/25691/is-an-old-mtb-with-replaced-gear-safe-to-buy,CULTURE,bicycles.stackexchange.com,0.7777777777777778,0.7777777777777778,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,0.8888888888888888,0.9333333333333332,0.0,0.0,0.6666666666666666,0.7777777777777778,Can old subway with new equipment be purchased safely?,"I believe this question to be on topic for this site, I want it to be more factual based than opinion, another similar question is this one. If its not feel free to close it.

I am looking at buying an older (10 yrs old) Giant NRS 1 MTB, it has very good reviews for the frame especially, but other parts have been replaced (it has a new front wheel, cables etc.). Should I be worried that other parts will be about to fall off, or are replacements a good thing?

EDIT: Ok so the wheel was replaced due to hitting a stump at night time, the cables were getting old, it has had plenty of action, but was well looked after. The rear sus has a tiny bit of play in the top bush (not enough to realise when riding)

It also has a leaking front fork, not a big issue (probably new seal, or not worry), but makes me wonder if it is worth it, will cost around $400 US ish, do you think it will have other issues?

cheers in advance!
","With a mountain bike parts do wear out. I would be more cautious of a 10 year old bike with original parts unless it had original tires and I could still see the manufacturer 'tags' (i.e. like new) showing it had been ridden only once or twice and been a garage ornament for all but the first 2 weeks of its life.  

If the bike has been ridden regularly you will be wanting a well maintained one. This means parts replaced as they wear out or get damaged.  

I have bough several second hand MTB's - you get a better bike for you money than new. The ones I have always ended up buying have had many parts replaced, as its these bikes that the riders are using regularity and keeping well tuned and maintained.  

With respect to the edits - a leaking front fork could simply need a new seal or it could be a new fork - its a deal breaker for me. 
"
5842,5842,9255,How to color lat/lon points in given RGB data?,"I am using QGIS on a Mac.

I am working with hydroacoustic data for mapping and interpreting the seafloor.
Data are collected, processed and interpreted. The result is a txt file with Lat and Lon in the first columns followed by R, G and B data, e.g. [54.20,7.78,0.94,0.62,0.37]. The files can have 100,000 lines or more. 
I am not really good in GIS but I need to use it for some reasons. I seem to be unable to plot these data in GIS. There is obviously no symbology/style way to tell the system to take the color values from a file (i.e. the next 3 values in the same line of the file). It is so easy in MatLab: scatter(lat, lon, symbolsize, [R G B]) but I can't work easily with multiple layers in Matlab.
",Chris,https://gis.stackexchange.com/users/35565,"The feature you want is implemented as ""Data defined properties"". See Data-defined Styles in QGIS for a first announcement.

It works for me this way:


Load the data as delimited text, and save it as a shapefile with CRS EPSG:4326 WGS84
Right-click on the layer -> Properties -&gt; Style
Leave the topmost dropdown field at Single Symbol
Click on Simple Marker below
On the right, click on Data defined properties
Check Fill Color, then on the epsilon to the right
In the field top left, select color, then color_rgb
Click on Fields and Values, then on the field for red
add a comma
proceed with the green and blue field, and close the bracket
Click OK to leave the forms


My color values are between 0 and 255, but scaling that should be a minor problem for you...

N,E,R,G,B
54.20,7.78,239,158,94
51,8,129,72,122
50.5,7,123,34,55
50,6,23,210,233
51.5,8,233,14,140
52,7.5,23,25,100
53,6,100,23,23
52.5,7,200,40,10



",AndreJ,https://gis.stackexchange.com/users/9159,http://gis.stackexchange.com/questions/109894/how-to-color-lat-lon-points-in-given-rgb-data,TECHNOLOGY,gis.stackexchange.com,1.0,1.0,0.0,0.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,1.0,How to color latitude / longitude points in given RGB data?,"I am using QGIS on a Mac.

I am working with hydroacoustic data for mapping and interpreting the seafloor.
Data are collected, processed and interpreted. The result is a txt file with Lat and Lon in the first columns followed by R, G and B data, e.g. [54.20,7.78,0.94,0.62,0.37]. The files can have 100,000 lines or more. 
I am not really good in GIS but I need to use it for some reasons. I seem to be unable to plot these data in GIS. There is obviously no symbology/style way to tell the system to take the color values from a file (i.e. the next 3 values in the same line of the file). It is so easy in MatLab: scatter(lat, lon, symbolsize, [R G B]) but I can't work easily with multiple layers in Matlab.
","The feature you want is implemented as ""Data defined properties"". See Data-defined Styles in QGIS for a first announcement.

It works for me this way:


Load the data as delimited text, and save it as a shapefile with CRS EPSG:4326 WGS84
Right-click on the layer -> Properties -&gt; Style
Leave the topmost dropdown field at Single Symbol
Click on Simple Marker below
On the right, click on Data defined properties
Check Fill Color, then on the epsilon to the right
In the field top left, select color, then color_rgb
Click on Fields and Values, then on the field for red
add a comma
proceed with the green and blue field, and close the bracket
Click OK to leave the forms


My color values are between 0 and 255, but scaling that should be a minor problem for you...

N,E,R,G,B
54.20,7.78,239,158,94
51,8,129,72,122
50.5,7,123,34,55
50,6,23,210,233
51.5,8,233,14,140
52,7.5,23,25,100
53,6,100,23,23
52.5,7,200,40,10



"
4340,4340,6912,Is Cyrus the Messiah?,"What are the actual words used for Isaiah 44:28 to describe his anointed? Why do most Bible translation translate that as shepherd? I've heard the Masoretic Text uses ""messiah"" and the Septuagint uses ""Christ"".  The English translation uses the word ""shepherd,"" which seems like lying or filtering.  Why the discrepancy?

I stumbled upon some atheist sites and found this. Translating a word like Christ into shepherd seems very misleading.

I also came across this discussion about this on the web.
",J. Chang,https://christianity.stackexchange.com/users/933,"The original Hebrew word being used here is רֹעִי (ro·'i),[1][2], which does indeed translate as ""shepherd"" according to Strong's Concordance.[3][4]
",Waggers,https://christianity.stackexchange.com/users/61,http://christianity.stackexchange.com/questions/4345/is-cyrus-the-messiah,CULTURE,christianity.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,0.3333333333333333,0.6666666666666666,0.3333333333333333,0.5555555555555556,0.4444444444444444,0.6666666666666666,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.7777777777777778,0.8888888888888888,0.5555555555555556,1.0,1.0,0.8,0.0,0.0,1.0,0.8888888888888888,Is Cyrus the Messiah?,"What does Isaiah 44:28 say about the anointed? Why do most Bible translations translate it into shepherds? I've heard that the messianic scriptures use ""Messiah"", while the seventh scriptures use ""Christ"". The English translation uses the word shepherd, which looks like lying or filtering. Why not?","The original Hebrew word used here is ""the shepherd"", which was written by the panel as ""the shepherd"", according to the consistency of strong. [3][4]"
375,375,592,Is it copyright infringement by US copyright law if someone else modifies and uses my design?,"My company is in a small town and there are not any graphic designers but we have enough business in the town and the surrounding area to support us.  But because of the small town nature some business owners do not know all the laws.  And since I am starting this from a career in architecture I am not quite clear on copyrights.  So here is my problem.  

I created a sign that has an oval with scrolls and flowers in different colors on a field of turquoise.  The client did not want to spend the money on a logo design so I said that I will  just retain the rights so that she would have to come to me for the approval to use the logo on anything else.  So anyway everything seems to be fine, I do her business cards and now all of a sudden I see a sign at the street.  I quoted her on this job figuring in using the logo.  Apparently this company did for much less and you can tell by the quality.

But here is my problem.  She had a jpeg that I allowed her to have so she could create her own fliers and I was ok with that since it would not have made me much if any money.  Well I am looking at the sign that the other person did and all that was done is they made a longer oval since this sign is more rectangle and used a different font.  And put this over the design that I did.  To me this is copyright infringement since the client did not want to buy all the rights.  But who do I address?  The client or the person that did the sign?
",user15955,https://graphicdesign.stackexchange.com/users/15955,"Did you have a contract that explicitly stated the agreement you had with the client? That would be ideal. But barring that, verbal agreements can still have some weight.

If you want to pursue this, you really need to get a lawyer involved. I'd suggest consulting a lawyer. They may consult you for free, or perhaps you may have to pay for an hour of their time. Only you can decide if it's worth that. 
",DA01,https://graphicdesign.stackexchange.com/users/306,http://graphicdesign.stackexchange.com/questions/21905/is-it-copyright-infringement-by-us-copyright-law-if-someone-else-modifies-and-us,LIFE_ARTS,graphicdesign.stackexchange.com,1.0,0.4444444444444444,0.0,0.6666666666666666,1.0,0.6666666666666666,0.6666666666666666,0.5555555555555556,1.0,0.0,1.0,1.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,0.0,1.0,0.8888888888888888,0.5555555555555556,1.0,1.0,0.8,0.6666666666666666,0.0,1.0,1.0,"If someone modifies and uses my design, does it violate American copyright law?","My company is in a small town and there are not any graphic designers but we have enough business in the town and the surrounding area to support us.  But because of the small town nature some business owners do not know all the laws.  And since I am starting this from a career in architecture I am not quite clear on copyrights.  So here is my problem.  

I created a sign that has an oval with scrolls and flowers in different colors on a field of turquoise.  The client did not want to spend the money on a logo design so I said that I will  just retain the rights so that she would have to come to me for the approval to use the logo on anything else.  So anyway everything seems to be fine, I do her business cards and now all of a sudden I see a sign at the street.  I quoted her on this job figuring in using the logo.  Apparently this company did for much less and you can tell by the quality.

But here is my problem.  She had a jpeg that I allowed her to have so she could create her own fliers and I was ok with that since it would not have made me much if any money.  Well I am looking at the sign that the other person did and all that was done is they made a longer oval since this sign is more rectangle and used a different font.  And put this over the design that I did.  To me this is copyright infringement since the client did not want to buy all the rights.  But who do I address?  The client or the person that did the sign?
","Did you have a contract that explicitly stated the agreement you had with the client? That would be ideal. But barring that, verbal agreements can still have some weight.

If you want to pursue this, you really need to get a lawyer involved. I'd suggest consulting a lawyer. They may consult you for free, or perhaps you may have to pay for an hour of their time. Only you can decide if it's worth that. 
"
4383,4383,6972,SQL VIEW Unsupported Data Type,"I'm trying to create a SQL View that pulls 2 tables together each from a different DB.  The SQL works fine in the query editor but when I try to run it as a view all the columns from the MSP_EpmProject table say ""Unsupported DataType"".

SELECT     TOP (200) dbo.Project.ProjectID, dbo.Project.ProjectGUID, dbo.Project.ProjectName, dbo.Project.DefaultBaselineID, 
                      FMM_ProjectServer_Reporting.dbo.MSP_EpmProject.ProjectName AS Expr1
FROM         dbo.Project INNER JOIN
                      FMM_ProjectServer_Reporting.dbo.MSP_EpmProject ON dbo.Project.ProjectGUID = FMM_ProjectServer_Reporting.dbo.MSP_EpmProject.ProjectUID

",user1842828,https://stackoverflow.com/users/1842828,"Check out this bug report - http://connect.microsoft.com/SQLServer/feedback/details/464339/unsupported-data-type-reported-for-supported-data-types-in-nested-query

It appears to be a long standing issue from SQL 2005 which they still havent fixed.

The work around appears to be to not work with your view in design mode, you will have to develop this view manually in query analyzer.
",EkoostikMartin,https://stackoverflow.com/users/903056,http://stackoverflow.com/questions/16362156/sql-view-unsupported-data-type,STACKOVERFLOW,stackoverflow.com,0.6666666666666666,0.6666666666666666,0.0,0.5,0.5,1.0,0.6666666666666666,0.3333333333333333,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.5,0.0,0.0,0.3333333333333333,0.6666666666666666,0.3333333333333333,0.8333333333333334,0.8333333333333334,0.5,0.5,0.0,0.5,0.8333333333333334,Data type not supported by SQL view,"I'm trying to create a SQL View that pulls 2 tables together each from a different DB.  The SQL works fine in the query editor but when I try to run it as a view all the columns from the MSP_EpmProject table say ""Unsupported DataType"".

SELECT     TOP (200) dbo.Project.ProjectID, dbo.Project.ProjectGUID, dbo.Project.ProjectName, dbo.Project.DefaultBaselineID, 
                      FMM_ProjectServer_Reporting.dbo.MSP_EpmProject.ProjectName AS Expr1
FROM         dbo.Project INNER JOIN
                      FMM_ProjectServer_Reporting.dbo.MSP_EpmProject ON dbo.Project.ProjectGUID = FMM_ProjectServer_Reporting.dbo.MSP_EpmProject.ProjectUID

","Check out this bug report - http://connect.microsoft.com/SQLServer/feedback/details/464339/unsupported-data-type-reported-for-supported-data-types-in-nested-query

It appears to be a long standing issue from SQL 2005 which they still havent fixed.

The work around appears to be to not work with your view in design mode, you will have to develop this view manually in query analyzer.
"
5189,5189,8243,IPython Qt Console doesn't have a title in GNOME app switcher,"  

When I use the app switcher in GNOME 3.16, the IPython Qt Console (version 3.1.0) doesn't have a title under its icon (see image, and compare with Chromium). I also noticed that the icon doesn't have a title in the GNOME dock, nor is it present in the GNOME bar at the top.

I thought that maybe the title would be set in the .desktop file, but then I had a look at my /usr/share/applications/ipython-qtconsole.desktop and it doesn't look any different from other applications (i.e. it has a Name label set to an IPython value).

Is there a way to add a title manually?

I'm on Arch Linux using GNOME 3.16.1.
",Stefan van den Akker,https://unix.stackexchange.com/users/73808,"This is not a solution but I know where the problem comes from.
Gnome Shell uses the WM_CLASS property to associate apps to their "".desktop"" files. Reference

IPython Qtconsole's WM_CLASS value is empty and that is why you do not see any title up there. I reported an upstream bug.

You could create a .desktop file without a name that would temporarily fix your problem but any other app with no WM_CLASS property would mapped to that one too.

cp /usr/share/applications/ipython-qtconsole.desktop .local/share/applications/.desktop

",183.amir,https://unix.stackexchange.com/users/82506,http://unix.stackexchange.com/questions/199801/ipython-qt-console-doesnt-have-a-title-in-gnome-app-switcher,TECHNOLOGY,unix.stackexchange.com,0.8888888888888888,0.6666666666666666,0.0,0.0,1.0,0.6666666666666666,0.6666666666666666,0.4444444444444444,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.7777777777777778,0.6666666666666666,0.5,0.8888888888888888,0.8888888888888888,0.6666666666666667,1.0,0.0,0.6666666666666666,0.7777777777777778,IPython QT console has no title in Gnome app switcher,"  

When I use the app switcher in GNOME 3.16, the IPython Qt Console (version 3.1.0) doesn't have a title under its icon (see image, and compare with Chromium). I also noticed that the icon doesn't have a title in the GNOME dock, nor is it present in the GNOME bar at the top.

I thought that maybe the title would be set in the .desktop file, but then I had a look at my /usr/share/applications/ipython-qtconsole.desktop and it doesn't look any different from other applications (i.e. it has a Name label set to an IPython value).

Is there a way to add a title manually?

I'm on Arch Linux using GNOME 3.16.1.
","This is not a solution but I know where the problem comes from.
Gnome Shell uses the WM_CLASS property to associate apps to their "".desktop"" files. Reference

IPython Qtconsole's WM_CLASS value is empty and that is why you do not see any title up there. I reported an upstream bug.

You could create a .desktop file without a name that would temporarily fix your problem but any other app with no WM_CLASS property would mapped to that one too.

cp /usr/share/applications/ipython-qtconsole.desktop .local/share/applications/.desktop

"
2962,2962,4711,"Are there fluid tripod heads made for panning with a lightweight, compact camera?","Are there fluid tripod heads made for use with compact or at least lightweight cameras (such as my LX100)? Most seem built to support a tank (or full-blown DSLR/video camera). 

I would like to be able to pan with my small compact.
",lara michaels,https://photo.stackexchange.com/users/37614,"A video camera tripod is different than a still photograph tripod, because it needs some resistance when panning and tilting.

It is normally more sturdy because it is expected to stay in place while you move the head. A light one will move when you pan. It does not really matter if the camera is light or heavy.

Of course if the camera is heavier you need one more reliable, in materials and construction.

If you just need a tripod for still photography, just buy one you like. But feel it first, do not buy something ""cheap"" just because.
",Rafael,https://photo.stackexchange.com/users/37321,http://photo.stackexchange.com/questions/65896/are-there-fluid-tripod-heads-made-for-panning-with-a-lightweight-compact-camera,LIFE_ARTS,photo.stackexchange.com,1.0,0.8333333333333334,0.0,1.0,1.0,1.0,0.5,0.6666666666666666,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,1.0,0.8333333333333334,0.6666666666666666,1.0,1.0,0.8,0.5,0.0,1.0,0.8333333333333334,Is there a small and light camera with tripod head for translation?,Is there a liquid tripod head for use with compact or at least lightweight cameras (like my lx100)? Most seem to support tanks (or all-around SLRs / cameras).,"A video camera tripod is different than a still photograph tripod, because it needs some resistance when panning and tilting.

It is normally more sturdy because it is expected to stay in place while you move the head. A light one will move when you pan. It does not really matter if the camera is light or heavy.

Of course if the camera is heavier you need one more reliable, in materials and construction.

If you just need a tripod for still photography, just buy one you like. But feel it first, do not buy something ""cheap"" just because.
"
5907,5907,9359,How to Enable Ports 25 - 28 on a Cisco Catalyst 3750,"I am trying to enable ports 25 - 28 on my 28 port Catalyst 3750. These four ports are my fiber ports. I am using the following command to bring up that interface.

interface range Gi1/0/25 - 28

That works and it dumps me in the config-if-interface prompt. This is where I get stuck. I just want to enable these four ports and have them be in VLAN1 and On just like ports 1 - 24.

How do I do this?
",Jared Brown,https://serverfault.com/users/99915,"Have you tried:
- a show interface gi1/0/25 capabilities to see if the switch recognizes the SFP?
- checked that the SFP type works with the fiber type you are trying to use?
- The fiber path in properly patch and consistently the same type of fiber?
- The switch on the other end has a compatible SFP as well?
- some interfaces allow speed changes to be configured, you might check that the switches are configured the same on both sides. 

I took a short LC and flipped the TX - RX, so that I can default the interface do a no shut, then plug in the tester to two interfaces on the same switch.  That will eliminate the other switch and the path if the link doesn't come up. 
",btk_,https://serverfault.com/users/51704,http://serverfault.com/questions/130710,TECHNOLOGY,serverfault.com,1.0,0.6666666666666666,0.0,0.6666666666666666,0.3333333333333333,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,0.0,0.8888888888888888,How to enable ports 25-28 on Cisco catalyst 3750,"I am trying to enable ports 25 - 28 on my 28 port Catalyst 3750. These four ports are my fiber ports. I am using the following command to bring up that interface.

interface range Gi1/0/25 - 28

That works and it dumps me in the config-if-interface prompt. This is where I get stuck. I just want to enable these four ports and have them be in VLAN1 and On just like ports 1 - 24.

How do I do this?
","Have you tried:
- a show interface gi1/0/25 capabilities to see if the switch recognizes the SFP?
- checked that the SFP type works with the fiber type you are trying to use?
- The fiber path in properly patch and consistently the same type of fiber?
- The switch on the other end has a compatible SFP as well?
- some interfaces allow speed changes to be configured, you might check that the switches are configured the same on both sides. 

I took a short LC and flipped the TX - RX, so that I can default the interface do a no shut, then plug in the tester to two interfaces on the same switch.  That will eliminate the other switch and the path if the link doesn't come up. 
"
1538,1538,2416,How do I fix my Base URLs so I can access my Magento site?,"
I changed Base Urls and now my website is inaccessible
I moved everything to a new server, didn't change the base_url and my website is inaccessible


How do I change or restore base_url my BaseURL settings?
",Fiasco Labs,https://magento.stackexchange.com/users/553,"Symptom: I changed Base Urls and now my website is inaccessible or I moved everything to a new server, didn't change the base_url and my website is inaccessible.

How to change or restore base_url settings with phpMyAdmin

Instructions are for a simple ""one store"" website where the ""default store view"" is set to inherit its setup from the ""default config"". There will be an additional instance of the below mentioned table rows for each unchecked Use Website checkbox.


Open your core_config_data table in phpMyAdmin.
Sort table by path column and find the following rows for your unsecure section, they should look like the following:


Columns

PATH                         VALUE
web/unsecure/base_url        http://www.mydomain.com/
web/unsecure/base_link_url   {{unsecure_base_url}}
web/unsecure/base_skin_url   {{unsecure_base_url}}skin/
web/unsecure/base_media_url  {{unsecure_base_url}}media/
web/unsecure/base_js_url     {{unsecure_base_url}}js/



Replace http://www.mydomain.com/ with your appropriate domain url (trailing slash necessary) and if you’ve installed in a subfolder append it with a / after it.
Find the following rows for your secure section, they should look like the following:


Columns

PATH                        VALUE
web/secure/base_url         https://www.mydomain.com/
web/secure/base_link_url    {{secure_base_url}}
web/secure/base_skin_url    {{secure_base_url}}skin/
web/secure/base_media_url   {{secure_base_url}}media/
web/secure/base_js_url      {{secure_base_url}}js/



Replace https://www.mydomain.com/ with your appropriate domain url (trailing slash necessary) and if you've installed in a subfolder append it with a / after it. If you haven't received your security certificate and enabled TLS/SSL yet, use http instead of https
Clear contents from var/cache, var/session directories after changing base_urls.


Clearing cache and sessions is necessary because your config is cached and clearing it forces a reread of the configuration data from the core_config_data table and reestablishment of sessions with the proper information.

NOTE: If you have set your base_url correctly for web/unsecure/base_url and web/secure/base_url you do not have to mess around with changing the {{UNSECURE_BASE_URL}} and {{SECURE_BASE_URL}} macros in the rest of the entries.

How to change base_url settings with mysql from the command line


Log into your MySQL database, replace $USER with your database user name and $DBASE with your database name. It will prompt you for your password:


mysql -u $USER -p $DBASE


Below are the SQL commands to change your base_url values. Replace unsecure http://www.mydomain.com/ and secure https://www.mydomain.com/ (if you have SSL/TLS enabled, else https should be http) with your appropriate domain url (trailing slash necessary) and if you’ve installed in a subfolder append it with a / after it.


SQL Commands

UPDATE core_config_data SET value = 'http://www.example.com/' WHERE path LIKE 'web/unsecure/base_url';
UPDATE core_config_data SET value = 'https://www.example.com/' WHERE path LIKE 'web/secure/base_url';



Check your base_url settings with the following:


SQL Commands

SELECT path,value FROM core_config_data WHERE path LIKE 'web/unsecure/base%';
SELECT path,value FROM core_config_data WHERE path LIKE 'web/secure/base%';&lt;/code&gt;



Clear contents from var/cache, var/session directories after changing base_urls. Clearing cache and sessions is necessary because your config is cached and clearing it forces a reread of the configuration data from the core_config_data table and reestablishment of sessions with the proper information.

",Fiasco Labs,https://magento.stackexchange.com/users/553,http://magento.stackexchange.com/questions/39752/how-do-i-fix-my-base-urls-so-i-can-access-my-magento-site,TECHNOLOGY,magento.stackexchange.com,0.8888888888888888,0.7777777777777778,0.0,1.0,0.6666666666666666,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,1.0,How can I fix my basic website so that I can visit my Magento website?,"
I changed Base Urls and now my website is inaccessible
I moved everything to a new server, didn't change the base_url and my website is inaccessible


How do I change or restore base_url my BaseURL settings?
","Symptom: I changed Base Urls and now my website is inaccessible or I moved everything to a new server, didn't change the base_url and my website is inaccessible.

How to change or restore base_url settings with phpMyAdmin

Instructions are for a simple ""one store"" website where the ""default store view"" is set to inherit its setup from the ""default config"". There will be an additional instance of the below mentioned table rows for each unchecked Use Website checkbox.


Open your core_config_data table in phpMyAdmin.
Sort table by path column and find the following rows for your unsecure section, they should look like the following:


Columns

PATH                         VALUE
web/unsecure/base_url        http://www.mydomain.com/
web/unsecure/base_link_url   {{unsecure_base_url}}
web/unsecure/base_skin_url   {{unsecure_base_url}}skin/
web/unsecure/base_media_url  {{unsecure_base_url}}media/
web/unsecure/base_js_url     {{unsecure_base_url}}js/



Replace http://www.mydomain.com/ with your appropriate domain url (trailing slash necessary) and if you’ve installed in a subfolder append it with a / after it.
Find the following rows for your secure section, they should look like the following:


Columns

PATH                        VALUE
web/secure/base_url         https://www.mydomain.com/
web/secure/base_link_url    {{secure_base_url}}
web/secure/base_skin_url    {{secure_base_url}}skin/
web/secure/base_media_url   {{secure_base_url}}media/
web/secure/base_js_url      {{secure_base_url}}js/



Replace https://www.mydomain.com/ with your appropriate domain url (trailing slash necessary) and if you've installed in a subfolder append it with a / after it. If you haven't received your security certificate and enabled TLS/SSL yet, use http instead of https
Clear contents from var/cache, var/session directories after changing base_urls.


Clearing cache and sessions is necessary because your config is cached and clearing it forces a reread of the configuration data from the core_config_data table and reestablishment of sessions with the proper information.

NOTE: If you have set your base_url correctly for web/unsecure/base_url and web/secure/base_url you do not have to mess around with changing the {{UNSECURE_BASE_URL}} and {{SECURE_BASE_URL}} macros in the rest of the entries.

How to change base_url settings with mysql from the command line


Log into your MySQL database, replace $USER with your database user name and $DBASE with your database name. It will prompt you for your password:


mysql -u $USER -p $DBASE


Below are the SQL commands to change your base_url values. Replace unsecure http://www.mydomain.com/ and secure https://www.mydomain.com/ (if you have SSL/TLS enabled, else https should be http) with your appropriate domain url (trailing slash necessary) and if you’ve installed in a subfolder append it with a / after it.


SQL Commands

UPDATE core_config_data SET value = 'http://www.example.com/' WHERE path LIKE 'web/unsecure/base_url';
UPDATE core_config_data SET value = 'https://www.example.com/' WHERE path LIKE 'web/secure/base_url';



Check your base_url settings with the following:


SQL Commands

SELECT path,value FROM core_config_data WHERE path LIKE 'web/unsecure/base%';
SELECT path,value FROM core_config_data WHERE path LIKE 'web/secure/base%';&lt;/code&gt;



Clear contents from var/cache, var/session directories after changing base_urls. Clearing cache and sessions is necessary because your config is cached and clearing it forces a reread of the configuration data from the core_config_data table and reestablishment of sessions with the proper information.

"
1354,1354,2133,Solving a two point boundary problem for a piecewise system of equations,"I'm trying to solve a two point boundary value problem with a piecewise system of equations like:

dx[t_] := Piecewise[{{0, y[t] &lt;= 0}, {x[t]^(3/4) - x[t], y[t] &gt; 0}}]
dy[t_] := Piecewise[{{0, y[t] &lt;= 0}, {(1 - y[t])/x[t]^(1/4) + y[t], y[t] &gt; 0}}]

NDSolve[{x'[t] == dx[t], y'[t] == dy[t], x[0] == 1, y[10] == 2}, {x, y}, {t, 0, 10}]


which produces the error

 NDSolve::bvdisc: NDSolve is not currently able to solve boundary value problems with discrete variables.


I tried the answers here by entering

funs = ParametricNDSolveValue[{x'[t] == dx[t], y'[t] == dy[t], x[0] == 1, y[10] == yt}, {x, y}, {t, 0, end}, yt]

FindRoot[funs[yt][end], {yt, 2}]


which yields the same error.

Is there any way to solve this system? Thanks for the help.
",Mauricio,https://mathematica.stackexchange.com/users/19635,"Here is now the - hopefully - correct (numeric) solution of the original problem.

To begin with, we define a time t0 such that y = 0 for 0&lt;=t&lt;=t0. 

Für x(t) we have x(t) = 1 for  0&lt;=t&lt;=t0, otherwise we have first to solve the equation

sx = DSolve[x'[t] == x[t]^(3/4) - x[t] &amp;&amp; x[0] == 1, x[t], t]


We can ignore the error Messages.

(* Out[701]= {{x[t] -&gt; E^-t (-2 + E^(t/4))^4}, {x[t] -&gt; 
   E^-t ((-1 - I) + E^(t/4))^4}, {x[t] -&gt; E^-t ((-1 + I) + E^(t/4))^4}} *)


Taking the real-valued solution:

x[t] /. sx[[1]]

(* Out[700]= E^-t (-2 + E^(t/4))^4 *)


Having caluclated that, we now define the complete function x[t,t0]

x[t_, t0_] := E^(-t + t0) (-2 + E^((t - t0)/4))^4 /; t &gt; t0

x[t_, t0_] := 1 /; 0 &lt;= t &lt;= t0


Plotting it (for t0 = 5)

Plot[{x[t, 5]}, {t, 0, 30}, PlotRange -&gt; {0, 1}]




Now inserting x[t,t0] we can NDSolve for y(t).
Here we have selected the parameter t0 by trial and error such that y[10]=2

t0 = 1.03214; 
ta = 0;
te = 12;
sn = NDSolve[{D[y[t], t] == 1 - y[t] (1/x[t, t0]^(1/4) - 1), y[t0] == 0}, 
    y[t], {t, ta, te}][[1]];
{ta, te} = Head[(List @@ sn[[1]])[[2]]][[1, 1]];
yy[t_] = y[t] /. sn;
Print[""y[10] = "", yy[10]];
Plot[{2, Evaluate[x[t, t0]], yy[t]}, {t, ta, te}, PlotRange -&gt; {-1, 2.2}, 
 PlotLabel -&gt; 
  ""Solution of the two-point boundary problem\nred curve = x(t), green curve \
= y(t)\nt0 = "" &lt;&gt; ToString[t0] &lt;&gt; ""\ty(10) = "" &lt;&gt; ToString[yy[10]]]

y[10] = 2.




Of course, y(t) must be set to zero below t=t0. This is trivial and not shown in the picture.

This seems to be the only solution. For greater values of t0 the boundary value y(10) decreases, and for smaller it increases.

Regards,
Wolfgang
",Dr. Wolfgang Hintze,https://mathematica.stackexchange.com/users/16361,http://mathematica.stackexchange.com/questions/59205/solving-a-two-point-boundary-problem-for-a-piecewise-system-of-equations,TECHNOLOGY,mathematica.stackexchange.com,0.8888888888888888,0.4444444444444444,0.0,0.3333333333333333,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.8888888888888888,The solution of two point boundary value problem of piecewise equations,"I'm trying to solve a two point boundary value problem with a piecewise system of equations like:

dx[t_] := Piecewise[{{0, y[t] &lt;= 0}, {x[t]^(3/4) - x[t], y[t] &gt; 0}}]
dy[t_] := Piecewise[{{0, y[t] &lt;= 0}, {(1 - y[t])/x[t]^(1/4) + y[t], y[t] &gt; 0}}]

NDSolve[{x'[t] == dx[t], y'[t] == dy[t], x[0] == 1, y[10] == 2}, {x, y}, {t, 0, 10}]


which produces the error

 NDSolve::bvdisc: NDSolve is not currently able to solve boundary value problems with discrete variables.


I tried the answers here by entering

funs = ParametricNDSolveValue[{x'[t] == dx[t], y'[t] == dy[t], x[0] == 1, y[10] == yt}, {x, y}, {t, 0, end}, yt]

FindRoot[funs[yt][end], {yt, 2}]


which yields the same error.

Is there any way to solve this system? Thanks for the help.
","Here is now the - hopefully - correct (numeric) solution of the original problem.

To begin with, we define a time t0 such that y = 0 for 0&lt;=t&lt;=t0. 

Für x(t) we have x(t) = 1 for  0&lt;=t&lt;=t0, otherwise we have first to solve the equation

sx = DSolve[x'[t] == x[t]^(3/4) - x[t] &amp;&amp; x[0] == 1, x[t], t]


We can ignore the error Messages.

(* Out[701]= {{x[t] -&gt; E^-t (-2 + E^(t/4))^4}, {x[t] -&gt; 
   E^-t ((-1 - I) + E^(t/4))^4}, {x[t] -&gt; E^-t ((-1 + I) + E^(t/4))^4}} *)


Taking the real-valued solution:

x[t] /. sx[[1]]

(* Out[700]= E^-t (-2 + E^(t/4))^4 *)


Having caluclated that, we now define the complete function x[t,t0]

x[t_, t0_] := E^(-t + t0) (-2 + E^((t - t0)/4))^4 /; t &gt; t0

x[t_, t0_] := 1 /; 0 &lt;= t &lt;= t0


Plotting it (for t0 = 5)

Plot[{x[t, 5]}, {t, 0, 30}, PlotRange -&gt; {0, 1}]




Now inserting x[t,t0] we can NDSolve for y(t).
Here we have selected the parameter t0 by trial and error such that y[10]=2

t0 = 1.03214; 
ta = 0;
te = 12;
sn = NDSolve[{D[y[t], t] == 1 - y[t] (1/x[t, t0]^(1/4) - 1), y[t0] == 0}, 
    y[t], {t, ta, te}][[1]];
{ta, te} = Head[(List @@ sn[[1]])[[2]]][[1, 1]];
yy[t_] = y[t] /. sn;
Print[""y[10] = "", yy[10]];
Plot[{2, Evaluate[x[t, t0]], yy[t]}, {t, ta, te}, PlotRange -&gt; {-1, 2.2}, 
 PlotLabel -&gt; 
  ""Solution of the two-point boundary problem\nred curve = x(t), green curve \
= y(t)\nt0 = "" &lt;&gt; ToString[t0] &lt;&gt; ""\ty(10) = "" &lt;&gt; ToString[yy[10]]]

y[10] = 2.




Of course, y(t) must be set to zero below t=t0. This is trivial and not shown in the picture.

This seems to be the only solution. For greater values of t0 the boundary value y(10) decreases, and for smaller it increases.

Regards,
Wolfgang
"
5637,5637,8937,Using VBA to change Picture,"I am trying to use VBA to automate the Change Picture function when you right click a Shape in Excel/Word/Powerpoint.

However, I am not able to find any reference, can you assist?
",PlayKid,https://stackoverflow.com/users/52590,"So far as I know you can't change the source of a picture, you need to delete the old one and insert a new one

Here's a start

strPic =""Picture Name""
Set shp = ws.Shapes(strPic)

'Capture properties of exisitng picture such as location and size
With shp
    t = .Top
    l = .Left
    h = .Height
    w = .Width
End With

ws.Shapes(strPic).Delete

Set shp = ws.Shapes.AddPicture(""Y:\our\Picture\Path\And\File.Name"", msoFalse, msoTrue, l, t, w, h)
shp.Name = strPic
shp.ScaleHeight Factor:=1, RelativeToOriginalSize:=msoTrue
shp.ScaleWidth Factor:=1, RelativeToOriginalSize:=msoTrue

",chris neilsen,https://stackoverflow.com/users/445425,http://stackoverflow.com/questions/10169011/using-vba-to-change-picture,STACKOVERFLOW,stackoverflow.com,1.0,0.6666666666666666,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.3333333333333333,0.3333333333333333,1.0,Change pictures with VBA,"When you right-click a shape in Excel / word / Powerpoint, I'm trying to use VBA to automatically change pictures.","So far as I know you can't change the source of a picture, you need to delete the old one and insert a new one

Here's a start

strPic =""Picture Name""
Set shp = ws.Shapes(strPic)

'Capture properties of exisitng picture such as location and size
With shp
    t = .Top
    l = .Left
    h = .Height
    w = .Width
End With

ws.Shapes(strPic).Delete

Set shp = ws.Shapes.AddPicture(""Y:\our\Picture\Path\And\File.Name"", msoFalse, msoTrue, l, t, w, h)
shp.Name = strPic
shp.ScaleHeight Factor:=1, RelativeToOriginalSize:=msoTrue
shp.ScaleWidth Factor:=1, RelativeToOriginalSize:=msoTrue

"
4839,4839,7700,"Can using ""@inherits"" solve my editor templates IEnumerable headaches?","I think it might be easier to explain by showing some code and explaining as I go along:

Create Product ViewModel:

[UIHint(""Prices"")]
public IList&lt;CreatePricesViewModel&gt; Prices { get; set; }


With this, I want the ability to use an ajax call to add another set of prices for a different currency to the product.

Create Prices ViewModel:

[DataType(DataType.Currency)]
[DisplayName(""Wholesale Price: "")]
public decimal Wholesale { get; set; }

[DataType(DataType.Currency)]
[Required]
[DisplayName(""Retail Price: "")]
public decimal Retail { get; set; }

[DataType(DataType.Currency)]
[DisplayName(""Discounted Price: "")]
public decimal Discount { get; set; }


In my controller I create a single CreatePricesViewModel and add it to the CreateProductViewModels list of CreatePricesViewModel's so there is at least one available instance to render in the view.

Create Product View:

@model CumbriaMD.Infrastructure.ViewModels.ProductViewModels.CreateProductViewModel 
......
&lt;div class=""editor-field""&gt;
    @Html.EditorFor(model =&gt; model.Prices)
    @Html.ValidationMessageFor(model =&gt; model.Prices)
&lt;/div&gt;


Prices EditorFor Templates:

This is where I'm struggling really. When I strongly-type to the CreatePricesViewModel I get a complaint because I'm passing in an IEnumerable of type CreatePricesViewModel instead of a single instance - but when I use a foreach loop my id and names are messed up so the model-binding fails? Can using @inherits here help?

@model CumbriaMD.Infrastructure.ViewModels.PriceViewModels.CreatePricesViewModel

&lt;div class=""editor-label""&gt;
   @Html.LabelFor(model =&gt; model.Wholesale)
&lt;/div&gt;
&lt;div class=""editor-field""&gt;
   @Html.EditorFor(model =&gt; model.Wholesale)
   @Html.ValidationMessageFor(model =&gt; model.Wholesale)
&lt;/div&gt;
&lt;div class=""editor-label""&gt;
   @Html.LabelFor(model =&gt; model.Retail)
&lt;/div&gt;
&lt;div class=""editor-field""&gt;
  @Html.EditorFor(model =&gt; model.Retail)
  @Html.ValidationMessageFor(model =&gt; model.Retail)
&lt;/div&gt;
&lt;div class=""editor-label""&gt;
  @Html.LabelFor(model =&gt; model.Discount)
&lt;/div&gt;   
&lt;div class=""editor-field""&gt;
  @Html.EditorFor(model =&gt; model.Discount)
  @Html.ValidationMessageFor(model =&gt; model.Discount)
&lt;/div&gt;  

",Kiada,https://stackoverflow.com/users/304554,"No, @inherits cannot solve your headaches.

When using UIHint, the entire enumerable is passed, so you need to make your template strongly typed to the list:

@model IEnumerable&lt;CumbriaMD.Infrastructure.ViewModels.PriceViewModels.CreatePricesViewModel&gt;
@foreach(var item in Model)
{
    @Html.Partial(""_SomePrice"", item)
}


and then define _SomePrice.cshtml partial:

@model CumbriaMD.Infrastructure.ViewModels.PriceViewModels.CreatePricesViewModel

&lt;div class=""editor-label""&gt;
   @Html.LabelFor(model =&gt; model.Wholesale)
&lt;/div&gt;
&lt;div class=""editor-field""&gt;
   @Html.EditorFor(model =&gt; model.Wholesale)
   @Html.ValidationMessageFor(model =&gt; model.Wholesale)
&lt;/div&gt;
&lt;div class=""editor-label""&gt;
   @Html.LabelFor(model =&gt; model.Retail)
&lt;/div&gt;
&lt;div class=""editor-field""&gt;
  @Html.EditorFor(model =&gt; model.Retail)
  @Html.ValidationMessageFor(model =&gt; model.Retail)
&lt;/div&gt;
&lt;div class=""editor-label""&gt;
  @Html.LabelFor(model =&gt; model.Discount)
&lt;/div&gt;   
&lt;div class=""editor-field""&gt;
  @Html.EditorFor(model =&gt; model.Discount)
  @Html.ValidationMessageFor(model =&gt; model.Discount)
&lt;/div&gt;  


This is not necessary when you don't use the UIHint attribute => the editor template is automatically invoked for each element of the Prices collection. It sucks but it's how it is.
",Darin Dimitrov,https://stackoverflow.com/users/29407,http://stackoverflow.com/questions/12041229/can-using-inherits-solve-my-editor-templates-ienumerable-headaches,STACKOVERFLOW,stackoverflow.com,1.0,1.0,0.0,1.0,1.0,1.0,0.5,0.3333333333333333,0.5,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.5,0.0,0.5,0.0,0.8333333333333334,1.0,0.6666666666666666,1.0,1.0,1.0,0.5,0.0,0.5,1.0,"Can I use ""@ inherits"" to solve countless problems with my editor templates?","I think it might be easier to explain by showing some code and explaining as I go along:

Create Product ViewModel:

[UIHint(""Prices"")]
public IList&lt;CreatePricesViewModel&gt; Prices { get; set; }


With this, I want the ability to use an ajax call to add another set of prices for a different currency to the product.

Create Prices ViewModel:

[DataType(DataType.Currency)]
[DisplayName(""Wholesale Price: "")]
public decimal Wholesale { get; set; }

[DataType(DataType.Currency)]
[Required]
[DisplayName(""Retail Price: "")]
public decimal Retail { get; set; }

[DataType(DataType.Currency)]
[DisplayName(""Discounted Price: "")]
public decimal Discount { get; set; }


In my controller I create a single CreatePricesViewModel and add it to the CreateProductViewModels list of CreatePricesViewModel's so there is at least one available instance to render in the view.

Create Product View:

@model CumbriaMD.Infrastructure.ViewModels.ProductViewModels.CreateProductViewModel 
......
&lt;div class=""editor-field""&gt;
    @Html.EditorFor(model =&gt; model.Prices)
    @Html.ValidationMessageFor(model =&gt; model.Prices)
&lt;/div&gt;


Prices EditorFor Templates:

This is where I'm struggling really. When I strongly-type to the CreatePricesViewModel I get a complaint because I'm passing in an IEnumerable of type CreatePricesViewModel instead of a single instance - but when I use a foreach loop my id and names are messed up so the model-binding fails? Can using @inherits here help?

@model CumbriaMD.Infrastructure.ViewModels.PriceViewModels.CreatePricesViewModel

&lt;div class=""editor-label""&gt;
   @Html.LabelFor(model =&gt; model.Wholesale)
&lt;/div&gt;
&lt;div class=""editor-field""&gt;
   @Html.EditorFor(model =&gt; model.Wholesale)
   @Html.ValidationMessageFor(model =&gt; model.Wholesale)
&lt;/div&gt;
&lt;div class=""editor-label""&gt;
   @Html.LabelFor(model =&gt; model.Retail)
&lt;/div&gt;
&lt;div class=""editor-field""&gt;
  @Html.EditorFor(model =&gt; model.Retail)
  @Html.ValidationMessageFor(model =&gt; model.Retail)
&lt;/div&gt;
&lt;div class=""editor-label""&gt;
  @Html.LabelFor(model =&gt; model.Discount)
&lt;/div&gt;   
&lt;div class=""editor-field""&gt;
  @Html.EditorFor(model =&gt; model.Discount)
  @Html.ValidationMessageFor(model =&gt; model.Discount)
&lt;/div&gt;  

","No, @inherits cannot solve your headaches.

When using UIHint, the entire enumerable is passed, so you need to make your template strongly typed to the list:

@model IEnumerable&lt;CumbriaMD.Infrastructure.ViewModels.PriceViewModels.CreatePricesViewModel&gt;
@foreach(var item in Model)
{
    @Html.Partial(""_SomePrice"", item)
}


and then define _SomePrice.cshtml partial:

@model CumbriaMD.Infrastructure.ViewModels.PriceViewModels.CreatePricesViewModel

&lt;div class=""editor-label""&gt;
   @Html.LabelFor(model =&gt; model.Wholesale)
&lt;/div&gt;
&lt;div class=""editor-field""&gt;
   @Html.EditorFor(model =&gt; model.Wholesale)
   @Html.ValidationMessageFor(model =&gt; model.Wholesale)
&lt;/div&gt;
&lt;div class=""editor-label""&gt;
   @Html.LabelFor(model =&gt; model.Retail)
&lt;/div&gt;
&lt;div class=""editor-field""&gt;
  @Html.EditorFor(model =&gt; model.Retail)
  @Html.ValidationMessageFor(model =&gt; model.Retail)
&lt;/div&gt;
&lt;div class=""editor-label""&gt;
  @Html.LabelFor(model =&gt; model.Discount)
&lt;/div&gt;   
&lt;div class=""editor-field""&gt;
  @Html.EditorFor(model =&gt; model.Discount)
  @Html.ValidationMessageFor(model =&gt; model.Discount)
&lt;/div&gt;  


This is not necessary when you don't use the UIHint attribute => the editor template is automatically invoked for each element of the Prices collection. It sucks but it's how it is.
"
5438,5438,8631,Create and open file with one command?,"I want to create a text file and open it in a text editor with a single command.

I know touch file.txt creates a file and open file.txt opens the file, but is there a way to do this with a single command?
",Marcus McLean,https://unix.stackexchange.com/users/36377,"Use vim. Just type 

vim newfile.txt


For vim you need to know the hot-keys.

i   - Insert text in the file
esc - return to the command-input-mode
:w  - Write (save)
:q  - Quit (exit)


or (Easier to use Nano):

nano newfile.txt


If you want a GUI type: (Works for ubuntu and other distros)

gedit newfile.txt

",AAlvz,https://unix.stackexchange.com/users/31772,http://unix.stackexchange.com/questions/70973/create-and-open-file-with-one-command,TECHNOLOGY,unix.stackexchange.com,1.0,0.7777777777777778,0.0,1.0,1.0,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.6666666666666666,0.0,0.6666666666666666,1.0,Create and open a file with one command?,"I want to create a text file and open it in a text editor with a single command.

I know touch file.txt creates a file and open file.txt opens the file, but is there a way to do this with a single command?
","Use vim. Just type 

vim newfile.txt


For vim you need to know the hot-keys.

i   - Insert text in the file
esc - return to the command-input-mode
:w  - Write (save)
:q  - Quit (exit)


or (Easier to use Nano):

nano newfile.txt


If you want a GUI type: (Works for ubuntu and other distros)

gedit newfile.txt

"
950,950,1506,Can I restrict a vhost to only a local IP?,"I have a subdomain I'd like to only be accessible by a local IP address.  Is it possible to specify this in the vhost?  I'm thinking it's not since I haven't found much on Google.  If not, what's the best way to do this on an apache level?  I forget the version of Linux we're using... but we have Samba running on it.

The site I'm trying to restrict is our site's documentation.
",Webnet,https://serverfault.com/users/37222,"You can definetly disable access to a directory based on IP with mod_access (included in most linux distributions):

i.e.

&lt;Directory /docroot&gt;
 Order Deny,Allow
 Deny from all
 Allow from 10.1.2.0/24 
&lt;/Directory&gt;


If you block the access to the whole document root for that vhost then the user from outside should not get more than 403 Forbidden all the time.
",Radek Hladík,https://serverfault.com/users/98204,http://serverfault.com/questions/323610,TECHNOLOGY,serverfault.com,0.8888888888888888,0.6666666666666666,0.0,1.0,1.0,1.0,0.5555555555555556,0.5555555555555556,0.3333333333333333,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.6666666666666666,0.3333333333333333,0.0,0.7777777777777778,Can I limit Vhost to local IP only?,"I have a subdomain, which I hope can only be accessed through the local IP address. Can I specify it in Vhost? I don't think it's because I didn't find anything on Google. If not, what's the best way to do it at the Apache level? I forgot the Linux version we were using... But there's Samba on it.","You can definetly disable access to a directory based on IP with mod_access (included in most linux distributions):

i.e.

&lt;Directory /docroot&gt;
 Order Deny,Allow
 Deny from all
 Allow from 10.1.2.0/24 
&lt;/Directory&gt;


If you block the access to the whole document root for that vhost then the user from outside should not get more than 403 Forbidden all the time.
"
1314,1314,2077,"What do you call a customer's customer in a specification document, use case, or scenario?","My team and I develop software that our customers will use to interact with their customers.  Additionally, we also eat our own dogfood and use the software ourselves to interact with our customers.

Therefore, it can sometimes be difficult to explain use cases and scenarios, as our employees can be operators, our customers can be operators, and our customers' customers can be visitors.

However, our customers can also be visitors interacting with our operator employees, our customers' customers can be visitors interacting with our customer or our employee.

Here is a model where:

A is an employee
B is a customer
C is our customers' customer

X  interacts with  Y
Operator --&gt; Visitor
      A  --&gt;  B
      A  --&gt;  C
      B  --&gt;  C


Because sometimes our customers can play different roles, it's sometimes necessary to refer to the specific role, Operator or Visitor, instead of Employee and Customer.

It's also a mouthful to say ""customer's customer"" all the time.

I was wondering how other development shops handle these semantic details when writing their use cases and scenarios.  


Are there any one-word, generic terms that can apply to any product that involves a third-level actor?
Other than using the specific roles, Operator and Visitor, what words could be used to identify a customer of a customer?  


The word would need to be short enough as to be adopted within an organization.  If longer than a couple syllables, it's shortened form must still differentiate it from the other actors.
",jmort253,https://programmers.stackexchange.com/users/12611,"Maybe a bit of a tangent but...

I'm fond of interaction design myself, and there you never use abstract ""roles"" or ""users"" but something called ""personas"". Basically you make a up a character with a name, description and photograph and then you use that in your design process

""Bob is a bank manager in his middle years, he has some computer experience but is not especially fond of them.""

Then in your project you can use their real names ""No, Bob wouldn't want that"" , ""If Bob does this then Alice needs to be notified somehow"". Personas are especially useful when you're doing scenarios.

I'd highly recommend The inmates are running the asylum and About face
",Homde,https://programmers.stackexchange.com/users/12354,http://programmers.stackexchange.com/questions/37973/what-do-you-call-a-customers-customer-in-a-specification-document-use-case-or,TECHNOLOGY,programmers.stackexchange.com,1.0,1.0,0.0,1.0,1.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.8,0.0,0.0,0.0,1.0,"What do you call a customer in a specification document, use case, or scenario?","My team and I develop software that our customers will use to interact with their customers.  Additionally, we also eat our own dogfood and use the software ourselves to interact with our customers.

Therefore, it can sometimes be difficult to explain use cases and scenarios, as our employees can be operators, our customers can be operators, and our customers' customers can be visitors.

However, our customers can also be visitors interacting with our operator employees, our customers' customers can be visitors interacting with our customer or our employee.

Here is a model where:

A is an employee
B is a customer
C is our customers' customer

X  interacts with  Y
Operator --&gt; Visitor
      A  --&gt;  B
      A  --&gt;  C
      B  --&gt;  C


Because sometimes our customers can play different roles, it's sometimes necessary to refer to the specific role, Operator or Visitor, instead of Employee and Customer.

It's also a mouthful to say ""customer's customer"" all the time.

I was wondering how other development shops handle these semantic details when writing their use cases and scenarios.  


Are there any one-word, generic terms that can apply to any product that involves a third-level actor?
Other than using the specific roles, Operator and Visitor, what words could be used to identify a customer of a customer?  


The word would need to be short enough as to be adopted within an organization.  If longer than a couple syllables, it's shortened form must still differentiate it from the other actors.
","Maybe a bit of a tangent but...

I'm fond of interaction design myself, and there you never use abstract ""roles"" or ""users"" but something called ""personas"". Basically you make a up a character with a name, description and photograph and then you use that in your design process

""Bob is a bank manager in his middle years, he has some computer experience but is not especially fond of them.""

Then in your project you can use their real names ""No, Bob wouldn't want that"" , ""If Bob does this then Alice needs to be notified somehow"". Personas are especially useful when you're doing scenarios.

I'd highly recommend The inmates are running the asylum and About face
"
1858,1858,2953,"Java access to protected member in subclass in different package, using object reference of parent type","I have the following code in two separate files.

package animal;

public class Frog
{
    protected void ribbit()
    {
        System.out.println(""In Frog class!"");
    }
}





package other;

import animal.*;

public class Tadpole extends Frog

{
    protected void ribbit()
    {
        System.out.println(""In Tadpole class!"");
    }

    public static void main(String[] args)
    {
        Tadpole t = new Tadpole();
        t.ribbit();

        Frog f = new Tadpole();
        f.ribbit(); // Does not compile
    }
}


The first Tadpole object assigned to Tadpole type obviously compiles fine and the call to ribbit() will be to the Tadpole's ribbit() implementation. The second Tadpole object that is created and assigned to a Frog reference. However, the call to ribbit() results in a compiler error. 

I know that if you create a subclass object in the subclass and assign to a superclass reference that is outside of the subclass's package and try to call a superclass method, this is not allowed. But in this case, shouldn't polymorphism make the object reference ""f"" call the Tadpole's ribbit() method since a Tadpole object was assigned to it? Why does this cause a compiler error and why is this is not allowed?
",Index Hacker,https://stackoverflow.com/users/1163968,"Just for simple understanding, method overriding is runtime feature . This is obtained in run time and compiler do not care about this during compilation. So your code has to be compiler compliance . So your compilation fails because the method is not accessible from other package during compilation ( despite the fact that it would be available during run time as it inherits the Frog class).
",Selene,https://stackoverflow.com/users/5213582,http://stackoverflow.com/questions/31995632/java-access-to-protected-member-in-subclass-in-different-package-using-object-r,STACKOVERFLOW,stackoverflow.com,0.6666666666666666,0.3333333333333333,0.0,1.0,0.6666666666666666,1.0,0.5555555555555556,0.3333333333333333,0.3333333333333333,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8,0.0,0.0,1.0,0.4444444444444444,Java access to protected members in subclasses of different packages using object references of the parent type,"I have the following code in two separate files.

package animal;

public class Frog
{
    protected void ribbit()
    {
        System.out.println(""In Frog class!"");
    }
}





package other;

import animal.*;

public class Tadpole extends Frog

{
    protected void ribbit()
    {
        System.out.println(""In Tadpole class!"");
    }

    public static void main(String[] args)
    {
        Tadpole t = new Tadpole();
        t.ribbit();

        Frog f = new Tadpole();
        f.ribbit(); // Does not compile
    }
}


The first Tadpole object assigned to Tadpole type obviously compiles fine and the call to ribbit() will be to the Tadpole's ribbit() implementation. The second Tadpole object that is created and assigned to a Frog reference. However, the call to ribbit() results in a compiler error. 

I know that if you create a subclass object in the subclass and assign to a superclass reference that is outside of the subclass's package and try to call a superclass method, this is not allowed. But in this case, shouldn't polymorphism make the object reference ""f"" call the Tadpole's ribbit() method since a Tadpole object was assigned to it? Why does this cause a compiler error and why is this is not allowed?
","Just for simple understanding, method overriding is runtime feature . This is obtained in run time and compiler do not care about this during compilation. So your code has to be compiler compliance . So your compilation fails because the method is not accessible from other package during compilation ( despite the fact that it would be available during run time as it inherits the Frog class).
"
3360,3360,5361,Create and open file with one command?,"I want to create a text file and open it in a text editor with a single command.

I know touch file.txt creates a file and open file.txt opens the file, but is there a way to do this with a single command?
",Marcus McLean,https://unix.stackexchange.com/users/36377,"If you are looking for some logic for this, ie. create a file and open if possible you could use something like this:

touch testFile &amp;&amp; vi testFile


Here testFile is created with touch. The &amp;&amp; part says if the creation was successful then open it with vi.

Also, you could just create a new file with something like vi, while opening it at the same time (this assumes you save the file after editing it).

vi testFile

",BriGuy,https://unix.stackexchange.com/users/34433,http://unix.stackexchange.com/questions/70973/create-and-open-file-with-one-command,TECHNOLOGY,unix.stackexchange.com,0.8888888888888888,0.4444444444444444,0.0,0.3333333333333333,1.0,1.0,0.7777777777777778,0.6666666666666666,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.6666666666666666,0.0,0.0,0.8888888888888888,Create and open a file with one command?,"I want to create a text file and open it in a text editor with a single command.

I know touch file.txt creates a file and open file.txt opens the file, but is there a way to do this with a single command?
","If you are looking for some logic for this, ie. create a file and open if possible you could use something like this:

touch testFile &amp;&amp; vi testFile


Here testFile is created with touch. The &amp;&amp; part says if the creation was successful then open it with vi.

Also, you could just create a new file with something like vi, while opening it at the same time (this assumes you save the file after editing it).

vi testFile

"
5989,5989,9494,"Google Fonts loading on desktop, but not on mobile?","Per Google PageSpeed's recommendation, I inlined much of my CSS. Previously, I had minified all of my CSS through W3 Total Cache, but now I inlined much of my CSS, plus all of the CSS that controls Google Fonts. 

Now Google Fonts aren't appearing on mobile devices, but they do appear on desktops. Any reason why this is the case? The mobile screen cap here shows the fonts not loading.

&lt;style&gt;@font-face{font-family:'Pathway Gothic One';font-style:normal;font-weight:400;src:local('Pathway Gothic One'),local(PathwayGothicOne-Regular),url(https://fonts.gstatic.com/s/pathwaygothicone/v4/Lqv9ztoTUV8Q0FmQZzPqaA6LSHyyJAN5JIFgwWnj0Az3rGVtsTkPsbDajuO5ueQw.woff2) format(""woff2"");unicode-range:U+0100-024F,U+1E00-1EFF,U+20A0-20AB,U+20AD-20CF,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Pathway Gothic One';font-style:normal;font-weight:400;src:local('Pathway Gothic One'),local(PathwayGothicOne-Regular),url(https://fonts.gstatic.com/s/pathwaygothicone/v4/Lqv9ztoTUV8Q0FmQZzPqaHT0-GP0evTJPrdxn7U7ioo.woff2) format(""woff2"");unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2212,U+2215,U+E0FF,U+EFFD,U+F000}@font-face{font-family:'Quicksand';font-style:normal;font-weight:400;src:local('Quicksand Regular'),local(Quicksand-Regular),url(https://fonts.gstatic.com/s/quicksand/v5/sKd0EMYPAh5PYCRKSryvW5Bw1xU1rKptJj_0jans920.woff2) format(""woff2"");unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2212,U+2215,U+E0FF,U+EFFD,U+F000}@font-face{font-family:'Roboto Condensed';font-style:normal;font-weight:400;src:local('Roboto Condensed'),local(RobotoCondensed-Regular),url(https://fonts.gstatic.com/s/robotocondensed/v13/Zd2E9abXLFGSr9G3YK2MsIPxuqWfQuZGbz5Rz4Zu1gk.woff2) format(""woff2"");unicode-range:U+0460-052F,U+20B4,U+2DE0-2DFF,U+A640-A69F}@font-face{font-family:'Roboto Condensed';font-style:normal;font-weight:400;src:local('Roboto Condensed'),local(RobotoCondensed-Regular),url(https://fonts.gstatic.com/s/robotocondensed/v13/Zd2E9abXLFGSr9G3YK2MsENRpQQ4njX3CLaCqI4awdk.woff2) format(""woff2"");unicode-range:U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Roboto Condensed';font-style:normal;font-weight:400;src:local('Roboto Condensed'),local(RobotoCondensed-Regular),url(https://fonts.gstatic.com/s/robotocondensed/v13/Zd2E9abXLFGSr9G3YK2MsET2KMEyTWEzJqg9U8VS8XM.woff2) format(""woff2"");unicode-range:U+1F00-1FFF}@font-face{font-family:'Roboto Condensed';font-style:normal;font-weight:400;src:local('Roboto Condensed'),local(RobotoCondensed-Regular),url(https://fonts.gstatic.com/s/robotocondensed/v13/Zd2E9abXLFGSr9G3YK2MsMH5J2QbmuFthYTFOnnSRco.woff2) format(""woff2"");unicode-range:U+0370-03FF}@font-face{font-family:'Roboto Condensed';font-style:normal;font-weight:400;src:local('Roboto Condensed'),local(RobotoCondensed-Regular),url(https://fonts.gstatic.com/s/robotocondensed/v13/Zd2E9abXLFGSr9G3YK2MsDcCYxVKuOcslAgPRMZ8RJE.woff2) format(""woff2"");unicode-range:U+0102-0103,U+1EA0-1EF1,U+20AB}@font-face{font-family:'Roboto Condensed';font-style:normal;font-weight:400;src:local('Roboto Condensed'),local(RobotoCondensed-Regular),url(https://fonts.gstatic.com/s/robotocondensed/v13/Zd2E9abXLFGSr9G3YK2MsNKDSU5nPdoBdru70FiVyb0.woff2) format(""woff2"");unicode-range:U+0100-024F,U+1E00-1EFF,U+20A0-20AB,U+20AD-20CF,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Roboto Condensed';font-style:normal;font-weight:400;src:local('Roboto Condensed'),local(RobotoCondensed-Regular),url(https://fonts.gstatic.com/s/robotocondensed/v13/Zd2E9abXLFGSr9G3YK2MsH4vxAoi6d67T_UKWi0EoHQ.woff2) format(""woff2"");unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2212,U+2215,U+E0FF,U+EFFD,U+F000}@font-face{font-family:'Roboto Condensed';font-style:normal;font-weight:700;src:local('Roboto Condensed Bold'),local(RobotoCondensed-Bold),url(https://fonts.gstatic.com/s/robotocondensed/v13/b9QBgL0iMZfDSpmcXcE8nBYyuMfI6pbvLqniwcbLofP2Ot9t5h1GRSTIE78Whtoh.woff2) format(""woff2"");unicode-range:U+0460-052F,U+20B4,U+2DE0-2DFF,U+A640-A69F}@font-face{font-family:'Roboto Condensed';font-style:normal;font-weight:700;src:local('Roboto Condensed Bold'),local(RobotoCondensed-Bold),url(https://fonts.gstatic.com/s/robotocondensed/v13/b9QBgL0iMZfDSpmcXcE8nIT75Viso9fCesWUO0IzDUX2Ot9t5h1GRSTIE78Whtoh.woff2) format(""woff2"");unicode-range:U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Roboto Condensed';font-style:normal;font-weight:700;src:local('Roboto Condensed Bold'),local(RobotoCondensed-Bold),url(https://fonts.gstatic.com/s/robotocondensed/v13/b9QBgL0iMZfDSpmcXcE8nL8EBb1YR1F8PhofwHtObrz2Ot9t5h1GRSTIE78Whtoh.woff2) format(""woff2"");unicode-range:U+1F00-1FFF}@font-face{font-family:'Roboto Condensed';font-style:normal;font-weight:700;src:local('Roboto Condensed Bold'),local(RobotoCondensed-Bold),url(https://fonts.gstatic.com/s/robotocondensed/v13/b9QBgL0iMZfDSpmcXcE8nAro84VToOve-uw23YSmBS72Ot9t5h1GRSTIE78Whtoh.woff2) format(""woff2"");unicode-range:U+0370-03FF}@font-face{font-family:'Roboto Condensed';font-style:normal;font-weight:700;src:local('Roboto Condensed Bold'),local(RobotoCondensed-Bold),url(https://fonts.gstatic.com/s/robotocondensed/v13/b9QBgL0iMZfDSpmcXcE8nACS0ZgDg4kY8EFPTGlvyHP2Ot9t5h1GRSTIE78Whtoh.woff2) format(""woff2"");unicode-range:U+0102-0103,U+1EA0-1EF1,U+20AB}@font-face{font-family:'Roboto Condensed';font-style:normal;font-weight:700;src:local('Roboto Condensed Bold'),local(RobotoCondensed-Bold),url(https://fonts.gstatic.com/s/robotocondensed/v13/b9QBgL0iMZfDSpmcXcE8nGPMCwzADhgEiQ8LZ-01G1L2Ot9t5h1GRSTIE78Whtoh.woff2) format(""woff2"");unicode-range:U+0100-024F,U+1E00-1EFF,U+20A0-20AB,U+20AD-20CF,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Roboto Condensed';font-style:normal;font-weight:700;src:local('Roboto Condensed Bold'),local(RobotoCondensed-Bold),url(https://fonts.gstatic.com/s/robotocondensed/v13/b9QBgL0iMZfDSpmcXcE8nPX2or14QGUHgbhSBV1Go0E.woff2) format(""woff2"");unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2212,U+2215,U+E0FF,U+EFFD,U+F000}&lt;/style&gt;


Can be seen here.
",eclipsis,https://stackoverflow.com/users/1350424,"What mobile browser are you using?

It may be because some browsers require eot/woff/otf files to load. Could you host these font files? 

read about webfont and @font-face syntax here: http://www.paulirish.com/2009/bulletproof-font-face-implementation-syntax/

also maybe a similar problem: @font-face not embedding on mobile Safari (iPhone/iPad)
",orangerblue,https://stackoverflow.com/users/4561738,http://stackoverflow.com/questions/28490837/google-fonts-loading-on-desktop-but-not-on-mobile,STACKOVERFLOW,stackoverflow.com,1.0,0.5555555555555556,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.0,1.0,1.0,"Google fonts loaded on the desktop, not mobile?","Per Google PageSpeed's recommendation, I inlined much of my CSS. Previously, I had minified all of my CSS through W3 Total Cache, but now I inlined much of my CSS, plus all of the CSS that controls Google Fonts. 

Now Google Fonts aren't appearing on mobile devices, but they do appear on desktops. Any reason why this is the case? The mobile screen cap here shows the fonts not loading.

&lt;style&gt;@font-face{font-family:'Pathway Gothic One';font-style:normal;font-weight:400;src:local('Pathway Gothic One'),local(PathwayGothicOne-Regular),url(https://fonts.gstatic.com/s/pathwaygothicone/v4/Lqv9ztoTUV8Q0FmQZzPqaA6LSHyyJAN5JIFgwWnj0Az3rGVtsTkPsbDajuO5ueQw.woff2) format(""woff2"");unicode-range:U+0100-024F,U+1E00-1EFF,U+20A0-20AB,U+20AD-20CF,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Pathway Gothic One';font-style:normal;font-weight:400;src:local('Pathway Gothic One'),local(PathwayGothicOne-Regular),url(https://fonts.gstatic.com/s/pathwaygothicone/v4/Lqv9ztoTUV8Q0FmQZzPqaHT0-GP0evTJPrdxn7U7ioo.woff2) format(""woff2"");unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2212,U+2215,U+E0FF,U+EFFD,U+F000}@font-face{font-family:'Quicksand';font-style:normal;font-weight:400;src:local('Quicksand Regular'),local(Quicksand-Regular),url(https://fonts.gstatic.com/s/quicksand/v5/sKd0EMYPAh5PYCRKSryvW5Bw1xU1rKptJj_0jans920.woff2) format(""woff2"");unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2212,U+2215,U+E0FF,U+EFFD,U+F000}@font-face{font-family:'Roboto Condensed';font-style:normal;font-weight:400;src:local('Roboto Condensed'),local(RobotoCondensed-Regular),url(https://fonts.gstatic.com/s/robotocondensed/v13/Zd2E9abXLFGSr9G3YK2MsIPxuqWfQuZGbz5Rz4Zu1gk.woff2) format(""woff2"");unicode-range:U+0460-052F,U+20B4,U+2DE0-2DFF,U+A640-A69F}@font-face{font-family:'Roboto Condensed';font-style:normal;font-weight:400;src:local('Roboto Condensed'),local(RobotoCondensed-Regular),url(https://fonts.gstatic.com/s/robotocondensed/v13/Zd2E9abXLFGSr9G3YK2MsENRpQQ4njX3CLaCqI4awdk.woff2) format(""woff2"");unicode-range:U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Roboto Condensed';font-style:normal;font-weight:400;src:local('Roboto Condensed'),local(RobotoCondensed-Regular),url(https://fonts.gstatic.com/s/robotocondensed/v13/Zd2E9abXLFGSr9G3YK2MsET2KMEyTWEzJqg9U8VS8XM.woff2) format(""woff2"");unicode-range:U+1F00-1FFF}@font-face{font-family:'Roboto Condensed';font-style:normal;font-weight:400;src:local('Roboto Condensed'),local(RobotoCondensed-Regular),url(https://fonts.gstatic.com/s/robotocondensed/v13/Zd2E9abXLFGSr9G3YK2MsMH5J2QbmuFthYTFOnnSRco.woff2) format(""woff2"");unicode-range:U+0370-03FF}@font-face{font-family:'Roboto Condensed';font-style:normal;font-weight:400;src:local('Roboto Condensed'),local(RobotoCondensed-Regular),url(https://fonts.gstatic.com/s/robotocondensed/v13/Zd2E9abXLFGSr9G3YK2MsDcCYxVKuOcslAgPRMZ8RJE.woff2) format(""woff2"");unicode-range:U+0102-0103,U+1EA0-1EF1,U+20AB}@font-face{font-family:'Roboto Condensed';font-style:normal;font-weight:400;src:local('Roboto Condensed'),local(RobotoCondensed-Regular),url(https://fonts.gstatic.com/s/robotocondensed/v13/Zd2E9abXLFGSr9G3YK2MsNKDSU5nPdoBdru70FiVyb0.woff2) format(""woff2"");unicode-range:U+0100-024F,U+1E00-1EFF,U+20A0-20AB,U+20AD-20CF,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Roboto Condensed';font-style:normal;font-weight:400;src:local('Roboto Condensed'),local(RobotoCondensed-Regular),url(https://fonts.gstatic.com/s/robotocondensed/v13/Zd2E9abXLFGSr9G3YK2MsH4vxAoi6d67T_UKWi0EoHQ.woff2) format(""woff2"");unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2212,U+2215,U+E0FF,U+EFFD,U+F000}@font-face{font-family:'Roboto Condensed';font-style:normal;font-weight:700;src:local('Roboto Condensed Bold'),local(RobotoCondensed-Bold),url(https://fonts.gstatic.com/s/robotocondensed/v13/b9QBgL0iMZfDSpmcXcE8nBYyuMfI6pbvLqniwcbLofP2Ot9t5h1GRSTIE78Whtoh.woff2) format(""woff2"");unicode-range:U+0460-052F,U+20B4,U+2DE0-2DFF,U+A640-A69F}@font-face{font-family:'Roboto Condensed';font-style:normal;font-weight:700;src:local('Roboto Condensed Bold'),local(RobotoCondensed-Bold),url(https://fonts.gstatic.com/s/robotocondensed/v13/b9QBgL0iMZfDSpmcXcE8nIT75Viso9fCesWUO0IzDUX2Ot9t5h1GRSTIE78Whtoh.woff2) format(""woff2"");unicode-range:U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Roboto Condensed';font-style:normal;font-weight:700;src:local('Roboto Condensed Bold'),local(RobotoCondensed-Bold),url(https://fonts.gstatic.com/s/robotocondensed/v13/b9QBgL0iMZfDSpmcXcE8nL8EBb1YR1F8PhofwHtObrz2Ot9t5h1GRSTIE78Whtoh.woff2) format(""woff2"");unicode-range:U+1F00-1FFF}@font-face{font-family:'Roboto Condensed';font-style:normal;font-weight:700;src:local('Roboto Condensed Bold'),local(RobotoCondensed-Bold),url(https://fonts.gstatic.com/s/robotocondensed/v13/b9QBgL0iMZfDSpmcXcE8nAro84VToOve-uw23YSmBS72Ot9t5h1GRSTIE78Whtoh.woff2) format(""woff2"");unicode-range:U+0370-03FF}@font-face{font-family:'Roboto Condensed';font-style:normal;font-weight:700;src:local('Roboto Condensed Bold'),local(RobotoCondensed-Bold),url(https://fonts.gstatic.com/s/robotocondensed/v13/b9QBgL0iMZfDSpmcXcE8nACS0ZgDg4kY8EFPTGlvyHP2Ot9t5h1GRSTIE78Whtoh.woff2) format(""woff2"");unicode-range:U+0102-0103,U+1EA0-1EF1,U+20AB}@font-face{font-family:'Roboto Condensed';font-style:normal;font-weight:700;src:local('Roboto Condensed Bold'),local(RobotoCondensed-Bold),url(https://fonts.gstatic.com/s/robotocondensed/v13/b9QBgL0iMZfDSpmcXcE8nGPMCwzADhgEiQ8LZ-01G1L2Ot9t5h1GRSTIE78Whtoh.woff2) format(""woff2"");unicode-range:U+0100-024F,U+1E00-1EFF,U+20A0-20AB,U+20AD-20CF,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Roboto Condensed';font-style:normal;font-weight:700;src:local('Roboto Condensed Bold'),local(RobotoCondensed-Bold),url(https://fonts.gstatic.com/s/robotocondensed/v13/b9QBgL0iMZfDSpmcXcE8nPX2or14QGUHgbhSBV1Go0E.woff2) format(""woff2"");unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2212,U+2215,U+E0FF,U+EFFD,U+F000}&lt;/style&gt;


Can be seen here.
","What mobile browser are you using?

It may be because some browsers require eot/woff/otf files to load. Could you host these font files? 

read about webfont and @font-face syntax here: http://www.paulirish.com/2009/bulletproof-font-face-implementation-syntax/

also maybe a similar problem: @font-face not embedding on mobile Safari (iPhone/iPad)
"
1586,1586,2498,Can the update manager download only a single package at a time?,"I need the update manager to only download a single package at a time and not try to download multiple packages at once.

My slow internet cannot handle multiple connections; slows the download to a crawl and some packages will reset themselves halfway through when they time-out.

EDIT

When using apt-get update multiple repositories get checked:


When using apt-get upgrade multiple packages are downloaded:

",SaultDon,https://askubuntu.com/users/22554,"Rather than using the update manager try sudo apt-get update&amp;&amp;sudo apt-get upgrade in the terminal

It would get the job done and also does not use parallel connections
",Amith KK,https://askubuntu.com/users/17722,http://askubuntu.com/questions/88731/can-the-update-manager-download-only-a-single-package-at-a-time,TECHNOLOGY,askubuntu.com,1.0,0.6666666666666666,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.0,0.0,0.8888888888888888,Can update manager download only one package at a time?,"I need the update manager to only download a single package at a time and not try to download multiple packages at once.

My slow internet cannot handle multiple connections; slows the download to a crawl and some packages will reset themselves halfway through when they time-out.

EDIT

When using apt-get update multiple repositories get checked:


When using apt-get upgrade multiple packages are downloaded:

","Rather than using the update manager try sudo apt-get update&amp;&amp;sudo apt-get upgrade in the terminal

It would get the job done and also does not use parallel connections
"
1920,1920,3057,"Orthogonal complement $V^\bot$ of the vector space $V=\langle(1,0,2),(3,-1,0)\rangle$ and $V\cap V^\bot$","Consider the inner product defined by polarizing the quadratic form $$q(x,y,z)=x^2-z^2+4xy-2yz$$ on $\mathbb{R}^3$.

Let $V=\langle(1,0,2),(3,-1,0)\rangle$. Could you show me how to find $V^\bot$ and $V\cap V^\bot$? I get $V^\bot=\langle(2,6,1)\rangle$, which doesn't feel right, and don't know how to calculate the intersection. Also, in general, what can we say about the dimension of $W^\bot$ if we know the dimension of $W$?
",user62029,https://math.stackexchange.com/users/174765,"The symmetric bilinear form that gives rise to your quadratic form $q$ is given by
$$
  b((x_1,y_1,z_1),(x_2,y_2,z_2))=x_1x_2-z_1z_2+2x_1y_2+2y_1x_2-y_1z_2-z_1y_2
$$
Now the conditions of being orthogonal to $(1,0,2)$ and to $(3,-1,0)$ are  respectively given by setting for instance $(x_2,y_2,z_2)$ equal to that vector and equating the resulting expression to$~0$; this respectively gives the equations 
$$ \begin{align}
 x-2z+2y-2y&amp;=0,\\ 3x-2x+6y+z&amp;=0,
\end{align}
$$
or after simplification
$$ \begin{align}
 x\phantom{{}+0y}-2z&amp;=0,\\ x+6y+\phantom0z&amp;=0.
\end{align}
$$
Then $V^\perp$ is spanned by for instance $(4,-1,2)$. It happens that this vector is also in $V$ (it is the sum of the two given vectors spanning $V$), which shows that you are not dealing with an inner product here (which should be positive definite). Indeed $q(4,-1,2)=0$. (Such a vector orthogonal to itself is called an isotropic vector for the bilinear form.)

If $E$ is the whole space, one does have $\dim(V)+\dim(V^\perp)=\dim(E)$ here. But even that is only valid in general provided that that bilinear form is nondegenerate, meaning that no nonzero vector is perpendicular to all vectors. Even though the given bilinear form is indefinite, it is nondegenerate. That can be checked by checking that the Gram matrixof $b$
$$
  \begin{pmatrix}1&amp;2&amp;0\\2&amp;0&amp;-1\\0&amp;-1&amp;1\end{pmatrix}
$$
has nonzero determinant. So $\dim(V)+\dim(V^\perp)=\dim(E)$ could have been expected here.
",Marc van Leeuwen,https://math.stackexchange.com/users/18880,http://math.stackexchange.com/questions/1124655/orthogonal-complement-v-bot-of-the-vector-space-v-langle1-0-2-3-1-0-ra,SCIENCE,math.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,1.0,1.0,1.0,0.5555555555555556,0.4444444444444444,0.6666666666666666,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,1.0,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.8888888888888888,"Orthogonal complement $V ^ \ BOT $, range $and $V \ cap V ^ \ BOT $of vector space $v = \ LANGLE (1,0,2), (3, - 1,0)$","Consider the inner product defined by polarizing the quadratic form $$q(x,y,z)=x^2-z^2+4xy-2yz$$ on $\mathbb{R}^3$.

Let $V=\langle(1,0,2),(3,-1,0)\rangle$. Could you show me how to find $V^\bot$ and $V\cap V^\bot$? I get $V^\bot=\langle(2,6,1)\rangle$, which doesn't feel right, and don't know how to calculate the intersection. Also, in general, what can we say about the dimension of $W^\bot$ if we know the dimension of $W$?
","The symmetric bilinear form that gives rise to your quadratic form $q$ is given by
$$
  b((x_1,y_1,z_1),(x_2,y_2,z_2))=x_1x_2-z_1z_2+2x_1y_2+2y_1x_2-y_1z_2-z_1y_2
$$
Now the conditions of being orthogonal to $(1,0,2)$ and to $(3,-1,0)$ are  respectively given by setting for instance $(x_2,y_2,z_2)$ equal to that vector and equating the resulting expression to$~0$; this respectively gives the equations 
$$ \begin{align}
 x-2z+2y-2y&amp;=0,\\ 3x-2x+6y+z&amp;=0,
\end{align}
$$
or after simplification
$$ \begin{align}
 x\phantom{{}+0y}-2z&amp;=0,\\ x+6y+\phantom0z&amp;=0.
\end{align}
$$
Then $V^\perp$ is spanned by for instance $(4,-1,2)$. It happens that this vector is also in $V$ (it is the sum of the two given vectors spanning $V$), which shows that you are not dealing with an inner product here (which should be positive definite). Indeed $q(4,-1,2)=0$. (Such a vector orthogonal to itself is called an isotropic vector for the bilinear form.)

If $E$ is the whole space, one does have $\dim(V)+\dim(V^\perp)=\dim(E)$ here. But even that is only valid in general provided that that bilinear form is nondegenerate, meaning that no nonzero vector is perpendicular to all vectors. Even though the given bilinear form is indefinite, it is nondegenerate. That can be checked by checking that the Gram matrixof $b$
$$
  \begin{pmatrix}1&amp;2&amp;0\\2&amp;0&amp;-1\\0&amp;-1&amp;1\end{pmatrix}
$$
has nonzero determinant. So $\dim(V)+\dim(V^\perp)=\dim(E)$ could have been expected here.
"
1938,1938,3091,How do you decide when a paladin has fallen from grace in DnD 5e?,"There does not seem to be a clear-cut way to determine when a paladin's actions have become egregious enough to justify them breaking their oath. Do a lot of minor slights eventually add up and cause an oath to be broken? Do they get some sort of warning like losing their laying on of hands ability? 
",adclark09,https://rpg.stackexchange.com/users/22899,"My opinion is that, for the most part. it is when they break an obvious part of their oath (like using poison for example) or willing commit a truly evil act with no good end.

Though on specific part of oaths. I feel that there are exceptions that a specific paladin can have. I'll use an example I had from a character

Scandal: The character had a flaw/compulsion to be a dracophile from his dragon blood. So I said that to avoid falling from favor and becoming shunned by the people he protected, he could lie about that part of his personality.

I also said that as long as their act wasn't grievous and for a truly good end, he could avoid almost any provocation (for example: a Paladin that kills the corrupt king of a corrupt land wouldn't fall from grace)

To sum up: I focused on the idea that justice is to some extent more important than their oaths.
",Cataru Moore,https://rpg.stackexchange.com/users/21755,http://rpg.stackexchange.com/questions/62167/how-do-you-decide-when-a-paladin-has-fallen-from-grace-in-dnd-5e,CULTURE,rpg.stackexchange.com,1.0,0.5555555555555556,0.0,1.0,0.3333333333333333,0.5,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.3333333333333333,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.6666666666666666,0.6666666666666666,1.0,How do you decide when a paladin will fall out of favor in dnd5e?,"There doesn't seem to be a clear way to determine when the Knights' behavior has become too much to prove that they have broken the oath. Will a lot of slight contempt eventually lead to the breaking of vows? Do they get some kind of warning, such as losing the ability to start?","My opinion is that, for the most part. it is when they break an obvious part of their oath (like using poison for example) or willing commit a truly evil act with no good end.

Though on specific part of oaths. I feel that there are exceptions that a specific paladin can have. I'll use an example I had from a character

Scandal: The character had a flaw/compulsion to be a dracophile from his dragon blood. So I said that to avoid falling from favor and becoming shunned by the people he protected, he could lie about that part of his personality.

I also said that as long as their act wasn't grievous and for a truly good end, he could avoid almost any provocation (for example: a Paladin that kills the corrupt king of a corrupt land wouldn't fall from grace)

To sum up: I focused on the idea that justice is to some extent more important than their oaths.
"
40,40,60,Flushing coolant after driving only with water in,"If I drive my truck for 30 min with just water in my system, would it be equivalent to just flushing it stationary (the proper way to flush it)? IOW, if I just drive around with a clean water refill in the coolant system instead of keeping the truck in place and then draining, would it be an okay way to flush?
",amphibient,https://mechanics.stackexchange.com/users/2618,"It would make no difference if you are standing still or driving the vehicle. You want to ensure you have the heater wide open when you do it to ensure you are getting the old fluid from the heater core as well as the engine. Driving the vehicle around will probably allow the process to happen a little faster, as you engine will get up to operating temperature faster. The real thing you are trying to accomplish is to get the thermostat open to allow everything to circulate.
",Pᴀᴜʟsᴛᴇʀ2,https://mechanics.stackexchange.com/users/4152,http://mechanics.stackexchange.com/questions/17345/flushing-coolant-after-driving-only-with-water-in,CULTURE,mechanics.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,1.0,0.3333333333333333,1.0,0.6666666666666666,0.7777777777777778,0.0,0.0,1.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.3333333333333333,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.6666666666666666,0.0,0.6666666666666666,0.8888888888888888,Only wash the running coolant with water,"If I drive the truck for 30 minutes and there is only water in the system, is this equivalent to static flushing (the correct method of flushing)? Listen, if I just fill the cooling system with clean water instead of keeping the truck in place and then draining, is this a good way to wash it?","If you stand still or drive, it makes no difference. When you do this, make sure your heater is fully turned on to make sure you get the old fluid from the heater core and the engine. Driving the vehicle around can make this process happen faster because your engine will reach operating temperature faster. What you really have to do is turn on the thermostat so that everything can cycle."
102,102,168,Why is the potential function defined differently in physics and calculus?,"I am very familiar with the concept of a potential function, and potential energy, from calculus-based physics.

For instance, if we have the familiar force field $\mathbf{F} = -mg \,\mathbf{j}$, then a potential function is given by $U = mgy + C$. (Since potential energy is relative, we have an infinite number of potential functions.)

Notice that the gradient of the potential function is the negative of the force field: $$\nabla U = \nabla(mgy + C) = mg \,\mathbf{j} = -\mathbf{F}.$$

That was perfectly fine with me. But now in vector calculus, I am reading that the potential function $f$ of a vector function $\mathbf{F}$ is such that $\nabla f = \mathbf{F}$. A negative sign appears to have been lost when migrating from physics to calculus.

It seems confusing to call $f$ a ""potential function"", since it cannot be interpreted as potential energy in the real world. So why is the calculus nomenclature as it is (i.e., why not call this something else and then say the potential function is the negative of it)?
",Radon Rosborough,https://math.stackexchange.com/users/160658,"After reading further on in my calculus textbook, I found that they later defined the potential energy as the negative of the potential function.

So it appears that the reasoning presented in my question was correct, but that some sources simply use a slightly different definition for ""potential function"" – not because it corresponds to potential energy, but because a convenient name is needed for it.

Wikipedia says that the gradient of the potential is the negative of the vector field, but that ""In some cases, mathematicians may use a positive sign in front of the gradient to define the potential.""
",Radon Rosborough,https://math.stackexchange.com/users/160658,http://math.stackexchange.com/questions/1335576/why-is-the-potential-function-defined-differently-in-physics-and-calculus,SCIENCE,math.stackexchange.com,0.8888888888888888,0.7777777777777778,0.0,0.0,1.0,1.0,0.6666666666666666,0.4444444444444444,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,1.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.8,0.0,0.0,1.0,1.0,Why are potential functions defined differently in physics and calculus?,"I am very familiar with the concept of a potential function, and potential energy, from calculus-based physics.

For instance, if we have the familiar force field $\mathbf{F} = -mg \,\mathbf{j}$, then a potential function is given by $U = mgy + C$. (Since potential energy is relative, we have an infinite number of potential functions.)

Notice that the gradient of the potential function is the negative of the force field: $$\nabla U = \nabla(mgy + C) = mg \,\mathbf{j} = -\mathbf{F}.$$

That was perfectly fine with me. But now in vector calculus, I am reading that the potential function $f$ of a vector function $\mathbf{F}$ is such that $\nabla f = \mathbf{F}$. A negative sign appears to have been lost when migrating from physics to calculus.

It seems confusing to call $f$ a ""potential function"", since it cannot be interpreted as potential energy in the real world. So why is the calculus nomenclature as it is (i.e., why not call this something else and then say the potential function is the negative of it)?
","After reading further on in my calculus textbook, I found that they later defined the potential energy as the negative of the potential function.

So it appears that the reasoning presented in my question was correct, but that some sources simply use a slightly different definition for ""potential function"" – not because it corresponds to potential energy, but because a convenient name is needed for it.

Wikipedia says that the gradient of the potential is the negative of the vector field, but that ""In some cases, mathematicians may use a positive sign in front of the gradient to define the potential.""
"
1222,1222,1917,Bake particle system animation and delete few particles,"I want to delete few particles from particle system. After baking the animation still I cant select particle objects, it selects all of them.
",wyy,https://blender.stackexchange.com/users/1751,"The only way I know to edit already emitted particle objects would be to Make Duplicates Real Shift-Ctrl-A accessible in Object Menu after that you could select the mesh and invoke Separate by loose parts in Edit Mode P. This wouldn't help on animations.


",stacker,https://blender.stackexchange.com/users/29,http://blender.stackexchange.com/questions/5882/bake-particle-system-animation-and-delete-few-particles,TECHNOLOGY,blender.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,0.8888888888888888,0.8666666666666666,1.0,0.3333333333333333,0.0,0.7777777777777778,Bake particle system animation and delete a small number of particles,"I want to remove some particles from the particle system. After baking the animation, I still can't select the particle object, it will select all the objects.","The only way I know to edit already emitted particle objects would be to Make Duplicates Real Shift-Ctrl-A accessible in Object Menu after that you could select the mesh and invoke Separate by loose parts in Edit Mode P. This wouldn't help on animations.


"
4039,4039,6449,Parallel circuit and Ohms law,"

Theoretical questions with ideal components.(R2 is 10 Ohm)
1) parallel circuit. R1 and ammeter, 
If I have a parallel circuit of 2 resistances, both zero Ohm, the current would split to 2 and each current would be half. If the resistor R1 would be 1 pico Ohm, and the ammeter zero Ohm, there would be no current through the resistor, and all the current would go through the ammeter?
2) Ohms law. R2 is 10 Ohm, current is 1A. voltage between point A and B is 0 volt,
resistance between A and B is 0 Ohm,  according to Ohms law, I = V / R = 0 / 0 = 0 A. Correction, 0/0 is not 0, it is undefined.(edited after posting)
Is it telling me that it sees this as 2 circuits, with a common wire, and the circuit between A and B has no current, but the circuit between (+) and (-) has 1 Amp. Correction, the current between A and B is undefined. (edited after posting)
Both questions are theoretical with ideal components, and the voltmeter and ammeter are connected this way on purpose. I would like to get some feedback on this topic.
",sparky Al,https://electronics.stackexchange.com/users/62485,"
  If I have a parallel circuit of 2 resistances, both zero Ohm, the current would split to 2 and each current would be half. 


""Zero ohms"" is an idealization. If you say you have two zero-ohm resistors in parallel, it just means your model is not accurate enough to determine how the current is split.


  If the resistor R1 would be 1 pico Ohm, and the ammeter zero Ohm, there would be no current through the resistor, and all the current would go through the ammeter?


If ""zero ohms"" means much much less than 1 picoohm, then yes, essentially all the current would go through the ammeter.

But real ammeters have burden resistance that's much much more than a picoohm (more like a few milliohms).


  2) Ohms law.
  R2 is 10 Ohm, current is 1A.
  voltage between point A and B is 0 volt, resistance between A and B is 0 Ohm,
  according to Ohms law, I = V / R = 0 / 0 = 0 A.


You have a false conclusion. Zero divided by zero is not zero. It is an undetermined value. Could be zero or could be infinite, depending on the situation.

To analyze this circuit, restate Ohm's law as V = I R. You know the current is 1 A due to the other circuit elements. You know the voltmeter doesn't pass current. Therefore there's 1 A passing from B to A, and because it's a perfect wire, the voltage is zero.
",The Photon,https://electronics.stackexchange.com/users/6334,http://electronics.stackexchange.com/questions/159983/parallel-circuit-and-ohms-law,TECHNOLOGY,electronics.stackexchange.com,0.6666666666666666,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.6666666666666666,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,0.8888888888888888,0.8,0.0,0.0,0.6666666666666666,0.7777777777777778,Parallel circuit and Ohm's law,"

Theoretical questions with ideal components.(R2 is 10 Ohm)
1) parallel circuit. R1 and ammeter, 
If I have a parallel circuit of 2 resistances, both zero Ohm, the current would split to 2 and each current would be half. If the resistor R1 would be 1 pico Ohm, and the ammeter zero Ohm, there would be no current through the resistor, and all the current would go through the ammeter?
2) Ohms law. R2 is 10 Ohm, current is 1A. voltage between point A and B is 0 volt,
resistance between A and B is 0 Ohm,  according to Ohms law, I = V / R = 0 / 0 = 0 A. Correction, 0/0 is not 0, it is undefined.(edited after posting)
Is it telling me that it sees this as 2 circuits, with a common wire, and the circuit between A and B has no current, but the circuit between (+) and (-) has 1 Amp. Correction, the current between A and B is undefined. (edited after posting)
Both questions are theoretical with ideal components, and the voltmeter and ammeter are connected this way on purpose. I would like to get some feedback on this topic.
","
  If I have a parallel circuit of 2 resistances, both zero Ohm, the current would split to 2 and each current would be half. 


""Zero ohms"" is an idealization. If you say you have two zero-ohm resistors in parallel, it just means your model is not accurate enough to determine how the current is split.


  If the resistor R1 would be 1 pico Ohm, and the ammeter zero Ohm, there would be no current through the resistor, and all the current would go through the ammeter?


If ""zero ohms"" means much much less than 1 picoohm, then yes, essentially all the current would go through the ammeter.

But real ammeters have burden resistance that's much much more than a picoohm (more like a few milliohms).


  2) Ohms law.
  R2 is 10 Ohm, current is 1A.
  voltage between point A and B is 0 volt, resistance between A and B is 0 Ohm,
  according to Ohms law, I = V / R = 0 / 0 = 0 A.


You have a false conclusion. Zero divided by zero is not zero. It is an undetermined value. Could be zero or could be infinite, depending on the situation.

To analyze this circuit, restate Ohm's law as V = I R. You know the current is 1 A due to the other circuit elements. You know the voltmeter doesn't pass current. Therefore there's 1 A passing from B to A, and because it's a perfect wire, the voltage is zero.
"
1732,1732,2739,Solving a two point boundary problem for a piecewise system of equations,"I'm trying to solve a two point boundary value problem with a piecewise system of equations like:

dx[t_] := Piecewise[{{0, y[t] &lt;= 0}, {x[t]^(3/4) - x[t], y[t] &gt; 0}}]
dy[t_] := Piecewise[{{0, y[t] &lt;= 0}, {(1 - y[t])/x[t]^(1/4) + y[t], y[t] &gt; 0}}]

NDSolve[{x'[t] == dx[t], y'[t] == dy[t], x[0] == 1, y[10] == 2}, {x, y}, {t, 0, 10}]


which produces the error

 NDSolve::bvdisc: NDSolve is not currently able to solve boundary value problems with discrete variables.


I tried the answers here by entering

funs = ParametricNDSolveValue[{x'[t] == dx[t], y'[t] == dy[t], x[0] == 1, y[10] == yt}, {x, y}, {t, 0, end}, yt]

FindRoot[funs[yt][end], {yt, 2}]


which yields the same error.

Is there any way to solve this system? Thanks for the help.
",Mauricio,https://mathematica.stackexchange.com/users/19635,"There is no need to use Piecewise because both $x(t)$ as well as $y(t)$ remain non negative.
Furthermore, the equation for x is independent of y and can be solved analytically.

The result $x(t)$ is then put into the equation for $y(t)$ which will be solved numerically.

Finally we verify our first statement about the non-negativity.

Ok, here we go.

The eqution for $x(t)$ is

sx = DSolve[x'[t] == x[t]^(3/4) - x[t] &amp;&amp; x[0] == 1, x[t], t]


We can safely ignore the error messages; they are just information which is not relevant here.

(* Out[105] = {{x[t] -&gt; E^-t (-2 + E^(t/4))^4}, {x[t] -&gt; E^-t ((-1 - I) + E^(t/4))^4}, {x[t] -&gt; E^-t ((-1 + I) + E^(t/4))^4}} *)


Taking the real-valued solution

xx[t_] = x[t] /. sx[[1]]

(* Out[106]= E^-t (-2 + E^(t/4))^4 *)

Plot[xx[t], {t, 0, 30}]




Now solving numerically the equation for $y(t)$ using the previously obtained function $xx(t)$:

sy = NDSolve[y'[t] == (1 - y[t])/xx[t]^(1/4) + y[t] &amp;&amp; y[0] == 10, y[t], {t, 0, 50}][[1]]


$\{y[t]\to \text{InterpolatingFunction}[\{\{0.,50.\}\},&lt;&gt;][t]\}$

Works out smoothly, no precision problems.
Here's the function itself

yy[t_] = y[t] /. sy


$\text{InterpolatingFunction}[\{\{0.,50.\}\},&lt;&gt;][t]$

Finally ploting both functions together, magnifying $x(t)$ by a factor of ten for better visibility:

Plot[{10 xx[t], yy[t]}, {t, 0, 30}, PlotRange -&gt; {-1, 20}, PlotLabel -&gt; ""blue x(t), red y(t)""]




Nice problem. Hope this helps.

Regards,
Wolfgang
",Dr. Wolfgang Hintze,https://mathematica.stackexchange.com/users/16361,http://mathematica.stackexchange.com/questions/59205/solving-a-two-point-boundary-problem-for-a-piecewise-system-of-equations,TECHNOLOGY,mathematica.stackexchange.com,0.6666666666666666,0.4444444444444444,0.0,1.0,1.0,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.7777777777777778,1.0,0.7777777777777778,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,1.0,The solution of two point boundary value problem of piecewise equations,"I'm trying to solve a two point boundary value problem with a piecewise system of equations like:

dx[t_] := Piecewise[{{0, y[t] &lt;= 0}, {x[t]^(3/4) - x[t], y[t] &gt; 0}}]
dy[t_] := Piecewise[{{0, y[t] &lt;= 0}, {(1 - y[t])/x[t]^(1/4) + y[t], y[t] &gt; 0}}]

NDSolve[{x'[t] == dx[t], y'[t] == dy[t], x[0] == 1, y[10] == 2}, {x, y}, {t, 0, 10}]


which produces the error

 NDSolve::bvdisc: NDSolve is not currently able to solve boundary value problems with discrete variables.


I tried the answers here by entering

funs = ParametricNDSolveValue[{x'[t] == dx[t], y'[t] == dy[t], x[0] == 1, y[10] == yt}, {x, y}, {t, 0, end}, yt]

FindRoot[funs[yt][end], {yt, 2}]


which yields the same error.

Is there any way to solve this system? Thanks for the help.
","There is no need to use Piecewise because both $x(t)$ as well as $y(t)$ remain non negative.
Furthermore, the equation for x is independent of y and can be solved analytically.

The result $x(t)$ is then put into the equation for $y(t)$ which will be solved numerically.

Finally we verify our first statement about the non-negativity.

Ok, here we go.

The eqution for $x(t)$ is

sx = DSolve[x'[t] == x[t]^(3/4) - x[t] &amp;&amp; x[0] == 1, x[t], t]


We can safely ignore the error messages; they are just information which is not relevant here.

(* Out[105] = {{x[t] -&gt; E^-t (-2 + E^(t/4))^4}, {x[t] -&gt; E^-t ((-1 - I) + E^(t/4))^4}, {x[t] -&gt; E^-t ((-1 + I) + E^(t/4))^4}} *)


Taking the real-valued solution

xx[t_] = x[t] /. sx[[1]]

(* Out[106]= E^-t (-2 + E^(t/4))^4 *)

Plot[xx[t], {t, 0, 30}]




Now solving numerically the equation for $y(t)$ using the previously obtained function $xx(t)$:

sy = NDSolve[y'[t] == (1 - y[t])/xx[t]^(1/4) + y[t] &amp;&amp; y[0] == 10, y[t], {t, 0, 50}][[1]]


$\{y[t]\to \text{InterpolatingFunction}[\{\{0.,50.\}\},&lt;&gt;][t]\}$

Works out smoothly, no precision problems.
Here's the function itself

yy[t_] = y[t] /. sy


$\text{InterpolatingFunction}[\{\{0.,50.\}\},&lt;&gt;][t]$

Finally ploting both functions together, magnifying $x(t)$ by a factor of ten for better visibility:

Plot[{10 xx[t], yy[t]}, {t, 0, 30}, PlotRange -&gt; {-1, 20}, PlotLabel -&gt; ""blue x(t), red y(t)""]




Nice problem. Hope this helps.

Regards,
Wolfgang
"
5034,5034,8011,Is hacking back a valid security technique for companies?,"Recently it has come to light through the reverse engineering of hacking tools that there are vulnerabilities in them that could be exploited to take over an attackers computer during a remote hacking session. In other words, while they are hacking you, you could get into the system from which they are launching the attack to find out what they have managed to access, what the system is, or even p4wn it yourself. The goals would be damage control, deterrence, and ultimately being able to charge the perpetrator of the crime. 

Leaving aside the many legal, ethical, and moral considerations (if you are curious there's a debate recorded here), my question is whether hacking back using this technique has any value to a company. If it was ethical and legal would it be worth a company to invest in the systems and skills needed to make this work, or is it a waste of money? 

EDIT:
There's been several comments regarding leaving the legal and ethical considerations out of the question, so here's the explanation behind that. So far the discussion of hacking back in this manner has been discussed by lawyers, some shouting it is legal, and others saying it isn't. What they do agree on is that there's no case law, and until there is there will be no clear answer. Also, legalities vary from nation to nation, so the answer to legality is ""maybe"" and ""it depends where you are"". 

However so far none of the discussion I've seen has been among IT Security professionals who would be the ones to design, deploy, and run systems that would to the hacking back. The lawyers all seem to think that organizations would adopt the technique as a matter of course, but I am not in agreement with that and I would like to hear the views of my peers. This is why I've asked the question apart from legal and ethical aspects. 
",GdD,https://security.stackexchange.com/users/10950,"We had this debate at our local OWASP chapter last night about whether a honeypot should strike back.  We did talk about some legal and moral issues however decided it was not a good idea because:


The majority of attacks are coming from dumb clients on botnets or through automated tools, so what are you actually achieving by taking out yet-another-dumb client?
The focus of your business should be aligned to your business objectives - fighting cybercrime (unless you work for a police authority) should not form part of that.
If the attack becomes serious and you need to go to court; evidence that you ""striked back"" would not look good and could work against you.  if you are going to spend money in this topic then spend it on forensic tools so that it strengthens any legal action
circular attacks:  consider if you accidentally strike back at another tool that has strike back capability?  then you're just eating up bandwidth unnecessarily.

",Callum Wilson,https://security.stackexchange.com/users/16502,http://security.stackexchange.com/questions/24700/is-hacking-back-a-valid-security-technique-for-companies,TECHNOLOGY,security.stackexchange.com,1.0,0.6666666666666666,1.0,0.3333333333333333,0.0,0.0,0.7777777777777778,0.5555555555555556,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,0.6666666666666666,0.8888888888888888,Is hacking an effective security technology for companies?,"Recently it has come to light through the reverse engineering of hacking tools that there are vulnerabilities in them that could be exploited to take over an attackers computer during a remote hacking session. In other words, while they are hacking you, you could get into the system from which they are launching the attack to find out what they have managed to access, what the system is, or even p4wn it yourself. The goals would be damage control, deterrence, and ultimately being able to charge the perpetrator of the crime. 

Leaving aside the many legal, ethical, and moral considerations (if you are curious there's a debate recorded here), my question is whether hacking back using this technique has any value to a company. If it was ethical and legal would it be worth a company to invest in the systems and skills needed to make this work, or is it a waste of money? 

EDIT:
There's been several comments regarding leaving the legal and ethical considerations out of the question, so here's the explanation behind that. So far the discussion of hacking back in this manner has been discussed by lawyers, some shouting it is legal, and others saying it isn't. What they do agree on is that there's no case law, and until there is there will be no clear answer. Also, legalities vary from nation to nation, so the answer to legality is ""maybe"" and ""it depends where you are"". 

However so far none of the discussion I've seen has been among IT Security professionals who would be the ones to design, deploy, and run systems that would to the hacking back. The lawyers all seem to think that organizations would adopt the technique as a matter of course, but I am not in agreement with that and I would like to hear the views of my peers. This is why I've asked the question apart from legal and ethical aspects. 
","We had this debate at our local OWASP chapter last night about whether a honeypot should strike back.  We did talk about some legal and moral issues however decided it was not a good idea because:


The majority of attacks are coming from dumb clients on botnets or through automated tools, so what are you actually achieving by taking out yet-another-dumb client?
The focus of your business should be aligned to your business objectives - fighting cybercrime (unless you work for a police authority) should not form part of that.
If the attack becomes serious and you need to go to court; evidence that you ""striked back"" would not look good and could work against you.  if you are going to spend money in this topic then spend it on forensic tools so that it strengthens any legal action
circular attacks:  consider if you accidentally strike back at another tool that has strike back capability?  then you're just eating up bandwidth unnecessarily.

"
3181,3181,5069,"Should I Cite a Journal's Page Number, or an Article's?","When I'm citing a page in a journal, and the article has an independent page numbering system, should I cite the page number of the journal or the article?
",Will Sewell,https://academia.stackexchange.com/users/715,"I'm not certain what you mean by an article with an independent page numbering system, but I assume you mean the following.  The published journal article is, say, on pages 25-48 of the journal, but there is also a preprint available online with different formatting, and it is numbered from 1-23.  Not only the page divisions, but even the number of pages differ, so there's no easy way to transfer a reference between these numberings except approximately.

The most important rule is to be clear and correct: you should leave no doubt or ambiguity about which numbering system you are using.  If you cite only one version of the paper, then you should use the same numbering used there.  If you cite several versions, then you need to make sure your references are clear.

The second rule is that you should focus on the ""most official"" version of the paper, whatever that is.  In most cases, a journal paper is more official than a conference paper, which is more official than a numbered technical report in a series, which is more official than a random preprint.  You want to cite the most final, complete, and authoritative version, and the one most likely to be accessible to future readers.  There may occasionally be subtle cases (for example, a paper that has been reprinted in books with corrections or additions), but this generally means the journal version.

P.S.  The only other interpretation of the question I can think of is for journals like Physical Review, where an article has its own page number (like 032326) and then the individual pages are given subsidiary numbers (like 032326-1 through 032326-8).  In that case, if you want to cite a specific page you could refer to it as 032326-3, or maybe just 3 if the context is clear.  In the bibliography, you would write 032326:1-8 or just 032326, depending on your bibliography style.
",Anonymous Mathematician,https://academia.stackexchange.com/users/612,http://academia.stackexchange.com/questions/1240/should-i-cite-a-journals-page-number-or-an-articles,LIFE_ARTS,academia.stackexchange.com,1.0,1.0,0.0,1.0,1.0,1.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,1.0,0.8888888888888888,1.0,1.0,1.0,0.0,0.6666666666666666,1.0,1.0,Should I quote the page number of the journal or the article?,"When I quote a page in a journal, the article has a separate page system. Should I quote the page number of the journal or the article?","I'm not certain what you mean by an article with an independent page numbering system, but I assume you mean the following.  The published journal article is, say, on pages 25-48 of the journal, but there is also a preprint available online with different formatting, and it is numbered from 1-23.  Not only the page divisions, but even the number of pages differ, so there's no easy way to transfer a reference between these numberings except approximately.

The most important rule is to be clear and correct: you should leave no doubt or ambiguity about which numbering system you are using.  If you cite only one version of the paper, then you should use the same numbering used there.  If you cite several versions, then you need to make sure your references are clear.

The second rule is that you should focus on the ""most official"" version of the paper, whatever that is.  In most cases, a journal paper is more official than a conference paper, which is more official than a numbered technical report in a series, which is more official than a random preprint.  You want to cite the most final, complete, and authoritative version, and the one most likely to be accessible to future readers.  There may occasionally be subtle cases (for example, a paper that has been reprinted in books with corrections or additions), but this generally means the journal version.

P.S.  The only other interpretation of the question I can think of is for journals like Physical Review, where an article has its own page number (like 032326) and then the individual pages are given subsidiary numbers (like 032326-1 through 032326-8).  In that case, if you want to cite a specific page you could refer to it as 032326-3, or maybe just 3 if the context is clear.  In the bibliography, you would write 032326:1-8 or just 032326, depending on your bibliography style.
"
1766,1766,2803,How much choice should I give users?,"I am considering adding an update to my iPhone app that allows the user to choose many new features such as the background image, where certain buttons are located, button colors, button design, certain label colors, etc. While I have a lot of ideas on where I could allow the user to change things, I wonder how much choice I should give them.

If I give them too much choice is it possible they will give me bad reviews, or is the opposite more often true? 

Also, if I give them that choice, should I put that all in a single preference panel, or should I split it up somehow? (I don't like using the Settings App, so I'm not asking about that here)
",cory ginsberg,https://ux.stackexchange.com/users/22960,"Give users as many options and features as you can, but have only the most used, or most likely to be used, features in plain sight.  
",Josh Campbell,https://ux.stackexchange.com/users/22680,http://ux.stackexchange.com/questions/31418/how-much-choice-should-i-give-users,TECHNOLOGY,ux.stackexchange.com,1.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.0,1.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.7777777777777778,0.8888888888888888,0.5555555555555556,1.0,1.0,0.7333333333333333,0.0,0.3333333333333333,0.3333333333333333,0.8888888888888888,How many choices should I give users?,"I'm considering adding an update to my iPhone app that allows users to choose many new features, such as background images, location of some buttons, button colors, button design, some label colors, and so on. Although I have a lot of ideas about where to allow users to change things, I want to know how many choices I should give them.","Give users as many options and features as you can, but have only the most used, or most likely to be used, features in plain sight.  
"
3582,3582,5723,Does syncing more Google accounts decrease a phone's battery life?,"I recently got a Motorola Moto G (4.3 upgraded to 4.4.2), and I wasn't getting the battery life that my vendor claimed I would get (Through mixed usage: 2-3 hours of music, some web browsing, a lot of Whatsapp, a little bit of gaming, and Wifi/mobile network completely turned off in the night (for some 8-9 hours), I barely touch 20 hours of battery life)

I was wondering whether this has got to do with the 3 google accounts that I've kept in sync for GMail and some other Google services.

I may be a bit paranoid because my previous Android phone suffered from woeful battery near the end of its life, but still I would like to know if syncing more accounts drains the battery more or not.
",wrahool,https://android.stackexchange.com/users/55059,"Short answer: yes and no.

Using three accounts won't run the battery down in itself: by far the bigger factor is how much activity there is. To take an example, Gmail uses push messages (via Google Cloud Messaging, GCM) to notify your phone of new mail, so the phone doesn't have to repeatedly poll the server for new messages for each account.

Because of this, adding a new account that never gets any email will have hardly any effect on battery use. OTOH, doubling the amount of email you get will have a much bigger effect, because GCM is waking up your phone twice as often. While adding a new account makes little difference on its own, you're probably adding the account because it's going to get mail, so you will end up using the battery more.

The same applies to other services too. Even for anything that does poll instead of using GCM, Android is clever enough to do all the polling tasks at the same time, to avoid repeatedly waking up your phone. This means that checking two accounts uses a little more battery than checking one, but less than twice as much: again, the amount of work it's doing each update (how much data it's fetching) is a bigger factor.

To address your particular situation, I'd guess that the background updates on your phone aren't using nearly as much battery as the foreground things you're doing. Don't forget you check the battery use of each app in the device settings.
",Dan Hulme,https://android.stackexchange.com/users/12442,http://android.stackexchange.com/questions/65005/does-syncing-more-google-accounts-decrease-a-phones-battery-life,TECHNOLOGY,android.stackexchange.com,1.0,0.8888888888888888,0.0,1.0,1.0,1.0,0.7777777777777778,0.4444444444444444,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,0.8888888888888888,Will syncing more Google accounts reduce the battery life of mobile phones?,"I recently bought a Motorola moto g (upgraded from 4.3 to 4.4.2), and my battery life is not as long as my suppliers say (through mixed use: 2-3 hours of music, some Internet browsing, a large number of WhatsApp, a little game and WiFi / mobile network shut down completely at night (about 8-9 hours), and I have almost no contact with 20 hours of battery life)","Short answer: yes and no.

Using three accounts won't run the battery down in itself: by far the bigger factor is how much activity there is. To take an example, Gmail uses push messages (via Google Cloud Messaging, GCM) to notify your phone of new mail, so the phone doesn't have to repeatedly poll the server for new messages for each account.

Because of this, adding a new account that never gets any email will have hardly any effect on battery use. OTOH, doubling the amount of email you get will have a much bigger effect, because GCM is waking up your phone twice as often. While adding a new account makes little difference on its own, you're probably adding the account because it's going to get mail, so you will end up using the battery more.

The same applies to other services too. Even for anything that does poll instead of using GCM, Android is clever enough to do all the polling tasks at the same time, to avoid repeatedly waking up your phone. This means that checking two accounts uses a little more battery than checking one, but less than twice as much: again, the amount of work it's doing each update (how much data it's fetching) is a bigger factor.

To address your particular situation, I'd guess that the background updates on your phone aren't using nearly as much battery as the foreground things you're doing. Don't forget you check the battery use of each app in the device settings.
"
2262,2262,3605,Android checktextview now working,"In my android code I have this

&lt;CheckedTextView
    android:id=""@+id/rememberMe""
    android:layout_width=""wrap_content""
    android:layout_height=""wrap_content""
    android:layout_alignRight=""@+id/advancedMenu""
    android:layout_below=""@+id/logInMode""
    android:checkMark=""@drawable/bg_checkbox""
    android:gravity=""center|center_horizontal""
    android:text=""@string/rememberMe""
    android:textColor=""#ffffff"" /&gt;


And bg_checkbox is

&lt;?xml version=""1.0"" encoding=""utf-8""?&gt;
&lt;selector xmlns:android=""http://schemas.android.com/apk/res/android""&gt;
     &lt;item android:state_checked=""true"" 
        android:drawable=""@drawable/checkbox_checked""
        android:state_focused=""false""&gt;
    &lt;/item&gt;
    &lt;item android:state_checked=""true"" 
        android:drawable=""@drawable/checkbox_checked""
        android:state_focused=""true""&gt;
    &lt;/item&gt;
    &lt;item android:state_checked=""false"" 
        android:drawable=""@drawable/checkbox""
        android:state_focused=""false""&gt;
    &lt;/item&gt;
    &lt;item android:state_checked=""false"" 
        android:drawable=""@drawable/checkbox""
        android:state_focused=""true""&gt;
    &lt;/item&gt;
&lt;/selector&gt;


This selector works for regular checkbox's, but for this, its not working, its just showing the unchecked state even if I click it.

Also, how can I put some space between the text and the checkbox?

Thanks.
",omega,https://stackoverflow.com/users/1497454,"Try using setCompoundDrawablePadding(int) (or android:drawablePadding in XML) to set some space between the text and checkbox.  

Regarding getting the selector working, &lt;CheckedTextView&gt; extends TextView, so try setting
android:clickable=""true"".  

Obviously, if you're using the CheckedTextView in a ListView, make sure your ChoiceMode isn't set to CHOICE_MODE_NONE.
",Sound Conception,https://stackoverflow.com/users/2598349,http://stackoverflow.com/questions/20319573/android-checktextview-now-working,STACKOVERFLOW,stackoverflow.com,1.0,0.4444444444444444,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.6666666666666666,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.3333333333333333,0.3333333333333333,1.0,Android checktextview is working,"In my android code I have this

&lt;CheckedTextView
    android:id=""@+id/rememberMe""
    android:layout_width=""wrap_content""
    android:layout_height=""wrap_content""
    android:layout_alignRight=""@+id/advancedMenu""
    android:layout_below=""@+id/logInMode""
    android:checkMark=""@drawable/bg_checkbox""
    android:gravity=""center|center_horizontal""
    android:text=""@string/rememberMe""
    android:textColor=""#ffffff"" /&gt;


And bg_checkbox is

&lt;?xml version=""1.0"" encoding=""utf-8""?&gt;
&lt;selector xmlns:android=""http://schemas.android.com/apk/res/android""&gt;
     &lt;item android:state_checked=""true"" 
        android:drawable=""@drawable/checkbox_checked""
        android:state_focused=""false""&gt;
    &lt;/item&gt;
    &lt;item android:state_checked=""true"" 
        android:drawable=""@drawable/checkbox_checked""
        android:state_focused=""true""&gt;
    &lt;/item&gt;
    &lt;item android:state_checked=""false"" 
        android:drawable=""@drawable/checkbox""
        android:state_focused=""false""&gt;
    &lt;/item&gt;
    &lt;item android:state_checked=""false"" 
        android:drawable=""@drawable/checkbox""
        android:state_focused=""true""&gt;
    &lt;/item&gt;
&lt;/selector&gt;


This selector works for regular checkbox's, but for this, its not working, its just showing the unchecked state even if I click it.

Also, how can I put some space between the text and the checkbox?

Thanks.
","Try using setCompoundDrawablePadding(int) (or android:drawablePadding in XML) to set some space between the text and checkbox.  

Regarding getting the selector working, &lt;CheckedTextView&gt; extends TextView, so try setting
android:clickable=""true"".  

Obviously, if you're using the CheckedTextView in a ListView, make sure your ChoiceMode isn't set to CHOICE_MODE_NONE.
"
27,27,38,Why is the potential function defined differently in physics and calculus?,"I am very familiar with the concept of a potential function, and potential energy, from calculus-based physics.

For instance, if we have the familiar force field $\mathbf{F} = -mg \,\mathbf{j}$, then a potential function is given by $U = mgy + C$. (Since potential energy is relative, we have an infinite number of potential functions.)

Notice that the gradient of the potential function is the negative of the force field: $$\nabla U = \nabla(mgy + C) = mg \,\mathbf{j} = -\mathbf{F}.$$

That was perfectly fine with me. But now in vector calculus, I am reading that the potential function $f$ of a vector function $\mathbf{F}$ is such that $\nabla f = \mathbf{F}$. A negative sign appears to have been lost when migrating from physics to calculus.

It seems confusing to call $f$ a ""potential function"", since it cannot be interpreted as potential energy in the real world. So why is the calculus nomenclature as it is (i.e., why not call this something else and then say the potential function is the negative of it)?
",Radon Rosborough,https://math.stackexchange.com/users/160658,"Recall where the negative sign comes from in physics -- it is simply due to your coordinate system and point of view. The difference is analogous to the difference between work done by gravity and work done on gravity.
",Nitin,https://math.stackexchange.com/users/217285,http://math.stackexchange.com/questions/1335576/why-is-the-potential-function-defined-differently-in-physics-and-calculus,SCIENCE,math.stackexchange.com,1.0,0.7777777777777778,0.0,1.0,1.0,1.0,0.6666666666666666,0.4444444444444444,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,0.8888888888888888,Why are potential functions defined differently in physics and calculus?,"I am very familiar with the concept of a potential function, and potential energy, from calculus-based physics.

For instance, if we have the familiar force field $\mathbf{F} = -mg \,\mathbf{j}$, then a potential function is given by $U = mgy + C$. (Since potential energy is relative, we have an infinite number of potential functions.)

Notice that the gradient of the potential function is the negative of the force field: $$\nabla U = \nabla(mgy + C) = mg \,\mathbf{j} = -\mathbf{F}.$$

That was perfectly fine with me. But now in vector calculus, I am reading that the potential function $f$ of a vector function $\mathbf{F}$ is such that $\nabla f = \mathbf{F}$. A negative sign appears to have been lost when migrating from physics to calculus.

It seems confusing to call $f$ a ""potential function"", since it cannot be interpreted as potential energy in the real world. So why is the calculus nomenclature as it is (i.e., why not call this something else and then say the potential function is the negative of it)?
",Think about where minus signs come from in Physics - it's just because of your coordinate system and your point of view. This difference is similar to the difference between gravity work and gravity work.
2176,2176,3468,Insert a Views Block into a node in Drupal 7,"[Drupal 7] 

I have a block I created in Views called ""handy_tips-block_1"".

Now I want to insert it into the body field of my node.

How do I do this?

I found a guide on here, which suggests to use the following code:

&lt;?php
print $block = module_invoke('views', 'block_view', 'handy_tips-block_1');
print render($block['content']['#content']);
?&gt;


However, all what is printed out are the words ""Array"".
(I have enabled the PHP input filter for the body field).

Note: in the posted code, I have also tried substituting 'views' with various items such as ""block"". I have used 'handy_tips-block_1' as the ID, because that is what is displayed on the configuration link of the block administration page. 
",big_smile,https://drupal.stackexchange.com/users/1606,"Output is ""array"" because indeed is an array, then I guess that you want to print your array to see what fields you can use:

print_r($block);
print_r($block['content']['#content']);
print_r(render($block['content']['#content']);


About display a View, you can use this line of code inside your template, to call a view:

echo views_embed_view('view-name', $display_id = 'display-name');


for example, inside my node.tl.php I want to insert a view called test view and I want to use his Block display with machine name block_test, then I can use:

echo views_embed_view('test_view', $display_id = 'block_test');


(Remember to use the machine name of your view and machine name of your display).

I hope this information will be useful.
",cigotete,https://drupal.stackexchange.com/users/2340,http://drupal.stackexchange.com/questions/13297/insert-a-views-block-into-a-node-in-drupal-7,TECHNOLOGY,drupal.stackexchange.com,0.7777777777777778,0.6666666666666666,0.0,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.8888888888888888,0.8333333333333334,0.6666666666666666,0.8333333333333334,1.0,0.9,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.7777777777777778,Inserting a view block into a node in Drupal 7,"[Drupal 7] 

I have a block I created in Views called ""handy_tips-block_1"".

Now I want to insert it into the body field of my node.

How do I do this?

I found a guide on here, which suggests to use the following code:

&lt;?php
print $block = module_invoke('views', 'block_view', 'handy_tips-block_1');
print render($block['content']['#content']);
?&gt;


However, all what is printed out are the words ""Array"".
(I have enabled the PHP input filter for the body field).

Note: in the posted code, I have also tried substituting 'views' with various items such as ""block"". I have used 'handy_tips-block_1' as the ID, because that is what is displayed on the configuration link of the block administration page. 
","Output is ""array"" because indeed is an array, then I guess that you want to print your array to see what fields you can use:

print_r($block);
print_r($block['content']['#content']);
print_r(render($block['content']['#content']);


About display a View, you can use this line of code inside your template, to call a view:

echo views_embed_view('view-name', $display_id = 'display-name');


for example, inside my node.tl.php I want to insert a view called test view and I want to use his Block display with machine name block_test, then I can use:

echo views_embed_view('test_view', $display_id = 'block_test');


(Remember to use the machine name of your view and machine name of your display).

I hope this information will be useful.
"
4443,4443,7052,Offline WordPress post editor/creator,"I have a WordPress site hosted on my personal server. I will be unavailable by Internet for a little while, and I'd like to write up some posts for my blog.

Normally, you need to be connected to WordPress to start writing the blog, and it will do offline-saving automatically. But this is limited to one entry, per tab. I could use Notepad, but it doesn't have spell check built in. I could use Microsoft Word, but the ""Paste from Word"" leaves a lot to be desired.

What I'm looking for is a program that does the following:


Start a new post while offline
Lets me edit posts I created already with the program
Spell check
Uploads new posts when I reconnect
Has the same features as the online editor (i.e. toolbars, WYSIWYG and code editor)
Free (as in beer)
Works on either Windows or Mac OSX


Bonus features:


Edit posts currently on the website (with an offline copy)

",Canadian Luke,https://softwarerecs.stackexchange.com/users/258,"For the mac users there's blogo. By the time of this writing, the version 1 has been discontinued and the version 2 hasn't yet been released, but there's a video on the official site showing its capabilities. Those include:


WordPress, tumblr and blogger / blogspot support
Offline composing
Editing of already published posts
Visual editor that uses the actual site theme to render the preview


Possible drawbacks:


Works only on mac
Not free


Looks like it doesn't offer spell-checking natively, but there will be a plugin system and it's possible that there'll be a speelcheck plugin for blogo:


  Power Ups are add-ons that will be available via in-app purchase to make your Blogo experience even better. 

",That Brazilian Guy,https://softwarerecs.stackexchange.com/users/554,http://softwarerecs.stackexchange.com/questions/2696/offline-wordpress-post-editor-creator,SCIENCE,softwarerecs.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,0.5,1.0,0.5,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.0,0.3333333333333333,0.0,0.3333333333333333,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.3333333333333333,0.0,0.7777777777777778,0.7777777777777778,0.5555555555555556,0.8888888888888888,1.0,0.6666666666666667,0.3333333333333333,0.0,0.6666666666666666,0.5555555555555556,Offline WordPress article editor / creator,"I have a WordPress site hosted on my personal server. I will be unavailable by Internet for a little while, and I'd like to write up some posts for my blog.

Normally, you need to be connected to WordPress to start writing the blog, and it will do offline-saving automatically. But this is limited to one entry, per tab. I could use Notepad, but it doesn't have spell check built in. I could use Microsoft Word, but the ""Paste from Word"" leaves a lot to be desired.

What I'm looking for is a program that does the following:


Start a new post while offline
Lets me edit posts I created already with the program
Spell check
Uploads new posts when I reconnect
Has the same features as the online editor (i.e. toolbars, WYSIWYG and code editor)
Free (as in beer)
Works on either Windows or Mac OSX


Bonus features:


Edit posts currently on the website (with an offline copy)

","For the mac users there's blogo. By the time of this writing, the version 1 has been discontinued and the version 2 hasn't yet been released, but there's a video on the official site showing its capabilities. Those include:


WordPress, tumblr and blogger / blogspot support
Offline composing
Editing of already published posts
Visual editor that uses the actual site theme to render the preview


Possible drawbacks:


Works only on mac
Not free


Looks like it doesn't offer spell-checking natively, but there will be a plugin system and it's possible that there'll be a speelcheck plugin for blogo:


  Power Ups are add-ons that will be available via in-app purchase to make your Blogo experience even better. 

"
6043,6043,9588,Safari - is there a way to set a preferred screen size?,"As the title says, I would like new windows to open in a set screen size. I believe that the default is that they open in the size of the last window. Sometimes, I want to make a window smaller for some reason, but I want new windows to open as usual. Is there a shell script/command to accomplish this? Thanks 
",David DelMonte,https://apple.stackexchange.com/users/11128,"I use the following bookmark, which you can create as many as needed, to resize my safari window to a specific size:

javascript:self.moveTo(0,0);self.resizeTo(1250,screen.availHeight);


This moves the window to the far left, top and then makes the width 1250 pixels and makes the hight fill to the available (limited by the dock hight, if not hidden).

To use, bookmark any page and then edit the address with the code above.

Every now and again, an update to safari will break this, and then it'll work again after a subsequent update. 
",quip,https://apple.stackexchange.com/users/28392,http://apple.stackexchange.com/questions/110737/safari-is-there-a-way-to-set-a-preferred-screen-size,TECHNOLOGY,apple.stackexchange.com,0.7777777777777778,0.5555555555555556,0.0,0.5,1.0,1.0,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8,0.6666666666666666,0.3333333333333333,0.0,0.5555555555555556,Safari - is there a way to set the preferred screen size?,"As the title shows, I want the new window to open at the set screen size. I think the default is that they open the same size as the last window. Sometimes, I want to narrow a window for some reason, but I want to open a new window as usual. Is there a shell script / command to complete this task? Thank you","I use the following bookmark, which you can create as many as needed, to resize my safari window to a specific size:

javascript:self.moveTo(0,0);self.resizeTo(1250,screen.availHeight);


This moves the window to the far left, top and then makes the width 1250 pixels and makes the hight fill to the available (limited by the dock hight, if not hidden).

To use, bookmark any page and then edit the address with the code above.

Every now and again, an update to safari will break this, and then it'll work again after a subsequent update. 
"
1212,1212,1903,Mystery cards in Magic 2015 card list,"If you look at the full card list for Magic 2015, at Gatherer or elsewhere, you'll see a bunch of cards listed with collectors number 270-284. What are these cards, and why are they listed as being part of Magic 2015? I played enough M15 Limited to be pretty sure that they aren't actually present in packs, and they're listed after the basic lands, which is very unusual. Is there some secret, bonus release of M15 that had these extra cards?
",JSBձոգչ,https://boardgames.stackexchange.com/users/156,"These are cards which you can get in the M15 learn to play packs. You can get these at your local (WPN) game store, but are mostly given to players which are new to the game.
",Ivo Geersen,https://boardgames.stackexchange.com/users/5859,http://boardgames.stackexchange.com/questions/19165/mystery-cards-in-magic-2015-card-list,CULTURE,boardgames.stackexchange.com,1.0,0.4444444444444444,0.0,1.0,1.0,1.0,0.6666666666666666,0.4444444444444444,0.6666666666666666,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.6666666666666666,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,0.6666666666666666,0.8888888888888888,Magic's Secret card ranking in 2015,"If you look at the complete list of magic 2015 cards in the gatherer or elsewhere, you will see a pile of cards listing collectors numbered 270-284. What are these cards and why are they listed as part of magic 2015? I played enough M15 restrictions to make sure they didn't actually appear in the package and they were listed in the base land, which is very unusual. Are there any secrets that bonus release M15 has these extra cards?","These are cards which you can get in the M15 learn to play packs. You can get these at your local (WPN) game store, but are mostly given to players which are new to the game.
"
3211,3211,5121,Rotating vector3 by a quaternion,"I am attempting to rotate a vector3 by a given quaternion.

I know that this is true

v' = q * v * (q^-1)


I know that q^(-1) is the inverse which just -q/magnitude(q), but how do I map the multiplication of the vector to the quaternion to get back a vector?

I have found that you can treat v as a matrix, and convert q, and q' to matrices, and then convert v' from a matrix to a vector, but this seems a little over the top just to get a vector. Is there a cleaner implementation that I could use?
",gardian06,https://gamedev.stackexchange.com/users/14586,"As Nathan Reed and teodron exposed, the recipe for rotating a vector v by a unit-length quaternion q is:

1) Create a pure quaternion p out of v. This simply means adding a fourth coordinate of 0:



2) Pre-multiply it with q and post-multiply it with the conjugate q*:



3) This will result in another pure quaternion which can be turned back to a vector:



This vector v' is v rotated by q.



This is working but far from optimal. Quaternion multiplications mean tons and tons of operations. I was curious about various implementations such as this one, and decided to find from where those came. Here are my findings.

We can also describe q as the combination of a 3-dimensional vector u and a scalar s:



By the rules of quaternion multiplication, and as the conjugate of a unit length quaternion is simply it's inverse, we get:



The scalar part (ellipses) results in zero, as detailed here. What's interesting is the vector part, AKA our rotated vector v'. It can be simplified using some basic vector identities:



This is now much more optimal; two dot products, a cross product and a few extras: around half the operations. Which would give something like that in source code (assuming some generic vector math library):

void rotate_vector_by_quaternion(const Vector3&amp; v, const Quaternion&amp; q, Vector3&amp; vprime)
{
    // Extract the vector part of the quaternion
    Vector3 u(q.x, q.y, q.z);

    // Extract the scalar part of the quaternion
    float s = q.w;

    // Do the math
    vprime = 2.0f * dot(u, v) * u
          + (s*s - dot(u, u)) * v
          + 2.0f * s * cross(u, v);
}

",Laurent Couvidou,https://gamedev.stackexchange.com/users/14808,http://gamedev.stackexchange.com/questions/28395/rotating-vector3-by-a-quaternion,TECHNOLOGY,gamedev.stackexchange.com,0.3333333333333333,1.0,0.0,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,0.0,1.0,Quaternion rotation vector 3,"I am attempting to rotate a vector3 by a given quaternion.

I know that this is true

v' = q * v * (q^-1)


I know that q^(-1) is the inverse which just -q/magnitude(q), but how do I map the multiplication of the vector to the quaternion to get back a vector?

I have found that you can treat v as a matrix, and convert q, and q' to matrices, and then convert v' from a matrix to a vector, but this seems a little over the top just to get a vector. Is there a cleaner implementation that I could use?
","As Nathan Reed and teodron exposed, the recipe for rotating a vector v by a unit-length quaternion q is:

1) Create a pure quaternion p out of v. This simply means adding a fourth coordinate of 0:



2) Pre-multiply it with q and post-multiply it with the conjugate q*:



3) This will result in another pure quaternion which can be turned back to a vector:



This vector v' is v rotated by q.



This is working but far from optimal. Quaternion multiplications mean tons and tons of operations. I was curious about various implementations such as this one, and decided to find from where those came. Here are my findings.

We can also describe q as the combination of a 3-dimensional vector u and a scalar s:



By the rules of quaternion multiplication, and as the conjugate of a unit length quaternion is simply it's inverse, we get:



The scalar part (ellipses) results in zero, as detailed here. What's interesting is the vector part, AKA our rotated vector v'. It can be simplified using some basic vector identities:



This is now much more optimal; two dot products, a cross product and a few extras: around half the operations. Which would give something like that in source code (assuming some generic vector math library):

void rotate_vector_by_quaternion(const Vector3&amp; v, const Quaternion&amp; q, Vector3&amp; vprime)
{
    // Extract the vector part of the quaternion
    Vector3 u(q.x, q.y, q.z);

    // Extract the scalar part of the quaternion
    float s = q.w;

    // Do the math
    vprime = 2.0f * dot(u, v) * u
          + (s*s - dot(u, u)) * v
          + 2.0f * s * cross(u, v);
}

"
5233,5233,8320,"How should I take a potential PhD supervisor's age into account, when planning to follow PhD with habilitation?","I plan to apply for PhD in Finance/Statistics next semester, and hence searched for potential supervisors.

An issue I have is that many interesting candidates are above age 60, and in Germany Professors retire at 65, such that a subsequent post-doc/habilitation would most likely require a different supervisor after PhD. One Professor just started his position at age 40, but so he has not many notable publications and I am unsure whether he might change university soon (he just changed it from another 4 years position).

Could someone advise me on the importance of age for selecting a PhD supervisor in context of a long-term future academic career?

The time for PhD would be 4-5 years, and PostDoc/Habilitation/AssociateProf usually again 4-6 years, with goal of potentially becoming Full Professor in Finance/Statistics.
",emcor,https://academia.stackexchange.com/users/18228,"As others have mentioned, planning the trajectory of your academic career past your PhD is very premature at this point. (After all, one of the jobs of your PhD advisor is precisely to help you with this.)

Something that -- surprisingly -- has not been mentioned so far: Talk to the professors. Taking on a PhD student is a serious commitment no advisor will make lightly, so if they have any doubts whether you can complete the thesis with them (either because they plan on retiring completely from academic life, or moving next year to a different continent), they will tell you so. We can only guess at the likelihood, but they will (hopefully) have a much clearer idea.
",Christian Clason,https://academia.stackexchange.com/users/13852,http://academia.stackexchange.com/questions/24439/how-should-i-take-a-potential-phd-supervisors-age-into-account-when-planning-t,LIFE_ARTS,academia.stackexchange.com,1.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.4444444444444444,0.5555555555555556,0.3333333333333333,0.0,1.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.7777777777777778,0.8888888888888888,0.5555555555555556,1.0,1.0,0.6666666666666667,0.0,0.3333333333333333,0.3333333333333333,1.0,How should I consider the age of a potential Ph.D. supervisor when I intend to continue to pursue a Ph.D. degree with adaptability?,"I plan to apply for PhD in Finance/Statistics next semester, and hence searched for potential supervisors.

An issue I have is that many interesting candidates are above age 60, and in Germany Professors retire at 65, such that a subsequent post-doc/habilitation would most likely require a different supervisor after PhD. One Professor just started his position at age 40, but so he has not many notable publications and I am unsure whether he might change university soon (he just changed it from another 4 years position).

Could someone advise me on the importance of age for selecting a PhD supervisor in context of a long-term future academic career?

The time for PhD would be 4-5 years, and PostDoc/Habilitation/AssociateProf usually again 4-6 years, with goal of potentially becoming Full Professor in Finance/Statistics.
","As others have mentioned, planning the trajectory of your academic career past your PhD is very premature at this point. (After all, one of the jobs of your PhD advisor is precisely to help you with this.)

Something that -- surprisingly -- has not been mentioned so far: Talk to the professors. Taking on a PhD student is a serious commitment no advisor will make lightly, so if they have any doubts whether you can complete the thesis with them (either because they plan on retiring completely from academic life, or moving next year to a different continent), they will tell you so. We can only guess at the likelihood, but they will (hopefully) have a much clearer idea.
"
4714,4714,7476,JSP mechanism for nav bar template/module,"I have a navigation bar and, for some pages, a sub-navigation bar as well.  I'd like to make this a module so I can easily import the navigation bars on each page.  Easy enough to simply put the code in a JSP file and call:

&lt;%@include file=""/WEB-INF/jsp/includes/sub_nav_bar.jsp""%&gt;


the only issue is the links and their labels change depending on what page you're on.  So my options are to create separate navigation bars for various groups of pages or pass in variables representing the links and labels.  Separate navigation bars isn't attractive because there are so many variations, particularly with the sub nav bars.  I'll end up with tons of navigation bars, all of which I have to maintain.

The variables approach works, but I'm hoping there's a better way to do this.  It's so messy and lengthy.  If I want to later have drop down menus, it's going to be even much worse.  Basically, I've done something to this effect:

&lt;c:set var=""subNav"" value=""1""/&gt;
&lt;c:set var=""subNavLink1"" value=""/""/&gt;
&lt;c:set var=""subNavLabel1"" value=""Home""/&gt;
&lt;c:set var=""subNavLink2"" value=""/fun""/&gt;
&lt;c:set var=""subNavLabel2"" value=""Fun Stuff""/&gt;
&lt;c:set var=""subNavLink3"" value=""/more""/&gt;
&lt;c:set var=""subNavLabel3"" value=""More Stuff""/&gt;
&lt;%@include file=""/WEB-INF/jsp/includes/sub_nav_bar.jsp""%&gt;


the sub_nav_bar.jsp include file looks pretty ugly:

&lt;ul id=""sub-nav""&gt;
    &lt;li class=""&lt;c:if test=""${subNav!='1'}""&gt;in&lt;/c:if&gt;active""&gt;&lt;a href=""&lt;c:url value='${subNavLink1}'/&gt;""&gt;${subNavLabel1}&lt;/a&gt;&lt;/li&gt;
    &lt;c:if test=""${subNavLink2!=null}""&gt;&lt;li class=""&lt;c:if test=""${subNav!='2'}""&gt;in&lt;/c:if&gt;active""&gt;&lt;a href=""&lt;c:url value='${subNavLink2}'/&gt;""&gt;${subNavLabel2}&lt;/a&gt;&lt;/li&gt;&lt;/c:if&gt;
    &lt;c:if test=""${subNavLink3!=null}""&gt;&lt;li class=""&lt;c:if test=""${subNav!='3'}""&gt;in&lt;/c:if&gt;active""&gt;&lt;a href=""&lt;c:url value='${subNavLink3}'/&gt;""&gt;${subNavLabel3}&lt;/a&gt;&lt;/li&gt;&lt;/c:if&gt;
    &lt;c:if test=""${subNavLink4!=null}""&gt;&lt;li class=""&lt;c:if test=""${subNav!='4'}""&gt;in&lt;/c:if&gt;active""&gt;&lt;a href=""&lt;c:url value='${subNavLink4}'/&gt;""&gt;${subNavLabel4}&lt;/a&gt;&lt;/li&gt;&lt;/c:if&gt;
&lt;/ul&gt;


So is there a better way?
",at.,https://stackoverflow.com/users/326389,"Any reason for you to stick to plain JSP/JSTL? Most web frameworks would simplify this work for you. The key would be to have a templating system like tiles, sitemesh, facelet, freemarker, ...
",Damien,https://stackoverflow.com/users/271887,http://stackoverflow.com/questions/3654472/jsp-mechanism-for-nav-bar-template-module,STACKOVERFLOW,stackoverflow.com,1.0,0.4444444444444444,0.0,1.0,1.0,1.0,0.5555555555555556,0.5555555555555556,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.0,0.0,0.6666666666666666,0.7777777777777778,0.5,0.8888888888888888,0.8888888888888888,0.6,0.3333333333333333,0.0,0.3333333333333333,0.7777777777777778,JSP mechanism of navigation bar template / module,"I have a navigation bar and, for some pages, a sub-navigation bar as well.  I'd like to make this a module so I can easily import the navigation bars on each page.  Easy enough to simply put the code in a JSP file and call:

&lt;%@include file=""/WEB-INF/jsp/includes/sub_nav_bar.jsp""%&gt;


the only issue is the links and their labels change depending on what page you're on.  So my options are to create separate navigation bars for various groups of pages or pass in variables representing the links and labels.  Separate navigation bars isn't attractive because there are so many variations, particularly with the sub nav bars.  I'll end up with tons of navigation bars, all of which I have to maintain.

The variables approach works, but I'm hoping there's a better way to do this.  It's so messy and lengthy.  If I want to later have drop down menus, it's going to be even much worse.  Basically, I've done something to this effect:

&lt;c:set var=""subNav"" value=""1""/&gt;
&lt;c:set var=""subNavLink1"" value=""/""/&gt;
&lt;c:set var=""subNavLabel1"" value=""Home""/&gt;
&lt;c:set var=""subNavLink2"" value=""/fun""/&gt;
&lt;c:set var=""subNavLabel2"" value=""Fun Stuff""/&gt;
&lt;c:set var=""subNavLink3"" value=""/more""/&gt;
&lt;c:set var=""subNavLabel3"" value=""More Stuff""/&gt;
&lt;%@include file=""/WEB-INF/jsp/includes/sub_nav_bar.jsp""%&gt;


the sub_nav_bar.jsp include file looks pretty ugly:

&lt;ul id=""sub-nav""&gt;
    &lt;li class=""&lt;c:if test=""${subNav!='1'}""&gt;in&lt;/c:if&gt;active""&gt;&lt;a href=""&lt;c:url value='${subNavLink1}'/&gt;""&gt;${subNavLabel1}&lt;/a&gt;&lt;/li&gt;
    &lt;c:if test=""${subNavLink2!=null}""&gt;&lt;li class=""&lt;c:if test=""${subNav!='2'}""&gt;in&lt;/c:if&gt;active""&gt;&lt;a href=""&lt;c:url value='${subNavLink2}'/&gt;""&gt;${subNavLabel2}&lt;/a&gt;&lt;/li&gt;&lt;/c:if&gt;
    &lt;c:if test=""${subNavLink3!=null}""&gt;&lt;li class=""&lt;c:if test=""${subNav!='3'}""&gt;in&lt;/c:if&gt;active""&gt;&lt;a href=""&lt;c:url value='${subNavLink3}'/&gt;""&gt;${subNavLabel3}&lt;/a&gt;&lt;/li&gt;&lt;/c:if&gt;
    &lt;c:if test=""${subNavLink4!=null}""&gt;&lt;li class=""&lt;c:if test=""${subNav!='4'}""&gt;in&lt;/c:if&gt;active""&gt;&lt;a href=""&lt;c:url value='${subNavLink4}'/&gt;""&gt;${subNavLabel4}&lt;/a&gt;&lt;/li&gt;&lt;/c:if&gt;
&lt;/ul&gt;


So is there a better way?
","Why do you insist on using JSP / JSTL? Most web frameworks simplify this for you. The key is to have a template system, such as tiles, SiteMesh, facelet, FreeMarker..."
3785,3785,6020,intersection between two multipolygons yielding anomalous GeometryCollection object full of LineString's & Polygon's (trying to get intersect area),"Normally when I call the #intersection method on a multipolygon to find the intersection shape on another multipolygon I get a multipolygon returned back to me. Either that or something else I can then call the #area function on.

Well, 150 spatial joins into a list of zoning shapefiles (ie this is a rare case) I'm scanning through my code throws an error because it can't call the #area method on a CAPIGeometryCollection. I am having problems linking qgis with my postgresql db and don't know how to create a kml for a ""GeometryCollection"" object

Here's what the WKT string output for the intersection shape looks like:

""GEOMETRYCOLLECTION (LINESTRING (1480424.245856002 596629.5658560097, 1480362.875856012 596566.8158560097), LINESTRING (1480362.875856012 596566.8158560097, 1480293.995856002 596496.4358560145), LINESTRING (1480293.995856002 596496.4358560145, 1480235.625856012 596435.0658560097), LINESTRING (1480235.625856012 596435.0658560097, 1480186.495856002 596385.8158560097), LINESTRING (1480186.495856002 596385.8158560097, 1480146.125856012 596345.3758560121), LINESTRING (1480146.125856012 596345.3758560121, 1480141.125856012 596341.3158560097), LINESTRING (1480141.125856012 596341.3158560097, 1480090.995856002 596301.3158560097), LINESTRING (1480090.995856002 596301.3158560097, 1480044.875856012 596263.8758560121), LINESTRING (1480044.875856012 596263.8758560121, 1480005.745856002 596231.995856002), POLYGON ((1480512.6034600246 596678.2322904326, 1480512.598981008 596678.1839810014, 1480511.7765895594 596677.7314431852, 1480512.6034600246 596678.2322904326)), POLYGON ((1480005.745856002 596231.995856002, 1479874.7139810026 596136.0839810073, 1479816.8752310127 596088.7502310127, 1479758.3752310127 596040.8127310127, 1479707.547731012 595999.19689875, 1479758.375856012 596040.8158560097, 1479816.875856012 596088.8158560097, 1479875.375856012 596136.6258560121, 1480005.745856002 596231.995856002)))""


I could skip this error with a rescue block or a next identifier and move on per case but that's not very professional. Documentation on this issue is extremely slim so I figured I'd contribute with a stackexchange question

Plus (just checked), I can't load GEOMETRYCOLLECTION wkts into qgis (currently passing in the polygons &amp; line string arghhs each by hand)

(note: someone with >300 points or whatever mark this question with these new question tags: 'geometry-collection' &amp; 'multi-polygon', they're pretty basic to gis I think, esp the multipolygons, thanks)

EDIT:
I could pluck out the polygon(s) from these collections, but I'm wondering what these linestrings mean (i.e. maybe they're the exterior rings of polygons that are part of the intersect shape)
",boulder_ruby,https://gis.stackexchange.com/users/20514,"Solution for now: ignore the LineStrings, these are probably produced by an ""st_touches"" type spatial join where only the perimeters of the multipolygons are touching

RGeo allows you to break out the pieces of a Geometry Collection so I wrote some code to catch the intersect shape if its a GeometryCollection type, sending it to a different area to pluck out the polygons, sum up their size, mark that as the intersect size, and move on

    x = shape.intersection(p.proj_shape_2264)
    if x.geometry_type.to_s == ""GeometryCollection""
      area = 0
      (0..(x.count - 1)).to_a.each do |k| 
        collection_shape = x.geometry_n(k)
        next if collection_shape.geometry_type.to_s == ""LineString""
        area  += collection_shape.area            
      end
      z.intersect_size = area
    else

",boulder_ruby,https://gis.stackexchange.com/users/20514,http://gis.stackexchange.com/questions/74112/intersection-between-two-multipolygons-yielding-anomalous-geometrycollection-obj,TECHNOLOGY,gis.stackexchange.com,1.0,0.5555555555555556,0.0,0.6666666666666666,0.3333333333333333,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.6666666666666666,0.0,0.5555555555555556,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.0,0.0,0.8888888888888888,The intersection between two polygons produces an abnormal geometric set object full of line strings and polygons (trying to get the intersection area),"Normally when I call the #intersection method on a multipolygon to find the intersection shape on another multipolygon I get a multipolygon returned back to me. Either that or something else I can then call the #area function on.

Well, 150 spatial joins into a list of zoning shapefiles (ie this is a rare case) I'm scanning through my code throws an error because it can't call the #area method on a CAPIGeometryCollection. I am having problems linking qgis with my postgresql db and don't know how to create a kml for a ""GeometryCollection"" object

Here's what the WKT string output for the intersection shape looks like:

""GEOMETRYCOLLECTION (LINESTRING (1480424.245856002 596629.5658560097, 1480362.875856012 596566.8158560097), LINESTRING (1480362.875856012 596566.8158560097, 1480293.995856002 596496.4358560145), LINESTRING (1480293.995856002 596496.4358560145, 1480235.625856012 596435.0658560097), LINESTRING (1480235.625856012 596435.0658560097, 1480186.495856002 596385.8158560097), LINESTRING (1480186.495856002 596385.8158560097, 1480146.125856012 596345.3758560121), LINESTRING (1480146.125856012 596345.3758560121, 1480141.125856012 596341.3158560097), LINESTRING (1480141.125856012 596341.3158560097, 1480090.995856002 596301.3158560097), LINESTRING (1480090.995856002 596301.3158560097, 1480044.875856012 596263.8758560121), LINESTRING (1480044.875856012 596263.8758560121, 1480005.745856002 596231.995856002), POLYGON ((1480512.6034600246 596678.2322904326, 1480512.598981008 596678.1839810014, 1480511.7765895594 596677.7314431852, 1480512.6034600246 596678.2322904326)), POLYGON ((1480005.745856002 596231.995856002, 1479874.7139810026 596136.0839810073, 1479816.8752310127 596088.7502310127, 1479758.3752310127 596040.8127310127, 1479707.547731012 595999.19689875, 1479758.375856012 596040.8158560097, 1479816.875856012 596088.8158560097, 1479875.375856012 596136.6258560121, 1480005.745856002 596231.995856002)))""


I could skip this error with a rescue block or a next identifier and move on per case but that's not very professional. Documentation on this issue is extremely slim so I figured I'd contribute with a stackexchange question

Plus (just checked), I can't load GEOMETRYCOLLECTION wkts into qgis (currently passing in the polygons &amp; line string arghhs each by hand)

(note: someone with >300 points or whatever mark this question with these new question tags: 'geometry-collection' &amp; 'multi-polygon', they're pretty basic to gis I think, esp the multipolygons, thanks)

EDIT:
I could pluck out the polygon(s) from these collections, but I'm wondering what these linestrings mean (i.e. maybe they're the exterior rings of polygons that are part of the intersect shape)
","Solution for now: ignore the LineStrings, these are probably produced by an ""st_touches"" type spatial join where only the perimeters of the multipolygons are touching

RGeo allows you to break out the pieces of a Geometry Collection so I wrote some code to catch the intersect shape if its a GeometryCollection type, sending it to a different area to pluck out the polygons, sum up their size, mark that as the intersect size, and move on

    x = shape.intersection(p.proj_shape_2264)
    if x.geometry_type.to_s == ""GeometryCollection""
      area = 0
      (0..(x.count - 1)).to_a.each do |k| 
        collection_shape = x.geometry_n(k)
        next if collection_shape.geometry_type.to_s == ""LineString""
        area  += collection_shape.area            
      end
      z.intersect_size = area
    else

"
4430,4430,7037,"""I wanted you to know that ..."" is it mean or offensive","I am not a native English speaker. I am writing an email to my boss and I want him to know an important thing, so will it be ok to say ""I wanted you to know that ..."", it is offensive/mean etc in any sense ?
",Androider,https://ell.stackexchange.com/users/3471,"I don't find it offensive or mean. If you wanted to soften the language somewhat, though, you could use:


  I wanted to let you know that ...


NOAD defines that idiomatic phrase as:


  let someone know inform someone 


You could also avoid the use of the word you by saying:


  I just wanted to say that...


which often implies that you are simply passing some information along.
",J.R.,https://ell.stackexchange.com/users/113,http://ell.stackexchange.com/questions/14230/i-wanted-you-to-know-that-is-it-mean-or-offensive,CULTURE,ell.stackexchange.com,1.0,0.8888888888888888,0.0,1.0,0.3333333333333333,0.6666666666666666,0.5555555555555556,0.6666666666666666,0.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,0.3333333333333333,0.8888888888888888,"""I want you to know..."" Is it mean or offensive","I am not a native speaker of English. I am writing an email to my boss. I want him to know an important thing, so I say ""I want you to know..."" OK? Is it offensive / despicable in any sense?","I don't find it offensive or mean. If you wanted to soften the language somewhat, though, you could use:


  I wanted to let you know that ...


NOAD defines that idiomatic phrase as:


  let someone know inform someone 


You could also avoid the use of the word you by saying:


  I just wanted to say that...


which often implies that you are simply passing some information along.
"
4088,4088,6524,Increasing voltage source frequency,"I am trying to simulate a simple circuit using a simulation program like SPICE. In the beginning of the circuit I have a pulse train voltage source, later it is connected to a normal LPF. The voltage source frequency is set as 1 kHz, my question is how to increase this frequency? 

The only options that I have is to change the time of the cycle and the voltage. If I set 1 ms and 5V, the frequency will be 1 kHz.

If I change the time to 0.5 ms, the result will be 5V for 0.5 ms and the rest is 0. (The second cycle will not start after 0.5 ms, so the frequency is same 1 kHz). Strange!

How do I increase the frequency of the voltage source?
",yaya,https://electronics.stackexchange.com/users/53052,"You can change the frequency by making changes in either time or frequency. As you mentioned that you have changed time to 0.5ms, please make sure whether you have changed time period of one complete cycle (on time + off time). If your time period of one complete cycle is 0.5ms, your frequency should be 2khz, because frequency is number of cycles per second.
",dasan,https://electronics.stackexchange.com/users/53041,http://electronics.stackexchange.com/questions/129410/increasing-voltage-source-frequency,SCIENCE,electronics.stackexchange.com,0.7777777777777778,0.4444444444444444,0.0,1.0,1.0,1.0,0.6666666666666666,0.5555555555555556,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.8888888888888888,Increase voltage source frequency,"I am trying to simulate a simple circuit using a simulation program like SPICE. In the beginning of the circuit I have a pulse train voltage source, later it is connected to a normal LPF. The voltage source frequency is set as 1 kHz, my question is how to increase this frequency? 

The only options that I have is to change the time of the cycle and the voltage. If I set 1 ms and 5V, the frequency will be 1 kHz.

If I change the time to 0.5 ms, the result will be 5V for 0.5 ms and the rest is 0. (The second cycle will not start after 0.5 ms, so the frequency is same 1 kHz). Strange!

How do I increase the frequency of the voltage source?
","You can change the frequency by making changes in either time or frequency. As you mentioned that you have changed time to 0.5ms, please make sure whether you have changed time period of one complete cycle (on time + off time). If your time period of one complete cycle is 0.5ms, your frequency should be 2khz, because frequency is number of cycles per second.
"
3491,3491,5571,Offline WordPress post editor/creator,"I have a WordPress site hosted on my personal server. I will be unavailable by Internet for a little while, and I'd like to write up some posts for my blog.

Normally, you need to be connected to WordPress to start writing the blog, and it will do offline-saving automatically. But this is limited to one entry, per tab. I could use Notepad, but it doesn't have spell check built in. I could use Microsoft Word, but the ""Paste from Word"" leaves a lot to be desired.

What I'm looking for is a program that does the following:


Start a new post while offline
Lets me edit posts I created already with the program
Spell check
Uploads new posts when I reconnect
Has the same features as the online editor (i.e. toolbars, WYSIWYG and code editor)
Free (as in beer)
Works on either Windows or Mac OSX


Bonus features:


Edit posts currently on the website (with an offline copy)

",Canadian Luke,https://softwarerecs.stackexchange.com/users/258,"As I recall the SU blog runs on wordpress, and I was using windows live writer to post on it. Its part of windows essentials, works with WP blogs and if I recall correctly did/does most of what you have listed there 


Start a new post while offline - yes
Lets me edit posts I created already with the program yes (though I can't remember if it edits uploaded posts)
Spell check - and grammar check
Uploads new posts when I reconnect - yes
Has the same features as the online editor (i.e. toolbars, WYSIWYG and Code editor)kind of - it has its own UI but its broadly compatible and in some ways better
Free (as in beer) yes
Works on either Windows or Mac OSX - windows only

",Journeyman Geek,https://softwarerecs.stackexchange.com/users/125,http://softwarerecs.stackexchange.com/questions/2696/offline-wordpress-post-editor-creator,SCIENCE,softwarerecs.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,0.6666666666666666,1.0,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.3333333333333333,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,0.8888888888888888,0.8666666666666666,0.6666666666666666,0.0,0.3333333333333333,0.6666666666666666,Offline WordPress article editor / creator,"I have a WordPress site hosted on my personal server. I will be unavailable by Internet for a little while, and I'd like to write up some posts for my blog.

Normally, you need to be connected to WordPress to start writing the blog, and it will do offline-saving automatically. But this is limited to one entry, per tab. I could use Notepad, but it doesn't have spell check built in. I could use Microsoft Word, but the ""Paste from Word"" leaves a lot to be desired.

What I'm looking for is a program that does the following:


Start a new post while offline
Lets me edit posts I created already with the program
Spell check
Uploads new posts when I reconnect
Has the same features as the online editor (i.e. toolbars, WYSIWYG and code editor)
Free (as in beer)
Works on either Windows or Mac OSX


Bonus features:


Edit posts currently on the website (with an offline copy)

","As I recall the SU blog runs on wordpress, and I was using windows live writer to post on it. Its part of windows essentials, works with WP blogs and if I recall correctly did/does most of what you have listed there 


Start a new post while offline - yes
Lets me edit posts I created already with the program yes (though I can't remember if it edits uploaded posts)
Spell check - and grammar check
Uploads new posts when I reconnect - yes
Has the same features as the online editor (i.e. toolbars, WYSIWYG and Code editor)kind of - it has its own UI but its broadly compatible and in some ways better
Free (as in beer) yes
Works on either Windows or Mac OSX - windows only

"
1495,1495,2352,Can only access one of the router's web portal and the Internet,"On both wired and wireless connections, I can only access one of 192.168.1.1 (the router web portal) and the general Internet.  Which ""mode"" my devices are in is seemingly random.  This has persisted so far for 5 days (since I began using this network).

When connected to the Internet, I can go to 192.168.102.1 and I see a landing page for ""mikrotik routeros"", but I cannot go to 192.168.1.1. When connected to the router but not the Internet, 192.168.1.1 yields the router web portal, and 192.168.102.1 is inaccessible.

Attempted solutions


Upgrading router firmware  
Resetting router to factory settings  
Rebooting devices  
Fiddling with router settings (changing wireless security modes, removing wireless security, etc)  
Upgrading wireless drivers on computers  


Some data


Affects BlackBerry, Windows, Android and Ubuntu devices
All devices work properly on other networks
Devices may switch modes if they have been offline for a long time (eg: overnight), but restarting a device has no effect
Router is TP-Link TL-WR740N v4
Router firmware DD-WRT v24-sp2 (04/18/14) std - build 23919
Both wired and wireless connections are affected, but not necessarily simultaneously


I don't know anything about networking, but here's some info that seems helpful taken from my Ubuntu laptop.

With internet access (wired in this case, but it varies):

~ $ route -n
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
0.0.0.0         192.168.102.1   0.0.0.0         UG    0      0        0 eth0
192.168.102.0   0.0.0.0         255.255.254.0   U     1      0        0 eth0

~ $ ifconfig
eth0      Link encap:Ethernet  HWaddr 54:ee:75:0c:02:80  
          inet addr:192.168.103.232  Bcast:192.168.103.255  Mask:255.255.254.0
          inet6 addr: fe80::56ee:75ff:fe0c:280/64 Scope:Link
          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
          RX packets:3273 errors:0 dropped:0 overruns:0 frame:0
          TX packets:3035 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:1000 
          RX bytes:2276482 (2.2 MB)  TX bytes:517732 (517.7 KB)
          Interrupt:20 Memory:f0500000-f0520000 

lo        Link encap:Local Loopback  
          inet addr:127.0.0.1  Mask:255.0.0.0
          inet6 addr: ::1/128 Scope:Host
          UP LOOPBACK RUNNING  MTU:65536  Metric:1
          RX packets:4315 errors:0 dropped:0 overruns:0 frame:0
          TX packets:4315 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:0 
          RX bytes:342880 (342.8 KB)  TX bytes:342880 (342.8 KB)


With ""router access"" (wireless in this case, but it varies):

~ $ route -n
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
0.0.0.0         192.168.1.1     0.0.0.0         UG    0      0        0 wlan0
192.168.1.0     0.0.0.0         255.255.255.0   U     9      0        0 wlan0

~ $ ifconfig
eth0      Link encap:Ethernet  HWaddr 54:ee:75:0c:02:80  
          UP BROADCAST MULTICAST  MTU:1500  Metric:1
          RX packets:9422 errors:0 dropped:0 overruns:0 frame:0
          TX packets:7545 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:1000 
          RX bytes:6216683 (6.2 MB)  TX bytes:1399280 (1.3 MB)
          Interrupt:20 Memory:f0500000-f0520000 

lo        Link encap:Local Loopback  
          inet addr:127.0.0.1  Mask:255.0.0.0
          inet6 addr: ::1/128 Scope:Host
          UP LOOPBACK RUNNING  MTU:65536  Metric:1
          RX packets:4446 errors:0 dropped:0 overruns:0 frame:0
          TX packets:4446 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:0 
          RX bytes:353415 (353.4 KB)  TX bytes:353415 (353.4 KB)

wlan0     Link encap:Ethernet  HWaddr e8:2a:ea:60:31:4b  
          inet addr:192.168.1.105  Bcast:192.168.1.255  Mask:255.255.255.0
          inet6 addr: fe80::ea2a:eaff:fe60:314b/64 Scope:Link
          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
          RX packets:77013 errors:0 dropped:0 overruns:0 frame:0
          TX packets:49506 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:1000 
          RX bytes:25275438 (25.2 MB)  TX bytes:30355132 (30.3 MB)


With both (wired with wireless turned on):

~ $ route -n
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
0.0.0.0         192.168.102.1   0.0.0.0         UG    0      0        0 eth0
192.168.1.0     0.0.0.0         255.255.255.0   U     9      0        0 wlan0
192.168.102.0   0.0.0.0         255.255.254.0   U     1      0        0 eth0

",William,https://superuser.com/users/367462,"Sounds like there's competing DHCP servers on your network.  

A few questions for you:


What model router do you have?  
And have you turned on DHCP services on any computers on your network?
How many computers do you have on your network?  Can you turn them all off and turn them on 1 at a time until the problem shows up?

",webmarc,https://superuser.com/users/367010,http://superuser.com/questions/810510,TECHNOLOGY,superuser.com,0.6666666666666666,0.4444444444444444,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.4444444444444444,0.8888888888888888,0.4444444444444444,1.0,0.8888888888888888,0.5333333333333333,0.3333333333333333,0.0,0.6666666666666666,0.8888888888888888,Only one web portal and Internet of router can be accessed,"On both wired and wireless connections, I can only access one of 192.168.1.1 (the router web portal) and the general Internet.  Which ""mode"" my devices are in is seemingly random.  This has persisted so far for 5 days (since I began using this network).

When connected to the Internet, I can go to 192.168.102.1 and I see a landing page for ""mikrotik routeros"", but I cannot go to 192.168.1.1. When connected to the router but not the Internet, 192.168.1.1 yields the router web portal, and 192.168.102.1 is inaccessible.

Attempted solutions


Upgrading router firmware  
Resetting router to factory settings  
Rebooting devices  
Fiddling with router settings (changing wireless security modes, removing wireless security, etc)  
Upgrading wireless drivers on computers  


Some data


Affects BlackBerry, Windows, Android and Ubuntu devices
All devices work properly on other networks
Devices may switch modes if they have been offline for a long time (eg: overnight), but restarting a device has no effect
Router is TP-Link TL-WR740N v4
Router firmware DD-WRT v24-sp2 (04/18/14) std - build 23919
Both wired and wireless connections are affected, but not necessarily simultaneously


I don't know anything about networking, but here's some info that seems helpful taken from my Ubuntu laptop.

With internet access (wired in this case, but it varies):

~ $ route -n
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
0.0.0.0         192.168.102.1   0.0.0.0         UG    0      0        0 eth0
192.168.102.0   0.0.0.0         255.255.254.0   U     1      0        0 eth0

~ $ ifconfig
eth0      Link encap:Ethernet  HWaddr 54:ee:75:0c:02:80  
          inet addr:192.168.103.232  Bcast:192.168.103.255  Mask:255.255.254.0
          inet6 addr: fe80::56ee:75ff:fe0c:280/64 Scope:Link
          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
          RX packets:3273 errors:0 dropped:0 overruns:0 frame:0
          TX packets:3035 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:1000 
          RX bytes:2276482 (2.2 MB)  TX bytes:517732 (517.7 KB)
          Interrupt:20 Memory:f0500000-f0520000 

lo        Link encap:Local Loopback  
          inet addr:127.0.0.1  Mask:255.0.0.0
          inet6 addr: ::1/128 Scope:Host
          UP LOOPBACK RUNNING  MTU:65536  Metric:1
          RX packets:4315 errors:0 dropped:0 overruns:0 frame:0
          TX packets:4315 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:0 
          RX bytes:342880 (342.8 KB)  TX bytes:342880 (342.8 KB)


With ""router access"" (wireless in this case, but it varies):

~ $ route -n
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
0.0.0.0         192.168.1.1     0.0.0.0         UG    0      0        0 wlan0
192.168.1.0     0.0.0.0         255.255.255.0   U     9      0        0 wlan0

~ $ ifconfig
eth0      Link encap:Ethernet  HWaddr 54:ee:75:0c:02:80  
          UP BROADCAST MULTICAST  MTU:1500  Metric:1
          RX packets:9422 errors:0 dropped:0 overruns:0 frame:0
          TX packets:7545 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:1000 
          RX bytes:6216683 (6.2 MB)  TX bytes:1399280 (1.3 MB)
          Interrupt:20 Memory:f0500000-f0520000 

lo        Link encap:Local Loopback  
          inet addr:127.0.0.1  Mask:255.0.0.0
          inet6 addr: ::1/128 Scope:Host
          UP LOOPBACK RUNNING  MTU:65536  Metric:1
          RX packets:4446 errors:0 dropped:0 overruns:0 frame:0
          TX packets:4446 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:0 
          RX bytes:353415 (353.4 KB)  TX bytes:353415 (353.4 KB)

wlan0     Link encap:Ethernet  HWaddr e8:2a:ea:60:31:4b  
          inet addr:192.168.1.105  Bcast:192.168.1.255  Mask:255.255.255.0
          inet6 addr: fe80::ea2a:eaff:fe60:314b/64 Scope:Link
          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
          RX packets:77013 errors:0 dropped:0 overruns:0 frame:0
          TX packets:49506 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:1000 
          RX bytes:25275438 (25.2 MB)  TX bytes:30355132 (30.3 MB)


With both (wired with wireless turned on):

~ $ route -n
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
0.0.0.0         192.168.102.1   0.0.0.0         UG    0      0        0 eth0
192.168.1.0     0.0.0.0         255.255.255.0   U     9      0        0 wlan0
192.168.102.0   0.0.0.0         255.255.254.0   U     1      0        0 eth0

","Sounds like there's competing DHCP servers on your network.  

A few questions for you:


What model router do you have?  
And have you turned on DHCP services on any computers on your network?
How many computers do you have on your network?  Can you turn them all off and turn them on 1 at a time until the problem shows up?

"
4968,4968,7914,guake not working,"I have seen other answers to this question, but I needed to post this again because there is no response from the maintainers on guake on this issue. i saw the possible answers in this ask ubuntu answer here, but it did not apply to me. I tried both sudo apt-get remove --purge python-notify and then sudo apt-get install python-notify, and that did not change the situation at all, guake still will not start and i still get the same error message everyone else sees:

$ guake
Traceback (most recent call last):
  File ""/usr/bin/guake"", line 1429, in &lt;module&gt;
    if not main():
  File ""/usr/bin/guake"", line 1373, in main
    instance = Guake()
  File ""/usr/bin/guake"", line 660, in __init__
    notification.show()
glib.GError: GDBus.Error:org.freedesktop.DBus.Error.ServiceUnknown: The name org.freedesktop.Notifications was not provided by any .service files


The answers in the previously referenced Ask Ubuntu answer no longer apply - there is no more patch to be found on the ""official"" guake.org site, as that site lost its domain on 20th October, 2014 and has not been updated nor is there a new site. There is no response either regarding that from the official maintainers at the github repository for guake. any other suggestions on making this work, or should i just uninstall?

Also, if the software, and its patches and its ""official"" site are not going to be maintained, I feel it should be removed from the Ubuntu Software Center - it is deceiving to install something only to have it not work and no other solution available.

please advise.
",faddah,https://askubuntu.com/users/338081,"guake depends on notification-daemon:

$ apt-cache depends guake
guake
...
 Depends: notification-daemon
  dunst
  mate-notification-daemon
  notify-osd
  plasma-widgets-workspace
  xfce4-notifyd


It is a hard dependency, so one of those packages must be installed. You could try reinstalling notify-osd, which is the usual package for Unity, or install it if it isn't present. See if another of those packages is installed and mention it in any bugs you file, since it doesn't seem to work for guake.
",muru,https://askubuntu.com/users/158442,http://askubuntu.com/questions/544090/guake-not-working,TECHNOLOGY,askubuntu.com,0.6666666666666666,0.3333333333333333,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.3333333333333333,0.3333333333333333,0.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.3333333333333333,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.6666666666666666,0.0,1.0,1.0,Guark doesn't work,"I have seen other answers to this question, but I needed to post this again because there is no response from the maintainers on guake on this issue. i saw the possible answers in this ask ubuntu answer here, but it did not apply to me. I tried both sudo apt-get remove --purge python-notify and then sudo apt-get install python-notify, and that did not change the situation at all, guake still will not start and i still get the same error message everyone else sees:

$ guake
Traceback (most recent call last):
  File ""/usr/bin/guake"", line 1429, in &lt;module&gt;
    if not main():
  File ""/usr/bin/guake"", line 1373, in main
    instance = Guake()
  File ""/usr/bin/guake"", line 660, in __init__
    notification.show()
glib.GError: GDBus.Error:org.freedesktop.DBus.Error.ServiceUnknown: The name org.freedesktop.Notifications was not provided by any .service files


The answers in the previously referenced Ask Ubuntu answer no longer apply - there is no more patch to be found on the ""official"" guake.org site, as that site lost its domain on 20th October, 2014 and has not been updated nor is there a new site. There is no response either regarding that from the official maintainers at the github repository for guake. any other suggestions on making this work, or should i just uninstall?

Also, if the software, and its patches and its ""official"" site are not going to be maintained, I feel it should be removed from the Ubuntu Software Center - it is deceiving to install something only to have it not work and no other solution available.

please advise.
","guake depends on notification-daemon:

$ apt-cache depends guake
guake
...
 Depends: notification-daemon
  dunst
  mate-notification-daemon
  notify-osd
  plasma-widgets-workspace
  xfce4-notifyd


It is a hard dependency, so one of those packages must be installed. You could try reinstalling notify-osd, which is the usual package for Unity, or install it if it isn't present. See if another of those packages is installed and mention it in any bugs you file, since it doesn't seem to work for guake.
"
2366,2366,3772,How do I count the number of different child id's belonging to a parent record?,"For instance I have two tables in a music database.

Table album and table track.

Each track record has (amongst other things), an album_id and an artist_id

Each album record has a unique album_id

In order to spot which albums are by 'various artists' I want to count the number of distinct artist_id's which belong to each album.

Such that two or more track records with the same album_id but with differing artist_id's should signal that I can flag the album as 'various artists'

I can do it with multiple queries but I'm seeking the elegant all in one query.
",user45244,https://dba.stackexchange.com/users/45244,"There are various ways to solve this problem, but with a composite index on (album_id, artist_id) most DBMS will manage to use only this index (a full index scan) with the following query and thus be quite efficient:

SELECT album_id
FROM track
GROUP BY album_id
HAVING MIN(artist_id) &lt; MAX(artist_id) ;


If you also want the number of artists per album, you can add COUNT(DISTINCT artist_id) in the select list.



A less obfuscated alternative condition is to use (which could be less efficient than the above MIN &lt; MAX method):

HAVING COUNT(DISTINCT artist_id) &gt; 1 ;

",ypercubeᵀᴹ,https://dba.stackexchange.com/users/993,http://dba.stackexchange.com/questions/73497/how-do-i-count-the-number-of-different-child-ids-belonging-to-a-parent-record,TECHNOLOGY,dba.stackexchange.com,1.0,0.5555555555555556,0.0,1.0,1.0,1.0,0.4444444444444444,0.4444444444444444,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.6666666666666666,0.0,0.8888888888888888,How to calculate the number of different child IDS belonging to the parent record?,"For instance I have two tables in a music database.

Table album and table track.

Each track record has (amongst other things), an album_id and an artist_id

Each album record has a unique album_id

In order to spot which albums are by 'various artists' I want to count the number of distinct artist_id's which belong to each album.

Such that two or more track records with the same album_id but with differing artist_id's should signal that I can flag the album as 'various artists'

I can do it with multiple queries but I'm seeking the elegant all in one query.
","There are various ways to solve this problem, but with a composite index on (album_id, artist_id) most DBMS will manage to use only this index (a full index scan) with the following query and thus be quite efficient:

SELECT album_id
FROM track
GROUP BY album_id
HAVING MIN(artist_id) &lt; MAX(artist_id) ;


If you also want the number of artists per album, you can add COUNT(DISTINCT artist_id) in the select list.



A less obfuscated alternative condition is to use (which could be less efficient than the above MIN &lt; MAX method):

HAVING COUNT(DISTINCT artist_id) &gt; 1 ;

"
620,620,975,iphone 3G data network timeout?,"My iPhone app sends data persistently over the network, and can handle having the network completely unavailable for a time. However I do my dev on an ipod and have difficulty testing 3G connectivity issues; My question: is there  period of non-connectivity, while an app is in the foreground, after which the iphone will stop checking for the network, such that there are no bars and reachability returns 0 until the user ""wakes"" the phone, e.g. by locking/unlocking? Or can e.g. 1 hr without data network pass and the iphone will recognize that the network is back and reachability will start returning true (I am polling every 1 minute while there is not connection to my server). 

This is my experience with wifi: if, while running my app, the ipod hasn't connected to a wifi network for 1/2 hr, it stops looking for networks, and I need to lock and unlock it to stir the device into looking again. 

One other thing: the iPhone has the screen dimmed by the proximity sensor while all this persistent network use is happening.
",ransomweaver,https://stackoverflow.com/users/151163,"Wi-Fi going down after 30 min of inactivity is a documented behavior. Cellular network is always active, unless turned off by the user. So if it goes down for a while it should  get back online automatically when possible even if there was no user activity.
",Alex Chugunov,https://stackoverflow.com/users/323035,http://stackoverflow.com/questions/6036388/iphone-3g-data-network-timeout,STACKOVERFLOW,stackoverflow.com,0.6666666666666666,0.4444444444444444,0.0,0.6666666666666666,1.0,1.0,0.6666666666666666,0.5555555555555556,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8,0.0,0.6666666666666666,1.0,0.8888888888888888,IPhone 3G data network timeout?,"My iPhone app continues to send data over the network and can handle situations where the network is completely unavailable for some time. However, I developed on the iPod and encountered difficulties in testing 3G connection problems. My question is: when the application is in the foreground, is there a period of time when it is not connected? After this period of time, the iPhone will stop checking the network, so that before the user ""wakes up"" the handset (for example, by locking / unlocking), there is no entry and accessibility back to 0? Or you can work for an hour without a data network pass, and the iPhone will recognize that the network has recovered, and accessibility will start to return true (I poll every minute when I'm not connected to the server).","Wi-Fi going down after 30 min of inactivity is a documented behavior. Cellular network is always active, unless turned off by the user. So if it goes down for a while it should  get back online automatically when possible even if there was no user activity.
"
3677,3677,5863,2D AABBs and resolving multiple collisions,"Okay, so this is a problem I've been trying to figure out for quite some time. Mine is a 2D platformer game with a world made up of (usually) immobile tiles and mobile sprites, both of which use AABBs to represent their hitboxes. This game is NOT grid-based due to some complications with moving layers of tiles.

I can detect collisions and easily figure out the depth of the collision. I use the ""shallowest axis method"" to determine which way to resolve a collision between the sprite and the tile. If the sprite is deeper horizontally than vertically, the direction to resolve is either up or down. If the sprite is deeper vertically than horizontally, the direction to resolve is either left or right.



This is simple enough, and it works pretty well. That is, until you have a sprite colliding with more than one tile. As, by their nature, each collision has to be checked separately, different collisions may have different direction to resolve in. For example, if a sprite is trying to walk across a row of tiles, for one frame they will intersect the next tile such that the horizontal depth is shorter than the vertical depth. As the collision says ""resolve left"", it will be pushed back and will be stuck on the corner.



I've been mulling this problem over, on and off, for quite some time, and several solutions have come to me, but all have flaws. I could mark certain sides as unreachable, but without a grid-based engine, determining ""unreachability"" is remarkably complex, especially with moving layers of tiles always a possibility.

Another possible method would be to predict collisions before they happen and ""work back"" the movement to the point of the collision, I suppose, but I'm not sure how the math on that works.

I feel that I'm missing something incredibly obvious, especially since games from the 80s have already solved this problem.
",Celarix,https://gamedev.stackexchange.com/users/34552,"The problem

The problem lies in your method of collision resolution. Your method goes as follows:


Move the player.
Check for collision.
Determine the shortest collision depth.
Resolve collision.


The problem with this, is that it can easily move the player in the wrong direction. You can see how this might happen in the image below:



Because the player is moving down to the right, and is above the ground, you would expect the player to land on top of the ground (by the green box). But instead, it gets pushed out of the ground to the left (represented by the red box). This can be a problem if the player is trying to jump from one platform to another, because the player may end up falling to his death due to bad collision code.

The solution

The solution to this problem is actually pretty simple. Instead of using the above method, you resolve collision like so:


Move the player along the X axis.
Check for colliding tiles.
Resolve X collision.
Move the player along the Y axis.
Check for colliding tiles.
Resolve Y collision.


Now I hope that you didn't throw your depth check code away, because you are still going to need it for steps 3 and 6.

To resolve collision between tiles on either of the two axes (after moving the player), you first get the depth of the collision. You then take the depth of the collision, and subtract that from the axes that you are currently checking for collision. Note that the depth should be negative if you are moving to the left, so that the player moves in the right direction.

Using this method, you will not only not have to worry about collision bugs like the one in the scenario in the above image, but this method also can handle collision with multiple tiles.

Example code:

void move(velocity)
{
    top = player.y / TILE_HEIGHT;
    bottom = top + (player.height / TILE_HEIGHT);
    left = player.x / TILE_WIDTH;
    right = left + (player.width / TILE_WIDTH);

    // Check X

    player.x += velocity.x;
    player.updateAABB();
    for(int tx = left - 1; tx &lt;= right + 1; tx++)
    {
        for(int ty = top - 1; ty &lt;= bottom + 1; ty++)
        {
            aabb = world.getTileAABB(tx, ty);
            if(aabb.collidesWith(player.aabb))
            {
                depth = player.aabb.getXDepth(aabb);
                player.x -= depth;
            }
        }
    }

    // Now check Y

    player.y += velocity.y;
    player.updateAABB();
    for(int tx = left - 1; tx &lt;= right + 1; tx++)
    {
        for(int ty = top - 1; ty &lt;= bottom + 1; ty++)
        {
            aabb = world.getTileAABB(tx, ty);
            if(aabb.collidesWith(player.aabb))
            {
                depth = player.aabb.getYDepth(aabb);
                player.y -= depth;
            }
        }
    }

    player.updateAABB();
}

",Aidan Mueller,https://gamedev.stackexchange.com/users/13658,http://gamedev.stackexchange.com/questions/69339/2d-aabbs-and-resolving-multiple-collisions,TECHNOLOGY,gamedev.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,0.6666666666666666,0.3333333333333333,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.6666666666666666,0.8888888888888888,2D AABBs and the solution of multiple collisions,"Okay, so this is a problem I've been trying to figure out for quite some time. Mine is a 2D platformer game with a world made up of (usually) immobile tiles and mobile sprites, both of which use AABBs to represent their hitboxes. This game is NOT grid-based due to some complications with moving layers of tiles.

I can detect collisions and easily figure out the depth of the collision. I use the ""shallowest axis method"" to determine which way to resolve a collision between the sprite and the tile. If the sprite is deeper horizontally than vertically, the direction to resolve is either up or down. If the sprite is deeper vertically than horizontally, the direction to resolve is either left or right.



This is simple enough, and it works pretty well. That is, until you have a sprite colliding with more than one tile. As, by their nature, each collision has to be checked separately, different collisions may have different direction to resolve in. For example, if a sprite is trying to walk across a row of tiles, for one frame they will intersect the next tile such that the horizontal depth is shorter than the vertical depth. As the collision says ""resolve left"", it will be pushed back and will be stuck on the corner.



I've been mulling this problem over, on and off, for quite some time, and several solutions have come to me, but all have flaws. I could mark certain sides as unreachable, but without a grid-based engine, determining ""unreachability"" is remarkably complex, especially with moving layers of tiles always a possibility.

Another possible method would be to predict collisions before they happen and ""work back"" the movement to the point of the collision, I suppose, but I'm not sure how the math on that works.

I feel that I'm missing something incredibly obvious, especially since games from the 80s have already solved this problem.
","The problem

The problem lies in your method of collision resolution. Your method goes as follows:


Move the player.
Check for collision.
Determine the shortest collision depth.
Resolve collision.


The problem with this, is that it can easily move the player in the wrong direction. You can see how this might happen in the image below:



Because the player is moving down to the right, and is above the ground, you would expect the player to land on top of the ground (by the green box). But instead, it gets pushed out of the ground to the left (represented by the red box). This can be a problem if the player is trying to jump from one platform to another, because the player may end up falling to his death due to bad collision code.

The solution

The solution to this problem is actually pretty simple. Instead of using the above method, you resolve collision like so:


Move the player along the X axis.
Check for colliding tiles.
Resolve X collision.
Move the player along the Y axis.
Check for colliding tiles.
Resolve Y collision.


Now I hope that you didn't throw your depth check code away, because you are still going to need it for steps 3 and 6.

To resolve collision between tiles on either of the two axes (after moving the player), you first get the depth of the collision. You then take the depth of the collision, and subtract that from the axes that you are currently checking for collision. Note that the depth should be negative if you are moving to the left, so that the player moves in the right direction.

Using this method, you will not only not have to worry about collision bugs like the one in the scenario in the above image, but this method also can handle collision with multiple tiles.

Example code:

void move(velocity)
{
    top = player.y / TILE_HEIGHT;
    bottom = top + (player.height / TILE_HEIGHT);
    left = player.x / TILE_WIDTH;
    right = left + (player.width / TILE_WIDTH);

    // Check X

    player.x += velocity.x;
    player.updateAABB();
    for(int tx = left - 1; tx &lt;= right + 1; tx++)
    {
        for(int ty = top - 1; ty &lt;= bottom + 1; ty++)
        {
            aabb = world.getTileAABB(tx, ty);
            if(aabb.collidesWith(player.aabb))
            {
                depth = player.aabb.getXDepth(aabb);
                player.x -= depth;
            }
        }
    }

    // Now check Y

    player.y += velocity.y;
    player.updateAABB();
    for(int tx = left - 1; tx &lt;= right + 1; tx++)
    {
        for(int ty = top - 1; ty &lt;= bottom + 1; ty++)
        {
            aabb = world.getTileAABB(tx, ty);
            if(aabb.collidesWith(player.aabb))
            {
                depth = player.aabb.getYDepth(aabb);
                player.y -= depth;
            }
        }
    }

    player.updateAABB();
}

"
5318,5318,8449,Disable tap on current Tab (UITabBarController) iPhone App,"Currently, Tapping on the same Tab (in which user is working), The App moves to the very first page of that Tab.

I want to disable the tap event on the Tab in which user is working currently.

Any Hint?
",viral,https://stackoverflow.com/users/887601,"You tried tabBarController:shouldSelectViewController: delegate method? I hope that should help you.

- (BOOL)tabBarController:(UITabBarController *)tabBarController shouldSelectViewController:(UIViewController *)viewController {

    id currentViewController = tabBarController.selectedViewController;
    return (viewController != currentViewController);
}


If all the view controllers of the tab bar controller are UINavigationControllers, you should do it like this.

- (BOOL)tabBarController:(UITabBarController *)tabBarController shouldSelectViewController:(UIViewController *)viewController {

    id nextVC = [(UINavigationController *)viewController topViewController];
    id currentVC = [(UINavigationController *)tabBarController.selectedViewController topViewController];
    return (nextVC != currentVC);
}

",EmptyStack,https://stackoverflow.com/users/491980,http://stackoverflow.com/questions/10054539/disable-tap-on-current-tab-uitabbarcontroller-iphone-app,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.6666666666666666,0.0,0.5,1.0,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.4444444444444444,0.8333333333333334,0.6666666666666666,0.8333333333333334,1.0,0.9,1.0,0.6666666666666666,0.0,0.6666666666666666,Disable clicking on the current tab (uitabbarcontroller) iPhone app,"Currently, clicking on the same tab (the user is working) moves the application to the first page of that tab.","You tried tabBarController:shouldSelectViewController: delegate method? I hope that should help you.

- (BOOL)tabBarController:(UITabBarController *)tabBarController shouldSelectViewController:(UIViewController *)viewController {

    id currentViewController = tabBarController.selectedViewController;
    return (viewController != currentViewController);
}


If all the view controllers of the tab bar controller are UINavigationControllers, you should do it like this.

- (BOOL)tabBarController:(UITabBarController *)tabBarController shouldSelectViewController:(UIViewController *)viewController {

    id nextVC = [(UINavigationController *)viewController topViewController];
    id currentVC = [(UINavigationController *)tabBarController.selectedViewController topViewController];
    return (nextVC != currentVC);
}

"
3302,3302,5267,Force Geoserver SRID 0,"I'm developing a gis solution which uses only geometry data.

I designed my spatial DB with PostGIS and now I'm performing some trials connecting the DB with GeoServer map server (using the administration page).

In the layer definition of the administration tool there is the mandatory field SRS(Spatial Reference System) to set with the appropriate SRID

I'd like to know which is the default SRID value to set in order to take into account the geometry type. I read that should be 0, but it doesn't work....

Thanks

nico
",nko,https://gis.stackexchange.com/users/18166,"GeoTools (and GeoServer) provide EPSG:404000 for generic 2D systems. Search for GENERIC_2D in http://docs.geotools.org/latest/userguide/library/referencing/crs.html for details. 

I've never tried to use it myself but I think it should do what you need.
",Ian Turton,https://gis.stackexchange.com/users/79,http://gis.stackexchange.com/questions/60825/force-geoserver-srid-0,TECHNOLOGY,gis.stackexchange.com,0.7777777777777778,0.4444444444444444,0.0,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.9,1.0,0.0,0.0,0.8888888888888888,Force geographic server SRID 0,"I'm developing a gis solution which uses only geometry data.

I designed my spatial DB with PostGIS and now I'm performing some trials connecting the DB with GeoServer map server (using the administration page).

In the layer definition of the administration tool there is the mandatory field SRS(Spatial Reference System) to set with the appropriate SRID

I'd like to know which is the default SRID value to set in order to take into account the geometry type. I read that should be 0, but it doesn't work....

Thanks

nico
","GeoTools (and GeoServer) provide EPSG:404000 for generic 2D systems. Search for GENERIC_2D in http://docs.geotools.org/latest/userguide/library/referencing/crs.html for details. 

I've never tried to use it myself but I think it should do what you need.
"
1329,1329,2096,Consider Global Reputation Points,"I have come to enjoy the Stack Exchange community as a whole over the past few weeks. Originally, I started out seeking computer help from a couple of subcommunities where I could learn and get help with my computer problems. Itself  is a great idea and there are a few forums that offer similar help resources.

What makes Stack Exchange different is that it expands across so many arenas with a single account making it a very expansive place to give and take. For example, I found myself on the English Learning site where I actually have a lot to contribute. I am actually an English teacher but I have computer problems sometimes.

One thing though, the reputation points don't carry over across subcommunities which I think is a bit detrimental and defeating the purpose in a way.

My arguments are:


If the purpose of reputation points is to build a character reference, then shouldn't it be global? For instance, I can be helpful in one community and have a ton of reputation but a complete 'weirdo' in another. Whereas a universal point system wouldn't allow this. Reputation as a whole builds your identity across multiple communities.
I join a new community and I am limited to what I can post (even if my post can be useful or helpful). Specifically, I ran across this during commenting. I had a perfectly viable comment to help a person but wasn't allowed because I didn't have reputation but I had reputation in another community. I had to post it as an answer and then I got 'moderated' by the community on where I should post and was down voted for leaving a comment in the answer area. Thus, losing reputation.
It doesn't seem to create a way for incentives in some cases. For example, I have computer problems and I can't say I am phenominal at solving or answering computer questions. I could ask a question that may not get answered but if I have enough reputation I could put a bounty on it as incentive to get people to answer it. BUT WAIT!! I can't really earn reputation on a computer community to put a bounty on a question because there is nothing I can really answer or be helpful with.


However, I am great at writing, editing and dealing with international students!!! But, what is the sense of me just racking up points in a community when I will hardly need to ask a question much less put a bounty on it? Sure, points are great. It's nice to have a lot of points but what if I need them elsewhere?

So, when I need computer help desperately I can use my reputation collected from another community to put incentive in trying to get a question answered. Essentially, I'm a good guy and helpful at something but I am not a computer whiz. 

Everyone is good at something and thats what the community at large should be in my opinion.

Just my opinion. I used my situation personally to explain but I am sure other people have experienced a similar situation or have had a similar thought.
",David,https://meta.stackexchange.com/users/275168,"
  For instance, I can be helpful in one community and have a ton of reputation but a complete 'weirdo' in another.


You are making points against yourself in your argument for the feature. That reason, right there, is exactly why this is a bad idea. Just because you are skilled and knowledgeable in one field and community doesn't mean you know what you're doing in another.

While the system and features of each site are the same, each community is different. They develop their own quality standards and their own expectations, and it doesn't make sense for reputation to carry over across all sites.

The system already gives you a small reputation boost up to at least 101, so long as you have at least 200 reputation on any other site in the network. That lets you get the two most basic features: upvoting and commenting. Privileges past that become highly dependent on the community in which you're participating, and it's dangerous to let just anyone out of the blue show up in a community and start editing or voting to close things when they've never participated there before.
",animuson,https://meta.stackexchange.com/users/141525,http://meta.stackexchange.com/questions/243464/consider-global-reputation-points,TECHNOLOGY,meta.stackexchange.com,0.7777777777777778,0.3333333333333333,0.3333333333333333,1.0,0.0,0.3333333333333333,0.6666666666666666,0.4444444444444444,0.0,0.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.3333333333333333,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.3333333333333333,1.0,1.0,Consider global reputation points,"I have come to enjoy the Stack Exchange community as a whole over the past few weeks. Originally, I started out seeking computer help from a couple of subcommunities where I could learn and get help with my computer problems. Itself  is a great idea and there are a few forums that offer similar help resources.

What makes Stack Exchange different is that it expands across so many arenas with a single account making it a very expansive place to give and take. For example, I found myself on the English Learning site where I actually have a lot to contribute. I am actually an English teacher but I have computer problems sometimes.

One thing though, the reputation points don't carry over across subcommunities which I think is a bit detrimental and defeating the purpose in a way.

My arguments are:


If the purpose of reputation points is to build a character reference, then shouldn't it be global? For instance, I can be helpful in one community and have a ton of reputation but a complete 'weirdo' in another. Whereas a universal point system wouldn't allow this. Reputation as a whole builds your identity across multiple communities.
I join a new community and I am limited to what I can post (even if my post can be useful or helpful). Specifically, I ran across this during commenting. I had a perfectly viable comment to help a person but wasn't allowed because I didn't have reputation but I had reputation in another community. I had to post it as an answer and then I got 'moderated' by the community on where I should post and was down voted for leaving a comment in the answer area. Thus, losing reputation.
It doesn't seem to create a way for incentives in some cases. For example, I have computer problems and I can't say I am phenominal at solving or answering computer questions. I could ask a question that may not get answered but if I have enough reputation I could put a bounty on it as incentive to get people to answer it. BUT WAIT!! I can't really earn reputation on a computer community to put a bounty on a question because there is nothing I can really answer or be helpful with.


However, I am great at writing, editing and dealing with international students!!! But, what is the sense of me just racking up points in a community when I will hardly need to ask a question much less put a bounty on it? Sure, points are great. It's nice to have a lot of points but what if I need them elsewhere?

So, when I need computer help desperately I can use my reputation collected from another community to put incentive in trying to get a question answered. Essentially, I'm a good guy and helpful at something but I am not a computer whiz. 

Everyone is good at something and thats what the community at large should be in my opinion.

Just my opinion. I used my situation personally to explain but I am sure other people have experienced a similar situation or have had a similar thought.
","
  For instance, I can be helpful in one community and have a ton of reputation but a complete 'weirdo' in another.


You are making points against yourself in your argument for the feature. That reason, right there, is exactly why this is a bad idea. Just because you are skilled and knowledgeable in one field and community doesn't mean you know what you're doing in another.

While the system and features of each site are the same, each community is different. They develop their own quality standards and their own expectations, and it doesn't make sense for reputation to carry over across all sites.

The system already gives you a small reputation boost up to at least 101, so long as you have at least 200 reputation on any other site in the network. That lets you get the two most basic features: upvoting and commenting. Privileges past that become highly dependent on the community in which you're participating, and it's dangerous to let just anyone out of the blue show up in a community and start editing or voting to close things when they've never participated there before.
"
5263,5263,8365,Can I expect my e-mail to be routed securely?,"If I connect to my e-mail server via SSL (SMTP/SSL) and the recipient also only checks his e-mail via SSL (web/https or IMAP/SSL), does this - generally speaking - increase the security for the message content in any way? 

That is, will the communication between my providers e-mail server and the recipients e-mail server be ""secure""(*), or will the e-mail be delivered plain text between the servers? 

(*) Secure in the context of: encrypted throughout it's transit. Not secure in the sense that I'd put any really sensitive info in there.
",Martin,https://security.stackexchange.com/users/3785,"Also, bear in mind that as email is store-and-forward even if the network link is encrypted in some way, each server in the delivery chain could potentially have stored a copy of the message which would potentially be readable to an administrator.  Whether this is likely or not depends entirely on who manages those servers... it might be a small risk in some cases and a huge one in others
",only1weasel,https://security.stackexchange.com/users/5542,http://security.stackexchange.com/questions/8289/can-i-expect-my-e-mail-to-be-routed-securely,TECHNOLOGY,security.stackexchange.com,1.0,0.3333333333333333,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.3333333333333333,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,0.6666666666666666,0.5555555555555556,1.0,0.8888888888888888,0.6,0.0,0.0,0.3333333333333333,0.8888888888888888,Can I count on my email to be delivered safely?,"If I connect to my e-mail server via SSL (SMTP/SSL) and the recipient also only checks his e-mail via SSL (web/https or IMAP/SSL), does this - generally speaking - increase the security for the message content in any way? 

That is, will the communication between my providers e-mail server and the recipients e-mail server be ""secure""(*), or will the e-mail be delivered plain text between the servers? 

(*) Secure in the context of: encrypted throughout it's transit. Not secure in the sense that I'd put any really sensitive info in there.
","In addition, remember that because e-mail is stored and forwarded, even if the network link is encrypted in some way, each server in the delivery chain may store a copy of the message, which may be read by the administrator. It all depends on who manages these servers... In some cases this can be a small risk, in others it can be a huge risk"
4734,4734,7508,Dialog is partially shown when SoftKeyBoard is shown,"I have a custom Dialog as shown below:



When I click on the Edit Text, The dialog is shifted upwards but half of the dialog becomes invisible as shown below:


I verified the issue on Android ICS and Gingerbread but it doesn't happen on Android Lollipop.

I appreciate your help for figuring out why.

Here is the custom dialog layout XML:

&lt;LinearLayout xmlns:android=""http://schemas.android.com/apk/res/android""
android:id=""@+id/layoutChatInGame""
android:layout_width=""305dp""
android:layout_height=""190dp""
android:background=""@drawable/dialog_table_border""
android:orientation=""vertical""
android:visibility=""visible""&gt;

&lt;LinearLayout
    android:orientation=""horizontal""
    android:layout_width=""match_parent""
    android:layout_height=""wrap_content""
    android:background=""@color/roomlist_title_background""&gt;

    &lt;ProgressBar
        android:layout_width=""wrap_content""
        android:layout_height=""wrap_content""
        android:id=""@+id/progressBar""
        android:layout_margin=""5dp""/&gt;

    &lt;LinearLayout
        android:orientation=""horizontal""
        android:layout_width=""fill_parent""
        android:layout_height=""fill_parent""
        android:layout_gravity=""center""
        android:layout_margin=""5dp""&gt;

        &lt;LinearLayout
            android:orientation=""vertical""
            android:layout_width=""fill_parent""
            android:layout_height=""wrap_content""
            android:layout_gravity=""center_vertical""&gt;

            &lt;TextView
                android:layout_width=""fill_parent""
                android:layout_height=""fill_parent""
                android:text=""Game is on hold because the host paused the app""
                android:id=""@+id/lblOnHoldDialogMessage""
                android:textColor=""@color/progress_dialog_on_hold_text""
                android:textSize=""18dp""
                android:singleLine=""false""
                android:layout_gravity=""center_horizontal""/&gt;
        &lt;/LinearLayout&gt;
    &lt;/LinearLayout&gt;

&lt;/LinearLayout&gt;

&lt;TextView
    android:id=""@+id/lblChatHistoryGameOnHold""
    android:layout_width=""match_parent""
    android:layout_height=""fill_parent""
    android:layout_weight=""1""
    android:gravity=""bottom""
    android:maxLines=""5""
    android:scrollbars=""vertical""
    android:textColor=""@color/edit_text_general_text""
    android:textColorHint=""@color/edit_text_general_hint""
    android:paddingRight=""2dp""
    android:paddingLeft=""2dp""/&gt;

&lt;LinearLayout
    android:layout_width=""match_parent""
    android:layout_height=""wrap_content""&gt;

    &lt;EditText
        android:id=""@+id/textChatGameOnHold""
        android:layout_width=""0dp""
        android:layout_height=""wrap_content""
        android:layout_marginLeft=""2dp""
        android:layout_marginStart=""2dp""
        android:layout_weight=""1""
        android:ems=""10""
        android:hint=""@string/edit_text_send_chat_message""
        android:imeOptions=""flagNoExtractUi|actionDone""
        android:inputType=""text""
        android:maxLength=""100""
        android:maxLines=""1""
        android:textColor=""@color/edit_text_general_text""
        android:textColorHint=""@color/edit_text_general_hint""/&gt;

    &lt;Button
        android:id=""@+id/btnSendGameOnHold""
        style=""@style/lightboxButton.Blue""
        android:layout_width=""wrap_content""
        android:layout_height=""wrap_content""
        android:onClick=""sendChatMessageInGame""
        android:text=""@string/btn_send""/&gt;
&lt;/LinearLayout&gt;

&lt;/LinearLayout&gt; 

",E B,https://stackoverflow.com/users/4718314,"Try to use also android:imeOptions=""flagNoFullscreen"" in your .xml. Recommend you to make some tests, using it with and without flagNoExtractUi. Please give me some feedback. 
",Geraldo Neto,https://stackoverflow.com/users/4398784,http://stackoverflow.com/questions/31895818/dialog-is-partially-shown-when-softkeyboard-is-shown,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.5555555555555556,0.0,1.0,0.6666666666666666,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,0.0,1.0,Partial display dialog box when displaying soft keyboard,"I have a custom Dialog as shown below:



When I click on the Edit Text, The dialog is shifted upwards but half of the dialog becomes invisible as shown below:


I verified the issue on Android ICS and Gingerbread but it doesn't happen on Android Lollipop.

I appreciate your help for figuring out why.

Here is the custom dialog layout XML:

&lt;LinearLayout xmlns:android=""http://schemas.android.com/apk/res/android""
android:id=""@+id/layoutChatInGame""
android:layout_width=""305dp""
android:layout_height=""190dp""
android:background=""@drawable/dialog_table_border""
android:orientation=""vertical""
android:visibility=""visible""&gt;

&lt;LinearLayout
    android:orientation=""horizontal""
    android:layout_width=""match_parent""
    android:layout_height=""wrap_content""
    android:background=""@color/roomlist_title_background""&gt;

    &lt;ProgressBar
        android:layout_width=""wrap_content""
        android:layout_height=""wrap_content""
        android:id=""@+id/progressBar""
        android:layout_margin=""5dp""/&gt;

    &lt;LinearLayout
        android:orientation=""horizontal""
        android:layout_width=""fill_parent""
        android:layout_height=""fill_parent""
        android:layout_gravity=""center""
        android:layout_margin=""5dp""&gt;

        &lt;LinearLayout
            android:orientation=""vertical""
            android:layout_width=""fill_parent""
            android:layout_height=""wrap_content""
            android:layout_gravity=""center_vertical""&gt;

            &lt;TextView
                android:layout_width=""fill_parent""
                android:layout_height=""fill_parent""
                android:text=""Game is on hold because the host paused the app""
                android:id=""@+id/lblOnHoldDialogMessage""
                android:textColor=""@color/progress_dialog_on_hold_text""
                android:textSize=""18dp""
                android:singleLine=""false""
                android:layout_gravity=""center_horizontal""/&gt;
        &lt;/LinearLayout&gt;
    &lt;/LinearLayout&gt;

&lt;/LinearLayout&gt;

&lt;TextView
    android:id=""@+id/lblChatHistoryGameOnHold""
    android:layout_width=""match_parent""
    android:layout_height=""fill_parent""
    android:layout_weight=""1""
    android:gravity=""bottom""
    android:maxLines=""5""
    android:scrollbars=""vertical""
    android:textColor=""@color/edit_text_general_text""
    android:textColorHint=""@color/edit_text_general_hint""
    android:paddingRight=""2dp""
    android:paddingLeft=""2dp""/&gt;

&lt;LinearLayout
    android:layout_width=""match_parent""
    android:layout_height=""wrap_content""&gt;

    &lt;EditText
        android:id=""@+id/textChatGameOnHold""
        android:layout_width=""0dp""
        android:layout_height=""wrap_content""
        android:layout_marginLeft=""2dp""
        android:layout_marginStart=""2dp""
        android:layout_weight=""1""
        android:ems=""10""
        android:hint=""@string/edit_text_send_chat_message""
        android:imeOptions=""flagNoExtractUi|actionDone""
        android:inputType=""text""
        android:maxLength=""100""
        android:maxLines=""1""
        android:textColor=""@color/edit_text_general_text""
        android:textColorHint=""@color/edit_text_general_hint""/&gt;

    &lt;Button
        android:id=""@+id/btnSendGameOnHold""
        style=""@style/lightboxButton.Blue""
        android:layout_width=""wrap_content""
        android:layout_height=""wrap_content""
        android:onClick=""sendChatMessageInGame""
        android:text=""@string/btn_send""/&gt;
&lt;/LinearLayout&gt;

&lt;/LinearLayout&gt; 

","Try using Android: imeoptions = ""flagnofullscreen"" in. XML as well. It is recommended that you perform some tests for flagnoextractui and not for flagnoextractui. Please give me some feedback."
4316,4316,6873,Office 2007 problems,"I just installed Ubuntu 14.04, 64-bit on a desktop pc. However, I HATE libreoffice and had trouble with open office. I want to install Office 2007 enterprise. Everytime I try to install it, Wine says that it encountered a serious error and needs to close. So, I put in a 32-bit wineprefix. Then, it kept saying ""EnterpriserWWW/osetup.dll does not validate or is not present"". So, I tried Playonlinux, and I kept getting the same error. How to I install office 2007 on my computer without these errors. I have wine 1.6.
I know it will work in some way because there are people who done it, and I flawlessly installed it on a 32-bit Ubuntu pc. Please help!!
",pdf4664,https://askubuntu.com/users/345524,"According to Wine MS Office 2007 was tested for installation only - you may check there to see if there's something you're missing on that installation.  I note also that office 2010 and 2013 do not perform well under wine.

Two alternatives would be to use the online versions of office (which would be the 2013 version, but not Office 365) or to install Windows in a virtual machine, and run Office 2007 from there.
",Charles Green,https://askubuntu.com/users/283721,http://askubuntu.com/questions/545592/office-2007-problems,TECHNOLOGY,askubuntu.com,1.0,0.3333333333333333,0.0,0.3333333333333333,1.0,1.0,0.7777777777777778,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.8,0.6666666666666666,0.0,1.0,1.0,Office 2007 questions,"I just installed 64 bit Ubuntu 14.04 on my desktop, but I hate libreoffice and I don't like opening office. I want to install Office 2007 enterprise. Every time I try to install it, wine says, it has encountered a serious error and needs to be shut down. So, I put a 32-bit wineprefix. Then, it kept saying ""enterpriseww / osetup. DLL is not validated or does not exist."". So I tried playonlinux, but the same error occurred. How to install Office 2007 on your computer without these errors. I have wine 1.6.","According to Wine MS Office 2007 was tested for installation only - you may check there to see if there's something you're missing on that installation.  I note also that office 2010 and 2013 do not perform well under wine.

Two alternatives would be to use the online versions of office (which would be the 2013 version, but not Office 365) or to install Windows in a virtual machine, and run Office 2007 from there.
"
5408,5408,8588,Comment form json?,"Just out of curiosity, is it possible to have a native comment-form return json instead of redirecting?

Thanks!


Steven

",Steven,https://expressionengine.stackexchange.com/users/195,"With a custom extension, you could. Just use the insert_comment_end hook, then do something like this:

if(ee()-&gt;input-&gt;is_ajax_request())
{
    ee()-&gt;extensions-&gt;end_script = TRUE;
    $data['comment_id'] = $comment_id;
    $data['moderated'] = $comment_moderate;
    echo json_encode($data);
}

",Derek Hogue,https://expressionengine.stackexchange.com/users/55,http://expressionengine.stackexchange.com/questions/11291/comment-form-json,TECHNOLOGY,expressionengine.stackexchange.com,0.6666666666666666,0.4444444444444444,0.0,1.0,1.0,1.0,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.3333333333333333,0.0,0.7777777777777778,Comment form JSON?,"Out of curiosity, is it possible to have the local comment form return JSON instead of redirection?","With a custom extension, you could. Just use the insert_comment_end hook, then do something like this:

if(ee()-&gt;input-&gt;is_ajax_request())
{
    ee()-&gt;extensions-&gt;end_script = TRUE;
    $data['comment_id'] = $comment_id;
    $data['moderated'] = $comment_moderate;
    echo json_encode($data);
}

"
1806,1806,2866,"Anybody knows if there is a counterpart for CTR+w , that deletes immediate words after cursor","I mean when the cursor is on the left side of the words ,I would like to remove the words on the immediate right side of it . CTR+k remove everything on the right side, i only want one word to be removed. 
",Eric,https://serverfault.com/users/67065,"In my bash shells, I hit ESC and 'd'.
",mfinni,https://serverfault.com/users/29373,http://serverfault.com/questions/226679,TECHNOLOGY,serverfault.com,0.8888888888888888,0.8888888888888888,0.0,1.0,1.0,1.0,0.5555555555555556,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,0.8888888888888888,0.6666666666666666,1.0,1.0,0.9,1.0,0.0,0.0,0.7777777777777778,"Anyone knows if CTR + W has a corresponding item, that is, delete the direct word after the cursor","I mean when the cursor is on the left side of the word, I want to delete the word on the right. CTR + K delete everything on the right, I just want to delete one word.","In my bash shells, I hit ESC and 'd'.
"
670,670,1063,Any smart way to get the interest down on our student loans?,"Trying to figure this out. I have a student loan $24,000 at 6.55% with Nelnet, and my wife has $48,000 at 5.2% with Mohelo. We have a home worth $220,000 with $40k in equity, and the rest at $180k at 3.9%. Any smart way to get the interest down on the student loans? A HELOC is an option I think, 4% may work. I tried to negotiate with Nelnet for a lower interest but they won't budge. We easily meet the $2k tax deduction between the two of us.
",Mike,https://money.stackexchange.com/users/6945,"There was another question about using a credit card to lower their student loan payments. There are drawbacks that will also apply in your situation regarding a HELOC or 2nd mortgage:


Make sure you understand the interest rate. If it is not fixed you could have made your situation worse. 
Monthly Payment. The repayment period of the HELOC or 2nd mortgage will greatly influence the monthly payment.
Closing costs?
There is no going back. If you want to switch back to a student loan you can't. 
Can you get a get a loan big enough? You need 72K, with only 40K in equity. Gone are the days where the loans could exceed the houses value at the start of the loan.
Tax implications?
Forgiveness programs. Some employers will forgive parts of the loan, or if you work in public service for X years they forgive some of the loan. They will not view the mortgage  debt the same way.

",mhoran_psprep,https://money.stackexchange.com/users/5414,http://money.stackexchange.com/questions/16376/any-smart-way-to-get-the-interest-down-on-our-student-loans,LIFE_ARTS,money.stackexchange.com,0.7777777777777778,0.5555555555555556,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,1.0,0.7777777777777778,0.8888888888888888,0.8888888888888888,1.0,0.7333333333333333,0.3333333333333333,0.6666666666666666,0.3333333333333333,0.6666666666666666,Is there any clever way to reduce the interest of our student loan?,"Want to find out. I have a $24000 student loan in nelnet at a 6.55% interest rate, and my wife has $48000 in mohelo at a 5.2% interest rate. We have a $220000 house with a $40000 share capital and $180000 for the rest, or 3.9%. Is there any clever way to reduce the interest of student loans? I think helicopter is an option, 4% may be useful. I tried to negotiate with nellett to lower interest rates, but they would not give in. It's easy for both of us to deduct $2000 in taxes.","There was another question about using a credit card to lower their student loan payments. There are drawbacks that will also apply in your situation regarding a HELOC or 2nd mortgage:


Make sure you understand the interest rate. If it is not fixed you could have made your situation worse. 
Monthly Payment. The repayment period of the HELOC or 2nd mortgage will greatly influence the monthly payment.
Closing costs?
There is no going back. If you want to switch back to a student loan you can't. 
Can you get a get a loan big enough? You need 72K, with only 40K in equity. Gone are the days where the loans could exceed the houses value at the start of the loan.
Tax implications?
Forgiveness programs. Some employers will forgive parts of the loan, or if you work in public service for X years they forgive some of the loan. They will not view the mortgage  debt the same way.

"
4231,4231,6747,Show tooltip on invalid input in edit control,"I have subclassed edit control to accept only floating numbers. I would like to pop a tooltip when user makes an invalid input. The behavior I target is like the one edit control with ES_NUMBER has :



So far I was able to implement tracking tooltip and display it when user makes invalid input.

However, the tooltip is misplaced. I have tried to use ScreenToClient and ClientToScreen to fix this but have failed.

Here are the instructions for creating SCCE :

1) Create default Win32 project in Visual Studio.

2) Add the following includes in your stdafx.h, just under #include &lt;windows.h&gt; :

#include &lt;windowsx.h&gt;
#include &lt;commctrl.h&gt;

#pragma comment( lib, ""comctl32.lib"")

#pragma comment(linker, \
    ""\""/manifestdependency:type='Win32' ""\
    ""name='Microsoft.Windows.Common-Controls' ""\
    ""version='6.0.0.0' ""\
    ""processorArchitecture='*' ""\
    ""publicKeyToken='6595b64144ccf1df' ""\
    ""language='*'\"""")


3) Add these global variables:

HWND g_hwndTT;
TOOLINFO g_ti;


4) Here is a simple subclass procedure for edit controls ( just for testing purposes ) :

LRESULT CALLBACK EditSubProc ( HWND hwnd, UINT message, 
    WPARAM wParam, LPARAM lParam, 
    UINT_PTR uIdSubclass, DWORD_PTR dwRefData )
{
    switch (message)
    {
    case WM_CHAR:
        {
            POINT pt;
            if( ! isdigit( wParam ) )  // if not a number pop a tooltip!
            {
                if (GetCaretPos(&amp;pt))  // here comes the problem
                {
                    // coordinates are not good, so tooltip is misplaced
                    ClientToScreen( hwnd, &amp;pt );


                    /************************** EDIT #1 ****************************/
                    /******* If I delete this line x-coordinate is OK *************/
                    /*** y-coordinate should be little lower, but it is still OK **/
                    /**************************************************************/

                    ScreenToClient( GetParent(hwnd), &amp;pt );

                    /************************* Edit #2 ****************************/

                    // this adjusts the y-coordinate, see the second edit
                    RECT rcClientRect;
                    Edit_GetRect( hwnd, &amp;rcClientRect );
                    pt.y = rcClientRect.bottom;

                    /**************************************************************/

                    SendMessage(g_hwndTT, TTM_TRACKACTIVATE, 
                        TRUE, (LPARAM)&amp;g_ti);
                    SendMessage(g_hwndTT, TTM_TRACKPOSITION, 
                        0, MAKELPARAM(pt.x, pt.y));
                }
                return FALSE;
            }
            else
            {
                SendMessage(g_hwndTT, TTM_TRACKACTIVATE, 
                    FALSE, (LPARAM)&amp;g_ti);
                return ::DefSubclassProc( hwnd, message, wParam, lParam );
            }
        }
        break;
    case WM_NCDESTROY:
        ::RemoveWindowSubclass( hwnd, EditSubProc, 0 );
        return DefSubclassProc( hwnd, message, wParam, lParam);
        break;
    }
    return DefSubclassProc( hwnd, message, wParam, lParam);
} 


5) Add the following WM_CREATE handler :

case WM_CREATE:
    {
        HWND hEdit = CreateWindowEx( 0, L""EDIT"", L""edit"", WS_CHILD | WS_VISIBLE |
            WS_BORDER | ES_CENTER, 150, 150, 100, 30, hWnd, (HMENU)1000, hInst, 0 );

        // try with tooltip
        g_hwndTT = CreateWindow(TOOLTIPS_CLASS, NULL,
            WS_POPUP | TTS_ALWAYSTIP | TTS_BALLOON,
            0, 0, 0, 0, hWnd, NULL, hInst, NULL);

        if( !g_hwndTT )
            MessageBeep(0);  // just to signal error somehow

        g_ti.cbSize = sizeof(TOOLINFO);
        g_ti.uFlags = TTF_TRACK | TTF_ABSOLUTE;
        g_ti.hwnd = hWnd;
        g_ti.hinst = hInst;
        g_ti.lpszText = TEXT(""Hi there"");

        if( ! SendMessage(g_hwndTT, TTM_ADDTOOL, 0, (LPARAM)&amp;g_ti) )
            MessageBeep(0);  // just to have some error signal

        // subclass edit control
        SetWindowSubclass( hEdit, EditSubProc, 0, 0 );
    }
    return 0L;  


6) Initialize common controls in MyRegisterClass ( before return statement ) :

// initialize common controls
INITCOMMONCONTROLSEX iccex;
iccex.dwSize = sizeof(INITCOMMONCONTROLSEX);
iccex.dwICC = ICC_BAR_CLASSES | ICC_WIN95_CLASSES | 
    ICC_TAB_CLASSES | ICC_TREEVIEW_CLASSES | ICC_STANDARD_CLASSES ;

if( !InitCommonControlsEx(&amp;iccex) ) 
    MessageBeep(0);   // signal error 


That's it, for the SSCCE.

My questions are following :


How can I properly position tooltip in my main window? How should I manipulate with caret coordinates?
Is there a way for tooltip handle and toolinfo structure to not be global?


Thank you for your time.

Best regards. 

EDIT #1:

I have managed to achieve quite an improvement by deleting ScreenToClient call in the subclass procedure. The x-coordinate is good, y-coordinate could be slightly lower. I still would like to remove global variables somehow...

EDIT #2:

I was able to adjust y-coordinate by using EM_GETRECT message and setting y-coordinate to the bottom of the formatting rectangle:

RECT rcClientRect;
Edit_GetRect( hwnd, &amp;rcClientRect );
pt.y = rcClient.bottom;


Now the end-result is much better. All that is left is to remove global variables...

EDIT #3:

It seems that I have cracked it! The solution is in EM_SHOWBALLOONTIP and EM_HIDEBALLOONTIP messages! Tooltip is placed at the caret position, ballon shape is the same as the one on the picture, and it auto-dismisses itself properly. And the best thing is that I do not need global variables!

Here is my subclass procedure snippet:

case WM_CHAR:
{
    // whatever... This condition is for testing purpose only
    if( ! IsCharAlpha( wParam ) &amp;&amp; IsCharAlphaNumeric( wParam ) )
    {
        SendMessage(hwnd, EM_HIDEBALLOONTIP, 0, 0);
        return ::DefSubclassProc( hwnd, message, wParam, lParam );
    }
    else
    {
        EDITBALLOONTIP ebt;

        ebt.cbStruct = sizeof( EDITBALLOONTIP );
        ebt.pszText = L"" Tooltip text! "";
        ebt.pszTitle = L"" Tooltip title!!! "";
        ebt.ttiIcon = TTI_ERROR_LARGE;    // tooltip icon

        SendMessage(hwnd, EM_SHOWBALLOONTIP, 0, (LPARAM)&amp;ebt);

        return FALSE;
    }
 }
 break;

",AlwaysLearningNewStuff,https://stackoverflow.com/users/2676466,"I'm giving the comment as an answer (I should have done that earlier) so that it's clear that the question has been answered:

MSDN Docs for TTM_TRACKPOSITION says that the x/y values are ""in screen coordinates"".

I'm not totally sure, but the y-coordinate probably corresponds to the top of the caret, you could add half of the edit box height if you want to position your tooltip in the middle of the edit box.

EDIT
re Global variables, you could bundle all your global variables into a structure, allocate memory for the structure and pass the pointer of the structure using the SetWindowLongPtr API call for the edit window using the GWLP_USERDATA, the window proc can then retrieve the values using GetWindowLongPtr...
",Edward Clements,https://stackoverflow.com/users/1850797,http://stackoverflow.com/questions/23892594/show-tooltip-on-invalid-input-in-edit-control,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.4444444444444444,0.0,0.5,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8,1.0,0.3333333333333333,0.0,1.0,Show tooltips for invalid input in the edit control,"I have subclassed edit control to accept only floating numbers. I would like to pop a tooltip when user makes an invalid input. The behavior I target is like the one edit control with ES_NUMBER has :



So far I was able to implement tracking tooltip and display it when user makes invalid input.

However, the tooltip is misplaced. I have tried to use ScreenToClient and ClientToScreen to fix this but have failed.

Here are the instructions for creating SCCE :

1) Create default Win32 project in Visual Studio.

2) Add the following includes in your stdafx.h, just under #include &lt;windows.h&gt; :

#include &lt;windowsx.h&gt;
#include &lt;commctrl.h&gt;

#pragma comment( lib, ""comctl32.lib"")

#pragma comment(linker, \
    ""\""/manifestdependency:type='Win32' ""\
    ""name='Microsoft.Windows.Common-Controls' ""\
    ""version='6.0.0.0' ""\
    ""processorArchitecture='*' ""\
    ""publicKeyToken='6595b64144ccf1df' ""\
    ""language='*'\"""")


3) Add these global variables:

HWND g_hwndTT;
TOOLINFO g_ti;


4) Here is a simple subclass procedure for edit controls ( just for testing purposes ) :

LRESULT CALLBACK EditSubProc ( HWND hwnd, UINT message, 
    WPARAM wParam, LPARAM lParam, 
    UINT_PTR uIdSubclass, DWORD_PTR dwRefData )
{
    switch (message)
    {
    case WM_CHAR:
        {
            POINT pt;
            if( ! isdigit( wParam ) )  // if not a number pop a tooltip!
            {
                if (GetCaretPos(&amp;pt))  // here comes the problem
                {
                    // coordinates are not good, so tooltip is misplaced
                    ClientToScreen( hwnd, &amp;pt );


                    /************************** EDIT #1 ****************************/
                    /******* If I delete this line x-coordinate is OK *************/
                    /*** y-coordinate should be little lower, but it is still OK **/
                    /**************************************************************/

                    ScreenToClient( GetParent(hwnd), &amp;pt );

                    /************************* Edit #2 ****************************/

                    // this adjusts the y-coordinate, see the second edit
                    RECT rcClientRect;
                    Edit_GetRect( hwnd, &amp;rcClientRect );
                    pt.y = rcClientRect.bottom;

                    /**************************************************************/

                    SendMessage(g_hwndTT, TTM_TRACKACTIVATE, 
                        TRUE, (LPARAM)&amp;g_ti);
                    SendMessage(g_hwndTT, TTM_TRACKPOSITION, 
                        0, MAKELPARAM(pt.x, pt.y));
                }
                return FALSE;
            }
            else
            {
                SendMessage(g_hwndTT, TTM_TRACKACTIVATE, 
                    FALSE, (LPARAM)&amp;g_ti);
                return ::DefSubclassProc( hwnd, message, wParam, lParam );
            }
        }
        break;
    case WM_NCDESTROY:
        ::RemoveWindowSubclass( hwnd, EditSubProc, 0 );
        return DefSubclassProc( hwnd, message, wParam, lParam);
        break;
    }
    return DefSubclassProc( hwnd, message, wParam, lParam);
} 


5) Add the following WM_CREATE handler :

case WM_CREATE:
    {
        HWND hEdit = CreateWindowEx( 0, L""EDIT"", L""edit"", WS_CHILD | WS_VISIBLE |
            WS_BORDER | ES_CENTER, 150, 150, 100, 30, hWnd, (HMENU)1000, hInst, 0 );

        // try with tooltip
        g_hwndTT = CreateWindow(TOOLTIPS_CLASS, NULL,
            WS_POPUP | TTS_ALWAYSTIP | TTS_BALLOON,
            0, 0, 0, 0, hWnd, NULL, hInst, NULL);

        if( !g_hwndTT )
            MessageBeep(0);  // just to signal error somehow

        g_ti.cbSize = sizeof(TOOLINFO);
        g_ti.uFlags = TTF_TRACK | TTF_ABSOLUTE;
        g_ti.hwnd = hWnd;
        g_ti.hinst = hInst;
        g_ti.lpszText = TEXT(""Hi there"");

        if( ! SendMessage(g_hwndTT, TTM_ADDTOOL, 0, (LPARAM)&amp;g_ti) )
            MessageBeep(0);  // just to have some error signal

        // subclass edit control
        SetWindowSubclass( hEdit, EditSubProc, 0, 0 );
    }
    return 0L;  


6) Initialize common controls in MyRegisterClass ( before return statement ) :

// initialize common controls
INITCOMMONCONTROLSEX iccex;
iccex.dwSize = sizeof(INITCOMMONCONTROLSEX);
iccex.dwICC = ICC_BAR_CLASSES | ICC_WIN95_CLASSES | 
    ICC_TAB_CLASSES | ICC_TREEVIEW_CLASSES | ICC_STANDARD_CLASSES ;

if( !InitCommonControlsEx(&amp;iccex) ) 
    MessageBeep(0);   // signal error 


That's it, for the SSCCE.

My questions are following :


How can I properly position tooltip in my main window? How should I manipulate with caret coordinates?
Is there a way for tooltip handle and toolinfo structure to not be global?


Thank you for your time.

Best regards. 

EDIT #1:

I have managed to achieve quite an improvement by deleting ScreenToClient call in the subclass procedure. The x-coordinate is good, y-coordinate could be slightly lower. I still would like to remove global variables somehow...

EDIT #2:

I was able to adjust y-coordinate by using EM_GETRECT message and setting y-coordinate to the bottom of the formatting rectangle:

RECT rcClientRect;
Edit_GetRect( hwnd, &amp;rcClientRect );
pt.y = rcClient.bottom;


Now the end-result is much better. All that is left is to remove global variables...

EDIT #3:

It seems that I have cracked it! The solution is in EM_SHOWBALLOONTIP and EM_HIDEBALLOONTIP messages! Tooltip is placed at the caret position, ballon shape is the same as the one on the picture, and it auto-dismisses itself properly. And the best thing is that I do not need global variables!

Here is my subclass procedure snippet:

case WM_CHAR:
{
    // whatever... This condition is for testing purpose only
    if( ! IsCharAlpha( wParam ) &amp;&amp; IsCharAlphaNumeric( wParam ) )
    {
        SendMessage(hwnd, EM_HIDEBALLOONTIP, 0, 0);
        return ::DefSubclassProc( hwnd, message, wParam, lParam );
    }
    else
    {
        EDITBALLOONTIP ebt;

        ebt.cbStruct = sizeof( EDITBALLOONTIP );
        ebt.pszText = L"" Tooltip text! "";
        ebt.pszTitle = L"" Tooltip title!!! "";
        ebt.ttiIcon = TTI_ERROR_LARGE;    // tooltip icon

        SendMessage(hwnd, EM_SHOWBALLOONTIP, 0, (LPARAM)&amp;ebt);

        return FALSE;
    }
 }
 break;

","I'm giving the comment as an answer (I should have done that earlier) so that it's clear that the question has been answered:

MSDN Docs for TTM_TRACKPOSITION says that the x/y values are ""in screen coordinates"".

I'm not totally sure, but the y-coordinate probably corresponds to the top of the caret, you could add half of the edit box height if you want to position your tooltip in the middle of the edit box.

EDIT
re Global variables, you could bundle all your global variables into a structure, allocate memory for the structure and pass the pointer of the structure using the SetWindowLongPtr API call for the edit window using the GWLP_USERDATA, the window proc can then retrieve the values using GetWindowLongPtr...
"
1004,1004,1583,Is hacking back a valid security technique for companies?,"Recently it has come to light through the reverse engineering of hacking tools that there are vulnerabilities in them that could be exploited to take over an attackers computer during a remote hacking session. In other words, while they are hacking you, you could get into the system from which they are launching the attack to find out what they have managed to access, what the system is, or even p4wn it yourself. The goals would be damage control, deterrence, and ultimately being able to charge the perpetrator of the crime. 

Leaving aside the many legal, ethical, and moral considerations (if you are curious there's a debate recorded here), my question is whether hacking back using this technique has any value to a company. If it was ethical and legal would it be worth a company to invest in the systems and skills needed to make this work, or is it a waste of money? 

EDIT:
There's been several comments regarding leaving the legal and ethical considerations out of the question, so here's the explanation behind that. So far the discussion of hacking back in this manner has been discussed by lawyers, some shouting it is legal, and others saying it isn't. What they do agree on is that there's no case law, and until there is there will be no clear answer. Also, legalities vary from nation to nation, so the answer to legality is ""maybe"" and ""it depends where you are"". 

However so far none of the discussion I've seen has been among IT Security professionals who would be the ones to design, deploy, and run systems that would to the hacking back. The lawyers all seem to think that organizations would adopt the technique as a matter of course, but I am not in agreement with that and I would like to hear the views of my peers. This is why I've asked the question apart from legal and ethical aspects. 
",GdD,https://security.stackexchange.com/users/10950,"I know a story of a man with a house and a little garden.

After being burgled many and many times, asking police for quicker intervention, but his house was burgled again and again,

Finally the man have installed some traps around his house. Caution advertisment and warning was instaled too, all around his house... But.

Thieves came again and fall in a trap. Harmed, tief had call police to ask for reparation. The man was convicted because of thief harmed. Finally man was forced to paid a lot.

My conviction is: To be better than, I have to not be worst
",F. Hauri,https://security.stackexchange.com/users/15701,http://security.stackexchange.com/questions/24700/is-hacking-back-a-valid-security-technique-for-companies,TECHNOLOGY,security.stackexchange.com,0.8888888888888888,1.0,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.7777777777777778,0.6666666666666666,1.0,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.8888888888888888,0.5555555555555556,0.4444444444444444,0.7777777777777778,0.5555555555555556,0.4666666666666667,0.0,0.0,0.3333333333333333,0.5555555555555556,Is hacking an effective security technology for companies?,"Recently it has come to light through the reverse engineering of hacking tools that there are vulnerabilities in them that could be exploited to take over an attackers computer during a remote hacking session. In other words, while they are hacking you, you could get into the system from which they are launching the attack to find out what they have managed to access, what the system is, or even p4wn it yourself. The goals would be damage control, deterrence, and ultimately being able to charge the perpetrator of the crime. 

Leaving aside the many legal, ethical, and moral considerations (if you are curious there's a debate recorded here), my question is whether hacking back using this technique has any value to a company. If it was ethical and legal would it be worth a company to invest in the systems and skills needed to make this work, or is it a waste of money? 

EDIT:
There's been several comments regarding leaving the legal and ethical considerations out of the question, so here's the explanation behind that. So far the discussion of hacking back in this manner has been discussed by lawyers, some shouting it is legal, and others saying it isn't. What they do agree on is that there's no case law, and until there is there will be no clear answer. Also, legalities vary from nation to nation, so the answer to legality is ""maybe"" and ""it depends where you are"". 

However so far none of the discussion I've seen has been among IT Security professionals who would be the ones to design, deploy, and run systems that would to the hacking back. The lawyers all seem to think that organizations would adopt the technique as a matter of course, but I am not in agreement with that and I would like to hear the views of my peers. This is why I've asked the question apart from legal and ethical aspects. 
","I know a story of a man with a house and a little garden.

After being burgled many and many times, asking police for quicker intervention, but his house was burgled again and again,

Finally the man have installed some traps around his house. Caution advertisment and warning was instaled too, all around his house... But.

Thieves came again and fall in a trap. Harmed, tief had call police to ask for reparation. The man was convicted because of thief harmed. Finally man was forced to paid a lot.

My conviction is: To be better than, I have to not be worst
"
5170,5170,8215,Need more memory to install Nova 3 Near Orbit on Samsung Galaxy S2,"I have a Samsung Galaxy S2, running Android 4.0.3. 

I want  to install Nova 3 Near Orbit on this device. I need 2 gigabyte of memory to install the game, but I only have 1.97 gigabytes in total.

How can i get the other 3 megabyte? I have 11 gigabyte of space on my phone, and I also have an SD card with 14 gigabyte. 
",steven ives,https://android.stackexchange.com/users/27739,"There is no way to add additional RAM to your Android device (as you've tagged your question ""RAM"" I assume you are meaning RAM). So: sorry, you won't be able to solve this.
",Izzy,https://android.stackexchange.com/users/16575,http://android.stackexchange.com/questions/38858/need-more-memory-to-install-nova-3-near-orbit-on-samsung-galaxy-s2,TECHNOLOGY,android.stackexchange.com,1.0,0.4444444444444444,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.5555555555555556,0.7777777777777778,0.6666666666666666,0.8888888888888888,1.0,0.9,0.0,0.0,1.0,0.8888888888888888,More memory required to install Nova 3 near orbit on Samsung Galaxy S2,"I have a Samsung Galaxy S2, running Android 4.0.3. 

I want  to install Nova 3 Near Orbit on this device. I need 2 gigabyte of memory to install the game, but I only have 1.97 gigabytes in total.

How can i get the other 3 megabyte? I have 11 gigabyte of space on my phone, and I also have an SD card with 14 gigabyte. 
","There's no way to add extra RAM to your Android device (because you've tagged your problem ""ram,"" I think you mean RAM). So: sorry, you can't solve this problem."
382,382,602,Adjustment to road bike brakes for high grade downhill,"I have a road bike with a front brake that wears a lot of brake pad when I ride downhill every day. I lose 900ft in elevation on steep grades with lots of stop signs and traffic lights. On top of that, it rains a decent amount and the rim brakes are terrible in that weather. I don't trust them downhill in the rain. Sometimes I just walk.

I feather the brakes going downhill, because otherwise I'm too fast to stop quickly for an errant car.

It'd be nice to not constantly replace pads, and have powerful stopping. How can I make this constant downhill more pleasant?

Thanks. 
",ash,https://bicycles.stackexchange.com/users/14519,"There are several solutions:

(1) Switch your brake pads - a harder compound will wear less, but be less effective at braking. Make sure to clean your rims for rim brakes as well. 

(2) Use your brakes less and get more comfortable with higher speeds.

(3) Change your brakes (some brake models brake better than others, even if you're using the same type of brakes, e.g. caliper brakes). 
",Batman,https://bicycles.stackexchange.com/users/8219,http://bicycles.stackexchange.com/questions/25771/adjustment-to-road-bike-brakes-for-high-grade-downhill,CULTURE,bicycles.stackexchange.com,1.0,0.4444444444444444,0.3333333333333333,0.5,1.0,0.5,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.8888888888888888,Adjustment of bicycle brake on high grade downhill road,"I have a road bike with front brakes, which wear a lot of brake pads every day when I go down the hill. I lost 900 feet above sea level on a steep slope, where there were lots of stop signs and traffic lights. Besides, it rained well and the brakes were terrible in that weather. I don't believe they came down in the rain. Sometimes I just walk.","There are several solutions:

(1) Switch your brake pads - a harder compound will wear less, but be less effective at braking. Make sure to clean your rims for rim brakes as well. 

(2) Use your brakes less and get more comfortable with higher speeds.

(3) Change your brakes (some brake models brake better than others, even if you're using the same type of brakes, e.g. caliper brakes). 
"
4716,4716,7482,What are lightbox / modal window UI best practices for viewing full-sized images in a gallery?,"I'm an artist and amateur web designer.

On my portfolio website, I've grouped my work into projects. Most of my projects contain few (20 or less) images, so I just display them in full size and let the visitor scroll (example) because this is how I prefer to browse other artist's work as well.

For projects containing more images, I use thumbnails which link to the full-sized images, because, again, when I browse other artist's portfolios, if there are lots of images on a page it's kinda cumbersome to load. 

Recently I wrote some jQuery to implement a lightbox effect (modal window overlay) so when you click on a thumbnail, the full-sized image appears (example).

My main reasons for implementing this:


it's much more presentable than having a direct link to the image,
which is what I used to do
if the visitor shares the image on something like tumblr or
Pinterest, the link back will be to the project page instead of a
direct link to the image
if the visitor wants to right-click on the thumbnails to load several
images in several new browser tabs/windows, they can still do so (the
lightbox is triggered on left click)


I did not include a close button because it seems like more work for the visitor to have to look for a close button, than to simply click anywhere to close the lightbox (which is what I did).

What are your thoughts regarding lightbox interface for this particular use?
The goal would be the best way to showcase visual art/design work, and the target audience would be, well, anyone who wants to view the work. The display method, in this case a lightbox interface, should be efficient, useable, and presentable (it should highlight, not detract from, the work).
",Feanne,https://ux.stackexchange.com/users/13655,"The modal image roll is very nice and is used on bigger social media sites, such as Facebook and Google+. So stick to it, but please do not omit the close button. It makes users confused and we wouldn't want that. One idea to use is Facebook's implementation, where you have the [X] fully working, but on hover user get a clue: use Esc to close! I think this is splendid design telling the users there are other ways and you do not have to grab your mouse to close the image:


",Benny Skogberg,https://ux.stackexchange.com/users/4679,http://ux.stackexchange.com/questions/19527/what-are-lightbox-modal-window-ui-best-practices-for-viewing-full-sized-images,TECHNOLOGY,ux.stackexchange.com,0.6666666666666666,0.3333333333333333,1.0,1.0,0.0,0.0,1.0,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,0.0,1.0,What are the Lightbox / modal window UI best practices for viewing full-size images in the library?,"I'm an artist and amateur web designer.

On my portfolio website, I've grouped my work into projects. Most of my projects contain few (20 or less) images, so I just display them in full size and let the visitor scroll (example) because this is how I prefer to browse other artist's work as well.

For projects containing more images, I use thumbnails which link to the full-sized images, because, again, when I browse other artist's portfolios, if there are lots of images on a page it's kinda cumbersome to load. 

Recently I wrote some jQuery to implement a lightbox effect (modal window overlay) so when you click on a thumbnail, the full-sized image appears (example).

My main reasons for implementing this:


it's much more presentable than having a direct link to the image,
which is what I used to do
if the visitor shares the image on something like tumblr or
Pinterest, the link back will be to the project page instead of a
direct link to the image
if the visitor wants to right-click on the thumbnails to load several
images in several new browser tabs/windows, they can still do so (the
lightbox is triggered on left click)


I did not include a close button because it seems like more work for the visitor to have to look for a close button, than to simply click anywhere to close the lightbox (which is what I did).

What are your thoughts regarding lightbox interface for this particular use?
The goal would be the best way to showcase visual art/design work, and the target audience would be, well, anyone who wants to view the work. The display method, in this case a lightbox interface, should be efficient, useable, and presentable (it should highlight, not detract from, the work).
","Modal image scrolling is great for larger social media sites like Facebook and Google +. So hold on, but don't ignore the close button. It's confusing to users, and we don't want that. One idea of using Facebook is that you can make [x] work completely, but when hovering, users can get a hint: use ESC to close! I think it's a good design to tell users that there are other ways to turn off images without using the mouse:"
2439,2439,3892,"Polite alternatives to ""as soon as possible""","I’ve found myself writing the phrase “as soon as possible” just too often. Sometimes I wonder if it sounds a little rude. How can I convey the same meaning in a more polite way but without losing sense of urgency?
",Albertus,https://english.stackexchange.com/users/20545,"You could say ""quick as you can"", ""expedite please"". 

This is not as polite but you could say ""immediately if not sooner"".
",jan,https://english.stackexchange.com/users/21625,http://english.stackexchange.com/questions/69101/polite-alternatives-to-as-soon-as-possible,CULTURE,english.stackexchange.com,1.0,1.0,0.6666666666666666,1.0,0.0,0.3333333333333333,0.7777777777777778,0.7777777777777778,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,0.8333333333333334,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.3333333333333333,0.3333333333333333,1.0,"Politely choose ""as soon as possible""","I find myself writing the word ""as soon as possible"". Sometimes I wonder if it sounds rude. How can I express the same meaning more politely without losing my sense of urgency?","You could say ""quick as you can"", ""expedite please"". 

This is not as polite but you could say ""immediately if not sooner"".
"
2791,2791,4450,Referencing (not Bibliography) in Harvard Style using Write Latex,"I am relatively new to Latex and I am trying to write my first project thesis. I am using WriteLatex, which is an online Latex environment. I was successful in obtaining the references from many sites, imported them into a .bib file in Bibtex and cite them in Author Year title format. My problem arises when I cannot see the References at the bottom in Harvard style. What I want to see is this

[Alpaydin,2004] Ethem Alpaydin, Introduction to Machine Learning, MIT Press, 2004.


What I get is just this under the name Bibliography

Ethem Alpaydin, Introduction to Machine Learning, MIT Press, 2004.


I am using the following packages

\documentclass[a4paper]{report}
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage{natbib}

\begin{document}

\addcontentsline{toc}{subsection}{Bibliography}
\bibliography{Ref} %My .bib file
\bibliographystyle{plainnat}
\end{document}


Edit: The Bibliography files are of the format:

@book{alpaydin2004introduction,
  title={Introduction to machine learning},
  author={Alpaydin, Ethem},
  year={2004},
  publisher={MIT press}
}


Can someone please help me get the Harvard style referencing even at the end of the document in the style I mentioned above. Thanks in advance
",Nikki_Champ,https://tex.stackexchange.com/users/60666,"To get the appearance of the entries in the references, keep using the plainnat bibliography style but do not load the natbib package. You'll get:



\documentclass[a4paper]{article} % to keep output all on one page
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{amsmath,amssymb,amsthm,graphicx}
%\usepackage{natbib} %% deliberately commented out
\bibliographystyle{plainnat}
\usepackage{filecontents}
\begin{filecontents*}{Ref.bib}
@book{alp:04,
  author   = ""Ethem Alpaydin"", 
  title    = ""Introduction to Machine Learning"",
  publisher= ""MIT Press"",
  year     = 2004,
}
\end{filecontents*}
\begin{document}
\cite{alp:04}
\bibliography{Ref}
\end{document}




If you do not want square brackets surrounding the citation callout, i.e., if you want it to look like Alpaydin(2004), you should also provide the following instructions in the preamble:

\usepackage[noadjust]{cite}
\renewcommand\citeleft{}
\renewcommand\citeright{}




If you did load natbib -- and, of course, didn't load the cite package as well -- you'd get the following look, which is, I gather, not what you want:


",Mico,https://tex.stackexchange.com/users/5001,http://tex.stackexchange.com/questions/197535/referencing-not-bibliography-in-harvard-style-using-write-latex,TECHNOLOGY,tex.stackexchange.com,1.0,0.3333333333333333,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,1.0,Use write latex to quote in Harvard style (not bibliography),"I am relatively new to Latex and I am trying to write my first project thesis. I am using WriteLatex, which is an online Latex environment. I was successful in obtaining the references from many sites, imported them into a .bib file in Bibtex and cite them in Author Year title format. My problem arises when I cannot see the References at the bottom in Harvard style. What I want to see is this

[Alpaydin,2004] Ethem Alpaydin, Introduction to Machine Learning, MIT Press, 2004.


What I get is just this under the name Bibliography

Ethem Alpaydin, Introduction to Machine Learning, MIT Press, 2004.


I am using the following packages

\documentclass[a4paper]{report}
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage{natbib}

\begin{document}

\addcontentsline{toc}{subsection}{Bibliography}
\bibliography{Ref} %My .bib file
\bibliographystyle{plainnat}
\end{document}


Edit: The Bibliography files are of the format:

@book{alpaydin2004introduction,
  title={Introduction to machine learning},
  author={Alpaydin, Ethem},
  year={2004},
  publisher={MIT press}
}


Can someone please help me get the Harvard style referencing even at the end of the document in the style I mentioned above. Thanks in advance
","To get the appearance of the entries in the references, keep using the plainnat bibliography style but do not load the natbib package. You'll get:



\documentclass[a4paper]{article} % to keep output all on one page
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{amsmath,amssymb,amsthm,graphicx}
%\usepackage{natbib} %% deliberately commented out
\bibliographystyle{plainnat}
\usepackage{filecontents}
\begin{filecontents*}{Ref.bib}
@book{alp:04,
  author   = ""Ethem Alpaydin"", 
  title    = ""Introduction to Machine Learning"",
  publisher= ""MIT Press"",
  year     = 2004,
}
\end{filecontents*}
\begin{document}
\cite{alp:04}
\bibliography{Ref}
\end{document}




If you do not want square brackets surrounding the citation callout, i.e., if you want it to look like Alpaydin(2004), you should also provide the following instructions in the preamble:

\usepackage[noadjust]{cite}
\renewcommand\citeleft{}
\renewcommand\citeright{}




If you did load natbib -- and, of course, didn't load the cite package as well -- you'd get the following look, which is, I gather, not what you want:


"
772,772,1219,Maximal ideals of commutative unital C* algebra using Gelfand-Naimark theorem,"Let $\mathcal{A}$ be a unital, commutative C*-algebra. The radical of $\mathcal{A}$ is defined as

$$\operatorname{Rad}(\mathcal{A}) = \bigcap \{\mathcal{I}\subset \mathcal{A}: \mathcal{I} \text{ is a maximal ideal}\}$$

How can one characterize $\operatorname{Rad}(\mathcal{A})$ using the Gelfand-Naimark theorem only, i.e. without referring to more evolved methods such as representation theory? 

EDIT: (Gelfand-Naimark theorem)

Let $\mathcal{A}$ be a unital commutative C*-algebra. Then the Gelfand transform $\Gamma: \mathcal{A} \rightarrow C(M(\mathcal{A})), \Gamma(A)(m):=m(A)$ is a *-isomorphism.
",madison54,https://math.stackexchange.com/users/64221,"Hint: For any space $X$ and any $x\in X$, the set of functions vanishing at $x$ is a maximal ideal in $C(X)$.
",tomasz,https://math.stackexchange.com/users/30222,http://math.stackexchange.com/questions/433602/maximal-ideals-of-commutative-unital-c-algebra-using-gelfand-naimark-theorem,SCIENCE,math.stackexchange.com,0.5555555555555556,0.4444444444444444,0.0,1.0,1.0,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.6666666666666666,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,0.9,1.0,0.0,0.0,1.0,The maximum ideals of Gelfand nimakes theorem for commutative unitary c * - algebras,"Let $\mathcal{A}$ be a unital, commutative C*-algebra. The radical of $\mathcal{A}$ is defined as

$$\operatorname{Rad}(\mathcal{A}) = \bigcap \{\mathcal{I}\subset \mathcal{A}: \mathcal{I} \text{ is a maximal ideal}\}$$

How can one characterize $\operatorname{Rad}(\mathcal{A})$ using the Gelfand-Naimark theorem only, i.e. without referring to more evolved methods such as representation theory? 

EDIT: (Gelfand-Naimark theorem)

Let $\mathcal{A}$ be a unital commutative C*-algebra. Then the Gelfand transform $\Gamma: \mathcal{A} \rightarrow C(M(\mathcal{A})), \Gamma(A)(m):=m(A)$ is a *-isomorphism.
","Hint: For any space $X$ and any $x\in X$, the set of functions vanishing at $x$ is a maximal ideal in $C(X)$.
"
756,756,1197,Removing a javscript from homepage,"i am trying to remove the validation.js script from my home page as it is not need here. I am using this code in my page.xml 

    &lt;cms_index_index&gt;
    &lt;reference name=""head""&gt;
                &lt;action method=""removeItem""&gt;&lt;script&gt;prototype/validation.js&lt;/script&gt;&lt;/action&gt;
    &lt;/reference&gt;
&lt;/cms_index_index&gt;


But the script is still being loaded. What am i doing wrong? 

Thanks 
",Adam Allen,https://magento.stackexchange.com/users/7706,"Try like this:

&lt;cms_index_index&gt;
    &lt;reference name=""head""&gt;
       &lt;action method=""removeItem""&gt;
           &lt;type&gt;js&lt;/type&gt;
           &lt;script&gt;prototype/validation.js&lt;/script&gt;
       &lt;/action&gt;
    &lt;/reference&gt;
&lt;/cms_index_index&gt;


The removeItem method receives 2 parameters. The type of the resource and the name of the resource. You were missing the type.
",Marius,https://magento.stackexchange.com/users/146,http://magento.stackexchange.com/questions/59570/removing-a-javscript-from-homepage,TECHNOLOGY,magento.stackexchange.com,1.0,0.5555555555555556,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.0,1.0,1.0,Remove javscript from the home page,"i am trying to remove the validation.js script from my home page as it is not need here. I am using this code in my page.xml 

    &lt;cms_index_index&gt;
    &lt;reference name=""head""&gt;
                &lt;action method=""removeItem""&gt;&lt;script&gt;prototype/validation.js&lt;/script&gt;&lt;/action&gt;
    &lt;/reference&gt;
&lt;/cms_index_index&gt;


But the script is still being loaded. What am i doing wrong? 

Thanks 
","Try like this:

&lt;cms_index_index&gt;
    &lt;reference name=""head""&gt;
       &lt;action method=""removeItem""&gt;
           &lt;type&gt;js&lt;/type&gt;
           &lt;script&gt;prototype/validation.js&lt;/script&gt;
       &lt;/action&gt;
    &lt;/reference&gt;
&lt;/cms_index_index&gt;


The removeItem method receives 2 parameters. The type of the resource and the name of the resource. You were missing the type.
"
1380,1380,2174,Finding columns that do not match existing primary key,"I'm trying to add a Foreign Key to a table, but database, Sql Server 2005, does not like it.

It says that columns do not match an existing primary key or unique constraint. 

How can I find the columns in question so I can delete/change them and add the foreign key?
",Chin,https://stackoverflow.com/users/135687,"Do a left join to the parent table on the key in question, then examine the values in the child table where the value in the left-joined parent table are null.

For example, if this was your schema...

table1:
    myKey int primary key,
    ...other columns...

table2:
    otherKey int primary key,
    myKeyFromTable1 int
    ...other columns...


You'd do this:

select distinct
    t2.myKeyFromTable1

from table2 t2

left join table1 t1 on t1.myKey = t2.myKeyFromTable1

where t1.myKey is null


That would give you the distinct values in table2 that wouldn't have a corresponding parent in table1.
",Adam Robinson,https://stackoverflow.com/users/82187,http://stackoverflow.com/questions/1178377/finding-columns-that-do-not-match-existing-primary-key,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.5555555555555556,0.0,1.0,0.6666666666666666,1.0,0.7777777777777778,0.5555555555555556,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,0.8888888888888888,Find columns that do not match the existing primary key,"I'm trying to add a Foreign Key to a table, but database, Sql Server 2005, does not like it.

It says that columns do not match an existing primary key or unique constraint. 

How can I find the columns in question so I can delete/change them and add the foreign key?
","Do a left join to the parent table on the key in question, then examine the values in the child table where the value in the left-joined parent table are null.

For example, if this was your schema...

table1:
    myKey int primary key,
    ...other columns...

table2:
    otherKey int primary key,
    myKeyFromTable1 int
    ...other columns...


You'd do this:

select distinct
    t2.myKeyFromTable1

from table2 t2

left join table1 t1 on t1.myKey = t2.myKeyFromTable1

where t1.myKey is null


That would give you the distinct values in table2 that wouldn't have a corresponding parent in table1.
"
5695,5695,9026,Nikon D3100 Won't Take Photo -- says light is too low,"I've had my Nikon D3100 camera for about 3 years.  I recently accidentally reset my shooting options.

Since I've done that, I'm having a hard time getting the camera to focus and take photos in lower light.  I can hear it (and see it) hunting to focus, but the bottom right flashes the image suggesting I use the flash and it won't let me take a picture.

I've ensured that it's set to AF-C, but I'm still not able to force the photo to be taken.  This happens with multiple lenses, including my prime which is fairly decent in low light.  Often the exposure information on the screen shows me that I am close to perfect exposure (and sometimes just a bit underexposed).

What's going on?  Is there something wrong with the camera?  What other settings can I check?

Some other tidbits, I have it set to Manual, and I'm able to take the photos if I manually focus--but that doesn't work for me since my eyesight isn't great.
",Ashley,https://photo.stackexchange.com/users/25458,"I had this problem in Low light with the AF Assist Light still coming on.

What I found was that using the Live View is completely different to focusing while keeping Live view off. 

I just stopped using Live view and the problem was immediately solved. Of course the AF Assiste light was working in my case for both scenarios.
",Chris,https://photo.stackexchange.com/users/41280,http://photo.stackexchange.com/questions/46979/nikon-d3100-wont-take-photo-says-light-is-too-low,LIFE_ARTS,photo.stackexchange.com,0.7777777777777778,0.8888888888888888,0.0,0.6666666666666666,1.0,1.0,0.6666666666666666,0.4444444444444444,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,0.0,1.0,0.6666666666666666,0.6666666666666666,1.0,0.8888888888888888,0.7333333333333333,0.0,0.0,1.0,0.8888888888888888,Nikon D3100 doesn't take pictures - it says the light is too low,"I've had my Nikon D3100 camera for about 3 years.  I recently accidentally reset my shooting options.

Since I've done that, I'm having a hard time getting the camera to focus and take photos in lower light.  I can hear it (and see it) hunting to focus, but the bottom right flashes the image suggesting I use the flash and it won't let me take a picture.

I've ensured that it's set to AF-C, but I'm still not able to force the photo to be taken.  This happens with multiple lenses, including my prime which is fairly decent in low light.  Often the exposure information on the screen shows me that I am close to perfect exposure (and sometimes just a bit underexposed).

What's going on?  Is there something wrong with the camera?  What other settings can I check?

Some other tidbits, I have it set to Manual, and I'm able to take the photos if I manually focus--but that doesn't work for me since my eyesight isn't great.
","I had this problem in Low light with the AF Assist Light still coming on.

What I found was that using the Live View is completely different to focusing while keeping Live view off. 

I just stopped using Live view and the problem was immediately solved. Of course the AF Assiste light was working in my case for both scenarios.
"
325,325,521,How to color lat/lon points in given RGB data?,"I am using QGIS on a Mac.

I am working with hydroacoustic data for mapping and interpreting the seafloor.
Data are collected, processed and interpreted. The result is a txt file with Lat and Lon in the first columns followed by R, G and B data, e.g. [54.20,7.78,0.94,0.62,0.37]. The files can have 100,000 lines or more. 
I am not really good in GIS but I need to use it for some reasons. I seem to be unable to plot these data in GIS. There is obviously no symbology/style way to tell the system to take the color values from a file (i.e. the next 3 values in the same line of the file). It is so easy in MatLab: scatter(lat, lon, symbolsize, [R G B]) but I can't work easily with multiple layers in Matlab.
",Chris,https://gis.stackexchange.com/users/35565,"Partly off-topic but because there is no user-friendly way for doing it with QGIS this image shows how it can be done with OpenJUMP.



OpenJUMP reads attribute column ""R_G_B"" and colours the feature with RGB values saved into the field as hexadecimal values. Perhaps QGIS some day can do the same or hopefully better by utilizing the OGR Feature Style Specification http://www.gdal.org/ogr_feature_style.html.
",user30184,https://gis.stackexchange.com/users/30184,http://gis.stackexchange.com/questions/109894/how-to-color-lat-lon-points-in-given-rgb-data,TECHNOLOGY,gis.stackexchange.com,0.8888888888888888,0.6666666666666666,0.0,0.0,1.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.8888888888888888,0.3333333333333333,0.5,0.6666666666666666,0.6666666666666666,0.4,0.3333333333333333,0.0,0.6666666666666666,0.8888888888888888,How to color latitude / longitude points in given RGB data?,"I am using QGIS on a Mac.

I am working with hydroacoustic data for mapping and interpreting the seafloor.
Data are collected, processed and interpreted. The result is a txt file with Lat and Lon in the first columns followed by R, G and B data, e.g. [54.20,7.78,0.94,0.62,0.37]. The files can have 100,000 lines or more. 
I am not really good in GIS but I need to use it for some reasons. I seem to be unable to plot these data in GIS. There is obviously no symbology/style way to tell the system to take the color values from a file (i.e. the next 3 values in the same line of the file). It is so easy in MatLab: scatter(lat, lon, symbolsize, [R G B]) but I can't work easily with multiple layers in Matlab.
","Partly off-topic but because there is no user-friendly way for doing it with QGIS this image shows how it can be done with OpenJUMP.



OpenJUMP reads attribute column ""R_G_B"" and colours the feature with RGB values saved into the field as hexadecimal values. Perhaps QGIS some day can do the same or hopefully better by utilizing the OGR Feature Style Specification http://www.gdal.org/ogr_feature_style.html.
"
1793,1793,2847,android using async http connection to get image bitmap,"I am trying to use async requests to fetch the images from urls, to prevent the url from hanging. This is the piece of code i am using for this

private void setImg(final ImageView im, String url){
    AsyncHttpClient client = new AsyncHttpClient();
    client.get(url, new AsyncHttpResponseHandler(){
        public void onSuccess(String response){
            try{
                byte[] imageAsBytes = response.getBytes();
                im.setImageBitmap(BitmapFactory.decodeByteArray(imageAsBytes, 0, imageAsBytes.length));
                im.refreshDrawableState();
            } catch(Throwable e){
                e.printStackTrace();
            }
        }
    });
}


This is always showing this warning in logcat

12-29 01:55:33.043: D/skia(14414): --- SkImageDecoder::Factory returned null

I cannot find a proper reason for this. Any help?
",Amit,https://stackoverflow.com/users/409110,"Now that a binary response handler has been added to AsyncHttp you can simply use androids BitmapFactory.decodeByeArray function:

AsyncHttpClient client = new AsyncHttpClient();
client.get(image_url, null, new AsyncHttpResponseHandler() {            
    @Override
    public void onSuccess(byte[] fileData) {
        Bitmap image = BitmapFactory.decodeByteArray(fileData, 0, fileData.length);
        //Do whatever you want with the image variable    
    }
});

",zarazan,https://stackoverflow.com/users/765297,http://stackoverflow.com/questions/8660885/android-using-async-http-connection-to-get-image-bitmap,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.3333333333333333,0.0,0.0,1.0,0.0,0.5555555555555556,0.7777777777777778,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,1.0,1.0,0.5555555555555556,1.0,1.0,0.8,1.0,0.0,0.0,1.0,Android uses asynchronous HTTP connection to obtain image bitmap,"I am trying to use async requests to fetch the images from urls, to prevent the url from hanging. This is the piece of code i am using for this

private void setImg(final ImageView im, String url){
    AsyncHttpClient client = new AsyncHttpClient();
    client.get(url, new AsyncHttpResponseHandler(){
        public void onSuccess(String response){
            try{
                byte[] imageAsBytes = response.getBytes();
                im.setImageBitmap(BitmapFactory.decodeByteArray(imageAsBytes, 0, imageAsBytes.length));
                im.refreshDrawableState();
            } catch(Throwable e){
                e.printStackTrace();
            }
        }
    });
}


This is always showing this warning in logcat

12-29 01:55:33.043: D/skia(14414): --- SkImageDecoder::Factory returned null

I cannot find a proper reason for this. Any help?
","Now that a binary response handler has been added to AsyncHttp you can simply use androids BitmapFactory.decodeByeArray function:

AsyncHttpClient client = new AsyncHttpClient();
client.get(image_url, null, new AsyncHttpResponseHandler() {            
    @Override
    public void onSuccess(byte[] fileData) {
        Bitmap image = BitmapFactory.decodeByteArray(fileData, 0, fileData.length);
        //Do whatever you want with the image variable    
    }
});

"
2386,2386,3806,Word for a result/achievement so exceptional that it is impossible?,"I am looking for a word or phrase regarding something that is ""impossible"". I can't seem to put my finger on it, but I am trying to think of the word to describe something that is the top of the top, and thus impossible to achieve? 

The only two words I have come up with are elusive and formidable, neither of which really mean what I want them to mean. I want something more clever to put it plainly.
",user128274,https://english.stackexchange.com/users/128274,"Unassailable sounds like it might fit the bill.


  
  Impossible to dispute or disprove; undeniable: unassailable truths.
  Not subject to attack or seizure; impregnable: an unassailable fortress.
  


thefreedictionary.com



Example sentence: 


  Liverpool football club are still looking unassailable.


Which is synonymous with:


  Defeating Liverpool football club still looks impossible.

",Charon,https://english.stackexchange.com/users/61558,http://english.stackexchange.com/questions/257713/word-for-a-result-achievement-so-exceptional-that-it-is-impossible,CULTURE,english.stackexchange.com,1.0,0.8888888888888888,0.3333333333333333,1.0,1.0,0.3333333333333333,0.6666666666666666,0.7777777777777778,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,0.0,1.0,A word whose result / achievement is so special that it is impossible?,"I'm looking for a word or phrase about ""impossible"". I don't seem to be able to point to it with my fingers, but I want to use this word to describe one thing, that is, what is on the top and thus impossible to achieve?","Unassailable sounds like it might fit the bill.


  
  Impossible to dispute or disprove; undeniable: unassailable truths.
  Not subject to attack or seizure; impregnable: an unassailable fortress.
  


thefreedictionary.com



Example sentence: 


  Liverpool football club are still looking unassailable.


Which is synonymous with:


  Defeating Liverpool football club still looks impossible.

"
5206,5206,8274,How replicas are formed in Frequency domain when a signal is sampled in Time Domain?,"I know that sampling in one domian [time or frequency] gives raise to replicas in another domain[frequency / time]. How replicas are formed. What is this Time domain periodicity and frequency domain periodicity here in sampling.
",rajez79,https://dsp.stackexchange.com/users/3638,"Sampling in one domain implies periodicity in the other. For example the Discrete Fourier Series (which the FFT is a special case off), requires both time and frequency domain signals to be discrete and periodic. 

This really isn't a topic that can be exhaustively discussed on board like this. I would recommend spending some quality time with good text book such as this http://www.amazon.com/Digital-Signal-Processing-Alan-Oppenheim/dp/0132146355 or http://www.dspguide.com/
",Hilmar,https://dsp.stackexchange.com/users/224,http://dsp.stackexchange.com/questions/7731/how-replicas-are-formed-in-frequency-domain-when-a-signal-is-sampled-in-time-dom,TECHNOLOGY,dsp.stackexchange.com,0.6666666666666666,0.3333333333333333,0.0,0.0,1.0,0.0,0.3333333333333333,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,1.0,"When the signal is sampled in time domain, how to form a replica in frequency domain?",I know that sampling in one domain [time or frequency] will increase to replicas in another domain [frequency / time]. How copies are made. What are the sampling periods in time domain and frequency domain.,"Sampling in one domain implies periodicity in the other. For example the Discrete Fourier Series (which the FFT is a special case off), requires both time and frequency domain signals to be discrete and periodic. 

This really isn't a topic that can be exhaustively discussed on board like this. I would recommend spending some quality time with good text book such as this http://www.amazon.com/Digital-Signal-Processing-Alan-Oppenheim/dp/0132146355 or http://www.dspguide.com/
"
1456,1456,2292,"Getting rid of ""Tethering Detected"" popup on Android ICS 4.0?","I just got a Samsung Galaxy S3 that runs Android ICS 4.0.8. When I connect the Galaxy S3 to my Mac laptop and use PDAnet to tether, I often get this popup on the Galaxy S3 screen:



Tethering via PDAnet works great, but the popup can get annoying. I can close the popup, but it comes back a few seconds later. 
How can I get rid of this popup permanently?
",solvingPuzzles,https://android.stackexchange.com/users/25730,"In the end, I rooted the phone and installed the Cyanogenmod distribution in place of the cell phone carrier's OS. :)
",solvingPuzzles,https://android.stackexchange.com/users/25730,http://android.stackexchange.com/questions/36313/getting-rid-of-tethering-detected-popup-on-android-ics-4-0,TECHNOLOGY,android.stackexchange.com,1.0,0.7777777777777778,0.0,0.6666666666666666,1.0,1.0,0.5555555555555556,0.5555555555555556,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.3333333333333333,0.3333333333333333,1.0,"Remove the ""tether detected"" pop-up on Android ICs 4.0?","I just bought a Samsung Galaxy S3 running Android ICs 4.0.8. When I connect Galaxy S3 to my Mac laptop and use PdaNet connection, I often see such a pop-up window on the galaxy S3 screen:","In the end, I rooted the phone and installed the Cyanogenmod distribution in place of the cell phone carrier's OS. :)
"
2834,2834,4509,Extending Internal Link and External Link to allow selection of Images,"I need to extend selection of external and Internal Link and provide a image selection.

Please see the snapshot in the below :


Here the above snapshot allows you to add properties for External Link.In the same popup can we add a field Called Image(as shown in screenshot) which will allow user to select images from the media library??

Thanks,
Suhas
",Suhas,https://stackoverflow.com/users/998504,"If you are talking about a whole field and not just an external link inside of a rich text field, you should create a custom field based on the documentation to do so in SDN:

http://sdn.sitecore.net/Articles/API/Creating%20a%20Composite%20Custom%20Field.aspx

You can inherit most functionality from the current link field.
",Paul Caponetti,https://stackoverflow.com/users/2201280,http://stackoverflow.com/questions/23337280/extending-internal-link-and-external-link-to-allow-selection-of-images,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.6666666666666666,0.0,1.0,1.0,1.0,0.5555555555555556,0.5555555555555556,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,0.8888888888888888,Expand internal and external links to allow image selection,"I need to extend selection of external and Internal Link and provide a image selection.

Please see the snapshot in the below :


Here the above snapshot allows you to add properties for External Link.In the same popup can we add a field Called Image(as shown in screenshot) which will allow user to select images from the media library??

Thanks,
Suhas
","If you are talking about a whole field and not just an external link inside of a rich text field, you should create a custom field based on the documentation to do so in SDN:

http://sdn.sitecore.net/Articles/API/Creating%20a%20Composite%20Custom%20Field.aspx

You can inherit most functionality from the current link field.
"
2677,2677,4268,What is Cold Iron actually?,"It came up in Dresden Files, but is not limited to that game, you can find the term in DnD as well. I would like to know what it means. 

If you look for Cold Iron on Wikipedia, you only get iron: 
""Cold iron is a poetic and archaic term for iron.""
This would imply everything made mostly from Fe is cold iron. Clearly, this is not the case, in every game Cold Iron is something special, the every day sword is not made out of it. 

The Dresden Files rulebook is not very specific about it:


  something that anyone could reasonably get access to, but usually doesn’t carry on them (like cold iron) page 185.


What is cold iron?
How do I create cold iron?
How do I get cold iron?   

To make the question easier to understand, compare Cold Iron to Holy Water. You know how it is different from usual Water, you know how you get it or create it. 
",András,https://rpg.stackexchange.com/users/9552,"In some treatments, Cold Iron is iron that has never been worked with fire; this means that it has either been magically extracted or that it's meteoric iron. A few take it to mean Iron that's poured - IE, cast iron. (Cast iron as a weapon is generally poor.)

In traditional folklore, it's just iron, or iron that isn't still hot from the forge. 

Note that iron weapons (as opposed to steel) are more brittle.

In most systems, it excludes steel - not in the Dresden Files setting, as is evidenced in Storm Knight (with the pixies), as the common box cutter blade is usually cheap steel.
",aramis,https://rpg.stackexchange.com/users/407,http://rpg.stackexchange.com/questions/40826/what-is-cold-iron-actually,CULTURE,rpg.stackexchange.com,1.0,0.6666666666666666,0.0,0.6666666666666666,1.0,1.0,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.0,0.7777777777777778,1.0,0.4444444444444444,1.0,1.0,0.6666666666666667,0.0,0.0,0.3333333333333333,0.8888888888888888,What is cold iron?,"It came up in Dresden Files, but is not limited to that game, you can find the term in DnD as well. I would like to know what it means. 

If you look for Cold Iron on Wikipedia, you only get iron: 
""Cold iron is a poetic and archaic term for iron.""
This would imply everything made mostly from Fe is cold iron. Clearly, this is not the case, in every game Cold Iron is something special, the every day sword is not made out of it. 

The Dresden Files rulebook is not very specific about it:


  something that anyone could reasonably get access to, but usually doesn’t carry on them (like cold iron) page 185.


What is cold iron?
How do I create cold iron?
How do I get cold iron?   

To make the question easier to understand, compare Cold Iron to Holy Water. You know how it is different from usual Water, you know how you get it or create it. 
","In some treatments, Cold Iron is iron that has never been worked with fire; this means that it has either been magically extracted or that it's meteoric iron. A few take it to mean Iron that's poured - IE, cast iron. (Cast iron as a weapon is generally poor.)

In traditional folklore, it's just iron, or iron that isn't still hot from the forge. 

Note that iron weapons (as opposed to steel) are more brittle.

In most systems, it excludes steel - not in the Dresden Files setting, as is evidenced in Storm Knight (with the pixies), as the common box cutter blade is usually cheap steel.
"
211,211,337,What exactly is computation?,"I know what computation is in some vague sense (it is the thing computers do), but I would like a more rigorous definition. 

Dictionary.com's definitions of computation, computing, calculate, and compute are circular, so it doesn't help. 

Wikipedia defines computation to be ""any type of calculation that follows a well-defined model."" 
It defines calculation as ""the deliberate process that transforms one or more inputs into one or more results, with variable change."" But it seems this definition includes many actions as computations even though they aren't typically thought of as computation. 

For example, wouldn't this entail that, say, a bomb exploding is a computation, with the input being the fuse being lighted and the output being the explosion?

So, what exactly is computation?
",Kelmikra,https://cs.stackexchange.com/users/24518,"This is the question that Turing set out to solve in his famous 1936 paper, On computable numbers, with an application to the Entscheidungsproblem, a paper in which he comes up with (what came to be known as) the Turing machine model. See in particular Section 9.

Turing's work is in the context of computable numbers. There are other notions of computation appropriate for computing other kinds of structures, and their study forms part of computation theory (also known as recursion theory).

The main difference between the common notion of computation and your example (an exploding bomb) is the thing being computed. What is being computed by your exploding bomb? Another difference is the computational means, but one can envision a mechanical contraption which uses bombs to compute something more legitimate.

Another point is whether the classical notions of computation apply to what we perceive today as computation – namely, two-way interaction between the computer and the user. This is a common criticism levelled against the classical notional of computability, though interaction can be modelled using the tools of computation theory (it's just not what you learn in class).
",Yuval Filmus,https://cs.stackexchange.com/users/683,http://cs.stackexchange.com/questions/43938/what-exactly-is-computation,SCIENCE,cs.stackexchange.com,1.0,0.7777777777777778,0.0,0.6666666666666666,1.0,0.6666666666666666,0.7777777777777778,0.8888888888888888,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.0,0.6666666666666666,1.0,What is computation?,"I know what computation is in some vague sense (it is the thing computers do), but I would like a more rigorous definition. 

Dictionary.com's definitions of computation, computing, calculate, and compute are circular, so it doesn't help. 

Wikipedia defines computation to be ""any type of calculation that follows a well-defined model."" 
It defines calculation as ""the deliberate process that transforms one or more inputs into one or more results, with variable change."" But it seems this definition includes many actions as computations even though they aren't typically thought of as computation. 

For example, wouldn't this entail that, say, a bomb exploding is a computation, with the input being the fuse being lighted and the output being the explosion?

So, what exactly is computation?
","This is the question that Turing set out to solve in his famous 1936 paper, On computable numbers, with an application to the Entscheidungsproblem, a paper in which he comes up with (what came to be known as) the Turing machine model. See in particular Section 9.

Turing's work is in the context of computable numbers. There are other notions of computation appropriate for computing other kinds of structures, and their study forms part of computation theory (also known as recursion theory).

The main difference between the common notion of computation and your example (an exploding bomb) is the thing being computed. What is being computed by your exploding bomb? Another difference is the computational means, but one can envision a mechanical contraption which uses bombs to compute something more legitimate.

Another point is whether the classical notions of computation apply to what we perceive today as computation – namely, two-way interaction between the computer and the user. This is a common criticism levelled against the classical notional of computability, though interaction can be modelled using the tools of computation theory (it's just not what you learn in class).
"
5282,5282,8390,Is it ok to use self-signed certificates for smtp transport?,"By ""by ok to use"" I mean:


are MTA agents receiving emails from my server going to reject my
email
if not, are they going to make other kind of bad treatment for my
emails (marking as spam, unsafe and so...)?


...or is it just better idea to stick with non-encrypted emails?
",Miloš Đakonović,https://serverfault.com/users/178855,"I ran an MTA with a self-signed certificate for a couple of years, until real ones got cheap enough that I could no longer be bothered to do so, and I didn't have a single rejection because of the unsigned certificate in all that time.  I never had a single complaint about a mail being marked as spam because of it, either; if anything, using TLS often seems to mark you out as a non-spamming professional.

In my opinion, it is definitely worth enabling SMTP TLS if you can, whether or not you pay for a third-party-signed certificate.

Edit in response to your comment: It's not that someone couldn't choose to restrict inbound mail on that basis; I've never come across it, is all. A third-party-signed certificate is still useful to prove there is no man-in-the-middle attack happening; but that doesn't seem to be a serious problem in the MTA world at this time. If that starts to change, we could well find that people start to insist on signed certificates.

Security exists to address threats, so if the threat model changes, the range of sane and proportionate security responses will change with it.
",MadHatter,https://serverfault.com/users/55514,http://serverfault.com/questions/579138,TECHNOLOGY,serverfault.com,0.8888888888888888,0.7777777777777778,0.0,0.6666666666666666,1.0,1.0,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,0.8888888888888888,0.9333333333333332,0.0,0.3333333333333333,1.0,0.8888888888888888,Can I use a self signed certificate for SMTP transmission?,"By ""by ok to use"" I mean:


are MTA agents receiving emails from my server going to reject my
email
if not, are they going to make other kind of bad treatment for my
emails (marking as spam, unsafe and so...)?


...or is it just better idea to stick with non-encrypted emails?
","I ran an MTA with a self-signed certificate for a couple of years, until real ones got cheap enough that I could no longer be bothered to do so, and I didn't have a single rejection because of the unsigned certificate in all that time.  I never had a single complaint about a mail being marked as spam because of it, either; if anything, using TLS often seems to mark you out as a non-spamming professional.

In my opinion, it is definitely worth enabling SMTP TLS if you can, whether or not you pay for a third-party-signed certificate.

Edit in response to your comment: It's not that someone couldn't choose to restrict inbound mail on that basis; I've never come across it, is all. A third-party-signed certificate is still useful to prove there is no man-in-the-middle attack happening; but that doesn't seem to be a serious problem in the MTA world at this time. If that starts to change, we could well find that people start to insist on signed certificates.

Security exists to address threats, so if the threat model changes, the range of sane and proportionate security responses will change with it.
"
1181,1181,1856,How to install the gedit markdown-preview plugin on 14.04?,"I've just installed the markdown preview plugin for gedit and I get the following error on the console when I try to activate it in the plugins tab:


  Traceback (most recent call last):   File
  ""/home/aarold/.local/share/gedit/plugins/markdown-preview/init.py"",
  line 25, in 
      import markdown ImportError: No module named 'markdown'
  
  (gedit:20735): libpeas-WARNING **: Error loading plugin
  'markdown-preview


Note that this is not the same question as the other one about gedit since its solution does not work for me.

I've tried setting the Loader parameter in my /home/aarold/.local/share/gedit/plugins/markdown-preview.plugin file to python and python3 as well but none of them work. I tried reinstalling the plugin with all possible permutations of options and although it says install was succesful I always get this error. What could be the problem?

I've checked the .py file and it seems that it cannot

import markdown.

Do I need to install some additional python modules?

I've tried

pip install markdown


but although it 


  Successfully installed markdown


I still get the same error.
",Adam Arold,https://askubuntu.com/users/74752,"This plugin is written for Python 2, but since gedit 3.8, only Python 3 plugins are supported. So some small changes are required.


Modify the installer (gedit-markdown.sh) to install the python3 markdown module:

This is a patch that you can apply on the existing file (or you can just copy the full modified version available here):

--- gedit-markdown_ori.sh   2014-05-14 16:14:58.386700310 +0200
+++ gedit-markdown.sh   2014-05-14 15:42:21.038783248 +0200
@@ -263,7 +263,9 @@

 # Note: sous Archlinux, «/usr/bin/python» correspond à Python 3. On teste donc les
 # chemins pour Python 2 en premier.
-if type -p python2.7 &gt; /dev/null; then
+if type -p python3 &gt; /dev/null; then
+   binPython=$(type -p python3)
+elif type -p python2.7 &gt; /dev/null; then
    binPython=$(type -p python2.7)
 elif type -p python2.6 &gt; /dev/null; then
    binPython=$(type -p python2.6)
@@ -287,15 +289,15 @@
            cheminPythonMarkdown=python-markdown/python2
            cheminPythonSitePackages=$(""$binPython"" -m site --user-site)
        fi
-#  elif [[ ${versionPython:0:1} == 3 ]]; then
-#      compareVersions ""$versionPython"" ""3.1""
-#      
-#      if [[ $? == 2 ]]; then
-#          bonneVersionPython=false
-#      else
-#          cheminPythonMarkdown=python-markdown/python3
-#          cheminPythonSitePackages=$(""$binPython"" -m site --user-site)
-#      fi
+   elif [[ ${versionPython:0:1} == 3 ]]; then
+       compareVersions ""$versionPython"" ""3.1""
+       
+       if [[ $? == 2 ]]; then
+           bonneVersionPython=false
+       else
+           cheminPythonMarkdown=python-markdown/python3
+           cheminPythonSitePackages=$(""$binPython"" -m site --user-site)
+       fi
    else
        bonneVersionPython=false
    fi

Run ./gedit-markdown.sh install

You should see python 3.4 instead of 2.7:

############################################################
##
## Installation of gedit-markdown
##
############################################################

## First step: check dependencies

- gedit: 3.10.4
- Python: 3.4

[...]

Change the plugin loader to python3

Replace /home/aarold/.local/share/gedit/plugins/markdown-preview.plugin with:

[Plugin]
Loader=python3
Module=markdown-preview
IAge=3
Name=Markdown Preview
Name[fr]=Aperçu Markdown
Description=Show the HTML version of the Markdown text you're editing
Description[fr]=Affiche l'aperçu en HTML du document Markdown en cours d'édition
Authors=Michele Campeotto &lt;micampe@micampe.it&gt;\nJean-Philippe Fleury &lt;contact@jpfleury.net&gt;
Copyright=Copyright © 2005, 2006 Michele Campeotto\nCopyright © 2009, 2011-2012 Jean-Philippe Fleury
Website=http://www.jpfleury.net/logiciels/gedit-markdown.php

Convert /home/aarold/.local/share/gedit/plugins/markdown-preview/__init__.py to python3:

Run:

2to3 -w /home/aarold/.local/share/gedit/plugins/markdown-preview/__init__.py


Finally open this file and edit line 86 (remove the binary mode, ""wb"" -> ""w""):

with open(confFile, ""w"") as confFile:

Activate the plugin in Gedit as you did.

",Sylvain Pineau,https://askubuntu.com/users/32239,http://askubuntu.com/questions/465763/how-to-install-the-gedit-markdown-preview-plugin-on-14-04,TECHNOLOGY,askubuntu.com,0.6666666666666666,0.5555555555555556,0.0,0.0,1.0,1.0,0.5555555555555556,0.4444444444444444,0.6666666666666666,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.9333333333333332,0.6666666666666666,0.3333333333333333,0.6666666666666666,1.0,How do I install the GEDIT tag preview plug-in on 14.04?,"I've just installed the markdown preview plugin for gedit and I get the following error on the console when I try to activate it in the plugins tab:


  Traceback (most recent call last):   File
  ""/home/aarold/.local/share/gedit/plugins/markdown-preview/init.py"",
  line 25, in 
      import markdown ImportError: No module named 'markdown'
  
  (gedit:20735): libpeas-WARNING **: Error loading plugin
  'markdown-preview


Note that this is not the same question as the other one about gedit since its solution does not work for me.

I've tried setting the Loader parameter in my /home/aarold/.local/share/gedit/plugins/markdown-preview.plugin file to python and python3 as well but none of them work. I tried reinstalling the plugin with all possible permutations of options and although it says install was succesful I always get this error. What could be the problem?

I've checked the .py file and it seems that it cannot

import markdown.

Do I need to install some additional python modules?

I've tried

pip install markdown


but although it 


  Successfully installed markdown


I still get the same error.
","This plugin is written for Python 2, but since gedit 3.8, only Python 3 plugins are supported. So some small changes are required.


Modify the installer (gedit-markdown.sh) to install the python3 markdown module:

This is a patch that you can apply on the existing file (or you can just copy the full modified version available here):

--- gedit-markdown_ori.sh   2014-05-14 16:14:58.386700310 +0200
+++ gedit-markdown.sh   2014-05-14 15:42:21.038783248 +0200
@@ -263,7 +263,9 @@

 # Note: sous Archlinux, «/usr/bin/python» correspond à Python 3. On teste donc les
 # chemins pour Python 2 en premier.
-if type -p python2.7 &gt; /dev/null; then
+if type -p python3 &gt; /dev/null; then
+   binPython=$(type -p python3)
+elif type -p python2.7 &gt; /dev/null; then
    binPython=$(type -p python2.7)
 elif type -p python2.6 &gt; /dev/null; then
    binPython=$(type -p python2.6)
@@ -287,15 +289,15 @@
            cheminPythonMarkdown=python-markdown/python2
            cheminPythonSitePackages=$(""$binPython"" -m site --user-site)
        fi
-#  elif [[ ${versionPython:0:1} == 3 ]]; then
-#      compareVersions ""$versionPython"" ""3.1""
-#      
-#      if [[ $? == 2 ]]; then
-#          bonneVersionPython=false
-#      else
-#          cheminPythonMarkdown=python-markdown/python3
-#          cheminPythonSitePackages=$(""$binPython"" -m site --user-site)
-#      fi
+   elif [[ ${versionPython:0:1} == 3 ]]; then
+       compareVersions ""$versionPython"" ""3.1""
+       
+       if [[ $? == 2 ]]; then
+           bonneVersionPython=false
+       else
+           cheminPythonMarkdown=python-markdown/python3
+           cheminPythonSitePackages=$(""$binPython"" -m site --user-site)
+       fi
    else
        bonneVersionPython=false
    fi

Run ./gedit-markdown.sh install

You should see python 3.4 instead of 2.7:

############################################################
##
## Installation of gedit-markdown
##
############################################################

## First step: check dependencies

- gedit: 3.10.4
- Python: 3.4

[...]

Change the plugin loader to python3

Replace /home/aarold/.local/share/gedit/plugins/markdown-preview.plugin with:

[Plugin]
Loader=python3
Module=markdown-preview
IAge=3
Name=Markdown Preview
Name[fr]=Aperçu Markdown
Description=Show the HTML version of the Markdown text you're editing
Description[fr]=Affiche l'aperçu en HTML du document Markdown en cours d'édition
Authors=Michele Campeotto &lt;micampe@micampe.it&gt;\nJean-Philippe Fleury &lt;contact@jpfleury.net&gt;
Copyright=Copyright © 2005, 2006 Michele Campeotto\nCopyright © 2009, 2011-2012 Jean-Philippe Fleury
Website=http://www.jpfleury.net/logiciels/gedit-markdown.php

Convert /home/aarold/.local/share/gedit/plugins/markdown-preview/__init__.py to python3:

Run:

2to3 -w /home/aarold/.local/share/gedit/plugins/markdown-preview/__init__.py


Finally open this file and edit line 86 (remove the binary mode, ""wb"" -> ""w""):

with open(confFile, ""w"") as confFile:

Activate the plugin in Gedit as you did.

"
1619,1619,2539,How is encapsulation used for safety?,"I am learning OOP. I have studied much about encapsulation but the more I read the more I became confused.

I understand we hide (by making private) data and expose it to user of class (other developers) as properties or methods. I also understand by encapsulation we hide details.

In an article (http://www.csharp-station.com/Tutorial/CSharp/lesson19) I read:

Abstract from article

When designing an object, you must think about how others could use it. In a best-case scenario any program using the object would be well designed and the code would never change. However, the reality is that programs do change often and in a team environment many people touch the same code at one time or another. Therefore, it is beneficial to consider what could go wrong as well as the pristine image of how the object should be used.

In the case of the BankAccount object, examine the situation where code outside of your object could access a decimal Amount field or a string CustomerName field. At the point of time that the code is written, everything would work well. However, later in the development cycle, you realize that the BankAccount object should keep track of an int CustomerID rather than string CustomerName because you don't want to duplicate relationships between information (or some other valid reason to alter the definition of internal state). Such changes cause a rippling effect in your code because it was built to use the BankAccount class, as originally designed (with CustomerName being a string), and you must now change code that accesses that state throughout your entire application.

The object-oriented principle of Encapsulation helps avoid such problems, allowing you to hide internal state and abstract access to it though type members such as methods, properties, and indexers. Encapsulation helps you reduce coupling between objects and increases the maintainability of your code. 

Question
How will encapsulation help when making changes in code and from its rippling effects.
For a data member, if I change its type from int to float, (even if I am exposing this using property) I will need to change variable type where I am using already using this code.

Kindly guide me how encapsulation will help with such changes.

Thanks for this help and guidance.
",haansi,https://programmers.stackexchange.com/users/54357,"In my experience, encapsulation makes doing the ""wrong"" thing much more difficult. You can group together functionality which semantically go together and isolate them from functionality which can lead to bad or unpredictable behavior. It can also help hide the details from the end user which may help increase safety and reliability. 

Consider this post by John D Cook. Consider that you have a Bread object. One natural thing to slice this bread. So you write a slice() function, so you can do 


slice(loaf)


with a new loaf object you've created. This makes sense. But if you're not careful, you might accidentally call


slice(finger)


with a finger object somewhere in your project. This could lead to very bad things. Instead, encapsulate this function/method into a Bread class so you can do this


loaf.slice()


This definitely  helps avoid calling finger.slice() accidentally, since finger probably doesn't have a slice() method associated with it. 

This is a bit of a contrived example but I've found it helpful. Encapsulation is can sometimes be an underrated aspect of OOP, but it's a good one.
",joshin4colours,https://programmers.stackexchange.com/users/36853,http://programmers.stackexchange.com/questions/149041/how-is-encapsulation-used-for-safety,TECHNOLOGY,programmers.stackexchange.com,0.8333333333333334,0.5,0.0,0.0,1.0,1.0,0.5,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,1.0,0.0,0.8333333333333334,0.8333333333333334,0.6666666666666666,0.8333333333333334,0.8333333333333334,0.8,0.0,0.0,1.0,0.6666666666666666,How to use encapsulation to ensure safety?,"I am learning OOP. I have studied much about encapsulation but the more I read the more I became confused.

I understand we hide (by making private) data and expose it to user of class (other developers) as properties or methods. I also understand by encapsulation we hide details.

In an article (http://www.csharp-station.com/Tutorial/CSharp/lesson19) I read:

Abstract from article

When designing an object, you must think about how others could use it. In a best-case scenario any program using the object would be well designed and the code would never change. However, the reality is that programs do change often and in a team environment many people touch the same code at one time or another. Therefore, it is beneficial to consider what could go wrong as well as the pristine image of how the object should be used.

In the case of the BankAccount object, examine the situation where code outside of your object could access a decimal Amount field or a string CustomerName field. At the point of time that the code is written, everything would work well. However, later in the development cycle, you realize that the BankAccount object should keep track of an int CustomerID rather than string CustomerName because you don't want to duplicate relationships between information (or some other valid reason to alter the definition of internal state). Such changes cause a rippling effect in your code because it was built to use the BankAccount class, as originally designed (with CustomerName being a string), and you must now change code that accesses that state throughout your entire application.

The object-oriented principle of Encapsulation helps avoid such problems, allowing you to hide internal state and abstract access to it though type members such as methods, properties, and indexers. Encapsulation helps you reduce coupling between objects and increases the maintainability of your code. 

Question
How will encapsulation help when making changes in code and from its rippling effects.
For a data member, if I change its type from int to float, (even if I am exposing this using property) I will need to change variable type where I am using already using this code.

Kindly guide me how encapsulation will help with such changes.

Thanks for this help and guidance.
","In my experience, encapsulation makes doing the ""wrong"" thing much more difficult. You can group together functionality which semantically go together and isolate them from functionality which can lead to bad or unpredictable behavior. It can also help hide the details from the end user which may help increase safety and reliability. 

Consider this post by John D Cook. Consider that you have a Bread object. One natural thing to slice this bread. So you write a slice() function, so you can do 


slice(loaf)


with a new loaf object you've created. This makes sense. But if you're not careful, you might accidentally call


slice(finger)


with a finger object somewhere in your project. This could lead to very bad things. Instead, encapsulate this function/method into a Bread class so you can do this


loaf.slice()


This definitely  helps avoid calling finger.slice() accidentally, since finger probably doesn't have a slice() method associated with it. 

This is a bit of a contrived example but I've found it helpful. Encapsulation is can sometimes be an underrated aspect of OOP, but it's a good one.
"
5854,5854,9273,glsl demo suggestions?,"In a lot of places I interviewed recently, I have been asked many a times if I have worked with shaders. Even though, I have read and understand the pipeline, the answer to that question has been no. Recently, one of the places asked me if I can send them a sample of 'something' that is ""visually polished"".

So, I decided to take the plunge and wrote some simple shader in GLSL(with opengl).I now have a basic setup where I can use vbos with glsl shaders.

I have a very short window left to send something to them and I was wondering if someone  with experience, could suggest an idea that is interesting enough to grab someone's attention.

Thanks
",brainydexter,https://gamedev.stackexchange.com/users/4638,"Everybody saw phong implemented. So how about:


water - there are tons of tutorials and it looks always great
shadow mapping - absolute basic in game dev. Multipass rendering is good thing to show. You can improve it with some kind of soft shadows (i highly recommend PCSS - easy effective or Variance Shadow Maps) 
bumpmapping 
parallax mapping - looks cool, and pretty easy if you got bump mapping done.
geometry shaders (if you do hairs/fur over the polygon - could be based on lines or billboards - they will love you :)) - whitepaper from nvidia
mirrors
post process - cartoon shader, old camera shader

",Notabene,https://gamedev.stackexchange.com/users/3794,http://gamedev.stackexchange.com/questions/8654/glsl-demo-suggestions,TECHNOLOGY,gamedev.stackexchange.com,0.8888888888888888,0.5555555555555556,0.3333333333333333,0.0,0.0,0.0,0.5555555555555556,0.4444444444444444,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.8666666666666666,0.0,0.3333333333333333,0.0,0.7777777777777778,Glsl presentation suggestions?,"In a lot of places I interviewed recently, I have been asked many a times if I have worked with shaders. Even though, I have read and understand the pipeline, the answer to that question has been no. Recently, one of the places asked me if I can send them a sample of 'something' that is ""visually polished"".

So, I decided to take the plunge and wrote some simple shader in GLSL(with opengl).I now have a basic setup where I can use vbos with glsl shaders.

I have a very short window left to send something to them and I was wondering if someone  with experience, could suggest an idea that is interesting enough to grab someone's attention.

Thanks
","Everybody saw phong implemented. So how about:


water - there are tons of tutorials and it looks always great
shadow mapping - absolute basic in game dev. Multipass rendering is good thing to show. You can improve it with some kind of soft shadows (i highly recommend PCSS - easy effective or Variance Shadow Maps) 
bumpmapping 
parallax mapping - looks cool, and pretty easy if you got bump mapping done.
geometry shaders (if you do hairs/fur over the polygon - could be based on lines or billboards - they will love you :)) - whitepaper from nvidia
mirrors
post process - cartoon shader, old camera shader

"
5579,5579,8859,Crosstalk vs interference,"I don't even clear about the differences between crosstalk and interference. Could you explain me please?

I just know that cross talk is the leakage power from other sources, whereas interference is the aliasing signal.

Could you tell me any other differences?
",Ny sokunthea,https://electronics.stackexchange.com/users/59555,"Wikipedia gives a reasonable summary of the types of interference, of which crosstalk is one:

http://en.wikipedia.org/wiki/Interference_%28communication%29
",John U,https://electronics.stackexchange.com/users/17077,http://electronics.stackexchange.com/questions/141271/crosstalk-vs-interference,SCIENCE,electronics.stackexchange.com,1.0,1.0,0.0,0.6666666666666666,1.0,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.0,0.0,0.6666666666666666,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5555555555555556,0.8888888888888888,0.4444444444444444,1.0,1.0,0.5333333333333333,0.3333333333333333,0.0,0.0,1.0,Crosstalk and interference,"I don't even clear about the differences between crosstalk and interference. Could you explain me please?

I just know that cross talk is the leakage power from other sources, whereas interference is the aliasing signal.

Could you tell me any other differences?
","Wikipedia gives a reasonable summary of the types of interference, in which crosstalk is a:"
6077,6077,9646,When should a supervisor be a co-author?,"What are people's views on this?  To be specific: suppose a PhD student has produced a piece of original mathematical research. Suppose that student's supervisor suggested the problem, and gave a few helpful comments, but otherwise did not contribute to the work.  Should that supervisor still be named as a co-author, or would an acknowledgment suffice?

I am interested in two aspects of this. Firstly the moral/etiquette aspect: do you consider it bad form for a student not to name their supervisor?  Or does it depend on that supervisor's input?  And secondly, the practical, career-advancing aspect: which is better, for a student to have a well-known name on his or her paper (and hence more chance of it being noticed/published), or to have a sole-authored piece of work under their belt to hopefully increase their chances of being offered a good post-doc position?

[To clarify: original question asked by MrB ]
",MrB,https://mathoverflow.net/users/2189,"As a non-mathematician, I am somewhat mystified by the prevailing norms of the mathematics community as I understand them from this thread. Correct me if I'm wrong, but it sounds like: 


Supervisors make important intellectual contributions to the thesis work of their students. 
Typically, the name of the supervisor does not appear on the work. 


For example, the most upvoted comment at the moment says ""as a rule the supervisor should not be a co-author in the main paper taken from a student's thesis, even if he has contributed substantially to it."" (emphasis is mine) Other comments echo the sentiment. 

This seems problematic, both morally and practically. In other scientific communities, the author list is supposed to reflect the people who contributed intellectually to the paper. Manipulating it is an ethical offense. For example, the practices described in this thread appear to violate IEEE policies on authorship which state (Section 8.2.1)


  Authorship and co-authorship should be
  based on a substantial  intellectual
  contribution ... the
  list of authors on an article serves
  multiple purposes; it  indicates who
  is responsible for the work and to
  whom questions  regarding the work
  should be addressed.


Finally, I would just like to add that as a student, I would feel horrible submitting a paper authored only by me if the paper was based in large part on the insights of someone else.  
",angela,https://mathoverflow.net/users/4267,http://mathoverflow.net/questions/57337,SCIENCE,mathoverflow.net,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.0,0.7777777777777778,0.5555555555555556,1.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,1.0,0.8888888888888888,0.5555555555555556,1.0,1.0,0.5333333333333333,0.0,0.3333333333333333,0.6666666666666666,1.0,When should a supervisor become a coauthor?,"What are people's views on this?  To be specific: suppose a PhD student has produced a piece of original mathematical research. Suppose that student's supervisor suggested the problem, and gave a few helpful comments, but otherwise did not contribute to the work.  Should that supervisor still be named as a co-author, or would an acknowledgment suffice?

I am interested in two aspects of this. Firstly the moral/etiquette aspect: do you consider it bad form for a student not to name their supervisor?  Or does it depend on that supervisor's input?  And secondly, the practical, career-advancing aspect: which is better, for a student to have a well-known name on his or her paper (and hence more chance of it being noticed/published), or to have a sole-authored piece of work under their belt to hopefully increase their chances of being offered a good post-doc position?

[To clarify: original question asked by MrB ]
","As a non-mathematician, I am somewhat mystified by the prevailing norms of the mathematics community as I understand them from this thread. Correct me if I'm wrong, but it sounds like: 


Supervisors make important intellectual contributions to the thesis work of their students. 
Typically, the name of the supervisor does not appear on the work. 


For example, the most upvoted comment at the moment says ""as a rule the supervisor should not be a co-author in the main paper taken from a student's thesis, even if he has contributed substantially to it."" (emphasis is mine) Other comments echo the sentiment. 

This seems problematic, both morally and practically. In other scientific communities, the author list is supposed to reflect the people who contributed intellectually to the paper. Manipulating it is an ethical offense. For example, the practices described in this thread appear to violate IEEE policies on authorship which state (Section 8.2.1)


  Authorship and co-authorship should be
  based on a substantial  intellectual
  contribution ... the
  list of authors on an article serves
  multiple purposes; it  indicates who
  is responsible for the work and to
  whom questions  regarding the work
  should be addressed.


Finally, I would just like to add that as a student, I would feel horrible submitting a paper authored only by me if the paper was based in large part on the insights of someone else.  
"
3128,3128,4981,"How to construct a closed, filled, path made of semi-circles and attach annotations to it with TikZ?","I have very limited LaTeX knowledge. I am trying to plot the following figure using ""tikz"" and I appreciate if anyone can help me to finish plotting my figure. I did the following so far:

\documentclass{article}
\usepackage{tikz}
\begin{document}

\begin{tikzpicture}

\draw (0,0) arc (0:180:6);
\draw   (-12,0)  - -(0,0);
\draw (-8,0) arc (0:180:2);
\draw (0,0) arc (0:180:4);
\draw (-6,-0.1) - - (-6,0.1);

\end{tikzpicture}

\end{document}


There is a BIG semi-circle and two inner SMALL semi-circles. I want to label the right endpoint of the BIG semi-circle by ""A"" and  the left endpoint of the BIG semi-circle by ""B"". I want to label the center of the BIG semi-circle by ""O"", and I want to label the point where the two SMALL semicircles meet by ""P"". I also want to shade the area inside the BIG semi-circle and outside the two SMALL semi-circles. I also want to mention on the figure that the radius of the big circle is: 6. and the distance between the point ""O"" and the point ""P"" is ""x""

Any help is much appreciated
",Pat_Ho,https://tex.stackexchange.com/users/60077,"Here is a quick attempt:

\documentclass{article}
\usepackage{tikz}

\begin{document}

\begin{tikzpicture}
  \draw[fill=blue] (0,0)node[below]{$A$} arc (0:180:6) node[below]{$B$};
  \draw (-12,0) - -(0,0);
  \draw[fill=white] (-8,0) arc (0:180:2);
  \draw[fill=white] (0,0) arc (0:180:4)node[below]{$P$};
  \draw (-6,-0.1) -- node[below]{$O$} (-6,0.1);
  \draw[&lt;-&gt;](-8,-0.6)--node[below]{$x$}(-6,-0.6);
  \draw[&lt;-&gt;](-6,-0.6)--node[below]{$6$}(0,-0.6);
\end{tikzpicture}

\end{document}


This produces:



Note that colouring/filling is cumulative: you can fill one region with a colour and then fill another overlapping region with a different colour, or white to remove the colour. The last colour in any given region wins.
",Andrew,https://tex.stackexchange.com/users/30471,http://tex.stackexchange.com/questions/194381/how-to-construct-a-closed-filled-path-made-of-semi-circles-and-attach-annotati,TECHNOLOGY,tex.stackexchange.com,0.7777777777777778,0.4444444444444444,0.0,0.0,1.0,1.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,1.0,"How to construct a closed, filled, semi-circular path and attach annotations to the path with tikz?","I have very limited LaTeX knowledge. I am trying to plot the following figure using ""tikz"" and I appreciate if anyone can help me to finish plotting my figure. I did the following so far:

\documentclass{article}
\usepackage{tikz}
\begin{document}

\begin{tikzpicture}

\draw (0,0) arc (0:180:6);
\draw   (-12,0)  - -(0,0);
\draw (-8,0) arc (0:180:2);
\draw (0,0) arc (0:180:4);
\draw (-6,-0.1) - - (-6,0.1);

\end{tikzpicture}

\end{document}


There is a BIG semi-circle and two inner SMALL semi-circles. I want to label the right endpoint of the BIG semi-circle by ""A"" and  the left endpoint of the BIG semi-circle by ""B"". I want to label the center of the BIG semi-circle by ""O"", and I want to label the point where the two SMALL semicircles meet by ""P"". I also want to shade the area inside the BIG semi-circle and outside the two SMALL semi-circles. I also want to mention on the figure that the radius of the big circle is: 6. and the distance between the point ""O"" and the point ""P"" is ""x""

Any help is much appreciated
","Here is a quick attempt:

\documentclass{article}
\usepackage{tikz}

\begin{document}

\begin{tikzpicture}
  \draw[fill=blue] (0,0)node[below]{$A$} arc (0:180:6) node[below]{$B$};
  \draw (-12,0) - -(0,0);
  \draw[fill=white] (-8,0) arc (0:180:2);
  \draw[fill=white] (0,0) arc (0:180:4)node[below]{$P$};
  \draw (-6,-0.1) -- node[below]{$O$} (-6,0.1);
  \draw[&lt;-&gt;](-8,-0.6)--node[below]{$x$}(-6,-0.6);
  \draw[&lt;-&gt;](-6,-0.6)--node[below]{$6$}(0,-0.6);
\end{tikzpicture}

\end{document}


This produces:



Note that colouring/filling is cumulative: you can fill one region with a colour and then fill another overlapping region with a different colour, or white to remove the colour. The last colour in any given region wins.
"
5832,5832,9244,Verifying the integrity of ciphertext using the cleartext hash?,"I want to be able to verify the integrity of a ciphertext by providing the cleartext hash, for this to work it would need to:

$$hash(crypt(cleartext)) = f(hash(cleartext))$$

Where $f$ is an arbitrary function mapping the cleartext hash to the ciphertext hash.

Is there such a pair?

Update: I'm trying to prove the integrity to the receiver while delaying the key exchange until I'm ready to commit (send him the decryption details). The hash that proves the integrity comes from another source entirely.
",cdecker,https://crypto.stackexchange.com/users/1274,"There really isn't such a function $f$; encryption algorithms attempt to generate what looks like random bitstrings (at least, it looks that way to anyone who doesn't know the key), and because the plaintexts and the ciphertexts look unrelated, their hashes are also going to look unrelated.

On the other hand, what is the problem you're trying to solve?  When you say 'verify the integrity of a ciphertext', who is doing the verification?


Are you trying to allow the decryptor to verify that the message he got was the message that the encryptor sent without someone modifying it in the middle?  If that's the case, the standard way of addressing it is with a Message Authentication Code
Are you attempting to allow the encryptor to verify that the encryption process proceeded properly?  About the only ways to do that are to either run the encryption process again (with the same IV) and compare, or attempt to decrypt the ciphertext and compare.
Are you trying to allow someone in the middle (without the keys) to verify that a specific ciphertext happens to be a specific plaintext?  Well, that would be an unusual requirement; I don't have any bright ideas on that one.

",poncho,https://crypto.stackexchange.com/users/452,http://crypto.stackexchange.com/questions/1510/verifying-the-integrity-of-ciphertext-using-the-cleartext-hash,TECHNOLOGY,crypto.stackexchange.com,1.0,0.5555555555555556,0.0,1.0,1.0,1.0,0.5555555555555556,0.5555555555555556,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8,0.0,0.6666666666666666,0.3333333333333333,0.8888888888888888,Use clear text hash to verify the integrity of ciphertext?,"I want to be able to verify the integrity of a ciphertext by providing the cleartext hash, for this to work it would need to:

$$hash(crypt(cleartext)) = f(hash(cleartext))$$

Where $f$ is an arbitrary function mapping the cleartext hash to the ciphertext hash.

Is there such a pair?

Update: I'm trying to prove the integrity to the receiver while delaying the key exchange until I'm ready to commit (send him the decryption details). The hash that proves the integrity comes from another source entirely.
","There really isn't such a function $f$; encryption algorithms attempt to generate what looks like random bitstrings (at least, it looks that way to anyone who doesn't know the key), and because the plaintexts and the ciphertexts look unrelated, their hashes are also going to look unrelated.

On the other hand, what is the problem you're trying to solve?  When you say 'verify the integrity of a ciphertext', who is doing the verification?


Are you trying to allow the decryptor to verify that the message he got was the message that the encryptor sent without someone modifying it in the middle?  If that's the case, the standard way of addressing it is with a Message Authentication Code
Are you attempting to allow the encryptor to verify that the encryption process proceeded properly?  About the only ways to do that are to either run the encryption process again (with the same IV) and compare, or attempt to decrypt the ciphertext and compare.
Are you trying to allow someone in the middle (without the keys) to verify that a specific ciphertext happens to be a specific plaintext?  Well, that would be an unusual requirement; I don't have any bright ideas on that one.

"
3936,3936,6279,custom email unable to send magento,"I get the following error:
""exception 'exception' with message 'this letter cannot be sent.' magento"" , in magento php.
below is the code i have used.

Observer.php

&lt;?php
class Metro_Purchaseorder_Model_Observer extends Mage_Core_Model_Abstract
{ 
    public function shipmentEmail($observer)
                {
                    $event = $observer-&gt;getEvent();
                    if(!$order = $event-&gt;getOrder())
                    {
                                    $order_Id = Mage::getSingleton('checkout/type_onepage')-&gt;getCheckout()
                      -&gt;getLastOrderId();
                                    $order = Mage::getModel('sales/order')-&gt;load($order_Id);
                                    $customer = Mage::getModel('customer/customer')-&gt;load($order-&gt;getCustomerId());
                    }
                    $payment = $order-&gt;getPayment()-&gt;getMethod();
                    $storeId = $order-&gt;getStoreId();
                    $emailTemplate  = Mage::getModel('core/email_template')-&gt;loadDefault('custom_email_po_template');   
                    $emailTemplateVariables = array();                  
                    $emailTemplateVariables['myvar1'] = 'Branko';
                    $emailTemplateVariables['myvar2'] = 'Ajzele';
                    $emailTemplateVariables['myvar3'] = 'ActiveCodeline';
                    $emailTemplateVariables['storeid'] = $storeId;                  
                    $processedTemplate = $emailTemplate-&gt;getProcessedTemplate($emailTemplateVariables);
                    /*  $emailTemplate-&gt;setSenderName('MetroCC');
                    $emailTemplate-&gt;setSenderEmail('info@metrocc.com');
                    $emailTemplate-&gt;setTemplateSubject($this-&gt;__('PO Test mail'));  */
                    //send mail
                    $emailTemplate-&gt;send('sachin301190@gmail.com', 'sachin', $emailTemplateVariables); 
                    return true;
                }       
}


in Config.xml

------------------------------
&lt;?xml version=""1.0""?&gt;
&lt;config&gt;
   &lt;modules&gt;
        &lt;Metro_Purchaseorder&gt;
            &lt;version&gt;0.1.0&lt;/version&gt;
        &lt;/Metro_Purchaseorder&gt;
    &lt;/modules&gt;
          &lt;frontend&gt;
            &lt;events&gt;
                &lt;checkout_onepage_controller_success_action&gt;
                    &lt;observers&gt;
                        &lt;purchaseorder_observer&gt;
                            &lt;type&gt;singleton&lt;/type&gt;
                            &lt;class&gt;Metro_Purchaseorder_Model_Observer&lt;/class&gt;
                            &lt;method&gt;shipmentEmail&lt;/method&gt;
                        &lt;/purchaseorder_observer&gt;
                    &lt;/observers&gt;
                &lt;/checkout_onepage_controller_success_action&gt;
            &lt;/events&gt;
            &lt;/frontend&gt;
                &lt;global&gt;
                  &lt;template&gt;
                        &lt;email&gt;                     
                                &lt;purchaseorder_custom_email1 translate=""label"" module=""purchaseorder""&gt;
                                        &lt;label&gt;Purchaseorder module&lt;/label&gt;
                                        &lt;file&gt;sales/purchaseorder_custom_email1.html&lt;/file&gt;
                                        &lt;type&gt;html&lt;/type&gt;
                                &lt;/purchaseorder_custom_email1&gt;
                        &lt;/email&gt;
                        &lt;/template&gt;      
                  &lt;/global&gt;    
&lt;/config&gt;


Please help me in correcting the above error for sending custom email template
",Sachin S,https://magento.stackexchange.com/users/22561,"Sachin,You issue with  event parameter.checkout_onepage_controller_success_action give last order ids in a  array .
You can easy check at class Mage_Checkout_OnepageController  at function successAction.

Mage::dispatchEvent('checkout_onepage_controller_success_action', array('order_ids' =&gt; array($lastOrderId)));


your observer code is

&lt;?php
class Metro_Purchaseorder_Model_Observer {

    public function shipmentEmail(Varien_Event_Observer $observer) 
        {
        $orderIds = $observer-&gt;getEvent()-&gt;getOrderIds();
        if (empty($orderIds) || !is_array($orderIds)) {
            return;
        }
        foreach($orderIds as $eachOrderId){
             $order = Mage::getModel('sales/order')-&gt;load($eachOrderId);
            try {
                    $order = Mage::getModel('sales/order')-&gt;load($eachOrderId);
                    $customer = Mage::getModel('customer/customer')-&gt;load($order-&gt;getCustomerId());
                    $payment = $order-&gt;getPayment()-&gt;getMethodInstance()-&gt;getCode();
                    $storeId = $order-&gt;getStoreId();
                    $emailTemplate  = Mage::getModel('core/email_template')-&gt;loadDefault('custom_email_po_template');   
                    $emailTemplateVariables = array();                  
                    $emailTemplateVariables['myvar1'] = 'Branko';
                    $emailTemplateVariables['myvar2'] = 'Ajzele';
                    $emailTemplateVariables['myvar3'] = 'ActiveCodeline';
                    $emailTemplateVariables['storeid'] = $storeId;                  
                    $processedTemplate = $emailTemplate-&gt;getProcessedTemplate($emailTemplateVariables);
                    /*  $emailTemplate-&gt;setSenderName('MetroCC');
                    $emailTemplate-&gt;setSenderEmail('info@metrocc.com');
                    $emailTemplate-&gt;setTemplateSubject($this-&gt;__('PO Test mail'));  */
                    //send mail
                    $emailTemplate-&gt;send('sachin301190@gmail.com', 'sachin', $emailTemplateVariables); 
                    return true;


                }catch (Mage_Core_Exception $e) {
            }
        break;
        }
            return $this;
        }

}

",Amit Bera,https://magento.stackexchange.com/users/4564,http://magento.stackexchange.com/questions/58779/custom-email-unable-to-send-magento,TECHNOLOGY,magento.stackexchange.com,1.0,0.4444444444444444,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.6666666666666666,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.3333333333333333,0.3333333333333333,0.6666666666666666,Custom email cannot send Magento,"I get the following error:
""exception 'exception' with message 'this letter cannot be sent.' magento"" , in magento php.
below is the code i have used.

Observer.php

&lt;?php
class Metro_Purchaseorder_Model_Observer extends Mage_Core_Model_Abstract
{ 
    public function shipmentEmail($observer)
                {
                    $event = $observer-&gt;getEvent();
                    if(!$order = $event-&gt;getOrder())
                    {
                                    $order_Id = Mage::getSingleton('checkout/type_onepage')-&gt;getCheckout()
                      -&gt;getLastOrderId();
                                    $order = Mage::getModel('sales/order')-&gt;load($order_Id);
                                    $customer = Mage::getModel('customer/customer')-&gt;load($order-&gt;getCustomerId());
                    }
                    $payment = $order-&gt;getPayment()-&gt;getMethod();
                    $storeId = $order-&gt;getStoreId();
                    $emailTemplate  = Mage::getModel('core/email_template')-&gt;loadDefault('custom_email_po_template');   
                    $emailTemplateVariables = array();                  
                    $emailTemplateVariables['myvar1'] = 'Branko';
                    $emailTemplateVariables['myvar2'] = 'Ajzele';
                    $emailTemplateVariables['myvar3'] = 'ActiveCodeline';
                    $emailTemplateVariables['storeid'] = $storeId;                  
                    $processedTemplate = $emailTemplate-&gt;getProcessedTemplate($emailTemplateVariables);
                    /*  $emailTemplate-&gt;setSenderName('MetroCC');
                    $emailTemplate-&gt;setSenderEmail('info@metrocc.com');
                    $emailTemplate-&gt;setTemplateSubject($this-&gt;__('PO Test mail'));  */
                    //send mail
                    $emailTemplate-&gt;send('sachin301190@gmail.com', 'sachin', $emailTemplateVariables); 
                    return true;
                }       
}


in Config.xml

------------------------------
&lt;?xml version=""1.0""?&gt;
&lt;config&gt;
   &lt;modules&gt;
        &lt;Metro_Purchaseorder&gt;
            &lt;version&gt;0.1.0&lt;/version&gt;
        &lt;/Metro_Purchaseorder&gt;
    &lt;/modules&gt;
          &lt;frontend&gt;
            &lt;events&gt;
                &lt;checkout_onepage_controller_success_action&gt;
                    &lt;observers&gt;
                        &lt;purchaseorder_observer&gt;
                            &lt;type&gt;singleton&lt;/type&gt;
                            &lt;class&gt;Metro_Purchaseorder_Model_Observer&lt;/class&gt;
                            &lt;method&gt;shipmentEmail&lt;/method&gt;
                        &lt;/purchaseorder_observer&gt;
                    &lt;/observers&gt;
                &lt;/checkout_onepage_controller_success_action&gt;
            &lt;/events&gt;
            &lt;/frontend&gt;
                &lt;global&gt;
                  &lt;template&gt;
                        &lt;email&gt;                     
                                &lt;purchaseorder_custom_email1 translate=""label"" module=""purchaseorder""&gt;
                                        &lt;label&gt;Purchaseorder module&lt;/label&gt;
                                        &lt;file&gt;sales/purchaseorder_custom_email1.html&lt;/file&gt;
                                        &lt;type&gt;html&lt;/type&gt;
                                &lt;/purchaseorder_custom_email1&gt;
                        &lt;/email&gt;
                        &lt;/template&gt;      
                  &lt;/global&gt;    
&lt;/config&gt;


Please help me in correcting the above error for sending custom email template
","Sachin,You issue with  event parameter.checkout_onepage_controller_success_action give last order ids in a  array .
You can easy check at class Mage_Checkout_OnepageController  at function successAction.

Mage::dispatchEvent('checkout_onepage_controller_success_action', array('order_ids' =&gt; array($lastOrderId)));


your observer code is

&lt;?php
class Metro_Purchaseorder_Model_Observer {

    public function shipmentEmail(Varien_Event_Observer $observer) 
        {
        $orderIds = $observer-&gt;getEvent()-&gt;getOrderIds();
        if (empty($orderIds) || !is_array($orderIds)) {
            return;
        }
        foreach($orderIds as $eachOrderId){
             $order = Mage::getModel('sales/order')-&gt;load($eachOrderId);
            try {
                    $order = Mage::getModel('sales/order')-&gt;load($eachOrderId);
                    $customer = Mage::getModel('customer/customer')-&gt;load($order-&gt;getCustomerId());
                    $payment = $order-&gt;getPayment()-&gt;getMethodInstance()-&gt;getCode();
                    $storeId = $order-&gt;getStoreId();
                    $emailTemplate  = Mage::getModel('core/email_template')-&gt;loadDefault('custom_email_po_template');   
                    $emailTemplateVariables = array();                  
                    $emailTemplateVariables['myvar1'] = 'Branko';
                    $emailTemplateVariables['myvar2'] = 'Ajzele';
                    $emailTemplateVariables['myvar3'] = 'ActiveCodeline';
                    $emailTemplateVariables['storeid'] = $storeId;                  
                    $processedTemplate = $emailTemplate-&gt;getProcessedTemplate($emailTemplateVariables);
                    /*  $emailTemplate-&gt;setSenderName('MetroCC');
                    $emailTemplate-&gt;setSenderEmail('info@metrocc.com');
                    $emailTemplate-&gt;setTemplateSubject($this-&gt;__('PO Test mail'));  */
                    //send mail
                    $emailTemplate-&gt;send('sachin301190@gmail.com', 'sachin', $emailTemplateVariables); 
                    return true;


                }catch (Mage_Core_Exception $e) {
            }
        break;
        }
            return $this;
        }

}

"
5290,5290,8400,Will enclosing my porch keep my house warmer?,"Will enclosing my porches during the winter help keep my house warmer? There is a lot of wind hitting the house, and I'm afraid that is causing a drop in temperature.
",Anthony Powell,https://diy.stackexchange.com/users/27718,"An enclosed porch can act as an oversized ""storm window"" for the part of the house it covers, so there is some insulation benefit. How much depends on how well the porch is air-sealed and insulated. It's probably a relatively small part of the surface of the house (unless it's a wrap-around porch), but it certainly won't hurt and, depending on prevailing winds and lighting conditions, might help.

An enclosed porch can also act as an ""airlock"", reducing how much warm air you lose each time you go in and out by preventing winds from blowing straight into the house. Again, probably not a huge effect, but it's there. And gives you a sheltered place to leave outdoor stuff like bicycles, or muddy shoes that you don't want to track into the house.

I doubt energy savings alone justify it. Those combined with increasing the year-round usefulness of the porch space might. 

(Mine just has storm windows all the way around. It definitely does work as windbreak and airlock and so on. Its R-value for the rest of the house is probably negligible, but I still find it useful -- and it gives me a screened porch in the summer as well. Someday I'll upgrade it into a three-season space, but there's no rush right now.)
",keshlam,https://diy.stackexchange.com/users/20958,http://diy.stackexchange.com/questions/52440/will-enclosing-my-porch-keep-my-house-warmer,LIFE_ARTS,diy.stackexchange.com,1.0,1.0,0.0,1.0,1.0,1.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.8888888888888888,1.0,0.7777777777777778,1.0,1.0,1.0,0.0,0.0,1.0,0.8888888888888888,Can I warm my house by enclosing my porch?,"Does it help to warm my house in winter by surrounding my porch? There's a lot of wind blowing into the house, I'm afraid it will cause the temperature to drop.","An enclosed porch can act as an oversized ""storm window"" for the part of the house it covers, so there is some insulation benefit. How much depends on how well the porch is air-sealed and insulated. It's probably a relatively small part of the surface of the house (unless it's a wrap-around porch), but it certainly won't hurt and, depending on prevailing winds and lighting conditions, might help.

An enclosed porch can also act as an ""airlock"", reducing how much warm air you lose each time you go in and out by preventing winds from blowing straight into the house. Again, probably not a huge effect, but it's there. And gives you a sheltered place to leave outdoor stuff like bicycles, or muddy shoes that you don't want to track into the house.

I doubt energy savings alone justify it. Those combined with increasing the year-round usefulness of the porch space might. 

(Mine just has storm windows all the way around. It definitely does work as windbreak and airlock and so on. Its R-value for the rest of the house is probably negligible, but I still find it useful -- and it gives me a screened porch in the summer as well. Someday I'll upgrade it into a three-season space, but there's no rush right now.)
"
2897,2897,4609,What size should I make the line art for a one-sheet poster?,"I have very little experience in print, if someone could give me some advice on this matter: I have to illustrate a one sheet movie poster (27""*40""), and I was wondering if I can get good results (meaning good quality for print) working on a less bigger piece of paper, and resizing it to poster size later in photoshop. I don't think there'd a problem if I scan it in 300 dpi? It's just that I find it terribly difficult to get proportions right working on large pieces.
",Azuv,https://graphicdesign.stackexchange.com/users/47325,"Work at whatever feels comfortable to you if you are working with pen and paper. Then scan it as large as you can with as much PPI as you can.

When you scan the drawing, you can scan it at 500% or more and 1200PPI or more... which will allow you to properly size it for larger reproduction than the original drawing.

Of course, enlarging it when scanning may mean you need to clean it up a bit digitally to possibly sharpen it a bit.
",Scott,https://graphicdesign.stackexchange.com/users/3270,http://graphicdesign.stackexchange.com/questions/57029/what-size-should-i-make-the-line-art-for-a-one-sheet-poster,LIFE_ARTS,graphicdesign.stackexchange.com,1.0,1.0,0.0,0.5,1.0,0.5,0.5,0.6666666666666666,0.0,0.0,1.0,0.5,0.0,0.0,0.0,0.5,0.0,0.0,0.5,0.0,0.8333333333333334,1.0,0.6666666666666666,1.0,1.0,1.0,0.5,0.5,0.5,0.8333333333333334,What is the line art size of a single poster?,"If someone can give me some advice, I have very little experience in printing: I have to give an example of a single Movie Poster (27 ""* 40""), I want to know if I can get good results (which means good printing quality) working on a smaller paper, and then resize it to poster size in Photoshop. If I scan with 300 dpi, it won't be a problem? It's just that I find it hard to find the right proportion for large clothes.","Work at whatever feels comfortable to you if you are working with pen and paper. Then scan it as large as you can with as much PPI as you can.

When you scan the drawing, you can scan it at 500% or more and 1200PPI or more... which will allow you to properly size it for larger reproduction than the original drawing.

Of course, enlarging it when scanning may mean you need to clean it up a bit digitally to possibly sharpen it a bit.
"
2497,2497,3983,business-class fiber to the home,"Suppose you're some sort of crazy nerd fellow and you live in an area that's absolutely covered in fiber optics and network facilities. What kind of cost / infrastructure would be needed to hook in somewhere and get you're internet connection directly from a local datacenter?
",neoice,https://serverfault.com/users/6134,"You need to talk to a local ISP and get a quote on a high-end connection. They can tell you how much it'll cost to get set up.

Lot of times your regular ""consumer"" ISPs have high end data plans available, in which case the cost would probably be minimal. Cable and DSL use pretty much the same equipment for home/business connections. I have a satellite office that gets it's internet from a local cable company (Cox) and we get 15/3 for about what a T1 would cost (though it's less reliable).
",Satanicpuppy,https://serverfault.com/users/21416,http://serverfault.com/questions/158286,TECHNOLOGY,serverfault.com,0.7777777777777778,0.3333333333333333,0.3333333333333333,1.0,0.3333333333333333,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.7777777777777778,0.7777777777777778,0.6666666666666666,1.0,0.8888888888888888,0.6666666666666667,0.6666666666666666,0.3333333333333333,0.0,1.0,Business class fiber home,"Suppose you're a crazy nerd, living in a place that's completely covered by fiber optics and networking. What cost / infrastructure is needed to connect to a place and directly from the local data center to the Internet?","You need to talk to a local ISP and get a quote on a high-end connection. They can tell you how much it'll cost to get set up.

Lot of times your regular ""consumer"" ISPs have high end data plans available, in which case the cost would probably be minimal. Cable and DSL use pretty much the same equipment for home/business connections. I have a satellite office that gets it's internet from a local cable company (Cox) and we get 15/3 for about what a T1 would cost (though it's less reliable).
"
1153,1153,1809,Where did the daylight come from in the interior of Babylon 5?,"The interior (open space) of Babylon 5 had night and day; whence came the daytime light? Light sources bright enough to account for the ‘daylight’ were never depicted in the show.

In Arthur C. Clarke’s Rama, the light sources are well described, and very bright.
",mlowry,https://scifi.stackexchange.com/users/23807,"In a piece originally written on GEnie and archived on the excellent Lurker's Guide website, J. Michael Straczynski describes the station as being;


  ""...patterned physically after the work of such scientists as Gerard
  K. O'Neill""


with the central core of the station containing a 


  ""hollow-world look, with fields and hydroponic gardens along the
  360-degree circular section (which is about a half-mile, or a mile
  across)...This area is known as the Garden.""


If you study other O'Neill Cyclinders, you can see that they have alternating glass and land sections to allow light but the B5 gardens seem to be lit using a ""sun line"", either chanelling light from the nearby Epsilon Eridani star using mirrors or simply creating artificial light using the station's powerful fusion reactors. The lack of an obvious channel between the exterior of the station and the interior would strongly suggest that it's the latter.

You can see the ""sun lines"" in the pictures and video below;






            
                
                    
                    
                    
                    
                    
                
            
",Valorum,https://scifi.stackexchange.com/users/20774,http://scifi.stackexchange.com/questions/51732/where-did-the-daylight-come-from-in-the-interior-of-babylon-5,LIFE_ARTS,scifi.stackexchange.com,1.0,1.0,0.0,1.0,1.0,1.0,0.6666666666666666,0.5555555555555556,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.8888888888888888,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,1.0,Where does the sun come from in the interior of Babylon 5?,"Babylon V's chambers (open spaces) are day and night. Where is the light of the day coming from? The show never depicts a light source that is bright enough to explain ""daylight."".","In a piece originally written on GEnie and archived on the excellent Lurker's Guide website, J. Michael Straczynski describes the station as being;


  ""...patterned physically after the work of such scientists as Gerard
  K. O'Neill""


with the central core of the station containing a 


  ""hollow-world look, with fields and hydroponic gardens along the
  360-degree circular section (which is about a half-mile, or a mile
  across)...This area is known as the Garden.""


If you study other O'Neill Cyclinders, you can see that they have alternating glass and land sections to allow light but the B5 gardens seem to be lit using a ""sun line"", either chanelling light from the nearby Epsilon Eridani star using mirrors or simply creating artificial light using the station's powerful fusion reactors. The lack of an obvious channel between the exterior of the station and the interior would strongly suggest that it's the latter.

You can see the ""sun lines"" in the pictures and video below;






            
                
                    
                    
                    
                    
                    
                
            
"
2272,2272,3620,Collections of two-player free-form adventure ideas?,"I'm planning a short two-person (one PC, one GM) free-form session. Is there a good quality compilation of adventure outlines tuned for one-on-one play somewhere? The theme doesn't matter much, but I'd like some ideas fit for just one PC to get started.
",Tim,https://rpg.stackexchange.com/users/1548,"One of the best genres as a whole for this is Espionage and Spys... Steal liberally from every James Bond movie and book. And any other such story.

Another good one, surprisingly, is the ""Rebel Scout"" in both the Star Wars and US Civil War settings. The prominent NPC in both has to do with the PC's mode of transport... in SW, it's the astromech droid; in the USCW, one's horse. Sneaking into systems/towns, finding out if that loner there is friend or foe...

Related, but suitable for guest PC's as well, is the investigation based scenario. It works best when the character has a mission-based reason. But it allows stealing from just about 30-some odd TV shows.

Which leads to another resource or two for ideas:


TV Tropes
Interned Movie DataBase (IMDB)


IMDB has plot synopses for many series' episodes. Steal liberally. Pick any series with a singular main character and rip away.
",aramis,https://rpg.stackexchange.com/users/407,http://rpg.stackexchange.com/questions/6739/collections-of-two-player-free-form-adventure-ideas,CULTURE,rpg.stackexchange.com,1.0,1.0,1.0,1.0,0.0,0.0,0.8333333333333334,0.8333333333333334,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.3333333333333333,1.0,1.0,0.8,1.0,0.0,0.0,1.0,A collection of two free-form adventure ideas?,"I'm planning a free meeting for two (one computer, one universal). Is there a good quality compilation of adventure outlines for one-on-one play adjustments somewhere? The theme doesn't matter, but I think some ideas for a computer start.","One of the best genres as a whole for this is Espionage and Spys... Steal liberally from every James Bond movie and book. And any other such story.

Another good one, surprisingly, is the ""Rebel Scout"" in both the Star Wars and US Civil War settings. The prominent NPC in both has to do with the PC's mode of transport... in SW, it's the astromech droid; in the USCW, one's horse. Sneaking into systems/towns, finding out if that loner there is friend or foe...

Related, but suitable for guest PC's as well, is the investigation based scenario. It works best when the character has a mission-based reason. But it allows stealing from just about 30-some odd TV shows.

Which leads to another resource or two for ideas:


TV Tropes
Interned Movie DataBase (IMDB)


IMDB has plot synopses for many series' episodes. Steal liberally. Pick any series with a singular main character and rip away.
"
470,470,732,Does a laptop computer charge faster when off?,"A laptop power supply can supply a limited amount of power. Conceivably, then, when the computer is running, some of the power must be diverted to the processor and other components, leaving less to charge the battery. (Power usage is roughly 10 to 30 watts, or maybe more if you have a graphics card. In my case, my charger is rated for 65 watts.) Why doesn&#39;t my laptop battery charge while the laptop is in use? is an example of an extreme case. So it's plausible that this would affect charging speed.

So do laptops in fact charge significantly faster when turned off or asleep (while plugged into a sufficient power supply)?
",Mechanical snail,https://superuser.com/users/34598,"It depends on the power supply.  We have a few computers which can be run off a lower-wattage power supply while running - it will not charge the battery at all.  If you attach a larger power supply, then it can charge and run.

Check with your laptop manufacturer.  It seems somewhat common to see power supplies with different wattage being offered.  The power supply with a higher wattage may be what you need to charge quickly and power the system while on.  Check to see if a larger power supply is available if you need to charge quickly while using the system.
",Zoredache,https://superuser.com/users/2057,http://superuser.com/questions/337527,TECHNOLOGY,superuser.com,1.0,1.0,0.0,1.0,0.6666666666666666,1.0,0.4444444444444444,0.4444444444444444,0.3333333333333333,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,0.8888888888888888,0.8666666666666666,0.3333333333333333,0.0,0.6666666666666666,0.8888888888888888,Does the laptop charge fast when it is turned off?,"Laptop power can provide limited power. As you can imagine, when the computer is running, part of the power must be transferred to the processor and other components, leaving less power for the battery to charge. (the power consumption is about 10 to 30 watts, maybe more if you have a video card. In my case, my charger is rated at 65 watts.) Why does my laptop battery not charge when it is in use? It's an extreme case. So this may affect the charging speed.","It depends on the power supply.  We have a few computers which can be run off a lower-wattage power supply while running - it will not charge the battery at all.  If you attach a larger power supply, then it can charge and run.

Check with your laptop manufacturer.  It seems somewhat common to see power supplies with different wattage being offered.  The power supply with a higher wattage may be what you need to charge quickly and power the system while on.  Check to see if a larger power supply is available if you need to charge quickly while using the system.
"
2313,2313,3690,Quantity based discount for single product in Expresso Store,"I'm using latest build of Expresso Store, 2.3.1. I need to apply quantity based discounts to products, but the discount needs to apply to a single product. For example:

I have 10% off discount for all products in store when you order 10 or more of a single product, but the discount only applies to the particular product. So I order 11 of Product 1, 10 of Product 2 and 5 of Product 3. Products 1 and 2 will get the discount, product 3 will be full price.

As far as I can see this is not possible in Store. If so are there any ways I can handle this in the template? As our discount will likely be pretty simple, with the same discount being applied store wide.

Failing that, what are our options for extending Store to achieve this?

Update: Just to clarify, we are looking to apply this discount at a category or store wide level, rather than updating the pricing of an individual product, as there are thousands of products this would not be viable, in particular as we will likely just have one percentage discount that is the same for all products.
",neekster,https://expressionengine.stackexchange.com/users/587,"We've just had the bulk discount configured to work with store 2.4 by another extension developer. 
You're right, it doesn't accept percentage discounts however you could easily use Datagrab to import the matrix fields all at once across any product range you wanted.

I'm sure we could put you in touch with the developer that made the add on compatible with store 2 if you wanted...
",Jos Medinger,https://expressionengine.stackexchange.com/users/3835,http://expressionengine.stackexchange.com/questions/24812/quantity-based-discount-for-single-product-in-expresso-store,TECHNOLOGY,expressionengine.stackexchange.com,1.0,0.5555555555555556,0.0,0.0,1.0,0.6666666666666666,0.7777777777777778,0.5555555555555556,1.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8,0.3333333333333333,1.0,0.6666666666666666,0.8888888888888888,Express store quantity discount,"I'm using latest build of Expresso Store, 2.3.1. I need to apply quantity based discounts to products, but the discount needs to apply to a single product. For example:

I have 10% off discount for all products in store when you order 10 or more of a single product, but the discount only applies to the particular product. So I order 11 of Product 1, 10 of Product 2 and 5 of Product 3. Products 1 and 2 will get the discount, product 3 will be full price.

As far as I can see this is not possible in Store. If so are there any ways I can handle this in the template? As our discount will likely be pretty simple, with the same discount being applied store wide.

Failing that, what are our options for extending Store to achieve this?

Update: Just to clarify, we are looking to apply this discount at a category or store wide level, rather than updating the pricing of an individual product, as there are thousands of products this would not be viable, in particular as we will likely just have one percentage discount that is the same for all products.
","We've just had the bulk discount configured to work with store 2.4 by another extension developer. 
You're right, it doesn't accept percentage discounts however you could easily use Datagrab to import the matrix fields all at once across any product range you wanted.

I'm sure we could put you in touch with the developer that made the add on compatible with store 2 if you wanted...
"
3871,3871,6162,"Can the term ""jack/jerk off"" be used for female masturbation?","I apologize for this potentially obscene question.

Can the terms jack off or jerk off be used for female masturbation? If not (which is my intuition), what would be the not too poetic vulgar slang equivalent? By too poetic I refer to expressions such as spank the monkey, choke the chicken, etc.

I checked online dictionaries, and most of them don't expand on the usage, and some of the definitions in the Urban Dictionary imply that jack off primarily refers to male masturbation, but do not provide the female counterpart. 
",Armen Ծիրունյան,https://english.stackexchange.com/users/11268,"I'm not sure how widespread it is but jill off (a reference to Jack and Jill) is sometimes used.  
",Wudang,https://english.stackexchange.com/users/12306,http://english.stackexchange.com/questions/60900/can-the-term-jack-jerk-off-be-used-for-female-masturbation,CULTURE,english.stackexchange.com,1.0,1.0,0.6666666666666666,1.0,0.0,0.3333333333333333,0.8888888888888888,0.5555555555555556,0.6666666666666666,0.0,1.0,1.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.6666666666666666,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,1.0,0.8888888888888888,0.8,0.0,0.0,0.6666666666666666,0.8888888888888888,"Can the word ""Jack"" be used for female masturbation?","I apologize for this potentially obscene question.

Can the terms jack off or jerk off be used for female masturbation? If not (which is my intuition), what would be the not too poetic vulgar slang equivalent? By too poetic I refer to expressions such as spank the monkey, choke the chicken, etc.

I checked online dictionaries, and most of them don't expand on the usage, and some of the definitions in the Urban Dictionary imply that jack off primarily refers to male masturbation, but do not provide the female counterpart. 
","I'm not sure how widespread it is but jill off (a reference to Jack and Jill) is sometimes used.  
"
1505,1505,2369,How to have remote standby PostgreSQL server in different location (AWS)?,"We have a primary PostgreSQL 9.4 server running multiple instances in our DC. It is using Continuous Archiving via WAL-E out to AWS S3. I would like to have a hot/warm standby server in our VPC within AWS EC2 that would be ready to take over should we need to DR. I can recover the server via WAL-E but can't seem to get it to work in hot_standby mode. What could I be missing? Docs I read seem to suggest that the standby needs to talk to the primary? Is this so? Is this required when log-shipping via WAL-E?
",n8gard,https://dba.stackexchange.com/users/71684,"There are two ways to run a replica. You can use either, or both together:


Streaming replication, where the replica makes a PostgreSQL protocol connection to the standby as configured with primary_conninfo in recovery.conf; or
WAL shipping, where the replica runs a restore_command (set in recovery.conf that fetches WAL archives to replay.


See recovery.conf.

Both require that standby_mode be set in recovery.conf.

WAL-E is designed to be used as an archive_command on the master, to store WAL into S3, then as a recovery_command on the replica to fetch WAL. There is no need for a streaming replication connection. You can add one anyway, and it will be used where available, and the system will fall back to WAL archive recovery if it can't connect over streaming replication. Or you can just use WAL-based archiving.

The main advantage of using streaming replication as well is that it's more timely; you don't have to wait until an entire WAL archive is filled and shipped before the replica sees the changes.

For more information see the manual.
",Craig Ringer,https://dba.stackexchange.com/users/7788,http://dba.stackexchange.com/questions/108480/how-to-have-remote-standby-postgresql-server-in-different-location-aws,TECHNOLOGY,dba.stackexchange.com,0.8888888888888888,0.4444444444444444,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.3333333333333333,0.6666666666666666,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,1.0,How to back up PostgreSQL server remotely in different locations (AWS)?,"We have a primary PostgreSQL 9.4 server running multiple instances in our DC. It is using a continuous archive output to AWS S3 via wal-e. I want to have a hot / hot standby server in AWS EC2 in our VPC, which can be taken over at any time if we need it. I can recover the server through wal-e, but it doesn't seem to work in hot standby mode. What will I miss? The files I read seem to indicate that the standby system needs to talk to the primary system? Is that so? Do you need to do this when transporting logs through wal-e?","There are two ways to run a replica. You can use either, or both together:


Streaming replication, where the replica makes a PostgreSQL protocol connection to the standby as configured with primary_conninfo in recovery.conf; or
WAL shipping, where the replica runs a restore_command (set in recovery.conf that fetches WAL archives to replay.


See recovery.conf.

Both require that standby_mode be set in recovery.conf.

WAL-E is designed to be used as an archive_command on the master, to store WAL into S3, then as a recovery_command on the replica to fetch WAL. There is no need for a streaming replication connection. You can add one anyway, and it will be used where available, and the system will fall back to WAL archive recovery if it can't connect over streaming replication. Or you can just use WAL-based archiving.

The main advantage of using streaming replication as well is that it's more timely; you don't have to wait until an entire WAL archive is filled and shipped before the replica sees the changes.

For more information see the manual.
"
949,949,1504,"Has Jesus ever directly said he would die as a voluntary sacrafice? If so, wasn't it double sense?","I know about mentioning Jesus died to redeem mankind in evangelical literature like:


  For God so loved the world, that he gave his only Son, that whoever believes in him should not perish but have eternal life. (John 3:16)


But I suspect these are only later interpretations. Has Jesus himself ever said his dead is a sacrifice?

If so, isn't double meaning in Greek? At least in Czech, English and German you could use the phrase ""he died for humans' sins"" in sense of ""because of"" - like cause of his death was humans' fault - fault of the Romans who crucified him.

(btw I think I understand the evangelical message so I'm not asking how christians get it today, so please don't make your interpretations of the direct Jesus' quote much distant)

Thank you.
",Probably,https://christianity.stackexchange.com/users/12541,"
  But I suspect these are only later interpretations. Has Jesus himself ever said his dead is a sacrifice?


Jesus's death is placed in the context of a Passover (Seder) meal, and since the meal is literally a liturgy, it must be completed or the participants defy the commandment of God. 

Anyway, Four cups must be drunk to complete the ceremony, and the Eucharistic cup Christ passed around at table was what the Jews call ""the cup of blessings,"" the third cup. However, any devote Jewish person would realize that the meal is then cut short, with Christ going to the Garden to pray while forgoing the fourth cup, meaning the meal was not completed. However, later on, in the Garden, Christ prays about ""letting this cup pass from me,"" which still indicates that Christ has the fourth cup in mind.

He is captured, and eventually sentenced, and again we hear ""Truly I tell you, I will not drink again from the fruit of the vine until that day when I drink it new in the kingdom of God,"" another reference to the fourth cup. Notice how he refuses to drink the wine while he still hasn't suffered.

After his agonizing pain on the Cross, right before His death, Christ is given some sour wine, which He does drink ""And someone ran, filled a sponge with sour wine, put it on a stick, and gave it to him to drink (Mark 15)"" which St. John, an eyewitness, describes in more detail:


  A jar full of sour wine was standing there. So they put a sponge full of the wine on a branch of hyssop and held it to his mouth. When Jesus had received the wine, he said, “It is finished.” Then he bowed his head and gave up his spirit (John 19:29-30)


In all Gospel accounts, Jesus drank the wine and then died. That wine was the fourth cup which finished the Pasover meal.

And what do Jews call the fourth cup? The cup of Salvation, meaning that the Cruxifiction was a part of the Last Supper which ended in the cup of Salvation, bitter in more ways than one.

St. Mark and St. Matthew then go on to point out: ""And the curtain of the temple was torn in two, from top to bottom"" immediately after, which indicates that the relationship between God and Man was healed, He forgave Man, as forgiveness is the only way to continue a relationship. Thus, the Cruxifiction was for forgiveness.

In other words, all four Gospels teach that the Cruxifiction was for the forgiveness of sins. It is not a later interpretation (as if that is a bad thing anyway :shrug:).

Christi pax,

Lucretius

Note:* I assume Markian priority in this article, although I disagree with it.

Note:** I also assume GJohn was written by an eyewitness. If you wish to believe otherwise (as the OP seems to implicitly believe), and instead see it as written by later Christians adding theological detail, that is fine. The point is that the Synoptics indicate the same events, although GJohn most clearly expresses the theological meaning, which are no less absent in the Synoptics, although they are not as clear. In a sense, one can see GJohn as a Gospel written to flush out more of the theological meanings of the other Gospels (which might be why GJohn is traditionally symbolized by an eagle, the bird that flies higher and sees farther than all other animals). Simply stated, the Synoptics, as well as the Old Testement, are the raw material which GJohn builds his theology.
",Lucretius,https://christianity.stackexchange.com/users/21939,http://christianity.stackexchange.com/questions/41485/did-jesus-ever-directly-say-he-would-die-as-a-voluntary-sacrifice-if-so-was-it,CULTURE,christianity.stackexchange.com,0.8888888888888888,0.8888888888888888,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.7777777777777778,0.3333333333333333,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.5555555555555556,0.7777777777777778,0.5,0.7777777777777778,0.8888888888888888,0.7,0.0,0.0,1.0,0.8888888888888888,"Did Jesus directly say that he would sacrifice voluntarily? If so, isn't that a double meaning?","I know about mentioning Jesus died to redeem mankind in evangelical literature like:


  For God so loved the world, that he gave his only Son, that whoever believes in him should not perish but have eternal life. (John 3:16)


But I suspect these are only later interpretations. Has Jesus himself ever said his dead is a sacrifice?

If so, isn't double meaning in Greek? At least in Czech, English and German you could use the phrase ""he died for humans' sins"" in sense of ""because of"" - like cause of his death was humans' fault - fault of the Romans who crucified him.

(btw I think I understand the evangelical message so I'm not asking how christians get it today, so please don't make your interpretations of the direct Jesus' quote much distant)

Thank you.
","
  But I suspect these are only later interpretations. Has Jesus himself ever said his dead is a sacrifice?


Jesus's death is placed in the context of a Passover (Seder) meal, and since the meal is literally a liturgy, it must be completed or the participants defy the commandment of God. 

Anyway, Four cups must be drunk to complete the ceremony, and the Eucharistic cup Christ passed around at table was what the Jews call ""the cup of blessings,"" the third cup. However, any devote Jewish person would realize that the meal is then cut short, with Christ going to the Garden to pray while forgoing the fourth cup, meaning the meal was not completed. However, later on, in the Garden, Christ prays about ""letting this cup pass from me,"" which still indicates that Christ has the fourth cup in mind.

He is captured, and eventually sentenced, and again we hear ""Truly I tell you, I will not drink again from the fruit of the vine until that day when I drink it new in the kingdom of God,"" another reference to the fourth cup. Notice how he refuses to drink the wine while he still hasn't suffered.

After his agonizing pain on the Cross, right before His death, Christ is given some sour wine, which He does drink ""And someone ran, filled a sponge with sour wine, put it on a stick, and gave it to him to drink (Mark 15)"" which St. John, an eyewitness, describes in more detail:


  A jar full of sour wine was standing there. So they put a sponge full of the wine on a branch of hyssop and held it to his mouth. When Jesus had received the wine, he said, “It is finished.” Then he bowed his head and gave up his spirit (John 19:29-30)


In all Gospel accounts, Jesus drank the wine and then died. That wine was the fourth cup which finished the Pasover meal.

And what do Jews call the fourth cup? The cup of Salvation, meaning that the Cruxifiction was a part of the Last Supper which ended in the cup of Salvation, bitter in more ways than one.

St. Mark and St. Matthew then go on to point out: ""And the curtain of the temple was torn in two, from top to bottom"" immediately after, which indicates that the relationship between God and Man was healed, He forgave Man, as forgiveness is the only way to continue a relationship. Thus, the Cruxifiction was for forgiveness.

In other words, all four Gospels teach that the Cruxifiction was for the forgiveness of sins. It is not a later interpretation (as if that is a bad thing anyway :shrug:).

Christi pax,

Lucretius

Note:* I assume Markian priority in this article, although I disagree with it.

Note:** I also assume GJohn was written by an eyewitness. If you wish to believe otherwise (as the OP seems to implicitly believe), and instead see it as written by later Christians adding theological detail, that is fine. The point is that the Synoptics indicate the same events, although GJohn most clearly expresses the theological meaning, which are no less absent in the Synoptics, although they are not as clear. In a sense, one can see GJohn as a Gospel written to flush out more of the theological meanings of the other Gospels (which might be why GJohn is traditionally symbolized by an eagle, the bird that flies higher and sees farther than all other animals). Simply stated, the Synoptics, as well as the Old Testement, are the raw material which GJohn builds his theology.
"
5978,5978,9479,.ibooks format on the iphone?,"I download a "".ibooks"" file for this free book and tried adding it to my iPhone library but it doesn't show up. Manually dragging it over doesn't work either.

Is it because .ibooks isn't supported by iPhone?
",Legendre,https://apple.stackexchange.com/users/45215,"It can't be done, because only the iPad can read the .ibooks format.  To let Apple know you want this expanded, tell them at

http://www.apple.com/feedback
",Tom Gewecke,https://apple.stackexchange.com/users/33767,http://apple.stackexchange.com/questions/85563/ibooks-format-on-the-iphone,TECHNOLOGY,apple.stackexchange.com,0.7777777777777778,0.4444444444444444,0.0,0.3333333333333333,1.0,1.0,0.8888888888888888,0.8888888888888888,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.3333333333333333,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.6666666666666666,0.0,1.0,1.0,. iBooks format on iPhone?,"I downloaded a "". IBooks"" file for this free book and tried to add it to my iPhone library, but it didn't show up. Manual drag does not work either.","This is not possible because only the iPad can read the. IBooks format. If you want apple to know you want this extension, please let them know"
4048,4048,6462,Where to install SSL Cert,"I have Bluehost hosting my landing page and a few subdomains.  One of the subdomains has a A-Record that points to an Amazon EC2 instance running tomcat.  I would like the tomcat application to be hosted over HTTPS.  Where do I need to install the certificate?  On Bluehost or in tomcat on my EC2 instance?
",Michael J. Lee,https://superuser.com/users/89886,"You install the certificate On Tomcat. See here.    

In general terms you run the certificate on the device you want to handle HTTPS, which is the web server hosting the subdomain.   This is fairly intuitive as an SSL cert [usually] specifices a single domain, unless you get a wildcard cert or an SNI cert, in which case you would use it in both places.
",davidgo,https://superuser.com/users/137786,http://superuser.com/questions/651361,TECHNOLOGY,superuser.com,0.8888888888888888,0.3333333333333333,0.0,1.0,1.0,1.0,0.5555555555555556,0.5555555555555556,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.8888888888888888,Where to install SSL certificate,I have a blue host hosting my landing page and some subdomains. One of the sub domains has a a-record that points to the Amazon EC2 instance running Tomcat. I want the Tomcat application to be hosted over HTTPS. Where do I need to install the certificate? On BlueHost or Tomcat?,"You install the certificate On Tomcat. See here.    

In general terms you run the certificate on the device you want to handle HTTPS, which is the web server hosting the subdomain.   This is fairly intuitive as an SSL cert [usually] specifices a single domain, unless you get a wildcard cert or an SNI cert, in which case you would use it in both places.
"
2654,2654,4223,php regular expession convert to python code,"i have this code written in php  , and i want to convert it into python code 

$title_regex = ""/&lt;title&gt;(.+)&lt;\/title&gt;/i"";
preg_match_all($title_regex, $string, $title, PREG_PATTERN_ORDER);
$url_title = $title[1];

/// fecth decription
$tags = get_meta_tags($url);

// fetch images
$image_regex = '/&lt;img[^&gt;]*'.'src=[\""|\'](.*)[\""|\']/Ui';
preg_match_all($image_regex, $string, $img, PREG_PATTERN_ORDER);
$images_array = $img[1];


i have tried this .. but it give me errors in pics part 

import re
out=Data #web site html page ..
title_regex = ""/&lt;title&gt;(.+)&lt;\/title&gt;/i"" #no need for this .. un used 
m = re.search(""&lt;title&gt;(.+)&lt;\/title&gt;"", out)
print ""title"",m.group(1)
#for pics i have tried this but it give me error ..
pics = re.match(r""/&lt;img[^&gt;]*'.'src=[\""|\'](.*)[\""|\']/Ui"", out)#the conversion is not correct  
print ""grop"",pics.group(1)


my full code 

import re
import urllib
print ""Start""
url=""http://www.deviantart.com""
data=urllib.urlopen(url)
out=data.read()
print 
title_regex = ""/&lt;title&gt;(.+)&lt;\/title&gt;/i""
m = re.search(""&lt;title&gt;(.+)&lt;\/title&gt;"", out)
print ""first"",m
print ""title="",m.group(1)

title_regex = ""/&lt;title&gt;(.+)&lt;\/title&gt;/i""

pics = re.match(r""/&lt;img[^&gt;]*src=[\""|\'](.*)[\""|\']/Ui"", out)

print ""pics&gt;&gt;"",pics.group(1)


how i can convert a php re>>""/]*'.'src=\""|\'[\""|\']/Ui""  to a python re ?
",John silver,https://stackoverflow.com/users/744852,"Working version .. display all images from a given web site using tag IMG src >
code:

  import re
  import urllib
  print ""Start""
  url=""http://www.deviantart.com""
  data=urllib.urlopen(url)
  out=data.read()
  print 
  title_regex = ""/&lt;title&gt;(.+)&lt;\/title&gt;/i""
  m = re.search(""&lt;title&gt;(.+)&lt;\/title&gt;"", out)
  print ""first"",m
  print ""grop"",m.group(1)

  title_regex = ""/&lt;title&gt;(.+)&lt;\/title&gt;/i""

  pics = re.compile(r""&lt;IMG[^&gt;]*src=([^&gt;]*[^/])"")#Change IMG tag 
  allpics=pics.findall(out)
  print ""found"",pics
  for mypic in allpics:
     print ""&lt; IMG src="",mypic


thanks all 
",John silver,https://stackoverflow.com/users/744852,http://stackoverflow.com/questions/6397021/php-regular-expession-convert-to-python-code,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.5555555555555556,0.0,0.3333333333333333,1.0,1.0,0.6666666666666666,0.4444444444444444,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.8333333333333334,0.7777777777777778,0.6666666666666666,0.7777777777777778,1.0,0.8,1.0,0.0,0.3333333333333333,0.6666666666666666,PHP regular expression converted to Python code,"i have this code written in php  , and i want to convert it into python code 

$title_regex = ""/&lt;title&gt;(.+)&lt;\/title&gt;/i"";
preg_match_all($title_regex, $string, $title, PREG_PATTERN_ORDER);
$url_title = $title[1];

/// fecth decription
$tags = get_meta_tags($url);

// fetch images
$image_regex = '/&lt;img[^&gt;]*'.'src=[\""|\'](.*)[\""|\']/Ui';
preg_match_all($image_regex, $string, $img, PREG_PATTERN_ORDER);
$images_array = $img[1];


i have tried this .. but it give me errors in pics part 

import re
out=Data #web site html page ..
title_regex = ""/&lt;title&gt;(.+)&lt;\/title&gt;/i"" #no need for this .. un used 
m = re.search(""&lt;title&gt;(.+)&lt;\/title&gt;"", out)
print ""title"",m.group(1)
#for pics i have tried this but it give me error ..
pics = re.match(r""/&lt;img[^&gt;]*'.'src=[\""|\'](.*)[\""|\']/Ui"", out)#the conversion is not correct  
print ""grop"",pics.group(1)


my full code 

import re
import urllib
print ""Start""
url=""http://www.deviantart.com""
data=urllib.urlopen(url)
out=data.read()
print 
title_regex = ""/&lt;title&gt;(.+)&lt;\/title&gt;/i""
m = re.search(""&lt;title&gt;(.+)&lt;\/title&gt;"", out)
print ""first"",m
print ""title="",m.group(1)

title_regex = ""/&lt;title&gt;(.+)&lt;\/title&gt;/i""

pics = re.match(r""/&lt;img[^&gt;]*src=[\""|\'](.*)[\""|\']/Ui"", out)

print ""pics&gt;&gt;"",pics.group(1)


how i can convert a php re>>""/]*'.'src=\""|\'[\""|\']/Ui""  to a python re ?
","Working version .. display all images from a given web site using tag IMG src >
code:

  import re
  import urllib
  print ""Start""
  url=""http://www.deviantart.com""
  data=urllib.urlopen(url)
  out=data.read()
  print 
  title_regex = ""/&lt;title&gt;(.+)&lt;\/title&gt;/i""
  m = re.search(""&lt;title&gt;(.+)&lt;\/title&gt;"", out)
  print ""first"",m
  print ""grop"",m.group(1)

  title_regex = ""/&lt;title&gt;(.+)&lt;\/title&gt;/i""

  pics = re.compile(r""&lt;IMG[^&gt;]*src=([^&gt;]*[^/])"")#Change IMG tag 
  allpics=pics.findall(out)
  print ""found"",pics
  for mypic in allpics:
     print ""&lt; IMG src="",mypic


thanks all 
"
3822,3822,6080,"both ""will"" ""would"" in one sentence","From a BBC article:


  The rise comes as Russia said it would will resume shipments of natural gas to Ukraine after Kiev makes its first payment for previous supplies next week.


Would and will both together? Is this a typo, or some kind of a verb form?
",Oleksiy Markunin,https://english.stackexchange.com/users/96337,"As Jon Hanna points out in a comment, the quoted language clearly includes a mistake of a type that no one at the BBC would make out of ignorance; rather it involves a stray word that the author and/or editor forgot to remove after tinkering with the wording of the sentence. It isn't accurate to call mistakes of this type typos; at the publications where I've worked, we call them brainos.

It's easy to see what triggered the tinkering: The sentence starts in present tense (""The rise comes"") but shifts to past tense in order to handle the paraphrasing of the communique from Russia (""as Russia said"")—leaving the author or editor to fiddle with deciding whether to pick up from the present tense rises or from the past tense said to handle the ""it will resume shipments""/""it would resume shipments"" section of the sentence, bearing in mind that the sentence eventually returns to present tense with ""makes its first payment.""

The odd verb out is evidently said, since it casts Russia's promises of future action as past, even though that action and the conditions precedent to it have not yet occurred. Under the circumstances, the writer/editor would probably have been better off putting the sentence this way:


  The rise coincides with an assurance from Russia that it will resume shipments of natural gas to Ukraine after Kiev makes its first payment next week for supplies previously delivered.

",Sven Yargs,https://english.stackexchange.com/users/36232,http://english.stackexchange.com/questions/205809/both-will-would-in-one-sentence,CULTURE,english.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,1.0,1.0,1.0,0.5555555555555556,0.5555555555555556,0.0,0.0,0.0,1.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.6666666666666666,0.0,0.6666666666666666,0.8888888888888888,0.8888888888888888,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,0.7777777777777778,"""Will"" ""would"" in a sentence","From a BBC article:


  The rise comes as Russia said it would will resume shipments of natural gas to Ukraine after Kiev makes its first payment for previous supplies next week.


Would and will both together? Is this a typo, or some kind of a verb form?
","As Jon Hanna points out in a comment, the quoted language clearly includes a mistake of a type that no one at the BBC would make out of ignorance; rather it involves a stray word that the author and/or editor forgot to remove after tinkering with the wording of the sentence. It isn't accurate to call mistakes of this type typos; at the publications where I've worked, we call them brainos.

It's easy to see what triggered the tinkering: The sentence starts in present tense (""The rise comes"") but shifts to past tense in order to handle the paraphrasing of the communique from Russia (""as Russia said"")—leaving the author or editor to fiddle with deciding whether to pick up from the present tense rises or from the past tense said to handle the ""it will resume shipments""/""it would resume shipments"" section of the sentence, bearing in mind that the sentence eventually returns to present tense with ""makes its first payment.""

The odd verb out is evidently said, since it casts Russia's promises of future action as past, even though that action and the conditions precedent to it have not yet occurred. Under the circumstances, the writer/editor would probably have been better off putting the sentence this way:


  The rise coincides with an assurance from Russia that it will resume shipments of natural gas to Ukraine after Kiev makes its first payment next week for supplies previously delivered.

"
1930,1930,3077,What are the possible cryptographic implications of Zhang's proof of the Twin Prime Conjecture?,"Earlier this year, Yitang Zhang published a proof of a weakened form of the Twin Prime Conjecture. I'm wondering if any of the new mathematical machinery he developed has uses in cryptography or could be adapted for future use in the field. 
",pg1989,https://crypto.stackexchange.com/users/1025,"There are no known applications or implications to cryptography of that mathematical machinery.  I've not seen any suggestion that the machinery would plausibly have implications for cryptography.  The twin primes problem doesn't have any obvious connection to any hardness assumption or problem in cryptography.

(Yes, both Zhang's proof and cryptography have something to do with prime numbers, but that is extremely thin. Much of number theory can say it is somehow related to prime numbers, but only a small fraction of number theory has had applications to cryptography. It'd be like assuming that recent improvements in building fast sailboats for the America's Cup has implications for the possible future availability of an immortality potion, since they both involve fluids.)

In other words, this is about as close to a ""No"" answer as one is likely to be able to give, given the nature of the question (which makes it very unlikely that you are going to get a definite, resounding no).

Here are some surveys of the mathematics of this result and related results, if you want to take a look for yourself:


https://gilkalai.wordpress.com/2013/09/20/polymath-8-a-success/
http://arxiv.org/pdf/math/0605696v1
https://terrytao.wordpress.com/2013/06/30/bounded-gaps-between-primes-polymath8-a-progress-report/

",D.W.,https://crypto.stackexchange.com/users/351,http://crypto.stackexchange.com/questions/10584/what-are-the-possible-cryptographic-implications-of-zhangs-proof-of-the-twin-pr,TECHNOLOGY,crypto.stackexchange.com,1.0,0.8888888888888888,0.3333333333333333,1.0,0.6666666666666666,0.5,0.6666666666666666,0.4444444444444444,0.0,0.0,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,0.6666666666666666,1.0,What cryptographic implications might Zhang's conjecture of twin prime numbers contain?,"Earlier this year, Zhang Yitang published a proof of the weakening form of the biprime conjecture. I would like to know whether the new mathematical machine he developed can be used in cryptography or in the future.","There are no known applications or implications to cryptography of that mathematical machinery.  I've not seen any suggestion that the machinery would plausibly have implications for cryptography.  The twin primes problem doesn't have any obvious connection to any hardness assumption or problem in cryptography.

(Yes, both Zhang's proof and cryptography have something to do with prime numbers, but that is extremely thin. Much of number theory can say it is somehow related to prime numbers, but only a small fraction of number theory has had applications to cryptography. It'd be like assuming that recent improvements in building fast sailboats for the America's Cup has implications for the possible future availability of an immortality potion, since they both involve fluids.)

In other words, this is about as close to a ""No"" answer as one is likely to be able to give, given the nature of the question (which makes it very unlikely that you are going to get a definite, resounding no).

Here are some surveys of the mathematics of this result and related results, if you want to take a look for yourself:


https://gilkalai.wordpress.com/2013/09/20/polymath-8-a-success/
http://arxiv.org/pdf/math/0605696v1
https://terrytao.wordpress.com/2013/06/30/bounded-gaps-between-primes-polymath8-a-progress-report/

"
2693,2693,4295,Should I write a recommendation letter for a student at a previous job/institution?,"I receive requests for recommendation many times, but I have received one from a student belonging at a previous affiliation of mine, asking for a favourable letter in view of their achievements.

I am aware of the fact that if I comment on the performance of the student, it could be used against me, since it is good practice to ""erase"" all the material, marks, personal information of the students and staff relationship at a previous job. So I am hesitant to go in that direction. On the other hand, I could comment only very generally on the skills of the student, which could backfire their application to a new job

Differently from this question I am not looking for a recommendation, but giving one...
",ElCid,https://academia.stackexchange.com/users/1520,"When you change job, you don’t erase your memory (well, not in all jobs), nor do you all your responsibilities related to this previous job vanish. It is true that leaving a position creates certain obligations in the data you can retain, and how you can use non-publicly available information pertaining to your older institution. However, in the particular case of a reference letter, I don't think it should cause trouble. Moreover, reference letters are confidential.

Actually, I'd go further than saying it should not be a problem. In fact, I think if you can honestly write him a good recommendation letter, it is part of your responsibility to do it. This responsibility is not to your former institution, but to the student and the academic system as a whole.
",F'x,https://academia.stackexchange.com/users/2700,http://academia.stackexchange.com/questions/5047/should-i-write-a-recommendation-letter-for-a-student-at-a-previous-job-instituti,LIFE_ARTS,academia.stackexchange.com,1.0,0.7777777777777778,0.3333333333333333,0.6666666666666666,0.0,0.3333333333333333,0.5555555555555556,0.6666666666666666,0.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,1.0,Should I write a letter of recommendation for a former work / institution student?,"I receive requests for recommendation many times, but I have received one from a student belonging at a previous affiliation of mine, asking for a favourable letter in view of their achievements.

I am aware of the fact that if I comment on the performance of the student, it could be used against me, since it is good practice to ""erase"" all the material, marks, personal information of the students and staff relationship at a previous job. So I am hesitant to go in that direction. On the other hand, I could comment only very generally on the skills of the student, which could backfire their application to a new job

Differently from this question I am not looking for a recommendation, but giving one...
","When you change job, you don’t erase your memory (well, not in all jobs), nor do you all your responsibilities related to this previous job vanish. It is true that leaving a position creates certain obligations in the data you can retain, and how you can use non-publicly available information pertaining to your older institution. However, in the particular case of a reference letter, I don't think it should cause trouble. Moreover, reference letters are confidential.

Actually, I'd go further than saying it should not be a problem. In fact, I think if you can honestly write him a good recommendation letter, it is part of your responsibility to do it. This responsibility is not to your former institution, but to the student and the academic system as a whole.
"
4585,4585,7267,Medibuntu vs Fluendo,"Can someone describe the difference between the codecs in the Medibuntu Repository versus buying the Fluendo codecs?

Are they the same? Does one have better quality etc?

My Dell Mini originally came with Fluendo installed, but I have since upgraded several times and just used Medibuntu - but I am wondering if I am missing something.
",rifferte,https://askubuntu.com/users/420,"Fluendo multimedia codecs exists as commercial products because of software patents (required for decoding mpeg, mp3, etc) and silly-DRM removal laws (ie parts of DMCA, Digital Economy and ACTA) that stop you removing the CSS DRM on DVDs. The Medibuntu variants are still free software as they're not infringing any copyright (to my knowledge anyway).

Whether you legally need it or not comes down to where you live honouring software patents or the DMCA-style DRM-cracking laws.

Regarding quality: the codebase for each implementation is different so there is scope for one implementation being better than another. The only test I've really seen is ffmpeg vs Google's own implementation, where ffmpeg trounces Google.

Dell plays it safe. They want top sell a product internationally that they can advertise as being able to play DVDs. That means they have to adhere to local laws and that undoubtedly means they'll need to license the software in some regions. I expect it is easier (and therefore cheaper) for them to just bulk-license from Fluendo.
",Oli,https://askubuntu.com/users/449,http://askubuntu.com/questions/4902/medibuntu-vs-fluendo,TECHNOLOGY,askubuntu.com,1.0,0.5555555555555556,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.4444444444444444,0.3333333333333333,0.0,0.3333333333333333,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,0.3333333333333333,0.8888888888888888,Madibangtu vs. frondor,"Can someone describe the difference between the codecs in the Medibuntu Repository versus buying the Fluendo codecs?

Are they the same? Does one have better quality etc?

My Dell Mini originally came with Fluendo installed, but I have since upgraded several times and just used Medibuntu - but I am wondering if I am missing something.
","Fluendo multimedia codecs exists as commercial products because of software patents (required for decoding mpeg, mp3, etc) and silly-DRM removal laws (ie parts of DMCA, Digital Economy and ACTA) that stop you removing the CSS DRM on DVDs. The Medibuntu variants are still free software as they're not infringing any copyright (to my knowledge anyway).

Whether you legally need it or not comes down to where you live honouring software patents or the DMCA-style DRM-cracking laws.

Regarding quality: the codebase for each implementation is different so there is scope for one implementation being better than another. The only test I've really seen is ffmpeg vs Google's own implementation, where ffmpeg trounces Google.

Dell plays it safe. They want top sell a product internationally that they can advertise as being able to play DVDs. That means they have to adhere to local laws and that undoubtedly means they'll need to license the software in some regions. I expect it is easier (and therefore cheaper) for them to just bulk-license from Fluendo.
"
4637,4637,7355,php regular expession convert to python code,"i have this code written in php  , and i want to convert it into python code 

$title_regex = ""/&lt;title&gt;(.+)&lt;\/title&gt;/i"";
preg_match_all($title_regex, $string, $title, PREG_PATTERN_ORDER);
$url_title = $title[1];

/// fecth decription
$tags = get_meta_tags($url);

// fetch images
$image_regex = '/&lt;img[^&gt;]*'.'src=[\""|\'](.*)[\""|\']/Ui';
preg_match_all($image_regex, $string, $img, PREG_PATTERN_ORDER);
$images_array = $img[1];


i have tried this .. but it give me errors in pics part 

import re
out=Data #web site html page ..
title_regex = ""/&lt;title&gt;(.+)&lt;\/title&gt;/i"" #no need for this .. un used 
m = re.search(""&lt;title&gt;(.+)&lt;\/title&gt;"", out)
print ""title"",m.group(1)
#for pics i have tried this but it give me error ..
pics = re.match(r""/&lt;img[^&gt;]*'.'src=[\""|\'](.*)[\""|\']/Ui"", out)#the conversion is not correct  
print ""grop"",pics.group(1)


my full code 

import re
import urllib
print ""Start""
url=""http://www.deviantart.com""
data=urllib.urlopen(url)
out=data.read()
print 
title_regex = ""/&lt;title&gt;(.+)&lt;\/title&gt;/i""
m = re.search(""&lt;title&gt;(.+)&lt;\/title&gt;"", out)
print ""first"",m
print ""title="",m.group(1)

title_regex = ""/&lt;title&gt;(.+)&lt;\/title&gt;/i""

pics = re.match(r""/&lt;img[^&gt;]*src=[\""|\'](.*)[\""|\']/Ui"", out)

print ""pics&gt;&gt;"",pics.group(1)


how i can convert a php re>>""/]*'.'src=\""|\'[\""|\']/Ui""  to a python re ?
",John silver,https://stackoverflow.com/users/744852,"the regular expression probably did not find anything.

try this :
also remove the /Ui at the end

import re
out=Data #web site html page ..
title_regex = ""/&lt;title&gt;(.+)&lt;\/title&gt;/i"" #no need for this .. un used 
if m is not None:  #  NEW  &lt;----------------
   m = re.search(""&lt;title&gt;(.+)&lt;\/title&gt;"", out)
print ""title"",m.group(1)
#for pics i have tried this but it give me error ..
pics = re.match(r""&lt;img[^&gt;]*src=[\""|\'](.*)[\""|\']"", out)
if pics is not None: # NEW &lt;----------------
   print ""grop"",pics.group(1)


for you 2nd question try this

for filename in pics.groups():
    print filename

",yossi,https://stackoverflow.com/users/486209,http://stackoverflow.com/questions/6397021/php-regular-expession-convert-to-python-code,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.4444444444444444,0.0,1.0,1.0,1.0,0.5555555555555556,0.5555555555555556,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.5555555555555556,0.7777777777777778,0.6666666666666666,0.8888888888888888,1.0,0.8,0.6666666666666666,0.3333333333333333,0.0,0.6666666666666666,PHP regular expression converted to Python code,"i have this code written in php  , and i want to convert it into python code 

$title_regex = ""/&lt;title&gt;(.+)&lt;\/title&gt;/i"";
preg_match_all($title_regex, $string, $title, PREG_PATTERN_ORDER);
$url_title = $title[1];

/// fecth decription
$tags = get_meta_tags($url);

// fetch images
$image_regex = '/&lt;img[^&gt;]*'.'src=[\""|\'](.*)[\""|\']/Ui';
preg_match_all($image_regex, $string, $img, PREG_PATTERN_ORDER);
$images_array = $img[1];


i have tried this .. but it give me errors in pics part 

import re
out=Data #web site html page ..
title_regex = ""/&lt;title&gt;(.+)&lt;\/title&gt;/i"" #no need for this .. un used 
m = re.search(""&lt;title&gt;(.+)&lt;\/title&gt;"", out)
print ""title"",m.group(1)
#for pics i have tried this but it give me error ..
pics = re.match(r""/&lt;img[^&gt;]*'.'src=[\""|\'](.*)[\""|\']/Ui"", out)#the conversion is not correct  
print ""grop"",pics.group(1)


my full code 

import re
import urllib
print ""Start""
url=""http://www.deviantart.com""
data=urllib.urlopen(url)
out=data.read()
print 
title_regex = ""/&lt;title&gt;(.+)&lt;\/title&gt;/i""
m = re.search(""&lt;title&gt;(.+)&lt;\/title&gt;"", out)
print ""first"",m
print ""title="",m.group(1)

title_regex = ""/&lt;title&gt;(.+)&lt;\/title&gt;/i""

pics = re.match(r""/&lt;img[^&gt;]*src=[\""|\'](.*)[\""|\']/Ui"", out)

print ""pics&gt;&gt;"",pics.group(1)


how i can convert a php re>>""/]*'.'src=\""|\'[\""|\']/Ui""  to a python re ?
","the regular expression probably did not find anything.

try this :
also remove the /Ui at the end

import re
out=Data #web site html page ..
title_regex = ""/&lt;title&gt;(.+)&lt;\/title&gt;/i"" #no need for this .. un used 
if m is not None:  #  NEW  &lt;----------------
   m = re.search(""&lt;title&gt;(.+)&lt;\/title&gt;"", out)
print ""title"",m.group(1)
#for pics i have tried this but it give me error ..
pics = re.match(r""&lt;img[^&gt;]*src=[\""|\'](.*)[\""|\']"", out)
if pics is not None: # NEW &lt;----------------
   print ""grop"",pics.group(1)


for you 2nd question try this

for filename in pics.groups():
    print filename

"
877,877,1392,Installing Theme for magento 1.9.0 pagayo,"Uploaded the files, saw it in design, put it as active today.  Cleared the cache and it didn't show, then disable the cache and it still pointing to /default vs. pt003
",Dan,https://magento.stackexchange.com/users/9621,"Go to System > Configuration > Design > Pacage and System > Configuration > Design > Package



and change some configurations.like replave yourtheme from the image with the pt003.

then save and clear cache and check frontend.
",Pradeep Sanku,https://magento.stackexchange.com/users/4556,http://magento.stackexchange.com/questions/25159/installing-theme-for-magento-1-9-0-pagayo,TECHNOLOGY,magento.stackexchange.com,0.7777777777777778,0.4444444444444444,0.0,1.0,0.3333333333333333,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,1.0,Theme page for installing Magento 1.9.0,"Uploaded the file, saw it in the design, and activated it today. Cleared the cache, but it didn't show up, then disabled the cache, which still points to / default vs.pt003","Go to System > Configuration > Design > Pacage and System > Configuration > Design > Package



and change some configurations.like replave yourtheme from the image with the pt003.

then save and clear cache and check frontend.
"
1652,1652,2605,Is there a list of Mitzvot and their corresponding body parts?,"The Talmud (Makkot 23B)and the Zohar (1:170B - unverified English translation here) say that the 248 positive commandments correspond to the 248 limbs of the human body. (The Mishna (Ohalot 1:8) lists the 248 Halachic limbs). The Talmud also says that the 365 Negative commandments correspond to the days of the year.

The Zohar adds that the 365 negative commandments also correspond to the 365 sinews in the human body (See Yonatan Ben Uziel Bereshit 1:27), and connects them to the days of the year.

R' Chaim Vital, in Shaar HaKavanot (Shaar 1, Part 1) says that ""Each of the 248 spiritual limbs gets its nourishment from a particular mitzvah that corresponds to that limb. When a person fails to perform that particular mitzvah, the corresponding limb will lack its proper nourishment..."" (translation from here)

Is there any source which tells us which limb (and/or sinew) each Mitzvah corresponds to?

As an example, the Zohar referenced above (1:170B), connects Gid Hanasheh (sciatic nerve), one of the 365 sinews, to the prohibition of eating on Tisha B'av.
",Menachem,https://judaism.stackexchange.com/users/603,"There is a little known Chassidic text published in 1834 entitled Pri Yitzchak that details all 613 Mitzvot and the corresponding limbs for positive mitzvot and 365 Gidim for negative commandments. It has not been translated from the Hebrew. It is a very sophisticated work. 

He uses the list of halachic limbs listed in the Mishna, and uses the Rambam's list of the 613 Mitzvot.

The Sefer was written by R' Yitzchak ben R' Tzvi Hersh, the Rav of the city of Shkod(?) and published by his son, Shabtai Sheptel, some years after his passing.  

The first 40 pages are available for free online, thanks to Otzar Hachachma (The other 20 are also available, but must be paid for). 

In the introduction, R' Yitzchak lays out the guidelines he used to develop this work. At the end of the introduction he says that while some of the Mitzvot and their corresponding limbs were found in various Sefarim, the majority of them were not. He decided which Mitzvot corresponded to which limbs, and as such, the list should not be considered definitive. The intent of the Sefer is to be used as a memory aid, increase the readers love and fear of G-d, and so the reader can realize how the soul of the Jewish people is connected to the whole Torah.
",david,https://judaism.stackexchange.com/users/1064,http://judaism.stackexchange.com/questions/10406/is-there-a-list-of-mitzvot-and-their-corresponding-body-parts,CULTURE,judaism.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,0.3333333333333333,1.0,1.0,0.5555555555555556,0.5555555555555556,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.7777777777777778,1.0,0.7777777777777778,1.0,0.8888888888888888,0.8,0.0,0.0,1.0,0.7777777777777778,Do you have a list of rite of passage and corresponding body parts?,"The Talmud (Makkot 23B)and the Zohar (1:170B - unverified English translation here) say that the 248 positive commandments correspond to the 248 limbs of the human body. (The Mishna (Ohalot 1:8) lists the 248 Halachic limbs). The Talmud also says that the 365 Negative commandments correspond to the days of the year.

The Zohar adds that the 365 negative commandments also correspond to the 365 sinews in the human body (See Yonatan Ben Uziel Bereshit 1:27), and connects them to the days of the year.

R' Chaim Vital, in Shaar HaKavanot (Shaar 1, Part 1) says that ""Each of the 248 spiritual limbs gets its nourishment from a particular mitzvah that corresponds to that limb. When a person fails to perform that particular mitzvah, the corresponding limb will lack its proper nourishment..."" (translation from here)

Is there any source which tells us which limb (and/or sinew) each Mitzvah corresponds to?

As an example, the Zohar referenced above (1:170B), connects Gid Hanasheh (sciatic nerve), one of the 365 sinews, to the prohibition of eating on Tisha B'av.
","There is a little known Chassidic text published in 1834 entitled Pri Yitzchak that details all 613 Mitzvot and the corresponding limbs for positive mitzvot and 365 Gidim for negative commandments. It has not been translated from the Hebrew. It is a very sophisticated work. 

He uses the list of halachic limbs listed in the Mishna, and uses the Rambam's list of the 613 Mitzvot.

The Sefer was written by R' Yitzchak ben R' Tzvi Hersh, the Rav of the city of Shkod(?) and published by his son, Shabtai Sheptel, some years after his passing.  

The first 40 pages are available for free online, thanks to Otzar Hachachma (The other 20 are also available, but must be paid for). 

In the introduction, R' Yitzchak lays out the guidelines he used to develop this work. At the end of the introduction he says that while some of the Mitzvot and their corresponding limbs were found in various Sefarim, the majority of them were not. He decided which Mitzvot corresponded to which limbs, and as such, the list should not be considered definitive. The intent of the Sefer is to be used as a memory aid, increase the readers love and fear of G-d, and so the reader can realize how the soul of the Jewish people is connected to the whole Torah.
"
835,835,1330,Converting expressions into functions,"I have defined an expression, such as

a = x


I would like to convert this into a function, such as

f[x_]:=x


However, in my case, the expression on the right-hand-side of a is rather complicated, so I do not want to manually write the expression on the right-hand-side of the function definition. I would like to write something like

f[x_]:=a


I know that this will not work. Is there a way to evaluate a in the function definition to ensure that I have actually defined a function in the end?
",Carl Morris,https://mathematica.stackexchange.com/users/2037,"In places where a function holds its arguments you can force evaluation by wrapping Evaluate. So for instance Hold[Evaluate[1+2]] will give you 3. The reson the right hand side is not evaluated is because SetDelayed has HoldAll:

 Attributes[SetDelayed]



{HoldAll, Protected, SequenceHold}



but you can simply force evaluation in the same manor:

 a = x^2
 f[x_] := Evaluate[a]

 f[k]



k^2



Depending on how much of your expression you want to evaluate this may work, but there may be cases where you need more control over the evaluation leaving some terms unevaluated until the actual function application of f. If this is the case and this doesn't work for you please extend your question.

As added by Szabolcs. Using Set rather then SetDelayed will also clear this up, since it doesn't hold its right hand side, only the left hand side (the first argument) arguments:

 Attributes[Set]



{HoldFirst, Protected, SequenceHold}



And here is a nice documentation reference again provided by Szabolcs: http://reference.wolfram.com/mathematica/tutorial/ImmediateAndDelayedDefinitions.html
",jVincent,https://mathematica.stackexchange.com/users/1194,http://mathematica.stackexchange.com/questions/14310/converting-expressions-into-functions,TECHNOLOGY,mathematica.stackexchange.com,1.0,0.4444444444444444,0.0,1.0,0.6666666666666666,1.0,0.4444444444444444,0.4444444444444444,0.3333333333333333,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.3333333333333333,0.6666666666666666,0.8888888888888888,Convert expression to function,"I have defined an expression, such as

a = x


I would like to convert this into a function, such as

f[x_]:=x


However, in my case, the expression on the right-hand-side of a is rather complicated, so I do not want to manually write the expression on the right-hand-side of the function definition. I would like to write something like

f[x_]:=a


I know that this will not work. Is there a way to evaluate a in the function definition to ensure that I have actually defined a function in the end?
","In places where a function holds its arguments you can force evaluation by wrapping Evaluate. So for instance Hold[Evaluate[1+2]] will give you 3. The reson the right hand side is not evaluated is because SetDelayed has HoldAll:

 Attributes[SetDelayed]



{HoldAll, Protected, SequenceHold}



but you can simply force evaluation in the same manor:

 a = x^2
 f[x_] := Evaluate[a]

 f[k]



k^2



Depending on how much of your expression you want to evaluate this may work, but there may be cases where you need more control over the evaluation leaving some terms unevaluated until the actual function application of f. If this is the case and this doesn't work for you please extend your question.

As added by Szabolcs. Using Set rather then SetDelayed will also clear this up, since it doesn't hold its right hand side, only the left hand side (the first argument) arguments:

 Attributes[Set]



{HoldFirst, Protected, SequenceHold}



And here is a nice documentation reference again provided by Szabolcs: http://reference.wolfram.com/mathematica/tutorial/ImmediateAndDelayedDefinitions.html
"
1912,1912,3044,Spokes keep breaking - bad hub or bad build?,"Background information

A bit of background information (I'll try keep it brief): Last year I bought an old but unused bike, 5 speeds with internal gearing.

Apparently the shop bought a lot of bikes somewhere in the 90's (not sure), but never got around to selling them. When I bought it, it was wrapped in plastic, had been stored in the shop's stock house for about 20 years and free of corrosion.

I'm about 95 kilos, thread quite hard but rides exclusive to paved bike paths. The original, 20(?) year-old wheel lasted me a year with no problems. The front wheel is still fine and true. 

Spokes breaking - and getting replaced

After a little under a year, I suddenly noticed that a few spokes had broken. On closer inspection, quite a few were too loose. Should have noticed sooner but didn't.

I took it to a shop, where they advised me to have the wheel rebuilt which I paid them to do. The gearing being internal, the new rims and spokes were built on the existing hub.

After just two weeks, the back wheel suddenly began to feel wobbly on my way to work. As careful as I could, I drove the bike back to the shop. Almost all spokes were terribly loose.

They retensioned the wheel free of charge (of course) and sent me on my way. The following weeks, I periodically checked that all spokes were still tensioned.

2,5 months later, I noticed three of the spokes were broken close to the hub. Went back to the shop and had the spokes replaced (free or charge). 1 month later I noticed 2 broken spokes and had those replaced as well. They seemed less eager to keep fixing the wheel free of charge, and when I asked why the spokes kept breaking, the guy muttered something about the hub holes maybe had burrs due to wear.

Now, a few weeks later, I find another spoke broken.

My gut tells me this all stems from a bad build, that quickly lost tension and thus damaged the spokes. I find the explanation about a worn hub a bit far fetched, but I don't have the knowledge to dismiss the theory.

Questions

Is there any way this is not the shop's fault? - A bad build? Cheap spokes? Improperly tensioned?

Given the wheel's history, is there any point in keep replacing spokes, a couple at a time, or should I get the wheel rebuilt (preferably at the shop's expense)?

Could the hub in any way be to blame for this?

Thank you!

Update Oct 24th

I've been trying to get in touch with the manager of the shop throughout the week. Failed again to reach him this morning, so I figured I'd have a chat about my problem with one of the guys on the floor.

Tried to get him to provide at least a theory of why my spokes keep breaking, but not much came out of it really. He mentioned that he've seen, on rare occasaions, that a worn hub could cut the spokes (could be the same guy as I spoke to last time).

I'll check the hubs as soon as possible, as @Daniel R Hicks suggested. Due to plumbing work in our appartment, I haven't been home or able to check my bike all week.

If I don't see any indicatations that the spokes were put in the wrong way, I'm going to follow the advice most of you have, and take my bike to another shop for advice and repair.

Thanks so far! - I'll update you after I've payed the other shop a visit.

Update Nov 3rd

Took the bike to the other shop, told them the story. Let them decide to replace the broken spoke or them all.

They decided to replace just the broken spoke with a DT spoke (what ever that means). They also trued the wheel, which had gotten a slight ""eggy"" shape.

My fingers are crossed that this wheel will last now.

Once again, thank you all for your input!

Anecdotal Update

In case anyone follows... Since the last repair at the other shop, the wheel kept being in good shape. Finally, my spokes stayed tensioned, wheels stiff and true - the long struggle was finally over. Alas, the joy didn't even last a month...

Going home from a company party, I returned to my bike I parked at the train station, only to find out that some punk kids had apparently tossed it to the ground, and jumped both wheels badly out of shape. Front wheel had to be replaced and back wheel was in desperate need for a trueing. sigh

Sorry for the melodrama, just thought I'd update you the faith of my bike ;-).
",abstrask,https://bicycles.stackexchange.com/users/3123,"If the wheel keeps on failing - for some unidentified reason - you have to review the variables: 
  - the rim 
  - the hub 
  - the spokes
  - the construction 

From your description it's probably not the rim and, like @Daniel says, 'burrs on the hub' sounds like some fake techno-jargon you're being fobbed off with. 

It certainly sounds like the spokes are failing to do the job the wheel builder is expecting of them. I'm a similar size and when I had some wheels made recently the builder used tandem spokes for their extra strength. Every little helps. 

That said, it sounds like, unless you've a particular reason to keep with them, finding another shop might keep you safe and sane - and a second opinion is rarely a bad thing in this sort of situation. 
",Unsliced,https://bicycles.stackexchange.com/users/425,http://bicycles.stackexchange.com/questions/12756/spokes-keep-breaking-bad-hub-or-bad-build,CULTURE,bicycles.stackexchange.com,0.7777777777777778,0.7777777777777778,0.0,1.0,1.0,0.6666666666666666,0.4444444444444444,0.4444444444444444,0.3333333333333333,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,0.0,0.6666666666666666,0.7777777777777778,0.6666666666666666,0.7777777777777778,0.8888888888888888,0.7333333333333333,0.3333333333333333,0.0,0.6666666666666666,0.8888888888888888,Broken spokes - broken hub or broken construction?,"Background information

A bit of background information (I'll try keep it brief): Last year I bought an old but unused bike, 5 speeds with internal gearing.

Apparently the shop bought a lot of bikes somewhere in the 90's (not sure), but never got around to selling them. When I bought it, it was wrapped in plastic, had been stored in the shop's stock house for about 20 years and free of corrosion.

I'm about 95 kilos, thread quite hard but rides exclusive to paved bike paths. The original, 20(?) year-old wheel lasted me a year with no problems. The front wheel is still fine and true. 

Spokes breaking - and getting replaced

After a little under a year, I suddenly noticed that a few spokes had broken. On closer inspection, quite a few were too loose. Should have noticed sooner but didn't.

I took it to a shop, where they advised me to have the wheel rebuilt which I paid them to do. The gearing being internal, the new rims and spokes were built on the existing hub.

After just two weeks, the back wheel suddenly began to feel wobbly on my way to work. As careful as I could, I drove the bike back to the shop. Almost all spokes were terribly loose.

They retensioned the wheel free of charge (of course) and sent me on my way. The following weeks, I periodically checked that all spokes were still tensioned.

2,5 months later, I noticed three of the spokes were broken close to the hub. Went back to the shop and had the spokes replaced (free or charge). 1 month later I noticed 2 broken spokes and had those replaced as well. They seemed less eager to keep fixing the wheel free of charge, and when I asked why the spokes kept breaking, the guy muttered something about the hub holes maybe had burrs due to wear.

Now, a few weeks later, I find another spoke broken.

My gut tells me this all stems from a bad build, that quickly lost tension and thus damaged the spokes. I find the explanation about a worn hub a bit far fetched, but I don't have the knowledge to dismiss the theory.

Questions

Is there any way this is not the shop's fault? - A bad build? Cheap spokes? Improperly tensioned?

Given the wheel's history, is there any point in keep replacing spokes, a couple at a time, or should I get the wheel rebuilt (preferably at the shop's expense)?

Could the hub in any way be to blame for this?

Thank you!

Update Oct 24th

I've been trying to get in touch with the manager of the shop throughout the week. Failed again to reach him this morning, so I figured I'd have a chat about my problem with one of the guys on the floor.

Tried to get him to provide at least a theory of why my spokes keep breaking, but not much came out of it really. He mentioned that he've seen, on rare occasaions, that a worn hub could cut the spokes (could be the same guy as I spoke to last time).

I'll check the hubs as soon as possible, as @Daniel R Hicks suggested. Due to plumbing work in our appartment, I haven't been home or able to check my bike all week.

If I don't see any indicatations that the spokes were put in the wrong way, I'm going to follow the advice most of you have, and take my bike to another shop for advice and repair.

Thanks so far! - I'll update you after I've payed the other shop a visit.

Update Nov 3rd

Took the bike to the other shop, told them the story. Let them decide to replace the broken spoke or them all.

They decided to replace just the broken spoke with a DT spoke (what ever that means). They also trued the wheel, which had gotten a slight ""eggy"" shape.

My fingers are crossed that this wheel will last now.

Once again, thank you all for your input!

Anecdotal Update

In case anyone follows... Since the last repair at the other shop, the wheel kept being in good shape. Finally, my spokes stayed tensioned, wheels stiff and true - the long struggle was finally over. Alas, the joy didn't even last a month...

Going home from a company party, I returned to my bike I parked at the train station, only to find out that some punk kids had apparently tossed it to the ground, and jumped both wheels badly out of shape. Front wheel had to be replaced and back wheel was in desperate need for a trueing. sigh

Sorry for the melodrama, just thought I'd update you the faith of my bike ;-).
","If the wheel keeps on failing - for some unidentified reason - you have to review the variables: 
  - the rim 
  - the hub 
  - the spokes
  - the construction 

From your description it's probably not the rim and, like @Daniel says, 'burrs on the hub' sounds like some fake techno-jargon you're being fobbed off with. 

It certainly sounds like the spokes are failing to do the job the wheel builder is expecting of them. I'm a similar size and when I had some wheels made recently the builder used tandem spokes for their extra strength. Every little helps. 

That said, it sounds like, unless you've a particular reason to keep with them, finding another shop might keep you safe and sane - and a second opinion is rarely a bad thing in this sort of situation. 
"
113,113,182,"How to determine if a matrix is positive/negative definite, having complex eigenvalues?","I am trying to deal with an issue: I am trying to determine the nature of some points, that's why I need to check in Matlab if a matrix with complex elements is positive or negative definite. After performing some research, I came to the following two methods:


Calculate the eigenvalues and see if it is positive/negative;

    eig(matrix)


If the eigenvalues are positive => matrix is positive definite;
Else, if eigenvalues are negative => matrix is negative definite;
Use the following function:

    [R P] = chol(matrix)


If p is 0 => you have a positive definite matrix; otherwise, your matrix is NOT positive definite.


My problem is that I have two complex eigenvalues (and  my symmetric matrix has complex elements), therefore, method 1 doesn't help me to draw any conclusion. And the method 2, doesn't give me information whether the matrix is negative definite or indefinite, because it tests only if the matrix is positive definite or not, therefore, doesn't solve my problem.

Does any one have any idea how I can check if a matrix with complex eigenvalues is positive or negative definite with other methods than the mentioned ones? Thank you.

LATER EDIT:

My function is: 11.*x1 + 22.*x1.^2.*x2 + x2.^2 + 31.*x1.^2;

I have done the partial derivative with respect to x1, x2 and I have equalized all the obtained relations with 0. Therefore, I have obtained the following system:

62*x1 + 44*x1*x2 + 11 = 0

22*x1^2 + 2*x2 = 0

from here, I got x1 having the following possible values: 
{0.333, -0.1025 + 0.2403i, -0.1025 - 0.2403i} 
and x2 having the following values: 
{-1.22, 0.5197 + 0.5417i,  0.5197 - 0.5417i}

My Hessian looks something like:

( 62+44*x2                 44*x1)

( 44*x1                    2    )

After taking the 3 possible pairs of (x1,x2) I obtain three values for the Hessian matrix. For the first (x1,x2) pair everything is ok => I have a saddle, since I have 2 real eigenvalues of opposite signs. The difficulties comes with the others, because intuitively I would say that we cannot determine the nature of those points, but I came across to the following idea, while surfing the internet for finding an explanation:

-if A belongs to Mn(C) and 

1) Re(x_star * A * x) > 0 => A positive definite.

2) Re(x_star * A * x) &lt; 0 => A negative definite.

(according to http://mathworld.wolfram.com/PositiveDefiniteMatrix.html)

So, I am a bit confused :-?
",SunnyDay,https://math.stackexchange.com/users/67286,"Well i guess for symmetric complex matrices the word ""positiv definite"" is senseless in general, for hermitian matrices there is a intepretation, we defined a matrix to be positiv definite if 
$$\langle x, A x \rangle&gt; 0$$ 
for $x\neq 0$, but this definition makes no sense when you expect complex numbers, as there is no order in the complex numbers. 

What do you mean with the nature of some points? Maybe you don't need to do that.
",Dominic Michaelis,https://math.stackexchange.com/users/62278,http://math.stackexchange.com/questions/333727/how-to-determine-if-a-matrix-is-positive-negative-definite-having-complex-eigen,SCIENCE,math.stackexchange.com,0.7777777777777778,0.6666666666666666,0.0,1.0,1.0,1.0,0.7777777777777778,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.8888888888888888,0.7777777777777778,0.5,0.8888888888888888,1.0,0.5333333333333333,0.6666666666666666,0.0,0.6666666666666666,0.7777777777777778,How to make sure that a matrix with complex eigenvalues is positive / negative definite?,"I am trying to deal with an issue: I am trying to determine the nature of some points, that's why I need to check in Matlab if a matrix with complex elements is positive or negative definite. After performing some research, I came to the following two methods:


Calculate the eigenvalues and see if it is positive/negative;

    eig(matrix)


If the eigenvalues are positive => matrix is positive definite;
Else, if eigenvalues are negative => matrix is negative definite;
Use the following function:

    [R P] = chol(matrix)


If p is 0 => you have a positive definite matrix; otherwise, your matrix is NOT positive definite.


My problem is that I have two complex eigenvalues (and  my symmetric matrix has complex elements), therefore, method 1 doesn't help me to draw any conclusion. And the method 2, doesn't give me information whether the matrix is negative definite or indefinite, because it tests only if the matrix is positive definite or not, therefore, doesn't solve my problem.

Does any one have any idea how I can check if a matrix with complex eigenvalues is positive or negative definite with other methods than the mentioned ones? Thank you.

LATER EDIT:

My function is: 11.*x1 + 22.*x1.^2.*x2 + x2.^2 + 31.*x1.^2;

I have done the partial derivative with respect to x1, x2 and I have equalized all the obtained relations with 0. Therefore, I have obtained the following system:

62*x1 + 44*x1*x2 + 11 = 0

22*x1^2 + 2*x2 = 0

from here, I got x1 having the following possible values: 
{0.333, -0.1025 + 0.2403i, -0.1025 - 0.2403i} 
and x2 having the following values: 
{-1.22, 0.5197 + 0.5417i,  0.5197 - 0.5417i}

My Hessian looks something like:

( 62+44*x2                 44*x1)

( 44*x1                    2    )

After taking the 3 possible pairs of (x1,x2) I obtain three values for the Hessian matrix. For the first (x1,x2) pair everything is ok => I have a saddle, since I have 2 real eigenvalues of opposite signs. The difficulties comes with the others, because intuitively I would say that we cannot determine the nature of those points, but I came across to the following idea, while surfing the internet for finding an explanation:

-if A belongs to Mn(C) and 

1) Re(x_star * A * x) > 0 => A positive definite.

2) Re(x_star * A * x) &lt; 0 => A negative definite.

(according to http://mathworld.wolfram.com/PositiveDefiniteMatrix.html)

So, I am a bit confused :-?
","Well i guess for symmetric complex matrices the word ""positiv definite"" is senseless in general, for hermitian matrices there is a intepretation, we defined a matrix to be positiv definite if 
$$\langle x, A x \rangle&gt; 0$$ 
for $x\neq 0$, but this definition makes no sense when you expect complex numbers, as there is no order in the complex numbers. 

What do you mean with the nature of some points? Maybe you don't need to do that.
"
162,162,256,When should a supervisor be a co-author?,"What are people's views on this?  To be specific: suppose a PhD student has produced a piece of original mathematical research. Suppose that student's supervisor suggested the problem, and gave a few helpful comments, but otherwise did not contribute to the work.  Should that supervisor still be named as a co-author, or would an acknowledgment suffice?

I am interested in two aspects of this. Firstly the moral/etiquette aspect: do you consider it bad form for a student not to name their supervisor?  Or does it depend on that supervisor's input?  And secondly, the practical, career-advancing aspect: which is better, for a student to have a well-known name on his or her paper (and hence more chance of it being noticed/published), or to have a sole-authored piece of work under their belt to hopefully increase their chances of being offered a good post-doc position?

[To clarify: original question asked by MrB ]
",MrB,https://mathoverflow.net/users/2189,"well, that depends :)

For my own students I usually do not insist on being a coauthor. However, in most cases it just happens that one works together on a project which, by accident, is the thesis of one of the persons. In my experience, I had students who worked very much on their own and then they published their stuff alone. Perfectly fair to me. On the other hand, I had students which did not just ask some questions but we really worked together as I would do it with a collegue. So in this case, there was no question that we all are on the paper, sometimes even with a third person. In these cases, the student gets already some flavour of (partially international) collaborations which I believe to be worthy.

For a diploma student (that is a sort of master thing in Germany...) I'm happy if there is a good enough outcome leading to a little paper. Usually, these students are quite happy if they don't have to do it all by themselves.

For PhD students, I have the ""rule"" that there is a big global project for the thesis which is worked on, essentially in a collaboration. But I strongly encourage the students to tell me that there is some aspect, where s/he wants to work more alone and publish also alone. In fact, for a student aiming at a very good mark in the thesis, I almost expect that s/he has a paper published alone before the thesis is finished.

So, as I said, it depends very much on the situation. I think both ways have advantages and disadvantages. Important to me is that all involved persons feel good about the policy and that things are said in the beginning. Supervising students is always a matter of trust, and this aspect is certainly one of the most delicate ones...
",Stefan Waldmann,https://mathoverflow.net/users/12482,http://mathoverflow.net/questions/57337,SCIENCE,mathoverflow.net,1.0,0.5555555555555556,1.0,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.6666666666666666,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8,0.3333333333333333,0.0,0.6666666666666666,0.8888888888888888,When should a supervisor become a coauthor?,"What are people's views on this?  To be specific: suppose a PhD student has produced a piece of original mathematical research. Suppose that student's supervisor suggested the problem, and gave a few helpful comments, but otherwise did not contribute to the work.  Should that supervisor still be named as a co-author, or would an acknowledgment suffice?

I am interested in two aspects of this. Firstly the moral/etiquette aspect: do you consider it bad form for a student not to name their supervisor?  Or does it depend on that supervisor's input?  And secondly, the practical, career-advancing aspect: which is better, for a student to have a well-known name on his or her paper (and hence more chance of it being noticed/published), or to have a sole-authored piece of work under their belt to hopefully increase their chances of being offered a good post-doc position?

[To clarify: original question asked by MrB ]
","well, that depends :)

For my own students I usually do not insist on being a coauthor. However, in most cases it just happens that one works together on a project which, by accident, is the thesis of one of the persons. In my experience, I had students who worked very much on their own and then they published their stuff alone. Perfectly fair to me. On the other hand, I had students which did not just ask some questions but we really worked together as I would do it with a collegue. So in this case, there was no question that we all are on the paper, sometimes even with a third person. In these cases, the student gets already some flavour of (partially international) collaborations which I believe to be worthy.

For a diploma student (that is a sort of master thing in Germany...) I'm happy if there is a good enough outcome leading to a little paper. Usually, these students are quite happy if they don't have to do it all by themselves.

For PhD students, I have the ""rule"" that there is a big global project for the thesis which is worked on, essentially in a collaboration. But I strongly encourage the students to tell me that there is some aspect, where s/he wants to work more alone and publish also alone. In fact, for a student aiming at a very good mark in the thesis, I almost expect that s/he has a paper published alone before the thesis is finished.

So, as I said, it depends very much on the situation. I think both ways have advantages and disadvantages. Important to me is that all involved persons feel good about the policy and that things are said in the beginning. Supervising students is always a matter of trust, and this aspect is certainly one of the most delicate ones...
"
430,430,667,Apache clustering,"I know how to run two or more tomcats under one apache server. I want to know how to run two or more apache servers in a cluster and run my application. I know it's possible. can someone suggest a simple tutorial? there are many articles for apache - tomcat integration, but not for apache clustering. :( it would be great if you guys suggested a basic tutorial. thanks.
",Senthil Kumar,https://serverfault.com/users/25438,"I'm assuming that you want to run this on multiple machines (running multiple Apache instances on the one machine makes very little sense).

Unfortunately, you can't find a simple tutorial for HA clustering because it's not a simple topic.  You've got a lot of different concepts, ranging from low-level network stuff to application-specific items like shared data storage.

I started my clustering adventures at http://linuxvirtualserver.org/.  You might like to start at http://www.linuxvirtualserver.org/architecture.html and go from there.
",womble,https://serverfault.com/users/1375,http://serverfault.com/questions/82657,TECHNOLOGY,serverfault.com,1.0,0.4444444444444444,0.0,0.5,1.0,0.5,0.4444444444444444,0.4444444444444444,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.0,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,1.0,0.3333333333333333,0.0,0.6666666666666666,0.8888888888888888,Apache cluster,"I know how to run two or more Tomcats on an Apache server. I want to know how to run two or more Apache servers in a cluster and run my application. I know it's possible. Can anyone recommend a simple tutorial? There are many articles about Apache Tomcat integration, but not about Apache clusters. It would be great if you could suggest a basic tutorial. Thank you.","I'm assuming that you want to run this on multiple machines (running multiple Apache instances on the one machine makes very little sense).

Unfortunately, you can't find a simple tutorial for HA clustering because it's not a simple topic.  You've got a lot of different concepts, ranging from low-level network stuff to application-specific items like shared data storage.

I started my clustering adventures at http://linuxvirtualserver.org/.  You might like to start at http://www.linuxvirtualserver.org/architecture.html and go from there.
"
5892,5892,9333,Questions about geometric distribution,"I have some trouble understanding the record value for a sequence of i.i.d. random variables of geometric distribution. Following quotation is from Univariate discrete distributions By Norman Lloyd Johnson, Adrienne W. Kemp, Samuel Kotz.


  The lack-of-memory property of the
  geometric distribution gives it a role
  comparable to that of the exponential
  distribution. There are a number of
  characterizations of the geometric
  distribution based on record values.



For the  record time $T_n$, 


  If $X_j$ is observed at time $j$ ,
  then the record time sequence $\{T_n ,n \geq 0\}$ is defined as
  $T_0 = 1$
  with probability $1$ and $T_n = \min\{j : X_j &gt; X_{t_{n−1}} \}$ for
  $n\geq 1$. 


Is there a typo in $T_n = \min \{j : X_j &gt;
    X_{t_{n−1}} \}$? Should it be instead $T_n
    = \min\{j : X_j &gt; X_{T_{n−1}} \}$?
For the  record value $R_n$, 


  The record value sequence
  $\{R_n \}$ is defined as $R_n =X_{T_n} , n = 0, 1, 2, ...$. Suppose
  that the $X_j$ ’s are iid geometric
  variables with pmf $$p_x = p(1 − p)^{x−1}, x = 1, 2, ...$$ Then $R_n
    =X_{T_n} = \sum_{j=0}^{n} X_j$ is
  distributed as the sum of $n + 1$ iid
  geometric variables.


why does the second equality in
""$R_n =X_{T_n} = \sum_{j=0}^{n} X_j$
"" hold?
For the process of the record values
$\{ R_n, n \in \mathbb{N}\}$, 


  Each of the following properties
  characterizes the geometric
  distribution: 
  
  (i) Independence: The rv’s $R_0 , R_1  - R_0 , ... , R_{n+1} - R_n ,...$ are independent. 
  
  (ii) Same Distribution: $R_{n+1} - R_n$ has the same distribution as
  $R_0$ . 
  
  (iii) Constant Regression: $E[R_{n+1}- R_n |R_n ]$ is constant.


How to show that the three
properties hold? Are they derived
from the memoryless property of
geometric distribution?

What else can we say about the
process based on the memoryless
property of geometric distribution?


Thanks for your advice!
",Ethan,https://math.stackexchange.com/users/3616,"Your second point looks wrong in the book.  I think
$$R_n = X_{T_n} = X_{T_0} + \sum_{i=1}^n \left(X_{T_i} - X_{T_{i-1}}\right)$$ 
or 
$$R_n = X_{T_n} = R_0 + \sum_{i=1}^n (R_i - R_{i-1})$$
might be better (and obvious).  

Since $T_0 = 1$, $R_0 = X_{T_0} = X_1$, identically distributed as each of the $X_j$. 

This is where the memorylessness of the geometric distribution applies, because it has the property that $R_n - R_{n-1} = X_{T_n} - X_{T_{n-1}}$ has the same distribution as $X_j$ because if $X_{T_{n-1}} = k$ then
$$Pr(X_{T_n} - X_{T_{n-1}} = m) = Pr(X_{T_n} = m+k | X_{T_n} &gt; k) = \frac{p(1 − p)^{m+k−1}}{\sum_{j \ge 1} p(1 − p)^{j+k−1} } = p(1 − p)^{m−1}$$
and is independent of k and of all the $X_j$ for $j &lt; T_{n-1}$ and $j&gt;T_n$

So $R_j - R_{j-1}$ has the same distribution as $X_j$ and combined with independence leads to $R_n$ having the same distribution as $\sum_{j=0}^n X_j$, i.e. 


  as the sum of $n + 1$ iid geometric variables.


as the book says.

I think the book is wrong with its equals sign: two (sums of) random variables can have the same distribution without being the same.  If $A$ is uniformly distributed on $[0,1]$ and $B = 1-A$, then $A$ and $B$ have the same distribution, but they are unlikely to be equal to each other. 
",Henry,https://math.stackexchange.com/users/6460,http://math.stackexchange.com/questions/26386/questions-about-geometric-distribution,SCIENCE,math.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,1.0,0.5555555555555556,0.3333333333333333,1.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,1.0,0.0,0.3333333333333333,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.3333333333333333,0.0,1.0,1.0,The problem of geometric distribution,"I have some trouble understanding the record value for a sequence of i.i.d. random variables of geometric distribution. Following quotation is from Univariate discrete distributions By Norman Lloyd Johnson, Adrienne W. Kemp, Samuel Kotz.


  The lack-of-memory property of the
  geometric distribution gives it a role
  comparable to that of the exponential
  distribution. There are a number of
  characterizations of the geometric
  distribution based on record values.



For the  record time $T_n$, 


  If $X_j$ is observed at time $j$ ,
  then the record time sequence $\{T_n ,n \geq 0\}$ is defined as
  $T_0 = 1$
  with probability $1$ and $T_n = \min\{j : X_j &gt; X_{t_{n−1}} \}$ for
  $n\geq 1$. 


Is there a typo in $T_n = \min \{j : X_j &gt;
    X_{t_{n−1}} \}$? Should it be instead $T_n
    = \min\{j : X_j &gt; X_{T_{n−1}} \}$?
For the  record value $R_n$, 


  The record value sequence
  $\{R_n \}$ is defined as $R_n =X_{T_n} , n = 0, 1, 2, ...$. Suppose
  that the $X_j$ ’s are iid geometric
  variables with pmf $$p_x = p(1 − p)^{x−1}, x = 1, 2, ...$$ Then $R_n
    =X_{T_n} = \sum_{j=0}^{n} X_j$ is
  distributed as the sum of $n + 1$ iid
  geometric variables.


why does the second equality in
""$R_n =X_{T_n} = \sum_{j=0}^{n} X_j$
"" hold?
For the process of the record values
$\{ R_n, n \in \mathbb{N}\}$, 


  Each of the following properties
  characterizes the geometric
  distribution: 
  
  (i) Independence: The rv’s $R_0 , R_1  - R_0 , ... , R_{n+1} - R_n ,...$ are independent. 
  
  (ii) Same Distribution: $R_{n+1} - R_n$ has the same distribution as
  $R_0$ . 
  
  (iii) Constant Regression: $E[R_{n+1}- R_n |R_n ]$ is constant.


How to show that the three
properties hold? Are they derived
from the memoryless property of
geometric distribution?

What else can we say about the
process based on the memoryless
property of geometric distribution?


Thanks for your advice!
","Your second point looks wrong in the book.  I think
$$R_n = X_{T_n} = X_{T_0} + \sum_{i=1}^n \left(X_{T_i} - X_{T_{i-1}}\right)$$ 
or 
$$R_n = X_{T_n} = R_0 + \sum_{i=1}^n (R_i - R_{i-1})$$
might be better (and obvious).  

Since $T_0 = 1$, $R_0 = X_{T_0} = X_1$, identically distributed as each of the $X_j$. 

This is where the memorylessness of the geometric distribution applies, because it has the property that $R_n - R_{n-1} = X_{T_n} - X_{T_{n-1}}$ has the same distribution as $X_j$ because if $X_{T_{n-1}} = k$ then
$$Pr(X_{T_n} - X_{T_{n-1}} = m) = Pr(X_{T_n} = m+k | X_{T_n} &gt; k) = \frac{p(1 − p)^{m+k−1}}{\sum_{j \ge 1} p(1 − p)^{j+k−1} } = p(1 − p)^{m−1}$$
and is independent of k and of all the $X_j$ for $j &lt; T_{n-1}$ and $j&gt;T_n$

So $R_j - R_{j-1}$ has the same distribution as $X_j$ and combined with independence leads to $R_n$ having the same distribution as $\sum_{j=0}^n X_j$, i.e. 


  as the sum of $n + 1$ iid geometric variables.


as the book says.

I think the book is wrong with its equals sign: two (sums of) random variables can have the same distribution without being the same.  If $A$ is uniformly distributed on $[0,1]$ and $B = 1-A$, then $A$ and $B$ have the same distribution, but they are unlikely to be equal to each other. 
"
5657,5657,8971,Do I need a visa to visit Belarus if I have a Russian visa?,"I am a U.S. citizen living in Russia with a multi-entry student visa. I noticed that on my migration card it lists the Russian Federation as well as the Republic of Belarus. Do I need to get another visa if I want to visit Belarus, or is what I already have sufficient?
",Peter Olson,https://travel.stackexchange.com/users/1107,"In short the answer is yes you do need a separate visa for Belarus.  Your Russian Student Visa doesn't allow you to enter Belarus.

The reason that it has the names of both countries is because the form they use is exactly the same.  From the US Embassy in Moscow:


  Although Russia and Belarus use the same migration card, travelers should be aware that each country maintains its own visa regime.  U.S. citizens wishing to travel to both nations must apply for two separate visas.  A traveler entering Russia directly from Belarus is not required to obtain a new migration card, but at his or her option may do so if blank ones are available at the time of entry.

",Karlson,https://travel.stackexchange.com/users/1372,http://travel.stackexchange.com/questions/24684/do-i-need-a-visa-to-visit-belarus-if-i-have-a-russian-visa,CULTURE,travel.stackexchange.com,1.0,0.3333333333333333,0.0,0.3333333333333333,1.0,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.3333333333333333,0.0,1.0,0.8888888888888888,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,1.0,"If I have a Russian visa, do I need a visa to go to Belarus?","I am a U.S. citizen living in Russia and hold a multi entry student visa. I note that there are lists of the Russian Federation and the Republic of Belarus on my immigration card. If I want to go to Belarus, do I need to apply for another visa? Or do I have enough visas?","In short the answer is yes you do need a separate visa for Belarus.  Your Russian Student Visa doesn't allow you to enter Belarus.

The reason that it has the names of both countries is because the form they use is exactly the same.  From the US Embassy in Moscow:


  Although Russia and Belarus use the same migration card, travelers should be aware that each country maintains its own visa regime.  U.S. citizens wishing to travel to both nations must apply for two separate visas.  A traveler entering Russia directly from Belarus is not required to obtain a new migration card, but at his or her option may do so if blank ones are available at the time of entry.

"
2602,2602,4140,Triac circuit confusion,"X1Iz.png

I have the following questions about the above circuit:

-Why are we even using a trica/diac combo above. Why would a circuit consisting of just the fuse, switch and primary not be sufficient for charging the battery?

-If we do go ahead with the above combo, what is the use of the resistor/capacitor combo attached in parallel above the triac?

Thanks
giv
",givknow,https://electronics.stackexchange.com/users/62399,"The circuit attached to the primary of the transformer is a phase chopper or ""dimmer"" which would reduce the power the transformer is getting (and thus delivering to the load) according to the selected value of the variable resistance.

The way a phase chopper works is delaying when the triac turns on each cycle, the variable resistor charges the capacitor until it reaches the breakdown voltage of the diac and then the triac turns on.
",Gabe,https://electronics.stackexchange.com/users/69414,http://electronics.stackexchange.com/questions/158662/triac-circuit-confusion,TECHNOLOGY,electronics.stackexchange.com,0.8888888888888888,0.4444444444444444,0.0,0.6666666666666666,1.0,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.0,0.6666666666666666,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.3333333333333333,1.0,0.0,0.6666666666666666,1.0,0.5555555555555556,1.0,1.0,0.8666666666666666,0.0,0.0,1.0,1.0,Triac circuit confusion,"X1Iz.png

I have the following questions about the above circuit:

-Why are we even using a trica/diac combo above. Why would a circuit consisting of just the fuse, switch and primary not be sufficient for charging the battery?

-If we do go ahead with the above combo, what is the use of the resistor/capacitor combo attached in parallel above the triac?

Thanks
giv
","The circuit attached to the primary of the transformer is a phase chopper or ""dimmer"" which would reduce the power the transformer is getting (and thus delivering to the load) according to the selected value of the variable resistance.

The way a phase chopper works is delaying when the triac turns on each cycle, the variable resistor charges the capacitor until it reaches the breakdown voltage of the diac and then the triac turns on.
"
2891,2891,4600,What is the difference between drought resistant non-succulent plants and plants that cannot be allowed to dry out?,"What features make one plant able to withstand dry spells better than another with relatively similar structure? For instance, one of my Rudbeckias is wilting from drought at the moment, and an Oenothera next to it is not yet showing signs of dryness.

Or like jewelweed (Impatiens capensis), which wilts even while the soil is damp, in full sun, and ragweed (Ambrosia artemisiifolia), which will grow in very dry locations without being phased.

Is it caused by a faster transpiration rate in some plants than in others?
",J. Musser,https://biology.stackexchange.com/users/338,"The difference may be related to how the plants fix carbon. While all plants convert CO₂ and H₂O to glucose and oxygen, there are at least three pathways that are used to do it. The C3 pathway is older and less efficient than the CAM and C4 pathways. Many drought tolerant plants use the CAM or C4 pathways because less water is needed. The C4 pathway is better than C3 in drier climates, hotter climates, and when CO₂ or nitrogen are limited. The hard part about this answer is that I'm not a botanist. Wikipedia lists some plants that use C4, CAM, and C3, but there is no comprehensive list, so I can't match up all the plants you mentioned in your question. In general, a higher percentage of monocots, especially grasses, use C4, but a wider diversity of dicots use C4. But you still can't draw conclusions about families of plants, because while corn and sorghum use C4, rice and barley use C3. Ragweed, a plant you say grows well in dry conditions, is a member of Asteraceae, which includes many plants that use C4. However, rudbeckias are also members of Asteraceae, but don't do as well in dry conditions. The C4 pathway has appeared and disappeared in several different plants, making any general claim hard to make. Here are some links that might help:


http://www.en.wikipedia.org/wiki/C4_carbon_fixation   
http://www.en.wikipedia.org/wiki/C3_carbon_fixation   
http://www.en.wikipedia.org/wiki/Crassulacean_acid_metabolism
http://www.brown.edu/Research/Edwards_Lab/reprints/sage_etal_2011jexb.pdf


If you know more about plants than me, that last link might be helpful, it's about the evolution of C4 pathway in plants and includes lists, but uses the formal species names I just don't recognize.
",user137,https://biology.stackexchange.com/users/4747,http://biology.stackexchange.com/questions/19545/what-is-the-difference-between-drought-resistant-non-succulent-plants-and-plants,SCIENCE,biology.stackexchange.com,1.0,0.6666666666666666,0.0,0.3333333333333333,1.0,1.0,0.5555555555555556,0.5555555555555556,1.0,0.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.8888888888888888,1.0,0.8888888888888888,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,0.8888888888888888,What's the difference between drought tolerant non fleshy plants and dry plants?,"What features make one plant able to withstand dry spells better than another with relatively similar structure? For instance, one of my Rudbeckias is wilting from drought at the moment, and an Oenothera next to it is not yet showing signs of dryness.

Or like jewelweed (Impatiens capensis), which wilts even while the soil is damp, in full sun, and ragweed (Ambrosia artemisiifolia), which will grow in very dry locations without being phased.

Is it caused by a faster transpiration rate in some plants than in others?
","The difference may be related to how the plants fix carbon. While all plants convert CO₂ and H₂O to glucose and oxygen, there are at least three pathways that are used to do it. The C3 pathway is older and less efficient than the CAM and C4 pathways. Many drought tolerant plants use the CAM or C4 pathways because less water is needed. The C4 pathway is better than C3 in drier climates, hotter climates, and when CO₂ or nitrogen are limited. The hard part about this answer is that I'm not a botanist. Wikipedia lists some plants that use C4, CAM, and C3, but there is no comprehensive list, so I can't match up all the plants you mentioned in your question. In general, a higher percentage of monocots, especially grasses, use C4, but a wider diversity of dicots use C4. But you still can't draw conclusions about families of plants, because while corn and sorghum use C4, rice and barley use C3. Ragweed, a plant you say grows well in dry conditions, is a member of Asteraceae, which includes many plants that use C4. However, rudbeckias are also members of Asteraceae, but don't do as well in dry conditions. The C4 pathway has appeared and disappeared in several different plants, making any general claim hard to make. Here are some links that might help:


http://www.en.wikipedia.org/wiki/C4_carbon_fixation   
http://www.en.wikipedia.org/wiki/C3_carbon_fixation   
http://www.en.wikipedia.org/wiki/Crassulacean_acid_metabolism
http://www.brown.edu/Research/Edwards_Lab/reprints/sage_etal_2011jexb.pdf


If you know more about plants than me, that last link might be helpful, it's about the evolution of C4 pathway in plants and includes lists, but uses the formal species names I just don't recognize.
"
1422,1422,2233,Show tooltip on invalid input in edit control,"I have subclassed edit control to accept only floating numbers. I would like to pop a tooltip when user makes an invalid input. The behavior I target is like the one edit control with ES_NUMBER has :



So far I was able to implement tracking tooltip and display it when user makes invalid input.

However, the tooltip is misplaced. I have tried to use ScreenToClient and ClientToScreen to fix this but have failed.

Here are the instructions for creating SCCE :

1) Create default Win32 project in Visual Studio.

2) Add the following includes in your stdafx.h, just under #include &lt;windows.h&gt; :

#include &lt;windowsx.h&gt;
#include &lt;commctrl.h&gt;

#pragma comment( lib, ""comctl32.lib"")

#pragma comment(linker, \
    ""\""/manifestdependency:type='Win32' ""\
    ""name='Microsoft.Windows.Common-Controls' ""\
    ""version='6.0.0.0' ""\
    ""processorArchitecture='*' ""\
    ""publicKeyToken='6595b64144ccf1df' ""\
    ""language='*'\"""")


3) Add these global variables:

HWND g_hwndTT;
TOOLINFO g_ti;


4) Here is a simple subclass procedure for edit controls ( just for testing purposes ) :

LRESULT CALLBACK EditSubProc ( HWND hwnd, UINT message, 
    WPARAM wParam, LPARAM lParam, 
    UINT_PTR uIdSubclass, DWORD_PTR dwRefData )
{
    switch (message)
    {
    case WM_CHAR:
        {
            POINT pt;
            if( ! isdigit( wParam ) )  // if not a number pop a tooltip!
            {
                if (GetCaretPos(&amp;pt))  // here comes the problem
                {
                    // coordinates are not good, so tooltip is misplaced
                    ClientToScreen( hwnd, &amp;pt );


                    /************************** EDIT #1 ****************************/
                    /******* If I delete this line x-coordinate is OK *************/
                    /*** y-coordinate should be little lower, but it is still OK **/
                    /**************************************************************/

                    ScreenToClient( GetParent(hwnd), &amp;pt );

                    /************************* Edit #2 ****************************/

                    // this adjusts the y-coordinate, see the second edit
                    RECT rcClientRect;
                    Edit_GetRect( hwnd, &amp;rcClientRect );
                    pt.y = rcClientRect.bottom;

                    /**************************************************************/

                    SendMessage(g_hwndTT, TTM_TRACKACTIVATE, 
                        TRUE, (LPARAM)&amp;g_ti);
                    SendMessage(g_hwndTT, TTM_TRACKPOSITION, 
                        0, MAKELPARAM(pt.x, pt.y));
                }
                return FALSE;
            }
            else
            {
                SendMessage(g_hwndTT, TTM_TRACKACTIVATE, 
                    FALSE, (LPARAM)&amp;g_ti);
                return ::DefSubclassProc( hwnd, message, wParam, lParam );
            }
        }
        break;
    case WM_NCDESTROY:
        ::RemoveWindowSubclass( hwnd, EditSubProc, 0 );
        return DefSubclassProc( hwnd, message, wParam, lParam);
        break;
    }
    return DefSubclassProc( hwnd, message, wParam, lParam);
} 


5) Add the following WM_CREATE handler :

case WM_CREATE:
    {
        HWND hEdit = CreateWindowEx( 0, L""EDIT"", L""edit"", WS_CHILD | WS_VISIBLE |
            WS_BORDER | ES_CENTER, 150, 150, 100, 30, hWnd, (HMENU)1000, hInst, 0 );

        // try with tooltip
        g_hwndTT = CreateWindow(TOOLTIPS_CLASS, NULL,
            WS_POPUP | TTS_ALWAYSTIP | TTS_BALLOON,
            0, 0, 0, 0, hWnd, NULL, hInst, NULL);

        if( !g_hwndTT )
            MessageBeep(0);  // just to signal error somehow

        g_ti.cbSize = sizeof(TOOLINFO);
        g_ti.uFlags = TTF_TRACK | TTF_ABSOLUTE;
        g_ti.hwnd = hWnd;
        g_ti.hinst = hInst;
        g_ti.lpszText = TEXT(""Hi there"");

        if( ! SendMessage(g_hwndTT, TTM_ADDTOOL, 0, (LPARAM)&amp;g_ti) )
            MessageBeep(0);  // just to have some error signal

        // subclass edit control
        SetWindowSubclass( hEdit, EditSubProc, 0, 0 );
    }
    return 0L;  


6) Initialize common controls in MyRegisterClass ( before return statement ) :

// initialize common controls
INITCOMMONCONTROLSEX iccex;
iccex.dwSize = sizeof(INITCOMMONCONTROLSEX);
iccex.dwICC = ICC_BAR_CLASSES | ICC_WIN95_CLASSES | 
    ICC_TAB_CLASSES | ICC_TREEVIEW_CLASSES | ICC_STANDARD_CLASSES ;

if( !InitCommonControlsEx(&amp;iccex) ) 
    MessageBeep(0);   // signal error 


That's it, for the SSCCE.

My questions are following :


How can I properly position tooltip in my main window? How should I manipulate with caret coordinates?
Is there a way for tooltip handle and toolinfo structure to not be global?


Thank you for your time.

Best regards. 

EDIT #1:

I have managed to achieve quite an improvement by deleting ScreenToClient call in the subclass procedure. The x-coordinate is good, y-coordinate could be slightly lower. I still would like to remove global variables somehow...

EDIT #2:

I was able to adjust y-coordinate by using EM_GETRECT message and setting y-coordinate to the bottom of the formatting rectangle:

RECT rcClientRect;
Edit_GetRect( hwnd, &amp;rcClientRect );
pt.y = rcClient.bottom;


Now the end-result is much better. All that is left is to remove global variables...

EDIT #3:

It seems that I have cracked it! The solution is in EM_SHOWBALLOONTIP and EM_HIDEBALLOONTIP messages! Tooltip is placed at the caret position, ballon shape is the same as the one on the picture, and it auto-dismisses itself properly. And the best thing is that I do not need global variables!

Here is my subclass procedure snippet:

case WM_CHAR:
{
    // whatever... This condition is for testing purpose only
    if( ! IsCharAlpha( wParam ) &amp;&amp; IsCharAlphaNumeric( wParam ) )
    {
        SendMessage(hwnd, EM_HIDEBALLOONTIP, 0, 0);
        return ::DefSubclassProc( hwnd, message, wParam, lParam );
    }
    else
    {
        EDITBALLOONTIP ebt;

        ebt.cbStruct = sizeof( EDITBALLOONTIP );
        ebt.pszText = L"" Tooltip text! "";
        ebt.pszTitle = L"" Tooltip title!!! "";
        ebt.ttiIcon = TTI_ERROR_LARGE;    // tooltip icon

        SendMessage(hwnd, EM_SHOWBALLOONTIP, 0, (LPARAM)&amp;ebt);

        return FALSE;
    }
 }
 break;

",AlwaysLearningNewStuff,https://stackoverflow.com/users/2676466,"After further testing, I have decided to put this as an answer so others can clearly spot it. 

The solution is in using EM_SHOWBALLOONTIP and EM_HIDEBALLOONTIP messages. You do not need to create tooltip and associate it to an edit control! Therefore, all I need to do now is simply subclass edit control and everything works :

LRESULT CALLBACK EditSubProc ( HWND hwnd, UINT message, 
WPARAM wParam, LPARAM lParam, 
UINT_PTR uIdSubclass, DWORD_PTR dwRefData )
{
    switch (message)
    {
    case WM_CHAR:
        {
            if( ! isdigit( wParam ) )  // if not a number pop a tooltip!
            {
                EDITBALLOONTIP ebt;

                ebt.cbStruct = sizeof( EDITBALLOONTIP );
                ebt.pszText = L"" Tooltip text! "";
                ebt.pszTitle = L"" Tooltip title!!! "";
                ebt.ttiIcon = TTI_ERROR_LARGE;    // tooltip icon

                SendMessage(hwnd, EM_SHOWBALLOONTIP, 0, (LPARAM)&amp;ebt);
                return FALSE;
            }
            else
            {
                SendMessage(hwnd, EM_HIDEBALLOONTIP, 0, 0);
                return ::DefSubclassProc( hwnd, message, wParam, lParam );
            }
        }
        break;
    case WM_NCDESTROY:
        ::RemoveWindowSubclass( hwnd, EditSubProc, 0 );
        return DefSubclassProc( hwnd, message, wParam, lParam);
        break;
    }
    return DefSubclassProc( hwnd, message, wParam, lParam);
} 


That's it!

Hopefully this answer will help someone too!
",AlwaysLearningNewStuff,https://stackoverflow.com/users/2676466,http://stackoverflow.com/questions/23892594/show-tooltip-on-invalid-input-in-edit-control,STACKOVERFLOW,stackoverflow.com,1.0,0.5,0.0,0.5,1.0,1.0,0.3333333333333333,0.3333333333333333,1.0,0.0,0.5,0.5,0.0,0.0,0.0,0.0,1.0,0.5,0.0,0.0,0.8333333333333334,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.5,0.0,0.8333333333333334,Show tooltips for invalid input in the edit control,"I have subclassed edit control to accept only floating numbers. I would like to pop a tooltip when user makes an invalid input. The behavior I target is like the one edit control with ES_NUMBER has :



So far I was able to implement tracking tooltip and display it when user makes invalid input.

However, the tooltip is misplaced. I have tried to use ScreenToClient and ClientToScreen to fix this but have failed.

Here are the instructions for creating SCCE :

1) Create default Win32 project in Visual Studio.

2) Add the following includes in your stdafx.h, just under #include &lt;windows.h&gt; :

#include &lt;windowsx.h&gt;
#include &lt;commctrl.h&gt;

#pragma comment( lib, ""comctl32.lib"")

#pragma comment(linker, \
    ""\""/manifestdependency:type='Win32' ""\
    ""name='Microsoft.Windows.Common-Controls' ""\
    ""version='6.0.0.0' ""\
    ""processorArchitecture='*' ""\
    ""publicKeyToken='6595b64144ccf1df' ""\
    ""language='*'\"""")


3) Add these global variables:

HWND g_hwndTT;
TOOLINFO g_ti;


4) Here is a simple subclass procedure for edit controls ( just for testing purposes ) :

LRESULT CALLBACK EditSubProc ( HWND hwnd, UINT message, 
    WPARAM wParam, LPARAM lParam, 
    UINT_PTR uIdSubclass, DWORD_PTR dwRefData )
{
    switch (message)
    {
    case WM_CHAR:
        {
            POINT pt;
            if( ! isdigit( wParam ) )  // if not a number pop a tooltip!
            {
                if (GetCaretPos(&amp;pt))  // here comes the problem
                {
                    // coordinates are not good, so tooltip is misplaced
                    ClientToScreen( hwnd, &amp;pt );


                    /************************** EDIT #1 ****************************/
                    /******* If I delete this line x-coordinate is OK *************/
                    /*** y-coordinate should be little lower, but it is still OK **/
                    /**************************************************************/

                    ScreenToClient( GetParent(hwnd), &amp;pt );

                    /************************* Edit #2 ****************************/

                    // this adjusts the y-coordinate, see the second edit
                    RECT rcClientRect;
                    Edit_GetRect( hwnd, &amp;rcClientRect );
                    pt.y = rcClientRect.bottom;

                    /**************************************************************/

                    SendMessage(g_hwndTT, TTM_TRACKACTIVATE, 
                        TRUE, (LPARAM)&amp;g_ti);
                    SendMessage(g_hwndTT, TTM_TRACKPOSITION, 
                        0, MAKELPARAM(pt.x, pt.y));
                }
                return FALSE;
            }
            else
            {
                SendMessage(g_hwndTT, TTM_TRACKACTIVATE, 
                    FALSE, (LPARAM)&amp;g_ti);
                return ::DefSubclassProc( hwnd, message, wParam, lParam );
            }
        }
        break;
    case WM_NCDESTROY:
        ::RemoveWindowSubclass( hwnd, EditSubProc, 0 );
        return DefSubclassProc( hwnd, message, wParam, lParam);
        break;
    }
    return DefSubclassProc( hwnd, message, wParam, lParam);
} 


5) Add the following WM_CREATE handler :

case WM_CREATE:
    {
        HWND hEdit = CreateWindowEx( 0, L""EDIT"", L""edit"", WS_CHILD | WS_VISIBLE |
            WS_BORDER | ES_CENTER, 150, 150, 100, 30, hWnd, (HMENU)1000, hInst, 0 );

        // try with tooltip
        g_hwndTT = CreateWindow(TOOLTIPS_CLASS, NULL,
            WS_POPUP | TTS_ALWAYSTIP | TTS_BALLOON,
            0, 0, 0, 0, hWnd, NULL, hInst, NULL);

        if( !g_hwndTT )
            MessageBeep(0);  // just to signal error somehow

        g_ti.cbSize = sizeof(TOOLINFO);
        g_ti.uFlags = TTF_TRACK | TTF_ABSOLUTE;
        g_ti.hwnd = hWnd;
        g_ti.hinst = hInst;
        g_ti.lpszText = TEXT(""Hi there"");

        if( ! SendMessage(g_hwndTT, TTM_ADDTOOL, 0, (LPARAM)&amp;g_ti) )
            MessageBeep(0);  // just to have some error signal

        // subclass edit control
        SetWindowSubclass( hEdit, EditSubProc, 0, 0 );
    }
    return 0L;  


6) Initialize common controls in MyRegisterClass ( before return statement ) :

// initialize common controls
INITCOMMONCONTROLSEX iccex;
iccex.dwSize = sizeof(INITCOMMONCONTROLSEX);
iccex.dwICC = ICC_BAR_CLASSES | ICC_WIN95_CLASSES | 
    ICC_TAB_CLASSES | ICC_TREEVIEW_CLASSES | ICC_STANDARD_CLASSES ;

if( !InitCommonControlsEx(&amp;iccex) ) 
    MessageBeep(0);   // signal error 


That's it, for the SSCCE.

My questions are following :


How can I properly position tooltip in my main window? How should I manipulate with caret coordinates?
Is there a way for tooltip handle and toolinfo structure to not be global?


Thank you for your time.

Best regards. 

EDIT #1:

I have managed to achieve quite an improvement by deleting ScreenToClient call in the subclass procedure. The x-coordinate is good, y-coordinate could be slightly lower. I still would like to remove global variables somehow...

EDIT #2:

I was able to adjust y-coordinate by using EM_GETRECT message and setting y-coordinate to the bottom of the formatting rectangle:

RECT rcClientRect;
Edit_GetRect( hwnd, &amp;rcClientRect );
pt.y = rcClient.bottom;


Now the end-result is much better. All that is left is to remove global variables...

EDIT #3:

It seems that I have cracked it! The solution is in EM_SHOWBALLOONTIP and EM_HIDEBALLOONTIP messages! Tooltip is placed at the caret position, ballon shape is the same as the one on the picture, and it auto-dismisses itself properly. And the best thing is that I do not need global variables!

Here is my subclass procedure snippet:

case WM_CHAR:
{
    // whatever... This condition is for testing purpose only
    if( ! IsCharAlpha( wParam ) &amp;&amp; IsCharAlphaNumeric( wParam ) )
    {
        SendMessage(hwnd, EM_HIDEBALLOONTIP, 0, 0);
        return ::DefSubclassProc( hwnd, message, wParam, lParam );
    }
    else
    {
        EDITBALLOONTIP ebt;

        ebt.cbStruct = sizeof( EDITBALLOONTIP );
        ebt.pszText = L"" Tooltip text! "";
        ebt.pszTitle = L"" Tooltip title!!! "";
        ebt.ttiIcon = TTI_ERROR_LARGE;    // tooltip icon

        SendMessage(hwnd, EM_SHOWBALLOONTIP, 0, (LPARAM)&amp;ebt);

        return FALSE;
    }
 }
 break;

","After further testing, I have decided to put this as an answer so others can clearly spot it. 

The solution is in using EM_SHOWBALLOONTIP and EM_HIDEBALLOONTIP messages. You do not need to create tooltip and associate it to an edit control! Therefore, all I need to do now is simply subclass edit control and everything works :

LRESULT CALLBACK EditSubProc ( HWND hwnd, UINT message, 
WPARAM wParam, LPARAM lParam, 
UINT_PTR uIdSubclass, DWORD_PTR dwRefData )
{
    switch (message)
    {
    case WM_CHAR:
        {
            if( ! isdigit( wParam ) )  // if not a number pop a tooltip!
            {
                EDITBALLOONTIP ebt;

                ebt.cbStruct = sizeof( EDITBALLOONTIP );
                ebt.pszText = L"" Tooltip text! "";
                ebt.pszTitle = L"" Tooltip title!!! "";
                ebt.ttiIcon = TTI_ERROR_LARGE;    // tooltip icon

                SendMessage(hwnd, EM_SHOWBALLOONTIP, 0, (LPARAM)&amp;ebt);
                return FALSE;
            }
            else
            {
                SendMessage(hwnd, EM_HIDEBALLOONTIP, 0, 0);
                return ::DefSubclassProc( hwnd, message, wParam, lParam );
            }
        }
        break;
    case WM_NCDESTROY:
        ::RemoveWindowSubclass( hwnd, EditSubProc, 0 );
        return DefSubclassProc( hwnd, message, wParam, lParam);
        break;
    }
    return DefSubclassProc( hwnd, message, wParam, lParam);
} 


That's it!

Hopefully this answer will help someone too!
"
5726,5726,9071,Can only access one of the router's web portal and the Internet,"On both wired and wireless connections, I can only access one of 192.168.1.1 (the router web portal) and the general Internet.  Which ""mode"" my devices are in is seemingly random.  This has persisted so far for 5 days (since I began using this network).

When connected to the Internet, I can go to 192.168.102.1 and I see a landing page for ""mikrotik routeros"", but I cannot go to 192.168.1.1. When connected to the router but not the Internet, 192.168.1.1 yields the router web portal, and 192.168.102.1 is inaccessible.

Attempted solutions


Upgrading router firmware  
Resetting router to factory settings  
Rebooting devices  
Fiddling with router settings (changing wireless security modes, removing wireless security, etc)  
Upgrading wireless drivers on computers  


Some data


Affects BlackBerry, Windows, Android and Ubuntu devices
All devices work properly on other networks
Devices may switch modes if they have been offline for a long time (eg: overnight), but restarting a device has no effect
Router is TP-Link TL-WR740N v4
Router firmware DD-WRT v24-sp2 (04/18/14) std - build 23919
Both wired and wireless connections are affected, but not necessarily simultaneously


I don't know anything about networking, but here's some info that seems helpful taken from my Ubuntu laptop.

With internet access (wired in this case, but it varies):

~ $ route -n
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
0.0.0.0         192.168.102.1   0.0.0.0         UG    0      0        0 eth0
192.168.102.0   0.0.0.0         255.255.254.0   U     1      0        0 eth0

~ $ ifconfig
eth0      Link encap:Ethernet  HWaddr 54:ee:75:0c:02:80  
          inet addr:192.168.103.232  Bcast:192.168.103.255  Mask:255.255.254.0
          inet6 addr: fe80::56ee:75ff:fe0c:280/64 Scope:Link
          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
          RX packets:3273 errors:0 dropped:0 overruns:0 frame:0
          TX packets:3035 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:1000 
          RX bytes:2276482 (2.2 MB)  TX bytes:517732 (517.7 KB)
          Interrupt:20 Memory:f0500000-f0520000 

lo        Link encap:Local Loopback  
          inet addr:127.0.0.1  Mask:255.0.0.0
          inet6 addr: ::1/128 Scope:Host
          UP LOOPBACK RUNNING  MTU:65536  Metric:1
          RX packets:4315 errors:0 dropped:0 overruns:0 frame:0
          TX packets:4315 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:0 
          RX bytes:342880 (342.8 KB)  TX bytes:342880 (342.8 KB)


With ""router access"" (wireless in this case, but it varies):

~ $ route -n
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
0.0.0.0         192.168.1.1     0.0.0.0         UG    0      0        0 wlan0
192.168.1.0     0.0.0.0         255.255.255.0   U     9      0        0 wlan0

~ $ ifconfig
eth0      Link encap:Ethernet  HWaddr 54:ee:75:0c:02:80  
          UP BROADCAST MULTICAST  MTU:1500  Metric:1
          RX packets:9422 errors:0 dropped:0 overruns:0 frame:0
          TX packets:7545 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:1000 
          RX bytes:6216683 (6.2 MB)  TX bytes:1399280 (1.3 MB)
          Interrupt:20 Memory:f0500000-f0520000 

lo        Link encap:Local Loopback  
          inet addr:127.0.0.1  Mask:255.0.0.0
          inet6 addr: ::1/128 Scope:Host
          UP LOOPBACK RUNNING  MTU:65536  Metric:1
          RX packets:4446 errors:0 dropped:0 overruns:0 frame:0
          TX packets:4446 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:0 
          RX bytes:353415 (353.4 KB)  TX bytes:353415 (353.4 KB)

wlan0     Link encap:Ethernet  HWaddr e8:2a:ea:60:31:4b  
          inet addr:192.168.1.105  Bcast:192.168.1.255  Mask:255.255.255.0
          inet6 addr: fe80::ea2a:eaff:fe60:314b/64 Scope:Link
          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
          RX packets:77013 errors:0 dropped:0 overruns:0 frame:0
          TX packets:49506 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:1000 
          RX bytes:25275438 (25.2 MB)  TX bytes:30355132 (30.3 MB)


With both (wired with wireless turned on):

~ $ route -n
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
0.0.0.0         192.168.102.1   0.0.0.0         UG    0      0        0 eth0
192.168.1.0     0.0.0.0         255.255.255.0   U     9      0        0 wlan0
192.168.102.0   0.0.0.0         255.255.254.0   U     1      0        0 eth0

",William,https://superuser.com/users/367462,"Router needs to have WAN Connection Type as DHCP and also needed static DNS set up (I used 8.8.8.8 and 8.8.4.4).  Router should have its own DHCP server turned on.

Network is apparently connected like this:  There is a central router, with a cable to my unit's local router.
",William,https://superuser.com/users/367462,http://superuser.com/questions/810510,TECHNOLOGY,superuser.com,0.7777777777777778,0.3333333333333333,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.0,0.6666666666666666,0.8888888888888888,Only one web portal and Internet of router can be accessed,"On both wired and wireless connections, I can only access one of 192.168.1.1 (the router web portal) and the general Internet.  Which ""mode"" my devices are in is seemingly random.  This has persisted so far for 5 days (since I began using this network).

When connected to the Internet, I can go to 192.168.102.1 and I see a landing page for ""mikrotik routeros"", but I cannot go to 192.168.1.1. When connected to the router but not the Internet, 192.168.1.1 yields the router web portal, and 192.168.102.1 is inaccessible.

Attempted solutions


Upgrading router firmware  
Resetting router to factory settings  
Rebooting devices  
Fiddling with router settings (changing wireless security modes, removing wireless security, etc)  
Upgrading wireless drivers on computers  


Some data


Affects BlackBerry, Windows, Android and Ubuntu devices
All devices work properly on other networks
Devices may switch modes if they have been offline for a long time (eg: overnight), but restarting a device has no effect
Router is TP-Link TL-WR740N v4
Router firmware DD-WRT v24-sp2 (04/18/14) std - build 23919
Both wired and wireless connections are affected, but not necessarily simultaneously


I don't know anything about networking, but here's some info that seems helpful taken from my Ubuntu laptop.

With internet access (wired in this case, but it varies):

~ $ route -n
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
0.0.0.0         192.168.102.1   0.0.0.0         UG    0      0        0 eth0
192.168.102.0   0.0.0.0         255.255.254.0   U     1      0        0 eth0

~ $ ifconfig
eth0      Link encap:Ethernet  HWaddr 54:ee:75:0c:02:80  
          inet addr:192.168.103.232  Bcast:192.168.103.255  Mask:255.255.254.0
          inet6 addr: fe80::56ee:75ff:fe0c:280/64 Scope:Link
          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
          RX packets:3273 errors:0 dropped:0 overruns:0 frame:0
          TX packets:3035 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:1000 
          RX bytes:2276482 (2.2 MB)  TX bytes:517732 (517.7 KB)
          Interrupt:20 Memory:f0500000-f0520000 

lo        Link encap:Local Loopback  
          inet addr:127.0.0.1  Mask:255.0.0.0
          inet6 addr: ::1/128 Scope:Host
          UP LOOPBACK RUNNING  MTU:65536  Metric:1
          RX packets:4315 errors:0 dropped:0 overruns:0 frame:0
          TX packets:4315 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:0 
          RX bytes:342880 (342.8 KB)  TX bytes:342880 (342.8 KB)


With ""router access"" (wireless in this case, but it varies):

~ $ route -n
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
0.0.0.0         192.168.1.1     0.0.0.0         UG    0      0        0 wlan0
192.168.1.0     0.0.0.0         255.255.255.0   U     9      0        0 wlan0

~ $ ifconfig
eth0      Link encap:Ethernet  HWaddr 54:ee:75:0c:02:80  
          UP BROADCAST MULTICAST  MTU:1500  Metric:1
          RX packets:9422 errors:0 dropped:0 overruns:0 frame:0
          TX packets:7545 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:1000 
          RX bytes:6216683 (6.2 MB)  TX bytes:1399280 (1.3 MB)
          Interrupt:20 Memory:f0500000-f0520000 

lo        Link encap:Local Loopback  
          inet addr:127.0.0.1  Mask:255.0.0.0
          inet6 addr: ::1/128 Scope:Host
          UP LOOPBACK RUNNING  MTU:65536  Metric:1
          RX packets:4446 errors:0 dropped:0 overruns:0 frame:0
          TX packets:4446 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:0 
          RX bytes:353415 (353.4 KB)  TX bytes:353415 (353.4 KB)

wlan0     Link encap:Ethernet  HWaddr e8:2a:ea:60:31:4b  
          inet addr:192.168.1.105  Bcast:192.168.1.255  Mask:255.255.255.0
          inet6 addr: fe80::ea2a:eaff:fe60:314b/64 Scope:Link
          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
          RX packets:77013 errors:0 dropped:0 overruns:0 frame:0
          TX packets:49506 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:1000 
          RX bytes:25275438 (25.2 MB)  TX bytes:30355132 (30.3 MB)


With both (wired with wireless turned on):

~ $ route -n
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
0.0.0.0         192.168.102.1   0.0.0.0         UG    0      0        0 eth0
192.168.1.0     0.0.0.0         255.255.255.0   U     9      0        0 wlan0
192.168.102.0   0.0.0.0         255.255.254.0   U     1      0        0 eth0

",The router needs to set the WAN connection type to DHCP and static DNS (I used 8.8.8.8 and 8.8.4.4). The router should open its own DHCP server.
5472,5472,8689,What kind of gasoline additives will help maintain the engine efficiency/life?,"Aside from the traditional maintenance of oil changes, and keeping fluid levels correct - what else will help prolong the engine's life?

I recall a few years back gasoline additives were the thing to go with - what's the best/recommended one currently? If any.

Edit: I recall reading about each gasoline brand having their own set of additives at one point, where it was suggested to cycle between a few different brands every X amount of km/miles. The reason behind switching was so that the next brand would cleanup any sediments left by the previous brand. How likely is this in today's world? And better yet, how important is it?
",Jesse,https://mechanics.stackexchange.com/users/2890,"Today's gasoline is already loaded up with all the additives that one is likely to need on a regular basis.  There really isn't anything you should be adding ""just because"".  Certain additives can be helpful if problems crop up though.
",Brian Knoblauch,https://mechanics.stackexchange.com/users/644,http://mechanics.stackexchange.com/questions/5729/what-kind-of-gasoline-additives-will-help-maintain-the-engine-efficiency-life,SCIENCE,mechanics.stackexchange.com,1.0,0.6666666666666666,0.0,1.0,0.3333333333333333,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.6666666666666666,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.3333333333333333,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.7333333333333333,0.0,0.0,1.0,1.0,Which gasoline additive helps maintain engine efficiency / life?,"Aside from the traditional maintenance of oil changes, and keeping fluid levels correct - what else will help prolong the engine's life?

I recall a few years back gasoline additives were the thing to go with - what's the best/recommended one currently? If any.

Edit: I recall reading about each gasoline brand having their own set of additives at one point, where it was suggested to cycle between a few different brands every X amount of km/miles. The reason behind switching was so that the next brand would cleanup any sediments left by the previous brand. How likely is this in today's world? And better yet, how important is it?
","Today's gasoline is full of all the additives that may be needed. You really shouldn't add ""just because."". But if there is a problem, some additives may help."
1602,1602,2518,XLConnect loadWorkbook error - POIXMLException (Java),"I'm trying to load a hefty Excel workbook (.xlsm format, ~30 mb) that has a large number of array calcs. 

&gt; wb1 &lt;- loadWorkbook(""Mar_SP_20130227_V6.1.xlsm"")
Error: POIXMLException (Java): java.lang.reflect.InvocationTargetException


But I am able to successfully load a values-only/no-macro version of the workbook.

&gt; wb2 &lt;- loadWorkbook(""Mar_SP_20130227_V6.1_VALUES_ONLY.xlsx"")
&gt; wb2
[1] ""Mar_SP_20130227_V6.1_VALUES_ONLY.xlsx""


What could be causing the error?

From the maintainer's website I can see that there can be issues with workbooks containing array calcs or unsupported formula functions, but this doesn't look like the same errror.

Java Info:

C:\&gt; java -version
java version ""1.6.0_21""
Java(TM) SE Runtime Environment (build 1.6.0_21-b07)
Java HotSpot(TM) Client VM (build 17.0-b17, mixed mode)

",Tommy O'Dell,https://stackoverflow.com/users/176995,"It turns out that the root of this error was the JVM running out of memory (even with options(java.parameters = ""-Xmx1024m"")). 

I tried to increase the memory, but couldn't get the JVM to take more than -Xmx2048m, which still wasn't enough to load the workbook. 

So I upgraded the JRE from 32 bit to 64 bit and ran 64 bit R.

I was then able to set -Xmx4096m and successfully load my 30mb workbook.
",Tommy O'Dell,https://stackoverflow.com/users/176995,http://stackoverflow.com/questions/15825004/xlconnect-loadworkbook-error-poixmlexception-java,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.5555555555555556,0.0,0.5,1.0,1.0,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,1.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,0.3333333333333333,0.6666666666666666,1.0,0.8888888888888888,Xlconnect load workbook error - poixmlexception (Java),"I'm trying to load a hefty Excel workbook (.xlsm format, ~30 mb) that has a large number of array calcs. 

&gt; wb1 &lt;- loadWorkbook(""Mar_SP_20130227_V6.1.xlsm"")
Error: POIXMLException (Java): java.lang.reflect.InvocationTargetException


But I am able to successfully load a values-only/no-macro version of the workbook.

&gt; wb2 &lt;- loadWorkbook(""Mar_SP_20130227_V6.1_VALUES_ONLY.xlsx"")
&gt; wb2
[1] ""Mar_SP_20130227_V6.1_VALUES_ONLY.xlsx""


What could be causing the error?

From the maintainer's website I can see that there can be issues with workbooks containing array calcs or unsupported formula functions, but this doesn't look like the same errror.

Java Info:

C:\&gt; java -version
java version ""1.6.0_21""
Java(TM) SE Runtime Environment (build 1.6.0_21-b07)
Java HotSpot(TM) Client VM (build 17.0-b17, mixed mode)

","It turns out that the root of this error was the JVM running out of memory (even with options(java.parameters = ""-Xmx1024m"")). 

I tried to increase the memory, but couldn't get the JVM to take more than -Xmx2048m, which still wasn't enough to load the workbook. 

So I upgraded the JRE from 32 bit to 64 bit and ran 64 bit R.

I was then able to set -Xmx4096m and successfully load my 30mb workbook.
"
4715,4715,7479,2D AABBs and resolving multiple collisions,"Okay, so this is a problem I've been trying to figure out for quite some time. Mine is a 2D platformer game with a world made up of (usually) immobile tiles and mobile sprites, both of which use AABBs to represent their hitboxes. This game is NOT grid-based due to some complications with moving layers of tiles.

I can detect collisions and easily figure out the depth of the collision. I use the ""shallowest axis method"" to determine which way to resolve a collision between the sprite and the tile. If the sprite is deeper horizontally than vertically, the direction to resolve is either up or down. If the sprite is deeper vertically than horizontally, the direction to resolve is either left or right.



This is simple enough, and it works pretty well. That is, until you have a sprite colliding with more than one tile. As, by their nature, each collision has to be checked separately, different collisions may have different direction to resolve in. For example, if a sprite is trying to walk across a row of tiles, for one frame they will intersect the next tile such that the horizontal depth is shorter than the vertical depth. As the collision says ""resolve left"", it will be pushed back and will be stuck on the corner.



I've been mulling this problem over, on and off, for quite some time, and several solutions have come to me, but all have flaws. I could mark certain sides as unreachable, but without a grid-based engine, determining ""unreachability"" is remarkably complex, especially with moving layers of tiles always a possibility.

Another possible method would be to predict collisions before they happen and ""work back"" the movement to the point of the collision, I suppose, but I'm not sure how the math on that works.

I feel that I'm missing something incredibly obvious, especially since games from the 80s have already solved this problem.
",Celarix,https://gamedev.stackexchange.com/users/34552,"You're overthinking the problem and conflating a couple of issues. But that's okay because, as you said, this is a very solved problem with lots of great answers out there.

Let's break it down:


Tilemaps. Your first example is of a sprite walking across a bunch of tiles laid out horizontally (or sliding down a wall of tiles laid out vertically, they're isomorphic). One very elegant solution to this is to simply not check the edges of tiles where we know a sprite can't get to, such as edges that are ""underground"" or edges that border another completely solid tile.  

You're right that the sprite would descend due to to gravity, then move laterally, then get stuck... but the answer is to not care about the left or right edges of the tiles that are underground. That way, your collision resolution routine only moves the sprite vertically — and your sprite can go on its merry way.

Check out the Metanet tile tutorials for a step-by-step explanation of this. You say in your question that you're not using a traditional tilemap, but that's okay too: static tiles are in the tilemap and update as above, while moving platforms and such update as #2 below.
Other AABBs. You'll only run into a problem if, in a single frame, your sprite can move a distance larger than the width/height of most AABBs in your game. If it can't, you're golden: resolve the collisions one-by-one and it'll work just fine.

If the AABBs can move very fast in a single frame then you should ""sweep"" the movement when checking for collisions: chunk up the movement into tinier fractions and check for collisions at each step.

",D. Hayes,https://gamedev.stackexchange.com/users/148,http://gamedev.stackexchange.com/questions/69339/2d-aabbs-and-resolving-multiple-collisions,TECHNOLOGY,gamedev.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,0.6666666666666666,0.3333333333333333,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.3333333333333333,0.8888888888888888,2D AABBs and the solution of multiple collisions,"Okay, so this is a problem I've been trying to figure out for quite some time. Mine is a 2D platformer game with a world made up of (usually) immobile tiles and mobile sprites, both of which use AABBs to represent their hitboxes. This game is NOT grid-based due to some complications with moving layers of tiles.

I can detect collisions and easily figure out the depth of the collision. I use the ""shallowest axis method"" to determine which way to resolve a collision between the sprite and the tile. If the sprite is deeper horizontally than vertically, the direction to resolve is either up or down. If the sprite is deeper vertically than horizontally, the direction to resolve is either left or right.



This is simple enough, and it works pretty well. That is, until you have a sprite colliding with more than one tile. As, by their nature, each collision has to be checked separately, different collisions may have different direction to resolve in. For example, if a sprite is trying to walk across a row of tiles, for one frame they will intersect the next tile such that the horizontal depth is shorter than the vertical depth. As the collision says ""resolve left"", it will be pushed back and will be stuck on the corner.



I've been mulling this problem over, on and off, for quite some time, and several solutions have come to me, but all have flaws. I could mark certain sides as unreachable, but without a grid-based engine, determining ""unreachability"" is remarkably complex, especially with moving layers of tiles always a possibility.

Another possible method would be to predict collisions before they happen and ""work back"" the movement to the point of the collision, I suppose, but I'm not sure how the math on that works.

I feel that I'm missing something incredibly obvious, especially since games from the 80s have already solved this problem.
","You're overthinking the problem and conflating a couple of issues. But that's okay because, as you said, this is a very solved problem with lots of great answers out there.

Let's break it down:


Tilemaps. Your first example is of a sprite walking across a bunch of tiles laid out horizontally (or sliding down a wall of tiles laid out vertically, they're isomorphic). One very elegant solution to this is to simply not check the edges of tiles where we know a sprite can't get to, such as edges that are ""underground"" or edges that border another completely solid tile.  

You're right that the sprite would descend due to to gravity, then move laterally, then get stuck... but the answer is to not care about the left or right edges of the tiles that are underground. That way, your collision resolution routine only moves the sprite vertically — and your sprite can go on its merry way.

Check out the Metanet tile tutorials for a step-by-step explanation of this. You say in your question that you're not using a traditional tilemap, but that's okay too: static tiles are in the tilemap and update as above, while moving platforms and such update as #2 below.
Other AABBs. You'll only run into a problem if, in a single frame, your sprite can move a distance larger than the width/height of most AABBs in your game. If it can't, you're golden: resolve the collisions one-by-one and it'll work just fine.

If the AABBs can move very fast in a single frame then you should ""sweep"" the movement when checking for collisions: chunk up the movement into tinier fractions and check for collisions at each step.

"
290,290,467,Need directions regarding the learning process I should follow for learning Photoshop,"I am starting out as a freelance website developer so I need to improve my graphics drawing skill. Up till now I'm using an open source tool GIMP to create the concepts and mock ups of the websites I design.I know that Photoshop is the Industry standard(at least as far as I know).

So,what books can help me in learning some advanced Photoshop techniques used frequently in web designing.Also I want to learn how to draw cartoon characters like this.I know it is a matter of creativity but still there must be some techniques which I can learn.Please express your views.

Just for the record, I'm basically a web developer so my graphics drawing capabilities are very limited(but I want to improve that). You can have a look at this site I designed using GIMP. 
",Rajat Saxena,https://graphicdesign.stackexchange.com/users/7481,"Personally, I find that Illustrator (with pixel preview and align to pixel grid) has been much more useful than Photoshop in a web workflow. Artboards are intuitively helpful when designing for multiple output devices, the Pathfinder panel allows you to create more nuanced objects, and the Symbols palette allows you to develop more modularity in your approach to asset creation. Modularity = rapid development = the way to go in the current industry environment.  Plus, the way Illustrator handles layers and stacking order is more simple than Photoshop's Layers panel.

I apologize for slightly derailing the question, but I feel that Illustrator is a tool much better suited for web work than Photoshop—it's more maintainable and intuitive, once you've gotten past the initial unfamiliarity that comes from working with vector files instead of raster files. I think the links I've provided will serve as a pretty good primer for getting yourself situated with using Illustrator as an alternative to Photoshop for web development.
",Brendon Roberto,https://graphicdesign.stackexchange.com/users/7455,http://graphicdesign.stackexchange.com/questions/11487/need-directions-regarding-the-learning-process-i-should-follow-for-learning-phot,LIFE_ARTS,graphicdesign.stackexchange.com,1.0,0.7777777777777778,0.0,0.3333333333333333,0.6666666666666666,0.0,0.7777777777777778,0.6666666666666666,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.0,0.0,0.7777777777777778,0.8888888888888888,0.5,1.0,0.8888888888888888,0.8,0.0,0.0,0.6666666666666666,1.0,Need guidance on the learning process of learning Photoshop,"I am starting out as a freelance website developer so I need to improve my graphics drawing skill. Up till now I'm using an open source tool GIMP to create the concepts and mock ups of the websites I design.I know that Photoshop is the Industry standard(at least as far as I know).

So,what books can help me in learning some advanced Photoshop techniques used frequently in web designing.Also I want to learn how to draw cartoon characters like this.I know it is a matter of creativity but still there must be some techniques which I can learn.Please express your views.

Just for the record, I'm basically a web developer so my graphics drawing capabilities are very limited(but I want to improve that). You can have a look at this site I designed using GIMP. 
","Personally, I find illustrator (with pixel preview and pixel grid alignment) much more useful in Web Workflow than Photoshop. When designing for multiple output devices, the art palette is intuitively helpful, the Pathfinder panel allows you to create more subtle objects, and the symbol palette allows you to develop more modularity in the asset creation method. Modularity = rapid development = development direction under the current industry environment. In addition, illustrator handles layers and stacking order in a much simpler way than Photoshop's layers panel."
2541,2541,4047,Images give 404 after changing default domain,"Never encountered this issue before. So I've just moved a site for a client to another server and for some reason all images give me a 404 when I change the default domain in the database (siteurl and home). CSS, JS and other files are linked correctly - it seems there's something affecting the uploads folder but I can't pinpoint what it is. Any ideas?
",Staffan Estberg,https://wordpress.stackexchange.com/users/67844,"You will want to run a find-and-replace script across the database to update all URLs to reflect the new domain. Just because you change the WordPress settings doesn't mean the content stored in the database has been updated with the new domain! I've had good luck with the Velvet Blues Update URLs plugin but you can also do this type of find and replace update using phpMyAdmin or other similar database tools.
",bemdesign,https://wordpress.stackexchange.com/users/64595,http://wordpress.stackexchange.com/questions/178742/images-give-404-after-changing-default-domain,TECHNOLOGY,wordpress.stackexchange.com,1.0,0.5555555555555556,0.0,0.6666666666666666,0.3333333333333333,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.3333333333333333,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,0.8888888888888888,0.8666666666666666,1.0,0.0,0.3333333333333333,0.8888888888888888,Image display 404 after changing the default domain,"This problem has never been encountered before. So I just moved one client's site to another server, and for some reason, when I changed the default domain (siteurl and home) in the database, all the images would show 404. CSS, JS, and other files are linked correctly - something seems to affect the uploads folder, but I'm not sure what it is. Do you have any ideas?","You will want to run a find-and-replace script across the database to update all URLs to reflect the new domain. Just because you change the WordPress settings doesn't mean the content stored in the database has been updated with the new domain! I've had good luck with the Velvet Blues Update URLs plugin but you can also do this type of find and replace update using phpMyAdmin or other similar database tools.
"
444,444,693,how to change my hostname?,"My hostname is localhost, reported by hostname command, and terminal prompt root@localhost:~#.

How can i change it to mismis.com with mismis alias? and what is the proper configuration.

I confused after reading some articles on web.

My /etc/hosts:

127.0.0.1       localhost
127.0.1.1       srv345.myweb.com      srv345
178.162.231.61  janstone.mismis.com    janstone
# The following lines are desirable for IPv6 capable hosts
::1     localhost ip6-localhost ip6-loopback
fe00::0 ip6-localnet
ff00::0 ip6-mcastprefix
ff02::1 ip6-allnodes
ff02::2 ip6-allrouters

",pylover,https://askubuntu.com/users/33292,"The system hostname is configured in /etc/hostname. A change made to this file will take effect after reboot.

At boot time the string in /etc/hostname is loaded into the kernel using the hostname command. If you edit /etc/hostname then you should also set the system hostname manually using the hostname command.

sudo hostname mismis


Note that in Debian and Ubuntu the system hostname is the short hostname, not a fully qualified domain name.

If the machine has a static external IP address ADRS then this address and the hostname should appear on a line in /etc/hosts, as follows.

ADRS &lt;hostname&gt;


If the machine has a static fully-qualified domain name then this should appear first after the IP address on the line and the short hostname should follow it.

ADRS &lt;fully-qualified-hostname&gt; &lt;short-hostname&gt;


In the present case, assuming that the external IP address is 178.162.231.61 and the desired canonical hostname is ""mismis.com"", the /etc/hosts line should look like the following.

178.162.231.61 mismis.com mismis


If the machine has no static external IP address, but gets assigned addresses dynamically via DHCP, for example, then 127.0.1.1 should be used instead.

127.0.1.1 mismis.com mismis


or

127.0.1.1 mismis


In /etc/hosts, any IP address should appear on at most ONE line. On that line the first domain name that follows the IP address is the canonical hostname associated with that IP address, and any subsequent domain names are aliases for the canonical hostname.
",jdthood,https://askubuntu.com/users/29569,http://askubuntu.com/questions/228202/how-to-change-my-hostname,TECHNOLOGY,askubuntu.com,1.0,0.4444444444444444,0.0,1.0,0.3333333333333333,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,1.0,1.0,How can I change my host name?,"My hostname is localhost, reported by hostname command, and terminal prompt root@localhost:~#.

How can i change it to mismis.com with mismis alias? and what is the proper configuration.

I confused after reading some articles on web.

My /etc/hosts:

127.0.0.1       localhost
127.0.1.1       srv345.myweb.com      srv345
178.162.231.61  janstone.mismis.com    janstone
# The following lines are desirable for IPv6 capable hosts
::1     localhost ip6-localhost ip6-loopback
fe00::0 ip6-localnet
ff00::0 ip6-mcastprefix
ff02::1 ip6-allnodes
ff02::2 ip6-allrouters

","The system hostname is configured in /etc/hostname. A change made to this file will take effect after reboot.

At boot time the string in /etc/hostname is loaded into the kernel using the hostname command. If you edit /etc/hostname then you should also set the system hostname manually using the hostname command.

sudo hostname mismis


Note that in Debian and Ubuntu the system hostname is the short hostname, not a fully qualified domain name.

If the machine has a static external IP address ADRS then this address and the hostname should appear on a line in /etc/hosts, as follows.

ADRS &lt;hostname&gt;


If the machine has a static fully-qualified domain name then this should appear first after the IP address on the line and the short hostname should follow it.

ADRS &lt;fully-qualified-hostname&gt; &lt;short-hostname&gt;


In the present case, assuming that the external IP address is 178.162.231.61 and the desired canonical hostname is ""mismis.com"", the /etc/hosts line should look like the following.

178.162.231.61 mismis.com mismis


If the machine has no static external IP address, but gets assigned addresses dynamically via DHCP, for example, then 127.0.1.1 should be used instead.

127.0.1.1 mismis.com mismis


or

127.0.1.1 mismis


In /etc/hosts, any IP address should appear on at most ONE line. On that line the first domain name that follows the IP address is the canonical hostname associated with that IP address, and any subsequent domain names are aliases for the canonical hostname.
"
3963,3963,6326,glsl demo suggestions?,"In a lot of places I interviewed recently, I have been asked many a times if I have worked with shaders. Even though, I have read and understand the pipeline, the answer to that question has been no. Recently, one of the places asked me if I can send them a sample of 'something' that is ""visually polished"".

So, I decided to take the plunge and wrote some simple shader in GLSL(with opengl).I now have a basic setup where I can use vbos with glsl shaders.

I have a very short window left to send something to them and I was wondering if someone  with experience, could suggest an idea that is interesting enough to grab someone's attention.

Thanks
",brainydexter,https://gamedev.stackexchange.com/users/4638,"Actually making this work is way out of my depth (and it's DX11 and not OpenGL) but I found this article on Bokeh and DOF effects fascinating, and the results look really good :

How To Fake Bokeh (And Make It Look Pretty Good)

There's a follow-up here too if you're interested.

Another suggestion would be a good HDR tone-mapping algorithm, for example from Uncharted 2's John Hable's blog.
",Bethor,https://gamedev.stackexchange.com/users/4897,http://gamedev.stackexchange.com/questions/8654/glsl-demo-suggestions,TECHNOLOGY,gamedev.stackexchange.com,0.8888888888888888,0.6666666666666666,0.3333333333333333,1.0,0.3333333333333333,0.0,0.6666666666666666,0.4444444444444444,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,0.5555555555555556,0.4444444444444444,0.7777777777777778,0.6666666666666666,0.5333333333333333,0.0,0.0,0.6666666666666666,0.8888888888888888,Glsl presentation suggestions?,"In a lot of places I interviewed recently, I have been asked many a times if I have worked with shaders. Even though, I have read and understand the pipeline, the answer to that question has been no. Recently, one of the places asked me if I can send them a sample of 'something' that is ""visually polished"".

So, I decided to take the plunge and wrote some simple shader in GLSL(with opengl).I now have a basic setup where I can use vbos with glsl shaders.

I have a very short window left to send something to them and I was wondering if someone  with experience, could suggest an idea that is interesting enough to grab someone's attention.

Thanks
","Actually making this work is way out of my depth (and it's DX11 and not OpenGL) but I found this article on Bokeh and DOF effects fascinating, and the results look really good :

How To Fake Bokeh (And Make It Look Pretty Good)

There's a follow-up here too if you're interested.

Another suggestion would be a good HDR tone-mapping algorithm, for example from Uncharted 2's John Hable's blog.
"
3887,3887,6193,Getting libraries to load with newer jQuery using jqmulti,"I'm kind of a newbie to this so I could be missing something really obvious, but I'm having trouble getting specific libraries to load with jQuery 1.7 in noconflict mode using jqmulti. I'm working on a theme based off twitter_bootstrap, and the bootstrap.js library is dependent on more recent jQuery. I've got jqmulti recognizing and loading 1.7 if I check ""load even if no libraries are assigned"" but when I have that unchecked and attempt to use hook_jqmulti_files() to assign particular libraries, nothing happens.

This is what I have in my template.php:

function regent_jqmulti_files() {
    return array(
        'sites/all/themes/regent/bootstrap/js/bootstrap.js',
        'sites/all/themes/regent/bootstrap/js/bootstrap.min.js'
    );
}


but when I look at my rendered html, the library is loaded, but nothing about noconflict mode,  and jQ 1.7 is nowhere to be found. I'm sure I'm missing something basic and stupid, this being the first time I've tried to set something like this up.
",jimhart3000,https://drupal.stackexchange.com/users/7553,"If you have checked ""load even if no libraries are assigned"", jQuery 1.7 should load regardless of anything else you do. So in your HTML you should see Drupal's jQuery loading, and you should also see jQuery1.7 loading, and also a script called switch.js, which takes care of the noConflict() mode. If you don't see those loading, there is a problem that's not related to your hook. Check the jQuery Multi settings page, does it list the jQuery version it's using?
",goron,https://drupal.stackexchange.com/users/6131,http://drupal.stackexchange.com/questions/31891/getting-libraries-to-load-with-newer-jquery-using-jqmulti,TECHNOLOGY,drupal.stackexchange.com,0.3333333333333333,0.6666666666666666,0.0,0.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,1.0,1.0,0.0,0.0,1.0,1.0,Using jqmulti to use the newer jQuery load Library,"I'm kind of a newbie to this so I could be missing something really obvious, but I'm having trouble getting specific libraries to load with jQuery 1.7 in noconflict mode using jqmulti. I'm working on a theme based off twitter_bootstrap, and the bootstrap.js library is dependent on more recent jQuery. I've got jqmulti recognizing and loading 1.7 if I check ""load even if no libraries are assigned"" but when I have that unchecked and attempt to use hook_jqmulti_files() to assign particular libraries, nothing happens.

This is what I have in my template.php:

function regent_jqmulti_files() {
    return array(
        'sites/all/themes/regent/bootstrap/js/bootstrap.js',
        'sites/all/themes/regent/bootstrap/js/bootstrap.min.js'
    );
}


but when I look at my rendered html, the library is loaded, but nothing about noconflict mode,  and jQ 1.7 is nowhere to be found. I'm sure I'm missing something basic and stupid, this being the first time I've tried to set something like this up.
","If you have checked ""load even if no libraries are assigned"", jQuery 1.7 should load regardless of anything else you do. So in your HTML you should see Drupal's jQuery loading, and you should also see jQuery1.7 loading, and also a script called switch.js, which takes care of the noConflict() mode. If you don't see those loading, there is a problem that's not related to your hook. Check the jQuery Multi settings page, does it list the jQuery version it's using?
"
3654,3654,5829,How did the Female Titan cut Eren's titan form?,"After she killed the Levi squad, Eren transformed to fight the Female Titan. In Chapter 29, Hammer, it looked like Eren was having the upper hand, but then the Female Titan turned around, and with one horizontal motion, cut Eren's titan form's head in half.

How did that happen? That part wasn't clear in the anime nor the manga. Did she take a tree and smacked him? Did she harden her hand and hit him?


",Madara Uchiha,https://anime.stackexchange.com/users/27,"As I recall there was an reaction of fist movement (in the anime).
Probably harden her hand and got the tree on the way when cutting his head off.
",Hashirama Senju,https://anime.stackexchange.com/users/85,http://anime.stackexchange.com/questions/5197/how-did-the-female-titan-cut-erens-titan-form,CULTURE,anime.stackexchange.com,1.0,0.8888888888888888,0.3333333333333333,1.0,1.0,1.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.7777777777777778,0.7777777777777778,0.5555555555555556,0.8888888888888888,1.0,0.8,0.0,0.0,1.0,0.6666666666666666,How did Titan cut Ellen's Titan?,"After she killed Levi, Ellen turned to fight the Titans. In Chapter 29 of the hammer, it looks like Ellen has the upper hand, but then the Titan turns around and, in a horizontal motion, cuts Ellen's Titan shaped head in half.","As I recall there was an reaction of fist movement (in the anime).
Probably harden her hand and got the tree on the way when cutting his head off.
"
3293,3293,5249,"Polite alternatives to ""as soon as possible""","I’ve found myself writing the phrase “as soon as possible” just too often. Sometimes I wonder if it sounds a little rude. How can I convey the same meaning in a more polite way but without losing sense of urgency?
",Albertus,https://english.stackexchange.com/users/20545,"An alternative I see in business emails is:


  As soon as you get a chance.


I like it because it implies sensitivity for the other person's schedule yet conveys the urgency of the matter.
",zooone9243,https://english.stackexchange.com/users/19504,http://english.stackexchange.com/questions/69101/polite-alternatives-to-as-soon-as-possible,CULTURE,english.stackexchange.com,1.0,1.0,0.0,1.0,0.0,0.0,0.7777777777777778,0.7777777777777778,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.7333333333333333,0.0,0.0,0.0,1.0,"Politely choose ""as soon as possible""","I find myself writing the word ""as soon as possible"". Sometimes I wonder if it sounds rude. How can I express the same meaning more politely without losing my sense of urgency?","An alternative I see in business emails is:


  As soon as you get a chance.


I like it because it implies sensitivity for the other person's schedule yet conveys the urgency of the matter.
"
2325,2325,3707,How can I disable a region at with the context module at all pages but the <front> (home page),"How can I disable a region at with the context module at all pages but the  (home page).

I've been trying to disable a region on all pages, except the , without having to write all the paths.
I can't make the wildcards * ~ work on the &lt;front&gt; page.

In the condition field, I've tried to put alot of different combos i cant show here, because my post is deemed spam:

Imagine me using * ~ wildcards in front and in back of all the ways you can write the front page path: eks.  http//www.domain.com/
same goes for &lt;front&gt; with all the different combos.

Which one is supposed to work? Hope you get the idea.

Thanks!
Best Regards Elias

",user30790,https://drupal.stackexchange.com/users/30790,"Set ~&lt;front&gt; in path. This will exclude only the front page.

I just tried it and it works properly.
",mixerowsky,https://drupal.stackexchange.com/users/14487,http://drupal.stackexchange.com/questions/127638/how-can-i-disable-a-region-at-with-the-context-module-at-all-pages-but-the-fron,TECHNOLOGY,drupal.stackexchange.com,1.0,0.5555555555555556,0.0,0.5,1.0,1.0,0.5555555555555556,0.4444444444444444,1.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.8,0.6666666666666666,0.3333333333333333,0.3333333333333333,1.0,How to use the context module to disable areas on all pages except the < front > (home page),"How can I disable a region at with the context module at all pages but the  (home page).

I've been trying to disable a region on all pages, except the , without having to write all the paths.
I can't make the wildcards * ~ work on the &lt;front&gt; page.

In the condition field, I've tried to put alot of different combos i cant show here, because my post is deemed spam:

Imagine me using * ~ wildcards in front and in back of all the ways you can write the front page path: eks.  http//www.domain.com/
same goes for &lt;front&gt; with all the different combos.

Which one is supposed to work? Hope you get the idea.

Thanks!
Best Regards Elias

","Set ~&lt;front&gt; in path. This will exclude only the front page.

I just tried it and it works properly.
"
4884,4884,7773,Can I pass along all properties when for a GradleBuild task?,"I'm executing a GradleBuild task, and I'd like to maintain all the properties that the current script has been given. In other words, I want to package up ""these startparameters"" and pass them along to the build I'm calling.

Is there any way to do this cleanly?
",Bosh,https://stackoverflow.com/users/318206,"If you mean project properties:

task foo(type: GradleBuild) {
    startParameter.projectProperties = gradle.startParameter.projectProperties
}


If you mean system properties, replace projectProperties with systemPropertiesArgs (on both sides).
",Peter Niederwieser,https://stackoverflow.com/users/84889,http://stackoverflow.com/questions/19020169/can-i-pass-along-all-properties-when-for-a-gradlebuild-task,STACKOVERFLOW,stackoverflow.com,1.0,0.6666666666666666,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.3333333333333333,0.0,1.0,Can I pass all the properties to the gradlebuild task?,"I'm performing a gradlebuild task and I want to maintain all the properties of the current script. In other words, I want to package ""these startparameters"" and pass them to the build I call.","If you mean project properties:

task foo(type: GradleBuild) {
    startParameter.projectProperties = gradle.startParameter.projectProperties
}


If you mean system properties, replace projectProperties with systemPropertiesArgs (on both sides).
"
4848,4848,7716,How to use ARM software in Raspberry?,"I would like to run Maestro Control Center software (for Mini Maestro 24-Channel USB Servo Controller) in Raspberry. But it is not ARM software. It is availabe for Linux and Windows.

I'm total newbie so i have no skills to do it, but i desperately need to do this and surely there is others who would like to do this too.

Maestro Control Center

Thanks
",user10936,https://raspberrypi.stackexchange.com/users/10936,"The general topic of running x86 programs on an ARM system has come up on Super User before.

You would need to get the source code of the Maestro Control Center and recompile it for the ARM architecture, but since it is closed-source software (as per this forum post by a Pololu employee), your chances of doing that are very slim, to say the least.

Alternatively, you could try some kind of emulator, but you will be better off searching for an alternative program that is open-source or at least available for the ARM architecture.
",n.st,https://raspberrypi.stackexchange.com/users/8286,http://raspberrypi.stackexchange.com/questions/12039/how-to-use-arm-software-in-raspberry,TECHNOLOGY,raspberrypi.stackexchange.com,1.0,0.7777777777777778,0.0,1.0,1.0,1.0,0.5555555555555556,0.5555555555555556,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.0,0.0,1.0,0.8333333333333334,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,0.0,1.0,How to use arm software in raspberry?,"I would like to run Maestro Control Center software (for Mini Maestro 24-Channel USB Servo Controller) in Raspberry. But it is not ARM software. It is availabe for Linux and Windows.

I'm total newbie so i have no skills to do it, but i desperately need to do this and surely there is others who would like to do this too.

Maestro Control Center

Thanks
","The general topic of running x86 programs on an ARM system has come up on Super User before.

You would need to get the source code of the Maestro Control Center and recompile it for the ARM architecture, but since it is closed-source software (as per this forum post by a Pololu employee), your chances of doing that are very slim, to say the least.

Alternatively, you could try some kind of emulator, but you will be better off searching for an alternative program that is open-source or at least available for the ARM architecture.
"
3135,3135,4996,Most effective way to increase programmer salary besides just doing your job?,"If you have the time and resources, what would be the most effective way to increase your salary as a full-time programmer, outside of just doing your job? 

By ""salary"" here, I mean salary (adjusted for location cost-of-living) coming from a single programming job. 
",T. Webster,https://programmers.stackexchange.com/users/19936,"The critical piece that you are missing is learn to negotiate.  Learn to do that effectively, and you will make a bigger difference in your income than any other single thing you can learn.  Even if you only negotiate once every three years when you are discussing salary, learning the basics of negotiation will pay you back more, dollar for dollar and hour for hour, than any other possible investment of your time.

So how do you do it?

Many years ago I asked a friend who was an excellent negotiator for his recommendation on how to learn how to negotiate.  He suggested a contrary book, Start with No.  It walks through a particular negotiation strategy that is highly effective and is a pretty good fit for a lot of people.  I happily can recommend it if you don't already have good negotiation skills.

Subsequently I ran across Bargaining for Advantage and it is by far the better book.  I would describe it as being geared towards giving people a theoretical framework from which they can better understand negotiations they are in, and can better figure out what works for them.    It can definitely take you farther than the previous book, however it doesn't give you as clear-cut ""this is what you do"".  It is a more advanced book.  I'm glad that I read it, but I am also glad that I didn't read it first.

How cost effective is learning something about negotiation?  Those two books combined cost well under $50.  I spent, combined, well under 20 hours reading them.  In the last three years they easily made me over $100,000 in extra income.
",btilly,https://programmers.stackexchange.com/users/16864,http://programmers.stackexchange.com/questions/76254/most-effective-way-to-increase-programmer-salary-besides-just-doing-your-job,TECHNOLOGY,programmers.stackexchange.com,1.0,0.8888888888888888,0.3333333333333333,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.7777777777777778,0.6666666666666666,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.3333333333333333,0.3333333333333333,1.0,"In addition to work, what is the most effective way to raise the salary of programmers?","If you have time and resources, what is the most effective way to increase your salary as a full-time programmer besides doing your job?","The critical piece that you are missing is learn to negotiate.  Learn to do that effectively, and you will make a bigger difference in your income than any other single thing you can learn.  Even if you only negotiate once every three years when you are discussing salary, learning the basics of negotiation will pay you back more, dollar for dollar and hour for hour, than any other possible investment of your time.

So how do you do it?

Many years ago I asked a friend who was an excellent negotiator for his recommendation on how to learn how to negotiate.  He suggested a contrary book, Start with No.  It walks through a particular negotiation strategy that is highly effective and is a pretty good fit for a lot of people.  I happily can recommend it if you don't already have good negotiation skills.

Subsequently I ran across Bargaining for Advantage and it is by far the better book.  I would describe it as being geared towards giving people a theoretical framework from which they can better understand negotiations they are in, and can better figure out what works for them.    It can definitely take you farther than the previous book, however it doesn't give you as clear-cut ""this is what you do"".  It is a more advanced book.  I'm glad that I read it, but I am also glad that I didn't read it first.

How cost effective is learning something about negotiation?  Those two books combined cost well under $50.  I spent, combined, well under 20 hours reading them.  In the last three years they easily made me over $100,000 in extra income.
"
2877,2877,4579,How do I build lengthwise multi-platform stations?,"In OpenTTD, it's possible to build multi-platform train stations side-by-side (pictured below as Parnpool Mines), and they would work as expected, allowing two trains to load/unload at that station at the same time. 

However, sometimes due to space constraints it would be more desirable to to build the two platforms lengthwise as shown below in Parnpool West. The signal-station combination pictured below, however, does not work, and I have not found one that does.


",Private Pansy,https://gaming.stackexchange.com/users/3936,"There isn't any solution that I can see after puzzling over the image for a while. The only ones that would work would be splitting them by two tiles instead of just one and using a bypass track to get around it, but that would mean you're going up to 2 tiles of width anyway, rendering the issue moot.

The only workable idea that I can come up with is to set them as two different stations and use the ""Non-stop"" flag for the two different trains (train A to get it to ignore the first station, train B to get it to ignore the second station) but then if your trains happen to get out-of-order you're pretty much up crap creek.

I guess the only real answer is that there is no answer.
",Xkeeper,https://gaming.stackexchange.com/users/11581,http://gaming.stackexchange.com/questions/19786/how-do-i-build-lengthwise-multi-platform-stations,CULTURE,gaming.stackexchange.com,1.0,0.7777777777777778,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.7333333333333333,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.8888888888888888,How to establish a vertical multi platform platform?,"In OpenTTD, it's possible to build multi-platform train stations side-by-side (pictured below as Parnpool Mines), and they would work as expected, allowing two trains to load/unload at that station at the same time. 

However, sometimes due to space constraints it would be more desirable to to build the two platforms lengthwise as shown below in Parnpool West. The signal-station combination pictured below, however, does not work, and I have not found one that does.


","There isn't any solution that I can see after puzzling over the image for a while. The only ones that would work would be splitting them by two tiles instead of just one and using a bypass track to get around it, but that would mean you're going up to 2 tiles of width anyway, rendering the issue moot.

The only workable idea that I can come up with is to set them as two different stations and use the ""Non-stop"" flag for the two different trains (train A to get it to ignore the first station, train B to get it to ignore the second station) but then if your trains happen to get out-of-order you're pretty much up crap creek.

I guess the only real answer is that there is no answer.
"
667,667,1058,How to install social engineering toolkit?,"When I searched for the social engineering toolkit I got the error ""no such path or file"".

I used this orders for installing it but without success.


  be sure to install subversion before installing the selected tools.


(i did it)

svn co http://svn.secmaniac.com/social_engineering_toolkit set/


and the link is not working anymore.
",user227691,https://askubuntu.com/users/227691,"I wouldn't use whatever guide you are using, they moved their stuff to git several months ago:

sudo apt-get install git
git clone https://github.com/trustedsec/social-engineer-toolkit/ set/


Resources:


https://www.trustedsec.com/downloads/social-engineer-toolkit/

",Braiam,https://askubuntu.com/users/169736,http://askubuntu.com/questions/394141/how-to-install-social-engineering-toolkit,TECHNOLOGY,askubuntu.com,1.0,0.8888888888888888,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.4444444444444444,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.8888888888888888,1.0,0.5555555555555556,1.0,1.0,0.6666666666666667,1.0,0.0,0.3333333333333333,0.8888888888888888,How to install social engineering toolkit?,"When I searched for the social engineering toolkit I got the error ""no such path or file"".

I used this orders for installing it but without success.


  be sure to install subversion before installing the selected tools.


(i did it)

svn co http://svn.secmaniac.com/social_engineering_toolkit set/


and the link is not working anymore.
","I wouldn't use whatever guide you are using, they moved their stuff to git several months ago:

sudo apt-get install git
git clone https://github.com/trustedsec/social-engineer-toolkit/ set/


Resources:


https://www.trustedsec.com/downloads/social-engineer-toolkit/

"
3609,3609,5762,"How to draw a double-ended arrow between the numerator and denominator in a frac inside a sqrt, and an arrow labeled by an otimes pointing to that?","Here's what I have, and I've hand drawn what I seeking:



I'm after (a) a double-ended arrow with the two ends pointing to the numerator and denominator of a fraction under a square root, and (b) an arrow pointing to the double-ended arrow labeled by an \otimes.

I'm typesetting old lecture notes in LaTeX and need to be as accurate as possible, so this is what I need to do.  But it doesn't strike as straightforward.

I tried using baseline in tikz, but it didn't come out symmetric, and I wouldn't even know where to begin with the arrow pointing to the double-ended arrow.

\documentclass{article}

\usepackage{amsmath}
\usepackage{tikz}

\begin{document}

\begin{equation*}
 \sqrt{\frac{N}{p(1-p)}}
\end{equation*}

\end{document}

",Rebecca J. Stones,https://tex.stackexchange.com/users/47311,"Here is something that should get you started on using tikzmark:



Notes:


This does require two runs. First one to determine the locations, and the second to do the drawing.
There probably are easier ways to determine the locations.


Code:

\documentclass{article}

\usepackage{amsmath}
\usepackage{tikz}
\usetikzlibrary{calc}

\newcommand{\mytikzmark}[1]{\tikz[remember picture] \node[baseline, inner sep=0pt] (#1) {};}

\begin{document}

\begin{equation*}
 \sqrt{\frac{N\mytikzmark{top}}{p(1-p)\mytikzmark{bottom}}}
\end{equation*}
\begin{tikzpicture}[remember picture, overlay]
    \coordinate (Top Start)  at ([yshift=0.25\baselineskip]top -| bottom);
    \coordinate (Bottom End) at ([yshift=0.2\baselineskip]bottom);
    \draw [latex-latex, red, thick] 
            (Top Start) to[out=-5, in=5, distance=0.75cm] 
            (Bottom End);
    \node (MidHeight) at (Top Start |- Bottom End) {};
    \node  at ([shift={(1.5cm,0.5\baselineskip)}]Bottom End) (OTIMES) {$\otimes$};
    \draw [blue, -stealth, thick] (OTIMES) -- ++(-0.8cm,0);
\end{tikzpicture}%
\end{document}

",Peter Grill,https://tex.stackexchange.com/users/4301,http://tex.stackexchange.com/questions/249699/how-to-draw-a-double-ended-arrow-between-the-numerator-and-denominator-in-a-frac,TECHNOLOGY,tex.stackexchange.com,0.5,0.6666666666666666,0.0,0.0,1.0,0.5,0.6666666666666666,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.5,0.0,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.8333333333333334,0.8,1.0,0.0,1.0,0.8333333333333334,"How to draw a double ended arrow between the numerator and denominator in frac in sqrt, and an arrow marked by otimes pointing to it?","Here's what I have, and I've hand drawn what I seeking:



I'm after (a) a double-ended arrow with the two ends pointing to the numerator and denominator of a fraction under a square root, and (b) an arrow pointing to the double-ended arrow labeled by an \otimes.

I'm typesetting old lecture notes in LaTeX and need to be as accurate as possible, so this is what I need to do.  But it doesn't strike as straightforward.

I tried using baseline in tikz, but it didn't come out symmetric, and I wouldn't even know where to begin with the arrow pointing to the double-ended arrow.

\documentclass{article}

\usepackage{amsmath}
\usepackage{tikz}

\begin{document}

\begin{equation*}
 \sqrt{\frac{N}{p(1-p)}}
\end{equation*}

\end{document}

","Here is something that should get you started on using tikzmark:



Notes:


This does require two runs. First one to determine the locations, and the second to do the drawing.
There probably are easier ways to determine the locations.


Code:

\documentclass{article}

\usepackage{amsmath}
\usepackage{tikz}
\usetikzlibrary{calc}

\newcommand{\mytikzmark}[1]{\tikz[remember picture] \node[baseline, inner sep=0pt] (#1) {};}

\begin{document}

\begin{equation*}
 \sqrt{\frac{N\mytikzmark{top}}{p(1-p)\mytikzmark{bottom}}}
\end{equation*}
\begin{tikzpicture}[remember picture, overlay]
    \coordinate (Top Start)  at ([yshift=0.25\baselineskip]top -| bottom);
    \coordinate (Bottom End) at ([yshift=0.2\baselineskip]bottom);
    \draw [latex-latex, red, thick] 
            (Top Start) to[out=-5, in=5, distance=0.75cm] 
            (Bottom End);
    \node (MidHeight) at (Top Start |- Bottom End) {};
    \node  at ([shift={(1.5cm,0.5\baselineskip)}]Bottom End) (OTIMES) {$\otimes$};
    \draw [blue, -stealth, thick] (OTIMES) -- ++(-0.8cm,0);
\end{tikzpicture}%
\end{document}

"
4931,4931,7853,business-class fiber to the home,"Suppose you're some sort of crazy nerd fellow and you live in an area that's absolutely covered in fiber optics and network facilities. What kind of cost / infrastructure would be needed to hook in somewhere and get you're internet connection directly from a local datacenter?
",neoice,https://serverfault.com/users/6134,"If you didn't know the carrier and had no discount structure in place then I'd suggest that simply running shielded good high performance (OM3) bare fibre from their switches to your home would cost in the tens of thousands of dollars, perhaps as much as $50,000-$75,000. Then you'd have to pay for the SFP/SFP+ (or Xenpak/X2), which are at least $1,000 each end for medium range transceivers, plus a fraction of a switch line card, say $2,000.  You'd also need an SFP/SFP+ capable switch/router at your end, say $2,000-$5,000 or more.
Then we get into the heavy cost, the actual carrier and support costs, which would be well into five figure per year. There would also be engineering and project management costs too.

So to recap, I'd suggest between $25,000 and $150,000-$250,000 depending on carrier, location, service level and speed.

Fast downloads though... 
",Chopper3,https://serverfault.com/users/1435,http://serverfault.com/questions/158286,TECHNOLOGY,serverfault.com,1.0,0.6666666666666666,0.0,1.0,1.0,1.0,0.5555555555555556,0.6666666666666666,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.7777777777777778,0.7777777777777778,0.7777777777777778,0.7777777777777778,1.0,0.9333333333333332,0.6666666666666666,0.0,0.0,1.0,Business class fiber home,"Suppose you're a crazy nerd, living in a place that's completely covered by fiber optics and networking. What cost / infrastructure is needed to connect to a place and directly from the local data center to the Internet?","If you don't know the operator and don't have a discount structure, I suggest that you only need to run the shielded high-performance (OM3) bare fiber from the switch to your home, which will cost tens of thousands of dollars, possibly as much as 50000-75000 dollars. Then you have to pay for SFPs / SFPs + (or xenpak / x2), and for medium range transceivers, at least $1000 per end, plus a fraction of a switched line card, such as $2000. You also need a switch / router with the SFP / SFP + function at your terminal, for example, $2000-5000 or more."
5890,5890,9331,How to disable the shape toggle hotkey in Windows Chinese Input method?,"In any version of Windows I have used so far (Xp, Vista, 7, 8) and all versions of the MSPY IME (RTM versions and the 2010 version)
There is this annoying bug that you cannot change or disable the hotkey for Chinese shape troggle (normal to double spaced chars).
The default is Shift+Space, and cannot be changed from the language input settings pane in the control panel.
Here are a couple screenshots to show the problem:



After that press Change Key Sequence

This dialog will appear:



Disabling it, has no effect, i.e. Windows will ignore the setting.
You will notice I already managed to change the sequence to Shift-None by using the registry, but Windows still uses Shift+Space for shape toggle, which is really annoying when you type Chinese faster (especially if you want to switch between English and Chinese).

Now after you changed or deleted the key with the dialogue, the setting will not be persistent with hitting Apply. Changing the corresponding registry value and rebooting also doesn't help, as the following screenshot demonstrates:



I hope anyone has experience with this problem.
",Sebastian Godelet,https://superuser.com/users/41264,"Why can't you change the Shift+Space combination to some unlikely combination
like Alt+F12 or whatever ?
This is not the same as totally disabling it, but it will liberate at least the space-bar.

As more experimentation, I believe that this key-combination is defined in the registry at :
HKEY_CURRENT_USER\Control Panel\Input Method\Hot Keys\00000011.

Export this registry-key to a .reg file and change the following items :
Key Modifiers to ""00 C0 00 00"", meaning no ""Control"" or ""Shift"" or ""Alt"".
Virtual Key to 0, meaning ""None"".

If this does not work, maybe a more forceful action is required, such as totally deleting the 00000011 key. Unfortunately also, this thread claims that Windows will reset these keys
as soon as they are changed, which you can verify on your computer,

(The above is based on Simplified Chinese MSPY 3.0 IME Hot Key Registry Settings.)

A reboot is required to be absolutely sure that any such change had an effect.
Create also, as a safety measure, a system quite-point before modifying the registry.

[EDIT]

It seems like Windows will not suffer a change to the above registry keys, so any changes
are immediately nullified.

The only working solution is to use AutoHotkey to replace the Shift+Space combination to something else.

One possibility is detailed here : ""+Space::Space"".
The poster actually used ""+Space:: WinActivate"".
",harrymc,https://superuser.com/users/8672,http://superuser.com/questions/392671,TECHNOLOGY,superuser.com,1.0,0.5555555555555556,0.0,1.0,1.0,1.0,0.5555555555555556,0.5555555555555556,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.6666666666666666,0.6666666666666666,0.8888888888888888,How to disable shape toggle hotkeys in Windows Chinese IME?,"In any version of Windows I have used so far (Xp, Vista, 7, 8) and all versions of the MSPY IME (RTM versions and the 2010 version)
There is this annoying bug that you cannot change or disable the hotkey for Chinese shape troggle (normal to double spaced chars).
The default is Shift+Space, and cannot be changed from the language input settings pane in the control panel.
Here are a couple screenshots to show the problem:



After that press Change Key Sequence

This dialog will appear:



Disabling it, has no effect, i.e. Windows will ignore the setting.
You will notice I already managed to change the sequence to Shift-None by using the registry, but Windows still uses Shift+Space for shape toggle, which is really annoying when you type Chinese faster (especially if you want to switch between English and Chinese).

Now after you changed or deleted the key with the dialogue, the setting will not be persistent with hitting Apply. Changing the corresponding registry value and rebooting also doesn't help, as the following screenshot demonstrates:



I hope anyone has experience with this problem.
","Why can't you change the Shift+Space combination to some unlikely combination
like Alt+F12 or whatever ?
This is not the same as totally disabling it, but it will liberate at least the space-bar.

As more experimentation, I believe that this key-combination is defined in the registry at :
HKEY_CURRENT_USER\Control Panel\Input Method\Hot Keys\00000011.

Export this registry-key to a .reg file and change the following items :
Key Modifiers to ""00 C0 00 00"", meaning no ""Control"" or ""Shift"" or ""Alt"".
Virtual Key to 0, meaning ""None"".

If this does not work, maybe a more forceful action is required, such as totally deleting the 00000011 key. Unfortunately also, this thread claims that Windows will reset these keys
as soon as they are changed, which you can verify on your computer,

(The above is based on Simplified Chinese MSPY 3.0 IME Hot Key Registry Settings.)

A reboot is required to be absolutely sure that any such change had an effect.
Create also, as a safety measure, a system quite-point before modifying the registry.

[EDIT]

It seems like Windows will not suffer a change to the above registry keys, so any changes
are immediately nullified.

The only working solution is to use AutoHotkey to replace the Shift+Space combination to something else.

One possibility is detailed here : ""+Space::Space"".
The poster actually used ""+Space:: WinActivate"".
"
4544,4544,7198,How do you include a user's default image in a Drupal 7 view that lists people?,"I have a view in Drupal 7 that lists people (users). It shows the username and the standard user picture field. If a user has a set image, it comes through perfectly. However, for users that didn't set a profile image no image is shown, even though I have a default profile image set in the people settings for the site.

How do I get views to use the default profile picture for people that do not have a profile image set?

Update: I wasn't clear. I know how to use the default image in the no results behavior. The issue is that I can't get the default image to use the imagestyle I use for the other images.
",Justin,https://drupal.stackexchange.com/users/1026,"I have just found the answer to this question via Drupal.org. You have to use a URI like this:

public://user_pictures/default.png


in your account settings.

Here, public:// stands for your public files location (often sites/default/files/). What comes after that, is the location of your image within public files. If you do this, the default image is treated like normal user images.
",Marijke Luttekes,https://drupal.stackexchange.com/users/7786,http://drupal.stackexchange.com/questions/31799/how-do-you-include-a-users-default-image-in-a-drupal-7-view-that-lists-people,TECHNOLOGY,drupal.stackexchange.com,1.0,0.7777777777777778,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.3333333333333333,1.0,How do I include a user's default image in the Drupal 7 view that lists users?,"I have a view in Drupal 7 that lists people (users). It displays the user name and standard user picture fields. If a user has a set image, it will pass perfectly. However, for users who do not have a profile image set, even if I set the default profile image in the ""people settings"" of the website, no image will be displayed.","I have just found the answer to this question via Drupal.org. You have to use a URI like this:

public://user_pictures/default.png


in your account settings.

Here, public:// stands for your public files location (often sites/default/files/). What comes after that, is the location of your image within public files. If you do this, the default image is treated like normal user images.
"
3572,3572,5709,Performance of SQL query with condition vs. without where clause,"Which SQL-query will be executed with less time — query with WHERE-clause or without, when:


WHERE-clause deals with indexed field (e.g. primary key field)
WHERE-clause deals with non-indexed field


I suppose when we're working with indexed fields, thus query with WHERE will be faster.
Am I right?

Thanks!
",Mike B.,https://stackoverflow.com/users/462347,"Not sure what you mean by 'query with WHERE-clause or without', but you're correct that most of the time a query with a WHERE clause on an indexed field with outperform a query whose WHERE clause on a non-indexed field. 

One instance where the performance will be the same (ie indexing doesn't matter) is when you run a range based query in your where clause (ie WHERE col1 > x ). This forces a scan of the table, and thus will be the same speed as a range query on a non indexed column.

Really, it depends on the columns you reference in the where clause, the types of data in the columns, the types of queries your running, etc. 
",ryanbwork,https://stackoverflow.com/users/1314354,http://stackoverflow.com/questions/11802884/performance-of-sql-query-with-condition-vs-without-where-clause,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.5555555555555556,0.0,1.0,0.3333333333333333,0.6666666666666666,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.6666666666666667,0.0,0.0,1.0,1.0,Performance comparison of SQL query with and without where clause,"Which SQL-query will be executed with less time — query with WHERE-clause or without, when:


WHERE-clause deals with indexed field (e.g. primary key field)
WHERE-clause deals with non-indexed field


I suppose when we're working with indexed fields, thus query with WHERE will be faster.
Am I right?

Thanks!
","Not sure what you mean by 'query with WHERE-clause or without', but you're correct that most of the time a query with a WHERE clause on an indexed field with outperform a query whose WHERE clause on a non-indexed field. 

One instance where the performance will be the same (ie indexing doesn't matter) is when you run a range based query in your where clause (ie WHERE col1 > x ). This forces a scan of the table, and thus will be the same speed as a range query on a non indexed column.

Really, it depends on the columns you reference in the where clause, the types of data in the columns, the types of queries your running, etc. 
"
5961,5961,9446,Creating DotPlots,"I've been struggling to create a DotPlot like the one shown in Cleveland's The Elements of Graphing Data.



Using the following dataset

data = Sort[{#, 
 WolframAlpha[
  StringJoin[""Number of native speakers "", #], {{""Result"", 1}, 
   ""ComputableData""}]} &amp; /@ {""Mandarin"", ""French"", ""English"", 
""Spanish"", ""German"", ""Hindi"", ""Malay"", ""Arabic"", ""Portuguese"", 
""Russian"", ""Korean"", ""Italian"", ""Cantonese"", ""Telugu"", 
""Urdu""}, #1[[2]] &lt; #2[[2]] &amp;]


What is the best approach to replicate this chart with its two axis, dot, dashed lines , etc?
",Zviovich,https://mathematica.stackexchange.com/users/1096,"It is a Chart so one may want to use BarChart:

(* speakers are stored with [people] units so we have to get rid of it, 
   I'm also deleting Malavian since there is no data now*)
sorted = MapAt[QuantityMagnitude, #, {2}] &amp; /@SortBy[data, #[[2]] &amp;] // Rest
len = Length[sorted]

mark[{{xmin_, xmax_}, {ymin_, ymax_}}, ___] := {Black, AbsolutePointSize@7, 
                                              Point[{Scaled[{0, -.02}, {xmax, ymax}]}]}
topt = Table[{i, 2^i}, {i, 0, 9}];

BarChart[Log[2, sorted[[ ;; , 2]]/10^6], 
         ChartLabels -&gt; sorted[[ ;; , 1]], BarOrigin -&gt; Left, BarSpacing -&gt; Large, 
         GridLines -&gt; {None, Range@len}, GridLinesStyle -&gt; Dotted, 
         ChartElementFunction -&gt; mark, Frame -&gt; {{False, True}, {True, True}},
         AxesOrigin -&gt; {0, -1}, FrameTicks -&gt; {{False, False}, {Automatic, topt}}]



",Kuba,https://mathematica.stackexchange.com/users/5478,http://mathematica.stackexchange.com/questions/7811/creating-dotplots,TECHNOLOGY,mathematica.stackexchange.com,1.0,0.3333333333333333,0.0,0.3333333333333333,1.0,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9,1.0,0.0,0.0,0.7777777777777778,Create point map,"I've been struggling to create a DotPlot like the one shown in Cleveland's The Elements of Graphing Data.



Using the following dataset

data = Sort[{#, 
 WolframAlpha[
  StringJoin[""Number of native speakers "", #], {{""Result"", 1}, 
   ""ComputableData""}]} &amp; /@ {""Mandarin"", ""French"", ""English"", 
""Spanish"", ""German"", ""Hindi"", ""Malay"", ""Arabic"", ""Portuguese"", 
""Russian"", ""Korean"", ""Italian"", ""Cantonese"", ""Telugu"", 
""Urdu""}, #1[[2]] &lt; #2[[2]] &amp;]


What is the best approach to replicate this chart with its two axis, dot, dashed lines , etc?
","It is a Chart so one may want to use BarChart:

(* speakers are stored with [people] units so we have to get rid of it, 
   I'm also deleting Malavian since there is no data now*)
sorted = MapAt[QuantityMagnitude, #, {2}] &amp; /@SortBy[data, #[[2]] &amp;] // Rest
len = Length[sorted]

mark[{{xmin_, xmax_}, {ymin_, ymax_}}, ___] := {Black, AbsolutePointSize@7, 
                                              Point[{Scaled[{0, -.02}, {xmax, ymax}]}]}
topt = Table[{i, 2^i}, {i, 0, 9}];

BarChart[Log[2, sorted[[ ;; , 2]]/10^6], 
         ChartLabels -&gt; sorted[[ ;; , 1]], BarOrigin -&gt; Left, BarSpacing -&gt; Large, 
         GridLines -&gt; {None, Range@len}, GridLinesStyle -&gt; Dotted, 
         ChartElementFunction -&gt; mark, Frame -&gt; {{False, True}, {True, True}},
         AxesOrigin -&gt; {0, -1}, FrameTicks -&gt; {{False, False}, {Automatic, topt}}]



"
2467,2467,3934,Should FPS exceed ticks/second?,"I was once told that you should never re-draw a frame if the game logic has not changed since the last draw. 

Assuming game logic is updated once every tick, and assuming a game runs at 40 FPS @ 20 ticks/second, does that mean that every two consecutive frames will be exactly the same? If so, is there any visual difference between a game running at 40 FPS @ 20 ticks/second versus a game running at 20 FPS @ 20 ticks/second?

Perhaps I don't understand game loops that well, but it seems to me that ticks/second is a limiting factor of FPS.
",mario_sunny,https://gamedev.stackexchange.com/users/41586,"Your engine and your game must be super flexible to allow the possibility of drawing two times with no state change.
A usual game loop ties very closely all updates in a sequential fashion.
One thread, one loop, one point to flush events, one point to execute processing updates (entity/component processors, or simply manager's updates), and finally one render call which triggers the whole engine 1-frame render.  

Whole engine 1 frame render can be made in two fashions, extrospective (intrusive), by accessing (with visitors) the state of the drwable objects of the game, and create the rendering states, passes and commands that go with it.

Or it could be fully retained, and the state of the engine was set BY the processors during the logic update, and it holds sufficient information per se to draw a frame in isolation.

This is a classical game loop. It uses a delta_time variable that is given to all managers during update.

If you have a physical manager, usually there is another loop within the Update itself, that will use a fixed dt and iterate as many time to fill the lagging-time to reach delta_time. And store the remainder for the next frame's refresh, to execute as part of the first loop next time.

Now, its possible to have a more advanced game loop by separating event treatments, by using a thread specific system event queue, preparing a pool of timestamped events, and when the main thread is in the event treatment update, it pulls this queue.

Its hardly possible to completely asychronize managers updates and frame rendering. Many engine state updates are not atomic. Even a fully retained engine will have limitations. DirectX11 introduces isolated command lists (deferred devices, in their parlance), which can help to design such an engine. But if you have such basic doubts about your own render loop, I suppose you don't use such things, yet.

Since you are in java, and you talk about ticks, I imagine you must have plugged your refresh function to a periodic timer. Of course this is sub-par as a game loop design, even from the most basic loop design described above. This is not how real time systems are designed, doing this, you rely on a framework, that depends on operating system native kernel tick rate, and java's virtual machine to relay you the wakening events (and scheduling) to fire up your frame routine. This will incur bad sampling rates (aliasing) and randomness from various sources. You will have to suffer from potentially long sleep times that are not controlled, in the thread ready queue, or kernel timer tick rounding issues. This will all misalign with your framerate presentation, and result in stutterings, and if the event queue is not fully depleted at each refresh, you will also have input lag, and potentially, building up with time. Worse, since you are event based, your events I fear, are consumed by event treatment, therefore your processing time will vary according to input, and delay your frame rendering. Potentially totally masking it out. This is like a security flaw, lots of input could overflow the game and make it unresponsive.

Event based systems are not made for real time applications, they are made for basically idling applications.

Now, back to your question, it should not be a problem to fraw at 40FPS when your game updates at 20. Also be careful, in a timer based system, 20 FPS = 50ms, it will likely round up to 60ms (4*15 ; 15=typical kernel), therefore you'll get 16FPS. Use some precise chronometers to display frame update time on screen, and another one to display display rate. (use a counter around the Present call. Or framebuffer Swap (OpenGL term), or simply install Fraps.)

This will give you some statistics.

The people advocating that high display rates are bad probably refer to useless loss of resource, resulting in machine heating up, or the useless frame taking time to finish, the GPU is not ready to render the next frame when its ready, that is to say, likely right in the middle of the useless redraw. Which is why, no redraw = better responsiveness, leaving the GPU available right away when the next frame is ready.

Also tearing, is an argument often heard. Tearing is caused by swappings (presentations) frequencies that are non multiples of the screen frequency. the VSynch is the feature that helps that, by using hardware support, the VGA/DVI/HDMI cable transports a tick signal that says ""I flipped!"", the graphic cards receives it, signal it to the CPU with an interrupt (most likely), and the driver gets it and communicate it to the currently waiting OpenGL/DirectX presenting threads. This unleash a fast back-to-front copy, which executes in much less that the 60Hz timeframe, and then when the screen next flips, a full image is presented, this avoids perfectly the tearing.

The best is to respect this presentation rate, it is a tempo given by hardware, and the whole game/engine thread is put to sleep by the graphics API itself inside of the Swap/Present call, which allows to rest the CPU, allowing it to cool down, and allows perfect frame/game synchronization if using a linear loop like mentioned above.

Provided your game can update faster than 60Hz. Otherwise, it will fallback immediately to 30Fps naturally, then 20, then 15, by plateaus. This is a natural response.
",v.oddou,https://gamedev.stackexchange.com/users/35669,http://gamedev.stackexchange.com/questions/86460/should-fps-exceed-ticks-second,TECHNOLOGY,gamedev.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,1.0,1.0,1.0,0.6666666666666666,0.4444444444444444,0.3333333333333333,0.0,0.3333333333333333,1.0,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.0,0.7777777777777778,0.8888888888888888,0.7777777777777778,0.8888888888888888,0.8888888888888888,0.9,0.6666666666666666,0.0,0.6666666666666666,0.8888888888888888,Should FPS exceed ticks / second?,"I was once told that you should never re-draw a frame if the game logic has not changed since the last draw. 

Assuming game logic is updated once every tick, and assuming a game runs at 40 FPS @ 20 ticks/second, does that mean that every two consecutive frames will be exactly the same? If so, is there any visual difference between a game running at 40 FPS @ 20 ticks/second versus a game running at 20 FPS @ 20 ticks/second?

Perhaps I don't understand game loops that well, but it seems to me that ticks/second is a limiting factor of FPS.
","Your engine and your game must be super flexible to allow the possibility of drawing two times with no state change.
A usual game loop ties very closely all updates in a sequential fashion.
One thread, one loop, one point to flush events, one point to execute processing updates (entity/component processors, or simply manager's updates), and finally one render call which triggers the whole engine 1-frame render.  

Whole engine 1 frame render can be made in two fashions, extrospective (intrusive), by accessing (with visitors) the state of the drwable objects of the game, and create the rendering states, passes and commands that go with it.

Or it could be fully retained, and the state of the engine was set BY the processors during the logic update, and it holds sufficient information per se to draw a frame in isolation.

This is a classical game loop. It uses a delta_time variable that is given to all managers during update.

If you have a physical manager, usually there is another loop within the Update itself, that will use a fixed dt and iterate as many time to fill the lagging-time to reach delta_time. And store the remainder for the next frame's refresh, to execute as part of the first loop next time.

Now, its possible to have a more advanced game loop by separating event treatments, by using a thread specific system event queue, preparing a pool of timestamped events, and when the main thread is in the event treatment update, it pulls this queue.

Its hardly possible to completely asychronize managers updates and frame rendering. Many engine state updates are not atomic. Even a fully retained engine will have limitations. DirectX11 introduces isolated command lists (deferred devices, in their parlance), which can help to design such an engine. But if you have such basic doubts about your own render loop, I suppose you don't use such things, yet.

Since you are in java, and you talk about ticks, I imagine you must have plugged your refresh function to a periodic timer. Of course this is sub-par as a game loop design, even from the most basic loop design described above. This is not how real time systems are designed, doing this, you rely on a framework, that depends on operating system native kernel tick rate, and java's virtual machine to relay you the wakening events (and scheduling) to fire up your frame routine. This will incur bad sampling rates (aliasing) and randomness from various sources. You will have to suffer from potentially long sleep times that are not controlled, in the thread ready queue, or kernel timer tick rounding issues. This will all misalign with your framerate presentation, and result in stutterings, and if the event queue is not fully depleted at each refresh, you will also have input lag, and potentially, building up with time. Worse, since you are event based, your events I fear, are consumed by event treatment, therefore your processing time will vary according to input, and delay your frame rendering. Potentially totally masking it out. This is like a security flaw, lots of input could overflow the game and make it unresponsive.

Event based systems are not made for real time applications, they are made for basically idling applications.

Now, back to your question, it should not be a problem to fraw at 40FPS when your game updates at 20. Also be careful, in a timer based system, 20 FPS = 50ms, it will likely round up to 60ms (4*15 ; 15=typical kernel), therefore you'll get 16FPS. Use some precise chronometers to display frame update time on screen, and another one to display display rate. (use a counter around the Present call. Or framebuffer Swap (OpenGL term), or simply install Fraps.)

This will give you some statistics.

The people advocating that high display rates are bad probably refer to useless loss of resource, resulting in machine heating up, or the useless frame taking time to finish, the GPU is not ready to render the next frame when its ready, that is to say, likely right in the middle of the useless redraw. Which is why, no redraw = better responsiveness, leaving the GPU available right away when the next frame is ready.

Also tearing, is an argument often heard. Tearing is caused by swappings (presentations) frequencies that are non multiples of the screen frequency. the VSynch is the feature that helps that, by using hardware support, the VGA/DVI/HDMI cable transports a tick signal that says ""I flipped!"", the graphic cards receives it, signal it to the CPU with an interrupt (most likely), and the driver gets it and communicate it to the currently waiting OpenGL/DirectX presenting threads. This unleash a fast back-to-front copy, which executes in much less that the 60Hz timeframe, and then when the screen next flips, a full image is presented, this avoids perfectly the tearing.

The best is to respect this presentation rate, it is a tempo given by hardware, and the whole game/engine thread is put to sleep by the graphics API itself inside of the Swap/Present call, which allows to rest the CPU, allowing it to cool down, and allows perfect frame/game synchronization if using a linear loop like mentioned above.

Provided your game can update faster than 60Hz. Otherwise, it will fallback immediately to 30Fps naturally, then 20, then 15, by plateaus. This is a natural response.
"
3179,3179,5066,Understanding one-way hash functions construction,"I understand the needs that lead to the development of cryptography and I am quite familiar with the uses we make of the cryptographic tools.

But, as a programmer, I am conditioned to see them as ""black boxes"" with specific properties. To me, SHA-X (with X being 1, 2 or 3) is some dark magic, even though I understand why I need it and use it.

That said, I am eager to find some literature to light this up.
From what I have read so far, I have seen that the common mathematical demonstrations consist of games and the evaluation of the winning advantage of an enlightened attacker over a player that would just randomly take decisions. This is exactly the kind of things I am looking for : what mathematical background lead to this construction for this hash function. Learning through an example can be worthy, but the more global this maths background is, the better.

To say it in other words, how does a cryptographer prove the essential properties of his design ? In the case of cryptographic hash functions, these properties are one-wayness, collision resistance and preimage resistances.

What are the logical steps, starting from the required properties, that lead to the specification of a hash function ? How are these properties translated into mathematical definitions ?

Note : I think I needed to ask that last question because for a cryptographic hash function, I feel there is the need to define some thresholds somewhere.
",Rerito,https://crypto.stackexchange.com/users/4977,"First, it's important to understand that no one knows how to build a practical hash function that is provably secure.

The stuff you've read about games and advantage are part of a theory for proving schemes secure, but that theory doesn't help you build a provably secure hash function all that much.  Rather, it starts from the assumption that a particular hash function is secure (or a block cipher or stream cipher is secure), and then builds more complicated stuff out of those basic building blocks.  So, that theory doesn't help us design the basic building blocks, like hash functions, in the first place.  (Sometimes the theory is used to help guide the design of the structure of a hash function, where designers build a hash function out of a building block like a compression function.  The designers might use the theoretical analysis to demonstrate that if the compression function is good, then the hash function will be good -- but it doesn't help you with the question of how to design a good compression function.)

For more details on how we know that a hash function is secure, see my answer to a similar question (on the IT Security Stack Exchange site).

Generally speaking, to learn how to build a secure hash function, you start by learning about all of the various attacks on hash functions.  Then, you try to design a hash function that will resist all of those attacks (as well as all others you can imagine).  Therefore, a good starting place for you would be to read about attacks on hash functions.

You could start by reading Chapter 9 of the Handbook of Applied Cryptography.  Also check out Wikipedia's articles on cryptographic hash functions and the Merkle–Damgård construction.
Then, you could read all of the submissions to the NIST hash algorithm competition; most of the submissions should provide a design rationale and security analysis, which should give you a chance to read about some of the attacks on hash functions and design strategies.  They should also cite related papers in the research literature, so next you could read papers in the research literature on hash function cryptanalysis -- you might start by reading the papers cited in the Wikipedia links mentioned above, then proceed to reading papers that are cited in submissions to the NIST competition or that you find through others means.  For instance, it's worth reading about parallel collision search, multicollision attacks, indifferentiability, and the sponge construction.

After several years of study, you'll be well on your way to becoming an expert in hash function cryptanalysis, and then you might be ready to start thinking about designing your own hash function.
",D.W.,https://crypto.stackexchange.com/users/351,http://crypto.stackexchange.com/questions/7903/understanding-one-way-hash-functions-construction,TECHNOLOGY,crypto.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,0.5,1.0,1.0,0.4444444444444444,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,0.7777777777777778,0.8888888888888888,0.8,0.6666666666666666,0.3333333333333333,1.0,0.8888888888888888,Understanding the construction of one-way hash function,"I understand the needs that lead to the development of cryptography and I am quite familiar with the uses we make of the cryptographic tools.

But, as a programmer, I am conditioned to see them as ""black boxes"" with specific properties. To me, SHA-X (with X being 1, 2 or 3) is some dark magic, even though I understand why I need it and use it.

That said, I am eager to find some literature to light this up.
From what I have read so far, I have seen that the common mathematical demonstrations consist of games and the evaluation of the winning advantage of an enlightened attacker over a player that would just randomly take decisions. This is exactly the kind of things I am looking for : what mathematical background lead to this construction for this hash function. Learning through an example can be worthy, but the more global this maths background is, the better.

To say it in other words, how does a cryptographer prove the essential properties of his design ? In the case of cryptographic hash functions, these properties are one-wayness, collision resistance and preimage resistances.

What are the logical steps, starting from the required properties, that lead to the specification of a hash function ? How are these properties translated into mathematical definitions ?

Note : I think I needed to ask that last question because for a cryptographic hash function, I feel there is the need to define some thresholds somewhere.
","First, it's important to understand that no one knows how to build a practical hash function that is provably secure.

The stuff you've read about games and advantage are part of a theory for proving schemes secure, but that theory doesn't help you build a provably secure hash function all that much.  Rather, it starts from the assumption that a particular hash function is secure (or a block cipher or stream cipher is secure), and then builds more complicated stuff out of those basic building blocks.  So, that theory doesn't help us design the basic building blocks, like hash functions, in the first place.  (Sometimes the theory is used to help guide the design of the structure of a hash function, where designers build a hash function out of a building block like a compression function.  The designers might use the theoretical analysis to demonstrate that if the compression function is good, then the hash function will be good -- but it doesn't help you with the question of how to design a good compression function.)

For more details on how we know that a hash function is secure, see my answer to a similar question (on the IT Security Stack Exchange site).

Generally speaking, to learn how to build a secure hash function, you start by learning about all of the various attacks on hash functions.  Then, you try to design a hash function that will resist all of those attacks (as well as all others you can imagine).  Therefore, a good starting place for you would be to read about attacks on hash functions.

You could start by reading Chapter 9 of the Handbook of Applied Cryptography.  Also check out Wikipedia's articles on cryptographic hash functions and the Merkle–Damgård construction.
Then, you could read all of the submissions to the NIST hash algorithm competition; most of the submissions should provide a design rationale and security analysis, which should give you a chance to read about some of the attacks on hash functions and design strategies.  They should also cite related papers in the research literature, so next you could read papers in the research literature on hash function cryptanalysis -- you might start by reading the papers cited in the Wikipedia links mentioned above, then proceed to reading papers that are cited in submissions to the NIST competition or that you find through others means.  For instance, it's worth reading about parallel collision search, multicollision attacks, indifferentiability, and the sponge construction.

After several years of study, you'll be well on your way to becoming an expert in hash function cryptanalysis, and then you might be ready to start thinking about designing your own hash function.
"
3010,3010,4797,Connect to Microsoft Access database via Microsoft SQL Server / MySQL,"A client has an Microsoft Access database where they save their products.
To access the database now you have to login via VPN and open Microsoft Office Access.
I need to access this database from a PHP script running on another server.

I've done some research and found that it's not possible to connect to an Access database like a MySQL database.
So what I wonder is if it may be possible to set up an Microsoft SQL Server on the same server that uses the Microsoft Access database. So I can connect to the Microsoft SQL Server with the PHP script. Or if it's possible MySQL.

They are running Microsoft Windows Server 2008 and Microsoft Office Access 2003.
",Patrik,https://dba.stackexchange.com/users/27985,"I thought you could use php to connect to an Access database.

Here's the php manual on this topic: http://php.net/manual/en/function.odbc-connect.php

And a code sample from that page connecting to Access database.

&lt;?php
// Microsoft SQL Server using the SQL Native Client 10.0 ODBC Driver - allows connection to SQL 7, 2000, 2005 and 2008
$connection = odbc_connect(""Driver={SQL Server Native Client 10.0};Server=$server;Database=$database;"", $user, $password);

// Microsoft Access
$connection = odbc_connect(""Driver={Microsoft Access Driver (*.mdb)};Dbq=$mdbFilename"", $user, $password);

// Microsoft Excel
$excelFile = realpath('C:/ExcelData.xls');
$excelDir = dirname($excelFile);
$connection = odbc_connect(""Driver={Microsoft Excel Driver (*.xls)};DriverId=790;Dbq=$excelFile;DefaultDir=$excelDir"" , '', '');
?&gt;

",sa555,https://dba.stackexchange.com/users/26481,http://dba.stackexchange.com/questions/49492/connect-to-microsoft-access-database-via-microsoft-sql-server-mysql,TECHNOLOGY,dba.stackexchange.com,1.0,0.3333333333333333,0.0,0.0,1.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8,0.0,0.0,1.0,1.0,Connect to Microsoft Access database through Microsoft SQL Server / MySQL,"A client has an Microsoft Access database where they save their products.
To access the database now you have to login via VPN and open Microsoft Office Access.
I need to access this database from a PHP script running on another server.

I've done some research and found that it's not possible to connect to an Access database like a MySQL database.
So what I wonder is if it may be possible to set up an Microsoft SQL Server on the same server that uses the Microsoft Access database. So I can connect to the Microsoft SQL Server with the PHP script. Or if it's possible MySQL.

They are running Microsoft Windows Server 2008 and Microsoft Office Access 2003.
","I thought you could use php to connect to an Access database.

Here's the php manual on this topic: http://php.net/manual/en/function.odbc-connect.php

And a code sample from that page connecting to Access database.

&lt;?php
// Microsoft SQL Server using the SQL Native Client 10.0 ODBC Driver - allows connection to SQL 7, 2000, 2005 and 2008
$connection = odbc_connect(""Driver={SQL Server Native Client 10.0};Server=$server;Database=$database;"", $user, $password);

// Microsoft Access
$connection = odbc_connect(""Driver={Microsoft Access Driver (*.mdb)};Dbq=$mdbFilename"", $user, $password);

// Microsoft Excel
$excelFile = realpath('C:/ExcelData.xls');
$excelDir = dirname($excelFile);
$connection = odbc_connect(""Driver={Microsoft Excel Driver (*.xls)};DriverId=790;Dbq=$excelFile;DefaultDir=$excelDir"" , '', '');
?&gt;

"
5693,5693,9024,How to crop a square at the exact centre of an image in Photoshop?,"Given a square image, how can I crop, at the exact center, of the image?

What if the image is not square itself?

What if I'm using Photoshop CS6 or some older version? 
Is the procedure the same?
",Pippo,https://graphicdesign.stackexchange.com/users/36498,"A simple method that works in all programs is to add another layer, and create a line from the upper left to the lower right corners, and the same for upper right to lower left. You can then select all, scale selection, and line it up on these lines. This will crop to the same aspect ratio, with a different overall size.

Like this:


While hardly being an elegant solution, it has the advantage of working on any platform.
",veryRandomMe,https://graphicdesign.stackexchange.com/users/35875,http://graphicdesign.stackexchange.com/questions/45295/how-to-crop-a-square-at-the-exact-centre-of-an-image-in-photoshop,LIFE_ARTS,graphicdesign.stackexchange.com,1.0,0.8888888888888888,0.0,0.3333333333333333,0.6666666666666666,1.0,0.4444444444444444,0.4444444444444444,0.6666666666666666,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,0.0,0.8888888888888888,How to cut the square in the center of the image in Photoshop?,"Given a square image, how can I crop, at the exact center, of the image?

What if the image is not square itself?

What if I'm using Photoshop CS6 or some older version? 
Is the procedure the same?
","A simple way to work in all programs is to add another layer and create a line from the top left to the bottom right, as well as from the top right to the bottom left. You can then select all, scale the selection, and arrange it on these lines. This will be cropped to the same aspect ratio with a different overall size."
724,724,1149,Meteor renderList intercept? client side,"I have chat messages displayed like this:

  {{#each msg}}
    {{&gt; chatMsg}}
  {{/each}}


When users enter the chat I add a document to the collection with user joins the chat. When a user rapidly reenters and leaves the chat I don't want to duplicate user joins the chat over and over again. I want to display something like user joins the chat x3.

Is there a way to do this on the client side by hooking into renderList? I know I can change the doc on the server side but it seems unnecessarily intensive.
",Harry,https://stackoverflow.com/users/663447,"The easiest way to get there from here is to write a custom publisher.  Instead of just returning a cursor from your publish function, call observe() on your cursor within the publish function, and do the appropriate set(), unset(), and flush() calls within that, that do the appropriate multiplying a previous message instead of adding a new one.   You can find the relevant documentation at the meteor documentation for Meteor.publish

To get a basis from comparison, you can look at the current code to publish a Cursor, which is  in packages/mongo-livedata/mongo_driver.js, in Cursor.prototype._publishCursor.  

Note: My answer here is for Meteor 0.5.2.  The API for custom publishers is going to be changing in a future release of Meteor, and there will be different functions you have to call than set() unset() and flush()
",Naomi Seyfer,https://stackoverflow.com/users/1892918,http://stackoverflow.com/questions/13663765/meteor-renderlist-intercept-client-side,STACKOVERFLOW,stackoverflow.com,1.0,0.4444444444444444,0.0,0.3333333333333333,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.5555555555555556,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.7777777777777778,1.0,0.7777777777777778,1.0,1.0,0.9333333333333332,1.0,0.3333333333333333,0.3333333333333333,1.0,Meteor Radar capture? Client,"I have chat messages displayed like this:

  {{#each msg}}
    {{&gt; chatMsg}}
  {{/each}}


When users enter the chat I add a document to the collection with user joins the chat. When a user rapidly reenters and leaves the chat I don't want to duplicate user joins the chat over and over again. I want to display something like user joins the chat x3.

Is there a way to do this on the client side by hooking into renderList? I know I can change the doc on the server side but it seems unnecessarily intensive.
","The easiest way to get there from here is to write a custom publisher.  Instead of just returning a cursor from your publish function, call observe() on your cursor within the publish function, and do the appropriate set(), unset(), and flush() calls within that, that do the appropriate multiplying a previous message instead of adding a new one.   You can find the relevant documentation at the meteor documentation for Meteor.publish

To get a basis from comparison, you can look at the current code to publish a Cursor, which is  in packages/mongo-livedata/mongo_driver.js, in Cursor.prototype._publishCursor.  

Note: My answer here is for Meteor 0.5.2.  The API for custom publishers is going to be changing in a future release of Meteor, and there will be different functions you have to call than set() unset() and flush()
"
3255,3255,5188,How much choice should I give users?,"I am considering adding an update to my iPhone app that allows the user to choose many new features such as the background image, where certain buttons are located, button colors, button design, certain label colors, etc. While I have a lot of ideas on where I could allow the user to change things, I wonder how much choice I should give them.

If I give them too much choice is it possible they will give me bad reviews, or is the opposite more often true? 

Also, if I give them that choice, should I put that all in a single preference panel, or should I split it up somehow? (I don't like using the Settings App, so I'm not asking about that here)
",cory ginsberg,https://ux.stackexchange.com/users/22960,"
  How much choice should I give users?


As little as possible that can net as large users as possible. As a rule of thumb, don't add choices when it does not matter. 

If the selling point of your app is productivity, only add choices when it affects workflow significantly. Again, don't add trivial customizations, things like position of buttons, colors, etc usually does not really matter.

If the selling point of your app is customization and personalization (most apps should not have this as the main selling point), things are a little different, put a set of different options as complete ""themes"" instead of individual options. Most people cannot make good themes, even if they think they do; you'll be having people walk around showing off your app with their crappy customizations. 

If the selling point of your app is ease of use, then less is more. Less means everyone will be using the same app the same way and there is less mine traps for the less proficient users.

Giving too many options is often born out of laziness, you're not doing your user research enough to actually know what they really needed so you give everything.
",Lie Ryan,https://ux.stackexchange.com/users/1908,http://ux.stackexchange.com/questions/31418/how-much-choice-should-i-give-users,TECHNOLOGY,ux.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.7777777777777778,0.6666666666666666,0.6666666666666666,0.0,1.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.8,0.3333333333333333,0.0,0.6666666666666666,1.0,How many choices should I give users?,"I'm considering adding an update to my iPhone app that allows users to choose many new features, such as background images, location of some buttons, button colors, button design, some label colors, and so on. Although I have a lot of ideas about where to allow users to change things, I want to know how many choices I should give them.","
  How much choice should I give users?


As little as possible that can net as large users as possible. As a rule of thumb, don't add choices when it does not matter. 

If the selling point of your app is productivity, only add choices when it affects workflow significantly. Again, don't add trivial customizations, things like position of buttons, colors, etc usually does not really matter.

If the selling point of your app is customization and personalization (most apps should not have this as the main selling point), things are a little different, put a set of different options as complete ""themes"" instead of individual options. Most people cannot make good themes, even if they think they do; you'll be having people walk around showing off your app with their crappy customizations. 

If the selling point of your app is ease of use, then less is more. Less means everyone will be using the same app the same way and there is less mine traps for the less proficient users.

Giving too many options is often born out of laziness, you're not doing your user research enough to actually know what they really needed so you give everything.
"
5005,5005,7969,Should FPS exceed ticks/second?,"I was once told that you should never re-draw a frame if the game logic has not changed since the last draw. 

Assuming game logic is updated once every tick, and assuming a game runs at 40 FPS @ 20 ticks/second, does that mean that every two consecutive frames will be exactly the same? If so, is there any visual difference between a game running at 40 FPS @ 20 ticks/second versus a game running at 20 FPS @ 20 ticks/second?

Perhaps I don't understand game loops that well, but it seems to me that ticks/second is a limiting factor of FPS.
",mario_sunny,https://gamedev.stackexchange.com/users/41586,"It depends on your design.

If you have interpolation/extrapolation in your render layer, then any extra frames will add to the smoothness on animation. For example particle effects don't affect games logic and can use much higher framerates. Your GUI might work at higher framerates to respond to player interaction faster.

If there's indeed no change between frames (no interpolation/extrapolation/GUI), then skipping the extra frames is beneficial, since that extra frame might overlap with next ticks frame, delaying it.
",Kromster,https://gamedev.stackexchange.com/users/3644,http://gamedev.stackexchange.com/questions/86460/should-fps-exceed-ticks-second,TECHNOLOGY,gamedev.stackexchange.com,0.8888888888888888,0.4444444444444444,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,0.8888888888888888,Should FPS exceed ticks / second?,"I was once told that you should never re-draw a frame if the game logic has not changed since the last draw. 

Assuming game logic is updated once every tick, and assuming a game runs at 40 FPS @ 20 ticks/second, does that mean that every two consecutive frames will be exactly the same? If so, is there any visual difference between a game running at 40 FPS @ 20 ticks/second versus a game running at 20 FPS @ 20 ticks/second?

Perhaps I don't understand game loops that well, but it seems to me that ticks/second is a limiting factor of FPS.
","It depends on your design.

If you have interpolation/extrapolation in your render layer, then any extra frames will add to the smoothness on animation. For example particle effects don't affect games logic and can use much higher framerates. Your GUI might work at higher framerates to respond to player interaction faster.

If there's indeed no change between frames (no interpolation/extrapolation/GUI), then skipping the extra frames is beneficial, since that extra frame might overlap with next ticks frame, delaying it.
"
1155,1155,1814,How to store length of time in a model with Rails?,"I can think of two solutions:

1) Store hours, minutes, seconds, etc. in separate columns in the database


Downside: a lot of columns


2) Convert and store the number of seconds


We still want to be able to show seperate fields for hour, minute, second, etc. in the form. We could write virtual attribute for each of these and write a before_save callback that converts the timespan to seconds (still messy tho).


Am I missing some other obvious solution? How do you people do this?
",randomguy,https://stackoverflow.com/users/377920,"I prefer to have separate columns in the database if I'm receiving the input via 3 fields on the form - it keeps things much cleaner and simpler (and after all, nowadays a few extra columns in a table isn't much to worry about). Then all you need is a nice method to output the stuff nicely.
",Ant,https://stackoverflow.com/users/289832,http://stackoverflow.com/questions/5532817/how-to-store-length-of-time-in-a-model-with-rails,STACKOVERFLOW,stackoverflow.com,1.0,0.6666666666666666,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,1.0,1.0,0.7333333333333333,0.3333333333333333,0.6666666666666666,0.3333333333333333,0.8888888888888888,How do I store the length of time in a model with rails?,"I can think of two solutions:

1) Store hours, minutes, seconds, etc. in separate columns in the database


Downside: a lot of columns


2) Convert and store the number of seconds


We still want to be able to show seperate fields for hour, minute, second, etc. in the form. We could write virtual attribute for each of these and write a before_save callback that converts the timespan to seconds (still messy tho).


Am I missing some other obvious solution? How do you people do this?
","I prefer to have separate columns in the database if I'm receiving the input via 3 fields on the form - it keeps things much cleaner and simpler (and after all, nowadays a few extra columns in a table isn't much to worry about). Then all you need is a nice method to output the stuff nicely.
"
208,208,332,"Superlatives with ""the""","What is the rule regarding using the with superlatives? For example:


  
  John is the fastest among his friends.
  John is fastest among his friends.
  


Both appear to be correct.   I have seen both formats in a variety of places.
",BVDL,https://english.stackexchange.com/users/10006,"Both are indeed correct. An article is only necessary in the superlative (or comparative) if the adjective is attributive (i.e. is in the same phrase as the noun it is describing).

Consider the following examples:


  
  Example #1:
  
  John is the fastest boy.
  *John is fastest boy.
  
  Example #2
  
  John is the fastest among his friends.
  John is fastest among his friends.
  
  


As is shown in the examples above, omitting the in #1 causes it to become ungrammatical, as the superlative fastest is in the same phrase as its noun boy. In #2, however, the may be freely omitted as it is not attributive.

Some English superlatives, however, use the adverb most, which can cause some amount of confusion. Consider the following examples:


  
  Mary is the most beautiful.
  Mary is most beautiful.
  Mary is a most beautiful woman.
  


All three of these examples are grammatical and show the overlap of an adverbial intensification with the superlative. With the definite article the, it can only be a superlative, but with the indefinite article a it can only be interpreted adverbially (i.e. essentially the same as ""very beautiful""). Both of these forms, however, allow omission of the article, and so the meaning of #2 is left ambiguous.

Note that there is a third form which is related to the superlative known as the elative. While it is not a separate inflection, it can be shown to exist in constructions such as the following:


  
  It is with the greatest pleasure [...]
  


This sentence is generally understood not to mean with a pleasure greater than any other, but rather something more akin to with extreme pleasure.
",rintaun,https://english.stackexchange.com/users/9999,http://english.stackexchange.com/questions/30272/superlatives-with-the,CULTURE,english.stackexchange.com,1.0,0.4444444444444444,0.0,1.0,1.0,0.6666666666666666,0.6666666666666666,0.7777777777777778,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.6666666666666666,0.0,0.7777777777777778,1.0,0.7777777777777778,1.0,0.8888888888888888,0.9333333333333332,0.0,0.0,1.0,0.8888888888888888,"Top level with ""the""","What is the rule regarding using the with superlatives? For example:


  
  John is the fastest among his friends.
  John is fastest among his friends.
  


Both appear to be correct.   I have seen both formats in a variety of places.
","Both are indeed correct. An article is only necessary in the superlative (or comparative) if the adjective is attributive (i.e. is in the same phrase as the noun it is describing).

Consider the following examples:


  
  Example #1:
  
  John is the fastest boy.
  *John is fastest boy.
  
  Example #2
  
  John is the fastest among his friends.
  John is fastest among his friends.
  
  


As is shown in the examples above, omitting the in #1 causes it to become ungrammatical, as the superlative fastest is in the same phrase as its noun boy. In #2, however, the may be freely omitted as it is not attributive.

Some English superlatives, however, use the adverb most, which can cause some amount of confusion. Consider the following examples:


  
  Mary is the most beautiful.
  Mary is most beautiful.
  Mary is a most beautiful woman.
  


All three of these examples are grammatical and show the overlap of an adverbial intensification with the superlative. With the definite article the, it can only be a superlative, but with the indefinite article a it can only be interpreted adverbially (i.e. essentially the same as ""very beautiful""). Both of these forms, however, allow omission of the article, and so the meaning of #2 is left ambiguous.

Note that there is a third form which is related to the superlative known as the elative. While it is not a separate inflection, it can be shown to exist in constructions such as the following:


  
  It is with the greatest pleasure [...]
  


This sentence is generally understood not to mean with a pleasure greater than any other, but rather something more akin to with extreme pleasure.
"
451,451,704,Test-Path returns differetn results in 64Bit and 32Bit powershell,"I am developing a script which should run under 64 and 32Bit Powershell. Unfortunately it seems that Test-Path return different results in 64 and 32 Environment. Both sessions are running under same user, this user has full access on specific registry key.

64Bit Powershell
&gt;test-path HKLM:\SOFTWARE\Citrix\ProvisioningServices
True

32Bit Powershell(x86)
&gt;test-path HKLM:\SOFTWARE\Citrix\ProvisioningServices
False


Any Idea?
",StarSpace,https://serverfault.com/users/123006,"32-bit programs default to the WOW64 node in the registry, but see it as ""normal"". If the key does not exist in WOW64 then it is correctly returning false.
",Mark Henderson,https://serverfault.com/users/7709,http://serverfault.com/questions/394282,TECHNOLOGY,serverfault.com,1.0,0.4444444444444444,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,0.8,0.0,0.0,1.0,1.0,The test path returns different results in 64 bit and 32-bit PowerShell,"I'm developing a script that should run under 64 bit and 32-bit PowerShell. Unfortunately, in 64 and 32 environments, the test path appears to return different results. Two sessions run under the same user, who has full access to a specific registry key.","32-bit programs default to the WOW64 node in the registry, but see it as ""normal"". If the key does not exist in WOW64 then it is correctly returning false.
"
2524,2524,4026,AE: Parent Element to a point of a path?,"I want to parent an element (pre-compose) to one of the points on a path.

Imagine a line that has two paths. I want to parent an object (say, a leaf) to the top point of the path. So if my path is to have a bounce effect (the point of the path will move to create the effect...), so will my leaf.

Ultimately, it should (the leaf) move the same as my bounce line's top point.

Thanks!
",Benjamin,https://graphicdesign.stackexchange.com/users/35908,"You'll want to go and download Chris Green's Script Vertex to Point. Then depending on your object you can use that along with Null Objects and Pick Whips to achieve your desired effect.

If your entire line is moving and you want it to track the entire line, not just a vertex then you could do it without the script just by using Null Objects and Pick Whip.

Another way without needing a script, if its a straight line, would be to use Null Objects and Generate Beam. The Beam becomes your line while giving you full usage of X/Y coordinates to Pick Whip to.
",Ryan,https://graphicdesign.stackexchange.com/users/2611,http://graphicdesign.stackexchange.com/questions/44640/ae-parent-element-to-a-point-of-a-path,LIFE_ARTS,graphicdesign.stackexchange.com,1.0,0.6666666666666666,0.0,0.0,1.0,1.0,0.8333333333333334,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,1.0,Parent element to a point in the path?,"I want to parent an element (pre-compose) to one of the points on a path.

Imagine a line that has two paths. I want to parent an object (say, a leaf) to the top point of the path. So if my path is to have a bounce effect (the point of the path will move to create the effect...), so will my leaf.

Ultimately, it should (the leaf) move the same as my bounce line's top point.

Thanks!
","You'll want to go and download Chris Green's Script Vertex to Point. Then depending on your object you can use that along with Null Objects and Pick Whips to achieve your desired effect.

If your entire line is moving and you want it to track the entire line, not just a vertex then you could do it without the script just by using Null Objects and Pick Whip.

Another way without needing a script, if its a straight line, would be to use Null Objects and Generate Beam. The Beam becomes your line while giving you full usage of X/Y coordinates to Pick Whip to.
"
1496,1496,2355,Integrate a division of polynomials,"Hi I have the following integral:
$$\int \frac{2x}{x^2+6x+3}\, dx$$

I made some changes like:
$$\int \dfrac{2x+6-6}{x^2+6x+3}\, dx$$

then I have: 
$$\int \dfrac{2x+6}{x^2+6x+3}\, dx -\int\dfrac{6}{x^2+6x+3}\, dx$$

and thus: $$\ln(x^2+6x+3)-\int\dfrac{6}{x^2+6x+3}\, dx$$

Ok, I have decomposed $$\frac{2x}{x^2+6x+3} $$  in: $$ \frac{3+\sqrt6}{\sqrt6(x+\sqrt 6+3)} + \frac{3-\sqrt6}{\sqrt6 (-x+\sqrt6-3)}$$

How can I integrate this expressions?
",Luis Armando,https://math.stackexchange.com/users/162185,"Another idea (just reducing it to another form):

Let $$I=6\int \frac{1}{x^2+6x+3} dx=6\int \frac{1}{(x+3)^2-6} dx=\int \frac{1}{(\frac{1}{\sqrt{6}}(x+3))^2-1} dx$$.

Now let $$\frac{1}{\sqrt{6}}(x+3)=\cosh a$$, hence using $$\cosh^2 a - 1 = \sinh ^2 a$$ and $$\frac{1}{\sqrt{6}} = \sinh a \frac{da}{dx}\Leftrightarrow dx = da \sinh a \sqrt{6}$$ we get $$I=\int \frac{1}{\sinh ^2 a} da \sinh a\sqrt{6} = \sqrt{6} \int \frac{1}{\sinh a} da$$.

EDIT: Can someone please show me how to write bigger LaTeX?
EDIT2: Neat!
",Is Ne,https://math.stackexchange.com/users/47912,http://math.stackexchange.com/questions/882692/integrate-a-division-of-polynomials,SCIENCE,math.stackexchange.com,1.0,0.4444444444444444,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.3333333333333333,0.0,0.5555555555555556,0.8888888888888888,0.6666666666666666,1.0,1.0,1.0,0.6666666666666666,0.0,0.3333333333333333,0.8888888888888888,Division of integral polynomials,"Hi I have the following integral:
$$\int \frac{2x}{x^2+6x+3}\, dx$$

I made some changes like:
$$\int \dfrac{2x+6-6}{x^2+6x+3}\, dx$$

then I have: 
$$\int \dfrac{2x+6}{x^2+6x+3}\, dx -\int\dfrac{6}{x^2+6x+3}\, dx$$

and thus: $$\ln(x^2+6x+3)-\int\dfrac{6}{x^2+6x+3}\, dx$$

Ok, I have decomposed $$\frac{2x}{x^2+6x+3} $$  in: $$ \frac{3+\sqrt6}{\sqrt6(x+\sqrt 6+3)} + \frac{3-\sqrt6}{\sqrt6 (-x+\sqrt6-3)}$$

How can I integrate this expressions?
","Another idea (just reducing it to another form):

Let $$I=6\int \frac{1}{x^2+6x+3} dx=6\int \frac{1}{(x+3)^2-6} dx=\int \frac{1}{(\frac{1}{\sqrt{6}}(x+3))^2-1} dx$$.

Now let $$\frac{1}{\sqrt{6}}(x+3)=\cosh a$$, hence using $$\cosh^2 a - 1 = \sinh ^2 a$$ and $$\frac{1}{\sqrt{6}} = \sinh a \frac{da}{dx}\Leftrightarrow dx = da \sinh a \sqrt{6}$$ we get $$I=\int \frac{1}{\sinh ^2 a} da \sinh a\sqrt{6} = \sqrt{6} \int \frac{1}{\sinh a} da$$.

EDIT: Can someone please show me how to write bigger LaTeX?
EDIT2: Neat!
"
1966,1966,3131,Find router on network,"I've just bought a Belkin N+ Wireless Router. When I plug it directly into my computer I can navigate to its setup page at 192.168.2.1 - however, when I plug it into a random part of the network it still functions as a wireless hub but I can't get to its setup page at 192.168.2.1

Now I'm guessing that the main router has given it an IP. How can I find out what that is? I've looked on the web page for the main router and listed all IP's that are connected to it and tried to access each one but that didn't work.
",Guy,https://superuser.com/users/3248,"You likely have the router plugged in to the main router via the WAN Port as shown here:



The router is expecting another network device to be transmitting data through that port such as a modem, rather than a computer to be requesting it's administration page from that interface. One of the IPs you see in your main router's administration page is probably assigned to the router, and you'll be able to ping it, but it simply isn't configured to respond with the admin interface from that port. You need to have a device connected to a LAN port or connected via wireless to bring up that interface. Some routers I've worked with may allow configuration via the WAN port, but most do not.
",John T,https://superuser.com/users/1931,http://superuser.com/questions/87212,TECHNOLOGY,superuser.com,1.0,0.3333333333333333,0.0,1.0,1.0,1.0,0.6666666666666666,0.5555555555555556,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.6666666666666666,0.0,1.0,1.0,Find a router on the network,"I just bought a Belkin n + wireless router. When I plug it directly into my computer, I can navigate to the settings page of 192.168.2.1 - but when I plug it into the random part of the network, it still works as a wireless hub, but I can't access the settings page of 192.168.2.1","You likely have the router plugged in to the main router via the WAN Port as shown here:



The router is expecting another network device to be transmitting data through that port such as a modem, rather than a computer to be requesting it's administration page from that interface. One of the IPs you see in your main router's administration page is probably assigned to the router, and you'll be able to ping it, but it simply isn't configured to respond with the admin interface from that port. You need to have a device connected to a LAN port or connected via wireless to bring up that interface. Some routers I've worked with may allow configuration via the WAN port, but most do not.
"
5331,5331,8470,How and when does SQL Agent update next_run_date/next_run_time values?,"I've been working on code in T-SQL to add new schedules to a SQL Agent job  using the sp_add_jobschedule proc in the msdb database.  When I add a new schedule (typically a run-once at a specific date/time) and immediately look at the values in sysjobschedules and sysschedules, I can see that the new schedule has been added and is tied to the job_id for my SQL Agent job. However, the values for next_run_date and next_run_time have 0 in them.  When I come back and look at them again in 2 or 3 minutes, they still show 0's in them.  However when I come back another 5 or 10 minutes later, it now correctly shows the date and time values corresponding to the next scheduled run.

So my questions are:


How often do these values get updated?
What process is it that updates these values?
If I were to add a schedule that was, say, 1 minute in the future, does that mean that the job will not run since the next_run_date/time haven't been updated yet?


Example of the code I use to add a new schedule:

exec msdb.dbo.sp_add_jobschedule @job_id = @jobID
                    , @name = @JobName
                    , @enabled = 1
                    , @freq_type = 1
                    , @freq_interval = 0
                    , @freq_subday_type = 0
                    , @freq_subday_interval = 0
                    , @freq_relative_interval = 0
                    , @freq_recurrence_factor = 0
                    , @active_start_date = @ScheduleRunDate
                    , @active_end_date = 99991231
                    , @active_start_time = @ScheduleRunTime
                    , @active_end_time = 235959


where @jobID is binary(16) that holds the job_id of the job in question, @ScheduleRunDate and @ScheduleRunTime are INTs with the date and time respectively.
",BBlake,https://dba.stackexchange.com/users/3898,"Short Answer

It looks like the data in msdb.dbo.sysjobschedules is updated by a background thread in SQL Agent, identified as SQLAgent - Schedule Saver, every 20 minutes (or less frequently, if xp_sqlagent_notify has not been called and no jobs have run in the meantime).

For more accurate information, look at next_scheduled_run_date in msdb.dbo.sysjobactivity. This is updated in real-time any time a job is changed or a job has run. As an added bonus, the sysjobactivity stores the data the right way (as a datetime column), making it a lot easier to work with than those stupid INTs.

That's the short answer: 


  It could be up to 20 minutes before sysjobschedules reflects the truth; however, sysjobactivity will always be up to date. If you want a lot more details about this, or how I figured it out...




Long Answer

If you care to follow the rabbit for a moment, when you call sp_add_jobschedule, this chain of events is set into motion:

msdb.dbo.sp_add_jobschedule == calls ==&gt; msdb.dbo.sp_add_schedule
                                         msdb.dbo.sp_attach_schedule

msdb.dbo.sp_attach_schedule == calls ==&gt; msdb.dbo.sp_sqlagent_notify

msdb.dbo.sp_sqlagent_notify == calls ==&gt; msdb.dbo.xp_sqlagent_notify


Now, we can't chase the rabbit any further, because we can't really peek into what xp_sqlagent_notify does. But I think we can presume that this extended procedure interacts with the Agent service and tells it that there has been a change to this specific job and schedule. By running a server-side trace we can see that, immediately, the following dynamic SQL is called by SQL Agent:

exec sp_executesql N'DECLARE @nextScheduledRunDate DATETIME 
  SET @nextScheduledRunDate = msdb.dbo.agent_datetime(@P1, @P2) 
  UPDATE msdb.dbo.sysjobactivity 
    SET next_scheduled_run_date = @nextScheduledRunDate 
    WHERE session_id = @P3 AND job_id = @P4',
N'@P1 int,@P2 int,@P3 int,@P4 uniqueidentifier',
20120819,181600,5,'36924B24-9706-4FD7-8B3A-1F9F0BECB52C'


It seems that sysjobactivity is updated immediately, and sysjobschedules is only updated on a schedule. If we change the new schedule to be once a day, e.g.

@freq_type=4, 
@freq_interval=1, 
@freq_subday_type=1, 
@freq_subday_interval=0, 
@freq_relative_interval=0, 
@freq_recurrence_factor=1, 


We still see the immediate update to sysjobactivity as above, and then another update after the job is finished. Various updates come from background and other threads within SQL Agent, e.g.:

SQLAgent - Job Manager
SQLAgent - Update job activity
SQLAgent - Job invocation engine
SQLAgent - Schedule Saver


A background thread (the ""Schedule Saver"" thread) eventually comes around and updates sysjobschedules; from my initial investigation it appears this is every 20 minutes, and only happens if xp_sqlagent_notify has been called due to a change made to a job since the last time it ran (I did not perform any further testing to see what happens if one job has been changed and another has been run, if the ""Schedule Saver"" thread updates both - I suspect it must, but will leave that as an exercise to the reader).

I am not sure if the 20-minute cycle is offset from when SQL Agent starts, or from midnight, or from something machine-specific. On two different instances on the same physical server, the ""Schedule Saver"" thread updated sysjobschedules, on both instances, at almost the exact same time - 18:31:37 &amp; 18:51:37 on one, and 18:31:39 &amp; 18:51:39 on the other. I did not start SQL Server Agent at the same time on these servers, but there is a remote possibility that the start times happened to be 20 minutes offset. I doubt it, but I don't have time right now to confirm by restarting Agent on one of them and waiting for more updates to happen.

I know who did it, and when it happened, because I placed a trigger there and captured it, in case I couldn't find it in the trace, or I inadvertently filtered it out.

CREATE TABLE dbo.JobAudit
(
  [action] CHAR(1),
  [table] CHAR(1), 
  hostname SYSNAME NOT NULL DEFAULT HOST_NAME(), 
  appname SYSNAME  NOT NULL DEFAULT PROGRAM_NAME(),
  dt DATETIME2     NOT NULL DEFAULT SYSDATETIME()
);

CREATE TRIGGER dbo.schedule1 ON dbo.sysjobactivity FOR INSERT
AS
  INSERT dbo.JobAudit([action], [table] SELECT 'I', 'A';
GO
CREATE TRIGGER dbo.schedule2 ON dbo.sysjobactivity FOR UPDATE
AS
  INSERT dbo.JobAudit([action], [table] SELECT 'U', 'A';
GO
CREATE TRIGGER dbo.schedule3 ON dbo.sysjobschedules FOR INSERT
AS
  INSERT dbo.JobAudit([action], [table] SELECT 'I', 'S';
GO
CREATE TRIGGER dbo.schedule4 ON dbo.sysjobschedules FOR UPDATE
AS
  INSERT dbo.JobAudit([action], [table] SELECT 'U', 'S';
GO


That said, it is not hard to catch with a standard trace, this one even comes through as non-dynamic DML:

UPDATE msdb.dbo.sysjobschedules 
  SET next_run_date = 20120817, 
      next_run_time = 20000 
 WHERE (job_id = 0xB87B329BFBF7BA40B30D9B27E0B120DE 
 and schedule_id = 8)


If you want to run a more filtered trace to track this behavior over time (e.g. persisting through SQL Agent restarts instead of on-demand), you can run one that has appname = 'SQLAgent - Schedule Saver'...

So I think that if you want to know the next run time immediately, look at sysjobactivity, not sysjobschedules. This table is directly updated by Agent or its background threads (""Update job activity"", ""Job Manager"" and ""Job invocation engine"") as activity happens or as it is notified by xp_sqlagent_notify.

Be aware, though, that it is very easy to muck up either table - since there are no protections against deleting data from these tables. (So if you decided to clean up, for example, you can easily remove all the rows for that job from the activity table.) In this case I'm not exactly sure how SQL Server Agent gets or saves the next run date. Perhaps worthy of more investigation at a later date when I have some free time...
",Aaron Bertrand,https://dba.stackexchange.com/users/1186,http://dba.stackexchange.com/questions/22644/how-and-when-does-sql-agent-update-next-run-date-next-run-time-values,TECHNOLOGY,dba.stackexchange.com,0.7777777777777778,0.5555555555555556,0.0,0.3333333333333333,1.0,0.6666666666666666,0.6666666666666666,0.4444444444444444,0.6666666666666666,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.0,0.8888888888888888,0.8888888888888888,0.7777777777777778,0.8888888888888888,0.8888888888888888,0.8,1.0,0.3333333333333333,1.0,0.7777777777777778,How and when does SQL agent update the next run date / next run time value?,"I've been working on code in T-SQL to add new schedules to a SQL Agent job  using the sp_add_jobschedule proc in the msdb database.  When I add a new schedule (typically a run-once at a specific date/time) and immediately look at the values in sysjobschedules and sysschedules, I can see that the new schedule has been added and is tied to the job_id for my SQL Agent job. However, the values for next_run_date and next_run_time have 0 in them.  When I come back and look at them again in 2 or 3 minutes, they still show 0's in them.  However when I come back another 5 or 10 minutes later, it now correctly shows the date and time values corresponding to the next scheduled run.

So my questions are:


How often do these values get updated?
What process is it that updates these values?
If I were to add a schedule that was, say, 1 minute in the future, does that mean that the job will not run since the next_run_date/time haven't been updated yet?


Example of the code I use to add a new schedule:

exec msdb.dbo.sp_add_jobschedule @job_id = @jobID
                    , @name = @JobName
                    , @enabled = 1
                    , @freq_type = 1
                    , @freq_interval = 0
                    , @freq_subday_type = 0
                    , @freq_subday_interval = 0
                    , @freq_relative_interval = 0
                    , @freq_recurrence_factor = 0
                    , @active_start_date = @ScheduleRunDate
                    , @active_end_date = 99991231
                    , @active_start_time = @ScheduleRunTime
                    , @active_end_time = 235959


where @jobID is binary(16) that holds the job_id of the job in question, @ScheduleRunDate and @ScheduleRunTime are INTs with the date and time respectively.
","Short Answer

It looks like the data in msdb.dbo.sysjobschedules is updated by a background thread in SQL Agent, identified as SQLAgent - Schedule Saver, every 20 minutes (or less frequently, if xp_sqlagent_notify has not been called and no jobs have run in the meantime).

For more accurate information, look at next_scheduled_run_date in msdb.dbo.sysjobactivity. This is updated in real-time any time a job is changed or a job has run. As an added bonus, the sysjobactivity stores the data the right way (as a datetime column), making it a lot easier to work with than those stupid INTs.

That's the short answer: 


  It could be up to 20 minutes before sysjobschedules reflects the truth; however, sysjobactivity will always be up to date. If you want a lot more details about this, or how I figured it out...




Long Answer

If you care to follow the rabbit for a moment, when you call sp_add_jobschedule, this chain of events is set into motion:

msdb.dbo.sp_add_jobschedule == calls ==&gt; msdb.dbo.sp_add_schedule
                                         msdb.dbo.sp_attach_schedule

msdb.dbo.sp_attach_schedule == calls ==&gt; msdb.dbo.sp_sqlagent_notify

msdb.dbo.sp_sqlagent_notify == calls ==&gt; msdb.dbo.xp_sqlagent_notify


Now, we can't chase the rabbit any further, because we can't really peek into what xp_sqlagent_notify does. But I think we can presume that this extended procedure interacts with the Agent service and tells it that there has been a change to this specific job and schedule. By running a server-side trace we can see that, immediately, the following dynamic SQL is called by SQL Agent:

exec sp_executesql N'DECLARE @nextScheduledRunDate DATETIME 
  SET @nextScheduledRunDate = msdb.dbo.agent_datetime(@P1, @P2) 
  UPDATE msdb.dbo.sysjobactivity 
    SET next_scheduled_run_date = @nextScheduledRunDate 
    WHERE session_id = @P3 AND job_id = @P4',
N'@P1 int,@P2 int,@P3 int,@P4 uniqueidentifier',
20120819,181600,5,'36924B24-9706-4FD7-8B3A-1F9F0BECB52C'


It seems that sysjobactivity is updated immediately, and sysjobschedules is only updated on a schedule. If we change the new schedule to be once a day, e.g.

@freq_type=4, 
@freq_interval=1, 
@freq_subday_type=1, 
@freq_subday_interval=0, 
@freq_relative_interval=0, 
@freq_recurrence_factor=1, 


We still see the immediate update to sysjobactivity as above, and then another update after the job is finished. Various updates come from background and other threads within SQL Agent, e.g.:

SQLAgent - Job Manager
SQLAgent - Update job activity
SQLAgent - Job invocation engine
SQLAgent - Schedule Saver


A background thread (the ""Schedule Saver"" thread) eventually comes around and updates sysjobschedules; from my initial investigation it appears this is every 20 minutes, and only happens if xp_sqlagent_notify has been called due to a change made to a job since the last time it ran (I did not perform any further testing to see what happens if one job has been changed and another has been run, if the ""Schedule Saver"" thread updates both - I suspect it must, but will leave that as an exercise to the reader).

I am not sure if the 20-minute cycle is offset from when SQL Agent starts, or from midnight, or from something machine-specific. On two different instances on the same physical server, the ""Schedule Saver"" thread updated sysjobschedules, on both instances, at almost the exact same time - 18:31:37 &amp; 18:51:37 on one, and 18:31:39 &amp; 18:51:39 on the other. I did not start SQL Server Agent at the same time on these servers, but there is a remote possibility that the start times happened to be 20 minutes offset. I doubt it, but I don't have time right now to confirm by restarting Agent on one of them and waiting for more updates to happen.

I know who did it, and when it happened, because I placed a trigger there and captured it, in case I couldn't find it in the trace, or I inadvertently filtered it out.

CREATE TABLE dbo.JobAudit
(
  [action] CHAR(1),
  [table] CHAR(1), 
  hostname SYSNAME NOT NULL DEFAULT HOST_NAME(), 
  appname SYSNAME  NOT NULL DEFAULT PROGRAM_NAME(),
  dt DATETIME2     NOT NULL DEFAULT SYSDATETIME()
);

CREATE TRIGGER dbo.schedule1 ON dbo.sysjobactivity FOR INSERT
AS
  INSERT dbo.JobAudit([action], [table] SELECT 'I', 'A';
GO
CREATE TRIGGER dbo.schedule2 ON dbo.sysjobactivity FOR UPDATE
AS
  INSERT dbo.JobAudit([action], [table] SELECT 'U', 'A';
GO
CREATE TRIGGER dbo.schedule3 ON dbo.sysjobschedules FOR INSERT
AS
  INSERT dbo.JobAudit([action], [table] SELECT 'I', 'S';
GO
CREATE TRIGGER dbo.schedule4 ON dbo.sysjobschedules FOR UPDATE
AS
  INSERT dbo.JobAudit([action], [table] SELECT 'U', 'S';
GO


That said, it is not hard to catch with a standard trace, this one even comes through as non-dynamic DML:

UPDATE msdb.dbo.sysjobschedules 
  SET next_run_date = 20120817, 
      next_run_time = 20000 
 WHERE (job_id = 0xB87B329BFBF7BA40B30D9B27E0B120DE 
 and schedule_id = 8)


If you want to run a more filtered trace to track this behavior over time (e.g. persisting through SQL Agent restarts instead of on-demand), you can run one that has appname = 'SQLAgent - Schedule Saver'...

So I think that if you want to know the next run time immediately, look at sysjobactivity, not sysjobschedules. This table is directly updated by Agent or its background threads (""Update job activity"", ""Job Manager"" and ""Job invocation engine"") as activity happens or as it is notified by xp_sqlagent_notify.

Be aware, though, that it is very easy to muck up either table - since there are no protections against deleting data from these tables. (So if you decided to clean up, for example, you can easily remove all the rows for that job from the activity table.) In this case I'm not exactly sure how SQL Server Agent gets or saves the next run date. Perhaps worthy of more investigation at a later date when I have some free time...
"
5447,5447,8646,Integrate a division of polynomials,"Hi I have the following integral:
$$\int \frac{2x}{x^2+6x+3}\, dx$$

I made some changes like:
$$\int \dfrac{2x+6-6}{x^2+6x+3}\, dx$$

then I have: 
$$\int \dfrac{2x+6}{x^2+6x+3}\, dx -\int\dfrac{6}{x^2+6x+3}\, dx$$

and thus: $$\ln(x^2+6x+3)-\int\dfrac{6}{x^2+6x+3}\, dx$$

Ok, I have decomposed $$\frac{2x}{x^2+6x+3} $$  in: $$ \frac{3+\sqrt6}{\sqrt6(x+\sqrt 6+3)} + \frac{3-\sqrt6}{\sqrt6 (-x+\sqrt6-3)}$$

How can I integrate this expressions?
",Luis Armando,https://math.stackexchange.com/users/162185,"A start: Note that $x^2+6x+3=0$ has the roots $\alpha=-3+\sqrt{6}$ and $\beta=-3-\sqrt{6}$. Thus $x^2+6x+3=(x-\alpha)(x-\beta)$.

Express $\frac{6}{(x-\alpha)(x-\beta)}$ as $\frac{A}{x-\alpha}+\frac{B}{(x-\beta)}$ (partial fractions).
",André Nicolas,https://math.stackexchange.com/users/6312,http://math.stackexchange.com/questions/882692/integrate-a-division-of-polynomials,SCIENCE,math.stackexchange.com,0.8888888888888888,0.4444444444444444,0.0,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,0.9,1.0,0.0,0.0,0.8888888888888888,Division of integral polynomials,"Hi I have the following integral:
$$\int \frac{2x}{x^2+6x+3}\, dx$$

I made some changes like:
$$\int \dfrac{2x+6-6}{x^2+6x+3}\, dx$$

then I have: 
$$\int \dfrac{2x+6}{x^2+6x+3}\, dx -\int\dfrac{6}{x^2+6x+3}\, dx$$

and thus: $$\ln(x^2+6x+3)-\int\dfrac{6}{x^2+6x+3}\, dx$$

Ok, I have decomposed $$\frac{2x}{x^2+6x+3} $$  in: $$ \frac{3+\sqrt6}{\sqrt6(x+\sqrt 6+3)} + \frac{3-\sqrt6}{\sqrt6 (-x+\sqrt6-3)}$$

How can I integrate this expressions?
",Start: note that $x ^ 2 + 6x + 3 = 0 $has roots $\ alpha = - 3 + \ sqrt {6} $and $\ beta = - 3 - \ sqrt {6} $. So $x ^ 2 + 6x + 3 = (x - \ alpha) (x - \ beta) $.
4486,4486,7112,Word for a result/achievement so exceptional that it is impossible?,"I am looking for a word or phrase regarding something that is ""impossible"". I can't seem to put my finger on it, but I am trying to think of the word to describe something that is the top of the top, and thus impossible to achieve? 

The only two words I have come up with are elusive and formidable, neither of which really mean what I want them to mean. I want something more clever to put it plainly.
",user128274,https://english.stackexchange.com/users/128274,"Unattainable


  Not able to be reached or achieved:
  
  an unattainable goal

",Tushar Raj,https://english.stackexchange.com/users/77339,http://english.stackexchange.com/questions/257713/word-for-a-result-achievement-so-exceptional-that-it-is-impossible,CULTURE,english.stackexchange.com,0.8888888888888888,0.7777777777777778,0.0,1.0,1.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,0.8888888888888888,0.7333333333333333,0.0,0.0,0.0,0.5555555555555556,A word whose result / achievement is so special that it is impossible?,"I'm looking for a word or phrase about ""impossible"". I don't seem to be able to point to it with my fingers, but I want to use this word to describe one thing, that is, what is on the top and thus impossible to achieve?","Unattainable


  Not able to be reached or achieved:
  
  an unattainable goal

"
5674,5674,8996,"Is ""Pick up those blocks"" grammatically incorrect?","I had someone correct me today as I instructed my child to ""pick up those blocks."" This person insisted that it should just be:


  Pick up those.


since ""those"" is already plural.

Is this person correct?
",Chris Dwyer,https://english.stackexchange.com/users/61,"""Pick up those blocks"" is perfectly correct. The fact that ""those"" is plural doesn't mean that you can leave out the object, ""blocks."" How would the child know what to pick up?

There's something off about the sentence ""Pick up those,"" because the antecedent of ""those"" is missing.


  ""Should I pick up these or those?""
  ""Pick up those.""


is OK. But by itself, it sounds wrong.
",Joel Spolsky,https://english.stackexchange.com/users/133,http://english.stackexchange.com/questions/11603/is-pick-up-those-blocks-grammatically-incorrect,CULTURE,english.stackexchange.com,1.0,0.8888888888888888,0.3333333333333333,1.0,1.0,1.0,0.5555555555555556,0.8888888888888888,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.6666666666666666,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,1.0,"Is the syntax ""pick up those blocks"" incorrect?","Today, I asked someone to correct me and let my child ""pick up those blocks."" The man insisted that it should be:","""Pick up those blocks"" is perfectly correct. The fact that ""those"" is plural doesn't mean that you can leave out the object, ""blocks."" How would the child know what to pick up?

There's something off about the sentence ""Pick up those,"" because the antecedent of ""those"" is missing.


  ""Should I pick up these or those?""
  ""Pick up those.""


is OK. But by itself, it sounds wrong.
"
1061,1061,1670,"Is the following usage of ""matter-of-factly"" correct?","Most of the usage of ""matter-of-factly"" that I've seen is to describe a manner of speaking - ""He said, matter of factly,..."", etc.

A friend brought up the following usage, which seems wrong, but I can't pinpoint exactly what is wrong. ""Matter of factly, I don't know. I know from my dad's experience.""

What's the view on this?

Couple of points:


The adjective form ""As a matter of fact, I don't know. ..."" seems correct.
Similar usage of literally works: ""I literally don't know."" or ""Literally, I don't know""

",ak86,https://english.stackexchange.com/users/3850,"The issue with the second usage is that ""matter-of-factly"" means ""in a matter-of-fact style""; it is not synonymous with ""as a matter of fact"".  ""As a matter of fact"" is by itself already an adverbial phrase (meaning ""actually""); tacking an additional -ly on the end to re-adverbialize it can't be right.

I'd be more inclined to express your friends' apparent intended meaning as ""I don't know personally"" or ""I don't know directly"".
",Hellion,https://english.stackexchange.com/users/2490,http://english.stackexchange.com/questions/9361/is-the-following-usage-of-matter-of-factly-correct,CULTURE,english.stackexchange.com,1.0,0.3333333333333333,0.0,0.6666666666666666,1.0,0.6666666666666666,0.6666666666666666,0.8888888888888888,0.0,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,0.8888888888888888,"Is the following ""be realistic"" correct?","Most of the usage of ""matter-of-factly"" that I've seen is to describe a manner of speaking - ""He said, matter of factly,..."", etc.

A friend brought up the following usage, which seems wrong, but I can't pinpoint exactly what is wrong. ""Matter of factly, I don't know. I know from my dad's experience.""

What's the view on this?

Couple of points:


The adjective form ""As a matter of fact, I don't know. ..."" seems correct.
Similar usage of literally works: ""I literally don't know."" or ""Literally, I don't know""

","The issue with the second usage is that ""matter-of-factly"" means ""in a matter-of-fact style""; it is not synonymous with ""as a matter of fact"".  ""As a matter of fact"" is by itself already an adverbial phrase (meaning ""actually""); tacking an additional -ly on the end to re-adverbialize it can't be right.

I'd be more inclined to express your friends' apparent intended meaning as ""I don't know personally"" or ""I don't know directly"".
"
1844,1844,2926,Sending Via PIC18F97J60 EUSART,"When trying to send and receive using a PIC18F97J60 and MAX232 using a program written with the C18 compiler, I am only able to transmit data.  For receiving, I have tried at least 50 methods but none are working. I even tried the software on multiple micro-controller boards to check for a hardware problem but none of the boards ever receive anything. I believe that the following items are correct:


My clock is perfect at 41.6667MHz
My baud generation is perfect
My hardware is OK (some other IIIrd party hex code able to receive also)
My host PC, its COM port, and the serial cable are OK


Can anyone guide with probable areas I may be missing?

------------------ FURTHER CLARIFICATIONS -------------------------------------------

Thanks Olin for helping, you are great man. Sorry for not putting my question correctly. Please note:

I was trying to do serial I/O to write a boot loader for the PIC18F97J60 myself as my vendor's supplied boot loader stops sending/receiving with PCloader software after a partial user application hex download.  It also ensures that RS232 port is able to both send and receive.  Moreover, Microchip's boot loader described in AN1310 also stucks on receiving data. 

My sample application (a bootloader) is able to transmit but never receives anything.  I'm in soup: either I need a new boot loader or my application must work. I have never faced such a problem in my 12 years of development and I am feeling like a fool.

Other details as you requested are as follows:


I had 10-12 PIC18F97J60 cards with MAX232 on C6/C7 for Serial I/O. The problem is the same for all boards (of different batches).
I wish to do 9600 baud, 8 bit, no parity, 1 stop, no handshake, no interrupt data exchange with RealTerm (Better Than Hyperterminal - Displays HEX Code). 
My clock and baud rate calculations are perfect for 41.6667MHz. I have set OSCTUNE = 0x40 and BAUDCON = 1084. I am able to receive perfectly on the PC with RealTerm.
My program not able to receive anything on the PIC but able to transmit.
I tried polling as well as interrupt but nothing works.


Snippet of code is as follows:

void putchar(unsigned char Char)
{
    //Wait for (TSR==1)
    while(TXSTA1bits.TRMT!=1);
    //Trasmit Current Data
    TXREG1= Char;
    //Wait for (TSR==1)
    while(TXSTA1bits.TRMT!=1);
}

void putstr(unsigned char *String)
{
     do
     {
         putchar((*String));
     }while(*String++);
    //CR
     putchar(CR);
    //LF
    putchar(LF);
}

void main(void)
{
    unsigned char RS232[] = ""RS-232"";
    OSCTUNE = 0x40;
    TXSTA1 = 0x24;
    RCSTA1 = 0x90;
    BAUDCON1=0x08;
    SPBRGH1=0x04;
    SPBRG1=0x3C;

while(1)
{
    putstr(RS232);
    Delay10KTCYx(200);
    if(PIR1bits.RC1IF == 1)
    {
            MYChar = RCREG1; //*** No OERR &amp; FERR present, RC1IF never gets set ***
    }
}


}
",Sachin Gupta,https://electronics.stackexchange.com/users/5648,"One annoying misfeature of the UART on every PIC I've worked with is that a data overrun error will shut down the receiver until code disables and re-enables it.  It is thus imperative to have code that will periodically check the overrun-error flag and, if it is set, disable and re-enable the UART receive function.  Otherwise if the receive buffer overruns, you won't just lose a received byte--you'll lose all data forevermore.

I'm not really sure why Microchip designed their UARTs this way.  My guess would be that in early PICs a receive overrun would cause the receive state machine to lose frame sync, and that disabling the receiver was considered preferable to receiving randomly-framed data (I might agree with them on that point, though I would consider dropping whole bytes while maintaining sync to be better still); later PICs maintained the behavior for compatibility, despite substantial redesigns of the UART subsystem.

In any case, the PIC's UART implementation is what it is.  Check to ensure that the UART receiver is enabled and the receive-overflow isn't tripped.  If not, disable the UART receive function and re-enable it.  Note, btw, that on some PICs the master disable for the UART function will not disable the receiver; you need to clear and re-set the receiver enable.
",supercat,https://electronics.stackexchange.com/users/3123,http://electronics.stackexchange.com/questions/19142/sending-via-pic18f97j60-eusart,SCIENCE,electronics.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,0.0,1.0,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.0,0.6666666666666666,0.8888888888888888,0.6666666666666666,0.8888888888888888,0.8888888888888888,0.8,0.3333333333333333,0.0,1.0,1.0,Sent via pic18f97j60 eusart,"When trying to send and receive using a PIC18F97J60 and MAX232 using a program written with the C18 compiler, I am only able to transmit data.  For receiving, I have tried at least 50 methods but none are working. I even tried the software on multiple micro-controller boards to check for a hardware problem but none of the boards ever receive anything. I believe that the following items are correct:


My clock is perfect at 41.6667MHz
My baud generation is perfect
My hardware is OK (some other IIIrd party hex code able to receive also)
My host PC, its COM port, and the serial cable are OK


Can anyone guide with probable areas I may be missing?

------------------ FURTHER CLARIFICATIONS -------------------------------------------

Thanks Olin for helping, you are great man. Sorry for not putting my question correctly. Please note:

I was trying to do serial I/O to write a boot loader for the PIC18F97J60 myself as my vendor's supplied boot loader stops sending/receiving with PCloader software after a partial user application hex download.  It also ensures that RS232 port is able to both send and receive.  Moreover, Microchip's boot loader described in AN1310 also stucks on receiving data. 

My sample application (a bootloader) is able to transmit but never receives anything.  I'm in soup: either I need a new boot loader or my application must work. I have never faced such a problem in my 12 years of development and I am feeling like a fool.

Other details as you requested are as follows:


I had 10-12 PIC18F97J60 cards with MAX232 on C6/C7 for Serial I/O. The problem is the same for all boards (of different batches).
I wish to do 9600 baud, 8 bit, no parity, 1 stop, no handshake, no interrupt data exchange with RealTerm (Better Than Hyperterminal - Displays HEX Code). 
My clock and baud rate calculations are perfect for 41.6667MHz. I have set OSCTUNE = 0x40 and BAUDCON = 1084. I am able to receive perfectly on the PC with RealTerm.
My program not able to receive anything on the PIC but able to transmit.
I tried polling as well as interrupt but nothing works.


Snippet of code is as follows:

void putchar(unsigned char Char)
{
    //Wait for (TSR==1)
    while(TXSTA1bits.TRMT!=1);
    //Trasmit Current Data
    TXREG1= Char;
    //Wait for (TSR==1)
    while(TXSTA1bits.TRMT!=1);
}

void putstr(unsigned char *String)
{
     do
     {
         putchar((*String));
     }while(*String++);
    //CR
     putchar(CR);
    //LF
    putchar(LF);
}

void main(void)
{
    unsigned char RS232[] = ""RS-232"";
    OSCTUNE = 0x40;
    TXSTA1 = 0x24;
    RCSTA1 = 0x90;
    BAUDCON1=0x08;
    SPBRGH1=0x04;
    SPBRG1=0x3C;

while(1)
{
    putstr(RS232);
    Delay10KTCYx(200);
    if(PIR1bits.RC1IF == 1)
    {
            MYChar = RCREG1; //*** No OERR &amp; FERR present, RC1IF never gets set ***
    }
}


}
","One annoying misfeature of the UART on every PIC I've worked with is that a data overrun error will shut down the receiver until code disables and re-enables it.  It is thus imperative to have code that will periodically check the overrun-error flag and, if it is set, disable and re-enable the UART receive function.  Otherwise if the receive buffer overruns, you won't just lose a received byte--you'll lose all data forevermore.

I'm not really sure why Microchip designed their UARTs this way.  My guess would be that in early PICs a receive overrun would cause the receive state machine to lose frame sync, and that disabling the receiver was considered preferable to receiving randomly-framed data (I might agree with them on that point, though I would consider dropping whole bytes while maintaining sync to be better still); later PICs maintained the behavior for compatibility, despite substantial redesigns of the UART subsystem.

In any case, the PIC's UART implementation is what it is.  Check to ensure that the UART receiver is enabled and the receive-overflow isn't tripped.  If not, disable the UART receive function and re-enable it.  Note, btw, that on some PICs the master disable for the UART function will not disable the receiver; you need to clear and re-set the receiver enable.
"
2078,2078,3309,Low pass filter to maintain edge information,"I am looking for a kernel acting as a low pass filter that satisfies these conditions:

$$K(-\mathbf{u})=K(\mathbf{u}) \tag{1}$$
$$K(\mathbf{u}) \ge K(\mathbf{v}), \;\; \text{if} \;\; |\mathbf{u}|&lt;|\mathbf{v}|, \;\; \text{and} \;\; \lim_{|\mathbf{u}|\rightarrow\infty} K(\mathbf{u})=0  \tag{2}$$
$$\int K(\mathbf{x})d\mathbf{x} = 1 \tag{3}$$

In the reference paper, the author suggested a Gaussian kernel that is:

$$K_\sigma(\mathbf{u})=\frac{1}{\left(\sqrt{2\pi}\sigma\right)^n}e^{-|\mathbf{u}|^2/2\sigma^2} $$

with a scale parameter $\sigma &gt; 0$.

The Gaussian kernel is very good at approximating the required properties. But the kernel reduces edge information when the kernel size is large. 

Could you suggest to me any kernel that can satisfy the three conditions above, and is more robust than Gaussian in noise reduction, while maintaining edge information? I found a modified kernel, but it was very difficult to implement. Thank you so much. 
",user8264,https://dsp.stackexchange.com/users/8264,"There are many ""Edge Preserving"" filters in the image processing world.
2 very popular would be:


The Bilateral Filter.
Anisotropic Diffusion Filter.


Google search on each of the terms will give you plenty of data and code samples of each.

For any specific question about them, let me know, I'd be happy to assist.
",Royi,https://dsp.stackexchange.com/users/128,http://dsp.stackexchange.com/questions/17591/low-pass-filter-to-maintain-edge-information,TECHNOLOGY,dsp.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,1.0,0.6666666666666666,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,1.0,0.0,0.0,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,0.9,0.6666666666666666,0.0,0.0,0.7777777777777778,Low pass filter keeping edge information,"I am looking for a kernel acting as a low pass filter that satisfies these conditions:

$$K(-\mathbf{u})=K(\mathbf{u}) \tag{1}$$
$$K(\mathbf{u}) \ge K(\mathbf{v}), \;\; \text{if} \;\; |\mathbf{u}|&lt;|\mathbf{v}|, \;\; \text{and} \;\; \lim_{|\mathbf{u}|\rightarrow\infty} K(\mathbf{u})=0  \tag{2}$$
$$\int K(\mathbf{x})d\mathbf{x} = 1 \tag{3}$$

In the reference paper, the author suggested a Gaussian kernel that is:

$$K_\sigma(\mathbf{u})=\frac{1}{\left(\sqrt{2\pi}\sigma\right)^n}e^{-|\mathbf{u}|^2/2\sigma^2} $$

with a scale parameter $\sigma &gt; 0$.

The Gaussian kernel is very good at approximating the required properties. But the kernel reduces edge information when the kernel size is large. 

Could you suggest to me any kernel that can satisfy the three conditions above, and is more robust than Gaussian in noise reduction, while maintaining edge information? I found a modified kernel, but it was very difficult to implement. Thank you so much. 
","There are many ""Edge Preserving"" filters in the image processing world.
2 very popular would be:


The Bilateral Filter.
Anisotropic Diffusion Filter.


Google search on each of the terms will give you plenty of data and code samples of each.

For any specific question about them, let me know, I'd be happy to assist.
"
2722,2722,4337,Is it an absolute must that we ignore/delete all compiled files before committing?,"I am working on a Drupal theme. I am going to be using ""intermediary"" languages to develop it, ie Stylus for styles, and CoffeeScript for some of the front-end scripts.

I am going to be using a git hosting service to be able to share the code among colleges. I am also going to be using it to update the code locally and then push onto hosting service, to be later pulled by the live drupal site.

This makes things really elegant.

However, I have noticed that a lot of developers tend to .gitignore all compiled code.

If it were a good practice, I would've loved to follow it, if and only if there wasn't this one issue: recompiling all the code that is needed in order for the theme to work out correctly.

This means that when I do a pull, I will have to recompile all the CSS and JavaScript code. Now, if I were to do a pull on the live site, there's a risk that a user goes to the site right at the moment I do the pull. No styles and scripts will be loaded on the user's end, so long as the code hasn't compiled.

Of course, compiling takes about a second, and the user might probably think to him/herself ""meh, it was just my internet connection.""

But there is also the issue that the server doesn't have the compilers installed to begin with. So now, I would do a pull, but there will be no styles, and no scripts.

Is it an absolute must that I delete all compiled code, or can I go ahead and include them in the commit?
",skizeey,https://programmers.stackexchange.com/users/17183,"MainMa's answer is great but it should be noted that this is a prime case for continuous integration. Setting up a machine (either a hosted solution or one of your own) that will identify when a commit has come in, compile the code, run appropriate tests, and build the deployment package if the tests succeed. This approach could be taken a step further and automate a scheduled deployment when your criteria for a deployment has been met.
",Skyler,https://programmers.stackexchange.com/users/53137,http://programmers.stackexchange.com/questions/146820/is-it-an-absolute-must-that-we-ignore-delete-all-compiled-files-before-committin,TECHNOLOGY,programmers.stackexchange.com,0.6666666666666666,0.4444444444444444,0.0,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.4444444444444444,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,1.0,0.0,0.8888888888888888,0.7777777777777778,0.5555555555555556,0.8888888888888888,1.0,0.7333333333333333,0.3333333333333333,0.3333333333333333,1.0,0.8888888888888888,Must all compiled files be ignored / deleted before submission?,"I am working on a Drupal theme. I am going to be using ""intermediary"" languages to develop it, ie Stylus for styles, and CoffeeScript for some of the front-end scripts.

I am going to be using a git hosting service to be able to share the code among colleges. I am also going to be using it to update the code locally and then push onto hosting service, to be later pulled by the live drupal site.

This makes things really elegant.

However, I have noticed that a lot of developers tend to .gitignore all compiled code.

If it were a good practice, I would've loved to follow it, if and only if there wasn't this one issue: recompiling all the code that is needed in order for the theme to work out correctly.

This means that when I do a pull, I will have to recompile all the CSS and JavaScript code. Now, if I were to do a pull on the live site, there's a risk that a user goes to the site right at the moment I do the pull. No styles and scripts will be loaded on the user's end, so long as the code hasn't compiled.

Of course, compiling takes about a second, and the user might probably think to him/herself ""meh, it was just my internet connection.""

But there is also the issue that the server doesn't have the compilers installed to begin with. So now, I would do a pull, but there will be no styles, and no scripts.

Is it an absolute must that I delete all compiled code, or can I go ahead and include them in the commit?
","MainMa's answer is great but it should be noted that this is a prime case for continuous integration. Setting up a machine (either a hosted solution or one of your own) that will identify when a commit has come in, compile the code, run appropriate tests, and build the deployment package if the tests succeed. This approach could be taken a step further and automate a scheduled deployment when your criteria for a deployment has been met.
"
2691,2691,4293,Configuring a biblatex bibliography style,"I just switched from natbib to biber + biblatex, and the closest bibliography style to my preferred style is ""ieee"" (by Joseph Wright).  I am using it with the citation style ""authoryear"".  This makes the numbers in the bibliography useless; how do I remove them?
",Neil G,https://tex.stackexchange.com/users/512,"I can't test it right now, but it should be possible to load biblatex with the options citestyle=authoryear,bibstyle=ieee and then to add authoryear's bibenvironment definition to the preamble:

\usepackage[citestyle=authoryear,bibstyle=ieee]{biblatex}

\defbibenvironment{bibliography}
  {\list
     {}
     {\setlength{\leftmargin}{\bibhang}%
      \setlength{\itemindent}{-\leftmargin}%
      \setlength{\itemsep}{\bibitemsep}%
      \setlength{\parsep}{\bibparsep}}}
  {\endlist}
  {\item}

",lockstep,https://tex.stackexchange.com/users/510,http://tex.stackexchange.com/questions/61370/configuring-a-biblatex-bibliography-style,TECHNOLOGY,tex.stackexchange.com,0.8888888888888888,0.4444444444444444,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,0.0,1.0,Configure biblatex bibliography style,"I just changed from natbib to Biber + biblatex, and my favorite style of bibliography is ""IEEE"" (by Joseph Wright). I use the citation style ""author ear"". This makes the numbers in the bibliography useless; how can I delete them?","I can't test it right now, but it should be possible to load biblatex with the options citestyle=authoryear,bibstyle=ieee and then to add authoryear's bibenvironment definition to the preamble:

\usepackage[citestyle=authoryear,bibstyle=ieee]{biblatex}

\defbibenvironment{bibliography}
  {\list
     {}
     {\setlength{\leftmargin}{\bibhang}%
      \setlength{\itemindent}{-\leftmargin}%
      \setlength{\itemsep}{\bibitemsep}%
      \setlength{\parsep}{\bibparsep}}}
  {\endlist}
  {\item}

"
1594,1594,2510,Displaying articles created by user in profile page using views,"I want to display the articles created by user in user profile page. It should also display to anonymous user also.

For example : twitter.com/google displays all tweets by google.

Like that I want to display xyz.com/john. I want to display all articles created by john in user profile page.

I also want to know how to add that view to profile page.
",Monish,https://drupal.stackexchange.com/users/35836,"
Create a view for content of type all 
Inside the view display node title and all other fields as per your requirement. 
Add a contextual filter content : author uid 
While adding that you will have a option for provide a default value 
select that option and inside that use filter by 'currently logged in user'.
Save it by this you will be able to see all the nodes of current logged in user. 
Inside the path you can enter just any path like '/my-nodes'. and you are done.
If you want you can avoid providing default value and switch to manual input
by placing the path as '/my-nodes/%' and then just add contextual filter as 'content : author:uid' without default value(depends as per the requirement).

For user name you can add a relationship content author:uid then
 in the contextual filter use User name with relationship author:uid 

",Pravin Ajaaz,https://drupal.stackexchange.com/users/34698,http://drupal.stackexchange.com/questions/141014/displaying-articles-created-by-user-in-profile-page-using-views,TECHNOLOGY,drupal.stackexchange.com,0.8333333333333334,0.5,0.0,1.0,0.5,1.0,0.5,0.3333333333333333,0.5,0.0,0.5,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.5,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,0.0,1.0,Use views to display user created articles in the profile page,"I want to display the articles created by user in user profile page. It should also display to anonymous user also.

For example : twitter.com/google displays all tweets by google.

Like that I want to display xyz.com/john. I want to display all articles created by john in user profile page.

I also want to know how to add that view to profile page.
","
Create a view for content of type all 
Inside the view display node title and all other fields as per your requirement. 
Add a contextual filter content : author uid 
While adding that you will have a option for provide a default value 
select that option and inside that use filter by 'currently logged in user'.
Save it by this you will be able to see all the nodes of current logged in user. 
Inside the path you can enter just any path like '/my-nodes'. and you are done.
If you want you can avoid providing default value and switch to manual input
by placing the path as '/my-nodes/%' and then just add contextual filter as 'content : author:uid' without default value(depends as per the requirement).

For user name you can add a relationship content author:uid then
 in the contextual filter use User name with relationship author:uid 

"
3101,3101,4938,SharePoint 2010 equivalent to SQL Profiler?,"Is there a way to view the CAML that is running on a SharePoint 2010 installation?

A bit like how you can monitor SQL running on a database with MS-SQL Server - is this possible with CAML and SharePoint?
",Josh Comley,https://sharepoint.stackexchange.com/users/1977,"You can use tools like U2U CAML builder and Stramit CamlViewer to see what CAML is generated or use it to roll your own.  I don't know of anything that monitors for that type of thing though.
",Eric Alexander,https://sharepoint.stackexchange.com/users/1806,http://sharepoint.stackexchange.com/questions/16040/sharepoint-2010-equivalent-to-sql-profiler,TECHNOLOGY,sharepoint.stackexchange.com,0.6666666666666666,0.8333333333333334,0.0,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.5,0.0,0.5,0.0,0.8333333333333334,0.8333333333333334,0.5,0.8333333333333334,1.0,0.7,0.5,0.0,0.0,1.0,SharePoint 2010 equivalent to SQL profiler?,"Is there a way to view the CAML that is running on a SharePoint 2010 installation?

A bit like how you can monitor SQL running on a database with MS-SQL Server - is this possible with CAML and SharePoint?
","You can use tools like U2U CAML builder and Stramit CamlViewer to see what CAML is generated or use it to roll your own.  I don't know of anything that monitors for that type of thing though.
"
489,489,763,Why IntegerPart[x/(x/2)]=1?,"Consider this code

x = 0.109354682484;
IntegerPart[x/(x/2)]
(* 1 *)

Precision[x]
(* MachinePrecision *)


Why does it give 1 ?

Version number: 9.0 on Mac 10.9.2

screenshot



Update:

If we use an undefined variable, IntegerPart[x0/(x0/2)] gives 2. Since Mathematica never gives warnings about this x0, I'm assuming for any x0 it is true.

If we calculate the same integer part using fortran, we get 2 instead of 1.

program main
implicit none

real(8):: x=0.109354682484
real(8):: y=1.4

write(*,*) int(x/(x/2))
write(*,*) nint(x/(x/2))
write(*,*) int(y)

end program main


compiled with ifort -O0 main.f90

output of above fortran code is

       2
       2
       1


according to here, int is a fortran intrinsic function that calculate the integer part.

Is this a bug?
",xslittlegrass,https://mathematica.stackexchange.com/users/1364,"The explanation is interesting here.  I tried the same in C++, and worked a bit extra to make sure the compiler won't optimize away the divisions (looking at the assembly output, it may optimize it away if you're not careful).  Indeed, I get 2 with C++.

And here's why:

C++ does the equivalent of 

IntegerPart@Divide[x, Divide[x, 2]]

(* ==&gt; 2 *)


while in Mathematica you're computing the equivalent of

x*(1/((1/2)*x))


which gives a different result.

If I do the calculation as (x* (1/ (0.5*x))) in C++, then the result is less than 2 and the integer part is 1.

Relevant reading:


Is there a difference between Divide[a,b] and a/b?

",Szabolcs,https://mathematica.stackexchange.com/users/12,http://mathematica.stackexchange.com/questions/45178/why-integerpartx-x-2-1,TECHNOLOGY,mathematica.stackexchange.com,0.6666666666666666,0.5555555555555556,0.0,1.0,1.0,1.0,0.7777777777777778,0.4444444444444444,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,0.8888888888888888,Why is the integer part [x / (x / 2)] = 1?,"Consider this code

x = 0.109354682484;
IntegerPart[x/(x/2)]
(* 1 *)

Precision[x]
(* MachinePrecision *)


Why does it give 1 ?

Version number: 9.0 on Mac 10.9.2

screenshot



Update:

If we use an undefined variable, IntegerPart[x0/(x0/2)] gives 2. Since Mathematica never gives warnings about this x0, I'm assuming for any x0 it is true.

If we calculate the same integer part using fortran, we get 2 instead of 1.

program main
implicit none

real(8):: x=0.109354682484
real(8):: y=1.4

write(*,*) int(x/(x/2))
write(*,*) nint(x/(x/2))
write(*,*) int(y)

end program main


compiled with ifort -O0 main.f90

output of above fortran code is

       2
       2
       1


according to here, int is a fortran intrinsic function that calculate the integer part.

Is this a bug?
","The explanation is interesting here.  I tried the same in C++, and worked a bit extra to make sure the compiler won't optimize away the divisions (looking at the assembly output, it may optimize it away if you're not careful).  Indeed, I get 2 with C++.

And here's why:

C++ does the equivalent of 

IntegerPart@Divide[x, Divide[x, 2]]

(* ==&gt; 2 *)


while in Mathematica you're computing the equivalent of

x*(1/((1/2)*x))


which gives a different result.

If I do the calculation as (x* (1/ (0.5*x))) in C++, then the result is less than 2 and the integer part is 1.

Relevant reading:


Is there a difference between Divide[a,b] and a/b?

"
5141,5141,8174,How to Enable Ports 25 - 28 on a Cisco Catalyst 3750,"I am trying to enable ports 25 - 28 on my 28 port Catalyst 3750. These four ports are my fiber ports. I am using the following command to bring up that interface.

interface range Gi1/0/25 - 28

That works and it dumps me in the config-if-interface prompt. This is where I get stuck. I just want to enable these four ports and have them be in VLAN1 and On just like ports 1 - 24.

How do I do this?
",Jared Brown,https://serverfault.com/users/99915,"Do the ports require GBICs (and, if so, do you have GBICs installed)? Do you have cables attached to the ports? If you're using fibre, you MAY have to swap the connectors around (I don't think this is possible for SFP connectors, so you'd have to have a cross-over cable or a connector that allows you to connect RX on one cable to TX on the other).
",Vatine,https://serverfault.com/users/5038,http://serverfault.com/questions/130710,TECHNOLOGY,serverfault.com,1.0,0.6666666666666666,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.7777777777777778,0.8888888888888888,0.5555555555555556,1.0,1.0,0.6666666666666667,1.0,0.0,0.0,0.8888888888888888,How to enable ports 25-28 on Cisco catalyst 3750,"I am trying to enable ports 25 - 28 on my 28 port Catalyst 3750. These four ports are my fiber ports. I am using the following command to bring up that interface.

interface range Gi1/0/25 - 28

That works and it dumps me in the config-if-interface prompt. This is where I get stuck. I just want to enable these four ports and have them be in VLAN1 and On just like ports 1 - 24.

How do I do this?
","Does the port require GBIC (if so, is GBIC installed)? Is there a cable on the port? If you are using optical fiber, you may need to replace the surrounding connectors (I don't think it's possible to do this with an SF connector, so you must use a cross cable or a connector that allows you to connect RX on one cable to TX on the other)."
485,485,755,Testing multiplayer android,"In what way can an android game be tested considering the following constrains:


minimal to no budget, so I cannot hire an external company to do the testing for me
Testing should occur on multiple devices and types (phones and tablets, I have 1 available for each)
I do not have a team of testers, nor a large group of people with android devices willing to back me up.
The game is a multiplayer game (min 2, max 4 players per game) with a
backend that will be hosted on an external server (which is already
arranged), so for every testrun 2 devices are needed.
The game server is not built in java and will be unit tested, the
testing is more about doing integration testing.
Optional is stress testing the game server so we can get some sort of
baseline for this hardware.

",Thomas,https://gamedev.stackexchange.com/users/12374,"Minimal to no budget means you're doing it yourself.  As an indie developer, you shouldn't be considering to hire an external company to ""test"" for you-- this is a game, not a NASA rocket.

If you have the hardware, then you're already halfway there.  A couple of ways to gather people to test your game:


If you live near a university or college, you might have success postering with things like ""Game test volunteers needed!  Android developer needs 2-4 students who are very interested in gaming to test new multiplayer game SPROCKETS.  Game genre is RTS strategy.  PIZZA will be provided."" and attach your number
Meetup.com might put you into contact with like-minded individuals in your area
You might also try Craigslist (volunteer jobs) and kijiji (also asking for volunteers)

",bobobobo,https://gamedev.stackexchange.com/users/998,http://gamedev.stackexchange.com/questions/46830/testing-multiplayer-android,TECHNOLOGY,gamedev.stackexchange.com,0.8888888888888888,0.4444444444444444,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.4444444444444444,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.3333333333333333,0.0,1.0,Test multiple Android,"In what way can an android game be tested considering the following constrains:


minimal to no budget, so I cannot hire an external company to do the testing for me
Testing should occur on multiple devices and types (phones and tablets, I have 1 available for each)
I do not have a team of testers, nor a large group of people with android devices willing to back me up.
The game is a multiplayer game (min 2, max 4 players per game) with a
backend that will be hosted on an external server (which is already
arranged), so for every testrun 2 devices are needed.
The game server is not built in java and will be unit tested, the
testing is more about doing integration testing.
Optional is stress testing the game server so we can get some sort of
baseline for this hardware.

","Minimal to no budget means you're doing it yourself.  As an indie developer, you shouldn't be considering to hire an external company to ""test"" for you-- this is a game, not a NASA rocket.

If you have the hardware, then you're already halfway there.  A couple of ways to gather people to test your game:


If you live near a university or college, you might have success postering with things like ""Game test volunteers needed!  Android developer needs 2-4 students who are very interested in gaming to test new multiplayer game SPROCKETS.  Game genre is RTS strategy.  PIZZA will be provided."" and attach your number
Meetup.com might put you into contact with like-minded individuals in your area
You might also try Craigslist (volunteer jobs) and kijiji (also asking for volunteers)

"
4270,4270,6807,Why don't wifi managers remember mac addresses for hotspots to defeat the jasager attack?,"So I just learned about the jasager attack, via the wifi pineapple and it struck me immediately that it wouldn't work at all if network managers (privately) associated MAC addresses with hotspots and asked for explicit permission if you were going to connect to a new physical device.

Obviously this would be mildly irritating in public hotspots where devices change and hundreds of diverse locations share network names, but it would make home and work networks much harder to penetrate.

I haven't found any wifi managers that do this, or at least I haven't found information that any do.

My question: 


Am I missing something obvious? Would remembering MACs not actually increase security?
If it would, are there any network managers that do this? (I'm on Linux, but if there are tools for other OS's I think it's worth having them in the answers)

",quodlibetor,https://security.stackexchange.com/users/8391,"MAC address spoofing is trivial for an attacker to carry out,  any form of mac address filtering will not help secure any network.   However,  MAC address filtering can cause real problems for legitimate users.   What if you buy a new router and give it the same SSID?

The best defense against this sort of attack is WPA.  It isn't prefect,  WPA-PSK is pretty easy to break,  but its better than anything else consumers have.
",rook,https://security.stackexchange.com/users/975,http://security.stackexchange.com/questions/14854/why-dont-wifi-managers-remember-mac-addresses-for-hotspots-to-defeat-the-jasage,TECHNOLOGY,security.stackexchange.com,0.7777777777777778,0.5555555555555556,0.3333333333333333,0.5,1.0,0.5,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8,0.3333333333333333,0.0,1.0,0.8888888888888888,Why don't WiFi administrators remember the MAC address of hotspot to resist jasager attack?,"So I just learned about the jasager attack, via the wifi pineapple and it struck me immediately that it wouldn't work at all if network managers (privately) associated MAC addresses with hotspots and asked for explicit permission if you were going to connect to a new physical device.

Obviously this would be mildly irritating in public hotspots where devices change and hundreds of diverse locations share network names, but it would make home and work networks much harder to penetrate.

I haven't found any wifi managers that do this, or at least I haven't found information that any do.

My question: 


Am I missing something obvious? Would remembering MACs not actually increase security?
If it would, are there any network managers that do this? (I'm on Linux, but if there are tools for other OS's I think it's worth having them in the answers)

","MAC address spoofing is trivial to attackers, and any form of MAC address filtering will not help protect any network. However, MAC address filtering will bring real problems to legitimate users. What if you bought a new router and gave it the same SSID?"
3682,3682,5871,how to display a message box for a user in Java,"I want to display a message box to show some message in Java, and the box should have three buttons that the user can press such that the program can get value when user presses the button.
",MagicConch,https://stackoverflow.com/users/1957202,"If you use Java Swing then take a look at

JOptionPane
",Nikolay Kuznetsov,https://stackoverflow.com/users/1360074,http://stackoverflow.com/questions/14209908/how-to-display-a-message-box-for-a-user-in-java,STACKOVERFLOW,stackoverflow.com,1.0,0.7777777777777778,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.3333333333333333,1.0,0.3333333333333333,0.0,0.0,1.0,0.8888888888888888,0.5555555555555556,1.0,1.0,0.7333333333333333,1.0,0.3333333333333333,0.0,1.0,How to display the user's message box in Java,"I want to display a message box that uses Java to display some messages. This box should have three buttons that users can press, so that when users press the button, the program can get the value.","If you use Java Swing then take a look at

JOptionPane
"
3212,3212,5122,"Anybody knows if there is a counterpart for CTR+w , that deletes immediate words after cursor","I mean when the cursor is on the left side of the words ,I would like to remove the words on the immediate right side of it . CTR+k remove everything on the right side, i only want one word to be removed. 
",Eric,https://serverfault.com/users/67065,"Many keyboards will work with Alt as Meta so you can press Alt-d.
",Dennis Williamson,https://serverfault.com/users/1293,http://serverfault.com/questions/226679,TECHNOLOGY,serverfault.com,1.0,0.6666666666666666,0.0,1.0,1.0,1.0,0.6666666666666666,0.5555555555555556,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.5555555555555556,0.8888888888888888,0.6666666666666666,1.0,1.0,0.9,1.0,0.0,0.0,0.8888888888888888,"Anyone knows if CTR + W has a corresponding item, that is, delete the direct word after the cursor","I mean when the cursor is on the left side of the word, I want to delete the word on the right. CTR + K delete everything on the right, I just want to delete one word.","Many keyboards will work with Alt as Meta so you can press Alt-d.
"
1810,1810,2873,How do I reset the software Mac OS X Update Server,"I somehow managed to miss configured my mac osx update-server and would like to reset it, the problem is that there is no reset button to put the update-server into it's original inactivated state. 

So does someone here know how to reset the update-server completely without leaving traces from the configurations which have been done before?
",elhombre,https://apple.stackexchange.com/users/2336,"It seems that that the question has been asked once in the superuser forum but I'm not sure if this method still works now with 10.6 Server. Can someone confirm if this method still works?

http://superuser.com/questions/85913/reset-os-x-software-update-server
",elhombre,https://apple.stackexchange.com/users/2336,http://apple.stackexchange.com/questions/6033/how-do-i-reset-the-software-mac-os-x-update-server,TECHNOLOGY,apple.stackexchange.com,0.8888888888888888,0.8888888888888888,0.0,0.6666666666666666,1.0,1.0,1.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.0,0.0,0.6666666666666666,0.7777777777777778,0.5555555555555556,1.0,0.8888888888888888,0.6,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.7777777777777778,How to reset the Software Mac OS X update server,"Somehow, I managed to miss configuring my Mac OSX update server and wanted to reset it. The problem was that there was no reset button to make the update server go into its original inactive state.","It seems that that the question has been asked once in the superuser forum but I'm not sure if this method still works now with 10.6 Server. Can someone confirm if this method still works?

http://superuser.com/questions/85913/reset-os-x-software-update-server
"
246,246,396,Beamer handout: Problem when creating border around frames,"I am trying to create handouts from a Beamer presentation. I want multiple frames to be on each sheet of printed paper, and I want the frames to have a border, say a border made with a thin line. To save ink, I do not want a shaded background.

I have two problems that need solved. First, how do I create a border for the frames in the handout? The portion of the code below marked Border creates a border, but it also creates a border for frames that do not exist. The portion of the code below marked Prints 8 on 1 allows me to put eight frames one each sheet of paper, but part of the top frames do not print (they're cut off). How can this be fixed without changing printer settings?

\documentclass[10pt,handout,mathserif]{beamer}

\usepackage{amsmath,amssymb,amsfonts,amsthm}
\usepackage{graphics}
\usepackage{color}
\usepackage{framed}
\usepackage{amsthm, array}
\usepackage{yhmath}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage{pgfpages} 
%
% Prints 8 on 1
\pgfpagesuselayout{8 on 1}[letterpaper,border shrink=1mm]
%
%
% Border
\pgfpageslogicalpageoptions{1}{border code=\pgfusepath{stroke}}
\pgfpageslogicalpageoptions{2}{border code=\pgfusepath{stroke}}
\pgfpageslogicalpageoptions{3}{border code=\pgfusepath{stroke}}
\pgfpageslogicalpageoptions{4}{border code=\pgfusepath{stroke}}
\pgfpageslogicalpageoptions{5}{border code=\pgfusepath{stroke}}
\pgfpageslogicalpageoptions{6}{border code=\pgfusepath{stroke}}
\pgfpageslogicalpageoptions{7}{border code=\pgfusepath{stroke}}
\pgfpageslogicalpageoptions{8}{border code=\pgfusepath{stroke}}
%
%
\begin{document}

%Stuff goes here.

\end{document}

",Nathan,https://tex.stackexchange.com/users/13430,"I prefer to not mess with pgfpages and its settings in the presentation source itself, but let an external tool, such as pdfnup, generate the (often various) x-up versions I need with or without borders, distances, scaling:

\documentclass[10pt,handout,onlymath]{beamer}
\usepackage{pgffor}
\usefonttheme{serif}
\begin{document}

\foreach \x in {1,...,7} {\begin{frame}{Title \x}The frame number \x\end{frame}}

\end{document}


If you compile this with:

pdflatex presentation.tex
pdfnup --no-landscape --nup 2x4 --frame true --no-tidy --delta '5mm 5mm' --scale 0.95 presentation.pdf


The result will be a file presentation-nup.pdf that looks as follows:

 

A plus of this approach is that this does not interfere with other LaTeX packages that also affect the shipout-level. textpos, for instance, is incompatible to pgfpages, even though it is mentioned in the beamer userguide as the way to go for absolute positioning.
",Daniel,https://tex.stackexchange.com/users/3751,http://tex.stackexchange.com/questions/53505/beamer-handout-problem-when-creating-border-around-frames,TECHNOLOGY,tex.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,1.0,1.0,1.0,0.3333333333333333,0.4444444444444444,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.6,1.0,0.0,0.0,1.0,Beamer handout: problem creating border around frame,"I am trying to create handouts from a Beamer presentation. I want multiple frames to be on each sheet of printed paper, and I want the frames to have a border, say a border made with a thin line. To save ink, I do not want a shaded background.

I have two problems that need solved. First, how do I create a border for the frames in the handout? The portion of the code below marked Border creates a border, but it also creates a border for frames that do not exist. The portion of the code below marked Prints 8 on 1 allows me to put eight frames one each sheet of paper, but part of the top frames do not print (they're cut off). How can this be fixed without changing printer settings?

\documentclass[10pt,handout,mathserif]{beamer}

\usepackage{amsmath,amssymb,amsfonts,amsthm}
\usepackage{graphics}
\usepackage{color}
\usepackage{framed}
\usepackage{amsthm, array}
\usepackage{yhmath}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage{pgfpages} 
%
% Prints 8 on 1
\pgfpagesuselayout{8 on 1}[letterpaper,border shrink=1mm]
%
%
% Border
\pgfpageslogicalpageoptions{1}{border code=\pgfusepath{stroke}}
\pgfpageslogicalpageoptions{2}{border code=\pgfusepath{stroke}}
\pgfpageslogicalpageoptions{3}{border code=\pgfusepath{stroke}}
\pgfpageslogicalpageoptions{4}{border code=\pgfusepath{stroke}}
\pgfpageslogicalpageoptions{5}{border code=\pgfusepath{stroke}}
\pgfpageslogicalpageoptions{6}{border code=\pgfusepath{stroke}}
\pgfpageslogicalpageoptions{7}{border code=\pgfusepath{stroke}}
\pgfpageslogicalpageoptions{8}{border code=\pgfusepath{stroke}}
%
%
\begin{document}

%Stuff goes here.

\end{document}

","I prefer to not mess with pgfpages and its settings in the presentation source itself, but let an external tool, such as pdfnup, generate the (often various) x-up versions I need with or without borders, distances, scaling:

\documentclass[10pt,handout,onlymath]{beamer}
\usepackage{pgffor}
\usefonttheme{serif}
\begin{document}

\foreach \x in {1,...,7} {\begin{frame}{Title \x}The frame number \x\end{frame}}

\end{document}


If you compile this with:

pdflatex presentation.tex
pdfnup --no-landscape --nup 2x4 --frame true --no-tidy --delta '5mm 5mm' --scale 0.95 presentation.pdf


The result will be a file presentation-nup.pdf that looks as follows:

 

A plus of this approach is that this does not interfere with other LaTeX packages that also affect the shipout-level. textpos, for instance, is incompatible to pgfpages, even though it is mentioned in the beamer userguide as the way to go for absolute positioning.
"
2630,2630,4180,"If NASA could send a camera into a black hole, could we then see what's inside the black hole?","Inspired by Stephen Hawking I recently tripped upon an idea of what is really inside a black hole.

I thought if NASA (or any other space agency) could send a super protected camera into a black hole, then we could see what's inside black hole.

Is this even possible?
",Amit Joki,https://physics.stackexchange.com/users/40854,"No. It would not be possible. Things get very hot around the edge of a black hole. There is no technology that exists or is likely to exist that could protect a camera. The fact that EM radiation is in fact light and the strength of gravity...lalala. No. It's just not possible.
",user40906,https://physics.stackexchange.com/users/40906,http://physics.stackexchange.com/questions/99678/if-nasa-could-send-a-camera-into-a-black-hole-could-we-then-see-whats-inside-t,SCIENCE,physics.stackexchange.com,1.0,1.0,0.0,0.0,1.0,1.0,0.6666666666666666,0.7777777777777778,0.0,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.0,0.6666666666666666,1.0,"If NASA can send cameras into black holes, can we see what's inside them?","Inspired by Stephen Hawking I recently tripped upon an idea of what is really inside a black hole.

I thought if NASA (or any other space agency) could send a super protected camera into a black hole, then we could see what's inside black hole.

Is this even possible?
","No. It would not be possible. Things get very hot around the edge of a black hole. There is no technology that exists or is likely to exist that could protect a camera. The fact that EM radiation is in fact light and the strength of gravity...lalala. No. It's just not possible.
"
5971,5971,9467,Java read pptx file,"Can someone help me how to read pptx file in java?i would prefer if this can be read with apache POI, i have been searched this tutorial but i can't find it.I've been successfully read the ppt file with this code :

try {
    FileInputStream fis = new FileInputStream(file);
    fs = new POIFSFileSystem(fis);
    HSLFSlideShow show = new HSLFSlideShow(fs);
    SlideShow ss = new SlideShow(show);
    Slide[] slides=ss.getSlides();
    for (int x = 0; x &lt; slides.length; x++) {
        System.out.println(""Slide = "" + (x + 1) + "" :"" + slides[x].getTitle());

        TextRun[] runs = slides[x].getTextRuns();
        for (int i = 0; i &lt; runs.length; i++) {
            TextRun run = runs[i];
            if (run.getRunType() == TextHeaderAtom.TITLE_TYPE) {
                System.out.println(""Slide title "" + (i + 1) + "": "" + run.getText());
            } else {
                System.out.println(""Slide text run "" + (i + 1) + "": ""  + run.getRunType() + "" : "" + run.getText());
            }
        }
    }
} catch (IOException ioe) {
    ioe.printStackTrace();
}


Can someone tell me what part of this code must be modified to read pptx file?
",user1290932,https://stackoverflow.com/users/1290932,"According to apache poi release notes, version 3.8 can be used to read PPTX. You have to check out the documentation though. 
",kostas,https://stackoverflow.com/users/831317,http://stackoverflow.com/questions/10684526/java-read-pptx-file,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.5555555555555556,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.3333333333333333,1.0,0.3333333333333333,0.0,0.0,0.4444444444444444,0.8888888888888888,0.6666666666666666,1.0,1.0,0.6666666666666667,1.0,0.0,0.0,1.0,Java reading pptx file,"Can someone help me how to read pptx file in java?i would prefer if this can be read with apache POI, i have been searched this tutorial but i can't find it.I've been successfully read the ppt file with this code :

try {
    FileInputStream fis = new FileInputStream(file);
    fs = new POIFSFileSystem(fis);
    HSLFSlideShow show = new HSLFSlideShow(fs);
    SlideShow ss = new SlideShow(show);
    Slide[] slides=ss.getSlides();
    for (int x = 0; x &lt; slides.length; x++) {
        System.out.println(""Slide = "" + (x + 1) + "" :"" + slides[x].getTitle());

        TextRun[] runs = slides[x].getTextRuns();
        for (int i = 0; i &lt; runs.length; i++) {
            TextRun run = runs[i];
            if (run.getRunType() == TextHeaderAtom.TITLE_TYPE) {
                System.out.println(""Slide title "" + (i + 1) + "": "" + run.getText());
            } else {
                System.out.println(""Slide text run "" + (i + 1) + "": ""  + run.getRunType() + "" : "" + run.getText());
            }
        }
    }
} catch (IOException ioe) {
    ioe.printStackTrace();
}


Can someone tell me what part of this code must be modified to read pptx file?
","According to the Apache POI release notes, version 3.8 can be used to read pptx. However, you must view the document."
3345,3345,5337,"Is ""my going"" correct, or should I use something else?","I want to say;


  If I go there, there will be a problem.


Is it possible to say is as below;


  My going there will create a problem.


Feel free to provide different examples.

Thanks. 
",discoversf,https://ell.stackexchange.com/users/12311,"Yeah, that's be fine to say! You could also use:


By going there, I'll create a problem.
In going there, I'll create a problem.


Sorry that this answer couldn't be more substantial, but yours worked just fine!
",HarryCBurn,https://ell.stackexchange.com/users/16147,http://ell.stackexchange.com/questions/52785/is-the-my-going-there-the-same-as-if-i-go-there,CULTURE,ell.stackexchange.com,0.8888888888888888,0.4444444444444444,0.3333333333333333,1.0,1.0,1.0,0.6666666666666666,0.7777777777777778,0.0,0.0,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.0,0.7777777777777778,1.0,0.7777777777777778,1.0,1.0,1.0,0.0,0.3333333333333333,0.3333333333333333,0.8888888888888888,"Is ""I'm going"" right, or should I use something else?","I want to say;


  If I go there, there will be a problem.


Is it possible to say is as below;


  My going there will create a problem.


Feel free to provide different examples.

Thanks. 
","Yeah, that's be fine to say! You could also use:


By going there, I'll create a problem.
In going there, I'll create a problem.


Sorry that this answer couldn't be more substantial, but yours worked just fine!
"
4045,4045,6457,Behavior when validating an expired certificate chain,"I have the following situation: 


A server certificate (CServ) is signed by self-signed certificate (C0)
A client certificate (CCli) is signed by CServ
Client's trust-store contains C0, so the client application can trust CServ


Note: C0 is actually a simulation of a CA certificate for testing purposes.

Now, let's consider a situation when C0 either is expired or not yet valid. Since it's stored in client's trust-store, is it still trusted? In other words is chain [C0, CServ] still valid?
",Andrey Atapin,https://security.stackexchange.com/users/9288,"The trust store seems to contain certificates, but that's an illusion (or a tradition). Technically, a trust anchor, i.e. the basis for the trust in certificate validation, is a name coupled with a public key. It so happens that people found it convenient to store the name and public key as a file with the same format as a certificate; this required some trickeries, such as the ""self-signature"", which makes no sense but had to be included because the format for a certificate includes a non-optional field for a signature.

At that point, it really depends on the OS/browser internal conventions. Some implementations will look at the ""validity dates"" in the trust anchor ""certificate"" and will use them as, indeed, validity dates (i.e. beyond the end of validity date, they will cease to trust that trust anchor, even if it is still ""there"", in the dedicated store for trust anchors). Some other implementations will ignore these dates altogether. It is really up to each implementation to make these choices, since the standard is silent on the subject.

So you have to test.
",Thomas Pornin,https://security.stackexchange.com/users/655,http://security.stackexchange.com/questions/27987/behavior-when-validating-an-expired-certificate-chain,TECHNOLOGY,security.stackexchange.com,1.0,0.4444444444444444,0.0,1.0,1.0,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.5555555555555556,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8,0.0,0.0,1.0,0.8888888888888888,Behavior when validating an expired certificate chain,"I have the following situation: 


A server certificate (CServ) is signed by self-signed certificate (C0)
A client certificate (CCli) is signed by CServ
Client's trust-store contains C0, so the client application can trust CServ


Note: C0 is actually a simulation of a CA certificate for testing purposes.

Now, let's consider a situation when C0 either is expired or not yet valid. Since it's stored in client's trust-store, is it still trusted? In other words is chain [C0, CServ] still valid?
","The trust store seems to contain certificates, but that's an illusion (or a tradition). Technically, a trust anchor, i.e. the basis for the trust in certificate validation, is a name coupled with a public key. It so happens that people found it convenient to store the name and public key as a file with the same format as a certificate; this required some trickeries, such as the ""self-signature"", which makes no sense but had to be included because the format for a certificate includes a non-optional field for a signature.

At that point, it really depends on the OS/browser internal conventions. Some implementations will look at the ""validity dates"" in the trust anchor ""certificate"" and will use them as, indeed, validity dates (i.e. beyond the end of validity date, they will cease to trust that trust anchor, even if it is still ""there"", in the dedicated store for trust anchors). Some other implementations will ignore these dates altogether. It is really up to each implementation to make these choices, since the standard is silent on the subject.

So you have to test.
"
2512,2512,4008,Extending Internal Link and External Link to allow selection of Images,"I need to extend selection of external and Internal Link and provide a image selection.

Please see the snapshot in the below :


Here the above snapshot allows you to add properties for External Link.In the same popup can we add a field Called Image(as shown in screenshot) which will allow user to select images from the media library??

Thanks,
Suhas
",Suhas,https://stackoverflow.com/users/998504,"If you are using Sitecore 7.2 and want to update internal link then you need to do with Sitecore speak and in case of external link simply update under /shell/Applications/Dialogs/ExternalLink folder.

To render this field create CustomLinkRenderer class and inheri this class by LinkRenderer of Sitecore.Kernel.dll.

Please see below code for CustomLinkRenderer

public class CustomLinkRenderer : LinkRenderer
    {
        public CustomLinkRenderer(Item item)
            : base(item)
        {

        }
        public override RenderFieldResult Render()
        {
            string str8;
            SafeDictionary&lt;string&gt; dictionary = new SafeDictionary&lt;string&gt;();
            dictionary.AddRange(this.Parameters);
            if (MainUtil.GetBool(dictionary[""endlink""], false))
            {
                return RenderFieldResult.EndLink;
            }
            Set&lt;string&gt; set = Set&lt;string&gt;.Create(new string[] { ""field"", ""select"", ""text"", ""haschildren"", ""before"", ""after"", ""enclosingtag"", ""fieldname"" });
            LinkField linkField = this.LinkField;
            if (linkField != null)
            {
                dictionary[""title""] = StringUtil.GetString(new string[] { dictionary[""title""], linkField.Title });
                dictionary[""target""] = StringUtil.GetString(new string[] { dictionary[""target""], linkField.Target });
                dictionary[""class""] = StringUtil.GetString(new string[] { dictionary[""class""], linkField.Class });
            }
            string str = string.Empty;
            string rawParameters = this.RawParameters;
            if (!string.IsNullOrEmpty(rawParameters) &amp;&amp; (rawParameters.IndexOfAny(new char[] { '=', '&amp;' }) &lt; 0))
            {
                str = rawParameters;
            }
            if (string.IsNullOrEmpty(str))
            {
                Item targetItem = this.TargetItem;
                string str3 = (targetItem != null) ? targetItem.DisplayName : string.Empty;
                string str4 = (linkField != null) ? linkField.Text : string.Empty;
                str = StringUtil.GetString(new string[] { str, dictionary[""text""], str4, str3 });
            }
            string url = this.GetUrl(linkField);
            if (((str8 = this.LinkType) != null) &amp;&amp; (str8 == ""javascript""))
            {
                dictionary[""href""] = ""#"";
                dictionary[""onclick""] = StringUtil.GetString(new string[] { dictionary[""onclick""], url });
            }
            else
            {
                dictionary[""href""] = HttpUtility.HtmlEncode(StringUtil.GetString(new string[] { dictionary[""href""], url }));
            }
            // Add onclick attribute for Google event tracking 
            dictionary[""onclick""] = LinkField.GetAttribute(""on_click"");
            StringBuilder tag = new StringBuilder(""&lt;a"", 0x2f);
            foreach (KeyValuePair&lt;string, string&gt; pair in dictionary)
            {
                string key = pair.Key;
                string str7 = pair.Value;
                if (!set.Contains(key.ToLowerInvariant()))
                {
                    FieldRendererBase.AddAttribute(tag, key, str7);
                }
            }
            tag.Append('&gt;');
            if (!MainUtil.GetBool(dictionary[""haschildren""], false))
            {
                if (string.IsNullOrEmpty(str))
                {
                    return RenderFieldResult.Empty;
                }
                tag.Append(str);
            }
            return new RenderFieldResult { FirstPart = tag.ToString(), LastPart = ""&lt;/a&gt;"" };
        }
    }


You need to extend this class as per your need to render image.
",Yogesh Sharma,https://stackoverflow.com/users/1273446,http://stackoverflow.com/questions/23337280/extending-internal-link-and-external-link-to-allow-selection-of-images,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.5555555555555556,0.0,1.0,0.6666666666666666,1.0,0.4444444444444444,0.4444444444444444,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.4444444444444444,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,0.0,0.6666666666666666,Expand internal and external links to allow image selection,"I need to extend selection of external and Internal Link and provide a image selection.

Please see the snapshot in the below :


Here the above snapshot allows you to add properties for External Link.In the same popup can we add a field Called Image(as shown in screenshot) which will allow user to select images from the media library??

Thanks,
Suhas
","If you are using Sitecore 7.2 and want to update internal link then you need to do with Sitecore speak and in case of external link simply update under /shell/Applications/Dialogs/ExternalLink folder.

To render this field create CustomLinkRenderer class and inheri this class by LinkRenderer of Sitecore.Kernel.dll.

Please see below code for CustomLinkRenderer

public class CustomLinkRenderer : LinkRenderer
    {
        public CustomLinkRenderer(Item item)
            : base(item)
        {

        }
        public override RenderFieldResult Render()
        {
            string str8;
            SafeDictionary&lt;string&gt; dictionary = new SafeDictionary&lt;string&gt;();
            dictionary.AddRange(this.Parameters);
            if (MainUtil.GetBool(dictionary[""endlink""], false))
            {
                return RenderFieldResult.EndLink;
            }
            Set&lt;string&gt; set = Set&lt;string&gt;.Create(new string[] { ""field"", ""select"", ""text"", ""haschildren"", ""before"", ""after"", ""enclosingtag"", ""fieldname"" });
            LinkField linkField = this.LinkField;
            if (linkField != null)
            {
                dictionary[""title""] = StringUtil.GetString(new string[] { dictionary[""title""], linkField.Title });
                dictionary[""target""] = StringUtil.GetString(new string[] { dictionary[""target""], linkField.Target });
                dictionary[""class""] = StringUtil.GetString(new string[] { dictionary[""class""], linkField.Class });
            }
            string str = string.Empty;
            string rawParameters = this.RawParameters;
            if (!string.IsNullOrEmpty(rawParameters) &amp;&amp; (rawParameters.IndexOfAny(new char[] { '=', '&amp;' }) &lt; 0))
            {
                str = rawParameters;
            }
            if (string.IsNullOrEmpty(str))
            {
                Item targetItem = this.TargetItem;
                string str3 = (targetItem != null) ? targetItem.DisplayName : string.Empty;
                string str4 = (linkField != null) ? linkField.Text : string.Empty;
                str = StringUtil.GetString(new string[] { str, dictionary[""text""], str4, str3 });
            }
            string url = this.GetUrl(linkField);
            if (((str8 = this.LinkType) != null) &amp;&amp; (str8 == ""javascript""))
            {
                dictionary[""href""] = ""#"";
                dictionary[""onclick""] = StringUtil.GetString(new string[] { dictionary[""onclick""], url });
            }
            else
            {
                dictionary[""href""] = HttpUtility.HtmlEncode(StringUtil.GetString(new string[] { dictionary[""href""], url }));
            }
            // Add onclick attribute for Google event tracking 
            dictionary[""onclick""] = LinkField.GetAttribute(""on_click"");
            StringBuilder tag = new StringBuilder(""&lt;a"", 0x2f);
            foreach (KeyValuePair&lt;string, string&gt; pair in dictionary)
            {
                string key = pair.Key;
                string str7 = pair.Value;
                if (!set.Contains(key.ToLowerInvariant()))
                {
                    FieldRendererBase.AddAttribute(tag, key, str7);
                }
            }
            tag.Append('&gt;');
            if (!MainUtil.GetBool(dictionary[""haschildren""], false))
            {
                if (string.IsNullOrEmpty(str))
                {
                    return RenderFieldResult.Empty;
                }
                tag.Append(str);
            }
            return new RenderFieldResult { FirstPart = tag.ToString(), LastPart = ""&lt;/a&gt;"" };
        }
    }


You need to extend this class as per your need to render image.
"
5945,5945,9420,How to install social engineering toolkit?,"When I searched for the social engineering toolkit I got the error ""no such path or file"".

I used this orders for installing it but without success.


  be sure to install subversion before installing the selected tools.


(i did it)

svn co http://svn.secmaniac.com/social_engineering_toolkit set/


and the link is not working anymore.
",user227691,https://askubuntu.com/users/227691,"The URL you're using has been permanently redirected to http://www.trustedsec.com, which looks to me like a website, not a Subversion repository.

You'll have to contact the owner of the repository for current information about its availability.
",ændrük,https://askubuntu.com/users/1859,http://askubuntu.com/questions/394141/how-to-install-social-engineering-toolkit,TECHNOLOGY,askubuntu.com,0.8888888888888888,0.7777777777777778,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,0.8888888888888888,0.9333333333333332,0.6666666666666666,0.0,0.6666666666666666,0.8888888888888888,How to install social engineering toolkit?,"When I searched for the social engineering toolkit I got the error ""no such path or file"".

I used this orders for installing it but without success.


  be sure to install subversion before installing the selected tools.


(i did it)

svn co http://svn.secmaniac.com/social_engineering_toolkit set/


and the link is not working anymore.
","The URL you are using has been permanently redirected to http://www.trustedsec.com, which in my opinion is a website, not a subversion repository."
457,457,712,Functional complete and xor,"Give a formal proof for the claim that the set $\{xor\}$ is not functional complete.

One possible way is to show that we cannot create the function $\lnot$. I tried to prove it by using induction on the structure of $A$. If $A$ is a formula and $V$ is a model that gives $f$ to all atomic formulas then $V(A) = f$. The base case is $A = p$ and so $V(A) = f$. We assume that it holds for the formulas $B$ and $C$. We have $A = xor(B,C)$ and by using the induction hypothesis and the definition of $xor$ we get $V(A) = f$.

But I want to show that we cannot create the function $\land$ I tried using the same method as before but it doesn't seem to work. What should the induction hypothesis be in this case?
",user91015,https://math.stackexchange.com/users/91015,"You have to consider an induction on the number of occurrences of connective in the formula.

Consider $\land$

Basis : in $p \land q$, when $p$ and $q$ have different truth values, then $p \land q$ is false.

Induction step : let $F_n^{\land}(p,q)$ a formula built with only the literals $p$ and $q$ with $n$ occurrences of $\land$, and assume as Induction hypo that it is identically false. 

If we consider now $F_{n+1}^{\land}(p,q)$ (i.e $F_n^{\land}(p,q) \land p$ or $F_n^{\land}(p,q) \land q$), again it is identically false.

Consider $xor$ (i.e. $\nLeftrightarrow$)

Basis : in $p \nLeftrightarrow q$, when $p$ and $q$ have different truth values, then $p \nLeftrightarrow q$ is true.

Induction step : let $F_n^{\nLeftrightarrow}(p,q)$ a formula built with only the literals $p$ and $q$ with $n$ occurrences of $\nLeftrightarrow $, ans assume as Induction hypo that it is not identically false. 

If we consider now $F_{n+1}^{\nLeftrightarrow}(p,q)$ (i.e $F_n^{\nLeftrightarrow}(p,q) \nLeftrightarrow p$ or $F_n^{\land}(p,q) \nLeftrightarrow q$), it can be true or false, and adding a new literal $p$ (or $q$), the result $F_{n+1}^{\nLeftrightarrow}$ will ""flip"" according to the value of $p$ (or $q$).

Thus, we have that it is not identically false.
",Mauro ALLEGRANZA,https://math.stackexchange.com/users/108274,http://math.stackexchange.com/questions/778451/functional-complete-and-xor,SCIENCE,math.stackexchange.com,0.8333333333333334,0.3333333333333333,0.0,1.0,1.0,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.8333333333333334,1.0,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,1.0,0.6666666666666666,Complete function and exclusive or,"Give a formal proof for the claim that the set $\{xor\}$ is not functional complete.

One possible way is to show that we cannot create the function $\lnot$. I tried to prove it by using induction on the structure of $A$. If $A$ is a formula and $V$ is a model that gives $f$ to all atomic formulas then $V(A) = f$. The base case is $A = p$ and so $V(A) = f$. We assume that it holds for the formulas $B$ and $C$. We have $A = xor(B,C)$ and by using the induction hypothesis and the definition of $xor$ we get $V(A) = f$.

But I want to show that we cannot create the function $\land$ I tried using the same method as before but it doesn't seem to work. What should the induction hypothesis be in this case?
","You have to consider an induction on the number of occurrences of connective in the formula.

Consider $\land$

Basis : in $p \land q$, when $p$ and $q$ have different truth values, then $p \land q$ is false.

Induction step : let $F_n^{\land}(p,q)$ a formula built with only the literals $p$ and $q$ with $n$ occurrences of $\land$, and assume as Induction hypo that it is identically false. 

If we consider now $F_{n+1}^{\land}(p,q)$ (i.e $F_n^{\land}(p,q) \land p$ or $F_n^{\land}(p,q) \land q$), again it is identically false.

Consider $xor$ (i.e. $\nLeftrightarrow$)

Basis : in $p \nLeftrightarrow q$, when $p$ and $q$ have different truth values, then $p \nLeftrightarrow q$ is true.

Induction step : let $F_n^{\nLeftrightarrow}(p,q)$ a formula built with only the literals $p$ and $q$ with $n$ occurrences of $\nLeftrightarrow $, ans assume as Induction hypo that it is not identically false. 

If we consider now $F_{n+1}^{\nLeftrightarrow}(p,q)$ (i.e $F_n^{\nLeftrightarrow}(p,q) \nLeftrightarrow p$ or $F_n^{\land}(p,q) \nLeftrightarrow q$), it can be true or false, and adding a new literal $p$ (or $q$), the result $F_{n+1}^{\nLeftrightarrow}$ will ""flip"" according to the value of $p$ (or $q$).

Thus, we have that it is not identically false.
"
4499,4499,7134,Use multiselect false property with checkboxCellTemplate,"I have an ng-grid that utilizes the showSelectionCheckbox: true property with a custom checkboxCellTemplate. 

If I remove checkboxCellTemplate I get the functionality I want where only one checkbox can be clicked at a time and clicking another checkbox will remove the selection from the previous one. 

I need the template to call a specific function so my question comes down to what property to I have to pass in the template so it can be aware of the multiselect property? 

The plunker can be found at http://plnkr.co/edit/nULoI4?p=preview.
",Ronald91,https://stackoverflow.com/users/1195546,"So to clarify you're wondering if you can get all the values that are selected when you call a function?  Don't you already have this setup in the $scope.selections.  You could pass this in the function of the template by doing something like this ng-click=""getDeliveryLocation({{selections}})"".

Another thought is that you use afterSelectionChange:function(){} and add in whatever you need instead of the ng-click on the checkmarks.  This will remove some of the odd issues you have between the different selects.
",Ty Danielson,https://stackoverflow.com/users/2661425,http://stackoverflow.com/questions/20074012/use-multiselect-false-property-with-checkboxcelltemplate,STACKOVERFLOW,stackoverflow.com,1.0,0.3333333333333333,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.5555555555555556,0.8888888888888888,0.6666666666666666,1.0,1.0,0.9,0.6666666666666666,0.0,0.3333333333333333,0.8888888888888888,Use multiselect false property on checkboxcelltemplate,"I have an ng-grid that utilizes the showSelectionCheckbox: true property with a custom checkboxCellTemplate. 

If I remove checkboxCellTemplate I get the functionality I want where only one checkbox can be clicked at a time and clicking another checkbox will remove the selection from the previous one. 

I need the template to call a specific function so my question comes down to what property to I have to pass in the template so it can be aware of the multiselect property? 

The plunker can be found at http://plnkr.co/edit/nULoI4?p=preview.
","So to clarify this, would you like to know if you can get all the values you selected when you call a function? Whether you have set this setting in $scope.selections. You can pass it to the function of the template by performing an operation similar to ng Click = ""getdeliverylocation ({selections})""."
1775,1775,2818,GIS Software Choice for a small university research centre,"I need to choose a GIS system for a small university research centre. We are handling a broad range of data, (for example, numerical tidal analyses, weather data, poverty, isolated economic activity, skills availability and renewable energy resource availability) and operate primarily in countries with relatively poor existing data sets. 

We interact with other groups, some of which use ARCGIS. Do I have to wade through every GIS software descriptor on the web, or can someone please give an indication of likely candidates? 
",Alan Owen,https://gis.stackexchange.com/users/8127,"Some excellent answers here, so I'll just throw one more GIS into the mix viz. Idrisi.  Idrisi seems to be a very popular choice for Universitys and student teaching labs.  I haven't used it for ages but it is a very capable product and Clark Labs always used to have an academic discount, and I presume they still do.
",MappaGnosis,https://gis.stackexchange.com/users/5222,http://gis.stackexchange.com/questions/27188/gis-software-choice-for-a-small-university-research-centre,TECHNOLOGY,gis.stackexchange.com,0.7777777777777778,0.7777777777777778,0.3333333333333333,1.0,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.4444444444444444,0.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.3333333333333333,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8,0.0,0.0,0.6666666666666666,1.0,Selection of GIS software for research center of small University,"I need to choose a geographic information system for a small university research center. We are working on a wide range of data (e.g., numerical tidal analysis, weather data, poverty, isolated economic activity, skill availability and renewable energy availability), mainly in countries with relatively poor existing data sets.","Some excellent answers here, so I'll just throw one more GIS into the mix viz. Idrisi.  Idrisi seems to be a very popular choice for Universitys and student teaching labs.  I haven't used it for ages but it is a very capable product and Clark Labs always used to have an academic discount, and I presume they still do.
"
886,886,1406,Are human males and females more genetically different than members of other species?,"I'm looking at this Ted talk about a Saudi Arabia woman who dared to drive a car in the last few years. This reminds me that until the last century or so, women (all over the world?) enjoyed less rights and might've been pigeonholed into roles predetermined by society. Those roles might've encouraged certain traits, and discouraged others. Those who did not conform might've been punished, like the woman in the talk above received death threats and was jailed.

This sounds to me like selective pressure, did it really exist, and did it have any effect on the genetics/traits of modern women?

This makes me interested in the question - compared to other species, are men and women more genetically different because of selective pressure put on women to conform to male-dominated world for thousands of years before 19th century?
",Alex Stone,https://biology.stackexchange.com/users/577,"I'm not sure I buy your premise: firstly, the degree and form of male-female differentiation in social roles has varied widely across time and culture in human history so I doubt it forms a uniform evolutionary driver such as you describe. Secondly, the degree of male-female differentiation appears to me to be much greater in species such as gorillas, lions and peacocks than it does in humans so I'm not convinced that humans would stand out on this front as a species we'd expect to have greater genetic differences.

Even so, the only genetic difference between male and female humans is the Y-chromosome. The X appears in both males and females and doesn't have exclusively female lineage so it can't acquire separate genes for male and female. The Y chromosome contains very few genes so its not capable of manifesting a major genetic gap and because there is no recombination in the Y chromosome it is not a fertile ground for new genes anyway.

So males and females have essentially the same genes. However, this isn't the whole story because how, when and whether genes are expressed is about as important as what genes are encoded anyway. It is these differences that enable big differences between the sexes not actual coding differences. 
",Jack Aidley,https://biology.stackexchange.com/users/2938,http://biology.stackexchange.com/questions/8816/are-human-males-and-females-more-genetically-different-than-members-of-other-spe,SCIENCE,biology.stackexchange.com,1.0,0.7777777777777778,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.8888888888888888,1.0,0.3333333333333333,0.0,0.6666666666666666,0.0,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,1.0,0.7777777777777778,0.6666666666666666,0.8888888888888888,1.0,0.8,0.0,0.0,1.0,0.8888888888888888,Are men and women genetically different from members of other species?,"I'm reading this Ted speech about a Saudi woman who has dared to drive in the past few years. This reminds me that until the last century or so, women (the world?) Having fewer rights may be divided into social predetermined roles. These characters may encourage certain traits and discourage others. Those who do not comply may be punished, like the woman in the conversation above, by death threats and imprisonment.","I'm not sure I buy your premise: firstly, the degree and form of male-female differentiation in social roles has varied widely across time and culture in human history so I doubt it forms a uniform evolutionary driver such as you describe. Secondly, the degree of male-female differentiation appears to me to be much greater in species such as gorillas, lions and peacocks than it does in humans so I'm not convinced that humans would stand out on this front as a species we'd expect to have greater genetic differences.

Even so, the only genetic difference between male and female humans is the Y-chromosome. The X appears in both males and females and doesn't have exclusively female lineage so it can't acquire separate genes for male and female. The Y chromosome contains very few genes so its not capable of manifesting a major genetic gap and because there is no recombination in the Y chromosome it is not a fertile ground for new genes anyway.

So males and females have essentially the same genes. However, this isn't the whole story because how, when and whether genes are expressed is about as important as what genes are encoded anyway. It is these differences that enable big differences between the sexes not actual coding differences. 
"
2788,2788,4444,Private IP getting routed over Internet,"We are setting up an internal program, on an internal server that uses the private 172.30.x.x subnet... when we ping the address 172.30.138.2, it routes across the internet: 

C:\&gt;tracert 172.30.138.2
Tracing route to 172.30.138.2 over a maximum of 30 hops

  1     6 ms     1 ms     1 ms  xxxx.xxxxxxxxxxxxxxx.org [192.168.28.1]
  2     *        *        *     Request timed out.
  3    12 ms    13 ms     9 ms  xxxxxxxxxxx.xxxxxx.xx.xxx.xxxxxxx.net [68.85.xx.xx]
  4    15 ms    11 ms    55 ms  te-7-3-ar01.salisbury.md.bad.comcast.net [68.87.xx.xx]
  5    13 ms    14 ms    18 ms  xe-11-0-3-0-ar04.capitolhghts.md.bad.comcast.net [68.85.xx.xx]
  6    19 ms    18 ms    14 ms  te-1-0-0-4-cr01.denver.co.ibone.comcast.net [68.86.xx.xx]
  7    28 ms    30 ms    30 ms  pos-4-12-0-0-cr01.atlanta.ga.ibone.comcast.net [68.86.xx.xx]
  8    30 ms    43 ms    30 ms  68.86.xx.xx
  9    30 ms    29 ms    31 ms  172.30.138.2

Trace complete.


This has a number of us confused. If we had a VPN setup, it wouldn't show up as being routed across the internet. If it hit an internet server, Private IP's (such as 192.168) shouldn't get routed.

What would let a private IP address get routed across servers? would the fact that it's all comcast mean that they have their routers setup wrong?
",WernerCD,https://serverfault.com/users/53719,"
  would the fact that it's all comcast mean that they have their routers setup wrong?


Set up wrong? Yes, private addressing should absolutely be filtered within the interior of their network. But if they've been a bit sloppy then it's possible if the path is all Comcast- in carrier networks, especially sloppy ones like Comcast, private addressing is filtered at the edge networking diligently, but not nearly as much at the core or access portions. In your case it appears that the entire route is Comcast-only, so it is 'reasonable' that this might actually be forwarded to a destination also within Comcast that actually answers for it. It isn't a clean networking implementation, to be sure, and you did go from the Baltimore area to Denver and finally to Georgia, but it is possible within a complete ""autonomous system"" that allows for it.
",danno,https://serverfault.com/users/78403,http://serverfault.com/questions/374126,TECHNOLOGY,serverfault.com,0.6666666666666666,0.6666666666666666,0.0,0.5,1.0,1.0,0.8333333333333334,0.6666666666666666,0.5,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.5,0.0,1.0,0.0,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,1.0,0.9,0.5,0.0,1.0,1.0,Private IP routed over the Internet,"We are setting up an internal program, on an internal server that uses the private 172.30.x.x subnet... when we ping the address 172.30.138.2, it routes across the internet: 

C:\&gt;tracert 172.30.138.2
Tracing route to 172.30.138.2 over a maximum of 30 hops

  1     6 ms     1 ms     1 ms  xxxx.xxxxxxxxxxxxxxx.org [192.168.28.1]
  2     *        *        *     Request timed out.
  3    12 ms    13 ms     9 ms  xxxxxxxxxxx.xxxxxx.xx.xxx.xxxxxxx.net [68.85.xx.xx]
  4    15 ms    11 ms    55 ms  te-7-3-ar01.salisbury.md.bad.comcast.net [68.87.xx.xx]
  5    13 ms    14 ms    18 ms  xe-11-0-3-0-ar04.capitolhghts.md.bad.comcast.net [68.85.xx.xx]
  6    19 ms    18 ms    14 ms  te-1-0-0-4-cr01.denver.co.ibone.comcast.net [68.86.xx.xx]
  7    28 ms    30 ms    30 ms  pos-4-12-0-0-cr01.atlanta.ga.ibone.comcast.net [68.86.xx.xx]
  8    30 ms    43 ms    30 ms  68.86.xx.xx
  9    30 ms    29 ms    31 ms  172.30.138.2

Trace complete.


This has a number of us confused. If we had a VPN setup, it wouldn't show up as being routed across the internet. If it hit an internet server, Private IP's (such as 192.168) shouldn't get routed.

What would let a private IP address get routed across servers? would the fact that it's all comcast mean that they have their routers setup wrong?
","
  would the fact that it's all comcast mean that they have their routers setup wrong?


Set up wrong? Yes, private addressing should absolutely be filtered within the interior of their network. But if they've been a bit sloppy then it's possible if the path is all Comcast- in carrier networks, especially sloppy ones like Comcast, private addressing is filtered at the edge networking diligently, but not nearly as much at the core or access portions. In your case it appears that the entire route is Comcast-only, so it is 'reasonable' that this might actually be forwarded to a destination also within Comcast that actually answers for it. It isn't a clean networking implementation, to be sure, and you did go from the Baltimore area to Denver and finally to Georgia, but it is possible within a complete ""autonomous system"" that allows for it.
"
5593,5593,8879,tar -c Error Messages and Source Files?,"During a tar archiving operation with tar -cvf archive.tar source does the resulting tar archive that reports a file changed as we read it error still contain ""some version"" of the source file that it reported the error on or does it completely abandon archiving that source file and move on?
",haziz,https://unix.stackexchange.com/users/12997,"tar is for tape archive and it is stream based. tar can't go backward to erase what it has already written. So, that message is to tell you that what's in the archive may not be consistent as it changed while being written.

What happens is that for each file, tar writes a header that includes the path to the file, metadata (ownership, permission, time...) and the size (n bytes) and then proceeds to dump those n bytes by reading it from the file. If the size of the file changes while tar is dumping its content, tar can't go back and change the header to say, no after all the size was not n but p. All it can do is truncate the content to n bytes if p is greater than n or pad with zeros if it's smaller.

In both cases, you'll get an error message.
",Stéphane Chazelas,https://unix.stackexchange.com/users/22565,http://unix.stackexchange.com/questions/57387/tar-c-error-messages-and-source-files,TECHNOLOGY,unix.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.0,1.0,0.8888888888888888,Tar-c error messages and source files?,"During the tar archive operation with tar-cvf archive.tar source, does the tar archive still contain ""some versions"" of the source file that reported the error, or do you want to discard the archive completely and continue?","tar is for tape archive and it is stream based. tar can't go backward to erase what it has already written. So, that message is to tell you that what's in the archive may not be consistent as it changed while being written.

What happens is that for each file, tar writes a header that includes the path to the file, metadata (ownership, permission, time...) and the size (n bytes) and then proceeds to dump those n bytes by reading it from the file. If the size of the file changes while tar is dumping its content, tar can't go back and change the header to say, no after all the size was not n but p. All it can do is truncate the content to n bytes if p is greater than n or pad with zeros if it's smaller.

In both cases, you'll get an error message.
"
862,862,1370,Wireless link frequency choice (900Mhz vs 5.8Ghz) for 2-3km distance,"I have recently been contracted by a client of mine to facilitate the wireless communication of his ""home"" offices and a secondary site. 

The primary site is the top two floors of a 5-story office building (15m height more or less) an the secondary is one of two open ""lots"" (which one is TBD by management). The ground distance from the secondary sites is a little more than 2km for the one closer and around 2.9km for the one furthest. 

The link will be used to transmit the video feed of 1 (or even possibly two) IP cameras and some kind of Ethernet-enabled environmental or weather sensor. I have checked the necessary b/w for the cameras and both 900Mhz and 5.8Ghz are more than adequate for even 4 of them, much more for 2. I have also verified that there is clear line-of-sight to both possible installation points and that the 60% Fresnel Zone clearance is more than covered. Bear in mind that this is my first long distance link (long with or without quotes) and I hate to admit that wireless physics is far from my strong suit.

The ultimate point of my question is that although I have read a lot about frequency choice the last few days, I continue to find some ambiguity (I know it is just me that finds it ambiguous). Most sources, like this one, agree that although the lower frequencies have less losses over a given distance (free-space-loss I learned it is called) they need larger antennae for the same ""strength"" of trasmission (is ""gain"" really the same as ""strength""?). 

So, for the given distance of 2-3km and given also that all typical requirements are met, which is preferable (or do I dare say ""better"") frequency? Should I choose 900Mhz with a relatively ""small"" antenna on the basis that 3km is not really ""long distance"" and that it will provide a link with less attenuation ergo less retransmits ergo higher overall speed? Or should I choose the 5.8Ghz option for the superior b/w (I am still not very sure about this, please correct me if wrong) on the basis that at this distance there is no real difference so why not take the ""better"" one?

On a side note, should I stay to the beaten path of true WiFi or should I consider proprietary bridging solutions like the ones from Ubiquiti? I have a lot of experience with their Access Points and am really satisfied, so I would not mind integrating one more of their products in my client. In any case, I am looking for an optimal solution, choice of vendor is of very little concern at this point.

Forgive my ignorance and the possible mistaken use of language. 

UPDATE:
I arranged to have a spectrum analyzer on loan for a couple of days. I will make sure that the 900Mhz band is reasonably clear and proceed down that way.

UPDATE 2:
I had the aforementioned equipment available to play with for a day and a half. The conclusive finding is that the 9Mhz band is almost ""empty"" in the area, as one suggested here, so that takes care for the frequency choice issue. 

Concerning the equipment now, I am going with Ubiquiti AirMax Yagi antennae and matching RM900 2x2 radios. Preliminary testing on my part and from the client's employees shows that performance exceeds expectations. 

On a side note, the chosen ""lot"" is the one that is 3km away. 
",dsljanus,https://serverfault.com/users/181235,"3km is approaching the limit of 5.8GHz equipment with reasonable size antennas and typical WiFi radios. With some of the best equipment you can only get ten times that distance with some caveats.

900MHz can easily go 3km, and much much farther. 900MHz is used for a wide variety of devices for this reason, so there's a good level of background noise. This might be a problem, especially if your neighbor has a 900MHz phone or similar (not a popular frequency for phones these days, but people hold on to technology for a long time too). I would avoid this frequency unless you're in the middle of nowhere (which you aren't). The 2.4GHz spectrum has worse problems with this, our microwave at work blasts 2.4GHz (I'm sure it violates FCC something or other, but nobody really cares as we have 5GHz WiFi). 
",Chris S,https://serverfault.com/users/33417,http://serverfault.com/questions/535403,TECHNOLOGY,serverfault.com,0.8888888888888888,0.4444444444444444,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.6666666666666666,0.0,1.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.8,0.3333333333333333,0.0,1.0,1.0,Radio link frequency selection for 2-3km distance (900MHz and 5.8GHz),"I have recently been contracted by a client of mine to facilitate the wireless communication of his ""home"" offices and a secondary site. 

The primary site is the top two floors of a 5-story office building (15m height more or less) an the secondary is one of two open ""lots"" (which one is TBD by management). The ground distance from the secondary sites is a little more than 2km for the one closer and around 2.9km for the one furthest. 

The link will be used to transmit the video feed of 1 (or even possibly two) IP cameras and some kind of Ethernet-enabled environmental or weather sensor. I have checked the necessary b/w for the cameras and both 900Mhz and 5.8Ghz are more than adequate for even 4 of them, much more for 2. I have also verified that there is clear line-of-sight to both possible installation points and that the 60% Fresnel Zone clearance is more than covered. Bear in mind that this is my first long distance link (long with or without quotes) and I hate to admit that wireless physics is far from my strong suit.

The ultimate point of my question is that although I have read a lot about frequency choice the last few days, I continue to find some ambiguity (I know it is just me that finds it ambiguous). Most sources, like this one, agree that although the lower frequencies have less losses over a given distance (free-space-loss I learned it is called) they need larger antennae for the same ""strength"" of trasmission (is ""gain"" really the same as ""strength""?). 

So, for the given distance of 2-3km and given also that all typical requirements are met, which is preferable (or do I dare say ""better"") frequency? Should I choose 900Mhz with a relatively ""small"" antenna on the basis that 3km is not really ""long distance"" and that it will provide a link with less attenuation ergo less retransmits ergo higher overall speed? Or should I choose the 5.8Ghz option for the superior b/w (I am still not very sure about this, please correct me if wrong) on the basis that at this distance there is no real difference so why not take the ""better"" one?

On a side note, should I stay to the beaten path of true WiFi or should I consider proprietary bridging solutions like the ones from Ubiquiti? I have a lot of experience with their Access Points and am really satisfied, so I would not mind integrating one more of their products in my client. In any case, I am looking for an optimal solution, choice of vendor is of very little concern at this point.

Forgive my ignorance and the possible mistaken use of language. 

UPDATE:
I arranged to have a spectrum analyzer on loan for a couple of days. I will make sure that the 900Mhz band is reasonably clear and proceed down that way.

UPDATE 2:
I had the aforementioned equipment available to play with for a day and a half. The conclusive finding is that the 9Mhz band is almost ""empty"" in the area, as one suggested here, so that takes care for the frequency choice issue. 

Concerning the equipment now, I am going with Ubiquiti AirMax Yagi antennae and matching RM900 2x2 radios. Preliminary testing on my part and from the client's employees shows that performance exceeds expectations. 

On a side note, the chosen ""lot"" is the one that is 3km away. 
","3km is approaching the limit of 5.8GHz equipment with reasonable size antennas and typical WiFi radios. With some of the best equipment you can only get ten times that distance with some caveats.

900MHz can easily go 3km, and much much farther. 900MHz is used for a wide variety of devices for this reason, so there's a good level of background noise. This might be a problem, especially if your neighbor has a 900MHz phone or similar (not a popular frequency for phones these days, but people hold on to technology for a long time too). I would avoid this frequency unless you're in the middle of nowhere (which you aren't). The 2.4GHz spectrum has worse problems with this, our microwave at work blasts 2.4GHz (I'm sure it violates FCC something or other, but nobody really cares as we have 5GHz WiFi). 
"
642,642,1015,"How to determine if a matrix is positive/negative definite, having complex eigenvalues?","I am trying to deal with an issue: I am trying to determine the nature of some points, that's why I need to check in Matlab if a matrix with complex elements is positive or negative definite. After performing some research, I came to the following two methods:


Calculate the eigenvalues and see if it is positive/negative;

    eig(matrix)


If the eigenvalues are positive => matrix is positive definite;
Else, if eigenvalues are negative => matrix is negative definite;
Use the following function:

    [R P] = chol(matrix)


If p is 0 => you have a positive definite matrix; otherwise, your matrix is NOT positive definite.


My problem is that I have two complex eigenvalues (and  my symmetric matrix has complex elements), therefore, method 1 doesn't help me to draw any conclusion. And the method 2, doesn't give me information whether the matrix is negative definite or indefinite, because it tests only if the matrix is positive definite or not, therefore, doesn't solve my problem.

Does any one have any idea how I can check if a matrix with complex eigenvalues is positive or negative definite with other methods than the mentioned ones? Thank you.

LATER EDIT:

My function is: 11.*x1 + 22.*x1.^2.*x2 + x2.^2 + 31.*x1.^2;

I have done the partial derivative with respect to x1, x2 and I have equalized all the obtained relations with 0. Therefore, I have obtained the following system:

62*x1 + 44*x1*x2 + 11 = 0

22*x1^2 + 2*x2 = 0

from here, I got x1 having the following possible values: 
{0.333, -0.1025 + 0.2403i, -0.1025 - 0.2403i} 
and x2 having the following values: 
{-1.22, 0.5197 + 0.5417i,  0.5197 - 0.5417i}

My Hessian looks something like:

( 62+44*x2                 44*x1)

( 44*x1                    2    )

After taking the 3 possible pairs of (x1,x2) I obtain three values for the Hessian matrix. For the first (x1,x2) pair everything is ok => I have a saddle, since I have 2 real eigenvalues of opposite signs. The difficulties comes with the others, because intuitively I would say that we cannot determine the nature of those points, but I came across to the following idea, while surfing the internet for finding an explanation:

-if A belongs to Mn(C) and 

1) Re(x_star * A * x) > 0 => A positive definite.

2) Re(x_star * A * x) &lt; 0 => A negative definite.

(according to http://mathworld.wolfram.com/PositiveDefiniteMatrix.html)

So, I am a bit confused :-?
",SunnyDay,https://math.stackexchange.com/users/67286,"Taken from here:


  A necessary and sufficient condition for a complex matrix $A$ to be positive definite is that the Hermitian part
  $$A_H=\frac{1}{2}(A+A^H)$$
  where $A^H$ denotes the conjugate transpose, be positive definite.


So, you can build a Hermitian part and then check if it is positive definite, e.g. by looking at its eigenvalues (which are real for hermitian matrices)
",dmytro,https://math.stackexchange.com/users/54020,http://math.stackexchange.com/questions/333727/how-to-determine-if-a-matrix-is-positive-negative-definite-having-complex-eigen,SCIENCE,math.stackexchange.com,0.7777777777777778,0.5555555555555556,0.0,0.5,1.0,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.6666666666666666,0.0,0.7777777777777778,0.7777777777777778,0.5555555555555556,0.8888888888888888,1.0,0.8,0.3333333333333333,0.6666666666666666,1.0,0.8888888888888888,How to make sure that a matrix with complex eigenvalues is positive / negative definite?,"I am trying to deal with an issue: I am trying to determine the nature of some points, that's why I need to check in Matlab if a matrix with complex elements is positive or negative definite. After performing some research, I came to the following two methods:


Calculate the eigenvalues and see if it is positive/negative;

    eig(matrix)


If the eigenvalues are positive => matrix is positive definite;
Else, if eigenvalues are negative => matrix is negative definite;
Use the following function:

    [R P] = chol(matrix)


If p is 0 => you have a positive definite matrix; otherwise, your matrix is NOT positive definite.


My problem is that I have two complex eigenvalues (and  my symmetric matrix has complex elements), therefore, method 1 doesn't help me to draw any conclusion. And the method 2, doesn't give me information whether the matrix is negative definite or indefinite, because it tests only if the matrix is positive definite or not, therefore, doesn't solve my problem.

Does any one have any idea how I can check if a matrix with complex eigenvalues is positive or negative definite with other methods than the mentioned ones? Thank you.

LATER EDIT:

My function is: 11.*x1 + 22.*x1.^2.*x2 + x2.^2 + 31.*x1.^2;

I have done the partial derivative with respect to x1, x2 and I have equalized all the obtained relations with 0. Therefore, I have obtained the following system:

62*x1 + 44*x1*x2 + 11 = 0

22*x1^2 + 2*x2 = 0

from here, I got x1 having the following possible values: 
{0.333, -0.1025 + 0.2403i, -0.1025 - 0.2403i} 
and x2 having the following values: 
{-1.22, 0.5197 + 0.5417i,  0.5197 - 0.5417i}

My Hessian looks something like:

( 62+44*x2                 44*x1)

( 44*x1                    2    )

After taking the 3 possible pairs of (x1,x2) I obtain three values for the Hessian matrix. For the first (x1,x2) pair everything is ok => I have a saddle, since I have 2 real eigenvalues of opposite signs. The difficulties comes with the others, because intuitively I would say that we cannot determine the nature of those points, but I came across to the following idea, while surfing the internet for finding an explanation:

-if A belongs to Mn(C) and 

1) Re(x_star * A * x) > 0 => A positive definite.

2) Re(x_star * A * x) &lt; 0 => A negative definite.

(according to http://mathworld.wolfram.com/PositiveDefiniteMatrix.html)

So, I am a bit confused :-?
","Taken from here:


  A necessary and sufficient condition for a complex matrix $A$ to be positive definite is that the Hermitian part
  $$A_H=\frac{1}{2}(A+A^H)$$
  where $A^H$ denotes the conjugate transpose, be positive definite.


So, you can build a Hermitian part and then check if it is positive definite, e.g. by looking at its eigenvalues (which are real for hermitian matrices)
"
4440,4440,7049,"Superlatives with ""the""","What is the rule regarding using the with superlatives? For example:


  
  John is the fastest among his friends.
  John is fastest among his friends.
  


Both appear to be correct.   I have seen both formats in a variety of places.
",BVDL,https://english.stackexchange.com/users/10006,"I don't know of a study that's looked at this formally, so I'm going ""off the top of my head"". It seems to me that the difference is that if you say ""David is fastest"", you are implying that David is the fastest among the small group of people that you have seen, but implying that it is likely you would find somebody faster in the wider world. If you say ""David is the fastest"", you are slightly more implying ""He is the fastest among this group and also is not likely to be beaten easily by other people"".

Omitting ""the"" seems slightly more informal as well, to my UK ear.
",Neil Coffey,https://english.stackexchange.com/users/4941,http://english.stackexchange.com/questions/30272/superlatives-with-the,CULTURE,english.stackexchange.com,1.0,0.5555555555555556,0.0,1.0,1.0,0.3333333333333333,0.6666666666666666,0.8888888888888888,0.0,0.0,0.3333333333333333,0.0,0.3333333333333333,0.0,0.3333333333333333,0.0,0.0,0.0,0.6666666666666666,0.0,1.0,0.8888888888888888,0.7777777777777778,1.0,1.0,0.9333333333333332,0.3333333333333333,0.0,0.3333333333333333,0.8888888888888888,"Top level with ""the""","What is the rule regarding using the with superlatives? For example:


  
  John is the fastest among his friends.
  John is fastest among his friends.
  


Both appear to be correct.   I have seen both formats in a variety of places.
","I don't know if there's any formal research, so I'm going crazy. In my opinion, the difference is that if you say ""David is the fastest"", you are implying that David is the fastest in a small group of people you have met, but it means that you are likely to find faster people in the wider world. If you say ""David is the fastest"", you will slightly hint that ""he is the fastest in this group and is unlikely to be easily defeated by others""."
5571,5571,8848,IPython Qt Console doesn't have a title in GNOME app switcher,"  

When I use the app switcher in GNOME 3.16, the IPython Qt Console (version 3.1.0) doesn't have a title under its icon (see image, and compare with Chromium). I also noticed that the icon doesn't have a title in the GNOME dock, nor is it present in the GNOME bar at the top.

I thought that maybe the title would be set in the .desktop file, but then I had a look at my /usr/share/applications/ipython-qtconsole.desktop and it doesn't look any different from other applications (i.e. it has a Name label set to an IPython value).

Is there a way to add a title manually?

I'm on Arch Linux using GNOME 3.16.1.
",Stefan van den Akker,https://unix.stackexchange.com/users/73808,"This has never happened to me but this is more a ""menu"" issue than an application one.

As a starting point I suggest you navigate to the file 

~/.config/menus/gnome-application.menu


See if its listed there and if there are any issues with the listing.

There is also an app called ""menulibre"" which allows you to add/modify icon names. It available in the AUR.
",user112694,https://unix.stackexchange.com/users/112694,http://unix.stackexchange.com/questions/199801/ipython-qt-console-doesnt-have-a-title-in-gnome-app-switcher,TECHNOLOGY,unix.stackexchange.com,1.0,0.3333333333333333,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.6666666666666666,1.0,IPython QT console has no title in Gnome app switcher,"  

When I use the app switcher in GNOME 3.16, the IPython Qt Console (version 3.1.0) doesn't have a title under its icon (see image, and compare with Chromium). I also noticed that the icon doesn't have a title in the GNOME dock, nor is it present in the GNOME bar at the top.

I thought that maybe the title would be set in the .desktop file, but then I had a look at my /usr/share/applications/ipython-qtconsole.desktop and it doesn't look any different from other applications (i.e. it has a Name label set to an IPython value).

Is there a way to add a title manually?

I'm on Arch Linux using GNOME 3.16.1.
","This has never happened to me but this is more a ""menu"" issue than an application one.

As a starting point I suggest you navigate to the file 

~/.config/menus/gnome-application.menu


See if its listed there and if there are any issues with the listing.

There is also an app called ""menulibre"" which allows you to add/modify icon names. It available in the AUR.
"
1216,1216,1910,Can I have an Animal Companions without being a druid or ranger?,"I'm looking for a way to have an animal companion with classes other than druid or ranger, for example a paladin that fights with a trained hawk. I'm all for multiclassing if need be, but I'm looking for other ways as well, through feats if necessary. I'm not really worried about min/max stats or optimized builds.
",DoomWolf,https://rpg.stackexchange.com/users/9549,"Many, many classes have an archetype that grants an animal companion or other special access to them.  However, failing that, any character of at least level 4 may gain access to an animal companion via the Animal Ally feat, though most characters may have to wait to level 5 (the next feat level in pathfinder) to actually take the feat.  

In the specific case of a paladin, you must delay access to the Divine Bond ability by one level (probably by dipping a level of cleric or some such) in order to be eligible for the feat.  You could also give up the mount from that ability for the weapon option, but if you choose the mount option your hawk (or whatever) has an effective druid level of (your total level including your paladin levels)+(your paladin levels again)-3, which is pretty cool.  At level 6 this is the difference between an EDL 8 hawk and an EDL 3 hawk, which is a sufficient difference to necessarily alter how you use it in game.

Consider also that not all animals you use in combat or otherwise need to be animal companions.  Animal companions are special super-powerful bonded animals that you pretty much control directly.  You can get a loyal, useful, hunting hawk by training one with the Handle Animal skill.  If you want a normal hawk to use for rabbit hunts and message delivery, this is probably more appropriate.  If you want your hawk to scout out the enemy troop movements and report back, the animal companion version is a better bet.
",the dark wanderer,https://rpg.stackexchange.com/users/14848,http://rpg.stackexchange.com/questions/55125/can-i-have-an-animal-companions-without-being-a-druid-or-ranger,CULTURE,rpg.stackexchange.com,0.8888888888888888,1.0,0.0,1.0,1.0,1.0,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.8888888888888888,0.8888888888888888,0.8333333333333334,1.0,1.0,1.0,0.3333333333333333,0.0,0.6666666666666666,1.0,"If I'm not a druid or a Ranger, can I have animal companions?","I'm looking for a way for an animal companion to fight with other classes, not Druids or Rangers, such as a paladin fighting with a trained eagle. I fully support multiclassification if needed, but I'm also looking for other ways, if needed, through expertise. I really don't worry about minimum / maximum statistics or optimizing builds.","Many, many classes have an archetype that grants an animal companion or other special access to them.  However, failing that, any character of at least level 4 may gain access to an animal companion via the Animal Ally feat, though most characters may have to wait to level 5 (the next feat level in pathfinder) to actually take the feat.  

In the specific case of a paladin, you must delay access to the Divine Bond ability by one level (probably by dipping a level of cleric or some such) in order to be eligible for the feat.  You could also give up the mount from that ability for the weapon option, but if you choose the mount option your hawk (or whatever) has an effective druid level of (your total level including your paladin levels)+(your paladin levels again)-3, which is pretty cool.  At level 6 this is the difference between an EDL 8 hawk and an EDL 3 hawk, which is a sufficient difference to necessarily alter how you use it in game.

Consider also that not all animals you use in combat or otherwise need to be animal companions.  Animal companions are special super-powerful bonded animals that you pretty much control directly.  You can get a loyal, useful, hunting hawk by training one with the Handle Animal skill.  If you want a normal hawk to use for rabbit hunts and message delivery, this is probably more appropriate.  If you want your hawk to scout out the enemy troop movements and report back, the animal companion version is a better bet.
"
5062,5062,8051,Visual Studio keeps changing resx files,"I'm working on a VB.Net project and using SVN. I noticed that every time I open my main form, Visual studio slightly modifies my .resx file, which means that I keep having to re-commit it, which is quite annoying.

Has anybody experienced such problems? A diff file demonstrating the problem can be seen at http://synchronicity.svn.sourceforge.net/viewvc/synchronicity/trunk/Create%20Synchronicity/MainForm.resx?r1=272&amp;r2=359&amp;pathrev=359

Thanks,
CFP.
",Clément,https://stackoverflow.com/users/695591,"Bit late, but this sounds like a problem I raised with Microsoft around Image Lists:https://connect.microsoft.com/VisualStudio/feedback/details/428868/png-files-corrupted-in-an-imagelist-when-opening-and-closing-a-form
",LaughingJohn,https://stackoverflow.com/users/3295396,http://stackoverflow.com/questions/2682682/visual-studio-keeps-changing-resx-files,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.5555555555555556,0.0,1.0,0.6666666666666666,1.0,0.4444444444444444,0.4444444444444444,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.3333333333333333,0.0,0.6666666666666666,0.7777777777777778,0.5,0.7777777777777778,0.8333333333333334,0.6,0.5,0.0,0.5,0.8888888888888888,Visual studio constantly changes resx files,"I'm working on a VB.Net project and using SVN. I noticed that every time I open my main form, Visual studio slightly modifies my .resx file, which means that I keep having to re-commit it, which is quite annoying.

Has anybody experienced such problems? A diff file demonstrating the problem can be seen at http://synchronicity.svn.sourceforge.net/viewvc/synchronicity/trunk/Create%20Synchronicity/MainForm.resx?r1=272&amp;r2=359&amp;pathrev=359

Thanks,
CFP.
","It's a little late, but it sounds like a question that Microsoft and I have asked about image list: https://connect.microsoft.com/visualstudio/feedback/details/428868/png-files-corrupted-in-an-imagelist-when-opening-and-closing-a-form"
1313,1313,2072,R biglm predict searching for dependent variable,"I'm using the biglm package to run a regression on a data set.  The regression runs fine using the following code: 

chunkStart &lt;- seq(1,150000000,1000000)
chunkEnd &lt;- seq(1000000,151000000,1000000)
ff &lt;- price ~ factor(Var1) + factor(Var2)

#for(i in 1:length(chunkStart)){
for(i in 1:5){

startRow &lt;- chunkStart[i]
endRow &lt;- chunkEnd[i]    
curchunk &lt;- data.frame( price=x[startRow:endRow,1]
     ,Var1=factor( x[startRow:endRow,6], levels=1:3), Var2= factor( x[startRow:endRow,7], levels=1:3 ) )

    if(i == 1){
    a &lt;- biglm(ff,curchunk )
    }
    if(i != 1){
    a &lt;- update(a,curchunk )
    }
rm(curchunk )
gc()
print(paste(i, "" | "",startRow ,"" | "",endRow ,"" | "", sep=""""))
flush.console()
}

&gt; summary(a)
Large data regression model: biglm(ff, curchunk)
Sample size =  5000000 
                 Coef    (95%     CI)    SE p
(Intercept)    0.0457  0.0454  0.0461 2e-04 0
factor(Var1)2  0.0189  0.0184  0.0194 2e-04 0
factor(Var1)3  0.0148  0.0142  0.0155 3e-04 0
factor(Var2)2 -0.0331 -0.0335 -0.0326 2e-04 0
factor(Var2)3 -0.0417 -0.0426 -0.0408 4e-04 0


The problems come when I try to predict using the biglm object, 'a'. 

&gt; df1 &lt;- data.frame(y[1:1000,])
&gt; pred1 &lt;- predict(a, df1)
Error in eval(expr, envir, enclos) : object 'price' not found


Why is the predict function looking for the price/ dependent variable?  Any suggestions?

EDIT: 

&gt; head(df1)
  Var1 Var2
1    3    3
2    3    1
3    3    2
4    2    1
5    2    2
6    1    1
&gt; str(df1)
'data.frame':   1000 obs. of  2 variables:
 $ Var1: Factor w/ 3 levels ""1"",""2"",""3"": 3 3 3 2 2 1 2 1 2 1 ...
 $ Var2: Factor w/ 3 levels ""1"",""2"",""3"": 3 1 2 1 2 1 1 1 2 1 ...
&gt; pred1 &lt;- predict(a, df1)
Error in eval(expr, envir, enclos) : object 'price' not found

",screechOwl,https://stackoverflow.com/users/914308,"The reason it is looking for the dependent variable is that the predict method uses a call to model.frame from the stats package, and that function requires all the variables to be present in the new data. This is indicated on the model.frame help page without explanation for the motivation behind it. 

All you actually need to do about this is create a variable in your new data that has the same name as the dependent variable, then fill it with zeroes (or any non-missing value). So it should work if you run this:

df1$price &lt;- 0
pred1 &lt;- predict(a, df1)

",Fojtasek,https://stackoverflow.com/users/205054,http://stackoverflow.com/questions/10507369/r-biglm-predict-searching-for-dependent-variable,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.3333333333333333,0.0,1.0,1.0,1.0,0.5555555555555556,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.3333333333333333,0.3333333333333333,1.0,1.0,R-biglm prediction search of dependent variable,"I'm using the biglm package to run a regression on a data set.  The regression runs fine using the following code: 

chunkStart &lt;- seq(1,150000000,1000000)
chunkEnd &lt;- seq(1000000,151000000,1000000)
ff &lt;- price ~ factor(Var1) + factor(Var2)

#for(i in 1:length(chunkStart)){
for(i in 1:5){

startRow &lt;- chunkStart[i]
endRow &lt;- chunkEnd[i]    
curchunk &lt;- data.frame( price=x[startRow:endRow,1]
     ,Var1=factor( x[startRow:endRow,6], levels=1:3), Var2= factor( x[startRow:endRow,7], levels=1:3 ) )

    if(i == 1){
    a &lt;- biglm(ff,curchunk )
    }
    if(i != 1){
    a &lt;- update(a,curchunk )
    }
rm(curchunk )
gc()
print(paste(i, "" | "",startRow ,"" | "",endRow ,"" | "", sep=""""))
flush.console()
}

&gt; summary(a)
Large data regression model: biglm(ff, curchunk)
Sample size =  5000000 
                 Coef    (95%     CI)    SE p
(Intercept)    0.0457  0.0454  0.0461 2e-04 0
factor(Var1)2  0.0189  0.0184  0.0194 2e-04 0
factor(Var1)3  0.0148  0.0142  0.0155 3e-04 0
factor(Var2)2 -0.0331 -0.0335 -0.0326 2e-04 0
factor(Var2)3 -0.0417 -0.0426 -0.0408 4e-04 0


The problems come when I try to predict using the biglm object, 'a'. 

&gt; df1 &lt;- data.frame(y[1:1000,])
&gt; pred1 &lt;- predict(a, df1)
Error in eval(expr, envir, enclos) : object 'price' not found


Why is the predict function looking for the price/ dependent variable?  Any suggestions?

EDIT: 

&gt; head(df1)
  Var1 Var2
1    3    3
2    3    1
3    3    2
4    2    1
5    2    2
6    1    1
&gt; str(df1)
'data.frame':   1000 obs. of  2 variables:
 $ Var1: Factor w/ 3 levels ""1"",""2"",""3"": 3 3 3 2 2 1 2 1 2 1 ...
 $ Var2: Factor w/ 3 levels ""1"",""2"",""3"": 3 1 2 1 2 1 1 1 2 1 ...
&gt; pred1 &lt;- predict(a, df1)
Error in eval(expr, envir, enclos) : object 'price' not found

","The reason it is looking for the dependent variable is that the predict method uses a call to model.frame from the stats package, and that function requires all the variables to be present in the new data. This is indicated on the model.frame help page without explanation for the motivation behind it. 

All you actually need to do about this is create a variable in your new data that has the same name as the dependent variable, then fill it with zeroes (or any non-missing value). So it should work if you run this:

df1$price &lt;- 0
pred1 &lt;- predict(a, df1)

"
1964,1964,3128,Why did Voldemort assume that no-one knew about Room of Hidden Things?,"Voldemort hid one of his Horcruxes inside Hogwarts. It seemed to be relying on security through obscurity as far as protecting it. But as we know, it ended up not being so secure because it wasn't so obscure - Harry Potter knew about the Room of Hidden Things.

My question is, the way Rowling describes this hints at the fact that Riddle had an assumption that very few people would ever stumble upon that room. *WHY???



First, let's show Harry's theory on what Voldemort was thinking, how and why:

Here's Harry understanding Voldemort's thinking in HP7 once he figured out where the Diadem was (bold emphasis mine):


  Tom Riddle, who confided in no one and operated alone, might have been arrogant
  enough to assume that he, and only he, had penetrated the deepest mysteries of
  Hogwarts Castle. Of course, Dumbledore and Flitwick, those model pupils, had never
  set foot in that particular place, but he, Harry, had strayed off the beaten track in his
  time at school – here at least was a secret area he and Voldemort knew, that
  Dumbledore had never discovered –


...and later on, with Harry explains the location to Ron/Hermione:


  “He hid it exactly where I had my old Potions book, where everyone’s been hiding stuff for centuries. He thought he was the only one to find it. Come on.”
  
  “And he never realized anyone could get in?” said Ron, his voice echoing in the silence.
  “He thought he was the only one,” said Harry.


.



Yet, from available evidence, that seems to be a completely wrong assumption, even at Voldemort's time. 

Let's examine that last quote again, with emphasis on other info available:


  “He hid it exactly where I had my old Potions book, where everyone’s been hiding stuff for centuries.” ...
  
  ...
  
  “And he never realized anyone could get in?” said Ron, his voice echoing in the silence.
  “He thought he was the only one,” said Harry. “Too bad for him I’ve had to hide stuff in
  my time... this way,” he added. “I think it’s down here... “ 
  
  They sped off up adjacent aisles; Harry could hear the others’ footsteps echoing through the towering piles of junk, of bottles, hats, crates, chairs, books, weapons, broomsticks, bats...


.

OK, so if there's a truckload (or train-load, by the description) of stuff in that room, isn't the only reasonable conclusion: ""the room is a fairly popular destination with plenty of people who've found their way there in the past, and therefore, likely, plenty who will in the future""? 

Doesn't matter what your arrogance level is, the evidence seems to point to only one conclusion - it's quite fine as a place to temporarily bury your dirt so teachers won't tag you for your misdeeds, but this is NOT the place to hide something that you want permanently safe! 

So why did Voldemort make such a moronic mistake?
",DVK-on-Ahch-To,https://scifi.stackexchange.com/users/976,"I think Voldemort's arrogance has to be included in the equation. Voldemort truly believed that he was the only person to discover the Room of Hidden Things/RoR/CaGR, whether that seems logical or not. After escaping Gringotts and jumping off the dragon into the lake, Harry finds himself inside Voldemort's head, able to read Voldemort's thoughts about the Horcruxes:


  [Voldemort] As for the school: he alone knew where in Hogwarts he had stowed the Horcrux, because he alone had plumbed the deepest secrets of that place ...
  And Hogwarts ... but he knew that his Horcrux there was safe, it would be impossible for Potter to enter Hogsmeade without detection, let alone the school. Nevertheless, it would be prudent to alert Snape to the fact that the boy might try to re-enter the castle ...
  Deathly Hallows - Page 444 - British Hardcover
  Harry says, ""He thinks the Hogwarts one is safest, because Snape’s there, because it’ll be so hard not to be seen getting in, I think he’ll check that one last, but he could
  still be there within hours –'


I also think Voldemort was emotionally compelled to hide at least one Horcrux in Hogwarts. Hogwarts -- not unlike for Harry -- was the only place Tom Riddle/Voldemort ever considered a home. Given his propensity for attachment to things (Hogwarts, Founders' items, the snake Nagini) rather than people, it makes sense that 1) he would want to hide a Horcrux in the place that he considered home and 2) due to his emotional attachment to Hogwarts, he could have very well thought that the castle itself claimed him as its ultimate master. If so, then of course no one else would have discovered the Room of Hidden Things, because Hogwarts belonged to Voldemort (in his mind) and Voldemort alone. This represents a twisted sense of entitlement, the inability to see others as equals (seeing people as unskilled in achieving the high level of magical power that he himself had), and unable to imagine that any wizard other than himself could possibly discover or work out the secrets contained within the castle. So, to answer the question, the reason Voldemort made such a moronic mistake in leaving the diadem Horcrux essentially in plain view is because his thinking is distorted and skewed -- for he recognises no other as an intellectual equal or someone to learn from (he already believes he knows it all -- and is full of logic and thinking errors.) Once again, Voldemort underestimates that which he does not value, and there is so much that he does not value that his perception of the world is myopic, imbalanced, and not reflective of reality.  
",Slytherincess,https://scifi.stackexchange.com/users/3500,http://scifi.stackexchange.com/questions/8734/why-did-voldemort-assume-that-no-one-knew-about-room-of-hidden-things,LIFE_ARTS,scifi.stackexchange.com,1.0,1.0,0.5,1.0,1.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.8,0.0,0.0,1.0,1.0,Why does Voldemort think no one knows what's hidden?,"Voldemort hid one of his Horcruxes inside Hogwarts. It seemed to be relying on security through obscurity as far as protecting it. But as we know, it ended up not being so secure because it wasn't so obscure - Harry Potter knew about the Room of Hidden Things.

My question is, the way Rowling describes this hints at the fact that Riddle had an assumption that very few people would ever stumble upon that room. *WHY???



First, let's show Harry's theory on what Voldemort was thinking, how and why:

Here's Harry understanding Voldemort's thinking in HP7 once he figured out where the Diadem was (bold emphasis mine):


  Tom Riddle, who confided in no one and operated alone, might have been arrogant
  enough to assume that he, and only he, had penetrated the deepest mysteries of
  Hogwarts Castle. Of course, Dumbledore and Flitwick, those model pupils, had never
  set foot in that particular place, but he, Harry, had strayed off the beaten track in his
  time at school – here at least was a secret area he and Voldemort knew, that
  Dumbledore had never discovered –


...and later on, with Harry explains the location to Ron/Hermione:


  “He hid it exactly where I had my old Potions book, where everyone’s been hiding stuff for centuries. He thought he was the only one to find it. Come on.”
  
  “And he never realized anyone could get in?” said Ron, his voice echoing in the silence.
  “He thought he was the only one,” said Harry.


.



Yet, from available evidence, that seems to be a completely wrong assumption, even at Voldemort's time. 

Let's examine that last quote again, with emphasis on other info available:


  “He hid it exactly where I had my old Potions book, where everyone’s been hiding stuff for centuries.” ...
  
  ...
  
  “And he never realized anyone could get in?” said Ron, his voice echoing in the silence.
  “He thought he was the only one,” said Harry. “Too bad for him I’ve had to hide stuff in
  my time... this way,” he added. “I think it’s down here... “ 
  
  They sped off up adjacent aisles; Harry could hear the others’ footsteps echoing through the towering piles of junk, of bottles, hats, crates, chairs, books, weapons, broomsticks, bats...


.

OK, so if there's a truckload (or train-load, by the description) of stuff in that room, isn't the only reasonable conclusion: ""the room is a fairly popular destination with plenty of people who've found their way there in the past, and therefore, likely, plenty who will in the future""? 

Doesn't matter what your arrogance level is, the evidence seems to point to only one conclusion - it's quite fine as a place to temporarily bury your dirt so teachers won't tag you for your misdeeds, but this is NOT the place to hide something that you want permanently safe! 

So why did Voldemort make such a moronic mistake?
","I think Voldemort's arrogance has to be included in the equation. Voldemort truly believed that he was the only person to discover the Room of Hidden Things/RoR/CaGR, whether that seems logical or not. After escaping Gringotts and jumping off the dragon into the lake, Harry finds himself inside Voldemort's head, able to read Voldemort's thoughts about the Horcruxes:


  [Voldemort] As for the school: he alone knew where in Hogwarts he had stowed the Horcrux, because he alone had plumbed the deepest secrets of that place ...
  And Hogwarts ... but he knew that his Horcrux there was safe, it would be impossible for Potter to enter Hogsmeade without detection, let alone the school. Nevertheless, it would be prudent to alert Snape to the fact that the boy might try to re-enter the castle ...
  Deathly Hallows - Page 444 - British Hardcover
  Harry says, ""He thinks the Hogwarts one is safest, because Snape’s there, because it’ll be so hard not to be seen getting in, I think he’ll check that one last, but he could
  still be there within hours –'


I also think Voldemort was emotionally compelled to hide at least one Horcrux in Hogwarts. Hogwarts -- not unlike for Harry -- was the only place Tom Riddle/Voldemort ever considered a home. Given his propensity for attachment to things (Hogwarts, Founders' items, the snake Nagini) rather than people, it makes sense that 1) he would want to hide a Horcrux in the place that he considered home and 2) due to his emotional attachment to Hogwarts, he could have very well thought that the castle itself claimed him as its ultimate master. If so, then of course no one else would have discovered the Room of Hidden Things, because Hogwarts belonged to Voldemort (in his mind) and Voldemort alone. This represents a twisted sense of entitlement, the inability to see others as equals (seeing people as unskilled in achieving the high level of magical power that he himself had), and unable to imagine that any wizard other than himself could possibly discover or work out the secrets contained within the castle. So, to answer the question, the reason Voldemort made such a moronic mistake in leaving the diadem Horcrux essentially in plain view is because his thinking is distorted and skewed -- for he recognises no other as an intellectual equal or someone to learn from (he already believes he knows it all -- and is full of logic and thinking errors.) Once again, Voldemort underestimates that which he does not value, and there is so much that he does not value that his perception of the world is myopic, imbalanced, and not reflective of reality.  
"
799,799,1268,How do I set serial special characters?,"In my ongoing quest to interface with some legacy equipment, I've discovered that the vendor supplied software sets the special characters to:

00 00 00 00 11 13 


But the SerialPort class of .NET set them to:

1A 00 00 1A 11 13 


I suppose that I have two questions:


What do these bytes mean?
How can I tell SerialPort to use a specific set of special characters?


The latter is all I really care about, but I suspect the former is going to be useful to know.



Update: The following doesn't work:

byte[] specialchars = {
    0x00,
    0x00,
    0x00,
    0x00,
    0x11,
    0x13
};

this.port.NewLine = System.Text.Encoding.ASCII.GetString(specialchars);




Update 2: As requested, here are Portmon logs for the vendor supplied app (filtered to remove the many thousands of IOCTL_SERIAL_GET_COMMSTATUS entries) and for my attempt to match even the first exchange.
",Tom Wright,https://stackoverflow.com/users/50151,"NewLine is not what you are looking for. It's the plain old 'new line' sequence, e.g. CR LF or LF alone.

The special characters are handled like this:


EOF — set to 0x1a, you cannot change it in .NET
ERR — set by SerialPort.ParityReplace
BRK — don't know
EVT — set to 0x1a, you cannot change it in .NET
XON — set to 0x11, you cannot change it in .NET, and it doesn't even usually make sesn
XOFF — set to 0x13, you cannot change it in .NET, and it doesn't even usually make sesn


It may be helpful for you to study the Win32 DCB structure as well. It's used by .NET internally to set the state of the serial port.
",Ondrej Tucny,https://stackoverflow.com/users/245183,http://stackoverflow.com/questions/5620469/how-do-i-set-serial-special-characters,STACKOVERFLOW,stackoverflow.com,1.0,0.4444444444444444,0.0,1.0,0.3333333333333333,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.6666666666666666,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,0.0,0.8888888888888888,0.8888888888888888,0.5555555555555556,0.8888888888888888,1.0,0.8,1.0,0.0,0.3333333333333333,0.7777777777777778,How to set sequence special characters?,"In my ongoing quest to interface with some legacy equipment, I've discovered that the vendor supplied software sets the special characters to:

00 00 00 00 11 13 


But the SerialPort class of .NET set them to:

1A 00 00 1A 11 13 


I suppose that I have two questions:


What do these bytes mean?
How can I tell SerialPort to use a specific set of special characters?


The latter is all I really care about, but I suspect the former is going to be useful to know.



Update: The following doesn't work:

byte[] specialchars = {
    0x00,
    0x00,
    0x00,
    0x00,
    0x11,
    0x13
};

this.port.NewLine = System.Text.Encoding.ASCII.GetString(specialchars);




Update 2: As requested, here are Portmon logs for the vendor supplied app (filtered to remove the many thousands of IOCTL_SERIAL_GET_COMMSTATUS entries) and for my attempt to match even the first exchange.
","NewLine is not what you are looking for. It's the plain old 'new line' sequence, e.g. CR LF or LF alone.

The special characters are handled like this:


EOF — set to 0x1a, you cannot change it in .NET
ERR — set by SerialPort.ParityReplace
BRK — don't know
EVT — set to 0x1a, you cannot change it in .NET
XON — set to 0x11, you cannot change it in .NET, and it doesn't even usually make sesn
XOFF — set to 0x13, you cannot change it in .NET, and it doesn't even usually make sesn


It may be helpful for you to study the Win32 DCB structure as well. It's used by .NET internally to set the state of the serial port.
"
3920,3920,6250,How do I set serial special characters?,"In my ongoing quest to interface with some legacy equipment, I've discovered that the vendor supplied software sets the special characters to:

00 00 00 00 11 13 


But the SerialPort class of .NET set them to:

1A 00 00 1A 11 13 


I suppose that I have two questions:


What do these bytes mean?
How can I tell SerialPort to use a specific set of special characters?


The latter is all I really care about, but I suspect the former is going to be useful to know.



Update: The following doesn't work:

byte[] specialchars = {
    0x00,
    0x00,
    0x00,
    0x00,
    0x11,
    0x13
};

this.port.NewLine = System.Text.Encoding.ASCII.GetString(specialchars);




Update 2: As requested, here are Portmon logs for the vendor supplied app (filtered to remove the many thousands of IOCTL_SERIAL_GET_COMMSTATUS entries) and for my attempt to match even the first exchange.
",Tom Wright,https://stackoverflow.com/users/50151,"You can add an extenstion to the serialPort in c# : 

http://social.msdn.microsoft.com/Forums/vstudio/en-us/89b88e89-5814-4819-8b50-7caa3faf5f54/xonxoff-values-in-net20-serialport-class?forum=csharpgeneral

for the other fields you can change :


  dcbType.GetField(""XonChar""); // ""XonChar"", ""XoffChar"", ""ErrorChar"", ""EofChar"", ""EvtChar""


Code : 

            using System;
            using System.ComponentModel;
            using System.IO.Ports;
            using System.Reflection;
            using System.Runtime.InteropServices;
            using System.Security;
            using System.Security.Permissions;
            using Microsoft.Win32.SafeHandles;

            class Program
            {
                static void Main(string[] args)
                {
                    using (var port = new SerialPort(""COM1""))
                    {
                        port.Open();
                        port.SetXonXoffChars(0x12, 0x14);
                    }
                }
            }

            internal static class SerialPortExtensions
            {
                [SecurityPermission(SecurityAction.LinkDemand, Flags = SecurityPermissionFlag.UnmanagedCode)]
                public static void SetXonXoffChars(this SerialPort port, byte xon, byte xoff)
                {
                    if (port == null)
                        throw new NullReferenceException();
                    if (port.BaseStream == null)
                        throw new InvalidOperationException(""Cannot change X chars until after the port has been opened."");

                    try
                    {
                        // Get the base stream and its type which is System.IO.Ports.SerialStream
                        object baseStream = port.BaseStream;
                        Type baseStreamType = baseStream.GetType();

                        // Get the Win32 file handle for the port
                        SafeFileHandle portFileHandle = (SafeFileHandle)baseStreamType.GetField(""_handle"", BindingFlags.NonPublic | BindingFlags.Instance).GetValue(baseStream);

                        // Get the value of the private DCB field (a value type)
                        FieldInfo dcbFieldInfo = baseStreamType.GetField(""dcb"", BindingFlags.NonPublic | BindingFlags.Instance);
                        object dcbValue = dcbFieldInfo.GetValue(baseStream);

                        // The type of dcb is Microsoft.Win32.UnsafeNativeMethods.DCB which is an internal type. We can only access it through reflection.
                        Type dcbType = dcbValue.GetType();
                        dcbType.GetField(""XonChar"").SetValue(dcbValue, xon);
                        dcbType.GetField(""XoffChar"").SetValue(dcbValue, xoff);

                        // We need to call SetCommState but because dcbValue is a private type, we don't have enough
                        //  information to create a p/Invoke declaration for it. We have to do the marshalling manually.

                        // Create unmanaged memory to copy DCB into
                        IntPtr hGlobal = Marshal.AllocHGlobal(Marshal.SizeOf(dcbValue));
                        try
                        {
                            // Copy their DCB value to unmanaged memory
                            Marshal.StructureToPtr(dcbValue, hGlobal, false);

                            // Call SetCommState
                            if (!SetCommState(portFileHandle, hGlobal))
                                throw new Win32Exception(Marshal.GetLastWin32Error());

                            // Update the BaseStream.dcb field if SetCommState succeeded
                            dcbFieldInfo.SetValue(baseStream, dcbValue);
                        }
                        finally
                        {
                            if (hGlobal != IntPtr.Zero)
                                Marshal.FreeHGlobal(hGlobal);
                        }
                    }
                    catch (SecurityException) { throw; }
                    catch (OutOfMemoryException) { throw; }
                    catch (Win32Exception) { throw; }
                    catch (Exception ex)
                    {
                        throw new ApplicationException(""SetXonXoffChars has failed due to incorrect assumptions about System.IO.Ports.SerialStream which is an internal type."", ex);
                    }
                }

                [DllImport(""kernel32.dll"", CharSet = CharSet.Auto, SetLastError = true)]
                private static extern bool SetCommState(SafeFileHandle hFile, IntPtr lpDCB);
            }

",Davut Engin,https://stackoverflow.com/users/2991270,http://stackoverflow.com/questions/5620469/how-do-i-set-serial-special-characters,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.4444444444444444,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.6666666666666666,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.7777777777777778,0.8888888888888888,0.5555555555555556,1.0,0.8888888888888888,0.8,0.6666666666666666,0.0,0.3333333333333333,0.8888888888888888,How to set sequence special characters?,"In my ongoing quest to interface with some legacy equipment, I've discovered that the vendor supplied software sets the special characters to:

00 00 00 00 11 13 


But the SerialPort class of .NET set them to:

1A 00 00 1A 11 13 


I suppose that I have two questions:


What do these bytes mean?
How can I tell SerialPort to use a specific set of special characters?


The latter is all I really care about, but I suspect the former is going to be useful to know.



Update: The following doesn't work:

byte[] specialchars = {
    0x00,
    0x00,
    0x00,
    0x00,
    0x11,
    0x13
};

this.port.NewLine = System.Text.Encoding.ASCII.GetString(specialchars);




Update 2: As requested, here are Portmon logs for the vendor supplied app (filtered to remove the many thousands of IOCTL_SERIAL_GET_COMMSTATUS entries) and for my attempt to match even the first exchange.
","You can add an extenstion to the serialPort in c# : 

http://social.msdn.microsoft.com/Forums/vstudio/en-us/89b88e89-5814-4819-8b50-7caa3faf5f54/xonxoff-values-in-net20-serialport-class?forum=csharpgeneral

for the other fields you can change :


  dcbType.GetField(""XonChar""); // ""XonChar"", ""XoffChar"", ""ErrorChar"", ""EofChar"", ""EvtChar""


Code : 

            using System;
            using System.ComponentModel;
            using System.IO.Ports;
            using System.Reflection;
            using System.Runtime.InteropServices;
            using System.Security;
            using System.Security.Permissions;
            using Microsoft.Win32.SafeHandles;

            class Program
            {
                static void Main(string[] args)
                {
                    using (var port = new SerialPort(""COM1""))
                    {
                        port.Open();
                        port.SetXonXoffChars(0x12, 0x14);
                    }
                }
            }

            internal static class SerialPortExtensions
            {
                [SecurityPermission(SecurityAction.LinkDemand, Flags = SecurityPermissionFlag.UnmanagedCode)]
                public static void SetXonXoffChars(this SerialPort port, byte xon, byte xoff)
                {
                    if (port == null)
                        throw new NullReferenceException();
                    if (port.BaseStream == null)
                        throw new InvalidOperationException(""Cannot change X chars until after the port has been opened."");

                    try
                    {
                        // Get the base stream and its type which is System.IO.Ports.SerialStream
                        object baseStream = port.BaseStream;
                        Type baseStreamType = baseStream.GetType();

                        // Get the Win32 file handle for the port
                        SafeFileHandle portFileHandle = (SafeFileHandle)baseStreamType.GetField(""_handle"", BindingFlags.NonPublic | BindingFlags.Instance).GetValue(baseStream);

                        // Get the value of the private DCB field (a value type)
                        FieldInfo dcbFieldInfo = baseStreamType.GetField(""dcb"", BindingFlags.NonPublic | BindingFlags.Instance);
                        object dcbValue = dcbFieldInfo.GetValue(baseStream);

                        // The type of dcb is Microsoft.Win32.UnsafeNativeMethods.DCB which is an internal type. We can only access it through reflection.
                        Type dcbType = dcbValue.GetType();
                        dcbType.GetField(""XonChar"").SetValue(dcbValue, xon);
                        dcbType.GetField(""XoffChar"").SetValue(dcbValue, xoff);

                        // We need to call SetCommState but because dcbValue is a private type, we don't have enough
                        //  information to create a p/Invoke declaration for it. We have to do the marshalling manually.

                        // Create unmanaged memory to copy DCB into
                        IntPtr hGlobal = Marshal.AllocHGlobal(Marshal.SizeOf(dcbValue));
                        try
                        {
                            // Copy their DCB value to unmanaged memory
                            Marshal.StructureToPtr(dcbValue, hGlobal, false);

                            // Call SetCommState
                            if (!SetCommState(portFileHandle, hGlobal))
                                throw new Win32Exception(Marshal.GetLastWin32Error());

                            // Update the BaseStream.dcb field if SetCommState succeeded
                            dcbFieldInfo.SetValue(baseStream, dcbValue);
                        }
                        finally
                        {
                            if (hGlobal != IntPtr.Zero)
                                Marshal.FreeHGlobal(hGlobal);
                        }
                    }
                    catch (SecurityException) { throw; }
                    catch (OutOfMemoryException) { throw; }
                    catch (Win32Exception) { throw; }
                    catch (Exception ex)
                    {
                        throw new ApplicationException(""SetXonXoffChars has failed due to incorrect assumptions about System.IO.Ports.SerialStream which is an internal type."", ex);
                    }
                }

                [DllImport(""kernel32.dll"", CharSet = CharSet.Auto, SetLastError = true)]
                private static extern bool SetCommState(SafeFileHandle hFile, IntPtr lpDCB);
            }

"
5327,5327,8466,Computing best subset of predictors for linear regression,"For the selection of predictors in multivariate linear regression with $p$ suitable predictors, what methods are available to find an 'optimal' subset of the predictors without explicitly testing all $2^p$ subsets? In 'Applied Survival Analysis,' Hosmer &amp; Lemeshow make reference to Kuk's method, but I cannot find the original paper. Can anyone describe this method, or, even better, a more modern technique? One may assume normally distributed errors.
",shabbychef,https://stats.stackexchange.com/users/795,"This is a huge topic. As previously mentioned, Hastie, Tibshirani and Friedman give a good intro in Ch3 of Elements of Statistical Learning.

A few points.
1) What do you mean by ""best"" or ""optimal""? What is best in one sense may not be best in another. Two common criteria are predictive accuracy (predicting the outcome variable) and producing unbiased estimators of the coefficients. Some methods, such as Lasso &amp; Ridge Regression inevitably produce biased coefficient estimators.

2) The phrase ""best subsets"" itself can be used in two separate senses. Generally to refer to the best subset among all predictors which optimises some model building criteria. More specifically it can refer to Furnival and Wilson's efficient algorithm for finding that subset among moderate (~50) numbers of linear predictors (Regressions by Leaps and Bounds. Technometrics, Vol. 16, No. 4 (Nov., 1974), pp. 499-51)

http://www.jstor.org/stable/1267601
",Thylacoleo,https://stats.stackexchange.com/users/521,http://stats.stackexchange.com/questions/2111/computing-best-subset-of-predictors-for-linear-regression,SCIENCE,stats.stackexchange.com,1.0,1.0,0.0,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.6666666666666666,1.0,0.8,1.0,0.0,0.0,1.0,The best subset calculation of linear regression prediction factors,"For selecting predictors with $p $appropriate predictors in multiple linear regression, which methods can find the ""optimal"" subset of predictors without explicitly testing all $2 ^ p $subsets? In applied survival analysis, horsmer and lemeshow mentioned cook's method, but I couldn't find the original. Can anyone describe this method, or, better yet, a more modern technology? We can assume the error of normal distribution.","This is a huge topic. As previously mentioned, Hastie, Tibshirani and Friedman give a good intro in Ch3 of Elements of Statistical Learning.

A few points.
1) What do you mean by ""best"" or ""optimal""? What is best in one sense may not be best in another. Two common criteria are predictive accuracy (predicting the outcome variable) and producing unbiased estimators of the coefficients. Some methods, such as Lasso &amp; Ridge Regression inevitably produce biased coefficient estimators.

2) The phrase ""best subsets"" itself can be used in two separate senses. Generally to refer to the best subset among all predictors which optimises some model building criteria. More specifically it can refer to Furnival and Wilson's efficient algorithm for finding that subset among moderate (~50) numbers of linear predictors (Regressions by Leaps and Bounds. Technometrics, Vol. 16, No. 4 (Nov., 1974), pp. 499-51)

http://www.jstor.org/stable/1267601
"
1271,1271,2002,How to identify if sentence is passive Voice or Indicative sentence?,"Examples: 


  ""One car was parked outside of the gate."" 
  ""Your work volume is increased or not""
  ""He was arrested""
  ""She was raped""
  ""After accident he was taken to hospital""
  ""He was informed about this""
  “My heart was broken”


All above statements can be in the stative form if we do not mentioned the agent.
But if we use the agent i.e. By Driver, By Boss,  By Police, By  boyfriend, By  friend, By  father, By  husband respectively, then sentence become as passive voice.

My questions are 
a) How to quickly make out whether a sentence is in the passive voice or just a simple sentence (Stative)?

B) If i use had been in above sentence does it mean the same?
",user4084,https://ell.stackexchange.com/users/4084,"The above sentences are still in passive form, just with an unstated agent.
 ""by agent"" is not added when the context of the sentence serves for the active object or simply when the object mention is not necessary. It is required only when we need to introduce a passive object.  

a) For quickly making out between active voice and passive voice sentences, you can go through the structures of passive voice sentences here.  

b) If you use had been in the above sentences, it just changes the tense of the sentences to participle, which is generally not advisable.
",v kumar,https://ell.stackexchange.com/users/10426,http://ell.stackexchange.com/questions/39139/how-to-identify-if-sentence-is-passive-voice-or-indicative-sentence,CULTURE,ell.stackexchange.com,0.6666666666666666,1.0,0.0,1.0,1.0,1.0,0.5555555555555556,0.5555555555555556,1.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,1.0,How to recognize whether a sentence is a passive sentence or an indicative sentence?,"Examples: 


  ""One car was parked outside of the gate."" 
  ""Your work volume is increased or not""
  ""He was arrested""
  ""She was raped""
  ""After accident he was taken to hospital""
  ""He was informed about this""
  “My heart was broken”


All above statements can be in the stative form if we do not mentioned the agent.
But if we use the agent i.e. By Driver, By Boss,  By Police, By  boyfriend, By  friend, By  father, By  husband respectively, then sentence become as passive voice.

My questions are 
a) How to quickly make out whether a sentence is in the passive voice or just a simple sentence (Stative)?

B) If i use had been in above sentence does it mean the same?
","The above sentences are still in passive form, just with an unstated agent.
 ""by agent"" is not added when the context of the sentence serves for the active object or simply when the object mention is not necessary. It is required only when we need to introduce a passive object.  

a) For quickly making out between active voice and passive voice sentences, you can go through the structures of passive voice sentences here.  

b) If you use had been in the above sentences, it just changes the tense of the sentences to participle, which is generally not advisable.
"
3168,3168,5045,Another instructor is pushing me out of the classroom right after my class ends,"I am a graduate student in math in my final year, and for several years have been teaching at my department as a lecturer. This semester, in the same lecture hall there is another lecture that starts 20 minutes after my class ends. It's taught by another instructor from my department. I usually have many students coming to office hours and there are also students asking questions immediately after lecture. Due to other activities, I cannot have office hours right after the lecture this semester and can only stay for about 15 minutes to answer questions.

Many times in the past I had a similar situation and never had any issues with it. This semester the instructor who is teaching right after often arrives 20-15 minutes before her class starts and tells me immediately that I have to go with my students somewhere else. 

I make sure to leave the blackboard clean and take all my stuff away from the instructor's desk before she arrives, but I do believe that I have a right to stay in the classroom after my lecture for at least 5-10 minutes. There is no vacant classroom around, and I don't have time to go with students to my office, which is in a different building.

Last time the instructor told me in front of my students that I don't understand ""simple things"" and that I am ""playing games"". When I was talking to one of my students, she stood very close to us and clearly demonstrated that she wanted us out. I tried to explain her that I couldn't go anywhere else due to my time constraints, but she didn't want to listen to me. I really don't understand what ""simple"" things she meant and what ""games"" I am playing. 

We leave the board clean. She doesn't need to set up a projector. She can still talk to her students before her class starts, if she wants to (even though it seems like her students don't ask her any questions before their class). So, I don't see how I cause any disruption. 

I had met this woman many times before this semester, but we never talked. I didn't see her talking to other instructors/students much, and she seems to be quite reserved and a bit neurotic. She doesn't want to have any conversation with me regarding the issue.

I felt really offended after last class when she said those things to me in front of my students. What would you do in my case? 

Added later: There are no official rules regarding classroom occupancy between classes. Instructors are supposed to use common sense and be reasonable. For me using 50% of the break time seems reasonable to answer questions after lecture seems reasonable. I agree that for some people it may not.

I don't block the entrance to the classroom. A few students from the next class who come earlier always go ahead and take their seats as soon as my students start leaving the room. I also had one of the students from the next class listening to my explanation to one of those after-class questions and asking me further questions before their class (which is the same class as I am teaching, just a different section). Maybe the instructor got jealous, I don't know.

The entrance to the classroom is from its front (not back), so I do stay in the front. But it is a big lecture hall, and there is a plenty of space in front of the room (the board itself consists of 8 huge panels).

Also, during my career as a grad.student who is also teaching for the department, I have had several observations from experienced professors who are considered to be great teachers at the department and are in charge of undergraduate teaching policy. In my evaluations the fact that there are always several students approaching me with questions after class considered as very positive, meaning that students find me approachable. 

Thank you everyone for answers. 
",Lidd88,https://academia.stackexchange.com/users/31345,"
  Last time the instructor told me in front of my students that I don't understand ""simple things"" and that I am ""playing games"". 


This is where she lost her argument. You should have simply totally ignored her. Let her make a formal complaint and only respond to such formal complaints. You don't have the duty to respond to insults, or to look up what the guidelines say in response to insults. If you were violating the small print of some guidelines, then it us her job to point that out. 
",Count Iblis,https://academia.stackexchange.com/users/17479,http://academia.stackexchange.com/questions/41133/another-instructor-is-pushing-me-out-of-the-classroom-right-after-my-class-ends,LIFE_ARTS,academia.stackexchange.com,1.0,0.3333333333333333,0.0,1.0,0.0,0.0,0.6666666666666666,0.5,1.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.6,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.8333333333333334,No sooner had I finished class than another teacher kicked me out of the classroom,"I am a graduate student in math in my final year, and for several years have been teaching at my department as a lecturer. This semester, in the same lecture hall there is another lecture that starts 20 minutes after my class ends. It's taught by another instructor from my department. I usually have many students coming to office hours and there are also students asking questions immediately after lecture. Due to other activities, I cannot have office hours right after the lecture this semester and can only stay for about 15 minutes to answer questions.

Many times in the past I had a similar situation and never had any issues with it. This semester the instructor who is teaching right after often arrives 20-15 minutes before her class starts and tells me immediately that I have to go with my students somewhere else. 

I make sure to leave the blackboard clean and take all my stuff away from the instructor's desk before she arrives, but I do believe that I have a right to stay in the classroom after my lecture for at least 5-10 minutes. There is no vacant classroom around, and I don't have time to go with students to my office, which is in a different building.

Last time the instructor told me in front of my students that I don't understand ""simple things"" and that I am ""playing games"". When I was talking to one of my students, she stood very close to us and clearly demonstrated that she wanted us out. I tried to explain her that I couldn't go anywhere else due to my time constraints, but she didn't want to listen to me. I really don't understand what ""simple"" things she meant and what ""games"" I am playing. 

We leave the board clean. She doesn't need to set up a projector. She can still talk to her students before her class starts, if she wants to (even though it seems like her students don't ask her any questions before their class). So, I don't see how I cause any disruption. 

I had met this woman many times before this semester, but we never talked. I didn't see her talking to other instructors/students much, and she seems to be quite reserved and a bit neurotic. She doesn't want to have any conversation with me regarding the issue.

I felt really offended after last class when she said those things to me in front of my students. What would you do in my case? 

Added later: There are no official rules regarding classroom occupancy between classes. Instructors are supposed to use common sense and be reasonable. For me using 50% of the break time seems reasonable to answer questions after lecture seems reasonable. I agree that for some people it may not.

I don't block the entrance to the classroom. A few students from the next class who come earlier always go ahead and take their seats as soon as my students start leaving the room. I also had one of the students from the next class listening to my explanation to one of those after-class questions and asking me further questions before their class (which is the same class as I am teaching, just a different section). Maybe the instructor got jealous, I don't know.

The entrance to the classroom is from its front (not back), so I do stay in the front. But it is a big lecture hall, and there is a plenty of space in front of the room (the board itself consists of 8 huge panels).

Also, during my career as a grad.student who is also teaching for the department, I have had several observations from experienced professors who are considered to be great teachers at the department and are in charge of undergraduate teaching policy. In my evaluations the fact that there are always several students approaching me with questions after class considered as very positive, meaning that students find me approachable. 

Thank you everyone for answers. 
","
  Last time the instructor told me in front of my students that I don't understand ""simple things"" and that I am ""playing games"". 


This is where she lost her argument. You should have simply totally ignored her. Let her make a formal complaint and only respond to such formal complaints. You don't have the duty to respond to insults, or to look up what the guidelines say in response to insults. If you were violating the small print of some guidelines, then it us her job to point that out. 
"
5368,5368,8527,"What do you call a customer's customer in a specification document, use case, or scenario?","My team and I develop software that our customers will use to interact with their customers.  Additionally, we also eat our own dogfood and use the software ourselves to interact with our customers.

Therefore, it can sometimes be difficult to explain use cases and scenarios, as our employees can be operators, our customers can be operators, and our customers' customers can be visitors.

However, our customers can also be visitors interacting with our operator employees, our customers' customers can be visitors interacting with our customer or our employee.

Here is a model where:

A is an employee
B is a customer
C is our customers' customer

X  interacts with  Y
Operator --&gt; Visitor
      A  --&gt;  B
      A  --&gt;  C
      B  --&gt;  C


Because sometimes our customers can play different roles, it's sometimes necessary to refer to the specific role, Operator or Visitor, instead of Employee and Customer.

It's also a mouthful to say ""customer's customer"" all the time.

I was wondering how other development shops handle these semantic details when writing their use cases and scenarios.  


Are there any one-word, generic terms that can apply to any product that involves a third-level actor?
Other than using the specific roles, Operator and Visitor, what words could be used to identify a customer of a customer?  


The word would need to be short enough as to be adopted within an organization.  If longer than a couple syllables, it's shortened form must still differentiate it from the other actors.
",jmort253,https://programmers.stackexchange.com/users/12611,"So the question becomes simpler when think of Roles as being relative entity a performs a role in relation to entity b. Your Customer consider's themselves to be a User and their Customer's are Customers to them. The only person who cares about your Customer as a Customer is you. You have two roles in the system as an Administrator and as a User.

I saw the explanation that you have Employees who interact with the End Customers through your chat software (let's call this role Agent). For clarification, does the Agent represent himself as an employee of your User?

I would argue that the role is still Agent, User, Customer. Referring to your User as a customer just confuses things. (As you can see).

I've had it worse...I had to work on three levels of indirection. There was a Company entity which in some cases were direct Users of our application. They had Accounts that they sold various packages from our offerings to and they tracked Customers for those Accounts. 
",Michael Brown,https://programmers.stackexchange.com/users/13181,http://programmers.stackexchange.com/questions/37973/what-do-you-call-a-customers-customer-in-a-specification-document-use-case-or,TECHNOLOGY,programmers.stackexchange.com,0.8888888888888888,1.0,0.0,1.0,1.0,0.3333333333333333,0.5555555555555556,0.6666666666666666,0.3333333333333333,0.0,0.6666666666666666,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.0,0.8888888888888888,1.0,0.8888888888888888,1.0,1.0,0.7333333333333333,0.0,0.0,0.3333333333333333,0.7777777777777778,"What do you call a customer in a specification document, use case, or scenario?","My team and I develop software that our customers will use to interact with their customers.  Additionally, we also eat our own dogfood and use the software ourselves to interact with our customers.

Therefore, it can sometimes be difficult to explain use cases and scenarios, as our employees can be operators, our customers can be operators, and our customers' customers can be visitors.

However, our customers can also be visitors interacting with our operator employees, our customers' customers can be visitors interacting with our customer or our employee.

Here is a model where:

A is an employee
B is a customer
C is our customers' customer

X  interacts with  Y
Operator --&gt; Visitor
      A  --&gt;  B
      A  --&gt;  C
      B  --&gt;  C


Because sometimes our customers can play different roles, it's sometimes necessary to refer to the specific role, Operator or Visitor, instead of Employee and Customer.

It's also a mouthful to say ""customer's customer"" all the time.

I was wondering how other development shops handle these semantic details when writing their use cases and scenarios.  


Are there any one-word, generic terms that can apply to any product that involves a third-level actor?
Other than using the specific roles, Operator and Visitor, what words could be used to identify a customer of a customer?  


The word would need to be short enough as to be adopted within an organization.  If longer than a couple syllables, it's shortened form must still differentiate it from the other actors.
","So the question becomes simpler when think of Roles as being relative entity a performs a role in relation to entity b. Your Customer consider's themselves to be a User and their Customer's are Customers to them. The only person who cares about your Customer as a Customer is you. You have two roles in the system as an Administrator and as a User.

I saw the explanation that you have Employees who interact with the End Customers through your chat software (let's call this role Agent). For clarification, does the Agent represent himself as an employee of your User?

I would argue that the role is still Agent, User, Customer. Referring to your User as a customer just confuses things. (As you can see).

I've had it worse...I had to work on three levels of indirection. There was a Company entity which in some cases were direct Users of our application. They had Accounts that they sold various packages from our offerings to and they tracked Customers for those Accounts. 
"
3406,3406,5428,Around the Clock,"I want to produce with Mathematica something like this



Or this



12 hours should be arranged in a pleasing (""rotated"") style around / within a rectangle. I don't ask for the hands - depending on numerical input - but only for a Graphics to begin with.


""Have you tried anything ?""
""Sure, but with non-presentable results.""

",eldo,https://mathematica.stackexchange.com/users/14254,"I think that the main problem here is the characteristic deformations of the numbers  due to the square clock.

Here is my attempt to reproduce the shape of the ""XI"" in the first square clock !

First some initialisation :

num = Text[ Style[""XI"", FontFamily -&gt; ""Times New Roman"", FontWeight -&gt; Bold, FontSize -&gt; 120]];
gnum = Rasterize[num, RasterSize -&gt; 400];


then my interactive tool :

Manipulate[FindGeometricTransform[{{0, 0}, {1, 0}, {1, 1}, {0, 1}}, 
{{c1, 0}, {c2, 0}, {c3, h}, {c4, h}}, TransformationClass -&gt; ""Perspective""] //
 ImageTransformation[gnum, #[[2]], 300, Padding -&gt; padcolor] &amp;,
 {{c1,0.346}, 0., 0.9}, {{c2, 0.882}, 0.50, 1}, {{c3, 0.75}, 0., 1}, {{c4, 0}, 0.0, 1}, 
{{h, 0.875}, -1, 2}, {padcolor, {0, 1}}]




You can play with the slider to change the shape.

You just need to modify the initialisation to try with some other number.
",SquareOne,https://mathematica.stackexchange.com/users/19960,http://mathematica.stackexchange.com/questions/60728/around-the-clock,TECHNOLOGY,mathematica.stackexchange.com,0.6666666666666666,0.3333333333333333,0.0,0.0,1.0,0.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.5,0.8333333333333334,0.6666666666666666,1.0,1.0,0.8,0.0,0.6666666666666666,0.3333333333333333,0.8888888888888888,All-weather,"I want to produce with Mathematica something like this



Or this



12 hours should be arranged in a pleasing (""rotated"") style around / within a rectangle. I don't ask for the hands - depending on numerical input - but only for a Graphics to begin with.


""Have you tried anything ?""
""Sure, but with non-presentable results.""

","I think that the main problem here is the characteristic deformations of the numbers  due to the square clock.

Here is my attempt to reproduce the shape of the ""XI"" in the first square clock !

First some initialisation :

num = Text[ Style[""XI"", FontFamily -&gt; ""Times New Roman"", FontWeight -&gt; Bold, FontSize -&gt; 120]];
gnum = Rasterize[num, RasterSize -&gt; 400];


then my interactive tool :

Manipulate[FindGeometricTransform[{{0, 0}, {1, 0}, {1, 1}, {0, 1}}, 
{{c1, 0}, {c2, 0}, {c3, h}, {c4, h}}, TransformationClass -&gt; ""Perspective""] //
 ImageTransformation[gnum, #[[2]], 300, Padding -&gt; padcolor] &amp;,
 {{c1,0.346}, 0., 0.9}, {{c2, 0.882}, 0.50, 1}, {{c3, 0.75}, 0., 1}, {{c4, 0}, 0.0, 1}, 
{{h, 0.875}, -1, 2}, {padcolor, {0, 1}}]




You can play with the slider to change the shape.

You just need to modify the initialisation to try with some other number.
"
5874,5874,9306,Need more memory to install Nova 3 Near Orbit on Samsung Galaxy S2,"I have a Samsung Galaxy S2, running Android 4.0.3. 

I want  to install Nova 3 Near Orbit on this device. I need 2 gigabyte of memory to install the game, but I only have 1.97 gigabytes in total.

How can i get the other 3 megabyte? I have 11 gigabyte of space on my phone, and I also have an SD card with 14 gigabyte. 
",steven ives,https://android.stackexchange.com/users/27739,"You can get free storage space the same way you do on your PC:


Uninstall some apps you're not using. You might find it useful to go into the device Settings, then Apps (or Applications manager), then press the menu key and choose Sort by size to see which are taking up the most space.
If you have lots of videos, photos, or music in your internal storage, delete them, or move them to your SD card.

",Dan Hulme,https://android.stackexchange.com/users/12442,http://android.stackexchange.com/questions/38858/need-more-memory-to-install-nova-3-near-orbit-on-samsung-galaxy-s2,TECHNOLOGY,android.stackexchange.com,0.8888888888888888,0.4444444444444444,0.0,0.6666666666666666,0.6666666666666666,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.8888888888888888,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,1.0,More memory required to install Nova 3 near orbit on Samsung Galaxy S2,"I have a Samsung Galaxy S2, running Android 4.0.3. 

I want  to install Nova 3 Near Orbit on this device. I need 2 gigabyte of memory to install the game, but I only have 1.97 gigabytes in total.

How can i get the other 3 megabyte? I have 11 gigabyte of space on my phone, and I also have an SD card with 14 gigabyte. 
","You can get free storage space the same way you do on your PC:


Uninstall some apps you're not using. You might find it useful to go into the device Settings, then Apps (or Applications manager), then press the menu key and choose Sort by size to see which are taking up the most space.
If you have lots of videos, photos, or music in your internal storage, delete them, or move them to your SD card.

"
5995,5995,9506,Which products should have FCC certification and about how much does that cost?,"I'm aware that nobody actually does this at the hobbyist level, that successful commercial products have been launched without certification, and it's probably something I can't afford if I have to ask. However, I've always wondered about the ballpark cost. About how much does it cost to receive FCC certification?
",joeforker,https://electronics.stackexchange.com/users/1363,"As a rough estimate, the cost is $10k-20k, plus your labor cost.

In the US, all products containing electronics that oscillate above 9 kHz must be certified. The law that governs this is FCC Part 15. The lawyers call this ""Title 47 CFR Part 15,"" meaning that it is the 15th subsection of the 47th section of the Code of Federal Regulations. In Europe, there is a similar regulation called CISPR 22. The requirements are almost the same, but slightly stricter about emissions at certain frequencies.

You can read 47 CFR 15 online. It's not as incomprehensible as you might expect. It seems overwhelming, but if you read the first few PDF's, you'll realize that most of it irrelevant for any single product.

Within 47 CFR 15, there are two classes of testing: Class A and Class B. Class A is an easier test to pass, intended for devices that are used in industrial settings. Class B is stricter, intended for devices that are targeted at consumers.

There is additional testing for ""intentional radiators,"" meaning radios, Wi-fi, Bluetooth and such. There may be an exception if your device is intended for use as a component in a larger system (like a microprocessor or memory card in a PC), but I'm not sure of the legal details there.

The major expense is renting the test chamber. This is what's called an ""anechoic chamber,"" instrumented with a pile of sensors for detecting electromagnetic radiation. To my knowledge, these cost around $1000/hour, and each testing session takes 2 or 3 hours. It's unlikely, but not impossible, that you will pass on the first try.

Here's a decent picture of a test chamber. The one I've been in was actually much larger, like a squash court. I think it was an Intertek facility in Menlo Park, CA.

Unless you're experienced with emissions testing, it is worth hiring an expert, which costs around $500/hour. They can tell you things like, ""Put a ferrite bead on that power cable, and that will reduce the emissions at this frequency."" The folks I've worked with arrive with a bunch of ferrite beads and inductors (and maybe caps?) of various sizes that you can use in the chamber to hack your device into compliance. 

(Perhaps it goes without saying, but I'm an engineer, not a lawyer. I have taken a few products through Part 15, but not in the last couple of years.)

If you're thinking about doing this, start by reading EMC for Product Designers by Tim Williams. I'd avoid the books by Mark I. Montrose; I found them less helpful and more expensive.
",pingswept,https://electronics.stackexchange.com/users/712,http://electronics.stackexchange.com/questions/5196/which-products-should-have-fcc-certification-and-about-how-much-does-that-cost,TECHNOLOGY,electronics.stackexchange.com,0.7777777777777778,0.7777777777777778,0.0,0.6666666666666666,1.0,1.0,0.5555555555555556,0.5555555555555556,0.6666666666666666,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.8888888888888888,1.0,0.7777777777777778,1.0,1.0,0.9333333333333332,0.0,0.3333333333333333,0.6666666666666666,1.0,Which products should have FCC certification and what is the price?,"I know that in fact, no one will do this at the level of fans. Successful commercial products are launched without certification. If I have to ask, I can't afford it. However, I always want to know the approximate cost. How much does it cost to get FCC certification?","As a rough estimate, the cost is $10k-20k, plus your labor cost.

In the US, all products containing electronics that oscillate above 9 kHz must be certified. The law that governs this is FCC Part 15. The lawyers call this ""Title 47 CFR Part 15,"" meaning that it is the 15th subsection of the 47th section of the Code of Federal Regulations. In Europe, there is a similar regulation called CISPR 22. The requirements are almost the same, but slightly stricter about emissions at certain frequencies.

You can read 47 CFR 15 online. It's not as incomprehensible as you might expect. It seems overwhelming, but if you read the first few PDF's, you'll realize that most of it irrelevant for any single product.

Within 47 CFR 15, there are two classes of testing: Class A and Class B. Class A is an easier test to pass, intended for devices that are used in industrial settings. Class B is stricter, intended for devices that are targeted at consumers.

There is additional testing for ""intentional radiators,"" meaning radios, Wi-fi, Bluetooth and such. There may be an exception if your device is intended for use as a component in a larger system (like a microprocessor or memory card in a PC), but I'm not sure of the legal details there.

The major expense is renting the test chamber. This is what's called an ""anechoic chamber,"" instrumented with a pile of sensors for detecting electromagnetic radiation. To my knowledge, these cost around $1000/hour, and each testing session takes 2 or 3 hours. It's unlikely, but not impossible, that you will pass on the first try.

Here's a decent picture of a test chamber. The one I've been in was actually much larger, like a squash court. I think it was an Intertek facility in Menlo Park, CA.

Unless you're experienced with emissions testing, it is worth hiring an expert, which costs around $500/hour. They can tell you things like, ""Put a ferrite bead on that power cable, and that will reduce the emissions at this frequency."" The folks I've worked with arrive with a bunch of ferrite beads and inductors (and maybe caps?) of various sizes that you can use in the chamber to hack your device into compliance. 

(Perhaps it goes without saying, but I'm an engineer, not a lawyer. I have taken a few products through Part 15, but not in the last couple of years.)

If you're thinking about doing this, start by reading EMC for Product Designers by Tim Williams. I'd avoid the books by Mark I. Montrose; I found them less helpful and more expensive.
"
1893,1893,3014,"Sorting the output of ""find""?","I need to be able to alphabetically sort the output of find before piping it to a command. Entering | sort | between didn't work, so what could I do?

find folder1 folder2 -name ""*.txt"" -print0 | xargs -0 myCommand

",Industrial,https://unix.stackexchange.com/users/3208,"If you have GNU Parallel http://www.gnu.org/software/parallel/ installed you can do this:

find folder1 folder2 -name ""*.txt"" -print | sort | parallel myCommand


You can install GNU Parallel simply by:

wget http://git.savannah.gnu.org/cgit/parallel.git/plain/src/parallel
chmod 755 parallel
cp parallel sem


Watch the intro videos for GNU Parallel to learn more:
https://www.youtube.com/playlist?list=PL284C9FF2488BC6D1
",Ole Tange,https://unix.stackexchange.com/users/2972,http://unix.stackexchange.com/questions/34325/sorting-the-output-of-find,TECHNOLOGY,unix.stackexchange.com,0.7777777777777778,0.7777777777777778,0.0,1.0,1.0,1.0,0.6666666666666666,0.4444444444444444,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,0.8888888888888888,1.0,0.7333333333333333,0.6666666666666666,0.0,0.3333333333333333,1.0,"Sort the output of ""find""?","I need to be able to sort the output of find alphabetically before sending it to the command. Sorting by typing in the middle doesn't work, so what should I do?","If you have GNU Parallel http://www.gnu.org/software/parallel/ installed you can do this:

find folder1 folder2 -name ""*.txt"" -print | sort | parallel myCommand


You can install GNU Parallel simply by:

wget http://git.savannah.gnu.org/cgit/parallel.git/plain/src/parallel
chmod 755 parallel
cp parallel sem


Watch the intro videos for GNU Parallel to learn more:
https://www.youtube.com/playlist?list=PL284C9FF2488BC6D1
"
816,816,1292,"Tight VNC Server, Ubutu 12.10 and unity desktop","I've done the following but all I get in VNC Viewer is a blank orange screen, any help appreciated.


apt-get -y install ubuntu-desktop tightvncserver
adduser vnc
passwd vnc
echo ""vnc ALL=(ALL)       ALL"" >> /etc/sudoers
su - vnc
vncpasswd
exit
cd ~
nano .vnc/xstartup


#!/bin/sh

# Uncomment the following two lines for normal desktop:
unset SESSION_MANAGER
. /etc/X11/xinit/xinitrc

[ -x /etc/vnc/xstartup ] &amp;&amp; exec /etc/vnc/xstartup
[ -r $HOME/.Xresources ] &amp;&amp; xrdb $HOME/.Xresources
xsetroot -solid grey
vncconfig -iconic &amp;
x-terminal-emulator -geometry 1280x1024+10+10 -ls -title ""$VNCDESKTOP Desktop"" &amp;

#x-window-manager &

save

THEN nano /etc/init.d/vncserver 

THEN paste in the following, then save:

#!/bin/sh -e
### BEGIN INIT INFO
# Provides:          vncserver
# Required-Start:    networking
# Default-Start:     3 4 5
# Default-Stop:      0 6
### END INIT INFO

PATH=""$PATH:/usr/bin/""

# The Username:Group that will run VNC
export USER=""vnc""
#${RUNAS}

# The display that VNC will use
DISPLAY=""1""

# Color depth (between 8 and 32)
DEPTH=""16""

# The Desktop geometry to use.
#GEOMETRY=""x""
#GEOMETRY=""800x600""
GEOMETRY=""1024x768""
#GEOMETRY=""1280x1024""

# The name that the VNC Desktop will have.
NAME=""my-vnc-server""

OPTIONS=""-name ${NAME} -depth ${DEPTH} -geometry ${GEOMETRY} :${DISPLAY}""

. /lib/lsb/init-functions

case ""$1"" in
start)
log_action_begin_msg ""Starting vncserver for user '${USER}' on   localhost:${DISPLAY}""
su ${USER} -c ""/usr/bin/vncserver ${OPTIONS}""
;;

stop)
log_action_begin_msg ""Stopping vncserver for user '${USER}' on localhost:${DISPLAY}""
su ${USER} -c ""/usr/bin/vncserver -kill :${DISPLAY}""
;;

restart)
$0 stop
$0 start
;;
esac

exit 0


Then ctrl-x to save, Y for Yes, and enter to accept file name.

THEN

chown -R vnc. /home/vnc/.vnc &amp;&amp; chmod +x /home/vnc/.vnc/xstartup
sed -i 's/allowed_users.*/allowed_users=anybody/g' /etc/X11/Xwrapper.config

THEN

chmod +x /etc/init.d/vncserver &amp;&amp; service vncserver start

THEN

update-rc.d vncserver defaults

THEN

reboot.

FINALLY: go in there with tightvnc viewer client, and voila, blank kool aid tangerine orange screen.

any help appreciated, of course it's been 3 x 8 hour evenings so far :}
",Randal Oulton,https://askubuntu.com/users/244335,"you didn't set gui session for xstartup file, that is why you see blank screen when try try to remotely connect to your desktop/server via vnc on ubuntu, if you want gnome, install these packages

# apt-get install gnome-panel gnome-settings-daemon metacity nautilus gnome-terminal


and use this xstartup file

#!/bin/sh

export XKL_XMODMAP_DISABLE=1
unset SESSION_MANAGER
unset DBUS_SESSION_BUS_ADDRESS

[ -x /etc/vnc/xstartup ] &amp;&amp; exec /etc/vnc/xstartup
[ -r $HOME/.Xresources ] &amp;&amp; xrdb $HOME/.Xresources
xsetroot -solid grey
vncconfig -iconic &amp;

gnome-panel &amp;
gnome-settings-daemon &amp;
metacity &amp;
nautilus &amp;
gnome-terminal &amp;

",Blanca Higgins,https://askubuntu.com/users/282622,http://askubuntu.com/questions/416151/tight-vnc-server-ubutu-12-10-and-unity-desktop,TECHNOLOGY,askubuntu.com,0.7777777777777778,0.3333333333333333,0.0,0.0,1.0,0.6666666666666666,0.6666666666666666,0.4444444444444444,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.0,0.6666666666666666,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8666666666666666,0.6666666666666666,0.3333333333333333,1.0,0.6666666666666666,"Tight VNC server, Ubuntu 12.10 and unity desktop","I've done the following but all I get in VNC Viewer is a blank orange screen, any help appreciated.


apt-get -y install ubuntu-desktop tightvncserver
adduser vnc
passwd vnc
echo ""vnc ALL=(ALL)       ALL"" >> /etc/sudoers
su - vnc
vncpasswd
exit
cd ~
nano .vnc/xstartup


#!/bin/sh

# Uncomment the following two lines for normal desktop:
unset SESSION_MANAGER
. /etc/X11/xinit/xinitrc

[ -x /etc/vnc/xstartup ] &amp;&amp; exec /etc/vnc/xstartup
[ -r $HOME/.Xresources ] &amp;&amp; xrdb $HOME/.Xresources
xsetroot -solid grey
vncconfig -iconic &amp;
x-terminal-emulator -geometry 1280x1024+10+10 -ls -title ""$VNCDESKTOP Desktop"" &amp;

#x-window-manager &

save

THEN nano /etc/init.d/vncserver 

THEN paste in the following, then save:

#!/bin/sh -e
### BEGIN INIT INFO
# Provides:          vncserver
# Required-Start:    networking
# Default-Start:     3 4 5
# Default-Stop:      0 6
### END INIT INFO

PATH=""$PATH:/usr/bin/""

# The Username:Group that will run VNC
export USER=""vnc""
#${RUNAS}

# The display that VNC will use
DISPLAY=""1""

# Color depth (between 8 and 32)
DEPTH=""16""

# The Desktop geometry to use.
#GEOMETRY=""x""
#GEOMETRY=""800x600""
GEOMETRY=""1024x768""
#GEOMETRY=""1280x1024""

# The name that the VNC Desktop will have.
NAME=""my-vnc-server""

OPTIONS=""-name ${NAME} -depth ${DEPTH} -geometry ${GEOMETRY} :${DISPLAY}""

. /lib/lsb/init-functions

case ""$1"" in
start)
log_action_begin_msg ""Starting vncserver for user '${USER}' on   localhost:${DISPLAY}""
su ${USER} -c ""/usr/bin/vncserver ${OPTIONS}""
;;

stop)
log_action_begin_msg ""Stopping vncserver for user '${USER}' on localhost:${DISPLAY}""
su ${USER} -c ""/usr/bin/vncserver -kill :${DISPLAY}""
;;

restart)
$0 stop
$0 start
;;
esac

exit 0


Then ctrl-x to save, Y for Yes, and enter to accept file name.

THEN

chown -R vnc. /home/vnc/.vnc &amp;&amp; chmod +x /home/vnc/.vnc/xstartup
sed -i 's/allowed_users.*/allowed_users=anybody/g' /etc/X11/Xwrapper.config

THEN

chmod +x /etc/init.d/vncserver &amp;&amp; service vncserver start

THEN

update-rc.d vncserver defaults

THEN

reboot.

FINALLY: go in there with tightvnc viewer client, and voila, blank kool aid tangerine orange screen.

any help appreciated, of course it's been 3 x 8 hour evenings so far :}
","you didn't set gui session for xstartup file, that is why you see blank screen when try try to remotely connect to your desktop/server via vnc on ubuntu, if you want gnome, install these packages

# apt-get install gnome-panel gnome-settings-daemon metacity nautilus gnome-terminal


and use this xstartup file

#!/bin/sh

export XKL_XMODMAP_DISABLE=1
unset SESSION_MANAGER
unset DBUS_SESSION_BUS_ADDRESS

[ -x /etc/vnc/xstartup ] &amp;&amp; exec /etc/vnc/xstartup
[ -r $HOME/.Xresources ] &amp;&amp; xrdb $HOME/.Xresources
xsetroot -solid grey
vncconfig -iconic &amp;

gnome-panel &amp;
gnome-settings-daemon &amp;
metacity &amp;
nautilus &amp;
gnome-terminal &amp;

"
4733,4733,7507,What happens to light and mass in the center of a black hole?,"I know that black holes are ""black"" because nothing can escape it due to the massive gravity, but I am wondering if there are any theories as to what happens to the light or mass that enters a black hole and cannot escape. 
",Annika Peterson,https://physics.stackexchange.com/users/4179,"One theory suggests that all the matter is squashed to a tiny point where its density is so incredibly that it literally rips a hole in the spacetime. This hole creates a loop to possibly another location in the universe in any time or even in a parallel universe. This matter is sucked through the black hole to the other side of the loop hole where something called a white hole is created. There is little evidence for this as no white holes have ever been found.
",Cameron,https://physics.stackexchange.com/users/1878,http://physics.stackexchange.com/questions/26704/what-happens-to-light-and-mass-in-the-center-of-a-black-hole,SCIENCE,physics.stackexchange.com,0.6666666666666666,0.7777777777777778,0.0,0.0,1.0,1.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,1.0,0.8888888888888888,0.6666666666666666,0.6666666666666666,1.0,0.9,0.0,0.6666666666666666,1.0,0.8888888888888888,What happens to the light and mass at the center of a black hole?,"I know that black holes are ""black"" because nothing can escape them because of the huge gravity, but I want to know if there is any theory that can explain what happened to the light or mass entering the black hole, and cannot escape.","One theory is that all matter is squeezed into a tiny point where its density is so high that it really tears a hole in space-time. This hole creates a cycle of possible positions in the universe at any time, even in a parallel universe. This material is sucked into the black hole, into the other side of the black hole, where it forms something called a white hole. There is little evidence to support this, as white holes have never been found."
3277,3277,5221,Rotating vector3 by a quaternion,"I am attempting to rotate a vector3 by a given quaternion.

I know that this is true

v' = q * v * (q^-1)


I know that q^(-1) is the inverse which just -q/magnitude(q), but how do I map the multiplication of the vector to the quaternion to get back a vector?

I have found that you can treat v as a matrix, and convert q, and q' to matrices, and then convert v' from a matrix to a vector, but this seems a little over the top just to get a vector. Is there a cleaner implementation that I could use?
",gardian06,https://gamedev.stackexchange.com/users/14586,"Here is an alternative way to transform a vector by a quaternion. It is the way MS does it in the xna framework.
http://pastebin.com/fAFp6NnN
",Steve H,https://gamedev.stackexchange.com/users/1923,http://gamedev.stackexchange.com/questions/28395/rotating-vector3-by-a-quaternion,TECHNOLOGY,gamedev.stackexchange.com,1.0,0.5,0.0,1.0,1.0,1.0,0.5,0.5,0.5,0.0,0.5,0.5,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.8333333333333334,0.5,1.0,0.8333333333333334,0.8,1.0,0.0,0.0,1.0,Quaternion rotation vector 3,"I am attempting to rotate a vector3 by a given quaternion.

I know that this is true

v' = q * v * (q^-1)


I know that q^(-1) is the inverse which just -q/magnitude(q), but how do I map the multiplication of the vector to the quaternion to get back a vector?

I have found that you can treat v as a matrix, and convert q, and q' to matrices, and then convert v' from a matrix to a vector, but this seems a little over the top just to get a vector. Is there a cleaner implementation that I could use?
","Here is an alternative way to transform a vector by a quaternion. It is the way MS does it in the xna framework.
http://pastebin.com/fAFp6NnN
"
261,261,424,"Orthogonal complement $V^\bot$ of the vector space $V=\langle(1,0,2),(3,-1,0)\rangle$ and $V\cap V^\bot$","Consider the inner product defined by polarizing the quadratic form $$q(x,y,z)=x^2-z^2+4xy-2yz$$ on $\mathbb{R}^3$.

Let $V=\langle(1,0,2),(3,-1,0)\rangle$. Could you show me how to find $V^\bot$ and $V\cap V^\bot$? I get $V^\bot=\langle(2,6,1)\rangle$, which doesn't feel right, and don't know how to calculate the intersection. Also, in general, what can we say about the dimension of $W^\bot$ if we know the dimension of $W$?
",user62029,https://math.stackexchange.com/users/174765,"you want to find $(x, y, z)$ so that it is orthogonal to $(1,0, 2)$ and $(3, -1, 0)$
that means $x + 2z = 0, 3x - y = 0$ if the basis of is more complex you will make a matrix made of these vectors as rows and row reduce them to solve for $x,y,z.$ in this example it is easier and we can set $z = -1$ and solve for $x = 2, y = 6$ so that $V^\perp$ is spanned  by $(2, 6, -1).$

the dimension of $W$ and $W^\perp$ should add up to the dimension of the space these are subspaces of.



edit: $\pmatrix{1&amp;0&amp;2&amp;|&amp;a\\3&amp;-1&amp;0&amp;|&amp;b} \rightarrow 
\pmatrix{1 &amp; 0 &amp; 2&amp;|&amp;a\\0&amp;-1&amp;-6&amp;|&amp;-3a + b}$

here $z$ is free variable and set it to $z = -1$. back substitution gives you $y = 6, x = 2$

if you had more than one free variable, you will set one of them to $1$ and the all rest to zero, then cycle through all of the free variables to get that many solutions in $W^\perp$
",abel,https://math.stackexchange.com/users/9252,http://math.stackexchange.com/questions/1124655/orthogonal-complement-v-bot-of-the-vector-space-v-langle1-0-2-3-1-0-ra,SCIENCE,math.stackexchange.com,0.7777777777777778,0.4444444444444444,0.0,0.3333333333333333,1.0,0.6666666666666666,0.6666666666666666,0.4444444444444444,0.6666666666666666,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.0,0.7777777777777778,0.7777777777777778,0.6666666666666666,0.7777777777777778,0.8888888888888888,0.8,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.6666666666666666,"Orthogonal complement $V ^ \ BOT $, range $and $V \ cap V ^ \ BOT $of vector space $v = \ LANGLE (1,0,2), (3, - 1,0)$","Consider the inner product defined by polarizing the quadratic form $$q(x,y,z)=x^2-z^2+4xy-2yz$$ on $\mathbb{R}^3$.

Let $V=\langle(1,0,2),(3,-1,0)\rangle$. Could you show me how to find $V^\bot$ and $V\cap V^\bot$? I get $V^\bot=\langle(2,6,1)\rangle$, which doesn't feel right, and don't know how to calculate the intersection. Also, in general, what can we say about the dimension of $W^\bot$ if we know the dimension of $W$?
","you want to find $(x, y, z)$ so that it is orthogonal to $(1,0, 2)$ and $(3, -1, 0)$
that means $x + 2z = 0, 3x - y = 0$ if the basis of is more complex you will make a matrix made of these vectors as rows and row reduce them to solve for $x,y,z.$ in this example it is easier and we can set $z = -1$ and solve for $x = 2, y = 6$ so that $V^\perp$ is spanned  by $(2, 6, -1).$

the dimension of $W$ and $W^\perp$ should add up to the dimension of the space these are subspaces of.



edit: $\pmatrix{1&amp;0&amp;2&amp;|&amp;a\\3&amp;-1&amp;0&amp;|&amp;b} \rightarrow 
\pmatrix{1 &amp; 0 &amp; 2&amp;|&amp;a\\0&amp;-1&amp;-6&amp;|&amp;-3a + b}$

here $z$ is free variable and set it to $z = -1$. back substitution gives you $y = 6, x = 2$

if you had more than one free variable, you will set one of them to $1$ and the all rest to zero, then cycle through all of the free variables to get that many solutions in $W^\perp$
"
5196,5196,8254,Using VBA to change Picture,"I am trying to use VBA to automate the Change Picture function when you right click a Shape in Excel/Word/Powerpoint.

However, I am not able to find any reference, can you assist?
",PlayKid,https://stackoverflow.com/users/52590,"You can change the source of a picture using the UserPicture method as applied to a rectangle shape. However, you will need to resize the rectangle accordingly if you wish to maintain the picture's original aspect ratio, as the picture will take the dimensions of the rectangle.

As an example:

 ActivePresentation.Slides(2).Shapes(shapeId).Fill.UserPicture (""C:\image.png"")

",richnis,https://stackoverflow.com/users/2642502,http://stackoverflow.com/questions/10169011/using-vba-to-change-picture,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.4444444444444444,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.5555555555555556,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.0,0.0,0.8888888888888888,Change pictures with VBA,"When you right-click a shape in Excel / word / Powerpoint, I'm trying to use VBA to automatically change pictures.","You can change the source of a picture using the userpicture method applied to a rectangular shape. However, if you want to keep the original aspect ratio of the picture, you need to adjust the size of the rectangle accordingly, because the picture will get the size of the rectangle."
1824,1824,2893,Self-managed IRA account brokerage as an HSA?,"Most specific than this question, I'm desperately seeking a TD Ameritrade or E-Trade type online brokerage that offers self managed HSAs to accompany an HDHP.  I cannot find one.

Is there another key word that I should be looking for?  Can any IRA be used as an HSA and I just don't realize it, assuming I do the right paperwork?

If there are no such options, are there legal reason why there cannot be?  Are there financial disincentives making such offerings unappealing to brokerages?

Thanks!
",Jason Kleban,https://money.stackexchange.com/users/3990,"Here is a Directory of HSA Administrators 

A google of HSA administrators turns up quite a list. These accounts are separate from IRAs, and an IRA can't substitute. The HSA is required to have the HDHP and the insurer running it should be offering you the linked HSA partners as they are closely tied.
",JoeTaxpayer,https://money.stackexchange.com/users/187,http://money.stackexchange.com/questions/9146/self-managed-ira-account-brokerage-as-an-hsa,LIFE_ARTS,money.stackexchange.com,1.0,0.4444444444444444,0.0,0.3333333333333333,1.0,0.3333333333333333,0.8888888888888888,0.7777777777777778,1.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,1.0,0.0,1.0,0.8888888888888888,0.4444444444444444,1.0,1.0,0.6666666666666667,0.3333333333333333,0.0,1.0,1.0,Manage IRA Account brokerage as HSA?,"Most specific than this question, I'm desperately seeking a TD Ameritrade or E-Trade type online brokerage that offers self managed HSAs to accompany an HDHP.  I cannot find one.

Is there another key word that I should be looking for?  Can any IRA be used as an HSA and I just don't realize it, assuming I do the right paperwork?

If there are no such options, are there legal reason why there cannot be?  Are there financial disincentives making such offerings unappealing to brokerages?

Thanks!
","Here is a Directory of HSA Administrators 

A google of HSA administrators turns up quite a list. These accounts are separate from IRAs, and an IRA can't substitute. The HSA is required to have the HDHP and the insurer running it should be offering you the linked HSA partners as they are closely tied.
"
4472,4472,7095,Equitably distributed curve on a sphere,"Let $\gamma=\gamma(L)$ be a
simple (non-self-intersecting) closed curve of length $L$
on the unit-radius sphere $S$.
So if $L=2\pi$, $\gamma$ could be a great circle.

I am seeking the most equitably distributed
$\gamma(L)$, distributed in the sense that
the length of $\gamma$ within any disk is minimized.
This is something like placing repelling electrons on a sphere,
but here the curve self-repels.
So there should be no ""clots"" of $\gamma$ anywhere on $S$.
I am especially interested in large $L$.
A possible $\gamma$ is shown below, surely not optimal for its length:

&nbsp;
&nbsp;
&nbsp;
&nbsp;
&nbsp;
&nbsp;




Here is an attempt to capture more formally ""equitably distributed.""
I find this an awkward definition, and perhaps there is a more
natural definition.

Around a point $c \in S$, measure the $r$-density
of $\gamma$ as the total length within an $r$-disk:
$$d_\gamma(c,r) = | \gamma \cap D(c,r)|$$
where $D(c,r)$ is the disk of geodesic radius $r$
centered on $c$.
Then define $d_\gamma(r)$ as the maximum of $d_\gamma(c,r)$ over
all $c \in S$.

Finally, we can say that, for two curves $\gamma_1$ and
$\gamma_2$ of the same length $L$, that
$\gamma_1 \le \gamma_2$
if $d_{\gamma_1}(r) \le d_{\gamma_2}(r)$
for all $r \in (0,\pi)$, i.e.,
$\gamma_1$ is less concentrated than $\gamma_2$ for all $r$
up to a hemisphere.

This definition provides a partial order on curves of a given length $L$.
One version of my question is:


  Q. What do the minimal elements of this poset
  look like, especially as $L$ gets large?


These minimal curves are in some sense nowhere densely clotted.

Update. Acknowledging Gerhard Paseman's remark, I thought I would include
this attractive image of a space-filling curve on a sphere:

&nbsp;


&nbsp;
(Image from this website).

But notice it is certainly not equidistributed in any sense, crowding near the northpole.
",Joseph O'Rourke,https://mathoverflow.net/users/6094,"I suppose one heuristic would be to find a shortest tour through uniformly distributed points on a sphere.  The following image applies Mathematica's FindShortestTour command to $10000$ points generated by your own sphere command from Computational Geometry in C.



We could also use more regularly distributed points to obtain a path that (I suspect) has better local properties.  This image uses 5000 points generated by the algorithm described here.



I don't know that I quite follow your $\gamma(L)$ function, but it might be something like an inverse of the function obtained by plotting the length $L$ as a function of the number of points input to this procedure.


",Mark McClure,https://mathoverflow.net/users/46214,http://mathoverflow.net/questions/188173,SCIENCE,mathoverflow.net,0.7777777777777778,0.3333333333333333,0.0,1.0,0.6666666666666666,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.3333333333333333,0.0,0.3333333333333333,1.0,0.6666666666666666,1.0,1.0,1.0,0.6666666666666666,0.0,0.3333333333333333,1.0,Uniformly distributed curve on sphere,"Let $\gamma=\gamma(L)$ be a
simple (non-self-intersecting) closed curve of length $L$
on the unit-radius sphere $S$.
So if $L=2\pi$, $\gamma$ could be a great circle.

I am seeking the most equitably distributed
$\gamma(L)$, distributed in the sense that
the length of $\gamma$ within any disk is minimized.
This is something like placing repelling electrons on a sphere,
but here the curve self-repels.
So there should be no ""clots"" of $\gamma$ anywhere on $S$.
I am especially interested in large $L$.
A possible $\gamma$ is shown below, surely not optimal for its length:

&nbsp;
&nbsp;
&nbsp;
&nbsp;
&nbsp;
&nbsp;




Here is an attempt to capture more formally ""equitably distributed.""
I find this an awkward definition, and perhaps there is a more
natural definition.

Around a point $c \in S$, measure the $r$-density
of $\gamma$ as the total length within an $r$-disk:
$$d_\gamma(c,r) = | \gamma \cap D(c,r)|$$
where $D(c,r)$ is the disk of geodesic radius $r$
centered on $c$.
Then define $d_\gamma(r)$ as the maximum of $d_\gamma(c,r)$ over
all $c \in S$.

Finally, we can say that, for two curves $\gamma_1$ and
$\gamma_2$ of the same length $L$, that
$\gamma_1 \le \gamma_2$
if $d_{\gamma_1}(r) \le d_{\gamma_2}(r)$
for all $r \in (0,\pi)$, i.e.,
$\gamma_1$ is less concentrated than $\gamma_2$ for all $r$
up to a hemisphere.

This definition provides a partial order on curves of a given length $L$.
One version of my question is:


  Q. What do the minimal elements of this poset
  look like, especially as $L$ gets large?


These minimal curves are in some sense nowhere densely clotted.

Update. Acknowledging Gerhard Paseman's remark, I thought I would include
this attractive image of a space-filling curve on a sphere:

&nbsp;


&nbsp;
(Image from this website).

But notice it is certainly not equidistributed in any sense, crowding near the northpole.
","I suppose one heuristic would be to find a shortest tour through uniformly distributed points on a sphere.  The following image applies Mathematica's FindShortestTour command to $10000$ points generated by your own sphere command from Computational Geometry in C.



We could also use more regularly distributed points to obtain a path that (I suspect) has better local properties.  This image uses 5000 points generated by the algorithm described here.



I don't know that I quite follow your $\gamma(L)$ function, but it might be something like an inverse of the function obtained by plotting the length $L$ as a function of the number of points input to this procedure.


"
2267,2267,3612,How do you include a user's default image in a Drupal 7 view that lists people?,"I have a view in Drupal 7 that lists people (users). It shows the username and the standard user picture field. If a user has a set image, it comes through perfectly. However, for users that didn't set a profile image no image is shown, even though I have a default profile image set in the people settings for the site.

How do I get views to use the default profile picture for people that do not have a profile image set?

Update: I wasn't clear. I know how to use the default image in the no results behavior. The issue is that I can't get the default image to use the imagestyle I use for the other images.
",Justin,https://drupal.stackexchange.com/users/1026,"Grab the path on the default image setting. Head over to your view and click on your image field. Look for ""no results behavior"". In the text area add 

Verify that your view does not have hide if empty checked.

Save your view. 
",Aaron Ortega,https://drupal.stackexchange.com/users/4845,http://drupal.stackexchange.com/questions/31799/how-do-you-include-a-users-default-image-in-a-drupal-7-view-that-lists-people,TECHNOLOGY,drupal.stackexchange.com,1.0,0.7777777777777778,0.0,1.0,0.6666666666666666,1.0,0.6666666666666666,0.4444444444444444,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,0.8888888888888888,How do I include a user's default image in the Drupal 7 view that lists users?,"I have a view in Drupal 7 that lists people (users). It displays the user name and standard user picture fields. If a user has a set image, it will pass perfectly. However, for users who do not have a profile image set, even if I set the default profile image in the ""people settings"" of the website, no image will be displayed.","Grab the path on the default image setting. Head over to your view and click on your image field. Look for ""no results behavior"". In the text area add 

Verify that your view does not have hide if empty checked.

Save your view. 
"
679,679,1072,Why does cyclopropane give bromine water test?,"This question was in my exam and all I could tell was that it is related to high angle strain as the angle is $60^\circ$ in stead of required $109.5^\circ$. No book I have read mentions this. Also, what is the product formed?
",evil999man,https://chemistry.stackexchange.com/users/4597,"The following ring opening reaction will occour:





You are quite right about the angle strain. Because orbital interactions are not optimal in this geometry. Consider $p$-orbitals, then a natural bond angle would be $\theta\in [90^\circ; 180^\circ]$. A mixing of $s$ and $p$ type orbitals allows a wide range of angles $\theta\in (90^\circ,\dots, 180^\circ)$.

In the cyclo propane $\ce{C3H6}$ - which you can also describe as trimethylene $\ce{(CH2)3}$ -   bonds have to be bent to overlap at all. A possible way of describing the bonding situation is regarding each $\ce{CH2}$ entity as $sp^2$ hybridised. Two of these orbitals are used for $\ce{C-H}$-bonds (not shown) and one forms an inner two-electron-three-centre $\sigma$ bond (left). Leaving $p$-orbitals to form some kind of degenerate $\pi$-like orbitals (middle, right). 



This very general approach can be derived from a Walsh diagram. Schwarz et.al. {@academia.edu} and Hoffmann {@roaldhoffmann.com} described bonding quite similar and it is in quite good agreement with a calculation (BP86/cc-PVTZ, $D_{3h}$) I have done. From this I have prepared a chart of all occupied molecular orbitals formed from valence orbitals and the LUMO. Preview:



Especially the symmetrical orbital 8 resembles very well the schematics. A quite rigorous approach for this theory can also be found here.

It is noteworthy - as mentioned by ron - that there is no notable increase in electron density in the centre of the ring. This may be due to the fact that there are much more orbitals having nodes in the centre than there are without.



Now bromine is known to be easily polarised $\ce{{}^{\delta+}Br-Br^{\delta-}}$ and may intercept at any point of the ring causing a bond break and relaxation to a less strained structure. It will most likely attack at the the $\pi$ type orbitals since bromine is an electrophile. The mechanism is analogous to the addition of bromine to ethene, which is nicely described at chemguide.co.uk. The essential part is the attack of the bromine at the HOMO(s).



The ring opening reaction can be reversed by adding sodium.

However, when there are bromine radicals present (UV light) then substitution will occur:
\begin{aligned}\ce{
Br2 &amp;-&gt;[\ce{h\nu}] 2Br.\\
&amp;+(CH2)3 -&gt; (CH2)2(CHBr) + HBr
}\end{aligned}
",Martin - マーチン,https://chemistry.stackexchange.com/users/4945,http://chemistry.stackexchange.com/questions/10653/why-does-cyclopropane-give-bromine-water-test,SCIENCE,chemistry.stackexchange.com,0.7777777777777778,0.4444444444444444,0.0,0.0,1.0,1.0,0.5555555555555556,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.3333333333333333,0.3333333333333333,0.0,1.0,0.0,0.8888888888888888,1.0,0.7777777777777778,1.0,1.0,0.8,0.3333333333333333,0.0,1.0,0.6666666666666666,Why does cyclopropane need bromine water test?,"This problem is that in my exam, all I can know is that it is related to the large angle strain, because the angle is $60 ^ \ CIRC $, not the necessary $109.5 ^ \ CIRC $. This is not mentioned in the book I read. In addition, what form is the product?","The following ring opening reaction will occour:





You are quite right about the angle strain. Because orbital interactions are not optimal in this geometry. Consider $p$-orbitals, then a natural bond angle would be $\theta\in [90^\circ; 180^\circ]$. A mixing of $s$ and $p$ type orbitals allows a wide range of angles $\theta\in (90^\circ,\dots, 180^\circ)$.

In the cyclo propane $\ce{C3H6}$ - which you can also describe as trimethylene $\ce{(CH2)3}$ -   bonds have to be bent to overlap at all. A possible way of describing the bonding situation is regarding each $\ce{CH2}$ entity as $sp^2$ hybridised. Two of these orbitals are used for $\ce{C-H}$-bonds (not shown) and one forms an inner two-electron-three-centre $\sigma$ bond (left). Leaving $p$-orbitals to form some kind of degenerate $\pi$-like orbitals (middle, right). 



This very general approach can be derived from a Walsh diagram. Schwarz et.al. {@academia.edu} and Hoffmann {@roaldhoffmann.com} described bonding quite similar and it is in quite good agreement with a calculation (BP86/cc-PVTZ, $D_{3h}$) I have done. From this I have prepared a chart of all occupied molecular orbitals formed from valence orbitals and the LUMO. Preview:



Especially the symmetrical orbital 8 resembles very well the schematics. A quite rigorous approach for this theory can also be found here.

It is noteworthy - as mentioned by ron - that there is no notable increase in electron density in the centre of the ring. This may be due to the fact that there are much more orbitals having nodes in the centre than there are without.



Now bromine is known to be easily polarised $\ce{{}^{\delta+}Br-Br^{\delta-}}$ and may intercept at any point of the ring causing a bond break and relaxation to a less strained structure. It will most likely attack at the the $\pi$ type orbitals since bromine is an electrophile. The mechanism is analogous to the addition of bromine to ethene, which is nicely described at chemguide.co.uk. The essential part is the attack of the bromine at the HOMO(s).



The ring opening reaction can be reversed by adding sodium.

However, when there are bromine radicals present (UV light) then substitution will occur:
\begin{aligned}\ce{
Br2 &amp;-&gt;[\ce{h\nu}] 2Br.\\
&amp;+(CH2)3 -&gt; (CH2)2(CHBr) + HBr
}\end{aligned}
"
3119,3119,4969,Another instructor is pushing me out of the classroom right after my class ends,"I am a graduate student in math in my final year, and for several years have been teaching at my department as a lecturer. This semester, in the same lecture hall there is another lecture that starts 20 minutes after my class ends. It's taught by another instructor from my department. I usually have many students coming to office hours and there are also students asking questions immediately after lecture. Due to other activities, I cannot have office hours right after the lecture this semester and can only stay for about 15 minutes to answer questions.

Many times in the past I had a similar situation and never had any issues with it. This semester the instructor who is teaching right after often arrives 20-15 minutes before her class starts and tells me immediately that I have to go with my students somewhere else. 

I make sure to leave the blackboard clean and take all my stuff away from the instructor's desk before she arrives, but I do believe that I have a right to stay in the classroom after my lecture for at least 5-10 minutes. There is no vacant classroom around, and I don't have time to go with students to my office, which is in a different building.

Last time the instructor told me in front of my students that I don't understand ""simple things"" and that I am ""playing games"". When I was talking to one of my students, she stood very close to us and clearly demonstrated that she wanted us out. I tried to explain her that I couldn't go anywhere else due to my time constraints, but she didn't want to listen to me. I really don't understand what ""simple"" things she meant and what ""games"" I am playing. 

We leave the board clean. She doesn't need to set up a projector. She can still talk to her students before her class starts, if she wants to (even though it seems like her students don't ask her any questions before their class). So, I don't see how I cause any disruption. 

I had met this woman many times before this semester, but we never talked. I didn't see her talking to other instructors/students much, and she seems to be quite reserved and a bit neurotic. She doesn't want to have any conversation with me regarding the issue.

I felt really offended after last class when she said those things to me in front of my students. What would you do in my case? 

Added later: There are no official rules regarding classroom occupancy between classes. Instructors are supposed to use common sense and be reasonable. For me using 50% of the break time seems reasonable to answer questions after lecture seems reasonable. I agree that for some people it may not.

I don't block the entrance to the classroom. A few students from the next class who come earlier always go ahead and take their seats as soon as my students start leaving the room. I also had one of the students from the next class listening to my explanation to one of those after-class questions and asking me further questions before their class (which is the same class as I am teaching, just a different section). Maybe the instructor got jealous, I don't know.

The entrance to the classroom is from its front (not back), so I do stay in the front. But it is a big lecture hall, and there is a plenty of space in front of the room (the board itself consists of 8 huge panels).

Also, during my career as a grad.student who is also teaching for the department, I have had several observations from experienced professors who are considered to be great teachers at the department and are in charge of undergraduate teaching policy. In my evaluations the fact that there are always several students approaching me with questions after class considered as very positive, meaning that students find me approachable. 

Thank you everyone for answers. 
",Lidd88,https://academia.stackexchange.com/users/31345,"So it seems strange that you can't have office hours right after this lecture, but you can, in fact, spend 15 minutes after the lecture time helping students.  It appears you could have 15 minutes of office hours right after this lecture.  Perhaps the travel time is excessive, or you have an aversion to setting up office hours of such short periods of time?

An option not already presented in other answers is to end your lecture 5-10 minutes early and encourage students to spend the remaining time working with each other, or asking you questions individually.

This would alleviate the issues you have with limited office time. I don't think it's a great choice, though, as lecture time is also valuable.

I think to root problem is convenience.  You find you can support your students better by providing some time at the end of class, which they already attend, to support them rather than expecting them to schedule time out of their day to visit you during normal office hours. You don't seem to suggest you don't have enough office hours, so it appears you are doing this purely as a convenience for your students.

You don't have a right to the classroom outside your lecture hours, save, perhaps, for several minutes before and after to set up the classroom if necessary.  Your use of the classroom as an informal office is a convenience.

If your university or college doesn't have rules regarding classroom use between lectures, or preparation/cleanup time, then I'd suggest it's fair for you and your students to vacate the room by the halfway point between your two lectures.  This doesn't mean ending your conversations ten minutes after your lecture, but being out of the room.

I suspect that she's only becoming more and more insistent as you are consistently going well over 10 minutes, and perhaps even infringing on her 5 minute preparation time.

Regardless, I believe your best bet in this case is to simply stand firm.  If she asks, tell her you and the students will be out ten minutes prior to her lecture start, and then stick to it aggressively so it's something she can count on.  She should, then, stop interrupting your activities and passive aggressively intruding on your after-lecture time. 
",Adam Davis,https://academia.stackexchange.com/users/11901,http://academia.stackexchange.com/questions/41133/another-instructor-is-pushing-me-out-of-the-classroom-right-after-my-class-ends,LIFE_ARTS,academia.stackexchange.com,1.0,0.5555555555555556,1.0,0.3333333333333333,0.0,0.0,0.6666666666666666,0.5555555555555556,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.7777777777777778,0.7777777777777778,0.7777777777777778,0.8888888888888888,1.0,0.9333333333333332,0.3333333333333333,0.0,0.6666666666666666,1.0,No sooner had I finished class than another teacher kicked me out of the classroom,"I am a graduate student in math in my final year, and for several years have been teaching at my department as a lecturer. This semester, in the same lecture hall there is another lecture that starts 20 minutes after my class ends. It's taught by another instructor from my department. I usually have many students coming to office hours and there are also students asking questions immediately after lecture. Due to other activities, I cannot have office hours right after the lecture this semester and can only stay for about 15 minutes to answer questions.

Many times in the past I had a similar situation and never had any issues with it. This semester the instructor who is teaching right after often arrives 20-15 minutes before her class starts and tells me immediately that I have to go with my students somewhere else. 

I make sure to leave the blackboard clean and take all my stuff away from the instructor's desk before she arrives, but I do believe that I have a right to stay in the classroom after my lecture for at least 5-10 minutes. There is no vacant classroom around, and I don't have time to go with students to my office, which is in a different building.

Last time the instructor told me in front of my students that I don't understand ""simple things"" and that I am ""playing games"". When I was talking to one of my students, she stood very close to us and clearly demonstrated that she wanted us out. I tried to explain her that I couldn't go anywhere else due to my time constraints, but she didn't want to listen to me. I really don't understand what ""simple"" things she meant and what ""games"" I am playing. 

We leave the board clean. She doesn't need to set up a projector. She can still talk to her students before her class starts, if she wants to (even though it seems like her students don't ask her any questions before their class). So, I don't see how I cause any disruption. 

I had met this woman many times before this semester, but we never talked. I didn't see her talking to other instructors/students much, and she seems to be quite reserved and a bit neurotic. She doesn't want to have any conversation with me regarding the issue.

I felt really offended after last class when she said those things to me in front of my students. What would you do in my case? 

Added later: There are no official rules regarding classroom occupancy between classes. Instructors are supposed to use common sense and be reasonable. For me using 50% of the break time seems reasonable to answer questions after lecture seems reasonable. I agree that for some people it may not.

I don't block the entrance to the classroom. A few students from the next class who come earlier always go ahead and take their seats as soon as my students start leaving the room. I also had one of the students from the next class listening to my explanation to one of those after-class questions and asking me further questions before their class (which is the same class as I am teaching, just a different section). Maybe the instructor got jealous, I don't know.

The entrance to the classroom is from its front (not back), so I do stay in the front. But it is a big lecture hall, and there is a plenty of space in front of the room (the board itself consists of 8 huge panels).

Also, during my career as a grad.student who is also teaching for the department, I have had several observations from experienced professors who are considered to be great teachers at the department and are in charge of undergraduate teaching policy. In my evaluations the fact that there are always several students approaching me with questions after class considered as very positive, meaning that students find me approachable. 

Thank you everyone for answers. 
","So it seems strange that you can't have office hours right after this lecture, but you can, in fact, spend 15 minutes after the lecture time helping students.  It appears you could have 15 minutes of office hours right after this lecture.  Perhaps the travel time is excessive, or you have an aversion to setting up office hours of such short periods of time?

An option not already presented in other answers is to end your lecture 5-10 minutes early and encourage students to spend the remaining time working with each other, or asking you questions individually.

This would alleviate the issues you have with limited office time. I don't think it's a great choice, though, as lecture time is also valuable.

I think to root problem is convenience.  You find you can support your students better by providing some time at the end of class, which they already attend, to support them rather than expecting them to schedule time out of their day to visit you during normal office hours. You don't seem to suggest you don't have enough office hours, so it appears you are doing this purely as a convenience for your students.

You don't have a right to the classroom outside your lecture hours, save, perhaps, for several minutes before and after to set up the classroom if necessary.  Your use of the classroom as an informal office is a convenience.

If your university or college doesn't have rules regarding classroom use between lectures, or preparation/cleanup time, then I'd suggest it's fair for you and your students to vacate the room by the halfway point between your two lectures.  This doesn't mean ending your conversations ten minutes after your lecture, but being out of the room.

I suspect that she's only becoming more and more insistent as you are consistently going well over 10 minutes, and perhaps even infringing on her 5 minute preparation time.

Regardless, I believe your best bet in this case is to simply stand firm.  If she asks, tell her you and the students will be out ten minutes prior to her lecture start, and then stick to it aggressively so it's something she can count on.  She should, then, stop interrupting your activities and passive aggressively intruding on your after-lecture time. 
"
1871,1871,2972,Georeferencing uneven/irregularly gridded rasters,"I'm trying to take a set of NetCDFs and turn them into georeferenced datasets using GDAL.

However, the only Geospatial data is a set of 2-D lat/lon arrays. The projection type is not lat/lon. THe arrays give the lat/lon of every individual cell.

I can't use a geotransform to reference the data because of the irregular gridding.

How can I create a dataset (such as a GeoTiff) that properly references the data? Ideally I would then warp to some even grid.

EDIT: I tried using an even spread of Ground Control Points, but the resulting GeoTiff did not display correctly... Despite giving GCPs up to 90 deg lat, ArcMap claims the GTiff has an extent ending at 70 deg latitude...

EDIT: Thanks to everyone for their help. I was able to solve the issue using gdalwarp -geoloc as  suggested. I created 3 VRTs (1 with cell values, 1 with latitude, 1 with longitude), and wrote the lat/lon vrts in a geoarrays in the data vrt metadata. Then using gdalwarp -geoloc worked like a charm.

The issue with extent was unrelated and due simply to the large difference between the original coordinate system and lat/lon. It was solved by explicitely stating the extent instead of having GDAL try to guess what it should be. (i.e. I added -te -180 0 180 90 to the gdalwarp line)

Thanks everyone!
",JFerg,https://gis.stackexchange.com/users/40581,"gdalwarp -geoloc allows you to use the complete 2d-array of latlon as georeference. With that, you can use any target CRS to reproject your data to a commonly used projection.

See my answer to this question for an example:

How to match a raster NetCDF data with a vector layer in QGIS?
",AndreJ,https://gis.stackexchange.com/users/9159,http://gis.stackexchange.com/questions/137331/georeferencing-uneven-irregularly-gridded-rasters,TECHNOLOGY,gis.stackexchange.com,1.0,0.3333333333333333,0.0,0.6666666666666666,0.3333333333333333,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.5555555555555556,1.0,0.5555555555555556,1.0,1.0,0.8,1.0,0.0,0.0,0.8888888888888888,Georeferenced uneven / irregular grid raster,"I'm trying to take a set of NetCDFs and turn them into georeferenced datasets using GDAL.

However, the only Geospatial data is a set of 2-D lat/lon arrays. The projection type is not lat/lon. THe arrays give the lat/lon of every individual cell.

I can't use a geotransform to reference the data because of the irregular gridding.

How can I create a dataset (such as a GeoTiff) that properly references the data? Ideally I would then warp to some even grid.

EDIT: I tried using an even spread of Ground Control Points, but the resulting GeoTiff did not display correctly... Despite giving GCPs up to 90 deg lat, ArcMap claims the GTiff has an extent ending at 70 deg latitude...

EDIT: Thanks to everyone for their help. I was able to solve the issue using gdalwarp -geoloc as  suggested. I created 3 VRTs (1 with cell values, 1 with latitude, 1 with longitude), and wrote the lat/lon vrts in a geoarrays in the data vrt metadata. Then using gdalwarp -geoloc worked like a charm.

The issue with extent was unrelated and due simply to the large difference between the original coordinate system and lat/lon. It was solved by explicitely stating the extent instead of having GDAL try to guess what it should be. (i.e. I added -te -180 0 180 90 to the gdalwarp line)

Thanks everyone!
","gdalwarp -geoloc allows you to use the complete 2d-array of latlon as georeference. With that, you can use any target CRS to reproject your data to a commonly used projection.

See my answer to this question for an example:

How to match a raster NetCDF data with a vector layer in QGIS?
"
5834,5834,9247,Scrabble variation: use double and triple word scores (but not double/triple letter scores) twice?,"Is there a popular Scrabble variation that: 


lets you play double/triple word scores twice, once vertically and 
once horizontally? 
does NOT let you play double/triple letter scores twice? 


This is how I've always played, so it surprised me to learn that 
official Scrabble rules do NOT permit using double/triple word scores 
twice. 

Perhaps this was true in an older version of Scrabble (I started 
playing in the 70s). 
",barrycarter,https://boardgames.stackexchange.com/users/639,"I searched Changes to the Box Top Rules, 1949 - 1999 and found the following clarification was made in 1953:


  1953: If a word is formed that covers two premium WORD squares, the score is doubled and then re-doubled (4 times letter count), or tripled and then re-tripled (9 times letter count) as the case may be.


Nowhere in the rules was there any mention of being able to use the same premium square twice.

The Diamond Anniversary Edition rules includes some interesting variations, but does not mention your scoring rules.

Personally, I would find your scoring variation confusing and prone to error, since Scrabble tiles are not transparent, and therefore a novice may have trouble realizing that they are reusing a premium word square.
",ghoppe,https://boardgames.stackexchange.com/users/632,http://boardgames.stackexchange.com/questions/9118/scrabble-variation-use-double-and-triple-word-scores-but-not-double-triple-let,CULTURE,boardgames.stackexchange.com,1.0,0.8888888888888888,0.0,0.0,1.0,1.0,0.6666666666666666,0.8888888888888888,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.0,0.6666666666666666,1.0,Spelling change: use two and three word scores (not two / three letter scores) twice?,"Is there a popular Scrabble variation that: 


lets you play double/triple word scores twice, once vertically and 
once horizontally? 
does NOT let you play double/triple letter scores twice? 


This is how I've always played, so it surprised me to learn that 
official Scrabble rules do NOT permit using double/triple word scores 
twice. 

Perhaps this was true in an older version of Scrabble (I started 
playing in the 70s). 
","I searched Changes to the Box Top Rules, 1949 - 1999 and found the following clarification was made in 1953:


  1953: If a word is formed that covers two premium WORD squares, the score is doubled and then re-doubled (4 times letter count), or tripled and then re-tripled (9 times letter count) as the case may be.


Nowhere in the rules was there any mention of being able to use the same premium square twice.

The Diamond Anniversary Edition rules includes some interesting variations, but does not mention your scoring rules.

Personally, I would find your scoring variation confusing and prone to error, since Scrabble tiles are not transparent, and therefore a novice may have trouble realizing that they are reusing a premium word square.
"
4793,4793,7609,SQL Server: update table from xml string,"this is the first time I am working with an XML input in SQL. 

I created the following procedure to insert all records from my XML string into my table which works well so far. 

Can someone tell me how I have to change this so that it only inserts a record as new if the itemID (every record in my XML has this as well) does not yet exist in my table, column itemID - otherwise it should update the existing record with the new data from the XML. 

I know how to use IF NOT EXISTS and UPDATE in general but am not sure how to realise this with an XML string as the input. 

My procedure (so far): 

ALTER PROCEDURE [dbo].[editor_UpdateQuestions]
    @xml xml
AS
BEGIN
    SET NOCOUNT ON;

    INSERT INTO editor_Questions
        (
            categoryID,
            question,
            sortID,
            modDate,
            modBy       
        )
    SELECT  ParamValues.x1.value('categoryID[1]', 'int'),
            ParamValues.x1.value('question[1]', 'nvarchar(1000)'),
            ParamValues.x1.value('sortID[1]', 'int'),
            GETDATE(),
            ParamValues.x1.value('modBy[1]', 'varchar(50)')
    FROM    @xml.nodes('/ranks/item') AS ParamValues(x1)

END


Example XML input:

&lt;ranks&gt;
    &lt;item&gt;&lt;itemID&gt;25&lt;/itemID&gt;&lt;categoryID&gt;1&lt;/categoryID&gt;&lt;question&gt;some text&lt;/question&gt;&lt;sortID&gt;1&lt;/sortID&gt;&lt;modBy&gt;abc&lt;/modBy&gt;&lt;/item&gt;
    &lt;item&gt;&lt;itemID&gt;12&lt;/itemID&gt;&lt;categoryID&gt;1&lt;/categoryID&gt;&lt;question&gt;some text 2&lt;/question&gt;&lt;sortID&gt;2&lt;/sortID&gt;&lt;modBy&gt;abc&lt;/modBy&gt;&lt;/item&gt;
    &lt;item&gt;&lt;itemID&gt;9&lt;/itemID&gt;&lt;categoryID&gt;1&lt;/categoryID&gt;&lt;question&gt;some text 3&lt;/question&gt;&lt;sortID&gt;3&lt;/sortID&gt;&lt;modBy&gt;abc&lt;/modBy&gt;&lt;/item&gt;
&lt;/ranks&gt;


Many thanks in advance for any help with this, Tim.
",user2571510,https://stackoverflow.com/users/2571510,"You can use merge statement as below

MERGE editor_Questions AS Target
    USING (
    SELECT  ParamValues.x1.value('categoryID[1]', 'int') AS categoryID,
            ParamValues.x1.value('question[1]', 'nvarchar(1000)') AS question,
            ParamValues.x1.value('sortID[1]', 'int') AS sortID,
            GETDATE() AS [Date],
            ParamValues.x1.value('modBy[1]', 'varchar(50)') AS ModBy
    FROM    @xml.nodes('/ranks/item') AS ParamValues(x1)

    ) AS SOURCE
    ON Target.categoryID =SOURCE.categoryID
    WHEN MATCHED THEN 
    UPDATE SET Target.question = Source.question,
            Target.sortID = Source.sortID,
            Target.modDate=Source.[Date],
            Target.ModBy = Source.ModBy
    WHEN NOT MATCHED  THEN
    INSERT 
        (
            categoryID,
            question,
            sortID,
            modDate,
            modBy       
        )
    VALUES  (categoryID,question,sortID,[Date],ModBy);

",Kiran Hegde,https://stackoverflow.com/users/875134,http://stackoverflow.com/questions/24167421/sql-server-update-table-from-xml-string,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,0.8888888888888888,SQL Server: updating tables from XML strings,"this is the first time I am working with an XML input in SQL. 

I created the following procedure to insert all records from my XML string into my table which works well so far. 

Can someone tell me how I have to change this so that it only inserts a record as new if the itemID (every record in my XML has this as well) does not yet exist in my table, column itemID - otherwise it should update the existing record with the new data from the XML. 

I know how to use IF NOT EXISTS and UPDATE in general but am not sure how to realise this with an XML string as the input. 

My procedure (so far): 

ALTER PROCEDURE [dbo].[editor_UpdateQuestions]
    @xml xml
AS
BEGIN
    SET NOCOUNT ON;

    INSERT INTO editor_Questions
        (
            categoryID,
            question,
            sortID,
            modDate,
            modBy       
        )
    SELECT  ParamValues.x1.value('categoryID[1]', 'int'),
            ParamValues.x1.value('question[1]', 'nvarchar(1000)'),
            ParamValues.x1.value('sortID[1]', 'int'),
            GETDATE(),
            ParamValues.x1.value('modBy[1]', 'varchar(50)')
    FROM    @xml.nodes('/ranks/item') AS ParamValues(x1)

END


Example XML input:

&lt;ranks&gt;
    &lt;item&gt;&lt;itemID&gt;25&lt;/itemID&gt;&lt;categoryID&gt;1&lt;/categoryID&gt;&lt;question&gt;some text&lt;/question&gt;&lt;sortID&gt;1&lt;/sortID&gt;&lt;modBy&gt;abc&lt;/modBy&gt;&lt;/item&gt;
    &lt;item&gt;&lt;itemID&gt;12&lt;/itemID&gt;&lt;categoryID&gt;1&lt;/categoryID&gt;&lt;question&gt;some text 2&lt;/question&gt;&lt;sortID&gt;2&lt;/sortID&gt;&lt;modBy&gt;abc&lt;/modBy&gt;&lt;/item&gt;
    &lt;item&gt;&lt;itemID&gt;9&lt;/itemID&gt;&lt;categoryID&gt;1&lt;/categoryID&gt;&lt;question&gt;some text 3&lt;/question&gt;&lt;sortID&gt;3&lt;/sortID&gt;&lt;modBy&gt;abc&lt;/modBy&gt;&lt;/item&gt;
&lt;/ranks&gt;


Many thanks in advance for any help with this, Tim.
","You can use merge statement as below

MERGE editor_Questions AS Target
    USING (
    SELECT  ParamValues.x1.value('categoryID[1]', 'int') AS categoryID,
            ParamValues.x1.value('question[1]', 'nvarchar(1000)') AS question,
            ParamValues.x1.value('sortID[1]', 'int') AS sortID,
            GETDATE() AS [Date],
            ParamValues.x1.value('modBy[1]', 'varchar(50)') AS ModBy
    FROM    @xml.nodes('/ranks/item') AS ParamValues(x1)

    ) AS SOURCE
    ON Target.categoryID =SOURCE.categoryID
    WHEN MATCHED THEN 
    UPDATE SET Target.question = Source.question,
            Target.sortID = Source.sortID,
            Target.modDate=Source.[Date],
            Target.ModBy = Source.ModBy
    WHEN NOT MATCHED  THEN
    INSERT 
        (
            categoryID,
            question,
            sortID,
            modDate,
            modBy       
        )
    VALUES  (categoryID,question,sortID,[Date],ModBy);

"
3472,3472,5536,"PCB design cost for 0.4mm pitch bga, 0.1mm drill hole, 4-layer routing using via-in-pad","I am doing a development board for a IC with 36 WLCSP package. My PCB layout has 16 via over pads, minimum 0.1mm drill holes, 4-layers. I need to fabricate my PCB. And I could not find a exact pricing for PCBs in the required design quality. I sent sample Gerber file for some PCB manufacturers. And they replied with extreme high prices and I can't afford their pricing (eg: 200$ for 10 boards with 2.5cm * 2.5cm). And most of manufactures are not willing to share their pricing strategy to optimize my design.

My target is to deliver my demo board for the lowest price (to make it lower than 10$, while component cost around 6.5$) . So I need to keep the PCB cost lower than 2$ with the minimum area of 2cm * 2cm. 



Could I achieve that much lower PCB cost?
what are the possible PCB fabricators with lower cost with required technology?
What would be the unit PCB cost if fabricate at least 500 boards?
Feasibility of my project to make it under 10$?


Thank you
",user3478108,https://electronics.stackexchange.com/users/77308,"You can develop via on pad as well the prototyping cost for 10 units will be higher but when you are going for 500 units and more than that is for sure that your price will be near above 2$ excluding shipping. 

As per your specification the 10 Unit 15 days delivery will cost you 12$ / Unit + Shipping.

Minimum Drill hole should be 6 mill = 0.2 mm 

500 Units Production = 1$ + Shipping. 

Yes it is feasable to make your project under 10$.
",Dhrumil Shah,https://electronics.stackexchange.com/users/77321,http://electronics.stackexchange.com/questions/172345/pcb-design-cost-for-0-4mm-pitch-bga-0-1mm-drill-hole-4-layer-routing-using-via,TECHNOLOGY,electronics.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,1.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.3333333333333333,0.6666666666666666,0.8888888888888888,"PCB design cost of 0.4mm BGA, 0.1mm drilling, 4-layer wiring (via in PAD)","I am making a 36 WLCSP integrated circuit development board. My PCB layout has 16 through-hole pads with a minimum of 0.1mm drilled holes and 4 layers. I need to make my PCB. I also couldn't find a precise price for PCBs in the required design quality. I sent samples of Gerber documents to some PCB manufacturers. They replied to me at a very high price, and I couldn't afford their price (for example: 2.5cm * 2.5cm, 10 boards, 200 dollars). And most vendors are reluctant to share their pricing strategies to optimize my design.","You can develop via on pad as well the prototyping cost for 10 units will be higher but when you are going for 500 units and more than that is for sure that your price will be near above 2$ excluding shipping. 

As per your specification the 10 Unit 15 days delivery will cost you 12$ / Unit + Shipping.

Minimum Drill hole should be 6 mill = 0.2 mm 

500 Units Production = 1$ + Shipping. 

Yes it is feasable to make your project under 10$.
"
4950,4950,7883,Extending Internal Link and External Link to allow selection of Images,"I need to extend selection of external and Internal Link and provide a image selection.

Please see the snapshot in the below :


Here the above snapshot allows you to add properties for External Link.In the same popup can we add a field Called Image(as shown in screenshot) which will allow user to select images from the media library??

Thanks,
Suhas
",Suhas,https://stackoverflow.com/users/998504,"You can actually extend any dialog by editing the xml files in /shell/Applications/Dialogs

In another thread I have shown how to add a maxlength to the title field, that should help you get on your way: Sitecore 7:Limit number of Characters entered for Link Title Field in General Link
",RvanDalen,https://stackoverflow.com/users/3568203,http://stackoverflow.com/questions/23337280/extending-internal-link-and-external-link-to-allow-selection-of-images,STACKOVERFLOW,stackoverflow.com,1.0,0.5555555555555556,0.0,0.6666666666666666,0.3333333333333333,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,1.0,0.6666666666666666,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.5555555555555556,0.8888888888888888,0.6666666666666666,1.0,1.0,0.6666666666666667,1.0,0.0,0.0,0.7777777777777778,Expand internal and external links to allow image selection,"I need to extend selection of external and Internal Link and provide a image selection.

Please see the snapshot in the below :


Here the above snapshot allows you to add properties for External Link.In the same popup can we add a field Called Image(as shown in screenshot) which will allow user to select images from the media library??

Thanks,
Suhas
","You can actually extend any dialog by editing the xml files in /shell/Applications/Dialogs

In another thread I have shown how to add a maxlength to the title field, that should help you get on your way: Sitecore 7:Limit number of Characters entered for Link Title Field in General Link
"
2846,2846,4529,Odd sound after tire rotation?,"About two days ago I got my tires rotated on my 2005 Chevy Cobalt while I was getting an oil change. This was the first time that the tires had been rotated in at least 14,000 miles (since I purchased the car). The car itself has about 36,000 miles, so I'd assume that's the age of the tires.

Anyways, whenever I go above 30 mph I hear a helicopter like sound, and it ramps up the faster I go.

Here's two videos I've recorded:


http://youtu.be/bb0gZGLJJ5M  
http://youtu.be/Ol6MMqPVfgQ


I've read that it can be caused by waiting too long to get the tires rotated, as they start to wear into a pattern, which can cause the noise.
",Josh Foskett,https://mechanics.stackexchange.com/users/3176,"Rotated or swopped back to front? Check on the tyres side wall for the word 'Rotation'. There will also be an arrow or indicater for the direction of rotation when driving forward. They must be on the correct side of the vehicle and rotating in a forward direction. The age of your tyres can be found by reading the DOT code on the tyre wall. You will see the word 'DOT' next to a box with four numbers within it. The first two numbers are for 'the week of the year', whilst the second two numbers are for 'year of manufacture'. ie. DOT 2414 would mean twenty-fourth week of 2014, which is when the tyre was produced.
",Allan Osborne,https://mechanics.stackexchange.com/users/3975,http://mechanics.stackexchange.com/questions/12242/odd-sound-after-tire-rotation,CULTURE,mechanics.stackexchange.com,1.0,0.5555555555555556,0.0,0.3333333333333333,1.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,1.0,0.0,0.8888888888888888,0.7777777777777778,0.5555555555555556,1.0,0.7777777777777778,0.6666666666666667,0.3333333333333333,0.6666666666666666,0.6666666666666666,1.0,Does the tyre make a strange noise after turning?,"About two days ago I got my tires rotated on my 2005 Chevy Cobalt while I was getting an oil change. This was the first time that the tires had been rotated in at least 14,000 miles (since I purchased the car). The car itself has about 36,000 miles, so I'd assume that's the age of the tires.

Anyways, whenever I go above 30 mph I hear a helicopter like sound, and it ramps up the faster I go.

Here's two videos I've recorded:


http://youtu.be/bb0gZGLJJ5M  
http://youtu.be/Ol6MMqPVfgQ


I've read that it can be caused by waiting too long to get the tires rotated, as they start to wear into a pattern, which can cause the noise.
","Rotated or swopped back to front? Check on the tyres side wall for the word 'Rotation'. There will also be an arrow or indicater for the direction of rotation when driving forward. They must be on the correct side of the vehicle and rotating in a forward direction. The age of your tyres can be found by reading the DOT code on the tyre wall. You will see the word 'DOT' next to a box with four numbers within it. The first two numbers are for 'the week of the year', whilst the second two numbers are for 'year of manufacture'. ie. DOT 2414 would mean twenty-fourth week of 2014, which is when the tyre was produced.
"
3039,3039,4847,How detect which OpenGL texture formats are natively supported?,"For example, how detect if my videocard doesn’t support ""bgr8"" and convert it to another format, such as ""rgba8"" in software mode.

UPDATE: Sorry for the confusion. This question more about situation when I set internalFormat in glTexImage2D to something like ""bgra8"" but videodriver internally convert data to another format, like ""rgba8"".
",KindDragon,https://gamedev.stackexchange.com/users/8399,"Generally most hardware doesn't suport 3-component texture formats so in this specific example you can make a reasonably safe assumption that it's converted.  A 3-component OpenGL texture is actually 4-component in hardware but with the alpha component ignored/set to 255/whatever.

http://www.opengl.org/wiki/Common_Mistakes#Texture_upload_and_pixel_reads
(That ""common mistakes"" page is a goldmine - bookmark it now!)

For a more general case, glTexSubImage2D performance can give you a good indication of whether or not the upload must go through a software conversion path.  You'd go about this during program startup - just create an empty texture (via glTexImage2D with NULL data), then issue a bunch of glTexSubImage2D calls, each followed by a glFinish to ensure it completes.  Ignore the first one because caches/states/etc are being setup for it, and time the rest of them.  Repeat this for a few different formats and pick the fastest.

Another alternative - seeing as you've tagged this question ""Windows"" - is to create a D3D device at startup (just after you've created your window but before you init OpenGL) then use D3D to check for format support.  While OpenGL allows for software conversion to a valid internal format, D3D doesn't - if it's not supported by the hardware you can't do it.  Then destroy D3D and bring up OpenGL.  (This technique can also be used for querying other stuff that OpenGL doesn't let you query directly).

It's actually a useful rule of thumb to cross-check what you're doing in OpenGL with the D3D documentation.  If D3D can't do something then it can be a good indication that the something in question is not supported in hardware.  Not always true, but a useful starting place.
",Maximus Minimus,https://gamedev.stackexchange.com/users/9134,http://gamedev.stackexchange.com/questions/17587/how-detect-which-opengl-texture-formats-are-natively-supported,TECHNOLOGY,gamedev.stackexchange.com,0.7777777777777778,0.8888888888888888,0.0,0.0,1.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.9,1.0,0.0,0.0,1.0,How to detect which OpenGL texture formats are natively supported?,"For example, how detect if my videocard doesn’t support ""bgr8"" and convert it to another format, such as ""rgba8"" in software mode.

UPDATE: Sorry for the confusion. This question more about situation when I set internalFormat in glTexImage2D to something like ""bgra8"" but videodriver internally convert data to another format, like ""rgba8"".
","Generally most hardware doesn't suport 3-component texture formats so in this specific example you can make a reasonably safe assumption that it's converted.  A 3-component OpenGL texture is actually 4-component in hardware but with the alpha component ignored/set to 255/whatever.

http://www.opengl.org/wiki/Common_Mistakes#Texture_upload_and_pixel_reads
(That ""common mistakes"" page is a goldmine - bookmark it now!)

For a more general case, glTexSubImage2D performance can give you a good indication of whether or not the upload must go through a software conversion path.  You'd go about this during program startup - just create an empty texture (via glTexImage2D with NULL data), then issue a bunch of glTexSubImage2D calls, each followed by a glFinish to ensure it completes.  Ignore the first one because caches/states/etc are being setup for it, and time the rest of them.  Repeat this for a few different formats and pick the fastest.

Another alternative - seeing as you've tagged this question ""Windows"" - is to create a D3D device at startup (just after you've created your window but before you init OpenGL) then use D3D to check for format support.  While OpenGL allows for software conversion to a valid internal format, D3D doesn't - if it's not supported by the hardware you can't do it.  Then destroy D3D and bring up OpenGL.  (This technique can also be used for querying other stuff that OpenGL doesn't let you query directly).

It's actually a useful rule of thumb to cross-check what you're doing in OpenGL with the D3D documentation.  If D3D can't do something then it can be a good indication that the something in question is not supported in hardware.  Not always true, but a useful starting place.
"
3067,3067,4884,Instrinsic definition of concave and convex polyhedron,"Is it possible to distinguish a concave polyhedron from a convex one by mesurements made only on its surface, without a reference to the 3d space around it?
",Leos Ondra,https://math.stackexchange.com/users/96188,"In general, any polyhedron, subtending a solid angle $\Omega&lt;2\pi$ sr at each of its vertices, is called a convex polyhedron. 

While any polyhedron, subtending a solid angle $\Omega&gt;2\pi$ sr at any of its vertices, is called a concave polyhedron. 

It is very practical that a convex polyhedron has its each vertex elevated (protruding outward) while a concave polyhedron has any of its vertices indented on the surface.      
",Harish Chandra Rajpoot,https://math.stackexchange.com/users/210295,http://math.stackexchange.com/questions/509726/instrinsic-definition-of-concave-and-convex-polyhedron,SCIENCE,math.stackexchange.com,0.8888888888888888,0.4444444444444444,0.0,0.3333333333333333,1.0,1.0,0.5555555555555556,0.3333333333333333,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,0.8888888888888888,Inner definition of concave convex polyhedron,"Is it possible to distinguish a concave polyhedron from a convex polyhedron by measuring only on its surface, without reference to the three-dimensional space around it?","In general, any polyhedron, subtending a solid angle $\Omega&lt;2\pi$ sr at each of its vertices, is called a convex polyhedron. 

While any polyhedron, subtending a solid angle $\Omega&gt;2\pi$ sr at any of its vertices, is called a concave polyhedron. 

It is very practical that a convex polyhedron has its each vertex elevated (protruding outward) while a concave polyhedron has any of its vertices indented on the surface.      
"
760,760,1203,jQuery - Adding a hyphen inside string,"I am pulling the text from a select box's options. Now I pass this string value to an append() function, but I want to add a hyphen to the string, for calling an image name:

HTML:

&lt;select&gt;
    &lt;option&gt;Demo Cars&lt;/option&gt;
    &lt;option&gt;New Cars&lt;/option&gt;
    &lt;option&gt;Used Cars&lt;/option&gt;
    &lt;option&gt;Other&lt;/option&gt;
&lt;/select&gt;




var p = 'http://myurl.com/images/';
$('select').eq(0).on('change',function(){
    $('#productQuote').empty();
    var j = $(this).children(':selected').val(); 
    $('#productQuote').append('&lt;img src=""'+ p + j + '.jpg' '"" /&gt;');
}); 


For example:

If I choose the first select option, the string will be: ""Demo Cars"", and thus, j == ""Demo Cars"".

But now I want to call its image, and my image names are not allowed to have spaces inside them. 
So, this begs the question, how do I add a hyphen between Demo and Cars?    
",DextrousDave,https://stackoverflow.com/users/1140828,"There are many simple ways to do this, each with different purpose at times. Here are a couple simple ways to do this ""inline"", without affecting much of your already usable code:

With .replace() (The downside is if you have more than one white space, it won't replace them all. This can be remidied with regex, as I'll show below, or split join)

 $('#productQuote').append('&lt;img src=""'+ p + j.replace("" "", ""-"") + '.jpg"" /&gt;');


Replace ALL style:

$('#productQuote').append('&lt;img src=""'+ p + j.replace(/ /g, ""-"") + '.jpg"" /&gt;');


With the team of .split().join()

$('#productQuote').append('&lt;img src=""'+ p + j.split("" "").join(""-"") + '.jpg"" /&gt;');

",SpYk3HH,https://stackoverflow.com/users/900807,http://stackoverflow.com/questions/16278701/jquery-adding-a-hyphen-inside-string,STACKOVERFLOW,stackoverflow.com,0.6666666666666666,0.3333333333333333,0.0,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,0.6666666666666666,0.6666666666666666,1.0,1.0,1.0,0.0,1.0,0.0,1.0,JQuery - add hyphens to strings,"I am pulling the text from a select box's options. Now I pass this string value to an append() function, but I want to add a hyphen to the string, for calling an image name:

HTML:

&lt;select&gt;
    &lt;option&gt;Demo Cars&lt;/option&gt;
    &lt;option&gt;New Cars&lt;/option&gt;
    &lt;option&gt;Used Cars&lt;/option&gt;
    &lt;option&gt;Other&lt;/option&gt;
&lt;/select&gt;




var p = 'http://myurl.com/images/';
$('select').eq(0).on('change',function(){
    $('#productQuote').empty();
    var j = $(this).children(':selected').val(); 
    $('#productQuote').append('&lt;img src=""'+ p + j + '.jpg' '"" /&gt;');
}); 


For example:

If I choose the first select option, the string will be: ""Demo Cars"", and thus, j == ""Demo Cars"".

But now I want to call its image, and my image names are not allowed to have spaces inside them. 
So, this begs the question, how do I add a hyphen between Demo and Cars?    
","There are many simple ways to do this, each with different purpose at times. Here are a couple simple ways to do this ""inline"", without affecting much of your already usable code:

With .replace() (The downside is if you have more than one white space, it won't replace them all. This can be remidied with regex, as I'll show below, or split join)

 $('#productQuote').append('&lt;img src=""'+ p + j.replace("" "", ""-"") + '.jpg"" /&gt;');


Replace ALL style:

$('#productQuote').append('&lt;img src=""'+ p + j.replace(/ /g, ""-"") + '.jpg"" /&gt;');


With the team of .split().join()

$('#productQuote').append('&lt;img src=""'+ p + j.split("" "").join(""-"") + '.jpg"" /&gt;');

"
2449,2449,3909,Can the update manager download only a single package at a time?,"I need the update manager to only download a single package at a time and not try to download multiple packages at once.

My slow internet cannot handle multiple connections; slows the download to a crawl and some packages will reset themselves halfway through when they time-out.

EDIT

When using apt-get update multiple repositories get checked:


When using apt-get upgrade multiple packages are downloaded:

",SaultDon,https://askubuntu.com/users/22554,"Right click in the window area that lists the updates > Deselect All, then enable individually. Some packages will require more than one at once, U-M will auto-select when needed
",doug,https://askubuntu.com/users/27773,http://askubuntu.com/questions/88731/can-the-update-manager-download-only-a-single-package-at-a-time,TECHNOLOGY,askubuntu.com,0.8888888888888888,0.5555555555555556,0.0,0.6666666666666666,1.0,1.0,0.6666666666666666,0.4444444444444444,0.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.3333333333333333,0.3333333333333333,0.8888888888888888,Can update manager download only one package at a time?,"I need the update manager to only download a single package at a time and not try to download multiple packages at once.

My slow internet cannot handle multiple connections; slows the download to a crawl and some packages will reset themselves halfway through when they time-out.

EDIT

When using apt-get update multiple repositories get checked:


When using apt-get upgrade multiple packages are downloaded:

","Right click in the window area that lists the updates > Deselect All, then enable individually. Some packages will require more than one at once, U-M will auto-select when needed
"
3279,3279,5224,"Can the word ""facet"" be used in a sentence like this one?","
  
  Leadership skills are also a valued facet in a friend. 
  


Can facet be used in this way?
",Kaylin Brantley,https://english.stackexchange.com/users/88870,"Usually you use the preposition ""of"" when talking about facets. And I've not seen it commonly being used when referring to persons. It's more commonly used when talking about inanimate objects or intangible ideas.

So a statement like ""Decisiveness is an important facet of leadership"" is perfectly natural and correct.

But ""Leadership skills are also a valued facet of a friend"" still sounds ""off"" to my ear.

Words like ""trait"" and ""virtue"" are preferred when talking about people.

Why not: ""Leadership skills are also a valued trait of a friend"".

Or: ""Leadership skills are also a valued virtue of a friend""?

You can also substitute the preposition ""in"" for ""of"" in the latter two suggestions I gave.
",Deepak,https://english.stackexchange.com/users/88871,http://english.stackexchange.com/questions/192473/can-the-word-facet-be-used-in-a-sentence-like-this-one,CULTURE,english.stackexchange.com,1.0,0.3333333333333333,0.3333333333333333,1.0,0.6666666666666666,1.0,0.6666666666666666,0.8333333333333334,0.0,0.0,1.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.6666666666666666,1.0,0.8333333333333334,1.0,1.0,0.8,0.0,0.0,0.6666666666666666,0.6666666666666666,"Can the word ""facet"" be used in such a sentence?",Leadership is also an important aspect of friends.,"Usually you use the preposition ""of"" when talking about facets. And I've not seen it commonly being used when referring to persons. It's more commonly used when talking about inanimate objects or intangible ideas.

So a statement like ""Decisiveness is an important facet of leadership"" is perfectly natural and correct.

But ""Leadership skills are also a valued facet of a friend"" still sounds ""off"" to my ear.

Words like ""trait"" and ""virtue"" are preferred when talking about people.

Why not: ""Leadership skills are also a valued trait of a friend"".

Or: ""Leadership skills are also a valued virtue of a friend""?

You can also substitute the preposition ""in"" for ""of"" in the latter two suggestions I gave.
"
2242,2242,3573,How to access beans from the applicationContext.xml in my service layer.,"How to access beans from the applicationContext.xml in my service layer.

I am working on a Spring Web MVC project and that issue is that my service layer needs a URL, User ID and Password to do a web post to a server to save my data.  I dont want to hardcode the URL, User ID and password in the Java Code of the Service Layer so I would like to put them into the applicationContent.xml file but I dont know how to access them from the service layer.

Can someone please help me out with this..  example code would be great.
",Java Review,https://stackoverflow.com/users/589450,"If your service is already a Spring managed bean, it should be trivial:

Add 3 properties to your service class (url, userId and password) along with their corresponding setters. Then you can set the values via your context:

&lt;bean id=""yourService"" class=""xxx.yyy.zz.YourService""&gt;
  &lt;property name=""url"" value=""http://someurl.com""/&gt;
  &lt;property name=""userId"" value=""username""/&gt;
  &lt;property name=""password"" value=""passwd""/&gt;
&lt;/bean&gt;

",Chris,https://stackoverflow.com/users/139506,http://stackoverflow.com/questions/8330372/how-to-access-beans-from-the-applicationcontext-xml-in-my-service-layer,STACKOVERFLOW,stackoverflow.com,0.6666666666666666,0.4444444444444444,0.0,0.0,1.0,0.0,0.3333333333333333,0.3333333333333333,1.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.8,1.0,0.3333333333333333,0.0,0.8888888888888888,How to access beans from applicationcontext.xml in my service layer.,"How to access beans from the applicationContext.xml in my service layer.

I am working on a Spring Web MVC project and that issue is that my service layer needs a URL, User ID and Password to do a web post to a server to save my data.  I dont want to hardcode the URL, User ID and password in the Java Code of the Service Layer so I would like to put them into the applicationContent.xml file but I dont know how to access them from the service layer.

Can someone please help me out with this..  example code would be great.
","If your service is already a Spring managed bean, it should be trivial:

Add 3 properties to your service class (url, userId and password) along with their corresponding setters. Then you can set the values via your context:

&lt;bean id=""yourService"" class=""xxx.yyy.zz.YourService""&gt;
  &lt;property name=""url"" value=""http://someurl.com""/&gt;
  &lt;property name=""userId"" value=""username""/&gt;
  &lt;property name=""password"" value=""passwd""/&gt;
&lt;/bean&gt;

"
474,474,738,What largest websites are written in php?,"What are some of the largest and most popular websites in the world written in php? I know 1 - this is wikipedia, tell please another large website.
",ANOTHER,https://webmasters.stackexchange.com/users/20044,"I would take a look at the graph on this site which displays some of the worlds largest websites and shows what they are built on

http://royal.pingdom.com/2007/08/22/what-nine-of-the-world%E2%80%99s-largest-websites-are-running-on/

And one other list which is pretty similar

http://blog.richardknop.com/2010/03/some-really-large-php-websites/
",Anagio,https://webmasters.stackexchange.com/users/10527,http://webmasters.stackexchange.com/questions/38030/what-largest-websites-are-written-in-php,TECHNOLOGY,webmasters.stackexchange.com,1.0,1.0,0.0,1.0,1.0,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.3333333333333333,0.0,0.0,1.0,Which of the largest websites are written in PHP?,What are the world's largest and most popular websites written in PHP? I know this is Wikipedia. Please tell another big website.,"I would take a look at the graph on this site which displays some of the worlds largest websites and shows what they are built on

http://royal.pingdom.com/2007/08/22/what-nine-of-the-world%E2%80%99s-largest-websites-are-running-on/

And one other list which is pretty similar

http://blog.richardknop.com/2010/03/some-really-large-php-websites/
"
2719,2719,4334,What's wrong with my launchctl config?,"I'm trying to auto-run SickBeard on login

python /Applications/Sick-Beard/Sickbeard.py

&lt;?xml version=""1.0"" encoding=""UTF-8""?&gt;
&lt;!DOCTYPE plist PUBLIC -//Apple Computer//DTD PLIST 1.0//EN http://www.apple.com/DTDs/PropertyList-1.0.dtd &gt;
&lt;plist version=""1.0""&gt;
&lt;dict&gt;
  &lt;key&gt;Label&lt;/key&gt;
  &lt;string&gt;com.sickbeard.sickbeard&lt;/string&gt;
  &lt;key&gt;ProgramArguments&lt;/key&gt;
  &lt;array&gt;
       &lt;string&gt;/usr/bin/python&lt;/string&gt;
       &lt;string&gt;/Applications/Sick-Beard/SickBeard.py&lt;/string&gt;
       &lt;string&gt;-q&lt;/string&gt;
       &lt;string&gt;-d&lt;/string&gt;
  &lt;/array&gt;
  &lt;key&gt;RunAtLoad&lt;/key&gt;
  &lt;true/&gt;
&lt;/dict&gt;
&lt;/plist&gt;


When I run launchctl com.sickbeard.sickbeard.plist it gives me the message:


  launchctl load com.sickbeard.sickbeard.plist  launchctl: no plist was
  returned for: com.sickbeard.sickbeard.plist launchctl: no plist was
  returned for: com.sickbeard.sickbeard.plist nothing found to load

",Joao Costa,https://apple.stackexchange.com/users/20798,"As I discovered the hard way, you must execute the command using sudo as well as passing the full path of the .plist file as follows (in your case):

sudo launchctl load /Library/LaunchDaemons/com.sickbeard.sickbeard.plist


The path may be different for you, but you must locate the file to find out its location and pass it as I quoted to the launchctl command.
",Johnny,https://apple.stackexchange.com/users/31090,http://apple.stackexchange.com/questions/46368/whats-wrong-with-my-launchctl-config,TECHNOLOGY,apple.stackexchange.com,0.8888888888888888,0.4444444444444444,0.0,1.0,1.0,1.0,0.6666666666666666,0.5555555555555556,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.3333333333333333,0.3333333333333333,1.0,0.8888888888888888,What's wrong with my launchctl configuration?,"I'm trying to auto-run SickBeard on login

python /Applications/Sick-Beard/Sickbeard.py

&lt;?xml version=""1.0"" encoding=""UTF-8""?&gt;
&lt;!DOCTYPE plist PUBLIC -//Apple Computer//DTD PLIST 1.0//EN http://www.apple.com/DTDs/PropertyList-1.0.dtd &gt;
&lt;plist version=""1.0""&gt;
&lt;dict&gt;
  &lt;key&gt;Label&lt;/key&gt;
  &lt;string&gt;com.sickbeard.sickbeard&lt;/string&gt;
  &lt;key&gt;ProgramArguments&lt;/key&gt;
  &lt;array&gt;
       &lt;string&gt;/usr/bin/python&lt;/string&gt;
       &lt;string&gt;/Applications/Sick-Beard/SickBeard.py&lt;/string&gt;
       &lt;string&gt;-q&lt;/string&gt;
       &lt;string&gt;-d&lt;/string&gt;
  &lt;/array&gt;
  &lt;key&gt;RunAtLoad&lt;/key&gt;
  &lt;true/&gt;
&lt;/dict&gt;
&lt;/plist&gt;


When I run launchctl com.sickbeard.sickbeard.plist it gives me the message:


  launchctl load com.sickbeard.sickbeard.plist  launchctl: no plist was
  returned for: com.sickbeard.sickbeard.plist launchctl: no plist was
  returned for: com.sickbeard.sickbeard.plist nothing found to load

","As I discovered the hard way, you must execute the command using sudo as well as passing the full path of the .plist file as follows (in your case):

sudo launchctl load /Library/LaunchDaemons/com.sickbeard.sickbeard.plist


The path may be different for you, but you must locate the file to find out its location and pass it as I quoted to the launchctl command.
"
4447,4447,7059,Placing the grid along date tickmarks,"I have the following data:

x=strptime(20010101:20010110)
y=1:10
z=data.frame(x,y)


So my data is this:

            x  y
1  2001-01-01  1
2  2001-01-02  2
3  2001-01-03  3
4  2001-01-04  4
5  2001-01-05  5
6  2001-01-06  6
7  2001-01-07  7
8  2001-01-08  8
9  2001-01-09  9
10 2001-01-10 10


When I create a plot in base using:

plot(x,y)
grid(NULL,NULL)


My vertical grid does not align with the date tick marks.  I know this seems like a pretty simple problem, but I have not found a solution to this anywhere.  Is there a way to get the vertical grid to align with the date tick marks using base that does not require me to do this:

abline(v=as.numeric(strptime(c(20010102,20010104,20010106,20010108,20010110),'%Y%m%d')))


I have a lot of plots with different dates and I would really like to automate this as much as possible, hopefully using base.
",thequerist,https://stackoverflow.com/users/915498,"The function axis draws your axes, tick marks and labels, and returns the tick mark positions as a vector.

Since you have Date data, you need to use axis.Date to do this, and then use abline to plot the grid:

z=data.frame(
  x=seq(as.Date(""2001-01-01""), by=""+1 month"", length.out=10)
  y=1:10
)
plot(y~x, data=z)
abline(v=axis.Date(1, z$x), col=""grey80"")



",Andrie,https://stackoverflow.com/users/602276,http://stackoverflow.com/questions/9119323/placing-the-grid-along-date-tickmarks,STACKOVERFLOW,stackoverflow.com,1.0,0.3333333333333333,0.0,0.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,1.0,Place grid along date mark,"I have the following data:

x=strptime(20010101:20010110)
y=1:10
z=data.frame(x,y)


So my data is this:

            x  y
1  2001-01-01  1
2  2001-01-02  2
3  2001-01-03  3
4  2001-01-04  4
5  2001-01-05  5
6  2001-01-06  6
7  2001-01-07  7
8  2001-01-08  8
9  2001-01-09  9
10 2001-01-10 10


When I create a plot in base using:

plot(x,y)
grid(NULL,NULL)


My vertical grid does not align with the date tick marks.  I know this seems like a pretty simple problem, but I have not found a solution to this anywhere.  Is there a way to get the vertical grid to align with the date tick marks using base that does not require me to do this:

abline(v=as.numeric(strptime(c(20010102,20010104,20010106,20010108,20010110),'%Y%m%d')))


I have a lot of plots with different dates and I would really like to automate this as much as possible, hopefully using base.
","The function axis draws your axes, tick marks and labels, and returns the tick mark positions as a vector.

Since you have Date data, you need to use axis.Date to do this, and then use abline to plot the grid:

z=data.frame(
  x=seq(as.Date(""2001-01-01""), by=""+1 month"", length.out=10)
  y=1:10
)
plot(y~x, data=z)
abline(v=axis.Date(1, z$x), col=""grey80"")



"
5689,5689,9019,How does critical strike chance stack?,"I was wondering how critical strike chance stacks? Say I buy a Phanton Dancer with its 30% crit chance. Now if I buy another Phanton Dancer, what is my critical chance?
",BubBidderskins,https://gaming.stackexchange.com/users/22482,"Crit chance caps out at 100% where your basic attacks are just crits. These are other things that stack additively     

Ability power
    Armor,
    Armor penetration,
    Armor reduction,
    Attack damage,
    Attack speed ,
    Cooldown reduction,
    Critical strike chance, 
    Critical strike damage,
    Health,
    Health regeneration,
    Life steal,
    Magic penetration,
    Magic resistance,
    Magic resistance reduction,
    Mana,
    Mana regeneration, and
    Spell vamp 

Source: http://leagueoflegends.wikia.com/wiki/Stacking
",Ryan McGahee,https://gaming.stackexchange.com/users/23061,http://gaming.stackexchange.com/questions/60921/how-does-critical-strike-chance-stack,CULTURE,gaming.stackexchange.com,0.8888888888888888,0.7777777777777778,0.0,1.0,1.0,1.0,0.7777777777777778,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.3333333333333333,0.6666666666666666,0.8888888888888888,How to stack critical strike chance?,"I want to know what's the chance of a deadly strike? Suppose I bought a phantom dancer with a 30% critical hit rate. If I buy another Fenton dancer, what's my chance?","Crit chance caps out at 100% where your basic attacks are just crits. These are other things that stack additively     

Ability power
    Armor,
    Armor penetration,
    Armor reduction,
    Attack damage,
    Attack speed ,
    Cooldown reduction,
    Critical strike chance, 
    Critical strike damage,
    Health,
    Health regeneration,
    Life steal,
    Magic penetration,
    Magic resistance,
    Magic resistance reduction,
    Mana,
    Mana regeneration, and
    Spell vamp 

Source: http://leagueoflegends.wikia.com/wiki/Stacking
"
343,343,548,Is a password easier to brute force if it contains a repeating pattern?,"My question is different from this previous question: Does repeating one word to form a password result in a similar pattern in its encrypted format?. I'm specifically wondering about brute force attacks. Based on my experiences with John The Ripper, I doubt that repeating a pattern in a password would shorten the time to successfully brute force a password like f00B@rf00B@rf00B@r as opposed to a random string of equal length. However, my doubt is based on the fact that, according to the documentation, JTR does not include a specific attack mode for repeating patterns. JTR, and presumably other brute force tools, can be customized for any arbitrary attack mode. But we can't know how often attackers bother to customize attacks in this way. So then the question becomes mathematical. Please forgive the awkward pseudo mathematical notation. 

T = brute force cracking time

PL = pattern of characters of length L

N = number of times PL is repeated

R(LN) = string of random characters of length (L times N)


Would it be true that

T(PL*N)= T(R(LN))


If true, then a repeating pattern password would not affect brute force cracking time. But is it true?
",Luke Sheppard,https://security.stackexchange.com/users/12057,"The knowledge of the password pattern could give you really speed-up in the brute-force method. If you know, that brute-forcing password is a repeating pattern password, you can reduce the cracking time.

If you know, that the password consists of N the same parts, then, all you have to do is find that part. So to speed the cracking process up, you need to add a few lines into your brute-force function. Let's say that the brute-force algorithm checked if your password is abba. Before you let it go to the another step (checking abbb), you should ""glue"" that try and check passwords like abbaabba, abbaabbaabba and so on.
",p____h,https://security.stackexchange.com/users/10414,http://security.stackexchange.com/questions/21562/is-a-password-easier-to-brute-force-if-it-contains-a-repeating-pattern,TECHNOLOGY,security.stackexchange.com,1.0,0.5555555555555556,0.0,0.6666666666666666,1.0,1.0,0.5555555555555556,0.5555555555555556,0.6666666666666666,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,0.0,0.8888888888888888,0.7777777777777778,0.5555555555555556,1.0,0.8888888888888888,0.7333333333333333,0.0,0.3333333333333333,1.0,0.8888888888888888,"If the password contains a repeating pattern, is it easier to force it?","My question is different from the previous one: does repeating a word to form a password result in a similar pattern of its encryption format? I particularly want to know about violent attacks. Based on my experience with John the Ripper, I suspect that repeating a pattern in a password will shorten the time to successfully enforce a password such as f00b @ rf00b @ rf00b @ r, rather than using a random string of the same length. However, my suspicions are based on the fact that, according to the documentation, jtr does not include specific attack patterns for duplicate patterns. Jtr and other violence tools can be customized for any attack mode. But we don't know how long it will take for attackers to customize attacks like this. So the problem became a mathematical problem. Please forgive this clumsy pseudo mathematical symbol.","The knowledge of the password pattern could give you really speed-up in the brute-force method. If you know, that brute-forcing password is a repeating pattern password, you can reduce the cracking time.

If you know, that the password consists of N the same parts, then, all you have to do is find that part. So to speed the cracking process up, you need to add a few lines into your brute-force function. Let's say that the brute-force algorithm checked if your password is abba. Before you let it go to the another step (checking abbb), you should ""glue"" that try and check passwords like abbaabba, abbaabbaabba and so on.
"
4521,4521,7166,Differences in student load at liberal arts colleges vs. research universities,"Do students at liberal arts universities have 'harder' courses than students at research universities? 

Computer Science curricula at large research universities have 5 to 6 courses per semester. The Liberal Arts model dictates roughly 4 courses per semester. If the load on the student is considered to be equivalent, there must be something special to the teaching in the Liberal Arts model.

How is it that a 4 course Liberal Arts semester is as intensive as a 6 course research university semester?

UPDATE: Many of the comments below say the course load I mention above is inaccurate. I have obtained the figures as follows.


The Liberal Arts Computer Science Consortium (LACS) has released 3 LACS curricula in response to ACM/IEEE CS curriculum recommendations. The first in 1986 in response to the 1978 recommendation, next in 1996 in response to the 1991 recommendation and the most recent in 2007 in response to the 2001 recommendation. The 4 year course breakdown in all the LACS recommendations is roughly the same:

4 courses per semester
30-35% CS courses, 10% math, 5% science, and the rest, i.e. 50% or more courses on arts, humanities and social sciences.

A typical graduation requirement at a research university is at least 120 credits, which comes to 5 3-credit courses per semester. Many require more than 120 so 6 course semesters are not uncommon.

",wsaleem,https://academia.stackexchange.com/users/14572,"You are making several unfounded assumptions:


That courses are always 3 credits, so that ""4 courses per semester"" means 12 credits. I have taken courses that were worth 1, 2, 3, 4, and 5 credits. Many of the science courses I've taken, including math and computer science courses, have been worth 4 credits. Basic sciences that involve a lecture, lab, and recitation have sometimes been 5 credits.
That most liberal arts colleges follow the LACS recommendations to the letter. 
That the LACS recommendations somehow suggest that less than 120 credits are required for graduation. Here is an example of a liberal arts college following the LACS recommendations for CS and requiring 120 credits. 


I did half of my undergraduate degree at a liberal arts college and then transferred to a large research university for the other half. There was virtually no difference in my courseload between the two - I took exactly one credit more in my two years in the research university. I just pulled up my transcripts, and this is what I took each semester:

Part 0

I transferred in 30 credits in humanities, etc. from college courses taken while in high school.

Part 1 - Liberal Arts College


16 credits, 4 classes (4, 3, 4, 5)
13 credits, 3 classes (4, 4, 5)
(Summer) 3 credits, 1 class (3)
19 credits, 5 classes (3, 4, 5, 4, 3)
12 credits, 4 classes (3, 3, 4, 2)


Part 2 - Research University


16 credits, 4 classes (4, 4, 4, 4)
19 credits, 5 classes (4, 3, 4, 4, 4)
16 credits, 6 classes (3, 4, 1, 3, 3, 2)
13 credits, 4 classes (4, 3, 3, 3)


(My undergraduate degree was in Electrical Engineering, with a minor in Computer Science.)
",ff524,https://academia.stackexchange.com/users/11365,http://academia.stackexchange.com/questions/19846/differences-in-student-load-at-liberal-arts-colleges-vs-research-universities,LIFE_ARTS,academia.stackexchange.com,0.6666666666666666,0.4444444444444444,0.6666666666666666,0.0,0.3333333333333333,0.6666666666666666,0.5555555555555556,0.5555555555555556,1.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.5555555555555556,1.0,0.8333333333333334,1.0,1.0,0.8,0.0,0.0,0.6666666666666666,0.6666666666666666,The difference of student load between liberal arts colleges and Research Universities,"Do students at liberal arts universities have 'harder' courses than students at research universities? 

Computer Science curricula at large research universities have 5 to 6 courses per semester. The Liberal Arts model dictates roughly 4 courses per semester. If the load on the student is considered to be equivalent, there must be something special to the teaching in the Liberal Arts model.

How is it that a 4 course Liberal Arts semester is as intensive as a 6 course research university semester?

UPDATE: Many of the comments below say the course load I mention above is inaccurate. I have obtained the figures as follows.


The Liberal Arts Computer Science Consortium (LACS) has released 3 LACS curricula in response to ACM/IEEE CS curriculum recommendations. The first in 1986 in response to the 1978 recommendation, next in 1996 in response to the 1991 recommendation and the most recent in 2007 in response to the 2001 recommendation. The 4 year course breakdown in all the LACS recommendations is roughly the same:

4 courses per semester
30-35% CS courses, 10% math, 5% science, and the rest, i.e. 50% or more courses on arts, humanities and social sciences.

A typical graduation requirement at a research university is at least 120 credits, which comes to 5 3-credit courses per semester. Many require more than 120 so 6 course semesters are not uncommon.

","You are making several unfounded assumptions:


That courses are always 3 credits, so that ""4 courses per semester"" means 12 credits. I have taken courses that were worth 1, 2, 3, 4, and 5 credits. Many of the science courses I've taken, including math and computer science courses, have been worth 4 credits. Basic sciences that involve a lecture, lab, and recitation have sometimes been 5 credits.
That most liberal arts colleges follow the LACS recommendations to the letter. 
That the LACS recommendations somehow suggest that less than 120 credits are required for graduation. Here is an example of a liberal arts college following the LACS recommendations for CS and requiring 120 credits. 


I did half of my undergraduate degree at a liberal arts college and then transferred to a large research university for the other half. There was virtually no difference in my courseload between the two - I took exactly one credit more in my two years in the research university. I just pulled up my transcripts, and this is what I took each semester:

Part 0

I transferred in 30 credits in humanities, etc. from college courses taken while in high school.

Part 1 - Liberal Arts College


16 credits, 4 classes (4, 3, 4, 5)
13 credits, 3 classes (4, 4, 5)
(Summer) 3 credits, 1 class (3)
19 credits, 5 classes (3, 4, 5, 4, 3)
12 credits, 4 classes (3, 3, 4, 2)


Part 2 - Research University


16 credits, 4 classes (4, 4, 4, 4)
19 credits, 5 classes (4, 3, 4, 4, 4)
16 credits, 6 classes (3, 4, 1, 3, 3, 2)
13 credits, 4 classes (4, 3, 3, 3)


(My undergraduate degree was in Electrical Engineering, with a minor in Computer Science.)
"
2097,2097,3339,Close all file descriptors in bash,"Is there a way to close all the open file descriptors, without having an explicit list of them beforehand?
",Lorenzo Pistone,https://unix.stackexchange.com/users/15172,"To answer literally, to close all open file descriptors for bash:

for fd in $(ls /proc/$$/fd); do
  eval ""exec $fd&gt;&amp;-""
done


However this really isn't a good idea since it will close the basic file descriptors the shell needs for input and output. If you do this, none of the programs you run will have their output displayed on the terminal (unless they write to the tty device directly). If fact in my tests closing stdin (exec 0&gt;&amp;-) just causes an interactive shell to exit.

What you may actually be looking to do is rather to close all file descriptors that are not part of the shell's basic operation. These are 0 for stdin, 1 for stdout and 2 for stderr. On top of this some shells also seem to have other file descriptors open by default. In bash, for example, you have 255 (also for terminal I/O) and in dash I have 10, which points to /dev/tty rather than the specific tty/pts device the terminal is using. To close everything apart from 0, 1, 2 and 255 in bash:

for fd in $(ls /proc/$$/fd); do
  case ""$fd"" in
    0|1|2|255)
      ;;
    *)
      eval ""exec $fd&gt;&amp;-""
      ;;
  esac
done


Note also that eval is required when redirecting the file descriptor contained in a variable, if not bash will expand the variable but consider it part of the command (in this case it would try to exec the command 0 or 1 or whichever file descriptor you are trying to close). 

NOTE: Also using a glob instead of ls (eg /proc/$$/fd/*) seems to open an extra file descriptor for the glob, so ls seems the best solution here.

Update

For further information on the portability of /proc/$$/fd, please see Portability of file descriptor links. If /proc/$$/fd is unavailable, then a drop in replacement for the $(ls /proc/$$/fd), using lsof (if that is available) would be $(lsof -p $$ -Ff | grep f[0-9] | cut -c 2-).
",Graeme,https://unix.stackexchange.com/users/48083,http://unix.stackexchange.com/questions/123413/close-all-file-descriptors-in-bash,TECHNOLOGY,unix.stackexchange.com,0.8888888888888888,0.7777777777777778,0.0,1.0,1.0,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.7777777777777778,1.0,1.0,1.0,1.0,0.8666666666666666,1.0,0.0,1.0,0.8888888888888888,Close all file descriptors in Bash,Is there a way to close all open file descriptors without providing an explicit list of them in advance?,"To answer literally, to close all open file descriptors for bash:

for fd in $(ls /proc/$$/fd); do
  eval ""exec $fd&gt;&amp;-""
done


However this really isn't a good idea since it will close the basic file descriptors the shell needs for input and output. If you do this, none of the programs you run will have their output displayed on the terminal (unless they write to the tty device directly). If fact in my tests closing stdin (exec 0&gt;&amp;-) just causes an interactive shell to exit.

What you may actually be looking to do is rather to close all file descriptors that are not part of the shell's basic operation. These are 0 for stdin, 1 for stdout and 2 for stderr. On top of this some shells also seem to have other file descriptors open by default. In bash, for example, you have 255 (also for terminal I/O) and in dash I have 10, which points to /dev/tty rather than the specific tty/pts device the terminal is using. To close everything apart from 0, 1, 2 and 255 in bash:

for fd in $(ls /proc/$$/fd); do
  case ""$fd"" in
    0|1|2|255)
      ;;
    *)
      eval ""exec $fd&gt;&amp;-""
      ;;
  esac
done


Note also that eval is required when redirecting the file descriptor contained in a variable, if not bash will expand the variable but consider it part of the command (in this case it would try to exec the command 0 or 1 or whichever file descriptor you are trying to close). 

NOTE: Also using a glob instead of ls (eg /proc/$$/fd/*) seems to open an extra file descriptor for the glob, so ls seems the best solution here.

Update

For further information on the portability of /proc/$$/fd, please see Portability of file descriptor links. If /proc/$$/fd is unavailable, then a drop in replacement for the $(ls /proc/$$/fd), using lsof (if that is available) would be $(lsof -p $$ -Ff | grep f[0-9] | cut -c 2-).
"
959,959,1517,Stop JS-event propagation on table row click,"I have the following HTML-table:

&lt;table&gt;
  &lt;tr&gt;
    &lt;td&gt;
      Row 1
    &lt;/td&gt;
    &lt;td&gt;
      &lt;!-- Hidden JSF-button --&gt;
      &lt;button class=""hide"" /&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;


When I click on a tr, I trigger a click on the hidden button with JS:

$('table tr').on('click', function(e) {
  var $button = $(this).find('button');  
  console.log('trigger click on', $button);

  $button.trigger('click');
});


The click event propagates up, and will cause a never ending loop (can be seen here: http://codepen.io/anon/pen/kDxHy) 

After some searching on SO, it is clear that the solution is to call event.stopPropagation,
like this (can be seen here: http://codepen.io/anon/pen/BnlfA):

$('table tr').on('click', function(e) {
  var $button = $(this).find('button');

  // Prevent the event from bubbling up the DOM tree.
  $button
    .off('click')
    .on('click', function(e) {
      console.log('click');
      e.stopPropagation();

    return true;
  });

  console.log('trigger click on', $button);

  $button.trigger('click');
});


The solution above works. But it feels like a hack, and I don't like it. 

Do I have to register a click handler on the on the $button just to call event.stopPropagation? Are there any better way(s) of preventing the click event from bubbeling? 
",nekman,https://stackoverflow.com/users/141363,"Modifying buttons behaviour, expecially in frameworks, can cause some unexpected issues. You could add a flag to the row and use it to check if the button should be clicked. But you have to know how many click are automatically generated and should be omitted.

var handleClick = function(e) {
  var $button = $(this).find('button');  
  console.log('triggerring click on...', $button);
  if (this.clicked !== true) {
    console.log('and clicked!')
    this.clicked = true;
    $button.trigger('click');
  } else
    this.clicked = false;
};


Here's the code: http://codepen.io/anon/pen/dJroL
",Nebril,https://stackoverflow.com/users/386307,http://stackoverflow.com/questions/18968847/stop-js-event-propagation-on-table-row-click,STACKOVERFLOW,stackoverflow.com,0.6666666666666666,0.6666666666666666,0.0,0.0,1.0,1.0,0.6666666666666666,0.3333333333333333,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,1.0,1.0,Stop JS event propagation when table row is clicked,"I have the following HTML-table:

&lt;table&gt;
  &lt;tr&gt;
    &lt;td&gt;
      Row 1
    &lt;/td&gt;
    &lt;td&gt;
      &lt;!-- Hidden JSF-button --&gt;
      &lt;button class=""hide"" /&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;


When I click on a tr, I trigger a click on the hidden button with JS:

$('table tr').on('click', function(e) {
  var $button = $(this).find('button');  
  console.log('trigger click on', $button);

  $button.trigger('click');
});


The click event propagates up, and will cause a never ending loop (can be seen here: http://codepen.io/anon/pen/kDxHy) 

After some searching on SO, it is clear that the solution is to call event.stopPropagation,
like this (can be seen here: http://codepen.io/anon/pen/BnlfA):

$('table tr').on('click', function(e) {
  var $button = $(this).find('button');

  // Prevent the event from bubbling up the DOM tree.
  $button
    .off('click')
    .on('click', function(e) {
      console.log('click');
      e.stopPropagation();

    return true;
  });

  console.log('trigger click on', $button);

  $button.trigger('click');
});


The solution above works. But it feels like a hack, and I don't like it. 

Do I have to register a click handler on the on the $button just to call event.stopPropagation? Are there any better way(s) of preventing the click event from bubbeling? 
","Modifying buttons behaviour, expecially in frameworks, can cause some unexpected issues. You could add a flag to the row and use it to check if the button should be clicked. But you have to know how many click are automatically generated and should be omitted.

var handleClick = function(e) {
  var $button = $(this).find('button');  
  console.log('triggerring click on...', $button);
  if (this.clicked !== true) {
    console.log('and clicked!')
    this.clicked = true;
    $button.trigger('click');
  } else
    this.clicked = false;
};


Here's the code: http://codepen.io/anon/pen/dJroL
"
3856,3856,6134,Roots of this third degree polynomial,"I've got the following polynomial
$$
x^3-6x^2-2x+40
$$
and I want to find its roots. The only option I see at the moment is to compute all the divisors of $40$ and their inverse, and manually check if it's result is $0$. This works, because $4$ is a zero and now we can divide the polynomial by the factor $x-4$, resulting in a second degree polynomial (which is easier to solve).

I was wondering if there's any other method/idea to manually find the roots of this polynomial?
",ABC,https://math.stackexchange.com/users/91270,"Your method, which starts by employing the Rational Root Theorem and then (implicitly) Factor Theorem and polynomial long division is the most elementary method and probably the quickest. Of course, it only works in certain cases. You can save a bit of work in the division step by using synthetic division.

There is a general cubic solution, but it's very tedious, and not worth it in this case.

Approximate (iterative) methods like Newton-Raphson may also be used, and they're quicker than the general cubic solution, but they don't give exact roots. Of course, if the values you get are ""suspiciously"" close to integers, you can just test the integers to see if they're indeed the roots the method is converging toward and short-cut the process.
",Deepak,https://math.stackexchange.com/users/151732,http://math.stackexchange.com/questions/962303/roots-of-this-third-degree-polynomial,SCIENCE,math.stackexchange.com,1.0,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.6666666666666666,1.0,0.7777777777777778,1.0,1.0,0.9333333333333332,0.6666666666666666,0.3333333333333333,0.3333333333333333,1.0,The root of this cubic polynomial,"I've got the following polynomial
$$
x^3-6x^2-2x+40
$$
and I want to find its roots. The only option I see at the moment is to compute all the divisors of $40$ and their inverse, and manually check if it's result is $0$. This works, because $4$ is a zero and now we can divide the polynomial by the factor $x-4$, resulting in a second degree polynomial (which is easier to solve).

I was wondering if there's any other method/idea to manually find the roots of this polynomial?
","Your method, which starts by employing the Rational Root Theorem and then (implicitly) Factor Theorem and polynomial long division is the most elementary method and probably the quickest. Of course, it only works in certain cases. You can save a bit of work in the division step by using synthetic division.

There is a general cubic solution, but it's very tedious, and not worth it in this case.

Approximate (iterative) methods like Newton-Raphson may also be used, and they're quicker than the general cubic solution, but they don't give exact roots. Of course, if the values you get are ""suspiciously"" close to integers, you can just test the integers to see if they're indeed the roots the method is converging toward and short-cut the process.
"
962,962,1522,Most effective way to increase programmer salary besides just doing your job?,"If you have the time and resources, what would be the most effective way to increase your salary as a full-time programmer, outside of just doing your job? 

By ""salary"" here, I mean salary (adjusted for location cost-of-living) coming from a single programming job. 
",T. Webster,https://programmers.stackexchange.com/users/19936,"By doing your job, I assume you mean the technical aspect. Programming, meeting requirements, attending meetings, etc. 

If so, than one of the most effective way would be to work on the social aspect of your job. 

You can meet all of your technical objectives but still get a lower salary than someone with good technical skills but great people skills.

You need to promote yourself to your boss and to your coworkers. Make contacts in the industry. Become a leader among your team. Be the guy people are asking for help when they are stuck. 

People that do these things are usually will usually be perceived favorably by management, thus be seen as more valuable.
",Gilles,https://programmers.stackexchange.com/users/20379,http://programmers.stackexchange.com/questions/76254/most-effective-way-to-increase-programmer-salary-besides-just-doing-your-job,TECHNOLOGY,programmers.stackexchange.com,1.0,1.0,0.5,1.0,0.0,0.5,0.6666666666666666,0.6666666666666666,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.5,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9,0.5,0.0,1.0,1.0,"In addition to work, what is the most effective way to raise the salary of programmers?","If you have time and resources, what is the most effective way to increase your salary as a full-time programmer besides doing your job?","By doing your job, I assume you mean the technical aspect. Programming, meeting requirements, attending meetings, etc. 

If so, than one of the most effective way would be to work on the social aspect of your job. 

You can meet all of your technical objectives but still get a lower salary than someone with good technical skills but great people skills.

You need to promote yourself to your boss and to your coworkers. Make contacts in the industry. Become a leader among your team. Be the guy people are asking for help when they are stuck. 

People that do these things are usually will usually be perceived favorably by management, thus be seen as more valuable.
"
2818,2818,4487,"""Caldoniafied"" In General Use in the 1980s?","I am curious about the word ""Caldoniafied"" meaning, roughly, hard headed, and presumably coming from the song entitled ""Caldonia""  (""Caldonia, Caldonia, what makes your big head so hard?"". )Louis Jordan had a big hit with it, and BB King still sings it. This word was used by my Brooklyn landlady in the 1980s. Was it in general use at this time?  Also, was it a huge insult? I am writing a novel set at this time and wanted to use it as a light term. Google doesn't have much about it.
",Valerie Clark,https://english.stackexchange.com/users/96524,"I would not use the term ""Caldoniafied,"" even in a lighthearted way. In the first place, I'm not aware that the expression was ever common in the United States, either during the 1980s (I spent 1980–81 in Washington, D.C.; 1982–84 in Staten Island, New York; and 1985–89 in Berkeley, California) or afterward.

A Google search turns up just one match for Caldoniafied and none for Caldoniafy. From Ed Ward, ""Dedicated to You,"" in Greil Marcus, ed., Stranded: Rock and Roll for a Desert Island (1979):


  One night, as they were leaving the backstage of a show, a teenager had called Obediah [Carter, who sang tenor for the ""5"" Royales] ""an old Caldoniafied nigger,"" and the rest of the guys had to hold him back to keep him from outright throttling the kid.


This incident occurred sometime in late 1959 or early 1960. It's not clear to me what exactly the teenager meant by ""Caldoniafied."" Since Louis Jordan sang comic and novelty songs (as the ""5"" Royales often did a decade later), and since Jordan's vocals launched into the high tenor range on ""Caldonia"" (as Carter's did on various songs in the ""5"" Royales repertoire), perhaps the kid was implying that Carter was stealing his singing style from Jordan and that the style was in any case behind the times. Or perhaps the kid simply meant that Carter and the other Royales were hopelessly hardheaded in refusing to adapt to the fundamental changes then occurring in R&amp;B and rock. In any event, the remark didn't sit well with Obediah Carter, and I don't get the impression that the choice of ""Caldoniafied"" as a modifier softened the blow of the ultimate racial epithet. 

It would be difficult (I think) to use ""Caldoniafied"" today in a non-race-inflected way. The OP's Brooklyn landlady may have pulled it off, but for anyone who has committed Louis Jordan's ""Caldonia! Caldonia! What makes your big head so hard?"" to memory, it is hard not to think of Caldonia as anything but a lean, lanky, hardheaded Black woman (with great big feet)—even though Jordan never specifies her race or color. In a culture sensitized to and uneasy about the implications of racial innuendo, I would do my best to steer clear of ""Caldoniafied,"" ""Jemimafied,"" ""Porgyfied,"" ""Rochesterfied,"" and the like as if they were so many land mines.
",Sven Yargs,https://english.stackexchange.com/users/36232,http://english.stackexchange.com/questions/211039/caldoniafied-in-general-use-in-the-1980s,CULTURE,english.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,0.6666666666666666,1.0,0.6666666666666666,0.5555555555555556,0.8888888888888888,0.6666666666666666,0.0,0.3333333333333333,1.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.7777777777777778,0.8888888888888888,0.7777777777777778,1.0,0.8888888888888888,0.8666666666666666,0.0,0.0,1.0,0.8888888888888888,"""Caldonianization"" was widely used in 1980s?","I'm curious about the meaning of the word ""caldonianism"". Generally speaking, it's hard to understand. It's probably from a song called ""caldonia"" (caldonia, caldonia, what makes your big head so hard to understand Louis Jordan is popular in the movie, while BB king is still singing. The word was used by my Brooklyn landlady in the 1980s. Is it universal at this time? What's more, is this a huge insult? I'm writing a novel now, and I want to use it as a simple term. Google doesn't know much about it.","I would not use the term ""Caldoniafied,"" even in a lighthearted way. In the first place, I'm not aware that the expression was ever common in the United States, either during the 1980s (I spent 1980–81 in Washington, D.C.; 1982–84 in Staten Island, New York; and 1985–89 in Berkeley, California) or afterward.

A Google search turns up just one match for Caldoniafied and none for Caldoniafy. From Ed Ward, ""Dedicated to You,"" in Greil Marcus, ed., Stranded: Rock and Roll for a Desert Island (1979):


  One night, as they were leaving the backstage of a show, a teenager had called Obediah [Carter, who sang tenor for the ""5"" Royales] ""an old Caldoniafied nigger,"" and the rest of the guys had to hold him back to keep him from outright throttling the kid.


This incident occurred sometime in late 1959 or early 1960. It's not clear to me what exactly the teenager meant by ""Caldoniafied."" Since Louis Jordan sang comic and novelty songs (as the ""5"" Royales often did a decade later), and since Jordan's vocals launched into the high tenor range on ""Caldonia"" (as Carter's did on various songs in the ""5"" Royales repertoire), perhaps the kid was implying that Carter was stealing his singing style from Jordan and that the style was in any case behind the times. Or perhaps the kid simply meant that Carter and the other Royales were hopelessly hardheaded in refusing to adapt to the fundamental changes then occurring in R&amp;B and rock. In any event, the remark didn't sit well with Obediah Carter, and I don't get the impression that the choice of ""Caldoniafied"" as a modifier softened the blow of the ultimate racial epithet. 

It would be difficult (I think) to use ""Caldoniafied"" today in a non-race-inflected way. The OP's Brooklyn landlady may have pulled it off, but for anyone who has committed Louis Jordan's ""Caldonia! Caldonia! What makes your big head so hard?"" to memory, it is hard not to think of Caldonia as anything but a lean, lanky, hardheaded Black woman (with great big feet)—even though Jordan never specifies her race or color. In a culture sensitized to and uneasy about the implications of racial innuendo, I would do my best to steer clear of ""Caldoniafied,"" ""Jemimafied,"" ""Porgyfied,"" ""Rochesterfied,"" and the like as if they were so many land mines.
"
1255,1255,1973,business-class fiber to the home,"Suppose you're some sort of crazy nerd fellow and you live in an area that's absolutely covered in fiber optics and network facilities. What kind of cost / infrastructure would be needed to hook in somewhere and get you're internet connection directly from a local datacenter?
",neoice,https://serverfault.com/users/6134,"You get a job at one of these places, and do your downloads at work. Seriously. Like the other posters said, if your town is lit up like this, you can probably get a seriously high-speed consumer-grade connection from your cableco or telco. Unless you're in Boston, where the mayor and Verizon got into a pissing contest and there is no FiOS. 

This is assuming you're in the US - your profile says Seattle WA. 
",mfinni,https://serverfault.com/users/29373,http://serverfault.com/questions/158286,TECHNOLOGY,serverfault.com,1.0,0.3333333333333333,0.0,0.6666666666666666,1.0,0.0,1.0,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.3333333333333333,0.0,0.8888888888888888,0.8888888888888888,0.5555555555555556,0.8888888888888888,0.6666666666666666,0.5333333333333333,0.6666666666666666,0.0,0.3333333333333333,0.8888888888888888,Business class fiber home,"Suppose you're a crazy nerd, living in a place that's completely covered by fiber optics and networking. What cost / infrastructure is needed to connect to a place and directly from the local data center to the Internet?","You get a job at one of these places, and do your downloads at work. Seriously. Like the other posters said, if your town is lit up like this, you can probably get a seriously high-speed consumer-grade connection from your cableco or telco. Unless you're in Boston, where the mayor and Verizon got into a pissing contest and there is no FiOS. 

This is assuming you're in the US - your profile says Seattle WA. 
"
897,897,1425,Can you disavow a whole domain apart from the index page?,"Many years ago I may have bought a few sitewide links for some of my sites, these have now come back to haunt me and I need to sort them out.

I've tried to contact the owners but they're too lazy to bother changing the sites so I figure it's time to disavow the links.

But is there a way to disavow all of the sitewide links on the domain apart from on the index page and would this be a benefit to leave the index or would it still be seen as spammy?

Something like ...

# Contacted owner of shadyseo.com on 7/1/2012 to
# ask for link removal but got no response
domain:shadyseo.com
!shadyseo.com/index.php

",Dan,https://webmasters.stackexchange.com/users/12631,"There is no way to disavow a portion of a site.  Here is the documentation for the disavow file format.  It only supports three types of lines:


Comments that start with a #
Single URLs (each on a line by itself)
Domain rules such as domain:shadyseo.com


The disavow file does NOT support more complex matches such as:


Folder matches
Wildcard matches
Regular expression matches.


The only way to disavow all the links on a site other than on the homepage would be to make a complete list of all the pages with links on the site but then not include the home page.
",Stephen Ostermiller,https://webmasters.stackexchange.com/users/14543,http://webmasters.stackexchange.com/questions/54877/can-you-disavow-a-whole-domain-apart-from-the-index-page,TECHNOLOGY,webmasters.stackexchange.com,1.0,1.0,0.0,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,1.0,0.8,0.0,0.0,1.0,1.0,Can you identify the entire domain name except the index page?,"Many years ago I may have bought a few sitewide links for some of my sites, these have now come back to haunt me and I need to sort them out.

I've tried to contact the owners but they're too lazy to bother changing the sites so I figure it's time to disavow the links.

But is there a way to disavow all of the sitewide links on the domain apart from on the index page and would this be a benefit to leave the index or would it still be seen as spammy?

Something like ...

# Contacted owner of shadyseo.com on 7/1/2012 to
# ask for link removal but got no response
domain:shadyseo.com
!shadyseo.com/index.php

","There is no way to disavow a portion of a site.  Here is the documentation for the disavow file format.  It only supports three types of lines:


Comments that start with a #
Single URLs (each on a line by itself)
Domain rules such as domain:shadyseo.com


The disavow file does NOT support more complex matches such as:


Folder matches
Wildcard matches
Regular expression matches.


The only way to disavow all the links on a site other than on the homepage would be to make a complete list of all the pages with links on the site but then not include the home page.
"
2907,2907,4623,Does a laptop computer charge faster when off?,"A laptop power supply can supply a limited amount of power. Conceivably, then, when the computer is running, some of the power must be diverted to the processor and other components, leaving less to charge the battery. (Power usage is roughly 10 to 30 watts, or maybe more if you have a graphics card. In my case, my charger is rated for 65 watts.) Why doesn&#39;t my laptop battery charge while the laptop is in use? is an example of an extreme case. So it's plausible that this would affect charging speed.

So do laptops in fact charge significantly faster when turned off or asleep (while plugged into a sufficient power supply)?
",Mechanical snail,https://superuser.com/users/34598,"No one answer fits all, it really depends on the laptop!

Some have built in features (vendor specific) that speed up the battery charging, others (including most of mine) charge a lot slower when in use.

Again, no one answer fits all.
",William Hilsum,https://superuser.com/users/4386,http://superuser.com/questions/337527,TECHNOLOGY,superuser.com,1.0,0.8888888888888888,0.0,1.0,1.0,1.0,0.6666666666666666,0.5555555555555556,0.0,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.3333333333333333,0.3333333333333333,0.3333333333333333,1.0,Does the laptop charge fast when it is turned off?,"Laptop power can provide limited power. As you can imagine, when the computer is running, part of the power must be transferred to the processor and other components, leaving less power for the battery to charge. (the power consumption is about 10 to 30 watts, maybe more if you have a video card. In my case, my charger is rated at 65 watts.) Why does my laptop battery not charge when it is in use? It's an extreme case. So this may affect the charging speed.","No one answer fits all, it really depends on the laptop!

Some have built in features (vendor specific) that speed up the battery charging, others (including most of mine) charge a lot slower when in use.

Again, no one answer fits all.
"
5762,5762,9131,Can I set the Brick Texture Node horizontal mortar size to be equivalent to the vertical mortar size?,"I'm using Blender 2.73 and I'm trying to create tiles using the brick texture node.  The problem I'm having is that the horizontal mortar size is smaller than the vertical.

Is it possible to have them be equivalent sizes?
",Mario,https://blender.stackexchange.com/users/11417,"the mortar size is a percentage of the width or height so they won't be equal unless width = height
or  you can try this :


tweak the scale on the Y axis till you get the effect
",Chebhou,https://blender.stackexchange.com/users/5113,http://blender.stackexchange.com/questions/24277/can-i-set-the-brick-texture-node-horizontal-mortar-size-to-be-equivalent-to-the,TECHNOLOGY,blender.stackexchange.com,1.0,1.0,0.0,0.3333333333333333,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.3333333333333333,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.0,0.3333333333333333,0.7777777777777778,Can I set the horizontal mortar size of the brick texture node to be equal to the vertical mortar size?,I'm using blender2.73 and trying to create a tile using the brick texture node. The problem I have is that the horizontal mortar is smaller than the vertical one.,"Mortar size is a percentage of width or height, so they will not be equal unless width = height"
2080,2080,3312,Multiple orders in a single list,"I have a problem with a ranking system I am using.

Scenario:

An online game with around 10k players calculates a real time ranking of points when a certain event occurs. Events don't occur that often, around 1 time per minute. This ranking is kept in the cache for quick calculations, sorting and access.

Now players can form groups and play against each other, but the scoring system is the same, only the ranking is based for the players in that group.

At first I created for every group a separate ranking, effectively having the same scores as the complete ranking, but with different positions in the ranking.

This is trivial because there are over 1.000 groups and every time an event occurs all the groups would have to be updated.

So what I did now is when the group ranking is requested take only the players that are in that group from the complete ranking and show them. The positions would have to be re-counted.

That re-counting is where the problem is. Because the sub-list is by-reference from the complete ranking list I cannot change the position of the player in the sub-ranking without updating it in the complete ranking, because it's just a reference.

I came up with two solutions:


Create a copy from the record every time it is requested and do some output caching (not very desirable because the rankings are live)
Create a copy and store this in a cache which is reset when an event occurs.
Create a sub-list with just the positions which is updated when an event occurs.


And the last solution: do the position counting in the output instead in the business side. This would be the best solution, only problem is that on some pages this text appears: ""You are on position # in the ranking"" where # is your ranking position. This number would be tedious to get then.

Does anybody have any suggestions to this problem?
",YesMan85,https://programmers.stackexchange.com/users/24248,"As you say yourself, the best solution is to do the counting in the output, instead of storing it in the various lists. That way you don't have to store (and recalculate) the ranking numbers on each event for each (sub-)list, but you only calculate them when needed.

For the ""You are on position # in the ranking"" text, you could have a method in the class that represents the ranking list, like this: RankingList::getRankingOf(Player). Only if this information is costly to obtain and you only need the ranking from the overall list, you could consider caching the current ranking numbers in the overall list (as an optimisation strategy).
",Bart van Ingen Schenau,https://programmers.stackexchange.com/users/5099,http://programmers.stackexchange.com/questions/198803/multiple-orders-in-a-single-list,TECHNOLOGY,programmers.stackexchange.com,0.5555555555555556,0.3333333333333333,0.0,0.3333333333333333,0.6666666666666666,0.3333333333333333,0.5555555555555556,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.7777777777777778,1.0,0.6666666666666666,0.8333333333333334,1.0,1.0,1.0,0.0,0.3333333333333333,1.0,Multiple orders in a list,"I have a problem with a ranking system I am using.

Scenario:

An online game with around 10k players calculates a real time ranking of points when a certain event occurs. Events don't occur that often, around 1 time per minute. This ranking is kept in the cache for quick calculations, sorting and access.

Now players can form groups and play against each other, but the scoring system is the same, only the ranking is based for the players in that group.

At first I created for every group a separate ranking, effectively having the same scores as the complete ranking, but with different positions in the ranking.

This is trivial because there are over 1.000 groups and every time an event occurs all the groups would have to be updated.

So what I did now is when the group ranking is requested take only the players that are in that group from the complete ranking and show them. The positions would have to be re-counted.

That re-counting is where the problem is. Because the sub-list is by-reference from the complete ranking list I cannot change the position of the player in the sub-ranking without updating it in the complete ranking, because it's just a reference.

I came up with two solutions:


Create a copy from the record every time it is requested and do some output caching (not very desirable because the rankings are live)
Create a copy and store this in a cache which is reset when an event occurs.
Create a sub-list with just the positions which is updated when an event occurs.


And the last solution: do the position counting in the output instead in the business side. This would be the best solution, only problem is that on some pages this text appears: ""You are on position # in the ranking"" where # is your ranking position. This number would be tedious to get then.

Does anybody have any suggestions to this problem?
","As you say yourself, the best solution is to do the counting in the output, instead of storing it in the various lists. That way you don't have to store (and recalculate) the ranking numbers on each event for each (sub-)list, but you only calculate them when needed.

For the ""You are on position # in the ranking"" text, you could have a method in the class that represents the ranking list, like this: RankingList::getRankingOf(Player). Only if this information is costly to obtain and you only need the ranking from the overall list, you could consider caching the current ranking numbers in the overall list (as an optimisation strategy).
"
2704,2704,4314,Can you make a hash out of a stream cipher?,"A comment on another question made me wonder about something:


  Assume you're on a rather constrained platform &mdash; say, a low-end embedded device &mdash; with no built-in crypto capabilities, but you do have access to a simple stream cipher; say, RC4 or one of the eSTREAM ciphers.  What other crypto primitives can you build out of that stream cipher?  In particular, are there any practical ways to build a cryptographic hash function and/or a MAC out of just a stream cipher?


We already have questions about turning a hash into a stream cipher and about turning a stream cipher into a block cipher, but this particular transformation doesn't seem to have been covered yet.

Obviously, if the platform constraints permit it, one could ignore the stream cipher and just implement a standard hash function from the ground up.  What I'm wondering is whether having the stream cipher available might let one do better than that in terms of code size, memory usage and/or speed.

While a construction that treats the stream cipher as a black box would be nice, schemes that only use parts of the stream cipher (like RC4-Hash, which, alas, has practical collision attacks) would be interesting too, at least if they're simple enough.
",Ilmari Karonen,https://crypto.stackexchange.com/users/598,"This is a really bad idea. Most stream ciphers, certainly RC4 and anything in a Counter Mode construction are ultimately a PRNG XORed onto the plaintext. This is fine for encryption -- the information theory is pretty easy to understand -- but is no basis for a hash function.

The goals of a hash function and a cipher are different. As it turns out, you can make a block cipher into a hash function, but even then not any block cipher makes for a good hash function.

Think of it this way -- a cipher is like a game of cards. It relies upon the fact that you can't see what's in your opponent's hand, and what makes it hard or intractable is the uncertainty. But a hash function is like a game of chess. Everyone knows everything, and the goal of the hash function is to make it so complex that you can't go backwards and that there's no easy way to predict forwards.
",Jon Callas,https://crypto.stackexchange.com/users/1702,http://crypto.stackexchange.com/questions/2214/can-you-make-a-hash-out-of-a-stream-cipher,TECHNOLOGY,crypto.stackexchange.com,0.6666666666666666,0.7777777777777778,0.0,0.5,1.0,1.0,0.6666666666666666,0.5555555555555556,0.3333333333333333,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.3333333333333333,0.0,1.0,1.0,0.5555555555555556,1.0,0.8888888888888888,0.6666666666666667,0.3333333333333333,0.0,1.0,1.0,Can you make a hash with a stream password?,"A comment on another question made me wonder about something:


  Assume you're on a rather constrained platform &mdash; say, a low-end embedded device &mdash; with no built-in crypto capabilities, but you do have access to a simple stream cipher; say, RC4 or one of the eSTREAM ciphers.  What other crypto primitives can you build out of that stream cipher?  In particular, are there any practical ways to build a cryptographic hash function and/or a MAC out of just a stream cipher?


We already have questions about turning a hash into a stream cipher and about turning a stream cipher into a block cipher, but this particular transformation doesn't seem to have been covered yet.

Obviously, if the platform constraints permit it, one could ignore the stream cipher and just implement a standard hash function from the ground up.  What I'm wondering is whether having the stream cipher available might let one do better than that in terms of code size, memory usage and/or speed.

While a construction that treats the stream cipher as a black box would be nice, schemes that only use parts of the stream cipher (like RC4-Hash, which, alas, has practical collision attacks) would be interesting too, at least if they're simple enough.
","This is a really bad idea. Most stream ciphers, certainly RC4 and anything in a Counter Mode construction are ultimately a PRNG XORed onto the plaintext. This is fine for encryption -- the information theory is pretty easy to understand -- but is no basis for a hash function.

The goals of a hash function and a cipher are different. As it turns out, you can make a block cipher into a hash function, but even then not any block cipher makes for a good hash function.

Think of it this way -- a cipher is like a game of cards. It relies upon the fact that you can't see what's in your opponent's hand, and what makes it hard or intractable is the uncertainty. But a hash function is like a game of chess. Everyone knows everything, and the goal of the hash function is to make it so complex that you can't go backwards and that there's no easy way to predict forwards.
"
4761,4761,7560,Differences between PS3 and Wii version of Rock Band The Beatles,"I'm considering buying Rock Band The Beatles for my only gaming console, the Nintendo Wii, but I was wondering if there are any big differences between the version on Wii and the version on Playstation 3?
",runaros,https://gaming.stackexchange.com/users/2968,"The only difference is with DLC. If you wish to download the remainder of Rubber Soul, Sgt Pepper or Abbey Road, you must pay for the tracks individually on the Wii rather than a group bundle.
",Jeff Winkworth,https://gaming.stackexchange.com/users/1539,http://gaming.stackexchange.com/questions/5707/differences-between-ps3-and-wii-version-of-rock-band-the-beatles,CULTURE,gaming.stackexchange.com,1.0,0.8888888888888888,0.3333333333333333,1.0,0.6666666666666666,1.0,0.7777777777777778,0.7777777777777778,0.0,0.0,0.6666666666666666,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,0.0,0.8888888888888888,The difference between PS3 and Wii rock band beatles,"I'm thinking about buying rock band beatles as my only console, Nintendo Wii, but I wonder what's the big difference between Wii and Playstation 3?","The only difference is DLC. If you want to download the rest of rubber soul, Sergeant Pepper or the way to the monastery, you have to pay separately on the Wii, not collectively."
4299,4299,6853,What kind of gasoline additives will help maintain the engine efficiency/life?,"Aside from the traditional maintenance of oil changes, and keeping fluid levels correct - what else will help prolong the engine's life?

I recall a few years back gasoline additives were the thing to go with - what's the best/recommended one currently? If any.

Edit: I recall reading about each gasoline brand having their own set of additives at one point, where it was suggested to cycle between a few different brands every X amount of km/miles. The reason behind switching was so that the next brand would cleanup any sediments left by the previous brand. How likely is this in today's world? And better yet, how important is it?
",Jesse,https://mechanics.stackexchange.com/users/2890,"The most important thing is to use good gas (Top Tier if you are in the states), and change your oil. Other than that, I use all high quality synthetic products from AMSOIL in my ride.

I personally use one bottle of their fuel treatment (P.i) in the spring and I use their oil flush before each oil change. Other than that I just keep to the maintenance schedules for when to flush/change fluids and filters etc...

Also if you are going to store your vehicle for any period of time never forget to use gasoline stabilizer.



Edit: Top Tier is a trademarked standard of gasoline which meets a certain specification or requirement for additives. You can read/see the retailers on their site.
",Mike Saull,https://mechanics.stackexchange.com/users/2895,http://mechanics.stackexchange.com/questions/5729/what-kind-of-gasoline-additives-will-help-maintain-the-engine-efficiency-life,SCIENCE,mechanics.stackexchange.com,1.0,0.4444444444444444,0.0,0.3333333333333333,1.0,0.6666666666666666,0.5555555555555556,0.4444444444444444,1.0,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,1.0,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.0,1.0,0.8888888888888888,Which gasoline additive helps maintain engine efficiency / life?,"Aside from the traditional maintenance of oil changes, and keeping fluid levels correct - what else will help prolong the engine's life?

I recall a few years back gasoline additives were the thing to go with - what's the best/recommended one currently? If any.

Edit: I recall reading about each gasoline brand having their own set of additives at one point, where it was suggested to cycle between a few different brands every X amount of km/miles. The reason behind switching was so that the next brand would cleanup any sediments left by the previous brand. How likely is this in today's world? And better yet, how important is it?
","The most important thing is to use good gas (Top Tier if you are in the states), and change your oil. Other than that, I use all high quality synthetic products from AMSOIL in my ride.

I personally use one bottle of their fuel treatment (P.i) in the spring and I use their oil flush before each oil change. Other than that I just keep to the maintenance schedules for when to flush/change fluids and filters etc...

Also if you are going to store your vehicle for any period of time never forget to use gasoline stabilizer.



Edit: Top Tier is a trademarked standard of gasoline which meets a certain specification or requirement for additives. You can read/see the retailers on their site.
"
1262,1262,1988,"Can the term ""jack/jerk off"" be used for female masturbation?","I apologize for this potentially obscene question.

Can the terms jack off or jerk off be used for female masturbation? If not (which is my intuition), what would be the not too poetic vulgar slang equivalent? By too poetic I refer to expressions such as spank the monkey, choke the chicken, etc.

I checked online dictionaries, and most of them don't expand on the usage, and some of the definitions in the Urban Dictionary imply that jack off primarily refers to male masturbation, but do not provide the female counterpart. 
",Armen Ծիրունյան,https://english.stackexchange.com/users/11268,"I would mention ""diddle, which is mentioned as a female alternative to ""masturbate"" alongside ""jill off"". By the way, it bears an assonance to ""dildo"", which is normally connected with female masturbation. See http://en.wiktionary.org/wiki/diddle
",Paola,https://english.stackexchange.com/users/19875,http://english.stackexchange.com/questions/60900/can-the-term-jack-jerk-off-be-used-for-female-masturbation,CULTURE,english.stackexchange.com,1.0,1.0,0.6666666666666666,1.0,0.0,0.3333333333333333,0.7777777777777778,0.6666666666666666,0.6666666666666666,0.0,1.0,1.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.7777777777777778,1.0,1.0,1.0,0.0,0.0,0.6666666666666666,0.8888888888888888,"Can the word ""Jack"" be used for female masturbation?","I apologize for this potentially obscene question.

Can the terms jack off or jerk off be used for female masturbation? If not (which is my intuition), what would be the not too poetic vulgar slang equivalent? By too poetic I refer to expressions such as spank the monkey, choke the chicken, etc.

I checked online dictionaries, and most of them don't expand on the usage, and some of the definitions in the Urban Dictionary imply that jack off primarily refers to male masturbation, but do not provide the female counterpart. 
","I would mention ""diddle, which is mentioned as a female alternative to ""masturbate"" alongside ""jill off"". By the way, it bears an assonance to ""dildo"", which is normally connected with female masturbation. See http://en.wiktionary.org/wiki/diddle
"
2759,2759,4397,Mystery cards in Magic 2015 card list,"If you look at the full card list for Magic 2015, at Gatherer or elsewhere, you'll see a bunch of cards listed with collectors number 270-284. What are these cards, and why are they listed as being part of Magic 2015? I played enough M15 Limited to be pretty sure that they aren't actually present in packs, and they're listed after the basic lands, which is very unusual. Is there some secret, bonus release of M15 that had these extra cards?
",JSBձոգչ,https://boardgames.stackexchange.com/users/156,"You are correct, these cards are not in booster packs. For the past few years, Wizards has put out 30 card sample decks to introduce new players into the game. This year they decided to put into these packs a number of reprinted cards not actually present in M15: see here for decklists. Like the article mentions, the Deck Builder's Toolkit for M15 also has the extra cards.

Since putting two of these sample decks together gives a basic 60 card, two-color deck, Wizards expects a number of people to do just that to build their first standard deck. They made those extra cards explicitly standard legal to allow people that option; most people would assume by default that such a deck is playable.
",Michael Snook,https://boardgames.stackexchange.com/users/7613,http://boardgames.stackexchange.com/questions/19165/mystery-cards-in-magic-2015-card-list,CULTURE,boardgames.stackexchange.com,1.0,0.4444444444444444,0.0,1.0,1.0,1.0,0.7777777777777778,0.6666666666666666,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,1.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,0.8888888888888888,Magic's Secret card ranking in 2015,"If you look at the complete list of magic 2015 cards in the gatherer or elsewhere, you will see a pile of cards listing collectors numbered 270-284. What are these cards and why are they listed as part of magic 2015? I played enough M15 restrictions to make sure they didn't actually appear in the package and they were listed in the base land, which is very unusual. Are there any secrets that bonus release M15 has these extra cards?","You are correct, these cards are not in booster packs. For the past few years, Wizards has put out 30 card sample decks to introduce new players into the game. This year they decided to put into these packs a number of reprinted cards not actually present in M15: see here for decklists. Like the article mentions, the Deck Builder's Toolkit for M15 also has the extra cards.

Since putting two of these sample decks together gives a basic 60 card, two-color deck, Wizards expects a number of people to do just that to build their first standard deck. They made those extra cards explicitly standard legal to allow people that option; most people would assume by default that such a deck is playable.
"
4853,4853,7722,Remove hostednetwork password,"I've set up my own Nintendo HomePass relay to get StreetPass from home, but recently something has changed and it doesn't work anymore. I've read I have to change some settings to make it work again, and I need to remove the password of my hosted network.

I know how to change hosted network settings:

netsh wlan set hostednetwork mode=allow ssid=&lt;mySSID&gt; key=&lt;password&gt;


But I don't know the command to remove the current key, or how to set the network as free. Or the command to delete the previous saved network, in order to set up a new one without the key attribute.  

Any hint?
",pinckerman,https://superuser.com/users/402950,"There are several methods to delete a hosted network.

Method 1 : Network and Sharing Center

Right click on the Network icon in the notification area () and
choose ""Network and Sharing Center"".

In the Network and Sharing Center windows, click on ""Change Adapter settings"",
to see all of your network connections. This will look like:



Select the Hosted Network and press the Delete button, then restart your PC.

Method 2 : Command-line to delete the virtual adapter

Open the Command Prompt with Administrator rights and enter the following command:

netsh wlan stop hostednetwork


You will receive a message confirming that the wireless hosted network stopped.
However it is not yet disabled.
In order to disable it, enter this command:

netsh wlan set hostednetwork mode=disallow


The result is the message ""The hosted network mode has been set to disallow"".
You'll also notice that the virtual adapter is no longer listed in the Network and Sharing Center.

Furthermore, if you want to double-check the status of the hosted network, you can run the following command:

netsh wlan show settings


It should say : ""Hosted network mode allowed in WLAN service: No"".

Method 3 : Command-line to delete/forget one network

Start the Command Prompt as administrator and type the following command :

netsh wlan show profiles


It will display all the wireless network profiles stored by Windows 8.1. The list can be long if you used your laptop or tablet for more than a couple of weeks :



Identify the name of the wireless network profile you want removed, then type the following command to remove it:

netsh wlan delete profile name=""swisscom""


Method 4 : Command-line to delete/forget all networks

In some scenarios you may need to remove all the wireless network profiles stored in Windows 8.1. 
This is done using this command:

netsh wlan delete profile name=* i=*

",harrymc,https://superuser.com/users/8672,http://superuser.com/questions/860626,TECHNOLOGY,superuser.com,0.8888888888888888,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,0.8888888888888888,Delete host network password,"I've set up my own Nintendo HomePass relay to get StreetPass from home, but recently something has changed and it doesn't work anymore. I've read I have to change some settings to make it work again, and I need to remove the password of my hosted network.

I know how to change hosted network settings:

netsh wlan set hostednetwork mode=allow ssid=&lt;mySSID&gt; key=&lt;password&gt;


But I don't know the command to remove the current key, or how to set the network as free. Or the command to delete the previous saved network, in order to set up a new one without the key attribute.  

Any hint?
","There are several methods to delete a hosted network.

Method 1 : Network and Sharing Center

Right click on the Network icon in the notification area () and
choose ""Network and Sharing Center"".

In the Network and Sharing Center windows, click on ""Change Adapter settings"",
to see all of your network connections. This will look like:



Select the Hosted Network and press the Delete button, then restart your PC.

Method 2 : Command-line to delete the virtual adapter

Open the Command Prompt with Administrator rights and enter the following command:

netsh wlan stop hostednetwork


You will receive a message confirming that the wireless hosted network stopped.
However it is not yet disabled.
In order to disable it, enter this command:

netsh wlan set hostednetwork mode=disallow


The result is the message ""The hosted network mode has been set to disallow"".
You'll also notice that the virtual adapter is no longer listed in the Network and Sharing Center.

Furthermore, if you want to double-check the status of the hosted network, you can run the following command:

netsh wlan show settings


It should say : ""Hosted network mode allowed in WLAN service: No"".

Method 3 : Command-line to delete/forget one network

Start the Command Prompt as administrator and type the following command :

netsh wlan show profiles


It will display all the wireless network profiles stored by Windows 8.1. The list can be long if you used your laptop or tablet for more than a couple of weeks :



Identify the name of the wireless network profile you want removed, then type the following command to remove it:

netsh wlan delete profile name=""swisscom""


Method 4 : Command-line to delete/forget all networks

In some scenarios you may need to remove all the wireless network profiles stored in Windows 8.1. 
This is done using this command:

netsh wlan delete profile name=* i=*

"
3004,3004,4788,business-class fiber to the home,"Suppose you're some sort of crazy nerd fellow and you live in an area that's absolutely covered in fiber optics and network facilities. What kind of cost / infrastructure would be needed to hook in somewhere and get you're internet connection directly from a local datacenter?
",neoice,https://serverfault.com/users/6134,"Fiber to the home would require laying a fiber optic cable, direct to you, over the ""last mile"".  This is what Verizon does with its FiOS service.  This is not cheap.  You need permits to dig, you need to hire a construction team, you need to have them bring out the big orange spools of plastic.  This is not something you would ever, ever do on your own.

Now, a normal leased line might be worth looking into.  But, if you're in an area with that much outlay already, you can probably get 50Mbps cable; try it out first and see if it's inadequate before you spring for crazy upgrades.
",Borealid,https://serverfault.com/users/47717,http://serverfault.com/questions/158286,TECHNOLOGY,serverfault.com,0.8888888888888888,0.4444444444444444,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.3333333333333333,0.6666666666666666,1.0,Business class fiber home,"Suppose you're a crazy nerd, living in a place that's completely covered by fiber optics and networking. What cost / infrastructure is needed to connect to a place and directly from the local data center to the Internet?","Fiber to the home would require laying a fiber optic cable, direct to you, over the ""last mile"".  This is what Verizon does with its FiOS service.  This is not cheap.  You need permits to dig, you need to hire a construction team, you need to have them bring out the big orange spools of plastic.  This is not something you would ever, ever do on your own.

Now, a normal leased line might be worth looking into.  But, if you're in an area with that much outlay already, you can probably get 50Mbps cable; try it out first and see if it's inadequate before you spring for crazy upgrades.
"
6023,6023,9557,Planet orbits: what's the difference between gravity and centripetal force?,"My physics teacher says that centripetal force is caused by gravity. I'm not entirely sure how this works? How can force cause another in space (ie where there's nothing). 

My astronomy teacher says that gravity is (note: not like) a 3D blanket and when you put mass on it, the mass causes a dip/dent in the blanket and so if you put another object with less mass it will roll down the dip onto the bigger mass. Is this true and is this what causes the centripetal force. 
",Jonathan.,https://physics.stackexchange.com/users/4,"Simple answer: gravity is a centripetal force, and can be envisaged clearly as such in Newtonian mechanics.

Centripetal just means a force that is ""radially inwards"" (""directed towards the centre""). The electric force, for example, is also clearly centripetal. (It's slightly harder to define ""centripetal"" for the magnetic force.)

Your astronomy teacher is referring to Einstein's theory of general relativity. His description is loosely an overview  of the topology (fabric) of space-time and how it interacts with matter/energy - the manifold is however 4-dimensional, not 3D.

In fact, test particles (particles which do not really disturb the gravitational field) in general relativity follow a geodesic. This is effectively a generalisation of a straight line (shortest route) of normal Euclidian space to the curved space of GR, and may be seen as the source of centripetal force in Newtonian physics.
",Noldorin,https://physics.stackexchange.com/users/13,http://physics.stackexchange.com/questions/321/planet-orbits-whats-the-difference-between-gravity-and-centripetal-force,SCIENCE,physics.stackexchange.com,0.8888888888888888,0.6666666666666666,0.0,0.3333333333333333,1.0,1.0,0.5555555555555556,0.6666666666666666,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,0.8888888888888888,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,1.0,Planetary orbit: what's the difference between gravity and centripetal force?,"My physics teacher says that centripetal force is caused by gravity. I'm not entirely sure how this works? How can force cause another in space (ie where there's nothing). 

My astronomy teacher says that gravity is (note: not like) a 3D blanket and when you put mass on it, the mass causes a dip/dent in the blanket and so if you put another object with less mass it will roll down the dip onto the bigger mass. Is this true and is this what causes the centripetal force. 
","Simple answer: gravity is a centripetal force, and can be envisaged clearly as such in Newtonian mechanics.

Centripetal just means a force that is ""radially inwards"" (""directed towards the centre""). The electric force, for example, is also clearly centripetal. (It's slightly harder to define ""centripetal"" for the magnetic force.)

Your astronomy teacher is referring to Einstein's theory of general relativity. His description is loosely an overview  of the topology (fabric) of space-time and how it interacts with matter/energy - the manifold is however 4-dimensional, not 3D.

In fact, test particles (particles which do not really disturb the gravitational field) in general relativity follow a geodesic. This is effectively a generalisation of a straight line (shortest route) of normal Euclidian space to the curved space of GR, and may be seen as the source of centripetal force in Newtonian physics.
"
1548,1548,2430,Differences between PS3 and Wii version of Rock Band The Beatles,"I'm considering buying Rock Band The Beatles for my only gaming console, the Nintendo Wii, but I was wondering if there are any big differences between the version on Wii and the version on Playstation 3?
",runaros,https://gaming.stackexchange.com/users/2968,"The only real difference is the graphics and maybe sound quality of the game.  More so the graphics though but, not enough for it to bother me honestly. 
",Corv1nus,https://gaming.stackexchange.com/users/44,http://gaming.stackexchange.com/questions/5707/differences-between-ps3-and-wii-version-of-rock-band-the-beatles,CULTURE,gaming.stackexchange.com,1.0,1.0,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.0,0.0,0.6666666666666666,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8,0.0,0.0,0.0,0.8888888888888888,The difference between PS3 and Wii rock band beatles,"I'm thinking about buying rock band beatles as my only console, Nintendo Wii, but I wonder what's the big difference between Wii and Playstation 3?","The only real difference is the graphics and maybe sound quality of the game.  More so the graphics though but, not enough for it to bother me honestly. 
"
3112,3112,4959,What abilities can be blocked by sivir's/nocturne's spell shield?,"Mainly, im wondering what ultimates would be blocked, and other spells that have long casts. But if you have a list that would be nice.
",Peter Jessen,https://gaming.stackexchange.com/users/34312,"
Spell shields block all activation of spells (Starts of channels included).
They do not block DoTs during the effect.
They do not break targeted channeled effects (Fiddle's drain as an example)
They do block spells of any type as long as it's a targeted single-hit spell (Magical, Physical and On-Hit effects) (For Requiem, the shield can be cast to block the damage part post-channel)
They do block ONE tick out of series of persistent damage abilities. (Panth's HSS, Kennens Maelstrom.)


There are several things I'm still not sure of, such as how Viktor's CC field and Ultimate are affected, or how the shields reacts to on-hit effects.
",user1337,https://gaming.stackexchange.com/users/37332,http://gaming.stackexchange.com/questions/105682/what-abilities-can-be-blocked-by-sivirs-nocturnes-spell-shield,CULTURE,gaming.stackexchange.com,1.0,0.7777777777777778,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.0,0.6666666666666666,0.8888888888888888,What ability can be blocked by the magic shield of sylvier / Nocturne?,"Basically, I want to know what ultimatums are blocked, and other spells that have a long cast time. But it would be great if you had a list.","
Spell shields block all activation of spells (Starts of channels included).
They do not block DoTs during the effect.
They do not break targeted channeled effects (Fiddle's drain as an example)
They do block spells of any type as long as it's a targeted single-hit spell (Magical, Physical and On-Hit effects) (For Requiem, the shield can be cast to block the damage part post-channel)
They do block ONE tick out of series of persistent damage abilities. (Panth's HSS, Kennens Maelstrom.)


There are several things I'm still not sure of, such as how Viktor's CC field and Ultimate are affected, or how the shields reacts to on-hit effects.
"
4065,4065,6488,Adding new menu item to QGIS Desktop app,"I need to add new menu item to the top level menu of QGIS Desktop (2.7.0);
I.e. it shall be on same level as ""Project"", ""Edit"", ""View"", ""Layer"" etc.

As far as I know there is pretty nice way how hide menu items (Settings->Customization)
Plus using QgisInterface (http://qgis.org/api/classQgisInterface.html) I can add new items to Menus already defined in QGIS (addLayerMenu, addPluginToDatabaseMenu etc) from my plugin code.

But I need new Menu item on top layer (this is req from customer):
will very appreciate if any ideas how can I make so

Thanks!
",Egor.Baykov,https://gis.stackexchange.com/users/47877,"You can add a custom menu to the QGIS GUI this way:

self.menu = QMenu( ""&amp;My tools"", self.iface.mainWindow().menuBar() )
actions = self.iface.mainWindow().menuBar().actions()
lastAction = actions[-1]
self.iface.mainWindow().menuBar().insertMenu( lastAction, self.menu )


As you can see in the code snippet above, you are adding a menu to the second to last position of the menu bar, right before the Help menu.



Then, you can add an action to your newly added menu this way:

self.menu.addAction( self.action )


You may already know, but just to make it clear, such GUI configuration should normally be located in the initGui() method of your plugin.
",Germán Carrillo,https://gis.stackexchange.com/users/4972,http://gis.stackexchange.com/questions/136267/adding-new-menu-item-to-qgis-desktop-app,TECHNOLOGY,gis.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,0.6666666666666666,1.0,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.5555555555555556,1.0,0.7777777777777778,1.0,1.0,0.9333333333333332,1.0,0.3333333333333333,0.0,1.0,Add new menu item to QGIS desktop application,"I need to add new menu item to the top level menu of QGIS Desktop (2.7.0);
I.e. it shall be on same level as ""Project"", ""Edit"", ""View"", ""Layer"" etc.

As far as I know there is pretty nice way how hide menu items (Settings->Customization)
Plus using QgisInterface (http://qgis.org/api/classQgisInterface.html) I can add new items to Menus already defined in QGIS (addLayerMenu, addPluginToDatabaseMenu etc) from my plugin code.

But I need new Menu item on top layer (this is req from customer):
will very appreciate if any ideas how can I make so

Thanks!
","You can add a custom menu to the QGIS GUI this way:

self.menu = QMenu( ""&amp;My tools"", self.iface.mainWindow().menuBar() )
actions = self.iface.mainWindow().menuBar().actions()
lastAction = actions[-1]
self.iface.mainWindow().menuBar().insertMenu( lastAction, self.menu )


As you can see in the code snippet above, you are adding a menu to the second to last position of the menu bar, right before the Help menu.



Then, you can add an action to your newly added menu this way:

self.menu.addAction( self.action )


You may already know, but just to make it clear, such GUI configuration should normally be located in the initGui() method of your plugin.
"
1075,1075,1695,Why does cyclopropane give bromine water test?,"This question was in my exam and all I could tell was that it is related to high angle strain as the angle is $60^\circ$ in stead of required $109.5^\circ$. No book I have read mentions this. Also, what is the product formed?
",evil999man,https://chemistry.stackexchange.com/users/4597,"The $\ce{H-C-H}$ angle in cyclopropane has been measured to be 114 degrees.  From this, and using Coulson's Theorem $$\ce{1+\lambda^2cos(114)=0}$$ where $\ce{\lambda^2}$ represents the hybridization index of the bond, the $\ce{C-H}$ bonds in cyclopropane can be deduced to be $\ce{sp^{2.46}}$ hybridized.  Now, using the equation $$\ce{\frac{2}{1+\lambda^_{C-H}^2}+\frac{2}{1+\lambda_{C-C}^2}=1}$$ (which says that summing the ""s"" character in all bonds at a given carbon must total to 1) we find that $\ce{\lambda_{c-c}^2=3.74}$, or the C-C bond is $\ce{sp^{3.74}}$ hybridized.  We see that the C-C bond in cyclopropane is very high in $\ce{P}$ character.  It is this high $\ce{P}$ content that allows cycloprane to behave in a similar fashion to an olefin in terms of stabilizing adjacent charge, absorbing bromine, etc.  By the way, an x-ray study of a cyclopropane derivative (Acta Cryst., 20, 80 (1966)) shows significant electron density only exterior to the cyclopropane ring, there is NO significant electron density interior to the ring, consistent with this analysis.
",ron,https://chemistry.stackexchange.com/users/4231,http://chemistry.stackexchange.com/questions/10653/why-does-cyclopropane-give-bromine-water-test,SCIENCE,chemistry.stackexchange.com,0.7777777777777778,0.4444444444444444,0.0,0.3333333333333333,1.0,1.0,0.5555555555555556,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.3333333333333333,0.0,0.0,1.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,0.8888888888888888,0.8,0.3333333333333333,0.0,1.0,0.8888888888888888,Why does cyclopropane need bromine water test?,"This problem is that in my exam, all I can know is that it is related to the large angle strain, because the angle is $60 ^ \ CIRC $, not the necessary $109.5 ^ \ CIRC $. This is not mentioned in the book I read. In addition, what form is the product?","The $\ce{H-C-H}$ angle in cyclopropane has been measured to be 114 degrees.  From this, and using Coulson's Theorem $$\ce{1+\lambda^2cos(114)=0}$$ where $\ce{\lambda^2}$ represents the hybridization index of the bond, the $\ce{C-H}$ bonds in cyclopropane can be deduced to be $\ce{sp^{2.46}}$ hybridized.  Now, using the equation $$\ce{\frac{2}{1+\lambda^_{C-H}^2}+\frac{2}{1+\lambda_{C-C}^2}=1}$$ (which says that summing the ""s"" character in all bonds at a given carbon must total to 1) we find that $\ce{\lambda_{c-c}^2=3.74}$, or the C-C bond is $\ce{sp^{3.74}}$ hybridized.  We see that the C-C bond in cyclopropane is very high in $\ce{P}$ character.  It is this high $\ce{P}$ content that allows cycloprane to behave in a similar fashion to an olefin in terms of stabilizing adjacent charge, absorbing bromine, etc.  By the way, an x-ray study of a cyclopropane derivative (Acta Cryst., 20, 80 (1966)) shows significant electron density only exterior to the cyclopropane ring, there is NO significant electron density interior to the ring, consistent with this analysis.
"
1679,1679,2653,"Are there fluid tripod heads made for panning with a lightweight, compact camera?","Are there fluid tripod heads made for use with compact or at least lightweight cameras (such as my LX100)? Most seem built to support a tank (or full-blown DSLR/video camera). 

I would like to be able to pan with my small compact.
",lara michaels,https://photo.stackexchange.com/users/37614,"Since you have specifically asked for a Fluid Head - presumably for video work - I Just bought a Manfrotto MVH500AH
(http://www.manfrotto.co.uk/lightweight-fluid-video-head-flat-base)

This is a fairly lightweight head which I have used for everything between a Sony NEX5 and a Nikon D800, even a Black Magic Ursa.

Very smooth, adjustable drag, lockable etc.

BUT you will need a suitably sturdy tripod, a cheapo twisty bendy thing just wont cut it.
",Digital Lightcraft,https://photo.stackexchange.com/users/9999,http://photo.stackexchange.com/questions/65896/are-there-fluid-tripod-heads-made-for-panning-with-a-lightweight-compact-camera,LIFE_ARTS,photo.stackexchange.com,0.8888888888888888,1.0,0.0,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.8888888888888888,1.0,0.7777777777777778,1.0,1.0,0.8,0.0,0.0,0.0,0.7777777777777778,Is there a small and light camera with tripod head for translation?,Is there a liquid tripod head for use with compact or at least lightweight cameras (like my lx100)? Most seem to support tanks (or all-around SLRs / cameras).,"Since you have specifically asked for a Fluid Head - presumably for video work - I Just bought a Manfrotto MVH500AH
(http://www.manfrotto.co.uk/lightweight-fluid-video-head-flat-base)

This is a fairly lightweight head which I have used for everything between a Sony NEX5 and a Nikon D800, even a Black Magic Ursa.

Very smooth, adjustable drag, lockable etc.

BUT you will need a suitably sturdy tripod, a cheapo twisty bendy thing just wont cut it.
"
4703,4703,7457,Breaking Masterwork Weapons/Armor,"I have an encounter in which my party will be fighting a slime that deals damage to their armor and weapons. My whole party has at least 2 masterworked items. Does masterwork imply that the items can not be broken?

Thank You
",DoomWolf,https://rpg.stackexchange.com/users/9549,"No

The masterwork property does a few things for items, but making them immune to breaking is not one of them. It does grant +1 to hit, and allows the item to be made into a magic item. Masterwork items that have been broken, be it through sundering etc., still have to be repaired like any other item (the exception is the Durable magic property).
",LeesusFreak,https://rpg.stackexchange.com/users/14626,http://rpg.stackexchange.com/questions/41156/breaking-masterwork-weapons-armor,CULTURE,rpg.stackexchange.com,1.0,0.5,0.0,1.0,1.0,1.0,0.5,0.6666666666666666,0.0,0.0,0.5,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,0.5,1.0,Broken masterpiece weapon / armor,I have a encounter where my team will fight a slime that causes damage to their armor and weapons. My whole Party has at least two masterpieces. Does a masterpiece mean that objects cannot be broken?,"No

The masterwork property does a few things for items, but making them immune to breaking is not one of them. It does grant +1 to hit, and allows the item to be made into a magic item. Masterwork items that have been broken, be it through sundering etc., still have to be repaired like any other item (the exception is the Durable magic property).
"
3549,3549,5659,Making new verbs from the given words,"The book asks me to make new verbs from the following words: clear, noble, body, rate, store.

For clear, I can use clarify; for body, embody; for store, restore.

For noble, I am not able to think of any new verb. For rate, ratify doesn't just satisfy me because I guess the meaning of rate and ratify are different, unlikely from clear and clarify which still have the same kind of meaning.

I wish somebody could help me with noble and rate.
",Ramit,https://ell.stackexchange.com/users/2273,"clear -> clarify, meaning to make clear.

noble -> ennoble, meaning to make noble. That word is used in the sense of ""make this person a member of the nobility"" and also ""make an action grand or self-sacrificing"".

body -> embody, to put something into concrete form.

rate is already a verb. I guess you could say rate -> rate.

Likewise store is already a verb.
",Jay,https://ell.stackexchange.com/users/803,http://ell.stackexchange.com/questions/10481/making-new-verbs-from-the-given-words,CULTURE,ell.stackexchange.com,1.0,0.3333333333333333,0.0,1.0,1.0,0.0,0.5555555555555556,0.6666666666666666,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.8888888888888888,1.0,0.7777777777777778,1.0,1.0,0.8666666666666666,0.0,0.0,0.0,0.8888888888888888,Create a new verb from a given word,"The book asks me to make new verbs from the following words: clear, noble, body, rate, store.

For clear, I can use clarify; for body, embody; for store, restore.

For noble, I am not able to think of any new verb. For rate, ratify doesn't just satisfy me because I guess the meaning of rate and ratify are different, unlikely from clear and clarify which still have the same kind of meaning.

I wish somebody could help me with noble and rate.
","clear -> clarify, meaning to make clear.

noble -> ennoble, meaning to make noble. That word is used in the sense of ""make this person a member of the nobility"" and also ""make an action grand or self-sacrificing"".

body -> embody, to put something into concrete form.

rate is already a verb. I guess you could say rate -> rate.

Likewise store is already a verb.
"
739,739,1173,"Get Custom Web template name programmatically , Sharepoint 2013","I am trying to get the web template name that is being used currently in order to create the site.

I have created and EvenReceiver and overriding WebProvisioned. in this method i would like to get the name of the template i am currently using in order to create the subsite.

I am using code below. GetCustomWebTemplates and GetWebTemplates gives list of all the templates but i am only interested in getting the name of the current one. Is it possible? any idea how can we do that? Kindly help.

using (SPSite thisSite = new SPSite(properties.FullUrl))
        {
            SPWeb thisWeb = thisSite.OpenWeb();

            SPWebTemplateCollection stc = thisSite.GetWebTemplates(thisWeb.Language);
            foreach (SPWebTemplate sc in stc)
            {
                string MyTempleName = sc.Name;
            }

        }

",Ishan,https://sharepoint.stackexchange.com/users/6696,"Use SPWeb.WebTemplate to get the name of the template. 

using (SPSite thisSite = new SPSite(properties.FullUrl))
        {
            SPWeb thisWeb = thisSite.OpenWeb();

            string MyTempleName = thisWeb.WebTemplate ;

        }

",Nadeem Yousuf,https://sharepoint.stackexchange.com/users/9472,http://sharepoint.stackexchange.com/questions/130107/get-custom-web-template-name-programmatically-sharepoint-2013,TECHNOLOGY,sharepoint.stackexchange.com,1.0,0.5555555555555556,0.0,0.5,1.0,1.0,0.3333333333333333,0.3333333333333333,1.0,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.0,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,0.8888888888888888,"Get custom web template name programmatically, SharePoint 2013","I am trying to get the web template name that is being used currently in order to create the site.

I have created and EvenReceiver and overriding WebProvisioned. in this method i would like to get the name of the template i am currently using in order to create the subsite.

I am using code below. GetCustomWebTemplates and GetWebTemplates gives list of all the templates but i am only interested in getting the name of the current one. Is it possible? any idea how can we do that? Kindly help.

using (SPSite thisSite = new SPSite(properties.FullUrl))
        {
            SPWeb thisWeb = thisSite.OpenWeb();

            SPWebTemplateCollection stc = thisSite.GetWebTemplates(thisWeb.Language);
            foreach (SPWebTemplate sc in stc)
            {
                string MyTempleName = sc.Name;
            }

        }

","Use SPWeb.WebTemplate to get the name of the template. 

using (SPSite thisSite = new SPSite(properties.FullUrl))
        {
            SPWeb thisWeb = thisSite.OpenWeb();

            string MyTempleName = thisWeb.WebTemplate ;

        }

"
2390,2390,3815,Bash script- Create usernames and passwords from txt file and store in group?,"This script takes a .txt file with four columns- which contains LastName FirstName MiddleInitial Group-as an argument and needs to create a unique username and password for each person; and then assign each user the appropriate directory depending on their group: i.e. If ""John Doe"" is in ""mgmt"" group, and his username is jdoe1234, then his directory would be /home/mgmt/jdoe1234. It should then generate a .txt file which contains the following columns- LastName FirstName UID(userid) Password- .

I have the following:

#!/bin/bash
IFS=$'\n';
for i in `cat $1`;
do
    last=`echo $i|cut -f 1 -d ' '`;
    first=`echo $i|cut -f 2 -d ' '`;
    middle=`echo $i|cut -f 3 -d ' '`;
    groups=`echo $i|cut -f 4 -d ' '`;
    r=$(( $RANDOM % 10 ));
    s=$(( $RANDOM % 10 ));
    y=$(( $RANDOM % 10 ));
    username=`echo $first| head -c 1 &amp;&amp; echo $last| head -c 3 &amp;&amp; echo $r$s$y`
    echo $username
done
#check if group exists, if not then create one
for group in ${groups[*]}
do
    grep -q ""^$group"" /etc/group ; let x=$?
    if [ $x -eq 1 ]
    then
            groupadd ""$group""
    fi
done

#try to add user to correct group
x=0
created=0
for user in ${username[*]}
do
    useradd -n -g ""{groups[$x]}"" -m $user 2&gt; /dev/null
done


I want the username to contain: 1st letter of firstName, first 3 letters of the lastName, the middle initial, and then 3 randomly generated numbers. So not exactly the same as the above example with John Doe but similar. It can't be any more than 8 characters. I'm not sure if I'm creating the usernames properly.

Of course, I'm having trouble with the password too; not sure if it needs to be created alongside the username or after.

After the first 'for loop' I first try to add a group if it doesn't already exist, and then I make an attempt at putting the usernames into the correct groups. I got the syntax off a Youtube video but he was working with it as arrays and I'm not sure if I'm doing that or not.

If it helps, let's say the .txt file contains:

doe john a mgmt
lee amy f temp
smith tracy s empl


If you have time, any help at all would be appreciated. Thank you.
",Jay,https://stackoverflow.com/users/4164304,"Depending on which distro you are using, there are a few alterations to your script which will help. I have not had time to actually test this, so use with caution: 

#!/bin/bash

# This will loop through the argumented txt file, and create the users as necessary.
# You will need to run this as root, so be very careful. Start with a small user file.

line=1 # Initiate variable for counting.
count=""$(cat $1 | wc -l)""  # This counts the number of lines, which will decide how many times the loop itterates.
until [ $line -gt $count ]
do
    # Begin by grabbing one line (user to be added)
    newuser=""$(head -$line $1 | tail -1)"" # This gets just the one line at a time.
    # Now split the data as needed according to your original post:
    fname=""$(echo $newuser | awk '{print $2}')"" # AWK to get First Name
    lname=""$(echo $newuser | awk '{print $1}')"" # AWK to get Last Name
    minit=""$(echo $newuser | awk '{print $3}')"" # AWK to get middle initial
    group=""$(echo $newuser | awk '{print $4}')"" # AWK to get Group
    # Now create the random username.
    initial=""$(echo $fname | head -c 1)""
    random=""$(shuf -i 1-9 -z -n 3)""
    shortname=""$(echo $lname | head -c 3)""
    username=""$initial$shortname$random"" # This will output exactly what is needed, although your example does not stick to what you want...
    # Now create the user.
    # Does group exist?
    if egrep -i ""^$group"" /etc/group
    then
        true # This is not the best way to do this, but my toddler kept me up all night...
    else
        groupadd $group
    fi
    if [ ! -d ""/home/$group"" ]
    then
        mkdir -m 774 /home/$group
    fi
    # Make the home dir.
    mkdir -m 777 /home/$group/$username

    # Actual useradd command
    useradd -g $group -d /home/$group/$username -p $(openssl passwd -1 $username) $username
    if [ $? = 0 ]
    then
       echo ""User $username has been successfully created.""
       chown $username:$group /home/$group/$username
       chmod 755 /home/$group/$username
    else
       echo ""Something went wrong, user $username was NOT created.""
       rm /home/$group/$username
    fi

    # Now generate line for txt output file
    output=""$lname $fname $(id -u $username) $username""
    printf ""\n$output"" &gt;&gt;./output.txt
    # Now increment the counter
    line=""$((line +1))""
done

exit


Like I said in the beginning, I haven't tested this properly, because I don't really want to create a bunch of users :-) so be careful - test the useradd line first. The rest should be solid.
",asimovwasright,https://stackoverflow.com/users/3749769,http://stackoverflow.com/questions/28957168/bash-script-create-usernames-and-passwords-from-txt-file-and-store-in-group,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.5555555555555556,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,0.0,0.8888888888888888,Bash script - create user name and password from TXT file and store in group?,"This script takes a .txt file with four columns- which contains LastName FirstName MiddleInitial Group-as an argument and needs to create a unique username and password for each person; and then assign each user the appropriate directory depending on their group: i.e. If ""John Doe"" is in ""mgmt"" group, and his username is jdoe1234, then his directory would be /home/mgmt/jdoe1234. It should then generate a .txt file which contains the following columns- LastName FirstName UID(userid) Password- .

I have the following:

#!/bin/bash
IFS=$'\n';
for i in `cat $1`;
do
    last=`echo $i|cut -f 1 -d ' '`;
    first=`echo $i|cut -f 2 -d ' '`;
    middle=`echo $i|cut -f 3 -d ' '`;
    groups=`echo $i|cut -f 4 -d ' '`;
    r=$(( $RANDOM % 10 ));
    s=$(( $RANDOM % 10 ));
    y=$(( $RANDOM % 10 ));
    username=`echo $first| head -c 1 &amp;&amp; echo $last| head -c 3 &amp;&amp; echo $r$s$y`
    echo $username
done
#check if group exists, if not then create one
for group in ${groups[*]}
do
    grep -q ""^$group"" /etc/group ; let x=$?
    if [ $x -eq 1 ]
    then
            groupadd ""$group""
    fi
done

#try to add user to correct group
x=0
created=0
for user in ${username[*]}
do
    useradd -n -g ""{groups[$x]}"" -m $user 2&gt; /dev/null
done


I want the username to contain: 1st letter of firstName, first 3 letters of the lastName, the middle initial, and then 3 randomly generated numbers. So not exactly the same as the above example with John Doe but similar. It can't be any more than 8 characters. I'm not sure if I'm creating the usernames properly.

Of course, I'm having trouble with the password too; not sure if it needs to be created alongside the username or after.

After the first 'for loop' I first try to add a group if it doesn't already exist, and then I make an attempt at putting the usernames into the correct groups. I got the syntax off a Youtube video but he was working with it as arrays and I'm not sure if I'm doing that or not.

If it helps, let's say the .txt file contains:

doe john a mgmt
lee amy f temp
smith tracy s empl


If you have time, any help at all would be appreciated. Thank you.
","Depending on which distro you are using, there are a few alterations to your script which will help. I have not had time to actually test this, so use with caution: 

#!/bin/bash

# This will loop through the argumented txt file, and create the users as necessary.
# You will need to run this as root, so be very careful. Start with a small user file.

line=1 # Initiate variable for counting.
count=""$(cat $1 | wc -l)""  # This counts the number of lines, which will decide how many times the loop itterates.
until [ $line -gt $count ]
do
    # Begin by grabbing one line (user to be added)
    newuser=""$(head -$line $1 | tail -1)"" # This gets just the one line at a time.
    # Now split the data as needed according to your original post:
    fname=""$(echo $newuser | awk '{print $2}')"" # AWK to get First Name
    lname=""$(echo $newuser | awk '{print $1}')"" # AWK to get Last Name
    minit=""$(echo $newuser | awk '{print $3}')"" # AWK to get middle initial
    group=""$(echo $newuser | awk '{print $4}')"" # AWK to get Group
    # Now create the random username.
    initial=""$(echo $fname | head -c 1)""
    random=""$(shuf -i 1-9 -z -n 3)""
    shortname=""$(echo $lname | head -c 3)""
    username=""$initial$shortname$random"" # This will output exactly what is needed, although your example does not stick to what you want...
    # Now create the user.
    # Does group exist?
    if egrep -i ""^$group"" /etc/group
    then
        true # This is not the best way to do this, but my toddler kept me up all night...
    else
        groupadd $group
    fi
    if [ ! -d ""/home/$group"" ]
    then
        mkdir -m 774 /home/$group
    fi
    # Make the home dir.
    mkdir -m 777 /home/$group/$username

    # Actual useradd command
    useradd -g $group -d /home/$group/$username -p $(openssl passwd -1 $username) $username
    if [ $? = 0 ]
    then
       echo ""User $username has been successfully created.""
       chown $username:$group /home/$group/$username
       chmod 755 /home/$group/$username
    else
       echo ""Something went wrong, user $username was NOT created.""
       rm /home/$group/$username
    fi

    # Now generate line for txt output file
    output=""$lname $fname $(id -u $username) $username""
    printf ""\n$output"" &gt;&gt;./output.txt
    # Now increment the counter
    line=""$((line +1))""
done

exit


Like I said in the beginning, I haven't tested this properly, because I don't really want to create a bunch of users :-) so be careful - test the useradd line first. The rest should be solid.
"
2088,2088,3326,Displaying articles created by user in profile page using views,"I want to display the articles created by user in user profile page. It should also display to anonymous user also.

For example : twitter.com/google displays all tweets by google.

Like that I want to display xyz.com/john. I want to display all articles created by john in user profile page.

I also want to know how to add that view to profile page.
",Monish,https://drupal.stackexchange.com/users/35836,"Add a contextual filter to your view:

User: Uid (if it is not available -> define a relationship to User)

Now select in the section ""When the filter value is NOT available"" the value ""Provide default value"" and choose ""User ID from url"". Additionally you can specify a validation criteria to accept UIDs and user names.
",seb,https://drupal.stackexchange.com/users/33742,http://drupal.stackexchange.com/questions/141014/displaying-articles-created-by-user-in-profile-page-using-views,TECHNOLOGY,drupal.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,1.0,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.3333333333333333,0.3333333333333333,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.7777777777777778,1.0,0.6666666666666666,0.8888888888888888,1.0,1.0,1.0,0.0,0.0,1.0,Use views to display user created articles in the profile page,"I want to display the articles created by user in user profile page. It should also display to anonymous user also.

For example : twitter.com/google displays all tweets by google.

Like that I want to display xyz.com/john. I want to display all articles created by john in user profile page.

I also want to know how to add that view to profile page.
","Add a contextual filter to your view:

User: Uid (if it is not available -> define a relationship to User)

Now select in the section ""When the filter value is NOT available"" the value ""Provide default value"" and choose ""User ID from url"". Additionally you can specify a validation criteria to accept UIDs and user names.
"
5767,5767,9138,Another instructor is pushing me out of the classroom right after my class ends,"I am a graduate student in math in my final year, and for several years have been teaching at my department as a lecturer. This semester, in the same lecture hall there is another lecture that starts 20 minutes after my class ends. It's taught by another instructor from my department. I usually have many students coming to office hours and there are also students asking questions immediately after lecture. Due to other activities, I cannot have office hours right after the lecture this semester and can only stay for about 15 minutes to answer questions.

Many times in the past I had a similar situation and never had any issues with it. This semester the instructor who is teaching right after often arrives 20-15 minutes before her class starts and tells me immediately that I have to go with my students somewhere else. 

I make sure to leave the blackboard clean and take all my stuff away from the instructor's desk before she arrives, but I do believe that I have a right to stay in the classroom after my lecture for at least 5-10 minutes. There is no vacant classroom around, and I don't have time to go with students to my office, which is in a different building.

Last time the instructor told me in front of my students that I don't understand ""simple things"" and that I am ""playing games"". When I was talking to one of my students, she stood very close to us and clearly demonstrated that she wanted us out. I tried to explain her that I couldn't go anywhere else due to my time constraints, but she didn't want to listen to me. I really don't understand what ""simple"" things she meant and what ""games"" I am playing. 

We leave the board clean. She doesn't need to set up a projector. She can still talk to her students before her class starts, if she wants to (even though it seems like her students don't ask her any questions before their class). So, I don't see how I cause any disruption. 

I had met this woman many times before this semester, but we never talked. I didn't see her talking to other instructors/students much, and she seems to be quite reserved and a bit neurotic. She doesn't want to have any conversation with me regarding the issue.

I felt really offended after last class when she said those things to me in front of my students. What would you do in my case? 

Added later: There are no official rules regarding classroom occupancy between classes. Instructors are supposed to use common sense and be reasonable. For me using 50% of the break time seems reasonable to answer questions after lecture seems reasonable. I agree that for some people it may not.

I don't block the entrance to the classroom. A few students from the next class who come earlier always go ahead and take their seats as soon as my students start leaving the room. I also had one of the students from the next class listening to my explanation to one of those after-class questions and asking me further questions before their class (which is the same class as I am teaching, just a different section). Maybe the instructor got jealous, I don't know.

The entrance to the classroom is from its front (not back), so I do stay in the front. But it is a big lecture hall, and there is a plenty of space in front of the room (the board itself consists of 8 huge panels).

Also, during my career as a grad.student who is also teaching for the department, I have had several observations from experienced professors who are considered to be great teachers at the department and are in charge of undergraduate teaching policy. In my evaluations the fact that there are always several students approaching me with questions after class considered as very positive, meaning that students find me approachable. 

Thank you everyone for answers. 
",Lidd88,https://academia.stackexchange.com/users/31345,"There are a number of good suggestions above.

If I were in your place I would want to understand why she wants / feel she needs the full 20 minutes before her class starts in the classroom without interruption. She might be territorial, she might find lecturing stressful and wants / needs the time to prepare.

You now seem to have a second problem that both you (from the fact that you are posting) and her are upset. At this point I would learn if there is a departmental guideline on when you should be out of the classroom, or if there is no guildline then with the knowledge be non-confrontational, say you don't understand, and ask her to explain why she wants/needs all of the 20 minutes. Be ready for her to be hostile but listen first, then explain why you would like to have time after the class. Again she may be hostile to your explanation.

Once you understand you can decide what to do next.

There is an good book called ""Getting to Yes: Negotiating Agreement Without Giving In"" by by Roger Fisher, William L. Ury, and Bruce Patton. Which is a good read.  
",B Patrick Chapman,https://academia.stackexchange.com/users/31380,http://academia.stackexchange.com/questions/41133/another-instructor-is-pushing-me-out-of-the-classroom-right-after-my-class-ends,LIFE_ARTS,academia.stackexchange.com,0.8888888888888888,0.4444444444444444,0.3333333333333333,1.0,0.0,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.7777777777777778,0.7777777777777778,0.7777777777777778,0.7777777777777778,1.0,0.8,0.6666666666666666,0.0,0.6666666666666666,1.0,No sooner had I finished class than another teacher kicked me out of the classroom,"I am a graduate student in math in my final year, and for several years have been teaching at my department as a lecturer. This semester, in the same lecture hall there is another lecture that starts 20 minutes after my class ends. It's taught by another instructor from my department. I usually have many students coming to office hours and there are also students asking questions immediately after lecture. Due to other activities, I cannot have office hours right after the lecture this semester and can only stay for about 15 minutes to answer questions.

Many times in the past I had a similar situation and never had any issues with it. This semester the instructor who is teaching right after often arrives 20-15 minutes before her class starts and tells me immediately that I have to go with my students somewhere else. 

I make sure to leave the blackboard clean and take all my stuff away from the instructor's desk before she arrives, but I do believe that I have a right to stay in the classroom after my lecture for at least 5-10 minutes. There is no vacant classroom around, and I don't have time to go with students to my office, which is in a different building.

Last time the instructor told me in front of my students that I don't understand ""simple things"" and that I am ""playing games"". When I was talking to one of my students, she stood very close to us and clearly demonstrated that she wanted us out. I tried to explain her that I couldn't go anywhere else due to my time constraints, but she didn't want to listen to me. I really don't understand what ""simple"" things she meant and what ""games"" I am playing. 

We leave the board clean. She doesn't need to set up a projector. She can still talk to her students before her class starts, if she wants to (even though it seems like her students don't ask her any questions before their class). So, I don't see how I cause any disruption. 

I had met this woman many times before this semester, but we never talked. I didn't see her talking to other instructors/students much, and she seems to be quite reserved and a bit neurotic. She doesn't want to have any conversation with me regarding the issue.

I felt really offended after last class when she said those things to me in front of my students. What would you do in my case? 

Added later: There are no official rules regarding classroom occupancy between classes. Instructors are supposed to use common sense and be reasonable. For me using 50% of the break time seems reasonable to answer questions after lecture seems reasonable. I agree that for some people it may not.

I don't block the entrance to the classroom. A few students from the next class who come earlier always go ahead and take their seats as soon as my students start leaving the room. I also had one of the students from the next class listening to my explanation to one of those after-class questions and asking me further questions before their class (which is the same class as I am teaching, just a different section). Maybe the instructor got jealous, I don't know.

The entrance to the classroom is from its front (not back), so I do stay in the front. But it is a big lecture hall, and there is a plenty of space in front of the room (the board itself consists of 8 huge panels).

Also, during my career as a grad.student who is also teaching for the department, I have had several observations from experienced professors who are considered to be great teachers at the department and are in charge of undergraduate teaching policy. In my evaluations the fact that there are always several students approaching me with questions after class considered as very positive, meaning that students find me approachable. 

Thank you everyone for answers. 
","There are a number of good suggestions above.

If I were in your place I would want to understand why she wants / feel she needs the full 20 minutes before her class starts in the classroom without interruption. She might be territorial, she might find lecturing stressful and wants / needs the time to prepare.

You now seem to have a second problem that both you (from the fact that you are posting) and her are upset. At this point I would learn if there is a departmental guideline on when you should be out of the classroom, or if there is no guildline then with the knowledge be non-confrontational, say you don't understand, and ask her to explain why she wants/needs all of the 20 minutes. Be ready for her to be hostile but listen first, then explain why you would like to have time after the class. Again she may be hostile to your explanation.

Once you understand you can decide what to do next.

There is an good book called ""Getting to Yes: Negotiating Agreement Without Giving In"" by by Roger Fisher, William L. Ury, and Bruce Patton. Which is a good read.  
"
4527,4527,7173,android using async http connection to get image bitmap,"I am trying to use async requests to fetch the images from urls, to prevent the url from hanging. This is the piece of code i am using for this

private void setImg(final ImageView im, String url){
    AsyncHttpClient client = new AsyncHttpClient();
    client.get(url, new AsyncHttpResponseHandler(){
        public void onSuccess(String response){
            try{
                byte[] imageAsBytes = response.getBytes();
                im.setImageBitmap(BitmapFactory.decodeByteArray(imageAsBytes, 0, imageAsBytes.length));
                im.refreshDrawableState();
            } catch(Throwable e){
                e.printStackTrace();
            }
        }
    });
}


This is always showing this warning in logcat

12-29 01:55:33.043: D/skia(14414): --- SkImageDecoder::Factory returned null

I cannot find a proper reason for this. Any help?
",Amit,https://stackoverflow.com/users/409110,"I've been using lately the following library: UrlImageViewHelper. It uses an AsyncTask to download the image. Your code would be something like this:

private void setImg(final ImageView im, String url){
    UrlImageViewHelper.setUrlDrawable(im, url) ;
}


Very simple now, am I right?
",Juan Ramón,https://stackoverflow.com/users/403297,http://stackoverflow.com/questions/8660885/android-using-async-http-connection-to-get-image-bitmap,STACKOVERFLOW,stackoverflow.com,0.6666666666666666,0.6666666666666666,0.0,0.5,0.5,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.5,0.0,1.0,0.0,0.5,0.6666666666666666,0.6666666666666666,0.8333333333333334,1.0,0.9,1.0,0.0,0.5,1.0,Android uses asynchronous HTTP connection to obtain image bitmap,"I am trying to use async requests to fetch the images from urls, to prevent the url from hanging. This is the piece of code i am using for this

private void setImg(final ImageView im, String url){
    AsyncHttpClient client = new AsyncHttpClient();
    client.get(url, new AsyncHttpResponseHandler(){
        public void onSuccess(String response){
            try{
                byte[] imageAsBytes = response.getBytes();
                im.setImageBitmap(BitmapFactory.decodeByteArray(imageAsBytes, 0, imageAsBytes.length));
                im.refreshDrawableState();
            } catch(Throwable e){
                e.printStackTrace();
            }
        }
    });
}


This is always showing this warning in logcat

12-29 01:55:33.043: D/skia(14414): --- SkImageDecoder::Factory returned null

I cannot find a proper reason for this. Any help?
",I've been using the following library recently: urlimageviewhelper. It uses asynchronous tasks to download images. Your code should look like this:
2243,2243,3575,How do I ward properly in DotA 2?,"I finally got my DotA 2 Beta invite. Now to learn the game I read it's a good start to play support heros (like I already loved to do in League of Legends). Even though I'm still pretty new to the game I suspect it's mostly the supports job to buy and set up wards.

I am therefore interested in learning how to ward effectively.


What are good/important spots for wards?
How do I time wards? When should I leave the lane?
And if there there different types of wards like in LoL: when to use which one?

",fschl,https://gaming.stackexchange.com/users/1400,"On the following image I additionally marked wards i use on regular basis in above average MMR (~3700).Works on AP mode on public matchmaking where counterwarding is less common.



Read full guide here for more detailed explanations about the marked colors and places.

For average skill games with low warding and no counterwards,you should focus mainly on red dots especially 2 hills near the runes with the priority of upper one in early game and lower one later when killing roshan becomes more likely.


Having at least one ward near the rune will eliminate the chance of
going the wrong side when timing runes
the hills will give you more vision than placing wards on the ground
easily prevent ganks since the river is most common way for ganking
seeing enemy team attacking roshan is huge advantage
also it reveals path near secret shop and neutral camp 




Wards should be placed as early as it gets and replaced just a bit before they expire(you can see the timer),it is the best if you can go grab a rune and place new ward at the same time so you don't lose much ""lane time"",if it is on opposite lane you could port there and combine it with a gank or push attempt.



There are 2 types of wards Observer wards and Sentry wards the ones you need are observer ones the other is used to reveal invisible enemies and is placed directly on the line near combat(pink)



If you want more advanced video guides you should check XV Rogues channel 
",Arremer,https://gaming.stackexchange.com/users/9888,http://gaming.stackexchange.com/questions/77757/how-do-i-ward-properly-in-dota-2,CULTURE,gaming.stackexchange.com,0.7777777777777778,0.7777777777777778,0.0,0.0,0.6666666666666666,0.5,0.6666666666666666,0.5555555555555556,1.0,0.0,0.6666666666666666,0.0,0.3333333333333333,0.0,0.0,0.3333333333333333,1.0,0.6666666666666666,0.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.8,1.0,0.3333333333333333,0.6666666666666666,0.8888888888888888,How to protect correctly in dota 2?,"I finally got an invitation for a beta version of DOTA 2. Now to learn about this game, I read that it's a good start to play supporting Heroes (as I've loved legends in the League). Although I'm still unfamiliar with the game, I suspect it's mainly about buying and building ward support.","On the following image I additionally marked wards i use on regular basis in above average MMR (~3700).Works on AP mode on public matchmaking where counterwarding is less common.



Read full guide here for more detailed explanations about the marked colors and places.

For average skill games with low warding and no counterwards,you should focus mainly on red dots especially 2 hills near the runes with the priority of upper one in early game and lower one later when killing roshan becomes more likely.


Having at least one ward near the rune will eliminate the chance of
going the wrong side when timing runes
the hills will give you more vision than placing wards on the ground
easily prevent ganks since the river is most common way for ganking
seeing enemy team attacking roshan is huge advantage
also it reveals path near secret shop and neutral camp 




Wards should be placed as early as it gets and replaced just a bit before they expire(you can see the timer),it is the best if you can go grab a rune and place new ward at the same time so you don't lose much ""lane time"",if it is on opposite lane you could port there and combine it with a gank or push attempt.



There are 2 types of wards Observer wards and Sentry wards the ones you need are observer ones the other is used to reveal invisible enemies and is placed directly on the line near combat(pink)



If you want more advanced video guides you should check XV Rogues channel 
"
4427,4427,7033,"Should I say ""another ones"" or ""another one's""","Since I'm implying possession should I say another one's and your's?


  The book could either be yours or another ones.


Is it ""yours"" or ""your's"" and ""another ones"" or ""another one's""?
",David,https://english.stackexchange.com/users/13748,"Neither of the options you present are correct. You should say:


  The book could either be yours or someone else's.

",RiMMER,https://english.stackexchange.com/users/6509,http://english.stackexchange.com/questions/57845/should-i-say-another-ones-or-another-ones,CULTURE,english.stackexchange.com,1.0,0.6666666666666666,0.0,1.0,1.0,0.6666666666666666,0.7777777777777778,0.8888888888888888,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,0.0,1.0,0.8888888888888888,0.5555555555555556,1.0,1.0,0.8,0.3333333333333333,0.3333333333333333,0.3333333333333333,1.0,"Should I say ""another"" or ""another""","Since I'm implying possession should I say another one's and your's?


  The book could either be yours or another ones.


Is it ""yours"" or ""your's"" and ""another ones"" or ""another one's""?
",Neither of the options you put forward is right. You should say:
4000,4000,6389,How to use ARM software in Raspberry?,"I would like to run Maestro Control Center software (for Mini Maestro 24-Channel USB Servo Controller) in Raspberry. But it is not ARM software. It is availabe for Linux and Windows.

I'm total newbie so i have no skills to do it, but i desperately need to do this and surely there is others who would like to do this too.

Maestro Control Center

Thanks
",user10936,https://raspberrypi.stackexchange.com/users/10936,"Short answer: Without the source code, you can't (unless you convince the developers to support the ARM architecture).

Long answer: Think of the apps on a phone.  If there wasn't a similar application for your computer, you could not run the phone application on your computer natively. This is also the same reason Raspberry Pi users can't run Ubuntu.  

So how can you get the software you want on the Raspberry Pi?
To start, you need the source code.  Unfortunately for you, it does not look like it is publicly available.  If you were able to get your hands on the source code, you would have to build it; depending on the size of the source code base, you might need a build farm for that.
",syb0rg,https://raspberrypi.stackexchange.com/users/8631,http://raspberrypi.stackexchange.com/questions/12039/how-to-use-arm-software-in-raspberry,TECHNOLOGY,raspberrypi.stackexchange.com,0.6666666666666666,0.7777777777777778,0.0,1.0,1.0,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,0.3333333333333333,1.0,How to use arm software in raspberry?,"I would like to run Maestro Control Center software (for Mini Maestro 24-Channel USB Servo Controller) in Raspberry. But it is not ARM software. It is availabe for Linux and Windows.

I'm total newbie so i have no skills to do it, but i desperately need to do this and surely there is others who would like to do this too.

Maestro Control Center

Thanks
","Short answer: Without the source code, you can't (unless you convince the developers to support the ARM architecture).

Long answer: Think of the apps on a phone.  If there wasn't a similar application for your computer, you could not run the phone application on your computer natively. This is also the same reason Raspberry Pi users can't run Ubuntu.  

So how can you get the software you want on the Raspberry Pi?
To start, you need the source code.  Unfortunately for you, it does not look like it is publicly available.  If you were able to get your hands on the source code, you would have to build it; depending on the size of the source code base, you might need a build farm for that.
"
1707,1707,2705,Safari - is there a way to set a preferred screen size?,"As the title says, I would like new windows to open in a set screen size. I believe that the default is that they open in the size of the last window. Sometimes, I want to make a window smaller for some reason, but I want new windows to open as usual. Is there a shell script/command to accomplish this? Thanks 
",David DelMonte,https://apple.stackexchange.com/users/11128,"There is a great extension available for Safari called ResponsiveResize which works great for me: http://www.midwinter-dg.com/downloads_safari-extension_responsive-resize.html
",tribulant,https://apple.stackexchange.com/users/126991,http://apple.stackexchange.com/questions/110737/safari-is-there-a-way-to-set-a-preferred-screen-size,TECHNOLOGY,apple.stackexchange.com,1.0,0.8888888888888888,0.0,1.0,0.6666666666666666,1.0,0.4444444444444444,0.4444444444444444,0.0,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.6666666666666666,0.0,0.0,1.0,Safari - is there a way to set the preferred screen size?,"As the title shows, I want the new window to open at the set screen size. I think the default is that they open the same size as the last window. Sometimes, I want to narrow a window for some reason, but I want to open a new window as usual. Is there a shell script / command to complete this task? Thank you","There is a great extension available for Safari called ResponsiveResize which works great for me: http://www.midwinter-dg.com/downloads_safari-extension_responsive-resize.html
"
5838,5838,9251,Need directions regarding the learning process I should follow for learning Photoshop,"I am starting out as a freelance website developer so I need to improve my graphics drawing skill. Up till now I'm using an open source tool GIMP to create the concepts and mock ups of the websites I design.I know that Photoshop is the Industry standard(at least as far as I know).

So,what books can help me in learning some advanced Photoshop techniques used frequently in web designing.Also I want to learn how to draw cartoon characters like this.I know it is a matter of creativity but still there must be some techniques which I can learn.Please express your views.

Just for the record, I'm basically a web developer so my graphics drawing capabilities are very limited(but I want to improve that). You can have a look at this site I designed using GIMP. 
",Rajat Saxena,https://graphicdesign.stackexchange.com/users/7481,"Experiment a lot, test out all those buttons and functions one by one, read tutorials, try them out, bring your knowledge over from Gimp such as how to use layers, repeat.

You can always buy a book and test out the techniques there, but unless you aim to become a 100% graphic designer I will recommend you to keep it simple at first, more related to what your purpose with it is.

(the cartoon you link to is probably made with Illustrator though)

Edit: if you specifically want to this for web design, check also Adobe Fireworks which is more targeted towards web design than PS is.
",K3N,https://graphicdesign.stackexchange.com/users/7179,http://graphicdesign.stackexchange.com/questions/11487/need-directions-regarding-the-learning-process-i-should-follow-for-learning-phot,LIFE_ARTS,graphicdesign.stackexchange.com,0.6666666666666666,0.3333333333333333,0.0,0.0,1.0,0.0,0.5555555555555556,0.4444444444444444,1.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.6666666666666666,0.6666666666666666,0.5,1.0,0.6666666666666666,0.6,1.0,0.0,1.0,1.0,Need guidance on the learning process of learning Photoshop,"I am starting out as a freelance website developer so I need to improve my graphics drawing skill. Up till now I'm using an open source tool GIMP to create the concepts and mock ups of the websites I design.I know that Photoshop is the Industry standard(at least as far as I know).

So,what books can help me in learning some advanced Photoshop techniques used frequently in web designing.Also I want to learn how to draw cartoon characters like this.I know it is a matter of creativity but still there must be some techniques which I can learn.Please express your views.

Just for the record, I'm basically a web developer so my graphics drawing capabilities are very limited(but I want to improve that). You can have a look at this site I designed using GIMP. 
","Experiment a lot, test out all those buttons and functions one by one, read tutorials, try them out, bring your knowledge over from Gimp such as how to use layers, repeat.

You can always buy a book and test out the techniques there, but unless you aim to become a 100% graphic designer I will recommend you to keep it simple at first, more related to what your purpose with it is.

(the cartoon you link to is probably made with Illustrator though)

Edit: if you specifically want to this for web design, check also Adobe Fireworks which is more targeted towards web design than PS is.
"
4601,4601,7297,Close all file descriptors in bash,"Is there a way to close all the open file descriptors, without having an explicit list of them beforehand?
",Lorenzo Pistone,https://unix.stackexchange.com/users/15172,"No. The kernel can close only one FD at a time, and bash does not have ""group commands"" for FDs.

for fd in $(ls -1 /proc/27343/fd); do echo exec ""$fd&gt;&amp;-""; done


Remove the echo after testing.

If this is not for the shell itself but for a command to be run then you can use nohup.
",Hauke Laging,https://unix.stackexchange.com/users/32191,http://unix.stackexchange.com/questions/123413/close-all-file-descriptors-in-bash,TECHNOLOGY,unix.stackexchange.com,1.0,0.5555555555555556,0.0,1.0,1.0,1.0,0.6666666666666666,0.4444444444444444,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,1.0,0.3333333333333333,0.0,1.0,0.8888888888888888,Close all file descriptors in Bash,Is there a way to close all open file descriptors without providing an explicit list of them in advance?,"No. The kernel can close only one FD at a time, and bash does not have ""group commands"" for FDs.

for fd in $(ls -1 /proc/27343/fd); do echo exec ""$fd&gt;&amp;-""; done


Remove the echo after testing.

If this is not for the shell itself but for a command to be run then you can use nohup.
"
4512,4512,7152,How to calculate the size of the image circle at infinity focus?,"How can I determine the diameter of the image circle (i.e. the diagonal size of CCD required to fully utilise a telescope's optics) at near-infinity focus? I have looked around online and found this calculator, but I am more interested in how the figure was calculated than knowing the figure itself. 

Background: I am new to astrophotography and recently bought a Celestron Nexstar 130 SLT telescope with a Barlow lens, T-adaptor and T-ring to connect it with my Nikon D80 to take photographs of the night sky in prime focus. The telescope dimensions are 130mm aperture and 650mm focal length. With the 2x Barlow lens (required to diverge the focus enough to mount the camera outside the optical tube assembly) it effectively becomes a telescope with 1300mm focal length. I can measure a picture of an object with known angular size (e.g. the moon) and use crop factors to establish a ratio, but this method doesn't help me understand how a bigger/newer telescope would fare on the same CCD. 

Edit:
Since this question now has a bounty, I would like to emphasize the real question is How to calculate the size of the image circle at infinity focus?, and not the follow-up question of 
Would the image circle size decrease if I was able to ditch the Barlow lens?
",Jono,https://photo.stackexchange.com/users/13946,"I am not sure about the answer to Would the image circle size decrease if I was able to ditch the Barlow lens?

But if you look at the JavaScript of that page you will see

var sensorw = ""Sensor Width""
var sensorh = ""Sensor Height""
var maxres  = ""Max Res""
var focleng = ""Focal Length""

var thisF = sensorw * 3438/focleng;
var thisF2 = sensorh * 3438/focleng;
var thisF3 = sensorw * 3438/focleng * 60/maxres;
var thisF4 = focleng/Math.sqrt(sensorw * sensorw + sensorh * sensorh);


Values:


thisF  = Arc Min of Sky- Width: 
thisF2 = Arc Min of Sky- Height: 
thisF3 = Arc Seconds/Pixel: 
thisF4 = Magnification (X):


This is how that page calculates it
",Rob,https://photo.stackexchange.com/users/5052,http://photo.stackexchange.com/questions/30365/how-to-calculate-the-size-of-the-image-circle-at-infinity-focus,LIFE_ARTS,photo.stackexchange.com,1.0,0.5555555555555556,0.0,1.0,0.6666666666666666,1.0,0.5555555555555556,0.4444444444444444,0.6666666666666666,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.6666666666666666,0.0,0.3333333333333333,1.0,How to calculate the size of image circle under infinite focal length?,"How can I determine the diameter of the image circle (i.e. the diagonal size of CCD required to fully utilise a telescope's optics) at near-infinity focus? I have looked around online and found this calculator, but I am more interested in how the figure was calculated than knowing the figure itself. 

Background: I am new to astrophotography and recently bought a Celestron Nexstar 130 SLT telescope with a Barlow lens, T-adaptor and T-ring to connect it with my Nikon D80 to take photographs of the night sky in prime focus. The telescope dimensions are 130mm aperture and 650mm focal length. With the 2x Barlow lens (required to diverge the focus enough to mount the camera outside the optical tube assembly) it effectively becomes a telescope with 1300mm focal length. I can measure a picture of an object with known angular size (e.g. the moon) and use crop factors to establish a ratio, but this method doesn't help me understand how a bigger/newer telescope would fare on the same CCD. 

Edit:
Since this question now has a bounty, I would like to emphasize the real question is How to calculate the size of the image circle at infinity focus?, and not the follow-up question of 
Would the image circle size decrease if I was able to ditch the Barlow lens?
","I am not sure about the answer to Would the image circle size decrease if I was able to ditch the Barlow lens?

But if you look at the JavaScript of that page you will see

var sensorw = ""Sensor Width""
var sensorh = ""Sensor Height""
var maxres  = ""Max Res""
var focleng = ""Focal Length""

var thisF = sensorw * 3438/focleng;
var thisF2 = sensorh * 3438/focleng;
var thisF3 = sensorw * 3438/focleng * 60/maxres;
var thisF4 = focleng/Math.sqrt(sensorw * sensorw + sensorh * sensorh);


Values:


thisF  = Arc Min of Sky- Width: 
thisF2 = Arc Min of Sky- Height: 
thisF3 = Arc Seconds/Pixel: 
thisF4 = Magnification (X):


This is how that page calculates it
"
896,896,1422,GIS Software Choice for a small university research centre,"I need to choose a GIS system for a small university research centre. We are handling a broad range of data, (for example, numerical tidal analyses, weather data, poverty, isolated economic activity, skills availability and renewable energy resource availability) and operate primarily in countries with relatively poor existing data sets. 

We interact with other groups, some of which use ARCGIS. Do I have to wade through every GIS software descriptor on the web, or can someone please give an indication of likely candidates? 
",Alan Owen,https://gis.stackexchange.com/users/8127,"Based on your requirements, you may need a GIS stack: server, database, presentation, and then the analysis tools. I'd recommend GeoServer (http://www.geoserver.org)  for server, PostgreSQL with PostGIS extension for database (http://postgis.net). 

This combination can enable easy distributed authoring/analysis and publishing using WFS, WPS, and WMS, which are OGC standards. You can use the tools mentioned above for analysis. In addition to QGIS, you can also use uDig (http://udig.refractions.net) for editing. For presentation, you may use OpenLayers or GeoExt.
",okello,https://gis.stackexchange.com/users/7560,http://gis.stackexchange.com/questions/27188/gis-software-choice-for-a-small-university-research-centre,TECHNOLOGY,gis.stackexchange.com,0.8888888888888888,0.8888888888888888,0.6666666666666666,0.6666666666666666,0.0,0.3333333333333333,0.6666666666666666,0.5555555555555556,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.3333333333333333,0.6666666666666666,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8,0.3333333333333333,0.0,0.3333333333333333,1.0,Selection of GIS software for research center of small University,"I need to choose a geographic information system for a small university research center. We are working on a wide range of data (e.g., numerical tidal analysis, weather data, poverty, isolated economic activity, skill availability and renewable energy availability), mainly in countries with relatively poor existing data sets.","Based on your requirements, you may need a GIS stack: server, database, presentation, and then the analysis tools. I'd recommend GeoServer (http://www.geoserver.org)  for server, PostgreSQL with PostGIS extension for database (http://postgis.net). 

This combination can enable easy distributed authoring/analysis and publishing using WFS, WPS, and WMS, which are OGC standards. You can use the tools mentioned above for analysis. In addition to QGIS, you can also use uDig (http://udig.refractions.net) for editing. For presentation, you may use OpenLayers or GeoExt.
"
1350,1350,2127,Can you make a hash out of a stream cipher?,"A comment on another question made me wonder about something:


  Assume you're on a rather constrained platform &mdash; say, a low-end embedded device &mdash; with no built-in crypto capabilities, but you do have access to a simple stream cipher; say, RC4 or one of the eSTREAM ciphers.  What other crypto primitives can you build out of that stream cipher?  In particular, are there any practical ways to build a cryptographic hash function and/or a MAC out of just a stream cipher?


We already have questions about turning a hash into a stream cipher and about turning a stream cipher into a block cipher, but this particular transformation doesn't seem to have been covered yet.

Obviously, if the platform constraints permit it, one could ignore the stream cipher and just implement a standard hash function from the ground up.  What I'm wondering is whether having the stream cipher available might let one do better than that in terms of code size, memory usage and/or speed.

While a construction that treats the stream cipher as a black box would be nice, schemes that only use parts of the stream cipher (like RC4-Hash, which, alas, has practical collision attacks) would be interesting too, at least if they're simple enough.
",Ilmari Karonen,https://crypto.stackexchange.com/users/598,"I am pretty sure that it is not advisable to use a stream model to construct a cryptographic hash. I do not have a full theoretic proof in hand, but can think about it from the perspective of a famous stream cipher, RC4. It is susceptible to related-key attack. Now to use RC4 for constructing a hash function, you need to argue that it should be resistant to a stronger adversarial model, viz chosen-key attack, whereupon the adversary can target the weakness in key scheduling. I am sure full chosen-key is not under consideration for RC4 (correct me if I am wrong). On the other hand, you allow the adversary to pick the key in the very first part of the definition of any form of resistance (apart from chosen-target-forced-prefix resistance which is not yet formally defined) for cryptographic hash function! So, I am pretty sure that it is not advisable.

However, if we look at few results from the theoretical point of view, Coron et al. showed the equivalence between ideal cipher model and the random oracle model. This give some hope: convert the stream cipher to block cipher secure in the ideal cipher model and then by equivalence it is secure in random oracle model; but we get stuck here (how to move from RO model to an instantiation of a hash function. After all, the million dollar question is whether we trust random oracle model after Canetti et al worked showed weakness in the random oracle model!
",Jalaj,https://crypto.stackexchange.com/users/1114,http://crypto.stackexchange.com/questions/2214/can-you-make-a-hash-out-of-a-stream-cipher,TECHNOLOGY,crypto.stackexchange.com,0.6666666666666666,0.3333333333333333,0.0,0.0,1.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,0.8333333333333334,0.6666666666666666,1.0,1.0,0.8,0.0,0.0,1.0,1.0,Can you make a hash with a stream password?,"A comment on another question made me wonder about something:


  Assume you're on a rather constrained platform &mdash; say, a low-end embedded device &mdash; with no built-in crypto capabilities, but you do have access to a simple stream cipher; say, RC4 or one of the eSTREAM ciphers.  What other crypto primitives can you build out of that stream cipher?  In particular, are there any practical ways to build a cryptographic hash function and/or a MAC out of just a stream cipher?


We already have questions about turning a hash into a stream cipher and about turning a stream cipher into a block cipher, but this particular transformation doesn't seem to have been covered yet.

Obviously, if the platform constraints permit it, one could ignore the stream cipher and just implement a standard hash function from the ground up.  What I'm wondering is whether having the stream cipher available might let one do better than that in terms of code size, memory usage and/or speed.

While a construction that treats the stream cipher as a black box would be nice, schemes that only use parts of the stream cipher (like RC4-Hash, which, alas, has practical collision attacks) would be interesting too, at least if they're simple enough.
","I am pretty sure that it is not advisable to use a stream model to construct a cryptographic hash. I do not have a full theoretic proof in hand, but can think about it from the perspective of a famous stream cipher, RC4. It is susceptible to related-key attack. Now to use RC4 for constructing a hash function, you need to argue that it should be resistant to a stronger adversarial model, viz chosen-key attack, whereupon the adversary can target the weakness in key scheduling. I am sure full chosen-key is not under consideration for RC4 (correct me if I am wrong). On the other hand, you allow the adversary to pick the key in the very first part of the definition of any form of resistance (apart from chosen-target-forced-prefix resistance which is not yet formally defined) for cryptographic hash function! So, I am pretty sure that it is not advisable.

However, if we look at few results from the theoretical point of view, Coron et al. showed the equivalence between ideal cipher model and the random oracle model. This give some hope: convert the stream cipher to block cipher secure in the ideal cipher model and then by equivalence it is secure in random oracle model; but we get stuck here (how to move from RO model to an instantiation of a hash function. After all, the million dollar question is whether we trust random oracle model after Canetti et al worked showed weakness in the random oracle model!
"
3185,3185,5074,Which products should have FCC certification and about how much does that cost?,"I'm aware that nobody actually does this at the hobbyist level, that successful commercial products have been launched without certification, and it's probably something I can't afford if I have to ask. However, I've always wondered about the ballpark cost. About how much does it cost to receive FCC certification?
",joeforker,https://electronics.stackexchange.com/users/1363,"Where I used to work we saved a lot of money on CE testing by hiring the facility for half a day and doing our own preliminary testing. We fixed any problems, they were usually quite minor, and the equipment always then passed first time. You do need to have someone who knows how to drive the test instruments, of course.
",Leon Heller,https://electronics.stackexchange.com/users/305,http://electronics.stackexchange.com/questions/5196/which-products-should-have-fcc-certification-and-about-how-much-does-that-cost,TECHNOLOGY,electronics.stackexchange.com,0.8888888888888888,1.0,0.0,1.0,1.0,1.0,0.5555555555555556,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.8888888888888888,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.5,0.3,0.0,0.0,0.0,0.7777777777777778,Which products should have FCC certification and what is the price?,"I know that in fact, no one will do this at the level of fans. Successful commercial products are launched without certification. If I have to ask, I can't afford it. However, I always want to know the approximate cost. How much does it cost to get FCC certification?","Where I used to work we saved a lot of money on CE testing by hiring the facility for half a day and doing our own preliminary testing. We fixed any problems, they were usually quite minor, and the equipment always then passed first time. You do need to have someone who knows how to drive the test instruments, of course.
"
79,79,128,add custom citation that differs in format than the rest,"This has been bugging me for quite some time now but can't find a nice way to work it out.

I have a list of citations that follow the regular author. Year. Title. Journal. Volume: Pages layout. I have to cite a legal document (Water framework directive). How do I go about this, as the paper has no authors, journals, pages...

I would like it to appear in the text as


  ... V Sloveniji smo leta 2000 sprejeli
  Vodno direktivo (2000/60/EC) (v
  nadaljevanju: VD), ki v evropskem
  prostoru enotno ureja politiko
  upravljanja površinskih in podzemnih
  celinskih voda, vključno s somornico
  in morjem....


and in the references as 


  Ter Braak, C. J. F., Verdonschot, P. F. M. 1995. Canonical correspondence analysis and related multivariate methods in aquatic ecology. Aquatic Sciences 57(3): 255–289.
  
  Vodna direktiva (2000/60/EC)
  
  Wickham, H. 2009. ggplot2: elegant graphics for data analysis. Springer New York. ISBN 978-0-387-98140-6.


How should I specify my BibTeX source to achieve this?

EDIT

This is a more or less minimal working example. Style file can be found here, and the bib file here.

\documentclass{article}

\usepackage{natbib}

\begin{document}

As specified in \citet{vd} and \citep{Fraschetti2006} \dots

\bibliographystyle{custom_style}
\bibliography{test}

\end{document}


EDIT 2

A workaround that worked for me (for now). The four questionmarks in question (hehe) were the result of missing year in the bib file. I have modified the custom_style.bst from

FUNCTION {format.date}
{ year ""year"" bibinfo.check duplicate$ empty$
    {
      ""empty year in "" cite$ * ""; set to ????"" * warning$
       pop$ ""????""
    }
    'skip$
  if$
  extra.label *
}


to

   FUNCTION {format.date}
    { year ""year"" bibinfo.check duplicate$ empty$
        {
          ""empty year in "" cite$ * ""; set to "" * warning$
           pop$ """"
        }
        'skip$
      if$
      extra.label *
    }

",Roman Luštrik,https://tex.stackexchange.com/users/72,"I suspect that even legal documents should be represented by a BibTeX entry with more than one field (and especially with a year field if one uses an author-year-style), but here goes.


I used the author instead of the title field because BibTeX otherwise would typeset the label V00 in the text.
The second pair of curly braces prevents BibTeX from breaking the ""author"" down in first name and last name.




\documentclass{article}

\usepackage{natbib}

\usepackage{filecontents}

\begin{filecontents}{\jobname.bib}
@misc{V00,
  author = {{\textit{Vodna direktiva (2000/60/EC)}}},
}
\end{filecontents}

\begin{document}

As specified in \citet{V00} \dots

\bibliographystyle{plainnat}
\bibliography{\jobname}

\end{document}

",lockstep,https://tex.stackexchange.com/users/510,http://tex.stackexchange.com/questions/6767/add-custom-citation-that-differs-in-format-than-the-rest,TECHNOLOGY,tex.stackexchange.com,0.7777777777777778,0.4444444444444444,0.0,1.0,0.6666666666666666,1.0,0.5555555555555556,0.5555555555555556,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9,1.0,0.0,0.0,1.0,Add a custom reference with a different reference format,"This has been bugging me for quite some time now but can't find a nice way to work it out.

I have a list of citations that follow the regular author. Year. Title. Journal. Volume: Pages layout. I have to cite a legal document (Water framework directive). How do I go about this, as the paper has no authors, journals, pages...

I would like it to appear in the text as


  ... V Sloveniji smo leta 2000 sprejeli
  Vodno direktivo (2000/60/EC) (v
  nadaljevanju: VD), ki v evropskem
  prostoru enotno ureja politiko
  upravljanja površinskih in podzemnih
  celinskih voda, vključno s somornico
  in morjem....


and in the references as 


  Ter Braak, C. J. F., Verdonschot, P. F. M. 1995. Canonical correspondence analysis and related multivariate methods in aquatic ecology. Aquatic Sciences 57(3): 255–289.
  
  Vodna direktiva (2000/60/EC)
  
  Wickham, H. 2009. ggplot2: elegant graphics for data analysis. Springer New York. ISBN 978-0-387-98140-6.


How should I specify my BibTeX source to achieve this?

EDIT

This is a more or less minimal working example. Style file can be found here, and the bib file here.

\documentclass{article}

\usepackage{natbib}

\begin{document}

As specified in \citet{vd} and \citep{Fraschetti2006} \dots

\bibliographystyle{custom_style}
\bibliography{test}

\end{document}


EDIT 2

A workaround that worked for me (for now). The four questionmarks in question (hehe) were the result of missing year in the bib file. I have modified the custom_style.bst from

FUNCTION {format.date}
{ year ""year"" bibinfo.check duplicate$ empty$
    {
      ""empty year in "" cite$ * ""; set to ????"" * warning$
       pop$ ""????""
    }
    'skip$
  if$
  extra.label *
}


to

   FUNCTION {format.date}
    { year ""year"" bibinfo.check duplicate$ empty$
        {
          ""empty year in "" cite$ * ""; set to "" * warning$
           pop$ """"
        }
        'skip$
      if$
      extra.label *
    }

","I suspect that even legal documents should be represented by a BibTeX entry with more than one field (and especially with a year field if one uses an author-year-style), but here goes.


I used the author instead of the title field because BibTeX otherwise would typeset the label V00 in the text.
The second pair of curly braces prevents BibTeX from breaking the ""author"" down in first name and last name.




\documentclass{article}

\usepackage{natbib}

\usepackage{filecontents}

\begin{filecontents}{\jobname.bib}
@misc{V00,
  author = {{\textit{Vodna direktiva (2000/60/EC)}}},
}
\end{filecontents}

\begin{document}

As specified in \citet{V00} \dots

\bibliographystyle{plainnat}
\bibliography{\jobname}

\end{document}

"
5935,5935,9404,Why doesn't Perl's Spreadsheet::ParseExcel never return from $parser->parse('test.xls')?,"The spreadsheet is Excel 97-2003 compatible and permissions 777

use strict;
use Spreadsheet::ParseExcel;
print ""Content-type: text/html\n\n"";   
my $parser   = Spreadsheet::ParseExcel-&gt;new();
print ""&lt;br&gt;gets here:"".__LINE__; 
my $workbook = $parser-&gt;parse('test.xls');
print ""&lt;br&gt;never gets here:"".__LINE__; 

",zzapper,https://stackoverflow.com/users/94335,"Do you use latest Spreadsheet::ParseExcel? Current version is 0.57.

I see that you run this as CGI. Can you run it from command line (locally, with same test file) and check if there is any error message?

Try also using eval (running from command line is still better) and check if $parser is defined:

print '$parser is undef&lt;br&gt;' unless defined $parser;
eval {
  my $workbook = $parser-&gt;parse('test.xls');
};
print ""Error message from eval: $@&lt;br&gt;"";


Try another Excel file.

If error still is unknown and with specific Excel file, report bug in bug tracker.
",Alexandr Ciornii,https://stackoverflow.com/users/13467,http://stackoverflow.com/questions/2191496/why-doesnt-perls-spreadsheetparseexcel-never-return-from-parser-parsetes,STACKOVERFLOW,stackoverflow.com,1.0,0.8888888888888888,0.0,1.0,1.0,1.0,0.5555555555555556,0.5555555555555556,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.8888888888888888,0.8,1.0,0.0,0.6666666666666666,1.0,Why does Perl's spreadsheet:: parseexcel never return from $Parser - > parse ('test. XLS')?,"The spreadsheet is Excel 97-2003 compatible and permissions 777

use strict;
use Spreadsheet::ParseExcel;
print ""Content-type: text/html\n\n"";   
my $parser   = Spreadsheet::ParseExcel-&gt;new();
print ""&lt;br&gt;gets here:"".__LINE__; 
my $workbook = $parser-&gt;parse('test.xls');
print ""&lt;br&gt;never gets here:"".__LINE__; 

","Do you use latest Spreadsheet::ParseExcel? Current version is 0.57.

I see that you run this as CGI. Can you run it from command line (locally, with same test file) and check if there is any error message?

Try also using eval (running from command line is still better) and check if $parser is defined:

print '$parser is undef&lt;br&gt;' unless defined $parser;
eval {
  my $workbook = $parser-&gt;parse('test.xls');
};
print ""Error message from eval: $@&lt;br&gt;"";


Try another Excel file.

If error still is unknown and with specific Excel file, report bug in bug tracker.
"
821,821,1303,"'Trying to help someone, but the other party doesn't appreciate it'","What is a word that best describes trying to help someone, but the other party doesn't appreciate it?  

I'm looking for a word.  
",yuritsuki,https://english.stackexchange.com/users/21921,"Ungrateful.

Pretty obvious answer.
",A.S.,https://english.stackexchange.com/users/64553,http://english.stackexchange.com/questions/149521/trying-to-help-someone-but-the-other-party-doesnt-appreciate-it,CULTURE,english.stackexchange.com,1.0,0.5555555555555556,0.0,1.0,1.0,0.6666666666666666,0.5555555555555556,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,0.0,0.8888888888888888,"""Want to help others, but they don't appreciate it""","What's the best word to describe trying to help others, but they don't appreciate it?","Ungrateful.

Pretty obvious answer.
"
5560,5560,8831,"What is the difference between unicast, anycast, broadcast and multicast traffic?","I have never had the privilege of working in an environment that required complicated routing or if it did require it, it was handled upstream of me. I've always used very simple static routing configurations and never needed to do any multipath routing -- hence my general confusion regarding this subject. I would like to understand multicasting and anycasting better. 


What is the difference between unicast, anycast, broadcast and multicast traffic?
What situations are they generally used in and why (e.g., what applications use which method)?
How do you calculate how much broadcast traffic is too much for a given network segment or broadcast domain?
What are the security implications of allowing broadcast and multicast traffic?

",kce,https://serverfault.com/users/62491,"Here's some basic info:

Unicast: Unicast traffic is traffic that is meant for a single host. All other hosts will ignore unicast traffic not meant for themselves. In a switched environment, unicast traffic is generally not ""heard"" by any hosts other than the host that the traffic is intended for. In an environment that uses hubs (shudder) all hosts will ""hear"" unicast traffic meant for every other host, but they'll ignore all traffic not intended for themselves.

Broadcast: Broadcast traffic is traffic that is sent with the intent of being ""heard"" by all hosts on a particular network segment. Examples of broadcast traffic would be an ARP request, which is a broadcast at the physical layer (MAC address FF-FF-FF-FF-FF-FF) or a NetBIOS name query, which is a broadcast at the network layer (whatever happens to be the broadcast address for that particular network, such as 64.28.42.63 for the network 64.28.42.0/26).

Multicast: Multicast traffic is traffic that is sent with the intent of being ""heard"" by a particular group of hosts on a network segment. Some multicast traffic can be considered broadcast traffic, such as traffic to the multicast address 224.0.0.1, which is multicast traffic meant for all hosts on the same network segment. Another example of multicast traffic would be traffic sent to the multicast address 224.0.0.9 which is what RIP routers use to send routing information to other RIP routers on the same network segment.

I'll leave Anycast to someone else as I really don't know that much about it.
",joeqwerty,https://serverfault.com/users/19152,http://serverfault.com/questions/279482,TECHNOLOGY,serverfault.com,0.8888888888888888,0.3333333333333333,0.0,0.3333333333333333,1.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,1.0,0.0,0.3333333333333333,0.0,1.0,0.0,0.3333333333333333,0.0,0.3333333333333333,0.0,0.3333333333333333,0.0,0.8888888888888888,1.0,0.4444444444444444,0.8888888888888888,1.0,0.7333333333333333,0.0,0.0,0.3333333333333333,1.0,"What's the difference between unicast, anycast, broadcast and multicast communication?","I have never had the privilege of working in an environment that required complicated routing or if it did require it, it was handled upstream of me. I've always used very simple static routing configurations and never needed to do any multipath routing -- hence my general confusion regarding this subject. I would like to understand multicasting and anycasting better. 


What is the difference between unicast, anycast, broadcast and multicast traffic?
What situations are they generally used in and why (e.g., what applications use which method)?
How do you calculate how much broadcast traffic is too much for a given network segment or broadcast domain?
What are the security implications of allowing broadcast and multicast traffic?

","Here's some basic info:

Unicast: Unicast traffic is traffic that is meant for a single host. All other hosts will ignore unicast traffic not meant for themselves. In a switched environment, unicast traffic is generally not ""heard"" by any hosts other than the host that the traffic is intended for. In an environment that uses hubs (shudder) all hosts will ""hear"" unicast traffic meant for every other host, but they'll ignore all traffic not intended for themselves.

Broadcast: Broadcast traffic is traffic that is sent with the intent of being ""heard"" by all hosts on a particular network segment. Examples of broadcast traffic would be an ARP request, which is a broadcast at the physical layer (MAC address FF-FF-FF-FF-FF-FF) or a NetBIOS name query, which is a broadcast at the network layer (whatever happens to be the broadcast address for that particular network, such as 64.28.42.63 for the network 64.28.42.0/26).

Multicast: Multicast traffic is traffic that is sent with the intent of being ""heard"" by a particular group of hosts on a network segment. Some multicast traffic can be considered broadcast traffic, such as traffic to the multicast address 224.0.0.1, which is multicast traffic meant for all hosts on the same network segment. Another example of multicast traffic would be traffic sent to the multicast address 224.0.0.9 which is what RIP routers use to send routing information to other RIP routers on the same network segment.

I'll leave Anycast to someone else as I really don't know that much about it.
"
4563,4563,7232,php escape sequence not working,"I just want to echo out some text on the webpage display with a tab space before a word.
I have the following codes in php:

&lt;?php
   echo ""\t\t hello!&lt;br&gt;"";
   echo ""\t\t"", ""hello!&lt;br&gt;"";
   echo ""\t\t"".""hello!&lt;br&gt;"";
?&gt;


I tried all sorts of combinations, but it just won't show the tab spacing before the word.

OUTPUT:

hello!
hello!
hello!


I visited some links like: Newline escape sequence not working on php 
but I am not echoing it from a function. I just simply want to echo it out from a .php file.
",user3437460,https://stackoverflow.com/users/3437460,"When you add a tab to html, it is only visible on the source code and then treated as whitespace when rendered in a browser....

just like \n is only visible in page source code and treated as whitespace when rendered... \t and \n are meaningless to html
",DLastCodeBender,https://stackoverflow.com/users/4280662,http://stackoverflow.com/questions/27111279/php-escape-sequence-not-working,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.6666666666666666,0.0,1.0,1.0,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.7777777777777778,0.8333333333333334,0.6666666666666666,0.8333333333333334,1.0,0.9,0.6666666666666666,0.0,0.3333333333333333,0.8888888888888888,PHP escape sequence does not work,"I just want to echo out some text on the webpage display with a tab space before a word.
I have the following codes in php:

&lt;?php
   echo ""\t\t hello!&lt;br&gt;"";
   echo ""\t\t"", ""hello!&lt;br&gt;"";
   echo ""\t\t"".""hello!&lt;br&gt;"";
?&gt;


I tried all sorts of combinations, but it just won't show the tab spacing before the word.

OUTPUT:

hello!
hello!
hello!


I visited some links like: Newline escape sequence not working on php 
but I am not echoing it from a function. I just simply want to echo it out from a .php file.
","When you add a tab to HTML, it's only visible in the source code, and then it's treated as blank when rendered in the browser...."
1377,1377,2169,"Is ""Pick up those blocks"" grammatically incorrect?","I had someone correct me today as I instructed my child to ""pick up those blocks."" This person insisted that it should just be:


  Pick up those.


since ""those"" is already plural.

Is this person correct?
",Chris Dwyer,https://english.stackexchange.com/users/61,"The English demonstratives—this, that, these, and those—can all be used as either adjectives (“Those blocks are square”) or pronouns (“Those are square”).

Also, how would you distinguish “those blocks” from “those dolls” if you could only say “those”?
",nohat,https://english.stackexchange.com/users/39,http://english.stackexchange.com/questions/11603/is-pick-up-those-blocks-grammatically-incorrect,CULTURE,english.stackexchange.com,1.0,0.6666666666666666,0.0,1.0,0.6666666666666666,1.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.0,1.0,0.8888888888888888,"Is the syntax ""pick up those blocks"" incorrect?","Today, I asked someone to correct me and let my child ""pick up those blocks."" The man insisted that it should be:","The English demonstratives—this, that, these, and those—can all be used as either adjectives (“Those blocks are square”) or pronouns (“Those are square”).

Also, how would you distinguish “those blocks” from “those dolls” if you could only say “those”?
"
4624,4624,7334,Another instructor is pushing me out of the classroom right after my class ends,"I am a graduate student in math in my final year, and for several years have been teaching at my department as a lecturer. This semester, in the same lecture hall there is another lecture that starts 20 minutes after my class ends. It's taught by another instructor from my department. I usually have many students coming to office hours and there are also students asking questions immediately after lecture. Due to other activities, I cannot have office hours right after the lecture this semester and can only stay for about 15 minutes to answer questions.

Many times in the past I had a similar situation and never had any issues with it. This semester the instructor who is teaching right after often arrives 20-15 minutes before her class starts and tells me immediately that I have to go with my students somewhere else. 

I make sure to leave the blackboard clean and take all my stuff away from the instructor's desk before she arrives, but I do believe that I have a right to stay in the classroom after my lecture for at least 5-10 minutes. There is no vacant classroom around, and I don't have time to go with students to my office, which is in a different building.

Last time the instructor told me in front of my students that I don't understand ""simple things"" and that I am ""playing games"". When I was talking to one of my students, she stood very close to us and clearly demonstrated that she wanted us out. I tried to explain her that I couldn't go anywhere else due to my time constraints, but she didn't want to listen to me. I really don't understand what ""simple"" things she meant and what ""games"" I am playing. 

We leave the board clean. She doesn't need to set up a projector. She can still talk to her students before her class starts, if she wants to (even though it seems like her students don't ask her any questions before their class). So, I don't see how I cause any disruption. 

I had met this woman many times before this semester, but we never talked. I didn't see her talking to other instructors/students much, and she seems to be quite reserved and a bit neurotic. She doesn't want to have any conversation with me regarding the issue.

I felt really offended after last class when she said those things to me in front of my students. What would you do in my case? 

Added later: There are no official rules regarding classroom occupancy between classes. Instructors are supposed to use common sense and be reasonable. For me using 50% of the break time seems reasonable to answer questions after lecture seems reasonable. I agree that for some people it may not.

I don't block the entrance to the classroom. A few students from the next class who come earlier always go ahead and take their seats as soon as my students start leaving the room. I also had one of the students from the next class listening to my explanation to one of those after-class questions and asking me further questions before their class (which is the same class as I am teaching, just a different section). Maybe the instructor got jealous, I don't know.

The entrance to the classroom is from its front (not back), so I do stay in the front. But it is a big lecture hall, and there is a plenty of space in front of the room (the board itself consists of 8 huge panels).

Also, during my career as a grad.student who is also teaching for the department, I have had several observations from experienced professors who are considered to be great teachers at the department and are in charge of undergraduate teaching policy. In my evaluations the fact that there are always several students approaching me with questions after class considered as very positive, meaning that students find me approachable. 

Thank you everyone for answers. 
",Lidd88,https://academia.stackexchange.com/users/31345,"If I were in your situation, I would ask the other professor for a reason and explain that I wanted to make an announcement to my students at the next lecture. If the response is ""because I want you out"" then I would politely explain that I would announce to the students that we could only remain for 10 minutes after class after which time we would all need to be out of the room. 

No need to make it confrontational.  I find that if you offer to help people solve a problem that helps reduce tension.  If this professor doesn't actually have a problem then offering to help solve a problem will be a non-confrontational way of pointing that out.  

This worked for me last semester.  We only had 15 minutes between classes and my course was taught in a computer lab. Quite often students had questions about projects they were working on and already had their code pulled up on their screen.  Unfortunately the students from the following course would be filing in and because their course required them to have access to code on a particular machine (shared drives wouldn't work) they needed particular seats which my students were still occupying. 

In my case, the professor after me simply explained why he needed the room and at the next lecture I explained to my students why they needed to exit within 5 minutes of the end of class. Everyone understood, no tension, no confrontation. 
",Matt S,https://academia.stackexchange.com/users/31376,http://academia.stackexchange.com/questions/41133/another-instructor-is-pushing-me-out-of-the-classroom-right-after-my-class-ends,LIFE_ARTS,academia.stackexchange.com,1.0,0.5555555555555556,0.0,0.0,0.0,0.0,0.5555555555555556,0.8888888888888888,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,1.0,1.0,0.7777777777777778,1.0,1.0,1.0,0.3333333333333333,0.3333333333333333,1.0,1.0,No sooner had I finished class than another teacher kicked me out of the classroom,"I am a graduate student in math in my final year, and for several years have been teaching at my department as a lecturer. This semester, in the same lecture hall there is another lecture that starts 20 minutes after my class ends. It's taught by another instructor from my department. I usually have many students coming to office hours and there are also students asking questions immediately after lecture. Due to other activities, I cannot have office hours right after the lecture this semester and can only stay for about 15 minutes to answer questions.

Many times in the past I had a similar situation and never had any issues with it. This semester the instructor who is teaching right after often arrives 20-15 minutes before her class starts and tells me immediately that I have to go with my students somewhere else. 

I make sure to leave the blackboard clean and take all my stuff away from the instructor's desk before she arrives, but I do believe that I have a right to stay in the classroom after my lecture for at least 5-10 minutes. There is no vacant classroom around, and I don't have time to go with students to my office, which is in a different building.

Last time the instructor told me in front of my students that I don't understand ""simple things"" and that I am ""playing games"". When I was talking to one of my students, she stood very close to us and clearly demonstrated that she wanted us out. I tried to explain her that I couldn't go anywhere else due to my time constraints, but she didn't want to listen to me. I really don't understand what ""simple"" things she meant and what ""games"" I am playing. 

We leave the board clean. She doesn't need to set up a projector. She can still talk to her students before her class starts, if she wants to (even though it seems like her students don't ask her any questions before their class). So, I don't see how I cause any disruption. 

I had met this woman many times before this semester, but we never talked. I didn't see her talking to other instructors/students much, and she seems to be quite reserved and a bit neurotic. She doesn't want to have any conversation with me regarding the issue.

I felt really offended after last class when she said those things to me in front of my students. What would you do in my case? 

Added later: There are no official rules regarding classroom occupancy between classes. Instructors are supposed to use common sense and be reasonable. For me using 50% of the break time seems reasonable to answer questions after lecture seems reasonable. I agree that for some people it may not.

I don't block the entrance to the classroom. A few students from the next class who come earlier always go ahead and take their seats as soon as my students start leaving the room. I also had one of the students from the next class listening to my explanation to one of those after-class questions and asking me further questions before their class (which is the same class as I am teaching, just a different section). Maybe the instructor got jealous, I don't know.

The entrance to the classroom is from its front (not back), so I do stay in the front. But it is a big lecture hall, and there is a plenty of space in front of the room (the board itself consists of 8 huge panels).

Also, during my career as a grad.student who is also teaching for the department, I have had several observations from experienced professors who are considered to be great teachers at the department and are in charge of undergraduate teaching policy. In my evaluations the fact that there are always several students approaching me with questions after class considered as very positive, meaning that students find me approachable. 

Thank you everyone for answers. 
","If I were in your situation, I would ask the other professor for a reason and explain that I wanted to make an announcement to my students at the next lecture. If the response is ""because I want you out"" then I would politely explain that I would announce to the students that we could only remain for 10 minutes after class after which time we would all need to be out of the room. 

No need to make it confrontational.  I find that if you offer to help people solve a problem that helps reduce tension.  If this professor doesn't actually have a problem then offering to help solve a problem will be a non-confrontational way of pointing that out.  

This worked for me last semester.  We only had 15 minutes between classes and my course was taught in a computer lab. Quite often students had questions about projects they were working on and already had their code pulled up on their screen.  Unfortunately the students from the following course would be filing in and because their course required them to have access to code on a particular machine (shared drives wouldn't work) they needed particular seats which my students were still occupying. 

In my case, the professor after me simply explained why he needed the room and at the next lecture I explained to my students why they needed to exit within 5 minutes of the end of class. Everyone understood, no tension, no confrontation. 
"
1755,1755,2779,How can I do some free design work?,"I am a designer that wants to do some free design work for people, but the problem is, how do I find people to do free work for? Is there any place online?

The reason behind this is that I am good at this, but I don't have any clients, or any previous experience and I am a freelancer, so this would look good on my portfolio.

My skills are very vast and include : 3D, 2D animation, 3D modeling, motion design, stop motion animation,video editing, game design, level design, FluidSIM, illustration, unreal engine 4, graphics design, editorial design, web design and I also know HTML5, CSS, JavaScript and jQuery.



By free work, I mean that the clients don't have to pay a single penny for the work that I do.
",Zach Roschack,https://graphicdesign.stackexchange.com/users/43164,"Have you tried offering your services to your community? Places always in need of graphic designers include:


Religious communities (churches)
Community centres
Amateur theatre groups
Support groups (i.e. AA)
Schools
Immigration welcoming groups
Senior communities
Condominiums


By the way, you can always do these things without saying explicitly ""hey, I am a graphic designer and I am looking for graphic design tasks"". Just volunteer to do things that are graphic design by nature like posters, websites, flyers etc. As a bonus, you will get experience on how to handle clients: even if you do it for free people can get very demanding and opinionated.

Mind you, the more we offer or work for free the more people think our work is worth nothing. It is always good to give back to the community, but it is also important to educate the world. We do what we do for a living, not just for the love of it.
",cockypup,https://graphicdesign.stackexchange.com/users/12151,http://graphicdesign.stackexchange.com/questions/51992/how-can-i-do-some-free-design-work,LIFE_ARTS,graphicdesign.stackexchange.com,0.8888888888888888,0.7777777777777778,0.0,0.3333333333333333,0.6666666666666666,0.0,0.4444444444444444,0.4444444444444444,0.6666666666666666,0.0,1.0,0.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,0.0,0.0,1.0,1.0,0.8888888888888888,1.0,1.0,0.8666666666666666,0.3333333333333333,0.6666666666666666,0.0,1.0,How can I do some free design work?,"I am a designer that wants to do some free design work for people, but the problem is, how do I find people to do free work for? Is there any place online?

The reason behind this is that I am good at this, but I don't have any clients, or any previous experience and I am a freelancer, so this would look good on my portfolio.

My skills are very vast and include : 3D, 2D animation, 3D modeling, motion design, stop motion animation,video editing, game design, level design, FluidSIM, illustration, unreal engine 4, graphics design, editorial design, web design and I also know HTML5, CSS, JavaScript and jQuery.



By free work, I mean that the clients don't have to pay a single penny for the work that I do.
","Have you tried offering your services to your community? Places always in need of graphic designers include:


Religious communities (churches)
Community centres
Amateur theatre groups
Support groups (i.e. AA)
Schools
Immigration welcoming groups
Senior communities
Condominiums


By the way, you can always do these things without saying explicitly ""hey, I am a graphic designer and I am looking for graphic design tasks"". Just volunteer to do things that are graphic design by nature like posters, websites, flyers etc. As a bonus, you will get experience on how to handle clients: even if you do it for free people can get very demanding and opinionated.

Mind you, the more we offer or work for free the more people think our work is worth nothing. It is always good to give back to the community, but it is also important to educate the world. We do what we do for a living, not just for the love of it.
"
3531,3531,5629,Create pass through with Mule ESB 2.2.1,"I'm attempting to set up a config file for Mule ESB 2.2.1 that routes incoming requests to another box. This seems straight forward, but I am getting connection refused exceptions and I'm not sure why. 

Here is the model from my Mule configuration file:

&lt;model name=""ProxySample""&gt;
    &lt;service name=""HttpProxyService""&gt;
        &lt;inbound&gt;
            &lt;http:inbound-endpoint address=""http://localhost:8787"" synchronous=""true""/&gt;
        &lt;/inbound&gt;
        &lt;outbound&gt;
            &lt;pass-through-router&gt;
                &lt;outbound-endpoint address=""http://server2.xyz.com:8080#[header:http.request]"" synchronous=""true""/&gt;
            &lt;/pass-through-router&gt;
        &lt;/outbound&gt;
    &lt;/service&gt;
&lt;/model&gt;


I am browsing to http://localhost:8787/my-site in my browser, thinking that it will route to http://server2.xyz.com:8080/my-site, but I get a connection refused error.

Here is the console output from the Mule server:

**********************************************************************
* Mule ESB and Integration Platform                                  *
* Version: 2.2.1 Build: 14422                                        *
* MuleSource, Inc.                                                   *
* For more information go to http://mule.mulesource.org              *
*                                                                    *
* Server started: 1/19/10 10:43 AM                                   *
* Server ID: 6802537d-0511-11df-bb89-710580f6c729                    *
* JDK: 1.6.0_18 (mixed mode, sharing)                                *
* OS encoding: UTF-8, Mule encoding: UTF-8                           *
* OS: Windows XP - Service Pack 3 (5.1, x86)                         *
* Host:                                      *
*                                                                    *
* Agents Running: None                                               *
**********************************************************************
INFO  2010-01-19 10:43:50,681 [connector.http.0.receiver.2] org.mule.transport.http.HttpClientMessageDispatcher: Connected: endpoint.outbound.http://localhost:8080#[header:http.request]
ERROR 2010-01-19 10:43:54,665 [connector.http.0.receiver.2] org.mule.DefaultExceptionStrategy: 
********************************************************************************
Message               : Failed to route event via endpoint: org.mule.endpoint.DynamicURIOutboundEndpoint@6645e149. Message payload is of type: GetMethod
Type                  : org.mule.api.transport.DispatchException
Code                  : MULE_ERROR-42999
Payload               : org.apache.commons.httpclient.methods.GetMethod@d67067
JavaDoc               : http://www.mulesource.org/docs/site/current2/apidocs/org/mule/api/transport/DispatchException.html
********************************************************************************
Exception stack is:
1. Connection refused: connect (java.net.ConnectException)
  java.net.PlainSocketImpl:-2 (null)
2. Failed to route event via endpoint: org.mule.endpoint.DynamicURIOutboundEndpoint@6645e149. Message payload is of type: GetMethod (org.mule.api.transport.DispatchException)
  org.mule.transport.http.HttpClientMessageDispatcher:127 (http://www.mulesource.org/docs/site/current2/apidocs/org/mule/api/transport/DispatchException.html)
********************************************************************************
Root Exception stack trace:
java.net.ConnectException: Connection refused: connect
    at java.net.PlainSocketImpl.socketConnect(Native Method)
    at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:333)
    at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:195)
    at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:182)
    at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)
    at java.net.Socket.connect(Socket.java:525)
    at java.net.Socket.connect(Socket.java:475)
    at java.net.Socket.&lt;init&gt;(Socket.java:372)
    at java.net.Socket.&lt;init&gt;(Socket.java:246)
    at org.apache.commons.httpclient.protocol.DefaultProtocolSocketFactory.createSocket(DefaultProtocolSocketFactory.java:80)
    at org.apache.commons.httpclient.protocol.DefaultProtocolSocketFactory.createSocket(DefaultProtocolSocketFactory.java:122)
    at org.apache.commons.httpclient.HttpConnection.open(HttpConnection.java:707)
    at org.apache.commons.httpclient.MultiThreadedHttpConnectionManager$HttpConnectionAdapter.open(MultiThreadedHttpConnectionManager.java:1361)
    at org.apache.commons.httpclient.HttpMethodDirector.executeWithRetry(HttpMethodDirector.java:387)
    at org.apache.commons.httpclient.HttpMethodDirector.executeMethod(HttpMethodDirector.java:171)
    at org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:397)
    at org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:346)
    at org.mule.transport.http.HttpClientMessageDispatcher.execute(HttpClientMessageDispatcher.java:120)
    at org.mule.transport.http.HttpClientMessageDispatcher.doSend(HttpClientMessageDispatcher.java:258)
    at org.mule.transport.AbstractMessageDispatcher.send(AbstractMessageDispatcher.java:163)
    at org.mule.transport.AbstractConnector.send(AbstractConnector.java:2016)
    at org.mule.endpoint.DynamicURIOutboundEndpoint.send(DynamicURIOutboundEndpoint.java:178)
    at org.mule.DefaultMuleSession.sendEvent(DefaultMuleSession.java:327)
    at org.mule.DefaultMuleSession.sendEvent(DefaultMuleSession.java:213)
    at org.mule.routing.outbound.AbstractOutboundRouter$2.doInTransaction(AbstractOutboundRouter.java:152)
    at org.mule.transaction.TransactionTemplate.execute(TransactionTemplate.java:99)
    at org.mule.routing.outbound.AbstractOutboundRouter.send(AbstractOutboundRouter.java:159)
    at org.mule.routing.outbound.ChainingRouter.route(ChainingRouter.java:123)
    at org.mule.routing.outbound.DefaultOutboundRouterCollection$1.doInTransaction(DefaultOutboundRouterCollection.java:88)
    at org.mule.transaction.TransactionTemplate.execute(TransactionTemplate.java:45)
    at org.mule.routing.outbound.DefaultOutboundRouterCollection.route(DefaultOutboundRouterCollection.java:93)
    at org.mule.service.AbstractService.sendToOutboundRouter(AbstractService.java:892)
    at org.mule.model.seda.SedaService.doSend(SedaService.java:258)
    at org.mule.service.AbstractService.sendEvent(AbstractService.java:500)
    at org.mule.DefaultMuleSession.sendEvent(DefaultMuleSession.java:354)
    at org.mule.routing.inbound.DefaultInboundRouterCollection.send(DefaultInboundRouterCollection.java:228)
    at org.mule.routing.inbound.DefaultInboundRouterCollection.route(DefaultInboundRouterCollection.java:188)
    at org.mule.transport.AbstractMessageReceiver$DefaultInternalMessageListener.onMessage(AbstractMessageReceiver.java:364)
    at org.mule.transport.AbstractMessageReceiver.routeMessage(AbstractMessageReceiver.java:252)
    at org.mule.transport.AbstractMessageReceiver.routeMessage(AbstractMessageReceiver.java:193)
    at org.mule.transport.http.HttpMessageReceiver$HttpWorker.doRequest(HttpMessageReceiver.java:273)
    at org.mule.transport.http.HttpMessageReceiver$HttpWorker.processRequest(HttpMessageReceiver.java:227)
    at org.mule.transport.http.HttpMessageReceiver$HttpWorker.run(HttpMessageReceiver.java:190)
    at org.mule.work.WorkerContext.run(WorkerContext.java:310)
    at edu.emory.mathcs.backport.java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1061)
    at edu.emory.mathcs.backport.java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:575)
    at java.lang.Thread.run(Thread.java:619)

********************************************************************************

INFO  2010-01-19 10:43:54,665 [connector.http.0.receiver.2] org.mule.transaction.TransactionTemplate: Exception Caught in Transaction template.  Handing off to exception handler: org.mule.service.DefaultServiceExceptionStrategy@1412e75
ERROR 2010-01-19 10:43:54,665 [connector.http.0.receiver.2] org.mule.service.DefaultServiceExceptionStrategy: 
********************************************************************************
Message               : Failed to route event via endpoint: org.mule.endpoint.DynamicURIOutboundEndpoint@6645e149. Message payload is of type: GetMethod
Type                  : org.mule.api.transport.DispatchException
Code                  : MULE_ERROR-42999
Payload               : org.apache.commons.httpclient.methods.GetMethod@d67067
JavaDoc               : http://www.mulesource.org/docs/site/current2/apidocs/org/mule/api/transport/DispatchException.html
********************************************************************************
Exception stack is:
1. Connection refused: connect (java.net.ConnectException)
  java.net.PlainSocketImpl:-2 (null)
2. Failed to route event via endpoint: org.mule.endpoint.DynamicURIOutboundEndpoint@6645e149. Message payload is of type: GetMethod (org.mule.api.transport.DispatchException)
  org.mule.transport.http.HttpClientMessageDispatcher:127 (http://www.mulesource.org/docs/site/current2/apidocs/org/mule/api/transport/DispatchException.html)
********************************************************************************
Root Exception stack trace:
java.net.ConnectException: Connection refused: connect
    at java.net.PlainSocketImpl.socketConnect(Native Method)
    at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:333)
    at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:195)
    at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:182)
    at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)
    at java.net.Socket.connect(Socket.java:525)
    at java.net.Socket.connect(Socket.java:475)
    at java.net.Socket.&lt;init&gt;(Socket.java:372)
    at java.net.Socket.&lt;init&gt;(Socket.java:246)
    at org.apache.commons.httpclient.protocol.DefaultProtocolSocketFactory.createSocket(DefaultProtocolSocketFactory.java:80)
    at org.apache.commons.httpclient.protocol.DefaultProtocolSocketFactory.createSocket(DefaultProtocolSocketFactory.java:122)
    at org.apache.commons.httpclient.HttpConnection.open(HttpConnection.java:707)
    at org.apache.commons.httpclient.MultiThreadedHttpConnectionManager$HttpConnectionAdapter.open(MultiThreadedHttpConnectionManager.java:1361)
    at org.apache.commons.httpclient.HttpMethodDirector.executeWithRetry(HttpMethodDirector.java:387)
    at org.apache.commons.httpclient.HttpMethodDirector.executeMethod(HttpMethodDirector.java:171)
    at org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:397)
    at org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:346)
    at org.mule.transport.http.HttpClientMessageDispatcher.execute(HttpClientMessageDispatcher.java:120)
    at org.mule.transport.http.HttpClientMessageDispatcher.doSend(HttpClientMessageDispatcher.java:258)
    at org.mule.transport.AbstractMessageDispatcher.send(AbstractMessageDispatcher.java:163)
    at org.mule.transport.AbstractConnector.send(AbstractConnector.java:2016)
    at org.mule.endpoint.DynamicURIOutboundEndpoint.send(DynamicURIOutboundEndpoint.java:178)
    at org.mule.DefaultMuleSession.sendEvent(DefaultMuleSession.java:327)
    at org.mule.DefaultMuleSession.sendEvent(DefaultMuleSession.java:213)
    at org.mule.routing.outbound.AbstractOutboundRouter$2.doInTransaction(AbstractOutboundRouter.java:152)
    at org.mule.transaction.TransactionTemplate.execute(TransactionTemplate.java:99)
    at org.mule.routing.outbound.AbstractOutboundRouter.send(AbstractOutboundRouter.java:159)
    at org.mule.routing.outbound.ChainingRouter.route(ChainingRouter.java:123)
    at org.mule.routing.outbound.DefaultOutboundRouterCollection$1.doInTransaction(DefaultOutboundRouterCollection.java:88)
    at org.mule.transaction.TransactionTemplate.execute(TransactionTemplate.java:45)
    at org.mule.routing.outbound.DefaultOutboundRouterCollection.route(DefaultOutboundRouterCollection.java:93)
    at org.mule.service.AbstractService.sendToOutboundRouter(AbstractService.java:892)
    at org.mule.model.seda.SedaService.doSend(SedaService.java:258)
    at org.mule.service.AbstractService.sendEvent(AbstractService.java:500)
    at org.mule.DefaultMuleSession.sendEvent(DefaultMuleSession.java:354)
    at org.mule.routing.inbound.DefaultInboundRouterCollection.send(DefaultInboundRouterCollection.java:228)
    at org.mule.routing.inbound.DefaultInboundRouterCollection.route(DefaultInboundRouterCollection.java:188)
    at org.mule.transport.AbstractMessageReceiver$DefaultInternalMessageListener.onMessage(AbstractMessageReceiver.java:364)
    at org.mule.transport.AbstractMessageReceiver.routeMessage(AbstractMessageReceiver.java:252)
    at org.mule.transport.AbstractMessageReceiver.routeMessage(AbstractMessageReceiver.java:193)
    at org.mule.transport.http.HttpMessageReceiver$HttpWorker.doRequest(HttpMessageReceiver.java:273)
    at org.mule.transport.http.HttpMessageReceiver$HttpWorker.processRequest(HttpMessageReceiver.java:227)
    at org.mule.transport.http.HttpMessageReceiver$HttpWorker.run(HttpMessageReceiver.java:190)
    at org.mule.work.WorkerContext.run(WorkerContext.java:310)
    at edu.emory.mathcs.backport.java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1061)
    at edu.emory.mathcs.backport.java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:575)
    at java.lang.Thread.run(Thread.java:619)

********************************************************************************

ERROR 2010-01-19 10:43:54,665 [connector.http.0.receiver.2] org.mule.service.DefaultServiceExceptionStrategy: 
********************************************************************************
Message               : Failed to route event via endpoint: org.mule.endpoint.DynamicURIOutboundEndpoint@6645e149. Message payload is of type: GetMethod
Type                  : org.mule.api.transport.DispatchException
Code                  : MULE_ERROR-42999
Payload               : org.apache.commons.httpclient.methods.GetMethod@d67067
JavaDoc               : http://www.mulesource.org/docs/site/current2/apidocs/org/mule/api/transport/DispatchException.html
********************************************************************************
Exception stack is:
1. Connection refused: connect (java.net.ConnectException)
  java.net.PlainSocketImpl:-2 (null)
2. Failed to route event via endpoint: org.mule.endpoint.DynamicURIOutboundEndpoint@6645e149. Message payload is of type: GetMethod (org.mule.api.transport.DispatchException)
  org.mule.transport.http.HttpClientMessageDispatcher:127 (http://www.mulesource.org/docs/site/current2/apidocs/org/mule/api/transport/DispatchException.html)
********************************************************************************
Root Exception stack trace:
java.net.ConnectException: Connection refused: connect
    at java.net.PlainSocketImpl.socketConnect(Native Method)
    at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:333)
    at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:195)
    at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:182)
    at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)
    at java.net.Socket.connect(Socket.java:525)
    at java.net.Socket.connect(Socket.java:475)
    at java.net.Socket.&lt;init&gt;(Socket.java:372)
    at java.net.Socket.&lt;init&gt;(Socket.java:246)
    at org.apache.commons.httpclient.protocol.DefaultProtocolSocketFactory.createSocket(DefaultProtocolSocketFactory.java:80)
    at org.apache.commons.httpclient.protocol.DefaultProtocolSocketFactory.createSocket(DefaultProtocolSocketFactory.java:122)
    at org.apache.commons.httpclient.HttpConnection.open(HttpConnection.java:707)
    at org.apache.commons.httpclient.MultiThreadedHttpConnectionManager$HttpConnectionAdapter.open(MultiThreadedHttpConnectionManager.java:1361)
    at org.apache.commons.httpclient.HttpMethodDirector.executeWithRetry(HttpMethodDirector.java:387)
    at org.apache.commons.httpclient.HttpMethodDirector.executeMethod(HttpMethodDirector.java:171)
    at org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:397)
    at org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:346)
    at org.mule.transport.http.HttpClientMessageDispatcher.execute(HttpClientMessageDispatcher.java:120)
    at org.mule.transport.http.HttpClientMessageDispatcher.doSend(HttpClientMessageDispatcher.java:258)
    at org.mule.transport.AbstractMessageDispatcher.send(AbstractMessageDispatcher.java:163)
    at org.mule.transport.AbstractConnector.send(AbstractConnector.java:2016)
    at org.mule.endpoint.DynamicURIOutboundEndpoint.send(DynamicURIOutboundEndpoint.java:178)
    at org.mule.DefaultMuleSession.sendEvent(DefaultMuleSession.java:327)
    at org.mule.DefaultMuleSession.sendEvent(DefaultMuleSession.java:213)
    at org.mule.routing.outbound.AbstractOutboundRouter$2.doInTransaction(AbstractOutboundRouter.java:152)
    at org.mule.transaction.TransactionTemplate.execute(TransactionTemplate.java:99)
    at org.mule.routing.outbound.AbstractOutboundRouter.send(AbstractOutboundRouter.java:159)
    at org.mule.routing.outbound.ChainingRouter.route(ChainingRouter.java:123)
    at org.mule.routing.outbound.DefaultOutboundRouterCollection$1.doInTransaction(DefaultOutboundRouterCollection.java:88)
    at org.mule.transaction.TransactionTemplate.execute(TransactionTemplate.java:45)
    at org.mule.routing.outbound.DefaultOutboundRouterCollection.route(DefaultOutboundRouterCollection.java:93)
    at org.mule.service.AbstractService.sendToOutboundRouter(AbstractService.java:892)
    at org.mule.model.seda.SedaService.doSend(SedaService.java:258)
    at org.mule.service.AbstractService.sendEvent(AbstractService.java:500)
    at org.mule.DefaultMuleSession.sendEvent(DefaultMuleSession.java:354)
    at org.mule.routing.inbound.DefaultInboundRouterCollection.send(DefaultInboundRouterCollection.java:228)
    at org.mule.routing.inbound.DefaultInboundRouterCollection.route(DefaultInboundRouterCollection.java:188)
    at org.mule.transport.AbstractMessageReceiver$DefaultInternalMessageListener.onMessage(AbstractMessageReceiver.java:364)
    at org.mule.transport.AbstractMessageReceiver.routeMessage(AbstractMessageReceiver.java:252)
    at org.mule.transport.AbstractMessageReceiver.routeMessage(AbstractMessageReceiver.java:193)
    at org.mule.transport.http.HttpMessageReceiver$HttpWorker.doRequest(HttpMessageReceiver.java:273)
    at org.mule.transport.http.HttpMessageReceiver$HttpWorker.processRequest(HttpMessageReceiver.java:227)
    at org.mule.transport.http.HttpMessageReceiver$HttpWorker.run(HttpMessageReceiver.java:190)
    at org.mule.work.WorkerContext.run(WorkerContext.java:310)
    at edu.emory.mathcs.backport.java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1061)
    at edu.emory.mathcs.backport.java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:575)
    at java.lang.Thread.run(Thread.java:619)

********************************************************************************

",Dan Polites,https://stackoverflow.com/users/43365,"That should definitelly work, if you wan't to make the service more readable, you can also write the implicit component : 

&lt;model name=""ProxySample""&gt;
    &lt;service name=""HttpProxyService""&gt;
        &lt;inbound&gt;
            &lt;http:inbound-endpoint address=""http://localhost:8787"" synchronous=""true""/&gt;
        &lt;/inbound&gt;

        &lt;bridge-component /&gt;

        &lt;outbound&gt;
            &lt;pass-through-router&gt;
                &lt;outbound-endpoint address=""http://server2.xyz.com:8080#[header:http.request]"" synchronous=""true""/&gt;
            &lt;/pass-through-router&gt;
        &lt;/outbound&gt;
    &lt;/service&gt;
&lt;/model&gt;

",Víctor Romero,https://stackoverflow.com/users/912190,http://stackoverflow.com/questions/2094757/create-pass-through-with-mule-esb-2-2-1,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.4444444444444444,0.0,1.0,0.6666666666666666,1.0,0.4444444444444444,0.4444444444444444,0.3333333333333333,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,0.0,0.6666666666666666,0.7777777777777778,0.4444444444444444,1.0,1.0,0.5333333333333333,1.0,0.0,0.0,0.7777777777777778,Create a pass using mule ESB 2.2.1,"I'm attempting to set up a config file for Mule ESB 2.2.1 that routes incoming requests to another box. This seems straight forward, but I am getting connection refused exceptions and I'm not sure why. 

Here is the model from my Mule configuration file:

&lt;model name=""ProxySample""&gt;
    &lt;service name=""HttpProxyService""&gt;
        &lt;inbound&gt;
            &lt;http:inbound-endpoint address=""http://localhost:8787"" synchronous=""true""/&gt;
        &lt;/inbound&gt;
        &lt;outbound&gt;
            &lt;pass-through-router&gt;
                &lt;outbound-endpoint address=""http://server2.xyz.com:8080#[header:http.request]"" synchronous=""true""/&gt;
            &lt;/pass-through-router&gt;
        &lt;/outbound&gt;
    &lt;/service&gt;
&lt;/model&gt;


I am browsing to http://localhost:8787/my-site in my browser, thinking that it will route to http://server2.xyz.com:8080/my-site, but I get a connection refused error.

Here is the console output from the Mule server:

**********************************************************************
* Mule ESB and Integration Platform                                  *
* Version: 2.2.1 Build: 14422                                        *
* MuleSource, Inc.                                                   *
* For more information go to http://mule.mulesource.org              *
*                                                                    *
* Server started: 1/19/10 10:43 AM                                   *
* Server ID: 6802537d-0511-11df-bb89-710580f6c729                    *
* JDK: 1.6.0_18 (mixed mode, sharing)                                *
* OS encoding: UTF-8, Mule encoding: UTF-8                           *
* OS: Windows XP - Service Pack 3 (5.1, x86)                         *
* Host:                                      *
*                                                                    *
* Agents Running: None                                               *
**********************************************************************
INFO  2010-01-19 10:43:50,681 [connector.http.0.receiver.2] org.mule.transport.http.HttpClientMessageDispatcher: Connected: endpoint.outbound.http://localhost:8080#[header:http.request]
ERROR 2010-01-19 10:43:54,665 [connector.http.0.receiver.2] org.mule.DefaultExceptionStrategy: 
********************************************************************************
Message               : Failed to route event via endpoint: org.mule.endpoint.DynamicURIOutboundEndpoint@6645e149. Message payload is of type: GetMethod
Type                  : org.mule.api.transport.DispatchException
Code                  : MULE_ERROR-42999
Payload               : org.apache.commons.httpclient.methods.GetMethod@d67067
JavaDoc               : http://www.mulesource.org/docs/site/current2/apidocs/org/mule/api/transport/DispatchException.html
********************************************************************************
Exception stack is:
1. Connection refused: connect (java.net.ConnectException)
  java.net.PlainSocketImpl:-2 (null)
2. Failed to route event via endpoint: org.mule.endpoint.DynamicURIOutboundEndpoint@6645e149. Message payload is of type: GetMethod (org.mule.api.transport.DispatchException)
  org.mule.transport.http.HttpClientMessageDispatcher:127 (http://www.mulesource.org/docs/site/current2/apidocs/org/mule/api/transport/DispatchException.html)
********************************************************************************
Root Exception stack trace:
java.net.ConnectException: Connection refused: connect
    at java.net.PlainSocketImpl.socketConnect(Native Method)
    at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:333)
    at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:195)
    at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:182)
    at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)
    at java.net.Socket.connect(Socket.java:525)
    at java.net.Socket.connect(Socket.java:475)
    at java.net.Socket.&lt;init&gt;(Socket.java:372)
    at java.net.Socket.&lt;init&gt;(Socket.java:246)
    at org.apache.commons.httpclient.protocol.DefaultProtocolSocketFactory.createSocket(DefaultProtocolSocketFactory.java:80)
    at org.apache.commons.httpclient.protocol.DefaultProtocolSocketFactory.createSocket(DefaultProtocolSocketFactory.java:122)
    at org.apache.commons.httpclient.HttpConnection.open(HttpConnection.java:707)
    at org.apache.commons.httpclient.MultiThreadedHttpConnectionManager$HttpConnectionAdapter.open(MultiThreadedHttpConnectionManager.java:1361)
    at org.apache.commons.httpclient.HttpMethodDirector.executeWithRetry(HttpMethodDirector.java:387)
    at org.apache.commons.httpclient.HttpMethodDirector.executeMethod(HttpMethodDirector.java:171)
    at org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:397)
    at org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:346)
    at org.mule.transport.http.HttpClientMessageDispatcher.execute(HttpClientMessageDispatcher.java:120)
    at org.mule.transport.http.HttpClientMessageDispatcher.doSend(HttpClientMessageDispatcher.java:258)
    at org.mule.transport.AbstractMessageDispatcher.send(AbstractMessageDispatcher.java:163)
    at org.mule.transport.AbstractConnector.send(AbstractConnector.java:2016)
    at org.mule.endpoint.DynamicURIOutboundEndpoint.send(DynamicURIOutboundEndpoint.java:178)
    at org.mule.DefaultMuleSession.sendEvent(DefaultMuleSession.java:327)
    at org.mule.DefaultMuleSession.sendEvent(DefaultMuleSession.java:213)
    at org.mule.routing.outbound.AbstractOutboundRouter$2.doInTransaction(AbstractOutboundRouter.java:152)
    at org.mule.transaction.TransactionTemplate.execute(TransactionTemplate.java:99)
    at org.mule.routing.outbound.AbstractOutboundRouter.send(AbstractOutboundRouter.java:159)
    at org.mule.routing.outbound.ChainingRouter.route(ChainingRouter.java:123)
    at org.mule.routing.outbound.DefaultOutboundRouterCollection$1.doInTransaction(DefaultOutboundRouterCollection.java:88)
    at org.mule.transaction.TransactionTemplate.execute(TransactionTemplate.java:45)
    at org.mule.routing.outbound.DefaultOutboundRouterCollection.route(DefaultOutboundRouterCollection.java:93)
    at org.mule.service.AbstractService.sendToOutboundRouter(AbstractService.java:892)
    at org.mule.model.seda.SedaService.doSend(SedaService.java:258)
    at org.mule.service.AbstractService.sendEvent(AbstractService.java:500)
    at org.mule.DefaultMuleSession.sendEvent(DefaultMuleSession.java:354)
    at org.mule.routing.inbound.DefaultInboundRouterCollection.send(DefaultInboundRouterCollection.java:228)
    at org.mule.routing.inbound.DefaultInboundRouterCollection.route(DefaultInboundRouterCollection.java:188)
    at org.mule.transport.AbstractMessageReceiver$DefaultInternalMessageListener.onMessage(AbstractMessageReceiver.java:364)
    at org.mule.transport.AbstractMessageReceiver.routeMessage(AbstractMessageReceiver.java:252)
    at org.mule.transport.AbstractMessageReceiver.routeMessage(AbstractMessageReceiver.java:193)
    at org.mule.transport.http.HttpMessageReceiver$HttpWorker.doRequest(HttpMessageReceiver.java:273)
    at org.mule.transport.http.HttpMessageReceiver$HttpWorker.processRequest(HttpMessageReceiver.java:227)
    at org.mule.transport.http.HttpMessageReceiver$HttpWorker.run(HttpMessageReceiver.java:190)
    at org.mule.work.WorkerContext.run(WorkerContext.java:310)
    at edu.emory.mathcs.backport.java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1061)
    at edu.emory.mathcs.backport.java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:575)
    at java.lang.Thread.run(Thread.java:619)

********************************************************************************

INFO  2010-01-19 10:43:54,665 [connector.http.0.receiver.2] org.mule.transaction.TransactionTemplate: Exception Caught in Transaction template.  Handing off to exception handler: org.mule.service.DefaultServiceExceptionStrategy@1412e75
ERROR 2010-01-19 10:43:54,665 [connector.http.0.receiver.2] org.mule.service.DefaultServiceExceptionStrategy: 
********************************************************************************
Message               : Failed to route event via endpoint: org.mule.endpoint.DynamicURIOutboundEndpoint@6645e149. Message payload is of type: GetMethod
Type                  : org.mule.api.transport.DispatchException
Code                  : MULE_ERROR-42999
Payload               : org.apache.commons.httpclient.methods.GetMethod@d67067
JavaDoc               : http://www.mulesource.org/docs/site/current2/apidocs/org/mule/api/transport/DispatchException.html
********************************************************************************
Exception stack is:
1. Connection refused: connect (java.net.ConnectException)
  java.net.PlainSocketImpl:-2 (null)
2. Failed to route event via endpoint: org.mule.endpoint.DynamicURIOutboundEndpoint@6645e149. Message payload is of type: GetMethod (org.mule.api.transport.DispatchException)
  org.mule.transport.http.HttpClientMessageDispatcher:127 (http://www.mulesource.org/docs/site/current2/apidocs/org/mule/api/transport/DispatchException.html)
********************************************************************************
Root Exception stack trace:
java.net.ConnectException: Connection refused: connect
    at java.net.PlainSocketImpl.socketConnect(Native Method)
    at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:333)
    at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:195)
    at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:182)
    at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)
    at java.net.Socket.connect(Socket.java:525)
    at java.net.Socket.connect(Socket.java:475)
    at java.net.Socket.&lt;init&gt;(Socket.java:372)
    at java.net.Socket.&lt;init&gt;(Socket.java:246)
    at org.apache.commons.httpclient.protocol.DefaultProtocolSocketFactory.createSocket(DefaultProtocolSocketFactory.java:80)
    at org.apache.commons.httpclient.protocol.DefaultProtocolSocketFactory.createSocket(DefaultProtocolSocketFactory.java:122)
    at org.apache.commons.httpclient.HttpConnection.open(HttpConnection.java:707)
    at org.apache.commons.httpclient.MultiThreadedHttpConnectionManager$HttpConnectionAdapter.open(MultiThreadedHttpConnectionManager.java:1361)
    at org.apache.commons.httpclient.HttpMethodDirector.executeWithRetry(HttpMethodDirector.java:387)
    at org.apache.commons.httpclient.HttpMethodDirector.executeMethod(HttpMethodDirector.java:171)
    at org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:397)
    at org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:346)
    at org.mule.transport.http.HttpClientMessageDispatcher.execute(HttpClientMessageDispatcher.java:120)
    at org.mule.transport.http.HttpClientMessageDispatcher.doSend(HttpClientMessageDispatcher.java:258)
    at org.mule.transport.AbstractMessageDispatcher.send(AbstractMessageDispatcher.java:163)
    at org.mule.transport.AbstractConnector.send(AbstractConnector.java:2016)
    at org.mule.endpoint.DynamicURIOutboundEndpoint.send(DynamicURIOutboundEndpoint.java:178)
    at org.mule.DefaultMuleSession.sendEvent(DefaultMuleSession.java:327)
    at org.mule.DefaultMuleSession.sendEvent(DefaultMuleSession.java:213)
    at org.mule.routing.outbound.AbstractOutboundRouter$2.doInTransaction(AbstractOutboundRouter.java:152)
    at org.mule.transaction.TransactionTemplate.execute(TransactionTemplate.java:99)
    at org.mule.routing.outbound.AbstractOutboundRouter.send(AbstractOutboundRouter.java:159)
    at org.mule.routing.outbound.ChainingRouter.route(ChainingRouter.java:123)
    at org.mule.routing.outbound.DefaultOutboundRouterCollection$1.doInTransaction(DefaultOutboundRouterCollection.java:88)
    at org.mule.transaction.TransactionTemplate.execute(TransactionTemplate.java:45)
    at org.mule.routing.outbound.DefaultOutboundRouterCollection.route(DefaultOutboundRouterCollection.java:93)
    at org.mule.service.AbstractService.sendToOutboundRouter(AbstractService.java:892)
    at org.mule.model.seda.SedaService.doSend(SedaService.java:258)
    at org.mule.service.AbstractService.sendEvent(AbstractService.java:500)
    at org.mule.DefaultMuleSession.sendEvent(DefaultMuleSession.java:354)
    at org.mule.routing.inbound.DefaultInboundRouterCollection.send(DefaultInboundRouterCollection.java:228)
    at org.mule.routing.inbound.DefaultInboundRouterCollection.route(DefaultInboundRouterCollection.java:188)
    at org.mule.transport.AbstractMessageReceiver$DefaultInternalMessageListener.onMessage(AbstractMessageReceiver.java:364)
    at org.mule.transport.AbstractMessageReceiver.routeMessage(AbstractMessageReceiver.java:252)
    at org.mule.transport.AbstractMessageReceiver.routeMessage(AbstractMessageReceiver.java:193)
    at org.mule.transport.http.HttpMessageReceiver$HttpWorker.doRequest(HttpMessageReceiver.java:273)
    at org.mule.transport.http.HttpMessageReceiver$HttpWorker.processRequest(HttpMessageReceiver.java:227)
    at org.mule.transport.http.HttpMessageReceiver$HttpWorker.run(HttpMessageReceiver.java:190)
    at org.mule.work.WorkerContext.run(WorkerContext.java:310)
    at edu.emory.mathcs.backport.java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1061)
    at edu.emory.mathcs.backport.java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:575)
    at java.lang.Thread.run(Thread.java:619)

********************************************************************************

ERROR 2010-01-19 10:43:54,665 [connector.http.0.receiver.2] org.mule.service.DefaultServiceExceptionStrategy: 
********************************************************************************
Message               : Failed to route event via endpoint: org.mule.endpoint.DynamicURIOutboundEndpoint@6645e149. Message payload is of type: GetMethod
Type                  : org.mule.api.transport.DispatchException
Code                  : MULE_ERROR-42999
Payload               : org.apache.commons.httpclient.methods.GetMethod@d67067
JavaDoc               : http://www.mulesource.org/docs/site/current2/apidocs/org/mule/api/transport/DispatchException.html
********************************************************************************
Exception stack is:
1. Connection refused: connect (java.net.ConnectException)
  java.net.PlainSocketImpl:-2 (null)
2. Failed to route event via endpoint: org.mule.endpoint.DynamicURIOutboundEndpoint@6645e149. Message payload is of type: GetMethod (org.mule.api.transport.DispatchException)
  org.mule.transport.http.HttpClientMessageDispatcher:127 (http://www.mulesource.org/docs/site/current2/apidocs/org/mule/api/transport/DispatchException.html)
********************************************************************************
Root Exception stack trace:
java.net.ConnectException: Connection refused: connect
    at java.net.PlainSocketImpl.socketConnect(Native Method)
    at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:333)
    at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:195)
    at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:182)
    at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)
    at java.net.Socket.connect(Socket.java:525)
    at java.net.Socket.connect(Socket.java:475)
    at java.net.Socket.&lt;init&gt;(Socket.java:372)
    at java.net.Socket.&lt;init&gt;(Socket.java:246)
    at org.apache.commons.httpclient.protocol.DefaultProtocolSocketFactory.createSocket(DefaultProtocolSocketFactory.java:80)
    at org.apache.commons.httpclient.protocol.DefaultProtocolSocketFactory.createSocket(DefaultProtocolSocketFactory.java:122)
    at org.apache.commons.httpclient.HttpConnection.open(HttpConnection.java:707)
    at org.apache.commons.httpclient.MultiThreadedHttpConnectionManager$HttpConnectionAdapter.open(MultiThreadedHttpConnectionManager.java:1361)
    at org.apache.commons.httpclient.HttpMethodDirector.executeWithRetry(HttpMethodDirector.java:387)
    at org.apache.commons.httpclient.HttpMethodDirector.executeMethod(HttpMethodDirector.java:171)
    at org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:397)
    at org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:346)
    at org.mule.transport.http.HttpClientMessageDispatcher.execute(HttpClientMessageDispatcher.java:120)
    at org.mule.transport.http.HttpClientMessageDispatcher.doSend(HttpClientMessageDispatcher.java:258)
    at org.mule.transport.AbstractMessageDispatcher.send(AbstractMessageDispatcher.java:163)
    at org.mule.transport.AbstractConnector.send(AbstractConnector.java:2016)
    at org.mule.endpoint.DynamicURIOutboundEndpoint.send(DynamicURIOutboundEndpoint.java:178)
    at org.mule.DefaultMuleSession.sendEvent(DefaultMuleSession.java:327)
    at org.mule.DefaultMuleSession.sendEvent(DefaultMuleSession.java:213)
    at org.mule.routing.outbound.AbstractOutboundRouter$2.doInTransaction(AbstractOutboundRouter.java:152)
    at org.mule.transaction.TransactionTemplate.execute(TransactionTemplate.java:99)
    at org.mule.routing.outbound.AbstractOutboundRouter.send(AbstractOutboundRouter.java:159)
    at org.mule.routing.outbound.ChainingRouter.route(ChainingRouter.java:123)
    at org.mule.routing.outbound.DefaultOutboundRouterCollection$1.doInTransaction(DefaultOutboundRouterCollection.java:88)
    at org.mule.transaction.TransactionTemplate.execute(TransactionTemplate.java:45)
    at org.mule.routing.outbound.DefaultOutboundRouterCollection.route(DefaultOutboundRouterCollection.java:93)
    at org.mule.service.AbstractService.sendToOutboundRouter(AbstractService.java:892)
    at org.mule.model.seda.SedaService.doSend(SedaService.java:258)
    at org.mule.service.AbstractService.sendEvent(AbstractService.java:500)
    at org.mule.DefaultMuleSession.sendEvent(DefaultMuleSession.java:354)
    at org.mule.routing.inbound.DefaultInboundRouterCollection.send(DefaultInboundRouterCollection.java:228)
    at org.mule.routing.inbound.DefaultInboundRouterCollection.route(DefaultInboundRouterCollection.java:188)
    at org.mule.transport.AbstractMessageReceiver$DefaultInternalMessageListener.onMessage(AbstractMessageReceiver.java:364)
    at org.mule.transport.AbstractMessageReceiver.routeMessage(AbstractMessageReceiver.java:252)
    at org.mule.transport.AbstractMessageReceiver.routeMessage(AbstractMessageReceiver.java:193)
    at org.mule.transport.http.HttpMessageReceiver$HttpWorker.doRequest(HttpMessageReceiver.java:273)
    at org.mule.transport.http.HttpMessageReceiver$HttpWorker.processRequest(HttpMessageReceiver.java:227)
    at org.mule.transport.http.HttpMessageReceiver$HttpWorker.run(HttpMessageReceiver.java:190)
    at org.mule.work.WorkerContext.run(WorkerContext.java:310)
    at edu.emory.mathcs.backport.java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1061)
    at edu.emory.mathcs.backport.java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:575)
    at java.lang.Thread.run(Thread.java:619)

********************************************************************************

","That should definitelly work, if you wan't to make the service more readable, you can also write the implicit component : 

&lt;model name=""ProxySample""&gt;
    &lt;service name=""HttpProxyService""&gt;
        &lt;inbound&gt;
            &lt;http:inbound-endpoint address=""http://localhost:8787"" synchronous=""true""/&gt;
        &lt;/inbound&gt;

        &lt;bridge-component /&gt;

        &lt;outbound&gt;
            &lt;pass-through-router&gt;
                &lt;outbound-endpoint address=""http://server2.xyz.com:8080#[header:http.request]"" synchronous=""true""/&gt;
            &lt;/pass-through-router&gt;
        &lt;/outbound&gt;
    &lt;/service&gt;
&lt;/model&gt;

"
3433,3433,5459,What is the purpose of active and passive voice?,"In both passive and active voice, the meaning of the sentence is same. 

So what is the purpose of passive and active as by two different names?
",john michal,https://ell.stackexchange.com/users/4123,"The sentence may recount the same facts, or it may not. One very significant difference is that in the active voice you must identify the Agent: the person (or other entity) who  performs the action, whereas in the passive you are free to omit the Agent.

Active


  ok John stole my book.
  &lowast;&nbsp; Stole my book. 


Passive


  ok My book was stolen by John.
  ok My book was stolen.  


In either case, the passive voice is employed to focus on the Patient of the action&mdash;the person or thing which 'suffered' it&mdash;rather than on Agent who or which performed it. There are several reasons you might want to do this:


Because you don&rsquo;t know or don&rsquo;t care who performed the action  
Because what is important is the action itself rather than who performed it
Because what is important is the result of the action rather than who performed it 
Because you want your readers to think of the action as 'impersonal'  


The last reason became particularly important in the 19th century, when scientific writers&mdash;or writers who wanted to be thought of as adopting a 'scientific' attitude&mdash;were particularly careful to banish any suggestion that the writer's personality or attitudes had any influence on what was reported. The passive voice remains to this day something of a fetish in the sciences, particularly in the 'soft' sciences, where there is still substantial anxiety about the scientific status and value of the work done. 



&lowast;&nbsp; marks an utterance as ungrammatical.
",StoneyB,https://ell.stackexchange.com/users/32,http://ell.stackexchange.com/questions/16406/what-is-the-purpose-of-active-and-passive-voice,CULTURE,ell.stackexchange.com,1.0,1.0,0.0,0.6666666666666666,1.0,1.0,0.3333333333333333,0.7777777777777778,0.0,0.0,0.6666666666666666,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.8888888888888888,1.0,0.7777777777777778,1.0,1.0,1.0,0.0,0.0,1.0,1.0,What is the purpose of active voice and passive voice?,The meaning of a sentence is the same whether it is a passive voice or an active voice.,"The sentence may recount the same facts, or it may not. One very significant difference is that in the active voice you must identify the Agent: the person (or other entity) who  performs the action, whereas in the passive you are free to omit the Agent.

Active


  ok John stole my book.
  &lowast;&nbsp; Stole my book. 


Passive


  ok My book was stolen by John.
  ok My book was stolen.  


In either case, the passive voice is employed to focus on the Patient of the action&mdash;the person or thing which 'suffered' it&mdash;rather than on Agent who or which performed it. There are several reasons you might want to do this:


Because you don&rsquo;t know or don&rsquo;t care who performed the action  
Because what is important is the action itself rather than who performed it
Because what is important is the result of the action rather than who performed it 
Because you want your readers to think of the action as 'impersonal'  


The last reason became particularly important in the 19th century, when scientific writers&mdash;or writers who wanted to be thought of as adopting a 'scientific' attitude&mdash;were particularly careful to banish any suggestion that the writer's personality or attitudes had any influence on what was reported. The passive voice remains to this day something of a fetish in the sciences, particularly in the 'soft' sciences, where there is still substantial anxiety about the scientific status and value of the work done. 



&lowast;&nbsp; marks an utterance as ungrammatical.
"
2904,2904,4619,Can I have an Animal Companions without being a druid or ranger?,"I'm looking for a way to have an animal companion with classes other than druid or ranger, for example a paladin that fights with a trained hawk. I'm all for multiclassing if need be, but I'm looking for other ways as well, through feats if necessary. I'm not really worried about min/max stats or optimized builds.
",DoomWolf,https://rpg.stackexchange.com/users/9549,"The Advanced Class Guide's Hunter has class abilities that specifically pertain to improving your animal companion and having it fight alongside you as a friend and teammate. One notable Hunter archetype is the Packmaster, which grants your character the ability to have multiple animal companions.

The Inquisitor archetype Sacred Huntsmaster grants your character an animal companion as well. 

You can also get an animal companion via the Animal Domain. Your effective druid level for this animal companion will be equal to your cleric level -3. 
",user3735278,https://rpg.stackexchange.com/users/14987,http://rpg.stackexchange.com/questions/55125/can-i-have-an-animal-companions-without-being-a-druid-or-ranger,CULTURE,rpg.stackexchange.com,0.8888888888888888,1.0,0.0,1.0,1.0,1.0,0.5555555555555556,0.5555555555555556,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,0.8333333333333334,0.8,0.6666666666666666,0.0,0.0,1.0,"If I'm not a druid or a Ranger, can I have animal companions?","I'm looking for a way for an animal companion to fight with other classes, not Druids or Rangers, such as a paladin fighting with a trained eagle. I fully support multiclassification if needed, but I'm also looking for other ways, if needed, through expertise. I really don't worry about minimum / maximum statistics or optimizing builds.","The Advanced Class Guide's Hunter has class abilities that specifically pertain to improving your animal companion and having it fight alongside you as a friend and teammate. One notable Hunter archetype is the Packmaster, which grants your character the ability to have multiple animal companions.

The Inquisitor archetype Sacred Huntsmaster grants your character an animal companion as well. 

You can also get an animal companion via the Animal Domain. Your effective druid level for this animal companion will be equal to your cleric level -3. 
"
5756,5756,9124,Get REQUEST_URI and don't overwrite,"I tried storing the REQUEST_URI in a session with the code below. I need to store the very first REQUEST_URI when a visitor lands on a page on our site and not have it overwritten when they begin browsing pages. This isn't working as I browse the site i'm seeing a new URI displayed by the echo.

session_start();
if ( !isset( $_SESSION['theuri'] ) ) {
    if ( !empty( $_SERVER['REQUEST_URI'] ) ) {
        $_SESSION['theuri'] = $_SERVER['REQUEST_URI'];
    }
}

echo $_SESSION['theuri'];

",Anagio,https://stackoverflow.com/users/804087,"You must start the session before any output so the cookies can be set correctly.
Wordpress is stateless and uses no sessions at all.
You mention you put this code in the footer, so probably there is output already.

A hacky solution would be to enter session_start() on the top of your index.php, or in wp-config.php.
",Green Black,https://stackoverflow.com/users/5763937,http://stackoverflow.com/questions/14636716/get-request-uri-and-dont-overwrite,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.4444444444444444,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,0.6666666666666666,0.8888888888888888,Get request URI and do not overwrite,"I try to store the request URI in the session with the following code. When visitors log on to a page of our website, I need to store the first request URI and do not overwrite it when they start browsing the page. This doesn't work because I'm browsing the site and I see an echo of a new URI display.","You must start the session before any output so the cookies can be set correctly.
Wordpress is stateless and uses no sessions at all.
You mention you put this code in the footer, so probably there is output already.

A hacky solution would be to enter session_start() on the top of your index.php, or in wp-config.php.
"
2059,2059,3281,Render displaying frame 1 of cloth simulation instead of baked result visible in the 3D view,"I have baked a 995 frame cloth simulation but when I go to render a still frame at frame 995 (tried 990) it displays frame 1. How do I render the final frame of the simulation instead?



",835,https://blender.stackexchange.com/users/6351,"Sounds like the cloth modifier is disabled in the render. 

Make sure the camera icon is selected in Properties  > Physics:


",gandalf3,https://blender.stackexchange.com/users/599,http://blender.stackexchange.com/questions/19679/render-displaying-frame-1-of-cloth-simulation-instead-of-baked-result-visible-in,TECHNOLOGY,blender.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,1.0,0.6666666666666666,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.5555555555555556,0.8888888888888888,0.6666666666666666,1.0,1.0,0.9,1.0,0.0,1.0,0.8888888888888888,Rendering displays the first frame of the cloth simulation instead of the baking results visible in the 3D view,"I baked a 995 frame cloth simulation, but when I rendered a still frame at 995 (tried 990), it showed frame 1. How to render the final frame of the simulation?","Sounds like the cloth modifier is disabled in the render. 

Make sure the camera icon is selected in Properties  > Physics:


"
2318,2318,3697,Differences between PS3 and Wii version of Rock Band The Beatles,"I'm considering buying Rock Band The Beatles for my only gaming console, the Nintendo Wii, but I was wondering if there are any big differences between the version on Wii and the version on Playstation 3?
",runaros,https://gaming.stackexchange.com/users/2968,"AFAIK, there is no difference between PS3 and Wii version.

The only difference I know for this game:

The Xbox 360 version of ""Rock Band: The Beatles"" has an exclusive song (All you need is love) which the PS3 and Wii don't have; but the song is available for download on the Wii and PS3.
",Mehper C. Palavuzlar,https://gaming.stackexchange.com/users/145,http://gaming.stackexchange.com/questions/5707/differences-between-ps3-and-wii-version-of-rock-band-the-beatles,CULTURE,gaming.stackexchange.com,1.0,1.0,0.0,1.0,1.0,1.0,0.5555555555555556,0.7777777777777778,0.0,0.0,0.3333333333333333,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.8888888888888888,1.0,0.8888888888888888,1.0,1.0,1.0,0.0,0.0,0.0,1.0,The difference between PS3 and Wii rock band beatles,"I'm thinking about buying rock band beatles as my only console, Nintendo Wii, but I wonder what's the big difference between Wii and Playstation 3?","AFAIK, there is no difference between PS3 and Wii version.

The only difference I know for this game:

The Xbox 360 version of ""Rock Band: The Beatles"" has an exclusive song (All you need is love) which the PS3 and Wii don't have; but the song is available for download on the Wii and PS3.
"
4381,4381,6968,My thesis advisor is absent in my final stage of completing my Ph.D. programme,"I am a mathematics Ph.D. student who are in my final stage of completing my Ph.D. programme. My advisor is visiting an institute for a few months. The institute that he is visiting is in another country; because of the visa requirements and many other practical reasons, I cannot go there with him.

Now my progress is, I have all the main results ready (most of them have been written down) and I need to finish writing my thesis in about three weeks. My advisor has guided my through all the mathematical difficulties; now he left me behind to write the thesis all by my own. Furthermore, he has clearly indicated that he will NOT help me with the writing process. 

Now I need to figure out many things all by myself, from LaTeX to the organization, from the usage of languages to drawing pictures, etc. Also I need to verify the correctness and validity of all the results; he mentioned that he will not carefully read my draft. And I do not have much time to finish everything. I am feeling somewhat stressed and overwhelming. 

In this situation, should I seek assistance from other professors/lecturers who do research in a similar field, or should I try to figure everything out by myself? Should I hire someone to proofread my thesis when the draft is finished? 
",Zuriel,https://academia.stackexchange.com/users/24832,"You are about to finish a PhD thesis. Somebody who obtained a PhD title is supposed to be able to organize and conduct reasonable projects independently. I think that your adviser is not being unreasonable in his demands.

Part of organization is also arranging to get more time, if your current time frame cannot be kept, or leads to serious degradation in quality and rigorousness. In some cases that might lead to working on your thesis without being funded. Personally, I would still advise to value doing a good job higher than meeting a deadline, but of course I cannot oversee all the consequences.
",Danny Ruijters,https://academia.stackexchange.com/users/28830,http://academia.stackexchange.com/questions/38143/my-thesis-advisor-is-absent-in-my-final-stage-of-completing-my-ph-d-programme,LIFE_ARTS,academia.stackexchange.com,1.0,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.0,0.0,0.6666666666666666,0.6666666666666666,1.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.3333333333333333,0.0,0.6666666666666666,0.8888888888888888,0.5555555555555556,0.8888888888888888,0.8888888888888888,0.6666666666666667,0.0,0.0,0.6666666666666666,0.8888888888888888,"At the end of my doctoral program, my thesis tutor was not available","I am a mathematics Ph.D. student who are in my final stage of completing my Ph.D. programme. My advisor is visiting an institute for a few months. The institute that he is visiting is in another country; because of the visa requirements and many other practical reasons, I cannot go there with him.

Now my progress is, I have all the main results ready (most of them have been written down) and I need to finish writing my thesis in about three weeks. My advisor has guided my through all the mathematical difficulties; now he left me behind to write the thesis all by my own. Furthermore, he has clearly indicated that he will NOT help me with the writing process. 

Now I need to figure out many things all by myself, from LaTeX to the organization, from the usage of languages to drawing pictures, etc. Also I need to verify the correctness and validity of all the results; he mentioned that he will not carefully read my draft. And I do not have much time to finish everything. I am feeling somewhat stressed and overwhelming. 

In this situation, should I seek assistance from other professors/lecturers who do research in a similar field, or should I try to figure everything out by myself? Should I hire someone to proofread my thesis when the draft is finished? 
","You are about to finish a PhD thesis. Somebody who obtained a PhD title is supposed to be able to organize and conduct reasonable projects independently. I think that your adviser is not being unreasonable in his demands.

Part of organization is also arranging to get more time, if your current time frame cannot be kept, or leads to serious degradation in quality and rigorousness. In some cases that might lead to working on your thesis without being funded. Personally, I would still advise to value doing a good job higher than meeting a deadline, but of course I cannot oversee all the consequences.
"
3902,3902,6218,Sump is sealed for radon remediation and doesn't drain water. What can I do for water drainage?,"Yesterday our 80 gallon water heater (less than 5 years old) ruptured - flooding our basement. Situated right next to the water heater is our sump - but it didn't do 1 ounce of its job, because it is sealed for radon remediation.

Any suggestions on how I can achieve both water drainage into a sump plus radon remediation?
",Dave Clausen,https://diy.stackexchange.com/users/4781,"Put a surface pump at the lowest portion of the basement? That should keep the flood down to an inch or so; not perfect but better.

(You could build up some sort of basin around the mechanicals so they have their own ""sump"" sitting on top of the slab... but Murphy's Law says that the next failure is going to be somewhere else in the system.)
",keshlam,https://diy.stackexchange.com/users/20958,http://diy.stackexchange.com/questions/48972/sump-is-sealed-for-radon-remediation-and-doesnt-drain-water-what-can-i-do-for,LIFE_ARTS,diy.stackexchange.com,1.0,0.8888888888888888,0.0,1.0,1.0,1.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.7777777777777778,0.8888888888888888,0.5555555555555556,0.8888888888888888,0.8888888888888888,0.6666666666666667,0.6666666666666666,0.3333333333333333,0.0,0.8888888888888888,The sump is sealed for radon remediation without drainage. What can I do for drainage?,"Yesterday our 80 gallon water heater (less than five years old) burst and flooded our basement. Our puddle was right next to the water heater, but it didn't do an ounce of work because it was sealed for radon remediation.","Put a surface pump at the lowest portion of the basement? That should keep the flood down to an inch or so; not perfect but better.

(You could build up some sort of basin around the mechanicals so they have their own ""sump"" sitting on top of the slab... but Murphy's Law says that the next failure is going to be somewhere else in the system.)
"
108,108,176,Get MS SQL Server to release disk space,"A poorly managed database table has grown to be enormous. 48+gigs of orphan records. I am trying to clean it up and put my dangerously full hard drive back to a normal state. I will be deleting approx 400 million records from this table. This is running as I type. I notice that I am not seeing any drop in my hard drive space but I am seeing the memory drop on system table queries, I am running to get table size. The database is using ""Simple Recovery Model"".

There are many questions similar to this with responses saying you need to shrink the database. But they go on to explain how bad/scary this is to do because of fragmented data etc. 


Since the database should not be this size. Is it still bad for me to shrink it?
This is a production database. If I shrink it will it cause downtime or lock the database?
In SQL Server Management Studio you have two options for shrink, database or files. Given my situation what would be the best option?
is there a rule on the percentage of free space a DB should have?


Even reading the tag description of shrink makes me not want to do it. Is there another way?
",jackncoke,https://dba.stackexchange.com/users/66232,"you have good reason to be concerned as DB shrinks in SQL Server often ""suck"".  Paul Randal, the head of the Storage Engine in SQL 2005 stated, ShrinkDB is written very poorly.  It will find empty space by taking the data at the very end and put it in the very beginning and keep doing this until it has free space at the 'end' of the DB files.  At this point it can then release the space from SQL Server and give it back to the OS.  You are effectively reversing your database files thus you will see massive fragmentation usually.  You can read about his views on this blog post or on this MCM Internals Video

As with everything, you really must test these in your environment first.  A better way of doing it is to move data to a different filegroup. You can do a online index rebuild with the clustered index and then reindex in the new filegroup.  Then you can drop the old one and release the space and have almost no fragmentation.  Note this will take about 120% extra space while it's working through it.  The problem with this is that you need even additional free space which it looks like you might not have.  This is an enterprise feature.

If free space is at that much of a premium, then you might have to bite the bullet and slowly shrink the DB a small chunk at a time to avoid long running processes.  Note that your data will be heavily fragmented and you will want to reindex everything again.  Note that after reindexing everything, you will then balloon up your used space a bit and go back to having additional free space.  See Brent's advice here.

As far as how much free space is good for you, is a matter of how much you can afford fragmentation and file growth activities.  With IFI enabled, the file growth is almost instant but you still get fragmentation.  A good rule of thumb is to preallocate as much as space as you think you'll need, or monitor the growth and adjust in chunks periodically if you have to.  This keeps physical fragmentation down.

Also log file growth is a lot more important.  Additional log files can cause VLF fragmentation.  This makes your restores a lot slower and can affect checkpoint/truncates.  Here's some performance risks you take with a fragmented log.  Do a DBCC LOGINFO(); on each database.  Try to keep the number around 50ish per Kim Tripp, but if you see hundreds, you have fragmentation issues which means your log files had to grow to support operations.  A good way to see what your log file should be per Paul Randal is to just let it grow for a week and reindex.  That could be a good point, perhaps you can throw a bit more free space on there just in case.  Make sure your logs are not fragmented with DBCC LOGINFO(); again and if they are, it means they grew a lot.  Shrink and re-expand the log file using this method. 
",Ali Razeghi,https://dba.stackexchange.com/users/12818,http://dba.stackexchange.com/questions/101211/get-ms-sql-server-to-release-disk-space,TECHNOLOGY,dba.stackexchange.com,1.0,0.3333333333333333,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.3333333333333333,0.6666666666666666,0.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.3333333333333333,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.3333333333333333,0.8888888888888888,Get MS SQL server to free disk space,"A poorly managed database table has grown to be enormous. 48+gigs of orphan records. I am trying to clean it up and put my dangerously full hard drive back to a normal state. I will be deleting approx 400 million records from this table. This is running as I type. I notice that I am not seeing any drop in my hard drive space but I am seeing the memory drop on system table queries, I am running to get table size. The database is using ""Simple Recovery Model"".

There are many questions similar to this with responses saying you need to shrink the database. But they go on to explain how bad/scary this is to do because of fragmented data etc. 


Since the database should not be this size. Is it still bad for me to shrink it?
This is a production database. If I shrink it will it cause downtime or lock the database?
In SQL Server Management Studio you have two options for shrink, database or files. Given my situation what would be the best option?
is there a rule on the percentage of free space a DB should have?


Even reading the tag description of shrink makes me not want to do it. Is there another way?
","you have good reason to be concerned as DB shrinks in SQL Server often ""suck"".  Paul Randal, the head of the Storage Engine in SQL 2005 stated, ShrinkDB is written very poorly.  It will find empty space by taking the data at the very end and put it in the very beginning and keep doing this until it has free space at the 'end' of the DB files.  At this point it can then release the space from SQL Server and give it back to the OS.  You are effectively reversing your database files thus you will see massive fragmentation usually.  You can read about his views on this blog post or on this MCM Internals Video

As with everything, you really must test these in your environment first.  A better way of doing it is to move data to a different filegroup. You can do a online index rebuild with the clustered index and then reindex in the new filegroup.  Then you can drop the old one and release the space and have almost no fragmentation.  Note this will take about 120% extra space while it's working through it.  The problem with this is that you need even additional free space which it looks like you might not have.  This is an enterprise feature.

If free space is at that much of a premium, then you might have to bite the bullet and slowly shrink the DB a small chunk at a time to avoid long running processes.  Note that your data will be heavily fragmented and you will want to reindex everything again.  Note that after reindexing everything, you will then balloon up your used space a bit and go back to having additional free space.  See Brent's advice here.

As far as how much free space is good for you, is a matter of how much you can afford fragmentation and file growth activities.  With IFI enabled, the file growth is almost instant but you still get fragmentation.  A good rule of thumb is to preallocate as much as space as you think you'll need, or monitor the growth and adjust in chunks periodically if you have to.  This keeps physical fragmentation down.

Also log file growth is a lot more important.  Additional log files can cause VLF fragmentation.  This makes your restores a lot slower and can affect checkpoint/truncates.  Here's some performance risks you take with a fragmented log.  Do a DBCC LOGINFO(); on each database.  Try to keep the number around 50ish per Kim Tripp, but if you see hundreds, you have fragmentation issues which means your log files had to grow to support operations.  A good way to see what your log file should be per Paul Randal is to just let it grow for a week and reindex.  That could be a good point, perhaps you can throw a bit more free space on there just in case.  Make sure your logs are not fragmented with DBCC LOGINFO(); again and if they are, it means they grew a lot.  Shrink and re-expand the log file using this method. 
"
1038,1038,1634,"If NASA could send a camera into a black hole, could we then see what's inside the black hole?","Inspired by Stephen Hawking I recently tripped upon an idea of what is really inside a black hole.

I thought if NASA (or any other space agency) could send a super protected camera into a black hole, then we could see what's inside black hole.

Is this even possible?
",Amit Joki,https://physics.stackexchange.com/users/40854,"No, not even light can escape a black hole, therefore radio will be unable to broadcast signals back to Earth. (Radio is a form of light)
",user37390,https://physics.stackexchange.com/users/37390,http://physics.stackexchange.com/questions/99678/if-nasa-could-send-a-camera-into-a-black-hole-could-we-then-see-whats-inside-t,SCIENCE,physics.stackexchange.com,1.0,0.7777777777777778,0.3333333333333333,1.0,0.6666666666666666,0.0,0.7777777777777778,0.8888888888888888,0.0,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.8888888888888888,0.6666666666666666,0.8888888888888888,0.8888888888888888,1.0,0.0,0.0,1.0,0.8888888888888888,"If NASA can send cameras into black holes, can we see what's inside them?","Inspired by Stephen Hawking I recently tripped upon an idea of what is really inside a black hole.

I thought if NASA (or any other space agency) could send a super protected camera into a black hole, then we could see what's inside black hole.

Is this even possible?
","No, not even light can escape a black hole, therefore radio will be unable to broadcast signals back to Earth. (Radio is a form of light)
"
601,601,942,How to dynamically override functions using Zend?,"Is it possible to override a function dynamically in Zend? 

class My_Core_Default_Api extends Zend_Mail_Transport_Sendmail
{
    public function getApi()
    {
        echo ""Old Api"";
    }
}

class My_Core_New_Api extends Zend_Mail_Transport_Sendmail
{
    public function getApi()
    {
        echo ""New Api"";
    }
}


Here I would like to override Core_Default_Api-&gt;getApi() with Core_New_Api-&gt;getApi(). Any suggestions please
",abhis,https://stackoverflow.com/users/276030,"It's not real ""Zend"" question. It's more PHP &amp; design patterns question. 

Problem would be that you would need to switch the instances of the Mail Transport - you're looking for Dependency injection, maybe.... or Proxy or Facade design pattern. You need ONE PLACE where you will switch the class and it will change everywhere else. I'd set that in config and have a class that loads propper class name from config and returns new instance... something like this:

TransportSelector::getTransport()-&gt;send($mail);

",Tomáš Fejfar,https://stackoverflow.com/users/112000,http://stackoverflow.com/questions/6367881/how-to-dynamically-override-functions-using-zend,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.7777777777777778,0.0,1.0,1.0,1.0,0.6666666666666666,0.4444444444444444,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,0.8888888888888888,0.8888888888888888,0.7,0.6666666666666666,0.3333333333333333,1.0,0.8888888888888888,How to use Zend dynamic rewrite function?,"Is it possible to override a function dynamically in Zend? 

class My_Core_Default_Api extends Zend_Mail_Transport_Sendmail
{
    public function getApi()
    {
        echo ""Old Api"";
    }
}

class My_Core_New_Api extends Zend_Mail_Transport_Sendmail
{
    public function getApi()
    {
        echo ""New Api"";
    }
}


Here I would like to override Core_Default_Api-&gt;getApi() with Core_New_Api-&gt;getApi(). Any suggestions please
","It's not real ""Zend"" question. It's more PHP &amp; design patterns question. 

Problem would be that you would need to switch the instances of the Mail Transport - you're looking for Dependency injection, maybe.... or Proxy or Facade design pattern. You need ONE PLACE where you will switch the class and it will change everywhere else. I'd set that in config and have a class that loads propper class name from config and returns new instance... something like this:

TransportSelector::getTransport()-&gt;send($mail);

"
4589,4589,7271,Scatterplots for subsets of multivariate data [Updated],"Update/Re-write

There has been a lot of ambiguity over what i'm am trying to do with this question so I have decided to give it a full rewrite. I'm really sorry for the confusion. If you want to see the background please see the edit history. I hope things are clearer now..

I have some data made up into the following fashion:

datac =
  {
   data1 = RandomReal[1, {7, 3}],
   data2 = RandomReal[1, {13, 3}],
   data3 = RandomReal[1, {19, 3}],
   data4 = RandomReal[1, {16, 3}],
   data5 = RandomReal[1, {5, 3}]
   };


data1 through data5 are subsets of a multivariate dataset with 3 independent variables. data1, for example, is composed of 7 individual data points (each with 3 variables).

If I use the following function: 

Needs[""StatisticalPlots`""]
pairwisecol[data_, col_] := 
PairwiseScatterPlot[data, 
                      PlotStyle -&gt; col, 
                      DataTicks -&gt; True,  
                      DataLabels -&gt; {""x"", ""y"", ""z""}]


I can create a combined plot comparing the various subsets. E.g.

Show[{pairwisecol[data1, Red], 
      pairwisecol[data2, Blue], 
      pairwisecol[data3, Green],  
      pairwisecol[data4, Purple], 
      pairwisecol[data5, Orange]}]




This curently has the major drawbacks that each subset has to be defined and have a colour explicitly assigned to it. Also, Show in this instance overlays all of the DataTicks etc, rather than just the elements from the first plot (as is normally the case with Show[{Plot1,Plot2}]).

What I'm looking for is a way to use the whole (partitioned) dataset datac to generate such a plot/diagram. i.e. something like,

Show[pairwisecol[#, Red] &amp; /@ datac]


but, with Red being replaced by a series of colours to represent each subset (like in the plot shown).

...Alternatively, starting with a 2-level list e.g.

datap = RandomReal[1, {60, 3}];


and a definition of sublist partitions,

parts = {7, 13, 19, 16, 5};


or

partspos = {[[1;;7]], [[8;;20]], [[21;;39]], [[40;;55]], [[56;;60]]};


then defining a function something like:

pairwiseP[data_, partlist_] := ...


that would partition datap into appropriate sublists, create a series of PairwiseScatterPlot's (each with a different plot colour) and then combine them using Show. 

Note that this example has n = 3 independent variables. I am looking for a method that works for 1 &lt; n &lt; ~20.

Can anyone suggest how to do this?
",geordie,https://mathematica.stackexchange.com/users/4626,"I'm still uncertain whether this is what you want.  Just make an array of plots and wrap it in Grid.  Fiddle with the options to get axes, dividers, etc. the way you want them.

The way I understand it, the data is really four subsets, each a group of datasets.  For each group, you want to plot one group vs. another group, for each pair of groups, data[[1, All, i ]] vs data[[1, All, j ]].  I'm still unsure about the desired coloring.  I've colored the plots by subset (which gives no extra information, except colors are pretty :).  The question states


  The individual colouring of the subsets is what i'm aiming for.


In the example plot, there are mixed colors.  I can only think that the plot is an amalgamation of subsets.  With my current understanding of the question, I don't how to use color to add more to each plot.  I feel like I'm missing something here.



Some random data with some structure:

SeedRandom[1];
data1 = Map[(# + RandomReal[{-0.1, 0.1}, 3])^Range[3] &amp;, RandomReal[{-1, 1}, {4, 4}], {-1}];
Dimensions[data1]


Plotting functions:

colorFn[subset_] := Hue[subset/4];
plot[subset_, datasets_] := Graphics[{colorFn[subset], Point[#]},
          AspectRatio -&gt; 1/GoldenRatio, ImageSize -&gt; 100] &amp; /@ datasets;


Mapping the plotting functions:

Grid[
 MapIndexed[plot[First@#2, Thread /@ Subsets[Transpose[#], {2}]] &amp;, data1],
 Dividers -&gt; All]




It's more interesting with 40 points instead of 4:

SeedRandom[1];
data1 = Map[(# + RandomReal[{-0.1, 0.1}, 3])^Range[3] &amp;, RandomReal[{-1, 1}, {4, 40}], {-1}];

Grid[
 MapIndexed[plot[First@#2, Thread /@ Subsets[Transpose@#, {2}]] &amp;, data1],
 Dividers -&gt; All]






Just to show the data is being processed as indicated:

foo = MapIndexed[Thread /@ Subsets[Transpose@#, {2}] &amp;, data1];
foo[[1, 1]] == Transpose@{data1[[1, All, 1]], data1[[1, All, 2]]}
foo[[1, 2]] == Transpose@{data1[[1, All, 1]], data1[[1, All, 3]]}
foo[[1, 3]] == Transpose@{data1[[1, All, 2]], data1[[1, All, 3]]}
(* etc. *)



True
True
True


",Michael E2,https://mathematica.stackexchange.com/users/4999,http://mathematica.stackexchange.com/questions/26595/scatterplots-for-subsets-of-multivariate-data-updated,TECHNOLOGY,mathematica.stackexchange.com,1.0,0.4444444444444444,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.3333333333333333,0.0,1.0,Scatter diagram [update] of multivariate data subset,"Update/Re-write

There has been a lot of ambiguity over what i'm am trying to do with this question so I have decided to give it a full rewrite. I'm really sorry for the confusion. If you want to see the background please see the edit history. I hope things are clearer now..

I have some data made up into the following fashion:

datac =
  {
   data1 = RandomReal[1, {7, 3}],
   data2 = RandomReal[1, {13, 3}],
   data3 = RandomReal[1, {19, 3}],
   data4 = RandomReal[1, {16, 3}],
   data5 = RandomReal[1, {5, 3}]
   };


data1 through data5 are subsets of a multivariate dataset with 3 independent variables. data1, for example, is composed of 7 individual data points (each with 3 variables).

If I use the following function: 

Needs[""StatisticalPlots`""]
pairwisecol[data_, col_] := 
PairwiseScatterPlot[data, 
                      PlotStyle -&gt; col, 
                      DataTicks -&gt; True,  
                      DataLabels -&gt; {""x"", ""y"", ""z""}]


I can create a combined plot comparing the various subsets. E.g.

Show[{pairwisecol[data1, Red], 
      pairwisecol[data2, Blue], 
      pairwisecol[data3, Green],  
      pairwisecol[data4, Purple], 
      pairwisecol[data5, Orange]}]




This curently has the major drawbacks that each subset has to be defined and have a colour explicitly assigned to it. Also, Show in this instance overlays all of the DataTicks etc, rather than just the elements from the first plot (as is normally the case with Show[{Plot1,Plot2}]).

What I'm looking for is a way to use the whole (partitioned) dataset datac to generate such a plot/diagram. i.e. something like,

Show[pairwisecol[#, Red] &amp; /@ datac]


but, with Red being replaced by a series of colours to represent each subset (like in the plot shown).

...Alternatively, starting with a 2-level list e.g.

datap = RandomReal[1, {60, 3}];


and a definition of sublist partitions,

parts = {7, 13, 19, 16, 5};


or

partspos = {[[1;;7]], [[8;;20]], [[21;;39]], [[40;;55]], [[56;;60]]};


then defining a function something like:

pairwiseP[data_, partlist_] := ...


that would partition datap into appropriate sublists, create a series of PairwiseScatterPlot's (each with a different plot colour) and then combine them using Show. 

Note that this example has n = 3 independent variables. I am looking for a method that works for 1 &lt; n &lt; ~20.

Can anyone suggest how to do this?
","I'm still uncertain whether this is what you want.  Just make an array of plots and wrap it in Grid.  Fiddle with the options to get axes, dividers, etc. the way you want them.

The way I understand it, the data is really four subsets, each a group of datasets.  For each group, you want to plot one group vs. another group, for each pair of groups, data[[1, All, i ]] vs data[[1, All, j ]].  I'm still unsure about the desired coloring.  I've colored the plots by subset (which gives no extra information, except colors are pretty :).  The question states


  The individual colouring of the subsets is what i'm aiming for.


In the example plot, there are mixed colors.  I can only think that the plot is an amalgamation of subsets.  With my current understanding of the question, I don't how to use color to add more to each plot.  I feel like I'm missing something here.



Some random data with some structure:

SeedRandom[1];
data1 = Map[(# + RandomReal[{-0.1, 0.1}, 3])^Range[3] &amp;, RandomReal[{-1, 1}, {4, 4}], {-1}];
Dimensions[data1]


Plotting functions:

colorFn[subset_] := Hue[subset/4];
plot[subset_, datasets_] := Graphics[{colorFn[subset], Point[#]},
          AspectRatio -&gt; 1/GoldenRatio, ImageSize -&gt; 100] &amp; /@ datasets;


Mapping the plotting functions:

Grid[
 MapIndexed[plot[First@#2, Thread /@ Subsets[Transpose[#], {2}]] &amp;, data1],
 Dividers -&gt; All]




It's more interesting with 40 points instead of 4:

SeedRandom[1];
data1 = Map[(# + RandomReal[{-0.1, 0.1}, 3])^Range[3] &amp;, RandomReal[{-1, 1}, {4, 40}], {-1}];

Grid[
 MapIndexed[plot[First@#2, Thread /@ Subsets[Transpose@#, {2}]] &amp;, data1],
 Dividers -&gt; All]






Just to show the data is being processed as indicated:

foo = MapIndexed[Thread /@ Subsets[Transpose@#, {2}] &amp;, data1];
foo[[1, 1]] == Transpose@{data1[[1, All, 1]], data1[[1, All, 2]]}
foo[[1, 2]] == Transpose@{data1[[1, All, 1]], data1[[1, All, 3]]}
foo[[1, 3]] == Transpose@{data1[[1, All, 2]], data1[[1, All, 3]]}
(* etc. *)



True
True
True


"
4047,4047,6460,Find router on network,"I've just bought a Belkin N+ Wireless Router. When I plug it directly into my computer I can navigate to its setup page at 192.168.2.1 - however, when I plug it into a random part of the network it still functions as a wireless hub but I can't get to its setup page at 192.168.2.1

Now I'm guessing that the main router has given it an IP. How can I find out what that is? I've looked on the web page for the main router and listed all IP's that are connected to it and tried to access each one but that didn't work.
",Guy,https://superuser.com/users/3248,"First of all, I am assuming you are connecting the WAN port of the wireless router to your hub, please correct me if my assumption is wrong.  Your wireless router is likely getting an WAN IP address like you said from your current DHCP server, however if your other DHCP server is giving out the same IP address ranges as your router (ie 192.168.2.xxx) then both your router and other gateway are likely trying to take 192.168.2.1 and so you'll probably never be able to access one of them.

Another thing to remember is that you likely cannot access the administration page of your router from the WAN side of the router.  You will need to access it from the wireless network or plug in a computer into one of the other (non-WAN) ports on the router to access the admin pages.

If you are just trying to use your wireless router as an access point (just to add wireless to your wired network) try plugging your hug into one of the non-WAN ports on your wireless router.
",heavyd,https://superuser.com/users/820,http://superuser.com/questions/87212,TECHNOLOGY,superuser.com,1.0,0.5,0.0,1.0,1.0,1.0,0.5,0.5,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,1.0,0.5,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.5,1.0,Find a router on the network,"I just bought a Belkin n + wireless router. When I plug it directly into my computer, I can navigate to the settings page of 192.168.2.1 - but when I plug it into the random part of the network, it still works as a wireless hub, but I can't access the settings page of 192.168.2.1","First of all, I am assuming you are connecting the WAN port of the wireless router to your hub, please correct me if my assumption is wrong.  Your wireless router is likely getting an WAN IP address like you said from your current DHCP server, however if your other DHCP server is giving out the same IP address ranges as your router (ie 192.168.2.xxx) then both your router and other gateway are likely trying to take 192.168.2.1 and so you'll probably never be able to access one of them.

Another thing to remember is that you likely cannot access the administration page of your router from the WAN side of the router.  You will need to access it from the wireless network or plug in a computer into one of the other (non-WAN) ports on the router to access the admin pages.

If you are just trying to use your wireless router as an access point (just to add wireless to your wired network) try plugging your hug into one of the non-WAN ports on your wireless router.
"
4027,4027,6429,Get selected value of a number model spinner,"How do you get the selected value from a number based spinner in java?

As i side note why does android always come up under the search term spinner
",nmu,https://stackoverflow.com/users/1649917,"A JSpinner has a SpinnerModel, that stores the selected Value, Bounds of the Values and step sizes, etc.

JSpinner spinner;
Object value = spinner.getModel().getValue();


Also other Spinners work this way. It is based on the Model-View-Controller(MVC)-Pattern and seperates the Data from their presentation and manipulation.
",Simulant,https://stackoverflow.com/users/1515052,http://stackoverflow.com/questions/12356410/get-selected-value-of-a-number-model-spinner,STACKOVERFLOW,stackoverflow.com,1.0,0.3333333333333333,0.0,1.0,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.6666666666666666,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.6666666666666666,0.0,0.5555555555555556,0.7777777777777778,0.4444444444444444,0.8888888888888888,0.8888888888888888,0.7333333333333333,0.3333333333333333,0.0,0.6666666666666666,1.0,Get the selected value of the digital model spinner,"How do you get the selected value from a number based spinner in java?

As i side note why does android always come up under the search term spinner
","A JSpinner has a SpinnerModel, that stores the selected Value, Bounds of the Values and step sizes, etc.

JSpinner spinner;
Object value = spinner.getModel().getValue();


Also other Spinners work this way. It is based on the Model-View-Controller(MVC)-Pattern and seperates the Data from their presentation and manipulation.
"
2270,2270,3617,What exactly is 'anti-aliased image generation'?,"I tried to google it, but didn't quite get it. Any help and/or examples?
Thank you!
",vascobnunes,https://gis.stackexchange.com/users/3530,"Anti-aliasing smooths out the text and features so it looks better and in many cases makes it easier to read.



",CaptDragon,https://gis.stackexchange.com/users/2022,http://gis.stackexchange.com/questions/21998/what-exactly-is-anti-aliased-image-generation,TECHNOLOGY,gis.stackexchange.com,0.8888888888888888,0.8888888888888888,0.0,1.0,1.0,1.0,0.4444444444444444,0.4444444444444444,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.0,0.0,1.0,0.8888888888888888,0.4444444444444444,0.8888888888888888,1.0,0.8666666666666666,0.0,0.0,0.0,1.0,What is anti aliasing image generation?,"I tried to search on Google, but I didn't find it completely. Any help and / or examples?","Anti-aliasing smooths out the text and features so it looks better and in many cases makes it easier to read.



"
5857,5857,9277,Flying and sorcery,"Rashi (Sanhedrin 44b, s.v. D'ba'ya) relates the story of Shimon ben Shetach's capture of 80 witches. He instructed his students to pick up the witches because the sorcery would be powerless against the students if the witches were ungrounded. Is this to say that sorcery does not work unless the practitioner is grounded?

If so, how can we interpret the Midrash (Bamidbar Rabba, 20:20) that states that Bilaam used sorcery to fly through the air?
",Fred,https://judaism.stackexchange.com/users/1442,"I think, in the Rashi on Sanhedrin 44b, the subject of the sentence ""He should lift one of them from the ground"" is not referring to one of the witches, but to one of the jars that he distributed in the sentence before.


  As translated here: http://www.bmv.org.il/shiurim/sanhedrin/san080.html
  
  [Shimon ben Shetach] assembled eighty tall young men and distributed to each of them a jar
  with a cloak wrapped up inside (it was a rainy day). He also told them
  to make sure that they were always eighty in number. ""When you come
  inside,"" he said, ""one of you must raise his jar from the ground; from
  that moment the witches will have no further hold over you; if that
  does not work then we can never beat them."" Shim'on ben-Shataĥ went
  into the witches' coven and left the young men outside. When the
  witches asked him who he was he replied that he was a wizard who had
  come to test them with his wizardry. ""What tricks can you do?"" they
  asked. ""Despite the fact that it is raining today I can produce eighty
  young men with dry cloaks!"" ""Show us!"" He went outside and beckoned
  the young men inside. They removed the cloaks from the jars, put them
  on, and came into the coven. Thus they bettered the witches, took them
  outside and strung them all up. 


I don't know how lifting one of the jars from the ground would render their powers useless, but maybe that answer lies in what power the witches claimed to have.
",zaq,https://judaism.stackexchange.com/users/702,http://judaism.stackexchange.com/questions/16216/flying-and-sorcery,CULTURE,judaism.stackexchange.com,0.6666666666666666,0.6666666666666666,0.5,0.5,0.5,0.5,0.8333333333333334,0.6666666666666666,0.5,0.0,0.5,0.5,0.0,0.0,0.0,0.5,0.0,0.5,1.0,0.0,1.0,0.8333333333333334,0.5,0.8333333333333334,1.0,0.8,0.0,0.0,1.0,1.0,Flying and witchcraft,"Sanhedrin 44B (s.v.d'ba'ya) tells the story of Simon Ben shetak's capture of 80 witches. He instructs his students to pick up the witch, because if the witch is not grounded, witchcraft can do nothing for the students. Does this mean that unless the practitioner is banned, witchcraft will not work?","I think, in the Rashi on Sanhedrin 44b, the subject of the sentence ""He should lift one of them from the ground"" is not referring to one of the witches, but to one of the jars that he distributed in the sentence before.


  As translated here: http://www.bmv.org.il/shiurim/sanhedrin/san080.html
  
  [Shimon ben Shetach] assembled eighty tall young men and distributed to each of them a jar
  with a cloak wrapped up inside (it was a rainy day). He also told them
  to make sure that they were always eighty in number. ""When you come
  inside,"" he said, ""one of you must raise his jar from the ground; from
  that moment the witches will have no further hold over you; if that
  does not work then we can never beat them."" Shim'on ben-Shataĥ went
  into the witches' coven and left the young men outside. When the
  witches asked him who he was he replied that he was a wizard who had
  come to test them with his wizardry. ""What tricks can you do?"" they
  asked. ""Despite the fact that it is raining today I can produce eighty
  young men with dry cloaks!"" ""Show us!"" He went outside and beckoned
  the young men inside. They removed the cloaks from the jars, put them
  on, and came into the coven. Thus they bettered the witches, took them
  outside and strung them all up. 


I don't know how lifting one of the jars from the ground would render their powers useless, but maybe that answer lies in what power the witches claimed to have.
"
4992,4992,7949,"Is it possible to ""add cold"" or to ""add heat"" to systems?","
  Amanda just poured herself a cup of hot coffee to get her day started.
  She took her first sip and nearly burned her tongue.  Since she didn't
  have much time to sit and wait for it to cool down, she put an ice
  cube in her coffee and stirred it with a metal spoon.  After a moment,
  she felt the spoon warm up, but when she took another sip, the coffee
  was cooler.  She was pretty sure, the ice added cold to her coffee,
  and the coffee added heat to her spoon.


Would you agree?
",Lisa,https://physics.stackexchange.com/users/22991,"The most important thing about feeling is that its relative and depends on the temperature of sensor point on skin. That's the reason we need thermometer to measure temperature with which everyone could agree.

Energy transfer is involved here, but it has very little to do with Amanda's feeling. Amanda's tongue and mouth was at high temperature due to initial sip which caused her to feel next sip cooler which was really cool due to addition of ice.

In case of spoon, spoon can't get hotter because heat of coffee (and some of heat of spoon) was consumed in melting ice. But, Amanda felt the spoon warmer because her fingers were relatively cold due to ice touch.
",Earth is Flat,https://physics.stackexchange.com/users/2170,http://physics.stackexchange.com/questions/60653/is-it-possible-to-add-cold-or-to-add-heat-to-systems,SCIENCE,physics.stackexchange.com,0.8888888888888888,0.5555555555555556,0.3333333333333333,1.0,0.6666666666666666,0.6666666666666666,0.7777777777777778,0.6666666666666666,0.0,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.8888888888888888,1.0,0.5555555555555556,1.0,1.0,0.7333333333333333,0.0,0.0,1.0,0.8888888888888888,"Is it possible to ""cool"" or ""heat"" the system?","
  Amanda just poured herself a cup of hot coffee to get her day started.
  She took her first sip and nearly burned her tongue.  Since she didn't
  have much time to sit and wait for it to cool down, she put an ice
  cube in her coffee and stirred it with a metal spoon.  After a moment,
  she felt the spoon warm up, but when she took another sip, the coffee
  was cooler.  She was pretty sure, the ice added cold to her coffee,
  and the coffee added heat to her spoon.


Would you agree?
","The most important thing about feeling is that its relative and depends on the temperature of sensor point on skin. That's the reason we need thermometer to measure temperature with which everyone could agree.

Energy transfer is involved here, but it has very little to do with Amanda's feeling. Amanda's tongue and mouth was at high temperature due to initial sip which caused her to feel next sip cooler which was really cool due to addition of ice.

In case of spoon, spoon can't get hotter because heat of coffee (and some of heat of spoon) was consumed in melting ice. But, Amanda felt the spoon warmer because her fingers were relatively cold due to ice touch.
"
1280,1280,2016,Get REQUEST_URI and don't overwrite,"I tried storing the REQUEST_URI in a session with the code below. I need to store the very first REQUEST_URI when a visitor lands on a page on our site and not have it overwritten when they begin browsing pages. This isn't working as I browse the site i'm seeing a new URI displayed by the echo.

session_start();
if ( !isset( $_SESSION['theuri'] ) ) {
    if ( !empty( $_SERVER['REQUEST_URI'] ) ) {
        $_SESSION['theuri'] = $_SERVER['REQUEST_URI'];
    }
}

echo $_SESSION['theuri'];

",Anagio,https://stackoverflow.com/users/804087,"I found this article which said to add this code to my functions.php and now the code in my footer is working fine.

http://devondev.com/2012/02/03/using-the-php-session-in-wordpress/

add_action('init', 'myStartSession', 1);
add_action('wp_logout', 'myEndSession');
add_action('wp_login', 'myEndSession');

function myStartSession() {
    if(!session_id()) {
        session_start();
    }
}

function myEndSession() {
    session_destroy ();
}

",Anagio,https://stackoverflow.com/users/804087,http://stackoverflow.com/questions/14636716/get-request-uri-and-dont-overwrite,STACKOVERFLOW,stackoverflow.com,0.6666666666666666,0.6666666666666666,0.0,1.0,0.3333333333333333,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,0.8888888888888888,Get request URI and do not overwrite,"I try to store the request URI in the session with the following code. When visitors log on to a page of our website, I need to store the first request URI and do not overwrite it when they start browsing the page. This doesn't work because I'm browsing the site and I see an echo of a new URI display.","I found this article which said to add this code to my functions.php and now the code in my footer is working fine.

http://devondev.com/2012/02/03/using-the-php-session-in-wordpress/

add_action('init', 'myStartSession', 1);
add_action('wp_logout', 'myEndSession');
add_action('wp_login', 'myEndSession');

function myStartSession() {
    if(!session_id()) {
        session_start();
    }
}

function myEndSession() {
    session_destroy ();
}

"
1630,1630,2554,Why don't wifi managers remember mac addresses for hotspots to defeat the jasager attack?,"So I just learned about the jasager attack, via the wifi pineapple and it struck me immediately that it wouldn't work at all if network managers (privately) associated MAC addresses with hotspots and asked for explicit permission if you were going to connect to a new physical device.

Obviously this would be mildly irritating in public hotspots where devices change and hundreds of diverse locations share network names, but it would make home and work networks much harder to penetrate.

I haven't found any wifi managers that do this, or at least I haven't found information that any do.

My question: 


Am I missing something obvious? Would remembering MACs not actually increase security?
If it would, are there any network managers that do this? (I'm on Linux, but if there are tools for other OS's I think it's worth having them in the answers)

",quodlibetor,https://security.stackexchange.com/users/8391,"Convenience, mostly: 


I'm now historically using my third AP device - each one has been completely different make and vendor, but as long as the configuration stayed the same (SSID, encryption mode, passphrase), there was no need to re-enter the AP data on any of the client devices. This may not be enough of an issue in a home setting; if you have hundreds of devices which can connect to the network, reconfiguring them when an AP dies would be a royal pain.
Likewise, having multiple identically-configured APs (and thus a larger signal-covered area), the client devices will switch to the AP with the strongest signal without trouble. A few frames may be lost before the new MAC address location propagates through the local network, but overall the roaming is close to seamless.


As for the ""only connect to this AP if it has a specific MAC address"" - this is already possible with NetworkManager on Linux: there is an option to specify the AP's BSSID, which should be the AP's MAC address (of course, the BSSID can be spoofed - hence ""should"").
",Piskvor,https://security.stackexchange.com/users/884,http://security.stackexchange.com/questions/14854/why-dont-wifi-managers-remember-mac-addresses-for-hotspots-to-defeat-the-jasage,TECHNOLOGY,security.stackexchange.com,1.0,0.3333333333333333,0.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.0,1.0,0.6666666666666666,0.0,1.0,0.0,1.0,1.0,0.4444444444444444,1.0,0.7777777777777778,0.9333333333333332,0.0,0.0,1.0,1.0,Why don't WiFi administrators remember the MAC address of hotspot to resist jasager attack?,"So I just learned about the jasager attack, via the wifi pineapple and it struck me immediately that it wouldn't work at all if network managers (privately) associated MAC addresses with hotspots and asked for explicit permission if you were going to connect to a new physical device.

Obviously this would be mildly irritating in public hotspots where devices change and hundreds of diverse locations share network names, but it would make home and work networks much harder to penetrate.

I haven't found any wifi managers that do this, or at least I haven't found information that any do.

My question: 


Am I missing something obvious? Would remembering MACs not actually increase security?
If it would, are there any network managers that do this? (I'm on Linux, but if there are tools for other OS's I think it's worth having them in the answers)

","Convenience, mostly: 


I'm now historically using my third AP device - each one has been completely different make and vendor, but as long as the configuration stayed the same (SSID, encryption mode, passphrase), there was no need to re-enter the AP data on any of the client devices. This may not be enough of an issue in a home setting; if you have hundreds of devices which can connect to the network, reconfiguring them when an AP dies would be a royal pain.
Likewise, having multiple identically-configured APs (and thus a larger signal-covered area), the client devices will switch to the AP with the strongest signal without trouble. A few frames may be lost before the new MAC address location propagates through the local network, but overall the roaming is close to seamless.


As for the ""only connect to this AP if it has a specific MAC address"" - this is already possible with NetworkManager on Linux: there is an option to specify the AP's BSSID, which should be the AP's MAC address (of course, the BSSID can be spoofed - hence ""should"").
"
471,471,734,"Has Jesus ever directly said he would die as a voluntary sacrafice? If so, wasn't it double sense?","I know about mentioning Jesus died to redeem mankind in evangelical literature like:


  For God so loved the world, that he gave his only Son, that whoever believes in him should not perish but have eternal life. (John 3:16)


But I suspect these are only later interpretations. Has Jesus himself ever said his dead is a sacrifice?

If so, isn't double meaning in Greek? At least in Czech, English and German you could use the phrase ""he died for humans' sins"" in sense of ""because of"" - like cause of his death was humans' fault - fault of the Romans who crucified him.

(btw I think I understand the evangelical message so I'm not asking how christians get it today, so please don't make your interpretations of the direct Jesus' quote much distant)

Thank you.
",Probably,https://christianity.stackexchange.com/users/12541,"The most obvious answer is Jesus' words to his disciples at the Last Supper, in Matthew's version:


  this is my blood of the covenant, which will be shed on behalf of many for the forgiveness of sins.


(Matthew 26:28, New American Bible Revised Edition) 
",Matt Gutting,https://christianity.stackexchange.com/users/12563,http://christianity.stackexchange.com/questions/41485/did-jesus-ever-directly-say-he-would-die-as-a-voluntary-sacrifice-if-so-was-it,CULTURE,christianity.stackexchange.com,1.0,0.7777777777777778,0.3333333333333333,0.6666666666666666,1.0,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.8888888888888888,0.8888888888888888,0.5555555555555556,0.8888888888888888,1.0,0.8666666666666666,0.0,0.0,0.3333333333333333,0.8888888888888888,"Did Jesus directly say that he would sacrifice voluntarily? If so, isn't that a double meaning?","I know about mentioning Jesus died to redeem mankind in evangelical literature like:


  For God so loved the world, that he gave his only Son, that whoever believes in him should not perish but have eternal life. (John 3:16)


But I suspect these are only later interpretations. Has Jesus himself ever said his dead is a sacrifice?

If so, isn't double meaning in Greek? At least in Czech, English and German you could use the phrase ""he died for humans' sins"" in sense of ""because of"" - like cause of his death was humans' fault - fault of the Romans who crucified him.

(btw I think I understand the evangelical message so I'm not asking how christians get it today, so please don't make your interpretations of the direct Jesus' quote much distant)

Thank you.
","The most obvious answer is Jesus' words to his disciples at the Last Supper, in Matthew's version:


  this is my blood of the covenant, which will be shed on behalf of many for the forgiveness of sins.


(Matthew 26:28, New American Bible Revised Edition) 
"
2905,2905,4621,How to store length of time in a model with Rails?,"I can think of two solutions:

1) Store hours, minutes, seconds, etc. in separate columns in the database


Downside: a lot of columns


2) Convert and store the number of seconds


We still want to be able to show seperate fields for hour, minute, second, etc. in the form. We could write virtual attribute for each of these and write a before_save callback that converts the timespan to seconds (still messy tho).


Am I missing some other obvious solution? How do you people do this?
",randomguy,https://stackoverflow.com/users/377920,"I vote for a single column to keep track of durations.  That keeps the duration normalized, whereas you'll need to do almost as much work or more to normalize multi-column durations.

Rails (activesupport) also gives you wonderful methods to work with time.  For example, if your duration is in seconds, you can easily add the duration in seconds to a point in time and get an end time:


  end_time = Time.now + duration_in_secs


It is a bit more work using virtual attributes to separate it out, but in my experience, it's not that more work.  perhaps there is a plugin or gem that simplifies it.
",edk750,https://stackoverflow.com/users/622139,http://stackoverflow.com/questions/5532817/how-to-store-length-of-time-in-a-model-with-rails,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.5555555555555556,0.0,0.3333333333333333,1.0,0.6666666666666666,0.6666666666666666,0.4444444444444444,0.6666666666666666,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,0.8888888888888888,0.8,0.0,0.6666666666666666,1.0,0.8888888888888888,How do I store the length of time in a model with rails?,"I can think of two solutions:

1) Store hours, minutes, seconds, etc. in separate columns in the database


Downside: a lot of columns


2) Convert and store the number of seconds


We still want to be able to show seperate fields for hour, minute, second, etc. in the form. We could write virtual attribute for each of these and write a before_save callback that converts the timespan to seconds (still messy tho).


Am I missing some other obvious solution? How do you people do this?
","I vote for a single column to keep track of durations.  That keeps the duration normalized, whereas you'll need to do almost as much work or more to normalize multi-column durations.

Rails (activesupport) also gives you wonderful methods to work with time.  For example, if your duration is in seconds, you can easily add the duration in seconds to a point in time and get an end time:


  end_time = Time.now + duration_in_secs


It is a bit more work using virtual attributes to separate it out, but in my experience, it's not that more work.  perhaps there is a plugin or gem that simplifies it.
"
1069,1069,1687,Bash script- Create usernames and passwords from txt file and store in group?,"This script takes a .txt file with four columns- which contains LastName FirstName MiddleInitial Group-as an argument and needs to create a unique username and password for each person; and then assign each user the appropriate directory depending on their group: i.e. If ""John Doe"" is in ""mgmt"" group, and his username is jdoe1234, then his directory would be /home/mgmt/jdoe1234. It should then generate a .txt file which contains the following columns- LastName FirstName UID(userid) Password- .

I have the following:

#!/bin/bash
IFS=$'\n';
for i in `cat $1`;
do
    last=`echo $i|cut -f 1 -d ' '`;
    first=`echo $i|cut -f 2 -d ' '`;
    middle=`echo $i|cut -f 3 -d ' '`;
    groups=`echo $i|cut -f 4 -d ' '`;
    r=$(( $RANDOM % 10 ));
    s=$(( $RANDOM % 10 ));
    y=$(( $RANDOM % 10 ));
    username=`echo $first| head -c 1 &amp;&amp; echo $last| head -c 3 &amp;&amp; echo $r$s$y`
    echo $username
done
#check if group exists, if not then create one
for group in ${groups[*]}
do
    grep -q ""^$group"" /etc/group ; let x=$?
    if [ $x -eq 1 ]
    then
            groupadd ""$group""
    fi
done

#try to add user to correct group
x=0
created=0
for user in ${username[*]}
do
    useradd -n -g ""{groups[$x]}"" -m $user 2&gt; /dev/null
done


I want the username to contain: 1st letter of firstName, first 3 letters of the lastName, the middle initial, and then 3 randomly generated numbers. So not exactly the same as the above example with John Doe but similar. It can't be any more than 8 characters. I'm not sure if I'm creating the usernames properly.

Of course, I'm having trouble with the password too; not sure if it needs to be created alongside the username or after.

After the first 'for loop' I first try to add a group if it doesn't already exist, and then I make an attempt at putting the usernames into the correct groups. I got the syntax off a Youtube video but he was working with it as arrays and I'm not sure if I'm doing that or not.

If it helps, let's say the .txt file contains:

doe john a mgmt
lee amy f temp
smith tracy s empl


If you have time, any help at all would be appreciated. Thank you.
",Jay,https://stackoverflow.com/users/4164304,"Your syntax is rather clunky, I'm afraid.  Refactoring to avoid dozens of superfluous external processes should also make the script more readable and maintainable, although you need to understand the new constructs.

Instead of doing a for loop over the output of cat, the usual idiom to read a file line by line is to use while read ...; do ...; done &lt;file and this also buys you the significant simplification that read will split the input into tokens for you.

Instead of calling $RANDOM three times, it would seem a lot more straightforward to call it once with a modulo of 1000 and add leading zeros if necessary.

And no, your arrays were not working right, but you don't even really need arrays here -- just do the stuff you want to do inside the main loop for each user.

As ever, you should properly quote every string unless you specifically require the shell to perform wildcard expansion and token splitting on the value.

I also took the liberty to fix the grep; if [ $? = 1 ]; then...  to just if ! grep; then... which is both simpler and more idiomatic, as well as more readable.  But then we should not use grep for examining passwords, so I replaced that with getent instead.  The construct getent || groupadd is basically shorthand for if ! getent; then groupadd; fi.

You were redirecting standard error from useradd to /dev/null but I took that away -- if there is a failure, you need to see the error message; otherwise you could spend hours debugging an error which would be obvious if you knew what's wrong.  (We see that here on StackOverflow a lot more than we should.)

One last note -- Bash has a simple built-in syntax for substring extraction; ${string:0:3} extracts a substring of length 3 at offset 0.  Similarly, ${string//foo/bar} returns the value of string with all occurrences of foo replaced with bar.

#!/bin/bash
while read last first middle groups; do
    rsy=$(prinf '%03i' $(($RANDOM % 1000)))
    username=""${first:0:1}${last:0:3}$middle$rsy""
    echo ""$username""
    for group in $groups; do
      getent group ""$group"" &gt;/dev/null || groupadd ""$group""
    done
    password=$(LC_ALL=C tr -dc '!-~' &lt;/dev/urandom | head -c 14)
    enc=$(openssl passwd -1 ""$password"")
    useradd -n -G ""${groups// /,}"" -m ""$username"" -p ""$enc"" -d ""/home/${groups%% *}/$username"" #2&gt; /dev/null
    # Print generated user's first, last, UID, and password
    echo ""$first $last $(id -u ""$username"") $password""
done &lt;""$1""


I have not attempted to enhance the useradd command -- as noted in the answer by @asimovwasright you probably need to do additional things to perform this properly.  If you are on a Debian-based distro, you should look into adduser as a higher-level replacement which takes care of many of these chores for you.

The password creation is a bit of a crock.  I adapted one of the answers from How to automatically add user account AND password with a Bash script? but it's probably not optimal from either a usability or a security standpoint.  But then, you should really not create passwords anyway -- just create users without passwords, put their SSH public key in place, and let them log in that way.

(I used /dev/random at first but it was taking forever in my tests so I switched to /dev/urandom.  I'm hoping you are making your users change their password first thing when they log in, so this should be an acceptable compromise.)
",tripleee,https://stackoverflow.com/users/874188,http://stackoverflow.com/questions/28957168/bash-script-create-usernames-and-passwords-from-txt-file-and-store-in-group,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.4444444444444444,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,1.0,1.0,0.7777777777777778,1.0,1.0,0.9333333333333332,1.0,0.3333333333333333,0.6666666666666666,1.0,Bash script - create user name and password from TXT file and store in group?,"This script takes a .txt file with four columns- which contains LastName FirstName MiddleInitial Group-as an argument and needs to create a unique username and password for each person; and then assign each user the appropriate directory depending on their group: i.e. If ""John Doe"" is in ""mgmt"" group, and his username is jdoe1234, then his directory would be /home/mgmt/jdoe1234. It should then generate a .txt file which contains the following columns- LastName FirstName UID(userid) Password- .

I have the following:

#!/bin/bash
IFS=$'\n';
for i in `cat $1`;
do
    last=`echo $i|cut -f 1 -d ' '`;
    first=`echo $i|cut -f 2 -d ' '`;
    middle=`echo $i|cut -f 3 -d ' '`;
    groups=`echo $i|cut -f 4 -d ' '`;
    r=$(( $RANDOM % 10 ));
    s=$(( $RANDOM % 10 ));
    y=$(( $RANDOM % 10 ));
    username=`echo $first| head -c 1 &amp;&amp; echo $last| head -c 3 &amp;&amp; echo $r$s$y`
    echo $username
done
#check if group exists, if not then create one
for group in ${groups[*]}
do
    grep -q ""^$group"" /etc/group ; let x=$?
    if [ $x -eq 1 ]
    then
            groupadd ""$group""
    fi
done

#try to add user to correct group
x=0
created=0
for user in ${username[*]}
do
    useradd -n -g ""{groups[$x]}"" -m $user 2&gt; /dev/null
done


I want the username to contain: 1st letter of firstName, first 3 letters of the lastName, the middle initial, and then 3 randomly generated numbers. So not exactly the same as the above example with John Doe but similar. It can't be any more than 8 characters. I'm not sure if I'm creating the usernames properly.

Of course, I'm having trouble with the password too; not sure if it needs to be created alongside the username or after.

After the first 'for loop' I first try to add a group if it doesn't already exist, and then I make an attempt at putting the usernames into the correct groups. I got the syntax off a Youtube video but he was working with it as arrays and I'm not sure if I'm doing that or not.

If it helps, let's say the .txt file contains:

doe john a mgmt
lee amy f temp
smith tracy s empl


If you have time, any help at all would be appreciated. Thank you.
","Your syntax is rather clunky, I'm afraid.  Refactoring to avoid dozens of superfluous external processes should also make the script more readable and maintainable, although you need to understand the new constructs.

Instead of doing a for loop over the output of cat, the usual idiom to read a file line by line is to use while read ...; do ...; done &lt;file and this also buys you the significant simplification that read will split the input into tokens for you.

Instead of calling $RANDOM three times, it would seem a lot more straightforward to call it once with a modulo of 1000 and add leading zeros if necessary.

And no, your arrays were not working right, but you don't even really need arrays here -- just do the stuff you want to do inside the main loop for each user.

As ever, you should properly quote every string unless you specifically require the shell to perform wildcard expansion and token splitting on the value.

I also took the liberty to fix the grep; if [ $? = 1 ]; then...  to just if ! grep; then... which is both simpler and more idiomatic, as well as more readable.  But then we should not use grep for examining passwords, so I replaced that with getent instead.  The construct getent || groupadd is basically shorthand for if ! getent; then groupadd; fi.

You were redirecting standard error from useradd to /dev/null but I took that away -- if there is a failure, you need to see the error message; otherwise you could spend hours debugging an error which would be obvious if you knew what's wrong.  (We see that here on StackOverflow a lot more than we should.)

One last note -- Bash has a simple built-in syntax for substring extraction; ${string:0:3} extracts a substring of length 3 at offset 0.  Similarly, ${string//foo/bar} returns the value of string with all occurrences of foo replaced with bar.

#!/bin/bash
while read last first middle groups; do
    rsy=$(prinf '%03i' $(($RANDOM % 1000)))
    username=""${first:0:1}${last:0:3}$middle$rsy""
    echo ""$username""
    for group in $groups; do
      getent group ""$group"" &gt;/dev/null || groupadd ""$group""
    done
    password=$(LC_ALL=C tr -dc '!-~' &lt;/dev/urandom | head -c 14)
    enc=$(openssl passwd -1 ""$password"")
    useradd -n -G ""${groups// /,}"" -m ""$username"" -p ""$enc"" -d ""/home/${groups%% *}/$username"" #2&gt; /dev/null
    # Print generated user's first, last, UID, and password
    echo ""$first $last $(id -u ""$username"") $password""
done &lt;""$1""


I have not attempted to enhance the useradd command -- as noted in the answer by @asimovwasright you probably need to do additional things to perform this properly.  If you are on a Debian-based distro, you should look into adduser as a higher-level replacement which takes care of many of these chores for you.

The password creation is a bit of a crock.  I adapted one of the answers from How to automatically add user account AND password with a Bash script? but it's probably not optimal from either a usability or a security standpoint.  But then, you should really not create passwords anyway -- just create users without passwords, put their SSH public key in place, and let them log in that way.

(I used /dev/random at first but it was taking forever in my tests so I switched to /dev/urandom.  I'm hoping you are making your users change their password first thing when they log in, so this should be an acceptable compromise.)
"
1219,1219,1914,Keeping values in textboxes permanently until changed by user in a sharepoint webpart,"I am working on a Visual Web Part for a SharePoint 2013 site that is a ""scoreboard"" for people to track progress on a project. Basically what I have is a lot of textboxes that users will enter values in. I want the values to stay in the textbox until someone changes it.

&lt;tr&gt;
    &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;td&gt;A-Crew&lt;/td&gt;
    &lt;td&gt;B-Crew&lt;/td&gt;
    &lt;td&gt;C-Crew&lt;/td&gt;
    &lt;td&gt;D-Crew&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
    &lt;td&gt;Daily&lt;/td&gt;
    &lt;td&gt;
        &lt;input id=""msaCrewDaily"" type=""text"" /&gt;
    &lt;/td&gt;
    &lt;td&gt;
        &lt;input id=""msbCrewDaily"" type=""text"" /&gt;
    &lt;/td&gt;
    &lt;td&gt;
        &lt;input id=""mscCrewDaily"" type=""text"" /&gt;
    &lt;/td&gt;
    &lt;td&gt;
        &lt;input id=""msdCrewDaily"" type=""text"" /&gt;
    &lt;/td&gt;
&lt;/tr&gt;


A few things I have tried are using PHP inside the input tag to save the value but it doesn't keep it after closing and re-opening the page with webpart on it. I've thought about using local storage but i'm not sure if that will work. 

My Question

Is there a way to keep the the input even if the page is closed? If not would it be better to set up a list as a Data Source? Is the something I could do in C# to keep the values?

Other Information

This is a temporary solution until a database is set up then the values will come from there. However its going to take some time to set that up. Also as of now all my code is HTML and CSS. Any help or ideas are very much appreciated and thank you in advanced!!!
",egalyk,https://stackoverflow.com/users/3864499,"You can use local storage ""jStorage"" write a javascript which will be called onkey of textbox and store value on local storage and call it on page load. Just check on page load if local storage contains any value if yes then set the textbox with that value
",Parag Ghogal,https://stackoverflow.com/users/1890798,http://stackoverflow.com/questions/24997100/keeping-values-in-textboxes-permanently-until-changed-by-user-in-a-sharepoint-we,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.5555555555555556,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.7333333333333333,1.0,0.0,0.0,0.8888888888888888,Leave the value permanently in the text box until the user changes the SharePoint web part,"I am working on a Visual Web Part for a SharePoint 2013 site that is a ""scoreboard"" for people to track progress on a project. Basically what I have is a lot of textboxes that users will enter values in. I want the values to stay in the textbox until someone changes it.

&lt;tr&gt;
    &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;td&gt;A-Crew&lt;/td&gt;
    &lt;td&gt;B-Crew&lt;/td&gt;
    &lt;td&gt;C-Crew&lt;/td&gt;
    &lt;td&gt;D-Crew&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
    &lt;td&gt;Daily&lt;/td&gt;
    &lt;td&gt;
        &lt;input id=""msaCrewDaily"" type=""text"" /&gt;
    &lt;/td&gt;
    &lt;td&gt;
        &lt;input id=""msbCrewDaily"" type=""text"" /&gt;
    &lt;/td&gt;
    &lt;td&gt;
        &lt;input id=""mscCrewDaily"" type=""text"" /&gt;
    &lt;/td&gt;
    &lt;td&gt;
        &lt;input id=""msdCrewDaily"" type=""text"" /&gt;
    &lt;/td&gt;
&lt;/tr&gt;


A few things I have tried are using PHP inside the input tag to save the value but it doesn't keep it after closing and re-opening the page with webpart on it. I've thought about using local storage but i'm not sure if that will work. 

My Question

Is there a way to keep the the input even if the page is closed? If not would it be better to set up a list as a Data Source? Is the something I could do in C# to keep the values?

Other Information

This is a temporary solution until a database is set up then the values will come from there. However its going to take some time to set that up. Also as of now all my code is HTML and CSS. Any help or ideas are very much appreciated and thank you in advanced!!!
","You can use local storage ""jStorage"" write a javascript which will be called onkey of textbox and store value on local storage and call it on page load. Just check on page load if local storage contains any value if yes then set the textbox with that value
"
5421,5421,8607,Double urn probability and multiple instances,"I've got a probability problem based on the following problem.
I provided some scenarios which I need to solve but I'm thankful for any hints or links on how to solve just one of them or how to described this scenario (and/or solutions) in proper 'mathematical notaion'

The Problem:
An urn contains 10 balls numbered from 1 to 10, every number occurs excactly once.
Person A picks balls from the urne and distributes the balls randomly among 4 other persons, say persons B, C, D and E (it is not neccessary for every person to get the same amount of balls). 
After the distribution process, person C picks $N$ ball(s) from its own urn, which holds another 10 balls, again numbered from 1 to 10.
What is the probability that person C received one or more balls from person A which have the same number as the ball(s) person C just picked from its own urn?

Some scenarios:
Scenario 1: Person C received one ball with nr.7. What is the probability that person C picks the ball with the same number (7) from its own urn?
Scenario 2: Person C received two balls with nr.7 and nr.8. What is the probability that person C picks the same two balls (7 and 8) from its own urn?
Scenario 3: Person C received two balls with nr.7 and nr.8. What is the probability that person C picks one ball from its own urn which number is either 7 or 8?
Scenario 4: Person C received one ball with nr.7. What is the probability that person C picks two balls of its own urn out of which one is ball nr.7?
Scenario 5: Person C received one ball with nr.7 and person D received three other balls, say balls 4, 5 and 6. What is the probability that person C picks one ball from its own urn which number is either 4, 5, 6 or 7? (Person C and person D are merged, they count as one)
",froua,https://math.stackexchange.com/users/230518,"For the general question, assuming picks are without replacement:


for each numbered ball picked by C from their own urn, the probability C did not get that numbered ball from A is $\displaystyle \frac34$ (i.e. it went to B, D or E), 
so the probability of no matches is $\displaystyle \left(\frac34\right)^N$, 
the probability of at least one match is $\displaystyle 1-\left(\frac34\right)^N$ and 
the probability of $n$ matches is $\displaystyle {N \choose n}\frac{3^{N-n}}{4^N}$. 


For the scenarios the numbered balls received by C from A are determined by the scenario, so:


if C picks one from ten balls, the probability it is number $7$ is $\dfrac{1}{10}$
if C picks two from ten balls, the probability they are numbers $7$  and $8$ is $\dfrac{1}{45}$
if C picks two from ten balls, the probability exactly one is number $7$  or $8$ is $\dfrac{16}{45}$, and the probability at least one is number $7$  or $8$ is $\dfrac{17}{45}$ 
if C picks two from ten balls, the probability one is number $7$ is $\dfrac{1}{5}$ 
if C picks one from ten balls, the probability it is numbers $4$, $5$, $6$ or $7$ is $\dfrac{2}{5}$

",Henry,https://math.stackexchange.com/users/6460,http://math.stackexchange.com/questions/1230002/double-urn-probability-and-multiple-instances,SCIENCE,math.stackexchange.com,1.0,0.3333333333333333,0.0,1.0,1.0,1.0,0.5555555555555556,0.4444444444444444,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.0,0.3333333333333333,1.0,0.6666666666666666,1.0,1.0,1.0,0.3333333333333333,0.0,0.6666666666666666,0.8888888888888888,Double urn probability and multiple instances,"I've got a probability problem based on the following problem.
I provided some scenarios which I need to solve but I'm thankful for any hints or links on how to solve just one of them or how to described this scenario (and/or solutions) in proper 'mathematical notaion'

The Problem:
An urn contains 10 balls numbered from 1 to 10, every number occurs excactly once.
Person A picks balls from the urne and distributes the balls randomly among 4 other persons, say persons B, C, D and E (it is not neccessary for every person to get the same amount of balls). 
After the distribution process, person C picks $N$ ball(s) from its own urn, which holds another 10 balls, again numbered from 1 to 10.
What is the probability that person C received one or more balls from person A which have the same number as the ball(s) person C just picked from its own urn?

Some scenarios:
Scenario 1: Person C received one ball with nr.7. What is the probability that person C picks the ball with the same number (7) from its own urn?
Scenario 2: Person C received two balls with nr.7 and nr.8. What is the probability that person C picks the same two balls (7 and 8) from its own urn?
Scenario 3: Person C received two balls with nr.7 and nr.8. What is the probability that person C picks one ball from its own urn which number is either 7 or 8?
Scenario 4: Person C received one ball with nr.7. What is the probability that person C picks two balls of its own urn out of which one is ball nr.7?
Scenario 5: Person C received one ball with nr.7 and person D received three other balls, say balls 4, 5 and 6. What is the probability that person C picks one ball from its own urn which number is either 4, 5, 6 or 7? (Person C and person D are merged, they count as one)
","For the general question, assuming picks are without replacement:


for each numbered ball picked by C from their own urn, the probability C did not get that numbered ball from A is $\displaystyle \frac34$ (i.e. it went to B, D or E), 
so the probability of no matches is $\displaystyle \left(\frac34\right)^N$, 
the probability of at least one match is $\displaystyle 1-\left(\frac34\right)^N$ and 
the probability of $n$ matches is $\displaystyle {N \choose n}\frac{3^{N-n}}{4^N}$. 


For the scenarios the numbered balls received by C from A are determined by the scenario, so:


if C picks one from ten balls, the probability it is number $7$ is $\dfrac{1}{10}$
if C picks two from ten balls, the probability they are numbers $7$  and $8$ is $\dfrac{1}{45}$
if C picks two from ten balls, the probability exactly one is number $7$  or $8$ is $\dfrac{16}{45}$, and the probability at least one is number $7$  or $8$ is $\dfrac{17}{45}$ 
if C picks two from ten balls, the probability one is number $7$ is $\dfrac{1}{5}$ 
if C picks one from ten balls, the probability it is numbers $4$, $5$, $6$ or $7$ is $\dfrac{2}{5}$

"
4038,4038,6448,"Polite alternatives to ""as soon as possible""","I’ve found myself writing the phrase “as soon as possible” just too often. Sometimes I wonder if it sounds a little rude. How can I convey the same meaning in a more polite way but without losing sense of urgency?
",Albertus,https://english.stackexchange.com/users/20545,"I often need to ask for things to be returned to me. In a business setting, I have found that giving people a specific date (and sometimes a specific time) helps them. I always follow up with something like, ""If you feel you need more time than that, please let me know."" or ""If this deadline is not feasible, please let me know."" Adding that sentence shows the recipient that you are sensitive to his or her schedule. Giving a firm date helps the recipient be cognizant of your schedule.

I have found writing, ""when you get a chance"" or ""as soon as possible"" leaves it too much up in the air. And, as the saying goes, if it weren't for the last minute, nothing would ever get done. Your items of business will be pushed back in the recipient's schedule and then you find yourself trying to find a polite way to write, ""where's my stuff!?!""
",JLG,https://english.stackexchange.com/users/18655,http://english.stackexchange.com/questions/69101/polite-alternatives-to-as-soon-as-possible,CULTURE,english.stackexchange.com,1.0,1.0,0.0,1.0,0.0,0.0,0.7777777777777778,0.7777777777777778,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,0.0,1.0,"Politely choose ""as soon as possible""","I find myself writing the word ""as soon as possible"". Sometimes I wonder if it sounds rude. How can I express the same meaning more politely without losing my sense of urgency?","I often need to ask for things to be returned to me. In a business setting, I have found that giving people a specific date (and sometimes a specific time) helps them. I always follow up with something like, ""If you feel you need more time than that, please let me know."" or ""If this deadline is not feasible, please let me know."" Adding that sentence shows the recipient that you are sensitive to his or her schedule. Giving a firm date helps the recipient be cognizant of your schedule.

I have found writing, ""when you get a chance"" or ""as soon as possible"" leaves it too much up in the air. And, as the saying goes, if it weren't for the last minute, nothing would ever get done. Your items of business will be pushed back in the recipient's schedule and then you find yourself trying to find a polite way to write, ""where's my stuff!?!""
"
424,424,658,Get MS SQL Server to release disk space,"A poorly managed database table has grown to be enormous. 48+gigs of orphan records. I am trying to clean it up and put my dangerously full hard drive back to a normal state. I will be deleting approx 400 million records from this table. This is running as I type. I notice that I am not seeing any drop in my hard drive space but I am seeing the memory drop on system table queries, I am running to get table size. The database is using ""Simple Recovery Model"".

There are many questions similar to this with responses saying you need to shrink the database. But they go on to explain how bad/scary this is to do because of fragmented data etc. 


Since the database should not be this size. Is it still bad for me to shrink it?
This is a production database. If I shrink it will it cause downtime or lock the database?
In SQL Server Management Studio you have two options for shrink, database or files. Given my situation what would be the best option?
is there a rule on the percentage of free space a DB should have?


Even reading the tag description of shrink makes me not want to do it. Is there another way?
",jackncoke,https://dba.stackexchange.com/users/66232,"It's ok for you to shrink it enough to ensure your server won't crash in the amount of time it takes you to assess your storage needs and plan hardware / hosting services appropriately (see question 4). No it won't lock it. See restrictions. Shrink the database because it keeps things simple.

I suggest contracting the expertise to conduct the study and write up the plan.
",user41207,https://dba.stackexchange.com/users/41207,http://dba.stackexchange.com/questions/101211/get-ms-sql-server-to-release-disk-space,TECHNOLOGY,dba.stackexchange.com,1.0,0.3333333333333333,0.3333333333333333,0.0,1.0,0.5,0.5555555555555556,0.4444444444444444,1.0,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.0,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.6666666666666666,0.0,1.0,0.7777777777777778,Get MS SQL server to free disk space,"A poorly managed database table has grown to be enormous. 48+gigs of orphan records. I am trying to clean it up and put my dangerously full hard drive back to a normal state. I will be deleting approx 400 million records from this table. This is running as I type. I notice that I am not seeing any drop in my hard drive space but I am seeing the memory drop on system table queries, I am running to get table size. The database is using ""Simple Recovery Model"".

There are many questions similar to this with responses saying you need to shrink the database. But they go on to explain how bad/scary this is to do because of fragmented data etc. 


Since the database should not be this size. Is it still bad for me to shrink it?
This is a production database. If I shrink it will it cause downtime or lock the database?
In SQL Server Management Studio you have two options for shrink, database or files. Given my situation what would be the best option?
is there a rule on the percentage of free space a DB should have?


Even reading the tag description of shrink makes me not want to do it. Is there another way?
","You can narrow it down enough to ensure that the server does not crash in the time required to assess storage requirements and properly plan hardware / host services (see question 4). No, it won't lock. See limits. Shrink the database because it keeps things simple."
6075,6075,9643,Adjustment to road bike brakes for high grade downhill,"I have a road bike with a front brake that wears a lot of brake pad when I ride downhill every day. I lose 900ft in elevation on steep grades with lots of stop signs and traffic lights. On top of that, it rains a decent amount and the rim brakes are terrible in that weather. I don't trust them downhill in the rain. Sometimes I just walk.

I feather the brakes going downhill, because otherwise I'm too fast to stop quickly for an errant car.

It'd be nice to not constantly replace pads, and have powerful stopping. How can I make this constant downhill more pleasant?

Thanks. 
",ash,https://bicycles.stackexchange.com/users/14519,"
You can replace the pads (as stated elsewhere).  There are a lot of variations in pad material, and a faster-wearing pad is not necessarily a better braking pad.  Unfortunately, it's hard to find a good selection of pads, and even harder to get good info on which is suitable to which conditions.
You can use your rear brake more, especially for speed control, and save the front for more ""serious"" efforts.  When I'm on a downhill (rarely as steep/long as yours, though) I like to alternate between front and rear brakes for speed control, and I do it more in bursts rather than with steady pressure.  I'm not sure if this is ""approved"" technique, but it's what makes sense to me.
You can install a second set of calipers.  This is often done on tandems, and can be done simply on some bikes/with great difficulty on others.  (Of course, you'd need to figure out how to operate the extra set, without growing a third hand, and you do have to worry a little about the rim overheating.)
You can get disk brakes (though from the war stories I hear here it's not clear that they are really any better in such a situation).

",Daniel R Hicks,https://bicycles.stackexchange.com/users/1584,http://bicycles.stackexchange.com/questions/25771/adjustment-to-road-bike-brakes-for-high-grade-downhill,CULTURE,bicycles.stackexchange.com,1.0,0.7777777777777778,0.0,1.0,0.6666666666666666,0.5,0.7777777777777778,0.7777777777777778,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.7777777777777778,0.8888888888888888,0.5555555555555556,1.0,1.0,0.7333333333333333,0.6666666666666666,0.3333333333333333,0.0,0.8888888888888888,Adjustment of bicycle brake on high grade downhill road,"I have a road bike with front brakes, which wear a lot of brake pads every day when I go down the hill. I lost 900 feet above sea level on a steep slope, where there were lots of stop signs and traffic lights. Besides, it rained well and the brakes were terrible in that weather. I don't believe they came down in the rain. Sometimes I just walk.","
You can replace the pads (as stated elsewhere).  There are a lot of variations in pad material, and a faster-wearing pad is not necessarily a better braking pad.  Unfortunately, it's hard to find a good selection of pads, and even harder to get good info on which is suitable to which conditions.
You can use your rear brake more, especially for speed control, and save the front for more ""serious"" efforts.  When I'm on a downhill (rarely as steep/long as yours, though) I like to alternate between front and rear brakes for speed control, and I do it more in bursts rather than with steady pressure.  I'm not sure if this is ""approved"" technique, but it's what makes sense to me.
You can install a second set of calipers.  This is often done on tandems, and can be done simply on some bikes/with great difficulty on others.  (Of course, you'd need to figure out how to operate the extra set, without growing a third hand, and you do have to worry a little about the rim overheating.)
You can get disk brakes (though from the war stories I hear here it's not clear that they are really any better in such a situation).

"
1776,1776,2819,How did the Female Titan cut Eren's titan form?,"After she killed the Levi squad, Eren transformed to fight the Female Titan. In Chapter 29, Hammer, it looked like Eren was having the upper hand, but then the Female Titan turned around, and with one horizontal motion, cut Eren's titan form's head in half.

How did that happen? That part wasn't clear in the anime nor the manga. Did she take a tree and smacked him? Did she harden her hand and hit him?


",Madara Uchiha,https://anime.stackexchange.com/users/27,"Warning This might contain spoilers. 

The move she used to finish Eren was a direct reference to a earlier scene in the anime (this has not been done in th manga as far as I know). At this point in time the viewer does not know Annie is the titan. The fight move used there resembles her fighting moves used during the training. this is one of the clue's beside the face resemblance of the titan to Annie. Some deeper information on this, the move she used is a karate move from the original Kata's. As stated in the video linked she has been trained in martial arts by her father.

",Dimitri mx,https://anime.stackexchange.com/users/1458,http://anime.stackexchange.com/questions/5197/how-did-the-female-titan-cut-erens-titan-form,CULTURE,anime.stackexchange.com,0.8888888888888888,0.6666666666666666,0.0,0.0,1.0,1.0,0.7777777777777778,0.5555555555555556,0.6666666666666666,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,1.0,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8,0.0,0.0,1.0,0.8888888888888888,How did Titan cut Ellen's Titan?,"After she killed Levi, Ellen turned to fight the Titans. In Chapter 29 of the hammer, it looks like Ellen has the upper hand, but then the Titan turns around and, in a horizontal motion, cuts Ellen's Titan shaped head in half.","Warning This might contain spoilers. 

The move she used to finish Eren was a direct reference to a earlier scene in the anime (this has not been done in th manga as far as I know). At this point in time the viewer does not know Annie is the titan. The fight move used there resembles her fighting moves used during the training. this is one of the clue's beside the face resemblance of the titan to Annie. Some deeper information on this, the move she used is a karate move from the original Kata's. As stated in the video linked she has been trained in martial arts by her father.

"
4310,4310,6867,Get phones on all members in a customer group,"I am working on a custom Magento extension.
I am working around the Adminhtml part and i've created a custom form there. 

Here is the form code:

&lt;?php

class VivasIndustries_SmsNotification_Block_Adminhtml_Sms_Sendmass_Edit_Form extends Mage_Adminhtml_Block_Widget_Form
    {

        public function _prepareLayout() 
           {
              $ExtensionPath = Mage::getModuleDir('js', 'VivasIndustries_SmsNotification'); 
              $head = $this-&gt;getLayout()-&gt;getBlock('head');
              $head-&gt;addJs('jquery.js');
              $head-&gt;addJs('vivas.js');

              return parent::_prepareLayout();
           }

        protected function _prepareForm()
            {
            $form = new Varien_Data_Form(array(
                                    'id' =&gt; 'edit_form',
                                    'action' =&gt; $this-&gt;getUrl('*/*/save', array('id' =&gt; $this-&gt;getRequest()-&gt;getParam('id'))),
                                    'method' =&gt; 'post',
                                 ));

                $fieldset = $form-&gt;addFieldset('edit_form', array('legend'=&gt;Mage::helper('smsnotification')-&gt;__('SMS Information')));

                $CustomerGroups = Mage::getResourceModel('customer/group_collection')-&gt;toOptionArray();

                $smsprice_value = Mage::getStoreConfig('vivas/smsprice/smsprice_value');
                $smsprice_tag = Mage::getStoreConfig('vivas/smsprice/smsprice_tag');

                $customerArray=array();
                foreach($CustomerGroups as $each){

                     $count=Mage::getResourceModel('customer/customer_collection')
                                -&gt;addAttributeToFilter('group_id',$each['value'])-&gt;getSize();
                $SMSPrice = $count * $smsprice_value;               
                     $customerArray[]=array('value'=&gt; $each['value'],'label'=&gt; $each['label'].' - ('.$count.' Members) - ('.$SMSPrice.' '.$smsprice_tag.')');

                }

                $CustomerGroups = array_merge(array('' =&gt; ''), $customerArray);

                $fieldset-&gt;addField('customergroups', 'select',
                        array(
                            'name'      =&gt; 'customergroups',
                            'label'     =&gt; Mage::helper('smsnotification')-&gt;__('Customer Group'),
                            'class'     =&gt; 'required-entry',
                            'after_element_html' =&gt; '&lt;br&gt;&lt;small&gt;If customer group is not selected the SMS will be sended&lt;br&gt; to all store members!&lt;/small&gt;',
                            'values'    =&gt; $CustomerGroups
                        )
                    );


                $fieldset-&gt;addField('smstext', 'textarea', array(
                          'label'     =&gt; Mage::helper('smsnotification')-&gt;__('SMS Text'),
                          'class'     =&gt; 'required-entry',
                          'required'  =&gt; true,
                          'name'      =&gt; 'smstext',
                          'onclick' =&gt; """",
                          'onkeyup' =&gt; ""CheckLetterSize(this)"",
                          'after_element_html' =&gt; '&lt;br&gt;&lt;b style=""color:brown;""&gt;&lt;span id=""charNum""&gt;&lt;/span&gt;&lt;span id=""charNum1""&gt;&lt;/span&gt;&lt;/b&gt;&lt;br&gt;&lt;small&gt;SMS text must &lt;b&gt;NOT&lt;/b&gt; be longer then 160 characters!&lt;/small&gt;',
                          'tabindex' =&gt; 1
                        ));






                if ( Mage::getSingleton('adminhtml/session')-&gt;getsmsnotificationData() )
                    {
                        $form-&gt;setValues(Mage::getSingleton('adminhtml/session')-&gt;getsmsnotificationData());
                        Mage::getSingleton('adminhtml/session')-&gt;setsmsnotificationData(null);
                    } elseif ( Mage::registry('smsnotification_data') ) {
                        $form-&gt;setValues(Mage::registry('smsnotification_data')-&gt;getData());
                    }
                // Add these two lines


                $form-&gt;setUseContainer(true);
                $this-&gt;setForm($form);

                ////

                return parent::_prepareForm();
            }
    }


Here is the code that i have in my save action:

$groupId = $this-&gt;getRequest()-&gt;getPost('customergroups', '');
if (!empty($groupId)) {
    //Get customers from a group
    $customers = Mage::getModel('customer/customer')
                        -&gt;getCollection()
                        -&gt;addAttributeToSelect('*')
                        -&gt;addFieldToFilter('group_id', $groupId);
} else {
    //Get all customers
    $customers = Mage::getModel('customer/customer')
                        -&gt;getCollection()
                        -&gt;addAttributeToSelect('*');
}


This code is supposed to give me the group id when i press the submit button. 
But i have to get all the phones of these members in array like that:

$phones = array($phone);


How can i get all the phone numbers and make them in array?
",Tony Stark,https://magento.stackexchange.com/users/15344,"The easiest way (just example):

$phones = array();
foreach($customers as $customer)
{
    if($customer-&gt;getPhone())
        $phones[] = $customer-&gt;getPhone();
}


Because collection is object with objects (function _getItems() return array of objects, if i remember right).
",Bruce Tucker,https://magento.stackexchange.com/users/26855,http://magento.stackexchange.com/questions/70040/get-phones-on-all-members-in-a-customer-group,TECHNOLOGY,magento.stackexchange.com,0.8888888888888888,0.6666666666666666,0.0,0.0,1.0,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.5555555555555556,0.7777777777777778,0.5555555555555556,0.8888888888888888,1.0,0.8,0.6666666666666666,0.3333333333333333,0.0,0.6666666666666666,Get calls for all members of the customer group,"I am working on a custom Magento extension.
I am working around the Adminhtml part and i've created a custom form there. 

Here is the form code:

&lt;?php

class VivasIndustries_SmsNotification_Block_Adminhtml_Sms_Sendmass_Edit_Form extends Mage_Adminhtml_Block_Widget_Form
    {

        public function _prepareLayout() 
           {
              $ExtensionPath = Mage::getModuleDir('js', 'VivasIndustries_SmsNotification'); 
              $head = $this-&gt;getLayout()-&gt;getBlock('head');
              $head-&gt;addJs('jquery.js');
              $head-&gt;addJs('vivas.js');

              return parent::_prepareLayout();
           }

        protected function _prepareForm()
            {
            $form = new Varien_Data_Form(array(
                                    'id' =&gt; 'edit_form',
                                    'action' =&gt; $this-&gt;getUrl('*/*/save', array('id' =&gt; $this-&gt;getRequest()-&gt;getParam('id'))),
                                    'method' =&gt; 'post',
                                 ));

                $fieldset = $form-&gt;addFieldset('edit_form', array('legend'=&gt;Mage::helper('smsnotification')-&gt;__('SMS Information')));

                $CustomerGroups = Mage::getResourceModel('customer/group_collection')-&gt;toOptionArray();

                $smsprice_value = Mage::getStoreConfig('vivas/smsprice/smsprice_value');
                $smsprice_tag = Mage::getStoreConfig('vivas/smsprice/smsprice_tag');

                $customerArray=array();
                foreach($CustomerGroups as $each){

                     $count=Mage::getResourceModel('customer/customer_collection')
                                -&gt;addAttributeToFilter('group_id',$each['value'])-&gt;getSize();
                $SMSPrice = $count * $smsprice_value;               
                     $customerArray[]=array('value'=&gt; $each['value'],'label'=&gt; $each['label'].' - ('.$count.' Members) - ('.$SMSPrice.' '.$smsprice_tag.')');

                }

                $CustomerGroups = array_merge(array('' =&gt; ''), $customerArray);

                $fieldset-&gt;addField('customergroups', 'select',
                        array(
                            'name'      =&gt; 'customergroups',
                            'label'     =&gt; Mage::helper('smsnotification')-&gt;__('Customer Group'),
                            'class'     =&gt; 'required-entry',
                            'after_element_html' =&gt; '&lt;br&gt;&lt;small&gt;If customer group is not selected the SMS will be sended&lt;br&gt; to all store members!&lt;/small&gt;',
                            'values'    =&gt; $CustomerGroups
                        )
                    );


                $fieldset-&gt;addField('smstext', 'textarea', array(
                          'label'     =&gt; Mage::helper('smsnotification')-&gt;__('SMS Text'),
                          'class'     =&gt; 'required-entry',
                          'required'  =&gt; true,
                          'name'      =&gt; 'smstext',
                          'onclick' =&gt; """",
                          'onkeyup' =&gt; ""CheckLetterSize(this)"",
                          'after_element_html' =&gt; '&lt;br&gt;&lt;b style=""color:brown;""&gt;&lt;span id=""charNum""&gt;&lt;/span&gt;&lt;span id=""charNum1""&gt;&lt;/span&gt;&lt;/b&gt;&lt;br&gt;&lt;small&gt;SMS text must &lt;b&gt;NOT&lt;/b&gt; be longer then 160 characters!&lt;/small&gt;',
                          'tabindex' =&gt; 1
                        ));






                if ( Mage::getSingleton('adminhtml/session')-&gt;getsmsnotificationData() )
                    {
                        $form-&gt;setValues(Mage::getSingleton('adminhtml/session')-&gt;getsmsnotificationData());
                        Mage::getSingleton('adminhtml/session')-&gt;setsmsnotificationData(null);
                    } elseif ( Mage::registry('smsnotification_data') ) {
                        $form-&gt;setValues(Mage::registry('smsnotification_data')-&gt;getData());
                    }
                // Add these two lines


                $form-&gt;setUseContainer(true);
                $this-&gt;setForm($form);

                ////

                return parent::_prepareForm();
            }
    }


Here is the code that i have in my save action:

$groupId = $this-&gt;getRequest()-&gt;getPost('customergroups', '');
if (!empty($groupId)) {
    //Get customers from a group
    $customers = Mage::getModel('customer/customer')
                        -&gt;getCollection()
                        -&gt;addAttributeToSelect('*')
                        -&gt;addFieldToFilter('group_id', $groupId);
} else {
    //Get all customers
    $customers = Mage::getModel('customer/customer')
                        -&gt;getCollection()
                        -&gt;addAttributeToSelect('*');
}


This code is supposed to give me the group id when i press the submit button. 
But i have to get all the phones of these members in array like that:

$phones = array($phone);


How can i get all the phone numbers and make them in array?
","The easiest way (just example):

$phones = array();
foreach($customers as $customer)
{
    if($customer-&gt;getPhone())
        $phones[] = $customer-&gt;getPhone();
}


Because collection is object with objects (function _getItems() return array of objects, if i remember right).
"
1011,1011,1596,"When we talk about an 88/76/etc Key piano, does that include all keys or just white notes?","I have an old cheap keyboard which spans 5 octaves plus one extra C, so it goes from C2-C7 (I think).

Does that make this a 41 (5 x 8 +1) key or a 61 (5 x 12 + 1) keyboard?

When we talk about a standard 88-key piano is that the total number of white and black notes, meaning it covers just over 7 octaves?

While I'm here, what are the standard keyboard configurations if any other than a traditional piano can be said to be standard?
",Mr. Boy,https://music.stackexchange.com/users/15313,"An 88 key piano will have a TOTAL of 88 keys. White keys + black keys = 88.
",Michal Paszkiewicz,https://music.stackexchange.com/users/15715,http://music.stackexchange.com/questions/26880/when-we-talk-about-an-88-76-etc-key-piano-does-that-include-all-keys-or-just-wh,LIFE_ARTS,music.stackexchange.com,1.0,0.5555555555555556,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.4444444444444444,1.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.8888888888888888,0.8888888888888888,0.4444444444444444,1.0,1.0,0.6,0.0,0.0,1.0,0.8888888888888888,"When we talk about the 88 / 76 / etc key piano, does it include all keys or just white notes?","I have an old cheap keyboard which spans 5 octaves plus one extra C, so it goes from C2-C7 (I think).

Does that make this a 41 (5 x 8 +1) key or a 61 (5 x 12 + 1) keyboard?

When we talk about a standard 88-key piano is that the total number of white and black notes, meaning it covers just over 7 octaves?

While I'm here, what are the standard keyboard configurations if any other than a traditional piano can be said to be standard?
","An 88 key piano will have a TOTAL of 88 keys. White keys + black keys = 88.
"
41,41,61,How does critical strike chance stack?,"I was wondering how critical strike chance stacks? Say I buy a Phanton Dancer with its 30% crit chance. Now if I buy another Phanton Dancer, what is my critical chance?
",BubBidderskins,https://gaming.stackexchange.com/users/22482,"they stack additively, so just add up the crit chance.  1 PD will increase your total crit chance by +30%.  The 2nd PD will increase your total crit chance by +30%, so +60% crit chance total from 2 PD's.
",Masck,https://gaming.stackexchange.com/users/23074,http://gaming.stackexchange.com/questions/60921/how-does-critical-strike-chance-stack,CULTURE,gaming.stackexchange.com,0.7777777777777778,0.5555555555555556,0.0,1.0,1.0,1.0,0.7777777777777778,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,1.0,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.8888888888888888,How to stack critical strike chance?,"I want to know what's the chance of a deadly strike? Suppose I bought a phantom dancer with a 30% critical hit rate. If I buy another Fenton dancer, what's my chance?","They're stacked together, so add up the critical chance. A little crit will increase your critical hit rate by 30%. The second inning will increase your total critical hit rate by + 30%, so + 60% critical hit rate will increase from 2 innings."
2794,2794,4453,Manually adding 's' to 'http',"I did a Wireshark capture of my login into a drupal-based website. The website does not use https. And so, quite obviously, I was able to capture my username and password in plain text by simply  using the http.request.method==POST filter in Wireshark. 

Then, I tried to access the same web page by manually adding a s to http in the url. Quite naturally, my browser showed this:



Then I went ahead and did my login again, and did the Wireshark capture again. 

To my surprise, I do not have the any captures corresponding to the http.request.method==POST filter. 

So, my questions:


When I am not really using https, why wasn't I able to capture login id and password in plain text?
What effect did manually adding s to http have?

",pnp,https://security.stackexchange.com/users/9778,"Despite what you may think, you actually were using HTTPS.  This is perhaps an over-simplification, but here's more or less what happened:

When you accessed the website with http:// as the protocol in your Address Bar, you effectively told your computer ""Make a request for this webpage, from this server, and send that request to port 80 on the server"".  If the server is configured to allow access via plain HTTP (apparently, it was), the server will respond and your session (unless re-directed) will continue over HTTP.

By changing the protocol to https://, you instead directed your computer to attempt an SSL/TLS handshake via port 443 on the server and then send the HTTP requests through that tunnel.  Obviously, this worked or you would not have been able to access the page.  Since the SSL/TLS connection was successful, that meant that all subsequent HTTP requests sent through that tunnel would be secured from casual eavesdropping (e.g.: via Wireshark).

But now, you ask, what about that nasty red slash through https, and the ""x"" on the lock?  These indicators do not mean that the SSL/TLS connection was unsuccessful, or that your communications to the website are not encrypted.  All these negative indicators mean is that the website is not signed by an authority your browser recognizes.  This is often the case for the web interfaces on SOHO networked equipment, business applications, or websites where the administrator has chosen to use a self-signed certificate instead of purchasing one from a well-recognized authority (e.g.: VeriSign).

This is analogous in some ways to selling alcohol in a jurisdiction where such sales are age-restricted.  Since I don't know all the intricacies of the real-world laws, let's say for the sake of argument that the law only goes so far as to say it is illegal to sell alcohol to a person who is younger than a given age.  What the law in this hypothetical case does not specify is whether you are required to check I.D. prior to a sale, or which forms of I.D. are considered to be valid proofs of age at time of sale.  Authoritative proof of the buyer's age is only ultimately required in court if the legality of the sale is ever challenged.  However, it is still of course a good idea to check I.D.s on every sale just to be safe.

Here, you are a clerk at a convenience store in the great state of Comodo.  Most of your customers will be fellow Comodoans, and so you are naturally able to easily recognize and verify their I.D.s which are issued by the Comodo Government.

One day though, you get a customer from the distant state of VeriSign.  What do you do now?  Fortunately, your store has a book called Trusted Root Certificates which has pictures and tips on how to verify I.D.s issued from various states in your country.  You check your book, compare the customer's I.D. to the relevant photograph and notes, and judge that the I.D. is indeed issued by an authority trusted by your store.  Given this, you can now trust that the information on the I.D. (particularly, stating the customers identity and age) is accurate, and therefore be comfortable in knowing that you are making a legal sale.

On another day, a customer comes in from overseas.  His name is Drupal, and he hails from the land of DigiNotar.  He says he is old enough to buy alcohol, and his DigiNotarian Government I.D. concurs with his statement.  However, your Trusted Root Certificates book does not have any information to help you verify an I.D. from his country.  What do you do here?

Strictly speaking, by the letter of the law in this hypothetical country, your sale would still be legal if your customer is in fact as old as he says he is.  You could choose to assume he is telling the truth and, if he actually is, go on with your life without ever being convicted of any crime related to that action.

But, without any documentation from an authority you recognize, you are still taking the risk that he is not telling the truth.  It's very possible that he is not of the proper age, despite what he and his I.D. may claim.  In this case, the sale will still be completed.  The product will still only be transferred between you and your customer (not immediately available to anyone else, unless your customer chooses to distribute it), but now the problem is that the alcohol has been given to someone who legally should not have it - and you could be in trouble for this.



TL;DR:  As long as your browser shows https:// as the protocol, you can be assured that the data in your communications are secured between your computer and some endpoint.  If there's any warning signs around that https:// area though, that means that the browser does not trust that endpoint to be what it claims to be.  It is then up to you to decide whether you trust the endpoint's claims to identity enough to transfer sensitive data over the connection.  The connection is still secure in the sense that nobody between you and the other end of the HTTPS connection can sniff the data, but you are taking the chance that the other end isn't what it claims to be.
",Iszi,https://security.stackexchange.com/users/953,http://security.stackexchange.com/questions/21509/manually-adding-s-to-http,TECHNOLOGY,security.stackexchange.com,1.0,0.3333333333333333,0.0,1.0,1.0,1.0,0.6666666666666666,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,1.0,1.0,1.0,1.0,0.0,0.0,1.0,1.0,"Manually add ""s"" to ""HTTP""","I did a Wireshark capture of my login into a drupal-based website. The website does not use https. And so, quite obviously, I was able to capture my username and password in plain text by simply  using the http.request.method==POST filter in Wireshark. 

Then, I tried to access the same web page by manually adding a s to http in the url. Quite naturally, my browser showed this:



Then I went ahead and did my login again, and did the Wireshark capture again. 

To my surprise, I do not have the any captures corresponding to the http.request.method==POST filter. 

So, my questions:


When I am not really using https, why wasn't I able to capture login id and password in plain text?
What effect did manually adding s to http have?

","Despite what you may think, you actually were using HTTPS.  This is perhaps an over-simplification, but here's more or less what happened:

When you accessed the website with http:// as the protocol in your Address Bar, you effectively told your computer ""Make a request for this webpage, from this server, and send that request to port 80 on the server"".  If the server is configured to allow access via plain HTTP (apparently, it was), the server will respond and your session (unless re-directed) will continue over HTTP.

By changing the protocol to https://, you instead directed your computer to attempt an SSL/TLS handshake via port 443 on the server and then send the HTTP requests through that tunnel.  Obviously, this worked or you would not have been able to access the page.  Since the SSL/TLS connection was successful, that meant that all subsequent HTTP requests sent through that tunnel would be secured from casual eavesdropping (e.g.: via Wireshark).

But now, you ask, what about that nasty red slash through https, and the ""x"" on the lock?  These indicators do not mean that the SSL/TLS connection was unsuccessful, or that your communications to the website are not encrypted.  All these negative indicators mean is that the website is not signed by an authority your browser recognizes.  This is often the case for the web interfaces on SOHO networked equipment, business applications, or websites where the administrator has chosen to use a self-signed certificate instead of purchasing one from a well-recognized authority (e.g.: VeriSign).

This is analogous in some ways to selling alcohol in a jurisdiction where such sales are age-restricted.  Since I don't know all the intricacies of the real-world laws, let's say for the sake of argument that the law only goes so far as to say it is illegal to sell alcohol to a person who is younger than a given age.  What the law in this hypothetical case does not specify is whether you are required to check I.D. prior to a sale, or which forms of I.D. are considered to be valid proofs of age at time of sale.  Authoritative proof of the buyer's age is only ultimately required in court if the legality of the sale is ever challenged.  However, it is still of course a good idea to check I.D.s on every sale just to be safe.

Here, you are a clerk at a convenience store in the great state of Comodo.  Most of your customers will be fellow Comodoans, and so you are naturally able to easily recognize and verify their I.D.s which are issued by the Comodo Government.

One day though, you get a customer from the distant state of VeriSign.  What do you do now?  Fortunately, your store has a book called Trusted Root Certificates which has pictures and tips on how to verify I.D.s issued from various states in your country.  You check your book, compare the customer's I.D. to the relevant photograph and notes, and judge that the I.D. is indeed issued by an authority trusted by your store.  Given this, you can now trust that the information on the I.D. (particularly, stating the customers identity and age) is accurate, and therefore be comfortable in knowing that you are making a legal sale.

On another day, a customer comes in from overseas.  His name is Drupal, and he hails from the land of DigiNotar.  He says he is old enough to buy alcohol, and his DigiNotarian Government I.D. concurs with his statement.  However, your Trusted Root Certificates book does not have any information to help you verify an I.D. from his country.  What do you do here?

Strictly speaking, by the letter of the law in this hypothetical country, your sale would still be legal if your customer is in fact as old as he says he is.  You could choose to assume he is telling the truth and, if he actually is, go on with your life without ever being convicted of any crime related to that action.

But, without any documentation from an authority you recognize, you are still taking the risk that he is not telling the truth.  It's very possible that he is not of the proper age, despite what he and his I.D. may claim.  In this case, the sale will still be completed.  The product will still only be transferred between you and your customer (not immediately available to anyone else, unless your customer chooses to distribute it), but now the problem is that the alcohol has been given to someone who legally should not have it - and you could be in trouble for this.



TL;DR:  As long as your browser shows https:// as the protocol, you can be assured that the data in your communications are secured between your computer and some endpoint.  If there's any warning signs around that https:// area though, that means that the browser does not trust that endpoint to be what it claims to be.  It is then up to you to decide whether you trust the endpoint's claims to identity enough to transfer sensitive data over the connection.  The connection is still secure in the sense that nobody between you and the other end of the HTTPS connection can sniff the data, but you are taking the chance that the other end isn't what it claims to be.
"
1361,1361,2142,How do I ward properly in DotA 2?,"I finally got my DotA 2 Beta invite. Now to learn the game I read it's a good start to play support heros (like I already loved to do in League of Legends). Even though I'm still pretty new to the game I suspect it's mostly the supports job to buy and set up wards.

I am therefore interested in learning how to ward effectively.


What are good/important spots for wards?
How do I time wards? When should I leave the lane?
And if there there different types of wards like in LoL: when to use which one?

",fschl,https://gaming.stackexchange.com/users/1400,"The linked guide that Arremer posted here is absolutely awesome, but it's probably a bit much for a very new player. When I teach new players I gave them 8 good ward spots to use- some more basic than others. I've circled them on the image linked: 




First, there are the two obvious ward spots near the runes. These are your default spots, and they're thus the most likely to be counterwarded. You should use others if you start getting counterwarded.
Next, there are the wards which block the pull camps. Blocking these should be done almost automatically in every game with the first set of wards bought. These are the circled spots in the image with the pink lines coming from them, which indicate the blocked camp. They can be a bit tricky to place, so try it out in a practice game.
Finally, there are 4 offensive ward spots. These are more situational in their use, but they're also the most important to allow you to take advantage of your team being ahead. If you don't ward offensively when you have a lead, you're inviting the other team back into the game. The yellow spots are the most well known, but the other two spots are nearly as good.


There is so much to warding that it's something you'll improve at for a very long time. For a complete new player, these are where I'd suggest starting.

So an overview: with your 2 wards at the start place one that's able to see a rune location, and one to block the pull camp. Try to do this right around 0:00, but not before, so that your mid hero is able to see where the 6:00 rune spawns. (Observer Wards last 6 minutes). This is pretty important. From there, keep wards up in the middle and maybe place aggressive wards if you know you can do so safely. Mostly you're concerned with keeping an eye on gank attempts and Roshan in the midgame. After you take T2 towers with your team, worry about getting offensive wards placed after you win teamfights. This will let you secure the game. Good support players are way more influential in Dota2 than they are in LoL, but it's still the same thankless role and much harder to accomplish.

I suggest you read my reply here too to know how to understand counterwarding, which is done with blue Sentry Wards (they last 3 minutes).

Good luck, any questions feel free to reply.
",Decency,https://gaming.stackexchange.com/users/11047,http://gaming.stackexchange.com/questions/77757/how-do-i-ward-properly-in-dota-2,CULTURE,gaming.stackexchange.com,0.7777777777777778,0.4444444444444444,0.3333333333333333,0.3333333333333333,1.0,0.3333333333333333,0.5555555555555556,0.3333333333333333,1.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.6666666666666666,0.6666666666666666,1.0,0.8888888888888888,How to protect correctly in dota 2?,"I finally got an invitation for a beta version of DOTA 2. Now to learn about this game, I read that it's a good start to play supporting Heroes (as I've loved legends in the League). Although I'm still unfamiliar with the game, I suspect it's mainly about buying and building ward support.","The linked guide that Arremer posted here is absolutely awesome, but it's probably a bit much for a very new player. When I teach new players I gave them 8 good ward spots to use- some more basic than others. I've circled them on the image linked: 




First, there are the two obvious ward spots near the runes. These are your default spots, and they're thus the most likely to be counterwarded. You should use others if you start getting counterwarded.
Next, there are the wards which block the pull camps. Blocking these should be done almost automatically in every game with the first set of wards bought. These are the circled spots in the image with the pink lines coming from them, which indicate the blocked camp. They can be a bit tricky to place, so try it out in a practice game.
Finally, there are 4 offensive ward spots. These are more situational in their use, but they're also the most important to allow you to take advantage of your team being ahead. If you don't ward offensively when you have a lead, you're inviting the other team back into the game. The yellow spots are the most well known, but the other two spots are nearly as good.


There is so much to warding that it's something you'll improve at for a very long time. For a complete new player, these are where I'd suggest starting.

So an overview: with your 2 wards at the start place one that's able to see a rune location, and one to block the pull camp. Try to do this right around 0:00, but not before, so that your mid hero is able to see where the 6:00 rune spawns. (Observer Wards last 6 minutes). This is pretty important. From there, keep wards up in the middle and maybe place aggressive wards if you know you can do so safely. Mostly you're concerned with keeping an eye on gank attempts and Roshan in the midgame. After you take T2 towers with your team, worry about getting offensive wards placed after you win teamfights. This will let you secure the game. Good support players are way more influential in Dota2 than they are in LoL, but it's still the same thankless role and much harder to accomplish.

I suggest you read my reply here too to know how to understand counterwarding, which is done with blue Sentry Wards (they last 3 minutes).

Good luck, any questions feel free to reply.
"
575,575,899,"When and why will an OS initialise memory to 0xCD, 0xDD, etc. on malloc/free/new/delete?","I know that the OS will sometimes initialise memory with certain patterns such as 0xCD and 0xDD.  What I want to know is when and why this happens.

When

Is this specific to the compiler used?

Do malloc/new and free/delete work in the same way with regard to this?

Is it platform specific?

Will it occur on other operating systems, such as Linux or VxWorks?

Why

My understanding is this only occurs in Win32 debug configuration, and it is used to detect memory overruns and to help the compiler catch exceptions.

Can you give any practical examples as to how this initialisation is useful?

I remember reading something (maybe in Code Complete 2) that it is good to initialise memory to a known pattern when allocating it, and certain patterns will trigger interrupts in Win32 which will result in exceptions showing in the debugger.

How portable is this?
",LeopardSkinPillBoxHat,https://stackoverflow.com/users/22489,"It's to easily see that memory has changed from its initial starting value, generally during debugging but sometimes for release code as well, since you can attach debuggers to the process while it's running.

It's not just memory either, many debuggers will set register contents to a sentinel value when the process starts (AIX sets its registers to 0xdeadbeef which is mildly humorous).
",paxdiablo,https://stackoverflow.com/users/14860,http://stackoverflow.com/questions/370195/when-and-why-will-an-os-initialise-memory-to-0xcd-0xdd-etc-on-malloc-free-new,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.3333333333333333,0.0,0.0,1.0,0.0,0.6666666666666666,1.0,1.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.6666666666666666,1.0,0.0,1.0,0.8888888888888888,0.3333333333333333,1.0,1.0,0.8666666666666666,0.0,0.0,1.0,0.8888888888888888,"When and why does the operating system initialize memory to 0xcd, 0xdd, etc. in malloc / free / new / delete?","I know that the OS will sometimes initialise memory with certain patterns such as 0xCD and 0xDD.  What I want to know is when and why this happens.

When

Is this specific to the compiler used?

Do malloc/new and free/delete work in the same way with regard to this?

Is it platform specific?

Will it occur on other operating systems, such as Linux or VxWorks?

Why

My understanding is this only occurs in Win32 debug configuration, and it is used to detect memory overruns and to help the compiler catch exceptions.

Can you give any practical examples as to how this initialisation is useful?

I remember reading something (maybe in Code Complete 2) that it is good to initialise memory to a known pattern when allocating it, and certain patterns will trigger interrupts in Win32 which will result in exceptions showing in the debugger.

How portable is this?
","It's to easily see that memory has changed from its initial starting value, generally during debugging but sometimes for release code as well, since you can attach debuggers to the process while it's running.

It's not just memory either, many debuggers will set register contents to a sentinel value when the process starts (AIX sets its registers to 0xdeadbeef which is mildly humorous).
"
429,429,664,Read Exif data from Image on WP,"How to read Exif data from Image.
There is ExifLib but have problem with Lumia device and Data taken field.
Are there any other way to read Exif data on Windows Phone (7./8).

Best regards
",Spaso Lazarevic,https://stackoverflow.com/users/1817664,"You should use ExifLib for that. Unfourtunately it takes a bit more work since it's not 100% adapted to WP. 

1) Download the ExifLib ZIP, unzip it, unblock the DLL (right click --> Properties --> Unblock) and add a reference to it from your project. I've hosted the ZIP on my server in the meanwhile @ http://JustinAngel.net/Storage/ExifLib.zip

2) Next you'll have to create an entry function which is usable from windows phone. Here's the one I use: 

public class ExifReaderEx : ExifReader
{
    protected ExifReaderEx(Stream stream)
        : base(stream)
    {
    }

    public static JpegInfo ReadJpeg(Picture picture)
    {
        Stream FileStream = null;
        try
        {
            FileStream = picture.GetImage();
        }
        catch
        {
            return null;
        }

        DateTime now = DateTime.Now;
        ExifReaderEx reader = new ExifReaderEx(FileStream);
        reader.info.FileSize = (int)FileStream.Length;
        reader.info.FileName = string.Format(""{0}.jpg"", ""fileName"");
        reader.info.LoadTime = (TimeSpan)(DateTime.Now - now);
        return reader.info;
    }
}


3) Invoke the code by calling ExifReaderEx.ReadJpeg(myPicture). For example the following code snippet will return a list of Exif items with all metadata:

            var items = 
                new MediaLibrary().Pictures
                    .Select(picture =&gt; ExifReaderEx.ReadJpeg(picture))
                    .Where(exif =&gt; exif != null)
                    .ToList();  

",JustinAngel,https://stackoverflow.com/users/81687,http://stackoverflow.com/questions/13722898/read-exif-data-from-image-on-wp,STACKOVERFLOW,stackoverflow.com,0.6666666666666666,1.0,0.0,1.0,1.0,1.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,0.8333333333333334,0.6666666666666666,0.8333333333333334,1.0,0.8,1.0,0.0,0.0,0.8333333333333334,Read EXIF data of image from WP,"How to read Exif data from Image.
There is ExifLib but have problem with Lumia device and Data taken field.
Are there any other way to read Exif data on Windows Phone (7./8).

Best regards
","You should use ExifLib for that. Unfourtunately it takes a bit more work since it's not 100% adapted to WP. 

1) Download the ExifLib ZIP, unzip it, unblock the DLL (right click --> Properties --> Unblock) and add a reference to it from your project. I've hosted the ZIP on my server in the meanwhile @ http://JustinAngel.net/Storage/ExifLib.zip

2) Next you'll have to create an entry function which is usable from windows phone. Here's the one I use: 

public class ExifReaderEx : ExifReader
{
    protected ExifReaderEx(Stream stream)
        : base(stream)
    {
    }

    public static JpegInfo ReadJpeg(Picture picture)
    {
        Stream FileStream = null;
        try
        {
            FileStream = picture.GetImage();
        }
        catch
        {
            return null;
        }

        DateTime now = DateTime.Now;
        ExifReaderEx reader = new ExifReaderEx(FileStream);
        reader.info.FileSize = (int)FileStream.Length;
        reader.info.FileName = string.Format(""{0}.jpg"", ""fileName"");
        reader.info.LoadTime = (TimeSpan)(DateTime.Now - now);
        return reader.info;
    }
}


3) Invoke the code by calling ExifReaderEx.ReadJpeg(myPicture). For example the following code snippet will return a list of Exif items with all metadata:

            var items = 
                new MediaLibrary().Pictures
                    .Select(picture =&gt; ExifReaderEx.ReadJpeg(picture))
                    .Where(exif =&gt; exif != null)
                    .ToList();  

"
389,389,611,Doctors working on Shabbat,"What are some general guidelines regarding the halakhic permissibility for Jewish doctors to work on Shabbat?  I know that saving lives generally overrides Shabbat, but I am curious about less black-and-white situations that may occur on Shabbat, such as having a shift where one must be in the hospital or be on call, receiving medical training, etc.  Also, in a practical halakhic sense, are there any situations in which the appropriateness of violating Shabbat would depend on whether the patients are Jewish?  I'm sure that these are not simple questions and that there are likely multiple opinions on various issues, but some insight into this topic would be welcome.
",Sam,https://judaism.stackexchange.com/users/9,"I'm sure there are several lectures on YUTorah.org about this; probably an article or two in Journal of Halacha &amp; Contemporary Society as well.  But in short:

""having a shift where one must be in the hospital or be on call"" -- we generally try to avoid putting ourselves into a situation in which a matter of life-or-death might occur which would necessitating violating Shabbat; this ""try to avoid"" can be balanced out by other considerations, though.  (That's one explanation given for why the Mishna prohibits getting on a ship too close to Shabbat -- a life-or-death situation may occur -- but if taking the trip is a mitzva, it's allowed.) 

""receiving medical training"" -- a tough issue, as usually the life-or-death situation must be fairly immediate, not ""oh this may allow me to save some life out there someplace, ten years from now.""  Nonetheless, I'm told that Rabbi Dovid Cohen of Brooklyn has allowed people to take residencies that may require working on Shabbat.  But check with your own rabbi.  

""are there any situations in which the appropriateness of violating Shabbat would depend on whether the patients are Jewish?"".  That's easy.  No.  The Halacha is that we violate Shabbat to save any human life; that's the Halacha, that's the practice, that's what we do.  
",Shalom,https://judaism.stackexchange.com/users/21,http://judaism.stackexchange.com/questions/315/doctors-working-on-shabbat,CULTURE,judaism.stackexchange.com,1.0,0.3333333333333333,0.6666666666666666,0.0,0.6666666666666666,0.3333333333333333,0.5555555555555556,0.4444444444444444,0.6666666666666666,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,1.0,Doctor studying Sabat,"What are the general guidelines for halakik's permission for Jewish doctors to work in Sabah? I know that saving lives usually trumps al Shabab, but I'm curious about the black and white situations that may arise in Al Shabab, such as having to change shifts in hospitals or places on call, receiving medical training, etc. Moreover, in the practical sense of harak, is there any case where the appropriateness of violating al Shabab will depend on whether the patient is Jewish or not? I believe these are not simple questions. There may be different opinions on different issues, but some opinions on this topic will be welcomed.","I'm sure there are several lectures on YUTorah.org about this; probably an article or two in Journal of Halacha &amp; Contemporary Society as well.  But in short:

""having a shift where one must be in the hospital or be on call"" -- we generally try to avoid putting ourselves into a situation in which a matter of life-or-death might occur which would necessitating violating Shabbat; this ""try to avoid"" can be balanced out by other considerations, though.  (That's one explanation given for why the Mishna prohibits getting on a ship too close to Shabbat -- a life-or-death situation may occur -- but if taking the trip is a mitzva, it's allowed.) 

""receiving medical training"" -- a tough issue, as usually the life-or-death situation must be fairly immediate, not ""oh this may allow me to save some life out there someplace, ten years from now.""  Nonetheless, I'm told that Rabbi Dovid Cohen of Brooklyn has allowed people to take residencies that may require working on Shabbat.  But check with your own rabbi.  

""are there any situations in which the appropriateness of violating Shabbat would depend on whether the patients are Jewish?"".  That's easy.  No.  The Halacha is that we violate Shabbat to save any human life; that's the Halacha, that's the practice, that's what we do.  
"
805,805,1275,What are good situations to use Multi-Flash / Repeating Flash feature?,"What can be done with the MULTI-Flash feature of a 580ex II flash?  What are good situations to use this feature?
",EtienneT,https://photo.stackexchange.com/users/6,"Stroboscopic flash (Multi mode on Canon, Repeating Flash on Nikon) fires several flashes within short time, by using shutter time long enough you can capture them all. You can calculate needed shutter time (in seconds) by dividing number of flashes by frequency in Herz. For example, 10 flashes at 5 Hz takes 2 seconds to fire.

Typical application is single-frame chronophotography - capturing several phases of movement on same photo. So a suitable situation is where some interesting movement occurs. If the subject stays in one place during its movement (e.g. a dancer spinning), you can slowly pan your camera instead to have different phases recorded on different locations in your frame.

A variation of this is capturing the same subject from several angles on single frame by moving your camera around it while the flash is strobing. The subject is still, but the camera is moving. So a suitable situation is when there are several views of the same subject you want to show simultaneously.

For these techniques, dark background and light-colored subject tend to give better results.

Another case would be when you want to imitate multiple flashes with one flash and you need constant frequency to form a pattern - when your flash is moving at constant speed this will give you flashes at equal distances:



If you don't need constant frequency, manually triggering the flash (e.g. with ""Test"" button) will give you more control over the outcome.
",Imre,https://photo.stackexchange.com/users/4390,http://photo.stackexchange.com/questions/16339/what-are-good-situations-to-use-multi-flash-repeating-flash-feature,LIFE_ARTS,photo.stackexchange.com,1.0,0.7777777777777778,0.0,0.0,1.0,0.6666666666666666,0.8888888888888888,0.6666666666666666,0.6666666666666666,0.0,0.6666666666666666,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.8888888888888888,1.0,0.7777777777777778,1.0,1.0,0.9333333333333332,0.3333333333333333,0.6666666666666666,0.6666666666666666,1.0,What is the best use of the multi flash / repeat flash feature?,What can the multi flash function of 580ex II flash memory do? What is the best way to use this feature?,"Stroboscopic flash (Multi mode on Canon, Repeating Flash on Nikon) fires several flashes within short time, by using shutter time long enough you can capture them all. You can calculate needed shutter time (in seconds) by dividing number of flashes by frequency in Herz. For example, 10 flashes at 5 Hz takes 2 seconds to fire.

Typical application is single-frame chronophotography - capturing several phases of movement on same photo. So a suitable situation is where some interesting movement occurs. If the subject stays in one place during its movement (e.g. a dancer spinning), you can slowly pan your camera instead to have different phases recorded on different locations in your frame.

A variation of this is capturing the same subject from several angles on single frame by moving your camera around it while the flash is strobing. The subject is still, but the camera is moving. So a suitable situation is when there are several views of the same subject you want to show simultaneously.

For these techniques, dark background and light-colored subject tend to give better results.

Another case would be when you want to imitate multiple flashes with one flash and you need constant frequency to form a pattern - when your flash is moving at constant speed this will give you flashes at equal distances:



If you don't need constant frequency, manually triggering the flash (e.g. with ""Test"" button) will give you more control over the outcome.
"
5363,5363,8514,When should a supervisor be a co-author?,"What are people's views on this?  To be specific: suppose a PhD student has produced a piece of original mathematical research. Suppose that student's supervisor suggested the problem, and gave a few helpful comments, but otherwise did not contribute to the work.  Should that supervisor still be named as a co-author, or would an acknowledgment suffice?

I am interested in two aspects of this. Firstly the moral/etiquette aspect: do you consider it bad form for a student not to name their supervisor?  Or does it depend on that supervisor's input?  And secondly, the practical, career-advancing aspect: which is better, for a student to have a well-known name on his or her paper (and hence more chance of it being noticed/published), or to have a sole-authored piece of work under their belt to hopefully increase their chances of being offered a good post-doc position?

[To clarify: original question asked by MrB ]
",MrB,https://mathoverflow.net/users/2189,"It really depends: I had two doctoral advisors, I wrote papers under the direction of both (separately):  my first supervisor did not have her name on the paper; one of the papers I worked on with my second supervisor is joint, another has just my name (and yet a third has both our names plus a co-author).

The details are boring and not very enlightening, so I won't go into them, but the important thing in that in every case, there was a different, rational and very good reason why the supervisor name did or did not appear. It had to do with the cultural differences between France and the US, publication medium, and how the work was conducted. 

In that respect, the etiquette question is similar as what happens when a colleague chats with you about your current research, or even better when they provide a crucial lemma or idea for your research. You should definitely acknowledge, but when do you offer co-author credit? In that case also, hierarchical considerations can easily come to the fore (if a person is clearly higher then the other in the pecking order, they can easily pass for a bully if they're not careful).

Even the area of math you work with is relevant (I've heard stories of people solving a problem in a group and the paper being published under a single name simply because the culture in that specific field does not give rise to many joint papers).
",Thierry Zell,https://mathoverflow.net/users/8212,http://mathoverflow.net/questions/57337,SCIENCE,mathoverflow.net,0.8888888888888888,0.4444444444444444,1.0,0.3333333333333333,0.0,0.0,0.7777777777777778,0.8888888888888888,1.0,0.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,1.0,0.5555555555555556,1.0,1.0,0.7333333333333333,0.0,0.0,1.0,1.0,When should a supervisor become a coauthor?,"What are people's views on this?  To be specific: suppose a PhD student has produced a piece of original mathematical research. Suppose that student's supervisor suggested the problem, and gave a few helpful comments, but otherwise did not contribute to the work.  Should that supervisor still be named as a co-author, or would an acknowledgment suffice?

I am interested in two aspects of this. Firstly the moral/etiquette aspect: do you consider it bad form for a student not to name their supervisor?  Or does it depend on that supervisor's input?  And secondly, the practical, career-advancing aspect: which is better, for a student to have a well-known name on his or her paper (and hence more chance of it being noticed/published), or to have a sole-authored piece of work under their belt to hopefully increase their chances of being offered a good post-doc position?

[To clarify: original question asked by MrB ]
","It really depends: I had two doctoral advisors, I wrote papers under the direction of both (separately):  my first supervisor did not have her name on the paper; one of the papers I worked on with my second supervisor is joint, another has just my name (and yet a third has both our names plus a co-author).

The details are boring and not very enlightening, so I won't go into them, but the important thing in that in every case, there was a different, rational and very good reason why the supervisor name did or did not appear. It had to do with the cultural differences between France and the US, publication medium, and how the work was conducted. 

In that respect, the etiquette question is similar as what happens when a colleague chats with you about your current research, or even better when they provide a crucial lemma or idea for your research. You should definitely acknowledge, but when do you offer co-author credit? In that case also, hierarchical considerations can easily come to the fore (if a person is clearly higher then the other in the pecking order, they can easily pass for a bully if they're not careful).

Even the area of math you work with is relevant (I've heard stories of people solving a problem in a group and the paper being published under a single name simply because the culture in that specific field does not give rise to many joint papers).
"
4216,4216,6721,Sort ListBox C#,"So I have a Class ""Video"" and The users enter the video name and rate different aspects of it using a numericupdown control. There is a button that the users click and the score for the video is calculated and the video, with it's score, and number ratings for each aspect, is added to a ListBox which just shows the name. So what I want to do, is have a button, that when clicked, sorts the list by checking the score each video got, sorting the list from highest score to lowest score. I am using visual studio 2010 and coding in C#.

Thanks in advance.
",cb1295,https://stackoverflow.com/users/815634,"videos = videos.OrderByDesc(x =&gt; x.Score).ToList();


Then set this sorted collection as datasource to ListBox.

Edit: to answer your question from comments.

You should separate presentation from data, ie have some data structures to hold data, not storing them in UI. So use for example:
List&lt;Video&gt; videos - this collection is filled from DB, XML, NetFlix webservice, whatever.

After filling this collection, bind it tu UI, in your case ListBox. Then, if you want to sort it, just use code i have posted.
",Tomas Voracek,https://stackoverflow.com/users/313199,http://stackoverflow.com/questions/6603556/sort-listbox-c-sharp,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.4444444444444444,0.0,1.0,1.0,1.0,0.6666666666666666,0.5555555555555556,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.3333333333333333,0.0,0.8888888888888888,Sort list box C#,"So I have a ""video"" class where the user enters the video name and uses the numericupdown control to rate different aspects of the video. There is a button that the user clicks, the score of the video is calculated, the score of the video, its score, and the digital rating of each aspect are added to a list box, displaying only the name. So what I want to do is have a button that, when clicked, sorts the list from the highest score to the lowest score by checking the scores for each video. I am using Visual Studio 2010 and writing code in C.","videos = videos.OrderByDesc(x =&gt; x.Score).ToList();


Then set this sorted collection as datasource to ListBox.

Edit: to answer your question from comments.

You should separate presentation from data, ie have some data structures to hold data, not storing them in UI. So use for example:
List&lt;Video&gt; videos - this collection is filled from DB, XML, NetFlix webservice, whatever.

After filling this collection, bind it tu UI, in your case ListBox. Then, if you want to sort it, just use code i have posted.
"
1617,1617,2537,two-way connection between SharePoint list and wiki page?,"I received an unusual request and I'm trying to figure out if it's possible:


store data in a custom list to be used for a report
output the formatted data to page 
let users edit the page
page must have ""track changes"" or ""page history"" functionality
(here's the kicker) edits made to the page should automatically appear in the list items


I think that I could write a custom program that would output the list data to a wiki page. However, if changes were made to the wiki page, they wouldn't be reflected in the original list.

Can this be done, and if so, how?
",LFurness,https://sharepoint.stackexchange.com/users/3021,"If the user really want to go this route.
You need to use an event receiver associated with the pages library.
On item updated you should parse the page html.

Another option is to edit wiki page layout and add a data sheet (but in this case the data will be tabular)
",Amal Hashim,https://sharepoint.stackexchange.com/users/34350,http://sharepoint.stackexchange.com/questions/120164/two-way-connection-between-sharepoint-list-and-wiki-page,TECHNOLOGY,sharepoint.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,0.8888888888888888,0.8,0.3333333333333333,0.6666666666666666,0.0,0.6666666666666666,A two-way connection between SharePoint lists and Wiki pages?,"I received an unusual request and I'm trying to figure out if it's possible:


store data in a custom list to be used for a report
output the formatted data to page 
let users edit the page
page must have ""track changes"" or ""page history"" functionality
(here's the kicker) edits made to the page should automatically appear in the list items


I think that I could write a custom program that would output the list data to a wiki page. However, if changes were made to the wiki page, they wouldn't be reflected in the original list.

Can this be done, and if so, how?
","If the user really want to go this route.
You need to use an event receiver associated with the pages library.
On item updated you should parse the page html.

Another option is to edit wiki page layout and add a data sheet (but in this case the data will be tabular)
"
1825,1825,2894,Moving a WP Multisite to a subdirectory,"Firstly, I've read a number of posts on this process. However, for various reasons, the process remains difficult to implement or troubleshoot for lack of even abstracted examples, or maybe too abstracted. And there's a few ""can not do"" posts, nearly always followed up by ""with 3.5, you now can"" caveats, so whether one can remains ambiguous, though no doubt non-trivial.

Summary:

How to move a wordpress multisite (WPMS) from root.com to root/blogs?

For this example, we're moving a WPMS from ""root.com"" to ""root.com/blogs""

I understand that I need to update the paths in the database and wp-config.php appropriately. It seems I may also have to update .htaccess? I'm also aware of the serialization issue with search/replace and mysql query updates.

I have a WPMS that I've updated to 3.5. I've found the following tables with domain and path info

Existing working configuration before move to subdirectory

1. wp_blogs

select blog_id, domain, path from wp_blogs;
+---------+-------------+--------+
| blog_id | domain      | path   |
+---------+-------------+--------+
|       1 | root.com    | /      |
|       2 | root.com    | /matt/ |
+---------+-------------+--------+


2. wp_site

select * in wp_site;
+----+-------------+------+
| id | domain      | path |
+----+-------------+------+
|  1 | root.com    | /    |
+----+-------------+------+


3. The blog_id corresponds to the wp_#_options tables which contain:

select option_name,option_value from wp_2_options 
where option_name = 'home' or option_name = 'siteurl';
+-------------+--------------------------+
| option_name | option_value             |
+-------------+--------------------------+
| home        | http://root.com/matt/    |
| siteurl     | http://root.com/matt/    |
+-------------+--------------------------+


4. In my wp-config.php I have the following WPMS-specific lines:

define('WP_ALLOW_MULTISITE', true);
define( 'MULTISITE', true );
define( 'SUBDOMAIN_INSTALL', false);
$base = '/';
define( 'DOMAIN_CURRENT_SITE', 'root.com' );
define( 'PATH_CURRENT_SITE', '/' );
define( 'SITE_ID_CURRENT_SITE', 1 );
define( 'BLOG_ID_CURRENT_SITE', 1 );


5. Lastly, in my .htaccess, I have:

RewriteEngine On
RewriteBase /
RewriteRule ^index\.php$ - [L]

# uploaded files
RewriteRule ^([_0-9a-zA-Z-]+/)?files/(.+) wp-includes/ms-files.php?file=$2 [L]

# add a trailing slash to /wp-admin
RewriteRule ^([_0-9a-zA-Z-]+/)?wp-admin$ $1wp-admin/ [R=301,L]

RewriteCond %{REQUEST_FILENAME} -f [OR]
RewriteCond %{REQUEST_FILENAME} -d
RewriteRule ^ - [L]
RewriteRule  ^[_0-9a-zA-Z-]+/(wp-(content|admin|includes).*) $1 [L]
RewriteRule  ^[_0-9a-zA-Z-]+/(.*\.php)$ $1 [L]
RewriteRule . index.php [L]


Updates required to move the site

It seems to me that in order to move my site to the /blogs , I would:

1. Update wp_blogs to

mysql&gt; update wp_blogs set domain=concat(domain, '/blogs'), path=concat(path, 'blogs/');
select blog_id, domain, path from wp_blogs where blog_id &lt; 3;
+---------+-------------+--------------+
| blog_id | domain      | path         |
+---------+-------------+--------------+
|       1 | root.com    | /blogs/      |
|       2 | root.com    | /blogs/matt/ |
+---------+-------------+--------------+


2. Update wp_site to

update wp_site set domain=concat(domain, '/blogs'), path=concat(path, 'blogs/');
select * from  wp_site;
+----+-------------+------------+
| id | domain      | path       |
+----+-------------+------------+
|  1 | root.com    | /blogs/    |
+----+-------------+------------+


3. wp_#_options

+-------------+--------------------------------+
| option_name | option_value                   |
+-------------+--------------------------------+
| home        | http://root.com/blogs/matt/    |
| siteurl     | http://root.com/blogs/matt/    |
+-------------+--------------------------------+


4. wp_config.php

define('WP_ALLOW_MULTISITE', true);
define( 'MULTISITE', true );
define( 'SUBDOMAIN_INSTALL', false);
$base = '/blogs/';
define( 'DOMAIN_CURRENT_SITE', 'root.com' );
define( 'PATH_CURRENT_SITE', '/blogs/' );
define( 'SITE_ID_CURRENT_SITE', 1 );
define( 'BLOG_ID_CURRENT_SITE', 1 );


note: I'm not clear how this step is appropriately updated

5. .htaccess

I found vague ""update .htaccess appropriately"" instructions, but not specifics. Update RewriteBase? Which lines in .htaccess to I update when I move root.com to root.com/blogs?

Missing from the above process will be the paths founds in posts. My druthers are to use the search and replace tool for that, after I've made this more fundamental updates; or am I wrong?

Update bungeshea suggests that, yes, I point RewriteBase to the ""blogs"" subdirectory, i.e.,

RewriteBase /Blogs


Finally, if you don't know about http://interconnectit.com/products/search-and-replace-for-wordpress-databases/ you should. It's excellent.
",Screenack,https://wordpress.stackexchange.com/users/18155,"It looks to me as if you've solved your own problem - just follow your steps 1-4, and for step 5 update the RewriteBase in .htaccess. For updating the paths in posts, I like using the Interconnect IT sterilized search-and-replace tool.
",shea,https://wordpress.stackexchange.com/users/19726,http://wordpress.stackexchange.com/questions/76913/moving-a-wp-multisite-to-a-subdirectory,TECHNOLOGY,wordpress.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,1.0,1.0,1.0,0.6666666666666666,0.6666666666666666,1.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.8888888888888888,Move WP multisite to subdirectory,"Firstly, I've read a number of posts on this process. However, for various reasons, the process remains difficult to implement or troubleshoot for lack of even abstracted examples, or maybe too abstracted. And there's a few ""can not do"" posts, nearly always followed up by ""with 3.5, you now can"" caveats, so whether one can remains ambiguous, though no doubt non-trivial.

Summary:

How to move a wordpress multisite (WPMS) from root.com to root/blogs?

For this example, we're moving a WPMS from ""root.com"" to ""root.com/blogs""

I understand that I need to update the paths in the database and wp-config.php appropriately. It seems I may also have to update .htaccess? I'm also aware of the serialization issue with search/replace and mysql query updates.

I have a WPMS that I've updated to 3.5. I've found the following tables with domain and path info

Existing working configuration before move to subdirectory

1. wp_blogs

select blog_id, domain, path from wp_blogs;
+---------+-------------+--------+
| blog_id | domain      | path   |
+---------+-------------+--------+
|       1 | root.com    | /      |
|       2 | root.com    | /matt/ |
+---------+-------------+--------+


2. wp_site

select * in wp_site;
+----+-------------+------+
| id | domain      | path |
+----+-------------+------+
|  1 | root.com    | /    |
+----+-------------+------+


3. The blog_id corresponds to the wp_#_options tables which contain:

select option_name,option_value from wp_2_options 
where option_name = 'home' or option_name = 'siteurl';
+-------------+--------------------------+
| option_name | option_value             |
+-------------+--------------------------+
| home        | http://root.com/matt/    |
| siteurl     | http://root.com/matt/    |
+-------------+--------------------------+


4. In my wp-config.php I have the following WPMS-specific lines:

define('WP_ALLOW_MULTISITE', true);
define( 'MULTISITE', true );
define( 'SUBDOMAIN_INSTALL', false);
$base = '/';
define( 'DOMAIN_CURRENT_SITE', 'root.com' );
define( 'PATH_CURRENT_SITE', '/' );
define( 'SITE_ID_CURRENT_SITE', 1 );
define( 'BLOG_ID_CURRENT_SITE', 1 );


5. Lastly, in my .htaccess, I have:

RewriteEngine On
RewriteBase /
RewriteRule ^index\.php$ - [L]

# uploaded files
RewriteRule ^([_0-9a-zA-Z-]+/)?files/(.+) wp-includes/ms-files.php?file=$2 [L]

# add a trailing slash to /wp-admin
RewriteRule ^([_0-9a-zA-Z-]+/)?wp-admin$ $1wp-admin/ [R=301,L]

RewriteCond %{REQUEST_FILENAME} -f [OR]
RewriteCond %{REQUEST_FILENAME} -d
RewriteRule ^ - [L]
RewriteRule  ^[_0-9a-zA-Z-]+/(wp-(content|admin|includes).*) $1 [L]
RewriteRule  ^[_0-9a-zA-Z-]+/(.*\.php)$ $1 [L]
RewriteRule . index.php [L]


Updates required to move the site

It seems to me that in order to move my site to the /blogs , I would:

1. Update wp_blogs to

mysql&gt; update wp_blogs set domain=concat(domain, '/blogs'), path=concat(path, 'blogs/');
select blog_id, domain, path from wp_blogs where blog_id &lt; 3;
+---------+-------------+--------------+
| blog_id | domain      | path         |
+---------+-------------+--------------+
|       1 | root.com    | /blogs/      |
|       2 | root.com    | /blogs/matt/ |
+---------+-------------+--------------+


2. Update wp_site to

update wp_site set domain=concat(domain, '/blogs'), path=concat(path, 'blogs/');
select * from  wp_site;
+----+-------------+------------+
| id | domain      | path       |
+----+-------------+------------+
|  1 | root.com    | /blogs/    |
+----+-------------+------------+


3. wp_#_options

+-------------+--------------------------------+
| option_name | option_value                   |
+-------------+--------------------------------+
| home        | http://root.com/blogs/matt/    |
| siteurl     | http://root.com/blogs/matt/    |
+-------------+--------------------------------+


4. wp_config.php

define('WP_ALLOW_MULTISITE', true);
define( 'MULTISITE', true );
define( 'SUBDOMAIN_INSTALL', false);
$base = '/blogs/';
define( 'DOMAIN_CURRENT_SITE', 'root.com' );
define( 'PATH_CURRENT_SITE', '/blogs/' );
define( 'SITE_ID_CURRENT_SITE', 1 );
define( 'BLOG_ID_CURRENT_SITE', 1 );


note: I'm not clear how this step is appropriately updated

5. .htaccess

I found vague ""update .htaccess appropriately"" instructions, but not specifics. Update RewriteBase? Which lines in .htaccess to I update when I move root.com to root.com/blogs?

Missing from the above process will be the paths founds in posts. My druthers are to use the search and replace tool for that, after I've made this more fundamental updates; or am I wrong?

Update bungeshea suggests that, yes, I point RewriteBase to the ""blogs"" subdirectory, i.e.,

RewriteBase /Blogs


Finally, if you don't know about http://interconnectit.com/products/search-and-replace-for-wordpress-databases/ you should. It's excellent.
","It looks to me as if you've solved your own problem - just follow your steps 1-4, and for step 5 update the RewriteBase in .htaccess. For updating the paths in posts, I like using the Interconnect IT sterilized search-and-replace tool.
"
4323,4323,6882,"Is ""learnable"" a valid English word?","In my thesis I am quoting a passage from a paper in which the author* used the word ""learnable"" in the sense of something that is easy to be learned.

I have searched for the word in both the Merriam-Webster and the Cambridge English online dictionaries, but didn't find it there. Nevertheless, this word seems to be used quite a lot in many scientific papers, it returns 775,000 results on Google and a lot of occurrences in Wikipedia.

So I ask: is this a valid word in English or, perhaps, just a neologism?

* he is from the University of South Florida and has a common American name - just in case somebody finds this relevant
",Luiz Vieira,https://ell.stackexchange.com/users/6766,"Learnable has been in use at least since the early 17th century.

By and large, when you find that an ordinary suffix has been attached to a word of the sort it is ordinarily attached to, and that the resulting sense is exactly that which such compounds ordinarily bear, it’s a legitimate word regardless of whether it appears in a dictionary. That’s what linguists mean when they say that a suffix or idiomatic pattern is ‘productive’: that it is regularly used to create valid new words or phrases. 

(And observe, please, that calling a term a neologism does not ‘invalidate’ it, whatever that might mean. To say a word is ‘valid’ can only mean that it is used and understood within its particular context or register, regardless of its age.)

In this case, -able is regularly attachable to any transitive VERB to express the meaning capable of being VERBed. Learn is a transitive verb, and learnable means capable of being learned. That’s all it takes.
",StoneyB,https://ell.stackexchange.com/users/32,http://ell.stackexchange.com/questions/24961/is-learnable-a-valid-english-word,CULTURE,ell.stackexchange.com,1.0,1.0,0.0,0.6666666666666666,1.0,1.0,0.5555555555555556,1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,0.8888888888888888,"Is ""learnable"" an effective English word?","In my thesis I am quoting a passage from a paper in which the author* used the word ""learnable"" in the sense of something that is easy to be learned.

I have searched for the word in both the Merriam-Webster and the Cambridge English online dictionaries, but didn't find it there. Nevertheless, this word seems to be used quite a lot in many scientific papers, it returns 775,000 results on Google and a lot of occurrences in Wikipedia.

So I ask: is this a valid word in English or, perhaps, just a neologism?

* he is from the University of South Florida and has a common American name - just in case somebody finds this relevant
","Learnable has been in use at least since the early 17th century.

By and large, when you find that an ordinary suffix has been attached to a word of the sort it is ordinarily attached to, and that the resulting sense is exactly that which such compounds ordinarily bear, it’s a legitimate word regardless of whether it appears in a dictionary. That’s what linguists mean when they say that a suffix or idiomatic pattern is ‘productive’: that it is regularly used to create valid new words or phrases. 

(And observe, please, that calling a term a neologism does not ‘invalidate’ it, whatever that might mean. To say a word is ‘valid’ can only mean that it is used and understood within its particular context or register, regardless of its age.)

In this case, -able is regularly attachable to any transitive VERB to express the meaning capable of being VERBed. Learn is a transitive verb, and learnable means capable of being learned. That’s all it takes.
"
5859,5859,9279,What exactly is 'anti-aliased image generation'?,"I tried to google it, but didn't quite get it. Any help and/or examples?
Thank you!
",vascobnunes,https://gis.stackexchange.com/users/3530,"An alias, in signal processing which is what we're dealing with when we are talking about images, is when a signal is sampled at a resolution that makes it impossible to recreate the original signal exactly.

Take this 1-dimensional case:



The original signal is the purple sine wave, and the blue dots are where it has been sampled. The blue line is the recreation of that signal based purely on those four samples - it is an alias of the original signal.

In 2D image processing, this aliasing tends to appear as ""jaggies"":



The line in image on the left is meant to be a perfectly straight line, but scaling it up has made it look less like a line. One way of improving the look of the line would just be to sample it at a higher resolution, the ideal resolution is called the Nyquist frequency, which is half of the highest frequency in the original signal. (In the case above there is no way of reproducing the signal perfectly because of its infinite frequency components).

Anti-aliasing (AA) is a general term for improving the recreation of a signal, without sampling it at a higher frequency. So linear interpolation (or a box filter) is a simple AA technique, but there are myriad other filters that have different properties and have to be chosen depending on the type of signal you're trying to recreate, the amount of memory/processing power you have to hand, and the sort of results you'd be happy with.
",MerseyViking,https://gis.stackexchange.com/users/2555,http://gis.stackexchange.com/questions/21998/what-exactly-is-anti-aliased-image-generation,TECHNOLOGY,gis.stackexchange.com,1.0,1.0,0.0,0.6666666666666666,1.0,1.0,0.5555555555555556,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.7777777777777778,1.0,0.7777777777777778,0.8888888888888888,1.0,0.9333333333333332,0.0,0.0,0.6666666666666666,1.0,What is anti aliasing image generation?,"I tried to search on Google, but I didn't find it completely. Any help and / or examples?","An alias, in signal processing which is what we're dealing with when we are talking about images, is when a signal is sampled at a resolution that makes it impossible to recreate the original signal exactly.

Take this 1-dimensional case:



The original signal is the purple sine wave, and the blue dots are where it has been sampled. The blue line is the recreation of that signal based purely on those four samples - it is an alias of the original signal.

In 2D image processing, this aliasing tends to appear as ""jaggies"":



The line in image on the left is meant to be a perfectly straight line, but scaling it up has made it look less like a line. One way of improving the look of the line would just be to sample it at a higher resolution, the ideal resolution is called the Nyquist frequency, which is half of the highest frequency in the original signal. (In the case above there is no way of reproducing the signal perfectly because of its infinite frequency components).

Anti-aliasing (AA) is a general term for improving the recreation of a signal, without sampling it at a higher frequency. So linear interpolation (or a box filter) is a simple AA technique, but there are myriad other filters that have different properties and have to be chosen depending on the type of signal you're trying to recreate, the amount of memory/processing power you have to hand, and the sort of results you'd be happy with.
"
1266,1266,1995,How to access beans from the applicationContext.xml in my service layer.,"How to access beans from the applicationContext.xml in my service layer.

I am working on a Spring Web MVC project and that issue is that my service layer needs a URL, User ID and Password to do a web post to a server to save my data.  I dont want to hardcode the URL, User ID and password in the Java Code of the Service Layer so I would like to put them into the applicationContent.xml file but I dont know how to access them from the service layer.

Can someone please help me out with this..  example code would be great.
",Java Review,https://stackoverflow.com/users/589450,"Had a similar question. May be this link will be of help.
Spring MVC 3.0 - Service layer using annonations 

Create a map of the values in dispatcher-servlet.xml and access it programmatically in your class. Or better inject the values to your bean in the xml file itself.
If you would rather have these values as environmental variables, that is also possible in Spring. Use a ""propertyplaceholderconfigurer"" for reading the external variables.
Let me know if you need further help.
",Raghav,https://stackoverflow.com/users/899488,http://stackoverflow.com/questions/8330372/how-to-access-beans-from-the-applicationcontext-xml-in-my-service-layer,STACKOVERFLOW,stackoverflow.com,0.5,0.8333333333333334,0.0,0.5,0.5,0.5,0.6666666666666666,0.3333333333333333,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.5,0.5,0.0,0.0,0.6666666666666666,0.8333333333333334,0.6666666666666666,0.8333333333333334,0.8333333333333334,0.9,0.5,0.5,0.0,0.8333333333333334,How to access beans from applicationcontext.xml in my service layer.,"How to access beans from the applicationContext.xml in my service layer.

I am working on a Spring Web MVC project and that issue is that my service layer needs a URL, User ID and Password to do a web post to a server to save my data.  I dont want to hardcode the URL, User ID and password in the Java Code of the Service Layer so I would like to put them into the applicationContent.xml file but I dont know how to access them from the service layer.

Can someone please help me out with this..  example code would be great.
","Had a similar question. May be this link will be of help.
Spring MVC 3.0 - Service layer using annonations 

Create a map of the values in dispatcher-servlet.xml and access it programmatically in your class. Or better inject the values to your bean in the xml file itself.
If you would rather have these values as environmental variables, that is also possible in Spring. Use a ""propertyplaceholderconfigurer"" for reading the external variables.
Let me know if you need further help.
"
2233,2233,3562,Disable tap on current Tab (UITabBarController) iPhone App,"Currently, Tapping on the same Tab (in which user is working), The App moves to the very first page of that Tab.

I want to disable the tap event on the Tab in which user is working currently.

Any Hint?
",viral,https://stackoverflow.com/users/887601,"use like below it will work   

- (BOOL)tabBarController:(UITabBarController *)tabBarController shouldSelectViewController:(UIViewController *)viewController
    {
        if(self.tabBarController.selectedIndex==[[self.tabBarController viewControllers] indexOfObject:viewController])
            return  NO;   
        else
            return YES;
    }

",Narayana,https://stackoverflow.com/users/815179,http://stackoverflow.com/questions/10054539/disable-tap-on-current-tab-uitabbarcontroller-iphone-app,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.7777777777777778,0.0,1.0,0.6666666666666666,1.0,0.6666666666666666,0.4444444444444444,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,0.8888888888888888,Disable clicking on the current tab (uitabbarcontroller) iPhone app,"Currently, clicking on the same tab (the user is working) moves the application to the first page of that tab.","use like below it will work   

- (BOOL)tabBarController:(UITabBarController *)tabBarController shouldSelectViewController:(UIViewController *)viewController
    {
        if(self.tabBarController.selectedIndex==[[self.tabBarController viewControllers] indexOfObject:viewController])
            return  NO;   
        else
            return YES;
    }

"
1791,1791,2845,"C - Print text from file, scroll with enter","I want to write a method which prints out the content of a file.

My method looks like this:

void showFile(char* src) {
char output[100];
char a = 0;
FILE *file;
int i = 0;

file = fopen(src, ""r"");
do {
    system(""cls"");
    for (i = 0; i &lt; min(24, filelength(src)-i); i++) {
        fgets(output, 24, file);
        printf(""%s"", output);
    }
    printf(""\nNaechste Seite mit &lt;Enter&gt; ausgeben\n"");
    a = _getch();
} while (a == 13 &amp;&amp; i &lt; filelength(src)-1);
printf(""\n\n"");
fclose(file); 
file = NULL;
}


It just needs the filepath the file is stored in as a String.

the min() method looks like this, it returns the smaller value:

int min(int x, int y) {
if (x &gt; y) {
    return y;
}
else {
    return x;
}
}


Now my problem is, when a file looks like this for example:

This
Is
The
Files
Content


It results in something like that:

This
Is
The
Files
Content
Content
Content
Content
Content
Content
Content
Content
Content


And so on. I don't know where exactly the problem is. I hope someone else can figure out my failure that I am unable to see?

Thanks in advance
",user2410644,https://stackoverflow.com/users/2410644,"You need to pay attention to the return status from fgets(), which is NULL when there is no more data (you've reached EOF).  Even though your loop would read more lines, there aren't any to read and it should stop.

You get the same data over and over again because fgets() typically doesn't modify its string if it has got EOF on the input stream it is reading from.  You might use this for the inner loop, which has a variety of clean-ups applied (one courtesy of Serge Ballesta — removing filelength() which measures the file size in bytes instead of lines, so the values 24 and the file length are incommensurate, and anyway that function is not something you want to call on each iteration of the loop for reasons of efficiency as well).

for (i = 0; i &lt; 24; i++)
{
    if (fgets(output, sizeof(output), file) == 0)
        break;
    printf(""%s"", output);
}


You may need to detect EOF in the outer loop too.  Just for once, it might even be reasonable to use feof(file) there, seeing as how the outer loop is a do … while loop.
",Jonathan Leffler,https://stackoverflow.com/users/15168,http://stackoverflow.com/questions/27425966/c-print-text-from-file-scroll-with-enter,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.3333333333333333,0.0,1.0,1.0,1.0,0.6666666666666666,0.5555555555555556,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8,0.6666666666666666,0.3333333333333333,1.0,1.0,C-Print the text in the file and press enter to scroll,"I want to write a method which prints out the content of a file.

My method looks like this:

void showFile(char* src) {
char output[100];
char a = 0;
FILE *file;
int i = 0;

file = fopen(src, ""r"");
do {
    system(""cls"");
    for (i = 0; i &lt; min(24, filelength(src)-i); i++) {
        fgets(output, 24, file);
        printf(""%s"", output);
    }
    printf(""\nNaechste Seite mit &lt;Enter&gt; ausgeben\n"");
    a = _getch();
} while (a == 13 &amp;&amp; i &lt; filelength(src)-1);
printf(""\n\n"");
fclose(file); 
file = NULL;
}


It just needs the filepath the file is stored in as a String.

the min() method looks like this, it returns the smaller value:

int min(int x, int y) {
if (x &gt; y) {
    return y;
}
else {
    return x;
}
}


Now my problem is, when a file looks like this for example:

This
Is
The
Files
Content


It results in something like that:

This
Is
The
Files
Content
Content
Content
Content
Content
Content
Content
Content
Content


And so on. I don't know where exactly the problem is. I hope someone else can figure out my failure that I am unable to see?

Thanks in advance
","You need to pay attention to the return status from fgets(), which is NULL when there is no more data (you've reached EOF).  Even though your loop would read more lines, there aren't any to read and it should stop.

You get the same data over and over again because fgets() typically doesn't modify its string if it has got EOF on the input stream it is reading from.  You might use this for the inner loop, which has a variety of clean-ups applied (one courtesy of Serge Ballesta — removing filelength() which measures the file size in bytes instead of lines, so the values 24 and the file length are incommensurate, and anyway that function is not something you want to call on each iteration of the loop for reasons of efficiency as well).

for (i = 0; i &lt; 24; i++)
{
    if (fgets(output, sizeof(output), file) == 0)
        break;
    printf(""%s"", output);
}


You may need to detect EOF in the outer loop too.  Just for once, it might even be reasonable to use feof(file) there, seeing as how the outer loop is a do … while loop.
"
3003,3003,4787,business-class fiber to the home,"Suppose you're some sort of crazy nerd fellow and you live in an area that's absolutely covered in fiber optics and network facilities. What kind of cost / infrastructure would be needed to hook in somewhere and get you're internet connection directly from a local datacenter?
",neoice,https://serverfault.com/users/6134,"Move.

Move either to someplace with Verizon FIOS service, or close to someplace where you can just throw it over the fence. Some guy's grandmother had 40Gbps three years ago that way. http://www.theregister.co.uk/2007/07/12/swedish_woman_has_fastest_internet_connection/

Just how fat a pipe do you need? Point to point wireless can offer good service up to 15Mbps, and of course there are various ""normal"" wired options.
",Ronald Pottol,https://serverfault.com/users/8668,http://serverfault.com/questions/158286,TECHNOLOGY,serverfault.com,1.0,0.4444444444444444,0.0,0.5,1.0,1.0,0.7777777777777778,0.7777777777777778,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.3333333333333333,0.0,0.8888888888888888,0.4444444444444444,0.5555555555555556,0.8888888888888888,0.7777777777777778,0.5333333333333333,0.3333333333333333,0.0,0.6666666666666666,1.0,Business class fiber home,"Suppose you're a crazy nerd, living in a place that's completely covered by fiber optics and networking. What cost / infrastructure is needed to connect to a place and directly from the local data center to the Internet?","Move.

Move either to someplace with Verizon FIOS service, or close to someplace where you can just throw it over the fence. Some guy's grandmother had 40Gbps three years ago that way. http://www.theregister.co.uk/2007/07/12/swedish_woman_has_fastest_internet_connection/

Just how fat a pipe do you need? Point to point wireless can offer good service up to 15Mbps, and of course there are various ""normal"" wired options.
"
6072,6072,9638,php escape sequence not working,"I just want to echo out some text on the webpage display with a tab space before a word.
I have the following codes in php:

&lt;?php
   echo ""\t\t hello!&lt;br&gt;"";
   echo ""\t\t"", ""hello!&lt;br&gt;"";
   echo ""\t\t"".""hello!&lt;br&gt;"";
?&gt;


I tried all sorts of combinations, but it just won't show the tab spacing before the word.

OUTPUT:

hello!
hello!
hello!


I visited some links like: Newline escape sequence not working on php 
but I am not echoing it from a function. I just simply want to echo it out from a .php file.
",user3437460,https://stackoverflow.com/users/3437460,"Try This:

&lt;pre&gt;&lt;?php
   echo ""\t\t hello!&lt;br&gt;"";
   echo ""\t\t"", ""hello!&lt;br&gt;"";
   echo ""\t\t"".""hello!&lt;br&gt;"";
?&gt;&lt;/pre&gt;


I would say you are probably viewing the generated page (html) rather than the page source.
",Nicholas Summers,https://stackoverflow.com/users/3511423,http://stackoverflow.com/questions/27111279/php-escape-sequence-not-working,STACKOVERFLOW,stackoverflow.com,1.0,0.3333333333333333,0.0,1.0,1.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,1.0,1.0,PHP escape sequence does not work,"I just want to echo out some text on the webpage display with a tab space before a word.
I have the following codes in php:

&lt;?php
   echo ""\t\t hello!&lt;br&gt;"";
   echo ""\t\t"", ""hello!&lt;br&gt;"";
   echo ""\t\t"".""hello!&lt;br&gt;"";
?&gt;


I tried all sorts of combinations, but it just won't show the tab spacing before the word.

OUTPUT:

hello!
hello!
hello!


I visited some links like: Newline escape sequence not working on php 
but I am not echoing it from a function. I just simply want to echo it out from a .php file.
","Try This:

&lt;pre&gt;&lt;?php
   echo ""\t\t hello!&lt;br&gt;"";
   echo ""\t\t"", ""hello!&lt;br&gt;"";
   echo ""\t\t"".""hello!&lt;br&gt;"";
?&gt;&lt;/pre&gt;


I would say you are probably viewing the generated page (html) rather than the page source.
"
983,983,1555,should have done vs should had done (sequence of tenses),"imagine you want to use ""should have done"" in a subordinate clause when there's some past tense in the main clause.

e.g.: ""He said I should have(had?) done it.""

which one is correct? 
or should i use some other modal verb for this purpose?
thanks
",Max Black,https://english.stackexchange.com/users/116742,"""should had done"" is never correct.  

Go with ""should have done"".
",Brian Hitchcock,https://english.stackexchange.com/users/95331,http://english.stackexchange.com/questions/238682/should-have-done-vs-should-had-done-sequence-of-tenses,CULTURE,english.stackexchange.com,1.0,0.6666666666666666,0.0,1.0,1.0,1.0,0.5555555555555556,0.8888888888888888,0.3333333333333333,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.5555555555555556,0.8888888888888888,0.5555555555555556,1.0,0.8888888888888888,0.8666666666666666,0.3333333333333333,0.0,0.3333333333333333,0.8888888888888888,Should do vs should do (temporal sequence),"imagine you want to use ""should have done"" in a subordinate clause when there's some past tense in the main clause.

e.g.: ""He said I should have(had?) done it.""

which one is correct? 
or should i use some other modal verb for this purpose?
thanks
","""should had done"" is never correct.  

Go with ""should have done"".
"
5887,5887,9327,Getting libraries to load with newer jQuery using jqmulti,"I'm kind of a newbie to this so I could be missing something really obvious, but I'm having trouble getting specific libraries to load with jQuery 1.7 in noconflict mode using jqmulti. I'm working on a theme based off twitter_bootstrap, and the bootstrap.js library is dependent on more recent jQuery. I've got jqmulti recognizing and loading 1.7 if I check ""load even if no libraries are assigned"" but when I have that unchecked and attempt to use hook_jqmulti_files() to assign particular libraries, nothing happens.

This is what I have in my template.php:

function regent_jqmulti_files() {
    return array(
        'sites/all/themes/regent/bootstrap/js/bootstrap.js',
        'sites/all/themes/regent/bootstrap/js/bootstrap.min.js'
    );
}


but when I look at my rendered html, the library is loaded, but nothing about noconflict mode,  and jQ 1.7 is nowhere to be found. I'm sure I'm missing something basic and stupid, this being the first time I've tried to set something like this up.
",jimhart3000,https://drupal.stackexchange.com/users/7553,"As you are talking of a template.php file, I get you are talking of theme code. The only hooks a theme can implement are alter hooks (the ones called with drupal_alter() and with a name ending in _alter), in Drupal 7. (Theme functions are not hooks.)

If you look at the code of drupal_alter(), you will notice it contains the following lines.

// Allow the theme to alter variables after the theme system has been
// initialized.
global $theme, $base_theme_info;
if (isset($theme)) {
  $theme_keys = array();
  foreach ($base_theme_info as $base) {
    $theme_keys[] = $base-&gt;name;
  }
  $theme_keys[] = $theme;
  foreach ($theme_keys as $theme_key) {
    $function = $theme_key . '_' . $hook;
    if (function_exists($function)) {
      $functions[$cid][] = $function;
    }
    if (isset($extra_types)) {
      foreach ($extra_types as $extra_type) {
        $function = $theme_key . '_' . $extra_type . '_alter';
        if (function_exists($function)) {
          $functions[$cid][] = $function;
        }
      }
    }
  }
}


Differently, module_implements() (used from any function that invokes hooks) doesn't check hooks implemented by themes.
",kiamlaluno,https://drupal.stackexchange.com/users/199,http://drupal.stackexchange.com/questions/31891/getting-libraries-to-load-with-newer-jquery-using-jqmulti,TECHNOLOGY,drupal.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,0.6666666666666666,1.0,0.6666666666666666,0.5555555555555556,0.7777777777777778,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.7777777777777778,1.0,0.5555555555555556,1.0,1.0,0.8666666666666666,0.6666666666666666,0.0,0.3333333333333333,1.0,Using jqmulti to use the newer jQuery load Library,"I'm kind of a newbie to this so I could be missing something really obvious, but I'm having trouble getting specific libraries to load with jQuery 1.7 in noconflict mode using jqmulti. I'm working on a theme based off twitter_bootstrap, and the bootstrap.js library is dependent on more recent jQuery. I've got jqmulti recognizing and loading 1.7 if I check ""load even if no libraries are assigned"" but when I have that unchecked and attempt to use hook_jqmulti_files() to assign particular libraries, nothing happens.

This is what I have in my template.php:

function regent_jqmulti_files() {
    return array(
        'sites/all/themes/regent/bootstrap/js/bootstrap.js',
        'sites/all/themes/regent/bootstrap/js/bootstrap.min.js'
    );
}


but when I look at my rendered html, the library is loaded, but nothing about noconflict mode,  and jQ 1.7 is nowhere to be found. I'm sure I'm missing something basic and stupid, this being the first time I've tried to set something like this up.
","As you are talking of a template.php file, I get you are talking of theme code. The only hooks a theme can implement are alter hooks (the ones called with drupal_alter() and with a name ending in _alter), in Drupal 7. (Theme functions are not hooks.)

If you look at the code of drupal_alter(), you will notice it contains the following lines.

// Allow the theme to alter variables after the theme system has been
// initialized.
global $theme, $base_theme_info;
if (isset($theme)) {
  $theme_keys = array();
  foreach ($base_theme_info as $base) {
    $theme_keys[] = $base-&gt;name;
  }
  $theme_keys[] = $theme;
  foreach ($theme_keys as $theme_key) {
    $function = $theme_key . '_' . $hook;
    if (function_exists($function)) {
      $functions[$cid][] = $function;
    }
    if (isset($extra_types)) {
      foreach ($extra_types as $extra_type) {
        $function = $theme_key . '_' . $extra_type . '_alter';
        if (function_exists($function)) {
          $functions[$cid][] = $function;
        }
      }
    }
  }
}


Differently, module_implements() (used from any function that invokes hooks) doesn't check hooks implemented by themes.
"
3201,3201,5102,Is a password easier to brute force if it contains a repeating pattern?,"My question is different from this previous question: Does repeating one word to form a password result in a similar pattern in its encrypted format?. I'm specifically wondering about brute force attacks. Based on my experiences with John The Ripper, I doubt that repeating a pattern in a password would shorten the time to successfully brute force a password like f00B@rf00B@rf00B@r as opposed to a random string of equal length. However, my doubt is based on the fact that, according to the documentation, JTR does not include a specific attack mode for repeating patterns. JTR, and presumably other brute force tools, can be customized for any arbitrary attack mode. But we can't know how often attackers bother to customize attacks in this way. So then the question becomes mathematical. Please forgive the awkward pseudo mathematical notation. 

T = brute force cracking time

PL = pattern of characters of length L

N = number of times PL is repeated

R(LN) = string of random characters of length (L times N)


Would it be true that

T(PL*N)= T(R(LN))


If true, then a repeating pattern password would not affect brute force cracking time. But is it true?
",Luke Sheppard,https://security.stackexchange.com/users/12057,"There are three scenarios here:

Attacker has no knowledge of the pattern scheme:
When the attacker has no knowledge of the patterns, the brute-force attempt will have to be exhaustive. The attacker gains no practical efficiency improvement, because there is no way of him knowing the construction of the password.

Attacker has some or full knowledge of the pattern scheme:
If the attacker has knowledge of the patterns, they may improve the efficiency of their bruteforce attack by not attempting passwords that do not match the pattern scheme.

Attacker has no initial knowledge of the pattern scheme, and multiple hashes are available:
If the attacker has no initial knowledge of the pattern, but has a number of different password hashes to crack (all of which use the same scheme for the password) he may crack a small number of them via exhaustive bruteforce, then deduce the pattern. From there, the attack becomes much more efficient.
",Polynomial,https://security.stackexchange.com/users/5400,http://security.stackexchange.com/questions/21562/is-a-password-easier-to-brute-force-if-it-contains-a-repeating-pattern,TECHNOLOGY,security.stackexchange.com,0.8888888888888888,1.0,0.0,0.3333333333333333,1.0,1.0,0.5555555555555556,0.5555555555555556,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,1.0,0.8888888888888888,0.8666666666666666,0.0,0.3333333333333333,1.0,0.8888888888888888,"If the password contains a repeating pattern, is it easier to force it?","My question is different from the previous one: does repeating a word to form a password result in a similar pattern of its encryption format? I particularly want to know about violent attacks. Based on my experience with John the Ripper, I suspect that repeating a pattern in a password will shorten the time to successfully enforce a password such as f00b @ rf00b @ rf00b @ r, rather than using a random string of the same length. However, my suspicions are based on the fact that, according to the documentation, jtr does not include specific attack patterns for duplicate patterns. Jtr and other violence tools can be customized for any attack mode. But we don't know how long it will take for attackers to customize attacks like this. So the problem became a mathematical problem. Please forgive this clumsy pseudo mathematical symbol.","There are three scenarios here:

Attacker has no knowledge of the pattern scheme:
When the attacker has no knowledge of the patterns, the brute-force attempt will have to be exhaustive. The attacker gains no practical efficiency improvement, because there is no way of him knowing the construction of the password.

Attacker has some or full knowledge of the pattern scheme:
If the attacker has knowledge of the patterns, they may improve the efficiency of their bruteforce attack by not attempting passwords that do not match the pattern scheme.

Attacker has no initial knowledge of the pattern scheme, and multiple hashes are available:
If the attacker has no initial knowledge of the pattern, but has a number of different password hashes to crack (all of which use the same scheme for the password) he may crack a small number of them via exhaustive bruteforce, then deduce the pattern. From there, the attack becomes much more efficient.
"
1184,1184,1860,"How should I take a potential PhD supervisor's age into account, when planning to follow PhD with habilitation?","I plan to apply for PhD in Finance/Statistics next semester, and hence searched for potential supervisors.

An issue I have is that many interesting candidates are above age 60, and in Germany Professors retire at 65, such that a subsequent post-doc/habilitation would most likely require a different supervisor after PhD. One Professor just started his position at age 40, but so he has not many notable publications and I am unsure whether he might change university soon (he just changed it from another 4 years position).

Could someone advise me on the importance of age for selecting a PhD supervisor in context of a long-term future academic career?

The time for PhD would be 4-5 years, and PostDoc/Habilitation/AssociateProf usually again 4-6 years, with goal of potentially becoming Full Professor in Finance/Statistics.
",emcor,https://academia.stackexchange.com/users/18228,"First: a few people commented that thinking about your postdoc/Habilitation before even starting your Ph.D. is premature. I disagree. I have seen too many people coast along during their Ph.D. time without ever knowing what they are going to do afterwards, and certainly not preparing for their post-Ph.D. time, whether in academia or in industry. So I would say you demonstrate good long-term thinking. Already thinking about your academic career will help you prepare to work out a research program, network (more on this below) etc.

Second: there is no problem whatsoever with changing advisors between the Ph.D. and the postdoc period. To the contrary! If you stay at the same place for almost ten years, you will need to explain why you never moved, never checked out other places to work, other approaches to research. Many, many (most?) people will switch advisors at least once, or possibly even do postdocs in two different places.

Incidentally, this is why I think it is a good thing you are already thinking about your long-term future now, because it is never too early to start meeting people at conferences with your future in mind. You may just meet someone at your first conference who you could collaborate with or spend your postdoc time with.

So I would definitely recommend that you consider the older potential advisor. He sounds like he could introduce you to lots of people, and you will likely not need to pack up and move somewhere else during your Ph.D. period, which seems possible with the younger professor and which could somewhat mess up your personal life.

Of course, these considerations are all not the highest priority. You should definitely keep other aspects in mind in choosing where to do your Ph.D., like the kind of project you would be doing for either of the two professors, or whether the two of you ""click"" on a personal level, or what financing there is, or lots of other things you should discuss with your potential advisor ahead of time.

Finally, there is no Habilitation in Germany any more. Nowadays, Germany has moved to a more American style in academic careers. You will do a Ph.D., then a postdoc, then usually a Juniorprofessur (roughly, assistant professorship - not tenured and limited to six years), then get your Ruf to a tenured position. It's quite possible to skip the Juniorprofessur, though.
",Stephan Kolassa,https://academia.stackexchange.com/users/4140,http://academia.stackexchange.com/questions/24439/how-should-i-take-a-potential-phd-supervisors-age-into-account-when-planning-t,LIFE_ARTS,academia.stackexchange.com,1.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.6666666666666666,0.7777777777777778,0.6666666666666666,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,1.0,1.0,0.7777777777777778,1.0,1.0,1.0,0.0,0.6666666666666666,0.6666666666666666,1.0,How do I consider the age of potential Ph.D. tutors when I'm going to be a Ph.D?,"I plan to apply for PhD in Finance/Statistics next semester, and hence searched for potential supervisors.

An issue I have is that many interesting candidates are above age 60, and in Germany Professors retire at 65, such that a subsequent post-doc/habilitation would most likely require a different supervisor after PhD. One Professor just started his position at age 40, but so he has not many notable publications and I am unsure whether he might change university soon (he just changed it from another 4 years position).

Could someone advise me on the importance of age for selecting a PhD supervisor in context of a long-term future academic career?

The time for PhD would be 4-5 years, and PostDoc/Habilitation/AssociateProf usually again 4-6 years, with goal of potentially becoming Full Professor in Finance/Statistics.
","First: a few people commented that thinking about your postdoc/Habilitation before even starting your Ph.D. is premature. I disagree. I have seen too many people coast along during their Ph.D. time without ever knowing what they are going to do afterwards, and certainly not preparing for their post-Ph.D. time, whether in academia or in industry. So I would say you demonstrate good long-term thinking. Already thinking about your academic career will help you prepare to work out a research program, network (more on this below) etc.

Second: there is no problem whatsoever with changing advisors between the Ph.D. and the postdoc period. To the contrary! If you stay at the same place for almost ten years, you will need to explain why you never moved, never checked out other places to work, other approaches to research. Many, many (most?) people will switch advisors at least once, or possibly even do postdocs in two different places.

Incidentally, this is why I think it is a good thing you are already thinking about your long-term future now, because it is never too early to start meeting people at conferences with your future in mind. You may just meet someone at your first conference who you could collaborate with or spend your postdoc time with.

So I would definitely recommend that you consider the older potential advisor. He sounds like he could introduce you to lots of people, and you will likely not need to pack up and move somewhere else during your Ph.D. period, which seems possible with the younger professor and which could somewhat mess up your personal life.

Of course, these considerations are all not the highest priority. You should definitely keep other aspects in mind in choosing where to do your Ph.D., like the kind of project you would be doing for either of the two professors, or whether the two of you ""click"" on a personal level, or what financing there is, or lots of other things you should discuss with your potential advisor ahead of time.

Finally, there is no Habilitation in Germany any more. Nowadays, Germany has moved to a more American style in academic careers. You will do a Ph.D., then a postdoc, then usually a Juniorprofessur (roughly, assistant professorship - not tenured and limited to six years), then get your Ruf to a tenured position. It's quite possible to skip the Juniorprofessur, though.
"
2454,2454,3917,"Looking for a word with a more positive connotation than ""infectious""","I recently was attempting to describe someone's smile. I wanted to describe it as being very 'infectious', or that it spreads very quickly and is contagious. However, as hard as I could try, I could only come up with words that have to do with infections or words that have a negative connotation. 

How could I describe a person's smile if it has the ability to 'spread' to other people, as denoted above?

Thanks!
",Conner,https://english.stackexchange.com/users/82110,"His smile was like barbecue sauce- it wound up on everyone's face.
",bobro,https://english.stackexchange.com/users/115362,http://english.stackexchange.com/questions/236329/looking-for-a-word-with-a-more-positive-connotation-than-infectious,CULTURE,english.stackexchange.com,1.0,0.7777777777777778,0.0,1.0,0.6666666666666666,0.0,0.5555555555555556,0.7777777777777778,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.8888888888888888,0.6666666666666666,0.5555555555555556,0.7777777777777778,0.8888888888888888,0.7333333333333333,0.0,0.0,0.0,1.0,"Find a more positive word than ""infectious""","I recently tried to describe someone's smile. I want to describe it as very ""infectious,"" or that it spreads very quickly and is infectious. However, to the best of my ability, I can only come up with some words related to infection, or words with negative meanings.","His smile was like barbecue sauce- it wound up on everyone's face.
"
2133,2133,3397,Meteor renderList intercept? client side,"I have chat messages displayed like this:

  {{#each msg}}
    {{&gt; chatMsg}}
  {{/each}}


When users enter the chat I add a document to the collection with user joins the chat. When a user rapidly reenters and leaves the chat I don't want to duplicate user joins the chat over and over again. I want to display something like user joins the chat x3.

Is there a way to do this on the client side by hooking into renderList? I know I can change the doc on the server side but it seems unnecessarily intensive.
",Harry,https://stackoverflow.com/users/663447,"One option is to make a method call that just updates the latest user joined message.

function formatJoinMessage(username,count) {...}

if (Meteor.isServer) Meteor.startup(function () {Chats._ensureIndex({modified:-1}); ...});

Meteor.methods({
    join:function() {
        var joinMessage = Chats.find({type:MESSAGE_TYPE_JOINED,userId:this.userId}).sort({modified:-1}).fetch()[0];
        if (joinMessage)
            Chats.update({_id:joinMessage._id},{$inc:{joins:1},$set:{text:formatJoinMessage(this.userId,joinMessage.joins+1),modified:new Date()});
        else
            Chats.insert({user:this.userId,joins:1,modified:new Date(),text:formatJoinMessage(this.userId,1)});
    }
)};


Don't want to change the server doc? That's okay, but conceptually a chat join isn't a chat message. So you should definitely have a meta field for stuff like this in your chat documents.

But supposing you don't want to do that. I'd do something like this:

var userIdToName = function(userId) {...}; // some kind of userId to name helper

Template.chatroom.msg = function() {
  var messages = Chat.findOne(Session.get(""currentChat"")).messages; // msg in your code?
  return _.reduce(messages,function (newMessages, currentMessage) {
    var lastMsg = newMessages[newMessages.length-1];
    if (currentMessage.type == MESSAGE_TYPES_JOIN) {
       if (lastMsg &amp;&amp; lastMsg.type == MESSAGE_TYPES_JOIN &amp;&amp; currentMessage.user == lastMsg.user) {
          currentMessage.timesJoined = lastMsg.timesJoined+1;
          newMessages.shift();
       } else {
          currentMessage.timesJoined = 1;
       }
       currentMessage.chatMsg = userIdToName(lastMsg.user) + "" joins the chat &amp;mult;"" + currentMessage.timesJoined.toString();
    }
    return newMessages.concat(currentMessage);
  },[]);
}


This is a bit of a doozy. Suffice it to say, it ""reduces"" all the join messages it finds in the chat's current messages down to one message. You dynamically add the property timesJoined; it does not appear in the document. But you should have a type field that lets you know the difference between a join message and a regular message is.

If you don't even have that metadata at minimum, then your chat application isn't going to work very well. Don't hesitate to change your model!
",DoctorPangloss,https://stackoverflow.com/users/1757994,http://stackoverflow.com/questions/13663765/meteor-renderlist-intercept-client-side,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.4444444444444444,0.0,1.0,0.6666666666666666,1.0,0.4444444444444444,0.4444444444444444,0.3333333333333333,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.6666666666666666,1.0,0.7777777777777778,1.0,1.0,0.9333333333333332,1.0,0.6666666666666666,0.6666666666666666,0.8888888888888888,Meteor Radar capture? Client,"I have chat messages displayed like this:

  {{#each msg}}
    {{&gt; chatMsg}}
  {{/each}}


When users enter the chat I add a document to the collection with user joins the chat. When a user rapidly reenters and leaves the chat I don't want to duplicate user joins the chat over and over again. I want to display something like user joins the chat x3.

Is there a way to do this on the client side by hooking into renderList? I know I can change the doc on the server side but it seems unnecessarily intensive.
","One option is to make a method call that just updates the latest user joined message.

function formatJoinMessage(username,count) {...}

if (Meteor.isServer) Meteor.startup(function () {Chats._ensureIndex({modified:-1}); ...});

Meteor.methods({
    join:function() {
        var joinMessage = Chats.find({type:MESSAGE_TYPE_JOINED,userId:this.userId}).sort({modified:-1}).fetch()[0];
        if (joinMessage)
            Chats.update({_id:joinMessage._id},{$inc:{joins:1},$set:{text:formatJoinMessage(this.userId,joinMessage.joins+1),modified:new Date()});
        else
            Chats.insert({user:this.userId,joins:1,modified:new Date(),text:formatJoinMessage(this.userId,1)});
    }
)};


Don't want to change the server doc? That's okay, but conceptually a chat join isn't a chat message. So you should definitely have a meta field for stuff like this in your chat documents.

But supposing you don't want to do that. I'd do something like this:

var userIdToName = function(userId) {...}; // some kind of userId to name helper

Template.chatroom.msg = function() {
  var messages = Chat.findOne(Session.get(""currentChat"")).messages; // msg in your code?
  return _.reduce(messages,function (newMessages, currentMessage) {
    var lastMsg = newMessages[newMessages.length-1];
    if (currentMessage.type == MESSAGE_TYPES_JOIN) {
       if (lastMsg &amp;&amp; lastMsg.type == MESSAGE_TYPES_JOIN &amp;&amp; currentMessage.user == lastMsg.user) {
          currentMessage.timesJoined = lastMsg.timesJoined+1;
          newMessages.shift();
       } else {
          currentMessage.timesJoined = 1;
       }
       currentMessage.chatMsg = userIdToName(lastMsg.user) + "" joins the chat &amp;mult;"" + currentMessage.timesJoined.toString();
    }
    return newMessages.concat(currentMessage);
  },[]);
}


This is a bit of a doozy. Suffice it to say, it ""reduces"" all the join messages it finds in the chat's current messages down to one message. You dynamically add the property timesJoined; it does not appear in the document. But you should have a type field that lets you know the difference between a join message and a regular message is.

If you don't even have that metadata at minimum, then your chat application isn't going to work very well. Don't hesitate to change your model!
"
5951,5951,9428,Finding columns that do not match existing primary key,"I'm trying to add a Foreign Key to a table, but database, Sql Server 2005, does not like it.

It says that columns do not match an existing primary key or unique constraint. 

How can I find the columns in question so I can delete/change them and add the foreign key?
",Chin,https://stackoverflow.com/users/135687,"SELECT 
   ForeignKey 
FROM 
   FK_TABLE f 
LEFT JOIN 
   PK_TABLE p ON f.ForeignKey = p.PrimaryKey 
WHERE 
   p.PrimaryKey = NULL


That should do it.

ForeignKey = the column you want to make into a foreign key
PK_TABLE = the table you want the foreign key to reference
PrimaryKey = the column ForeignKey will be a foreign key to.
",Sean,https://stackoverflow.com/users/112713,http://stackoverflow.com/questions/1178377/finding-columns-that-do-not-match-existing-primary-key,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.7777777777777778,0.0,0.5,1.0,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,0.8888888888888888,0.8,1.0,0.0,0.0,0.8333333333333334,Find columns that do not match the existing primary key,"I'm trying to add a Foreign Key to a table, but database, Sql Server 2005, does not like it.

It says that columns do not match an existing primary key or unique constraint. 

How can I find the columns in question so I can delete/change them and add the foreign key?
","SELECT 
   ForeignKey 
FROM 
   FK_TABLE f 
LEFT JOIN 
   PK_TABLE p ON f.ForeignKey = p.PrimaryKey 
WHERE 
   p.PrimaryKey = NULL


That should do it.

ForeignKey = the column you want to make into a foreign key
PK_TABLE = the table you want the foreign key to reference
PrimaryKey = the column ForeignKey will be a foreign key to.
"
3998,3998,6385,"""How big of a problem"" vs. ""how big a problem""","Quite a few phrases in English are constructed like so:


  How [adjective] a [noun]...?


This is the question form of the construction, which is often answered with the negative:


  Not that [adjective] a [noun].


or the positive:


  Quite [adjective] a [noun].


However, from time to time I'll hear the word 'of' inserted before the 'a', e.g.:


  Not that [adjective] of a [noun].


This usually sounds wrong to me, with the exception of the case where the adjective 'much' is used.  So, this sounds fine to my ear:


  Not that much of a problem.


whereas this doesn't:


  Not that loud of a noise.


Why is it that 'much' should be used with 'of', and other adjectives not?  Is it because 'much' is seen as measuring a quantity (of something), whereas other adjectives that may be used in this construction are seen as measuring the quality of a whole thing?
",Jez,https://english.stackexchange.com/users/4801,"What about ""not that high (of) a fence""? ""not that red (of) a heart"" ""not that smart (of) a person? not that big (of) a problem?

I would argue that if you use the word that to qualify the adjective, the of is in fact necessary to convey the meaning of comparison of a specific entity to the class of general entities to which it belongs.

I'm sure the usage can be regional, as well. There is no hard and fast rule.

EDIT

Hey, I did some more research. Dictionary.com has the following usage note for ""of"" :


  Of  is sometimes added to phrases beginning with the adverb how or too followed by a descriptive adjective: How long of a drive will it be? It's too hot of a day for tennis.  This construction is probably modeled on that in which how  or too  is followed by much,  an unquestionably standard use in all varieties of speech and writing: How much of a problem will that cause the government? There was too much of an uproar for the speaker to be heard.  The use of of with descriptive adjectives after how  or too  is largely restricted to informal speech. It occurs occasionally in informal writing and written representations of speech.


So, I suppose that's the reason why adjectives other than ""much"" combined with ""of"" sound odd to your ear. I believe ""that"" can be included with ""how"" or ""too"" in this synopsis. Replacing ""much"" with another adjective occurs occasionally in informal writing and in speech, but isn't unquestionably standard.

When I say these constructions out loud, to me, I often want to insert the of but perhaps that has something more to say about the informality of my speech rather than the correctness of the construction. :)
",ghoppe,https://english.stackexchange.com/users/1871,http://english.stackexchange.com/questions/30011/how-big-of-a-problem-vs-how-big-a-problem,CULTURE,english.stackexchange.com,1.0,0.7777777777777778,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.5555555555555556,0.3333333333333333,0.0,0.6666666666666666,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.7777777777777778,1.0,0.8888888888888888,1.0,1.0,0.8,0.0,0.0,1.0,0.8888888888888888,"""How big is the problem"" and ""how big is the problem""","Quite a few phrases in English are constructed like so:


  How [adjective] a [noun]...?


This is the question form of the construction, which is often answered with the negative:


  Not that [adjective] a [noun].


or the positive:


  Quite [adjective] a [noun].


However, from time to time I'll hear the word 'of' inserted before the 'a', e.g.:


  Not that [adjective] of a [noun].


This usually sounds wrong to me, with the exception of the case where the adjective 'much' is used.  So, this sounds fine to my ear:


  Not that much of a problem.


whereas this doesn't:


  Not that loud of a noise.


Why is it that 'much' should be used with 'of', and other adjectives not?  Is it because 'much' is seen as measuring a quantity (of something), whereas other adjectives that may be used in this construction are seen as measuring the quality of a whole thing?
","What about ""not that high (of) a fence""? ""not that red (of) a heart"" ""not that smart (of) a person? not that big (of) a problem?

I would argue that if you use the word that to qualify the adjective, the of is in fact necessary to convey the meaning of comparison of a specific entity to the class of general entities to which it belongs.

I'm sure the usage can be regional, as well. There is no hard and fast rule.

EDIT

Hey, I did some more research. Dictionary.com has the following usage note for ""of"" :


  Of  is sometimes added to phrases beginning with the adverb how or too followed by a descriptive adjective: How long of a drive will it be? It's too hot of a day for tennis.  This construction is probably modeled on that in which how  or too  is followed by much,  an unquestionably standard use in all varieties of speech and writing: How much of a problem will that cause the government? There was too much of an uproar for the speaker to be heard.  The use of of with descriptive adjectives after how  or too  is largely restricted to informal speech. It occurs occasionally in informal writing and written representations of speech.


So, I suppose that's the reason why adjectives other than ""much"" combined with ""of"" sound odd to your ear. I believe ""that"" can be included with ""how"" or ""too"" in this synopsis. Replacing ""much"" with another adjective occurs occasionally in informal writing and in speech, but isn't unquestionably standard.

When I say these constructions out loud, to me, I often want to insert the of but perhaps that has something more to say about the informality of my speech rather than the correctness of the construction. :)
"
4548,4548,7205,rm -f files starting with a digit,"I've accidentally redirected the output of a CSV file to my directory.  How can I rm only the files that start with a number, and leave the files that start with a letter intact? 

mymachine$ ls
71.24         README.md        30            4.29
8             filter.sh        42.81         5.58         
8.36          purchases.csv    1,208.8       100          
16.7          2.56             21.78         269.96        

",spuder,https://unix.stackexchange.com/users/39263,"Something like this should do it:

$ rm [0-9]*


Remember you can always use echo with any globbing arguments prior to letting rm run with them.

$ echo [0-9]*
100 1,208.8 16.7 21.78 2.56 269.96 30 42.81 4.29 5.58 71.24 8 8.36


After running the rm command above:

$ ls
filter.sh  purchases.csv  README.md

",slm,https://unix.stackexchange.com/users/7453,http://unix.stackexchange.com/questions/114501/rm-f-files-starting-with-a-digit,TECHNOLOGY,unix.stackexchange.com,0.3333333333333333,0.3333333333333333,0.0,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,Rm-f files starting with numbers,"I've accidentally redirected the output of a CSV file to my directory.  How can I rm only the files that start with a number, and leave the files that start with a letter intact? 

mymachine$ ls
71.24         README.md        30            4.29
8             filter.sh        42.81         5.58         
8.36          purchases.csv    1,208.8       100          
16.7          2.56             21.78         269.96        

","Something like this should do it:

$ rm [0-9]*


Remember you can always use echo with any globbing arguments prior to letting rm run with them.

$ echo [0-9]*
100 1,208.8 16.7 21.78 2.56 269.96 30 42.81 4.29 5.58 71.24 8 8.36


After running the rm command above:

$ ls
filter.sh  purchases.csv  README.md

"
4402,4402,6996,"Tight VNC Server, Ubutu 12.10 and unity desktop","I've done the following but all I get in VNC Viewer is a blank orange screen, any help appreciated.


apt-get -y install ubuntu-desktop tightvncserver
adduser vnc
passwd vnc
echo ""vnc ALL=(ALL)       ALL"" >> /etc/sudoers
su - vnc
vncpasswd
exit
cd ~
nano .vnc/xstartup


#!/bin/sh

# Uncomment the following two lines for normal desktop:
unset SESSION_MANAGER
. /etc/X11/xinit/xinitrc

[ -x /etc/vnc/xstartup ] &amp;&amp; exec /etc/vnc/xstartup
[ -r $HOME/.Xresources ] &amp;&amp; xrdb $HOME/.Xresources
xsetroot -solid grey
vncconfig -iconic &amp;
x-terminal-emulator -geometry 1280x1024+10+10 -ls -title ""$VNCDESKTOP Desktop"" &amp;

#x-window-manager &

save

THEN nano /etc/init.d/vncserver 

THEN paste in the following, then save:

#!/bin/sh -e
### BEGIN INIT INFO
# Provides:          vncserver
# Required-Start:    networking
# Default-Start:     3 4 5
# Default-Stop:      0 6
### END INIT INFO

PATH=""$PATH:/usr/bin/""

# The Username:Group that will run VNC
export USER=""vnc""
#${RUNAS}

# The display that VNC will use
DISPLAY=""1""

# Color depth (between 8 and 32)
DEPTH=""16""

# The Desktop geometry to use.
#GEOMETRY=""x""
#GEOMETRY=""800x600""
GEOMETRY=""1024x768""
#GEOMETRY=""1280x1024""

# The name that the VNC Desktop will have.
NAME=""my-vnc-server""

OPTIONS=""-name ${NAME} -depth ${DEPTH} -geometry ${GEOMETRY} :${DISPLAY}""

. /lib/lsb/init-functions

case ""$1"" in
start)
log_action_begin_msg ""Starting vncserver for user '${USER}' on   localhost:${DISPLAY}""
su ${USER} -c ""/usr/bin/vncserver ${OPTIONS}""
;;

stop)
log_action_begin_msg ""Stopping vncserver for user '${USER}' on localhost:${DISPLAY}""
su ${USER} -c ""/usr/bin/vncserver -kill :${DISPLAY}""
;;

restart)
$0 stop
$0 start
;;
esac

exit 0


Then ctrl-x to save, Y for Yes, and enter to accept file name.

THEN

chown -R vnc. /home/vnc/.vnc &amp;&amp; chmod +x /home/vnc/.vnc/xstartup
sed -i 's/allowed_users.*/allowed_users=anybody/g' /etc/X11/Xwrapper.config

THEN

chmod +x /etc/init.d/vncserver &amp;&amp; service vncserver start

THEN

update-rc.d vncserver defaults

THEN

reboot.

FINALLY: go in there with tightvnc viewer client, and voila, blank kool aid tangerine orange screen.

any help appreciated, of course it's been 3 x 8 hour evenings so far :}
",Randal Oulton,https://askubuntu.com/users/244335,"From what i've seen you cant vnc into unity.  Install a different desktop environment and you'll be good.  Heres how woth xfce:

https://www.digitalocean.com/community/articles/how-to-setup-vnc-for-ubuntu-12
",user242616,https://askubuntu.com/users/242616,http://askubuntu.com/questions/416151/tight-vnc-server-ubutu-12-10-and-unity-desktop,TECHNOLOGY,askubuntu.com,0.6666666666666666,0.3333333333333333,0.0,0.0,1.0,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,1.0,0.0,0.4444444444444444,0.7777777777777778,0.5555555555555556,1.0,0.7777777777777778,0.8,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.5555555555555556,"Tight VNC server, Ubuntu 12.10 and unity desktop","I've done the following but all I get in VNC Viewer is a blank orange screen, any help appreciated.


apt-get -y install ubuntu-desktop tightvncserver
adduser vnc
passwd vnc
echo ""vnc ALL=(ALL)       ALL"" >> /etc/sudoers
su - vnc
vncpasswd
exit
cd ~
nano .vnc/xstartup


#!/bin/sh

# Uncomment the following two lines for normal desktop:
unset SESSION_MANAGER
. /etc/X11/xinit/xinitrc

[ -x /etc/vnc/xstartup ] &amp;&amp; exec /etc/vnc/xstartup
[ -r $HOME/.Xresources ] &amp;&amp; xrdb $HOME/.Xresources
xsetroot -solid grey
vncconfig -iconic &amp;
x-terminal-emulator -geometry 1280x1024+10+10 -ls -title ""$VNCDESKTOP Desktop"" &amp;

#x-window-manager &

save

THEN nano /etc/init.d/vncserver 

THEN paste in the following, then save:

#!/bin/sh -e
### BEGIN INIT INFO
# Provides:          vncserver
# Required-Start:    networking
# Default-Start:     3 4 5
# Default-Stop:      0 6
### END INIT INFO

PATH=""$PATH:/usr/bin/""

# The Username:Group that will run VNC
export USER=""vnc""
#${RUNAS}

# The display that VNC will use
DISPLAY=""1""

# Color depth (between 8 and 32)
DEPTH=""16""

# The Desktop geometry to use.
#GEOMETRY=""x""
#GEOMETRY=""800x600""
GEOMETRY=""1024x768""
#GEOMETRY=""1280x1024""

# The name that the VNC Desktop will have.
NAME=""my-vnc-server""

OPTIONS=""-name ${NAME} -depth ${DEPTH} -geometry ${GEOMETRY} :${DISPLAY}""

. /lib/lsb/init-functions

case ""$1"" in
start)
log_action_begin_msg ""Starting vncserver for user '${USER}' on   localhost:${DISPLAY}""
su ${USER} -c ""/usr/bin/vncserver ${OPTIONS}""
;;

stop)
log_action_begin_msg ""Stopping vncserver for user '${USER}' on localhost:${DISPLAY}""
su ${USER} -c ""/usr/bin/vncserver -kill :${DISPLAY}""
;;

restart)
$0 stop
$0 start
;;
esac

exit 0


Then ctrl-x to save, Y for Yes, and enter to accept file name.

THEN

chown -R vnc. /home/vnc/.vnc &amp;&amp; chmod +x /home/vnc/.vnc/xstartup
sed -i 's/allowed_users.*/allowed_users=anybody/g' /etc/X11/Xwrapper.config

THEN

chmod +x /etc/init.d/vncserver &amp;&amp; service vncserver start

THEN

update-rc.d vncserver defaults

THEN

reboot.

FINALLY: go in there with tightvnc viewer client, and voila, blank kool aid tangerine orange screen.

any help appreciated, of course it's been 3 x 8 hour evenings so far :}
","From what I've seen, you can't turn VNC into unity. Install a different desktop environment and you'll be fine. Here's how to use xfce:"
5252,5252,8351,Show tooltip on invalid input in edit control,"I have subclassed edit control to accept only floating numbers. I would like to pop a tooltip when user makes an invalid input. The behavior I target is like the one edit control with ES_NUMBER has :



So far I was able to implement tracking tooltip and display it when user makes invalid input.

However, the tooltip is misplaced. I have tried to use ScreenToClient and ClientToScreen to fix this but have failed.

Here are the instructions for creating SCCE :

1) Create default Win32 project in Visual Studio.

2) Add the following includes in your stdafx.h, just under #include &lt;windows.h&gt; :

#include &lt;windowsx.h&gt;
#include &lt;commctrl.h&gt;

#pragma comment( lib, ""comctl32.lib"")

#pragma comment(linker, \
    ""\""/manifestdependency:type='Win32' ""\
    ""name='Microsoft.Windows.Common-Controls' ""\
    ""version='6.0.0.0' ""\
    ""processorArchitecture='*' ""\
    ""publicKeyToken='6595b64144ccf1df' ""\
    ""language='*'\"""")


3) Add these global variables:

HWND g_hwndTT;
TOOLINFO g_ti;


4) Here is a simple subclass procedure for edit controls ( just for testing purposes ) :

LRESULT CALLBACK EditSubProc ( HWND hwnd, UINT message, 
    WPARAM wParam, LPARAM lParam, 
    UINT_PTR uIdSubclass, DWORD_PTR dwRefData )
{
    switch (message)
    {
    case WM_CHAR:
        {
            POINT pt;
            if( ! isdigit( wParam ) )  // if not a number pop a tooltip!
            {
                if (GetCaretPos(&amp;pt))  // here comes the problem
                {
                    // coordinates are not good, so tooltip is misplaced
                    ClientToScreen( hwnd, &amp;pt );


                    /************************** EDIT #1 ****************************/
                    /******* If I delete this line x-coordinate is OK *************/
                    /*** y-coordinate should be little lower, but it is still OK **/
                    /**************************************************************/

                    ScreenToClient( GetParent(hwnd), &amp;pt );

                    /************************* Edit #2 ****************************/

                    // this adjusts the y-coordinate, see the second edit
                    RECT rcClientRect;
                    Edit_GetRect( hwnd, &amp;rcClientRect );
                    pt.y = rcClientRect.bottom;

                    /**************************************************************/

                    SendMessage(g_hwndTT, TTM_TRACKACTIVATE, 
                        TRUE, (LPARAM)&amp;g_ti);
                    SendMessage(g_hwndTT, TTM_TRACKPOSITION, 
                        0, MAKELPARAM(pt.x, pt.y));
                }
                return FALSE;
            }
            else
            {
                SendMessage(g_hwndTT, TTM_TRACKACTIVATE, 
                    FALSE, (LPARAM)&amp;g_ti);
                return ::DefSubclassProc( hwnd, message, wParam, lParam );
            }
        }
        break;
    case WM_NCDESTROY:
        ::RemoveWindowSubclass( hwnd, EditSubProc, 0 );
        return DefSubclassProc( hwnd, message, wParam, lParam);
        break;
    }
    return DefSubclassProc( hwnd, message, wParam, lParam);
} 


5) Add the following WM_CREATE handler :

case WM_CREATE:
    {
        HWND hEdit = CreateWindowEx( 0, L""EDIT"", L""edit"", WS_CHILD | WS_VISIBLE |
            WS_BORDER | ES_CENTER, 150, 150, 100, 30, hWnd, (HMENU)1000, hInst, 0 );

        // try with tooltip
        g_hwndTT = CreateWindow(TOOLTIPS_CLASS, NULL,
            WS_POPUP | TTS_ALWAYSTIP | TTS_BALLOON,
            0, 0, 0, 0, hWnd, NULL, hInst, NULL);

        if( !g_hwndTT )
            MessageBeep(0);  // just to signal error somehow

        g_ti.cbSize = sizeof(TOOLINFO);
        g_ti.uFlags = TTF_TRACK | TTF_ABSOLUTE;
        g_ti.hwnd = hWnd;
        g_ti.hinst = hInst;
        g_ti.lpszText = TEXT(""Hi there"");

        if( ! SendMessage(g_hwndTT, TTM_ADDTOOL, 0, (LPARAM)&amp;g_ti) )
            MessageBeep(0);  // just to have some error signal

        // subclass edit control
        SetWindowSubclass( hEdit, EditSubProc, 0, 0 );
    }
    return 0L;  


6) Initialize common controls in MyRegisterClass ( before return statement ) :

// initialize common controls
INITCOMMONCONTROLSEX iccex;
iccex.dwSize = sizeof(INITCOMMONCONTROLSEX);
iccex.dwICC = ICC_BAR_CLASSES | ICC_WIN95_CLASSES | 
    ICC_TAB_CLASSES | ICC_TREEVIEW_CLASSES | ICC_STANDARD_CLASSES ;

if( !InitCommonControlsEx(&amp;iccex) ) 
    MessageBeep(0);   // signal error 


That's it, for the SSCCE.

My questions are following :


How can I properly position tooltip in my main window? How should I manipulate with caret coordinates?
Is there a way for tooltip handle and toolinfo structure to not be global?


Thank you for your time.

Best regards. 

EDIT #1:

I have managed to achieve quite an improvement by deleting ScreenToClient call in the subclass procedure. The x-coordinate is good, y-coordinate could be slightly lower. I still would like to remove global variables somehow...

EDIT #2:

I was able to adjust y-coordinate by using EM_GETRECT message and setting y-coordinate to the bottom of the formatting rectangle:

RECT rcClientRect;
Edit_GetRect( hwnd, &amp;rcClientRect );
pt.y = rcClient.bottom;


Now the end-result is much better. All that is left is to remove global variables...

EDIT #3:

It seems that I have cracked it! The solution is in EM_SHOWBALLOONTIP and EM_HIDEBALLOONTIP messages! Tooltip is placed at the caret position, ballon shape is the same as the one on the picture, and it auto-dismisses itself properly. And the best thing is that I do not need global variables!

Here is my subclass procedure snippet:

case WM_CHAR:
{
    // whatever... This condition is for testing purpose only
    if( ! IsCharAlpha( wParam ) &amp;&amp; IsCharAlphaNumeric( wParam ) )
    {
        SendMessage(hwnd, EM_HIDEBALLOONTIP, 0, 0);
        return ::DefSubclassProc( hwnd, message, wParam, lParam );
    }
    else
    {
        EDITBALLOONTIP ebt;

        ebt.cbStruct = sizeof( EDITBALLOONTIP );
        ebt.pszText = L"" Tooltip text! "";
        ebt.pszTitle = L"" Tooltip title!!! "";
        ebt.ttiIcon = TTI_ERROR_LARGE;    // tooltip icon

        SendMessage(hwnd, EM_SHOWBALLOONTIP, 0, (LPARAM)&amp;ebt);

        return FALSE;
    }
 }
 break;

",AlwaysLearningNewStuff,https://stackoverflow.com/users/2676466,"As a follow-up to comments regarding the use of the SetProp function to remove the need to hold onto a pair of globals for the tool-tip data, I present the following solution.

Note: By error-checking on calls to GetProp, I've designed a WndProc for the subclassed edit control that would function regardless of whether or not it was desired to make use of tool-tips. If the property isn't found, I simply omit any tool-tip handling code.

Note 2: One downside to all of the available approaches to making the tooltip info non-global is that it introduces coupling between the subclassed WndProc and the parent window's wndProc.


By using dwRefData, one must check that it holds a non-NULL
pointer.
By using SetWindowLongPtr, one must remember an index into the
user-data.
By using SetProp, one must remember a textual property name. I find
this easier.


Removing the call to SetProp removes the tool-tip functionality. I.e you could use the same subclassed wndProc for edit controls whether they took advantage of tooltips or not.

Anyhoo, on with the (Code::Blocks) code.

#define _WIN32_IE 0x0500
#define _WIN32_WINNT 0x0501

#if defined(UNICODE) &amp;&amp; !defined(_UNICODE)
    #define _UNICODE
#elif defined(_UNICODE) &amp;&amp; !defined(UNICODE)
    #define UNICODE
#endif

#include &lt;tchar.h&gt;
#include &lt;windows.h&gt;
#include &lt;windowsx.h&gt;
#include &lt;commctrl.h&gt;
#include &lt;ctype.h&gt;
#include &lt;cstdio&gt;

/*  Declare Windows procedure  */
LRESULT CALLBACK WindowProcedure (HWND, UINT, WPARAM, LPARAM);

/*  Make the class name into a global variable  */
TCHAR szClassName[ ] = _T(""CodeBlocksWindowsApp"");



HWND g_hwndTT;
TOOLINFO g_ti;
typedef struct mToolTipInfo
{
    HWND hwnd;
    TOOLINFO tInfo;
} * p_mToolTipInfo;


LRESULT CALLBACK EditSubProc ( HWND hwnd, UINT message,
    WPARAM wParam, LPARAM lParam,
    UINT_PTR uIdSubclass, DWORD_PTR dwRefData )
{
    p_mToolTipInfo tmp = (p_mToolTipInfo)GetProp(hwnd, _T(""tipData""));

    switch (message)
    {
    case WM_CHAR:
        {
            POINT pt;

            if( ! isdigit( wParam ) )  // if not a number pop a tooltip!
            {
                if (GetCaretPos(&amp;pt))  // here comes the problem
                {
                    // coordinates are not good, so tooltip is misplaced
                    ClientToScreen( hwnd, &amp;pt );

                    RECT lastCharRect;
                    lastCharRect.left = lastCharRect.top = 0;
                    lastCharRect.right = lastCharRect.bottom = 32;

                    HDC editHdc;
                    char lastChar;
                    int charHeight, charWidth;

                    lastChar = (char)wParam;
                    editHdc = GetDC(hwnd);
                    charHeight = DrawText(editHdc, &amp;lastChar, 1, &amp;lastCharRect, DT_CALCRECT);
                    charWidth = lastCharRect.right;
                    ReleaseDC(hwnd, editHdc);

                    //pt.x += xOfs + charWidth; // invalid char isn't drawn, so no need to advance xPos to reflect width of last char
                    pt.y += charHeight;

                    if (tmp)
                    {
                        SendMessage(tmp-&gt;hwnd, TTM_TRACKACTIVATE, TRUE, (LPARAM)&amp;tmp-&gt;tInfo);
                        SendMessage(tmp-&gt;hwnd, TTM_TRACKPOSITION, 0, MAKELPARAM(pt.x, pt.y));
                    }
                }
                return FALSE;
            }
            else
            {
                if (tmp)
                    SendMessage(tmp-&gt;hwnd, TTM_TRACKACTIVATE,
                    FALSE, (LPARAM)&amp;tmp-&gt;tInfo  );
                return ::DefSubclassProc( hwnd, message, wParam, lParam );
            }
        }
        break;

    case WM_DESTROY:
        {
            p_mToolTipInfo tmp = (p_mToolTipInfo)GetProp(hwnd, _T(""tipData""));
            if (tmp)
            {
                delete(tmp);
                RemoveProp(hwnd, _T(""tipData""));
            }
        }
        return 0;

    case WM_NCDESTROY:
        ::RemoveWindowSubclass( hwnd, EditSubProc, 0 );
        return DefSubclassProc( hwnd, message, wParam, lParam);
        break;
    }
    return DefSubclassProc( hwnd, message, wParam, lParam);
}






HINSTANCE hInst;

int WINAPI WinMain (HINSTANCE hThisInstance,
                     HINSTANCE hPrevInstance,
                     LPSTR lpszArgument,
                     int nCmdShow)
{
    HWND hwnd;               /* This is the handle for our window */
    MSG messages;            /* Here messages to the application are saved */
    WNDCLASSEX wincl;        /* Data structure for the windowclass */

    /* The Window structure */
    wincl.hInstance = hThisInstance;
    wincl.lpszClassName = szClassName;
    wincl.lpfnWndProc = WindowProcedure;      /* This function is called by windows */
    wincl.style = CS_DBLCLKS;                 /* Catch double-clicks */
    wincl.cbSize = sizeof (WNDCLASSEX);

    /* Use default icon and mouse-pointer */
    wincl.hIcon = LoadIcon (NULL, IDI_APPLICATION);
    wincl.hIconSm = LoadIcon (NULL, IDI_APPLICATION);
    wincl.hCursor = LoadCursor (NULL, IDC_ARROW);
    wincl.lpszMenuName = NULL;                 /* No menu */
    wincl.cbClsExtra = 0;                      /* No extra bytes after the window class */
    wincl.cbWndExtra = 0;                      /* structure or the window instance */
    /* Use Windows's default colour as the background of the window */
    wincl.hbrBackground = (HBRUSH) COLOR_BACKGROUND;

    /* Register the window class, and if it fails quit the program */
    if (!RegisterClassEx (&amp;wincl))
        return 0;

    /* The class is registered, let's create the program*/
    hwnd = CreateWindowEx (
           0,                   /* Extended possibilites for variation */
           szClassName,         /* Classname */
           _T(""Code::Blocks Template Windows App""),       /* Title Text */
           WS_OVERLAPPEDWINDOW, /* default window */
           CW_USEDEFAULT,       /* Windows decides the position */
           CW_USEDEFAULT,       /* where the window ends up on the screen */
           544,                 /* The programs width */
           375,                 /* and height in pixels */
           HWND_DESKTOP,        /* The window is a child-window to desktop */
           NULL,                /* No menu */
           hThisInstance,       /* Program Instance handler */
           NULL                 /* No Window Creation data */
           );

    /* Make the window visible on the screen */
    ShowWindow (hwnd, nCmdShow);

    /* Run the message loop. It will run until GetMessage() returns 0 */
    while (GetMessage (&amp;messages, NULL, 0, 0))
    {
        /* Translate virtual-key messages into character messages */
        TranslateMessage(&amp;messages);
        /* Send message to WindowProcedure */
        DispatchMessage(&amp;messages);
    }

    /* The program return-value is 0 - The value that PostQuitMessage() gave */
    return messages.wParam;
}


/*  This function is called by the Windows function DispatchMessage()  */
LRESULT CALLBACK WindowProcedure (HWND hWnd, UINT message, WPARAM wParam, LPARAM lParam)
{
    switch (message)                  /* handle the messages */
    {
        case WM_CREATE:
        {
            HWND hEdit = CreateWindowEx( 0, _T(""EDIT""), _T(""edit""), WS_CHILD | WS_VISIBLE |
                WS_BORDER | ES_CENTER, 150, 150, 100, 30, hWnd, (HMENU)1000, hInst, 0 );

            p_mToolTipInfo tmp = new mToolTipInfo;
            SetProp(hEdit, _T(""tipData""), tmp);

            // try with tooltip
            //g_hwndTT = CreateWindow(TOOLTIPS_CLASS, NULL,
            tmp-&gt;hwnd = CreateWindow(TOOLTIPS_CLASS, NULL,
                WS_POPUP | TTS_ALWAYSTIP | TTS_BALLOON,
                0, 0, 0, 0, hWnd, NULL, hInst, NULL);

            //if( !g_hwndTT )
            if( !tmp-&gt;hwnd )
                MessageBeep(0);  // just to signal error somehow

//            g_ti.cbSize = sizeof(TOOLINFO);
//            g_ti.uFlags = TTF_TRACK | TTF_ABSOLUTE;
//            g_ti.hwnd = hWnd;
//            g_ti.hinst = hInst;
//            g_ti.lpszText = _T(""Hi there"");
            tmp-&gt;tInfo.cbSize = sizeof(TOOLINFO);
            tmp-&gt;tInfo.uFlags = TTF_TRACK | TTF_ABSOLUTE;
            tmp-&gt;tInfo.hwnd = hWnd;
            tmp-&gt;tInfo.hinst = hInst;
            tmp-&gt;tInfo.lpszText = _T(""Hi there"");

//            if( ! SendMessage(g_hwndTT, TTM_ADDTOOL, 0, (LPARAM)&amp;g_ti) )
            if( ! SendMessage(tmp-&gt;hwnd, TTM_ADDTOOL, 0, (LPARAM)&amp;tmp-&gt;tInfo) )
                MessageBeep(0);  // just to have some error signal

            // subclass edit control
            SetWindowSubclass( hEdit, EditSubProc, 0, 0 );
        }
        return 0L;

        case WM_DESTROY:
            PostQuitMessage (0);       /* send a WM_QUIT to the message queue */
            break;
        default:                      /* for messages that we don't deal with */
            return DefWindowProc (hWnd, message, wParam, lParam);
    }

    return 0;
}

",enhzflep,https://stackoverflow.com/users/1630963,http://stackoverflow.com/questions/23892594/show-tooltip-on-invalid-input-in-edit-control,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.3333333333333333,0.0,0.5,1.0,1.0,0.4444444444444444,0.3333333333333333,0.6666666666666666,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.0,0.7777777777777778,0.7777777777777778,0.8333333333333334,0.8888888888888888,1.0,0.8666666666666666,0.6666666666666666,0.3333333333333333,0.6666666666666666,1.0,Show tooltips for invalid input in the edit control,"I have subclassed edit control to accept only floating numbers. I would like to pop a tooltip when user makes an invalid input. The behavior I target is like the one edit control with ES_NUMBER has :



So far I was able to implement tracking tooltip and display it when user makes invalid input.

However, the tooltip is misplaced. I have tried to use ScreenToClient and ClientToScreen to fix this but have failed.

Here are the instructions for creating SCCE :

1) Create default Win32 project in Visual Studio.

2) Add the following includes in your stdafx.h, just under #include &lt;windows.h&gt; :

#include &lt;windowsx.h&gt;
#include &lt;commctrl.h&gt;

#pragma comment( lib, ""comctl32.lib"")

#pragma comment(linker, \
    ""\""/manifestdependency:type='Win32' ""\
    ""name='Microsoft.Windows.Common-Controls' ""\
    ""version='6.0.0.0' ""\
    ""processorArchitecture='*' ""\
    ""publicKeyToken='6595b64144ccf1df' ""\
    ""language='*'\"""")


3) Add these global variables:

HWND g_hwndTT;
TOOLINFO g_ti;


4) Here is a simple subclass procedure for edit controls ( just for testing purposes ) :

LRESULT CALLBACK EditSubProc ( HWND hwnd, UINT message, 
    WPARAM wParam, LPARAM lParam, 
    UINT_PTR uIdSubclass, DWORD_PTR dwRefData )
{
    switch (message)
    {
    case WM_CHAR:
        {
            POINT pt;
            if( ! isdigit( wParam ) )  // if not a number pop a tooltip!
            {
                if (GetCaretPos(&amp;pt))  // here comes the problem
                {
                    // coordinates are not good, so tooltip is misplaced
                    ClientToScreen( hwnd, &amp;pt );


                    /************************** EDIT #1 ****************************/
                    /******* If I delete this line x-coordinate is OK *************/
                    /*** y-coordinate should be little lower, but it is still OK **/
                    /**************************************************************/

                    ScreenToClient( GetParent(hwnd), &amp;pt );

                    /************************* Edit #2 ****************************/

                    // this adjusts the y-coordinate, see the second edit
                    RECT rcClientRect;
                    Edit_GetRect( hwnd, &amp;rcClientRect );
                    pt.y = rcClientRect.bottom;

                    /**************************************************************/

                    SendMessage(g_hwndTT, TTM_TRACKACTIVATE, 
                        TRUE, (LPARAM)&amp;g_ti);
                    SendMessage(g_hwndTT, TTM_TRACKPOSITION, 
                        0, MAKELPARAM(pt.x, pt.y));
                }
                return FALSE;
            }
            else
            {
                SendMessage(g_hwndTT, TTM_TRACKACTIVATE, 
                    FALSE, (LPARAM)&amp;g_ti);
                return ::DefSubclassProc( hwnd, message, wParam, lParam );
            }
        }
        break;
    case WM_NCDESTROY:
        ::RemoveWindowSubclass( hwnd, EditSubProc, 0 );
        return DefSubclassProc( hwnd, message, wParam, lParam);
        break;
    }
    return DefSubclassProc( hwnd, message, wParam, lParam);
} 


5) Add the following WM_CREATE handler :

case WM_CREATE:
    {
        HWND hEdit = CreateWindowEx( 0, L""EDIT"", L""edit"", WS_CHILD | WS_VISIBLE |
            WS_BORDER | ES_CENTER, 150, 150, 100, 30, hWnd, (HMENU)1000, hInst, 0 );

        // try with tooltip
        g_hwndTT = CreateWindow(TOOLTIPS_CLASS, NULL,
            WS_POPUP | TTS_ALWAYSTIP | TTS_BALLOON,
            0, 0, 0, 0, hWnd, NULL, hInst, NULL);

        if( !g_hwndTT )
            MessageBeep(0);  // just to signal error somehow

        g_ti.cbSize = sizeof(TOOLINFO);
        g_ti.uFlags = TTF_TRACK | TTF_ABSOLUTE;
        g_ti.hwnd = hWnd;
        g_ti.hinst = hInst;
        g_ti.lpszText = TEXT(""Hi there"");

        if( ! SendMessage(g_hwndTT, TTM_ADDTOOL, 0, (LPARAM)&amp;g_ti) )
            MessageBeep(0);  // just to have some error signal

        // subclass edit control
        SetWindowSubclass( hEdit, EditSubProc, 0, 0 );
    }
    return 0L;  


6) Initialize common controls in MyRegisterClass ( before return statement ) :

// initialize common controls
INITCOMMONCONTROLSEX iccex;
iccex.dwSize = sizeof(INITCOMMONCONTROLSEX);
iccex.dwICC = ICC_BAR_CLASSES | ICC_WIN95_CLASSES | 
    ICC_TAB_CLASSES | ICC_TREEVIEW_CLASSES | ICC_STANDARD_CLASSES ;

if( !InitCommonControlsEx(&amp;iccex) ) 
    MessageBeep(0);   // signal error 


That's it, for the SSCCE.

My questions are following :


How can I properly position tooltip in my main window? How should I manipulate with caret coordinates?
Is there a way for tooltip handle and toolinfo structure to not be global?


Thank you for your time.

Best regards. 

EDIT #1:

I have managed to achieve quite an improvement by deleting ScreenToClient call in the subclass procedure. The x-coordinate is good, y-coordinate could be slightly lower. I still would like to remove global variables somehow...

EDIT #2:

I was able to adjust y-coordinate by using EM_GETRECT message and setting y-coordinate to the bottom of the formatting rectangle:

RECT rcClientRect;
Edit_GetRect( hwnd, &amp;rcClientRect );
pt.y = rcClient.bottom;


Now the end-result is much better. All that is left is to remove global variables...

EDIT #3:

It seems that I have cracked it! The solution is in EM_SHOWBALLOONTIP and EM_HIDEBALLOONTIP messages! Tooltip is placed at the caret position, ballon shape is the same as the one on the picture, and it auto-dismisses itself properly. And the best thing is that I do not need global variables!

Here is my subclass procedure snippet:

case WM_CHAR:
{
    // whatever... This condition is for testing purpose only
    if( ! IsCharAlpha( wParam ) &amp;&amp; IsCharAlphaNumeric( wParam ) )
    {
        SendMessage(hwnd, EM_HIDEBALLOONTIP, 0, 0);
        return ::DefSubclassProc( hwnd, message, wParam, lParam );
    }
    else
    {
        EDITBALLOONTIP ebt;

        ebt.cbStruct = sizeof( EDITBALLOONTIP );
        ebt.pszText = L"" Tooltip text! "";
        ebt.pszTitle = L"" Tooltip title!!! "";
        ebt.ttiIcon = TTI_ERROR_LARGE;    // tooltip icon

        SendMessage(hwnd, EM_SHOWBALLOONTIP, 0, (LPARAM)&amp;ebt);

        return FALSE;
    }
 }
 break;

","As a follow-up to comments regarding the use of the SetProp function to remove the need to hold onto a pair of globals for the tool-tip data, I present the following solution.

Note: By error-checking on calls to GetProp, I've designed a WndProc for the subclassed edit control that would function regardless of whether or not it was desired to make use of tool-tips. If the property isn't found, I simply omit any tool-tip handling code.

Note 2: One downside to all of the available approaches to making the tooltip info non-global is that it introduces coupling between the subclassed WndProc and the parent window's wndProc.


By using dwRefData, one must check that it holds a non-NULL
pointer.
By using SetWindowLongPtr, one must remember an index into the
user-data.
By using SetProp, one must remember a textual property name. I find
this easier.


Removing the call to SetProp removes the tool-tip functionality. I.e you could use the same subclassed wndProc for edit controls whether they took advantage of tooltips or not.

Anyhoo, on with the (Code::Blocks) code.

#define _WIN32_IE 0x0500
#define _WIN32_WINNT 0x0501

#if defined(UNICODE) &amp;&amp; !defined(_UNICODE)
    #define _UNICODE
#elif defined(_UNICODE) &amp;&amp; !defined(UNICODE)
    #define UNICODE
#endif

#include &lt;tchar.h&gt;
#include &lt;windows.h&gt;
#include &lt;windowsx.h&gt;
#include &lt;commctrl.h&gt;
#include &lt;ctype.h&gt;
#include &lt;cstdio&gt;

/*  Declare Windows procedure  */
LRESULT CALLBACK WindowProcedure (HWND, UINT, WPARAM, LPARAM);

/*  Make the class name into a global variable  */
TCHAR szClassName[ ] = _T(""CodeBlocksWindowsApp"");



HWND g_hwndTT;
TOOLINFO g_ti;
typedef struct mToolTipInfo
{
    HWND hwnd;
    TOOLINFO tInfo;
} * p_mToolTipInfo;


LRESULT CALLBACK EditSubProc ( HWND hwnd, UINT message,
    WPARAM wParam, LPARAM lParam,
    UINT_PTR uIdSubclass, DWORD_PTR dwRefData )
{
    p_mToolTipInfo tmp = (p_mToolTipInfo)GetProp(hwnd, _T(""tipData""));

    switch (message)
    {
    case WM_CHAR:
        {
            POINT pt;

            if( ! isdigit( wParam ) )  // if not a number pop a tooltip!
            {
                if (GetCaretPos(&amp;pt))  // here comes the problem
                {
                    // coordinates are not good, so tooltip is misplaced
                    ClientToScreen( hwnd, &amp;pt );

                    RECT lastCharRect;
                    lastCharRect.left = lastCharRect.top = 0;
                    lastCharRect.right = lastCharRect.bottom = 32;

                    HDC editHdc;
                    char lastChar;
                    int charHeight, charWidth;

                    lastChar = (char)wParam;
                    editHdc = GetDC(hwnd);
                    charHeight = DrawText(editHdc, &amp;lastChar, 1, &amp;lastCharRect, DT_CALCRECT);
                    charWidth = lastCharRect.right;
                    ReleaseDC(hwnd, editHdc);

                    //pt.x += xOfs + charWidth; // invalid char isn't drawn, so no need to advance xPos to reflect width of last char
                    pt.y += charHeight;

                    if (tmp)
                    {
                        SendMessage(tmp-&gt;hwnd, TTM_TRACKACTIVATE, TRUE, (LPARAM)&amp;tmp-&gt;tInfo);
                        SendMessage(tmp-&gt;hwnd, TTM_TRACKPOSITION, 0, MAKELPARAM(pt.x, pt.y));
                    }
                }
                return FALSE;
            }
            else
            {
                if (tmp)
                    SendMessage(tmp-&gt;hwnd, TTM_TRACKACTIVATE,
                    FALSE, (LPARAM)&amp;tmp-&gt;tInfo  );
                return ::DefSubclassProc( hwnd, message, wParam, lParam );
            }
        }
        break;

    case WM_DESTROY:
        {
            p_mToolTipInfo tmp = (p_mToolTipInfo)GetProp(hwnd, _T(""tipData""));
            if (tmp)
            {
                delete(tmp);
                RemoveProp(hwnd, _T(""tipData""));
            }
        }
        return 0;

    case WM_NCDESTROY:
        ::RemoveWindowSubclass( hwnd, EditSubProc, 0 );
        return DefSubclassProc( hwnd, message, wParam, lParam);
        break;
    }
    return DefSubclassProc( hwnd, message, wParam, lParam);
}






HINSTANCE hInst;

int WINAPI WinMain (HINSTANCE hThisInstance,
                     HINSTANCE hPrevInstance,
                     LPSTR lpszArgument,
                     int nCmdShow)
{
    HWND hwnd;               /* This is the handle for our window */
    MSG messages;            /* Here messages to the application are saved */
    WNDCLASSEX wincl;        /* Data structure for the windowclass */

    /* The Window structure */
    wincl.hInstance = hThisInstance;
    wincl.lpszClassName = szClassName;
    wincl.lpfnWndProc = WindowProcedure;      /* This function is called by windows */
    wincl.style = CS_DBLCLKS;                 /* Catch double-clicks */
    wincl.cbSize = sizeof (WNDCLASSEX);

    /* Use default icon and mouse-pointer */
    wincl.hIcon = LoadIcon (NULL, IDI_APPLICATION);
    wincl.hIconSm = LoadIcon (NULL, IDI_APPLICATION);
    wincl.hCursor = LoadCursor (NULL, IDC_ARROW);
    wincl.lpszMenuName = NULL;                 /* No menu */
    wincl.cbClsExtra = 0;                      /* No extra bytes after the window class */
    wincl.cbWndExtra = 0;                      /* structure or the window instance */
    /* Use Windows's default colour as the background of the window */
    wincl.hbrBackground = (HBRUSH) COLOR_BACKGROUND;

    /* Register the window class, and if it fails quit the program */
    if (!RegisterClassEx (&amp;wincl))
        return 0;

    /* The class is registered, let's create the program*/
    hwnd = CreateWindowEx (
           0,                   /* Extended possibilites for variation */
           szClassName,         /* Classname */
           _T(""Code::Blocks Template Windows App""),       /* Title Text */
           WS_OVERLAPPEDWINDOW, /* default window */
           CW_USEDEFAULT,       /* Windows decides the position */
           CW_USEDEFAULT,       /* where the window ends up on the screen */
           544,                 /* The programs width */
           375,                 /* and height in pixels */
           HWND_DESKTOP,        /* The window is a child-window to desktop */
           NULL,                /* No menu */
           hThisInstance,       /* Program Instance handler */
           NULL                 /* No Window Creation data */
           );

    /* Make the window visible on the screen */
    ShowWindow (hwnd, nCmdShow);

    /* Run the message loop. It will run until GetMessage() returns 0 */
    while (GetMessage (&amp;messages, NULL, 0, 0))
    {
        /* Translate virtual-key messages into character messages */
        TranslateMessage(&amp;messages);
        /* Send message to WindowProcedure */
        DispatchMessage(&amp;messages);
    }

    /* The program return-value is 0 - The value that PostQuitMessage() gave */
    return messages.wParam;
}


/*  This function is called by the Windows function DispatchMessage()  */
LRESULT CALLBACK WindowProcedure (HWND hWnd, UINT message, WPARAM wParam, LPARAM lParam)
{
    switch (message)                  /* handle the messages */
    {
        case WM_CREATE:
        {
            HWND hEdit = CreateWindowEx( 0, _T(""EDIT""), _T(""edit""), WS_CHILD | WS_VISIBLE |
                WS_BORDER | ES_CENTER, 150, 150, 100, 30, hWnd, (HMENU)1000, hInst, 0 );

            p_mToolTipInfo tmp = new mToolTipInfo;
            SetProp(hEdit, _T(""tipData""), tmp);

            // try with tooltip
            //g_hwndTT = CreateWindow(TOOLTIPS_CLASS, NULL,
            tmp-&gt;hwnd = CreateWindow(TOOLTIPS_CLASS, NULL,
                WS_POPUP | TTS_ALWAYSTIP | TTS_BALLOON,
                0, 0, 0, 0, hWnd, NULL, hInst, NULL);

            //if( !g_hwndTT )
            if( !tmp-&gt;hwnd )
                MessageBeep(0);  // just to signal error somehow

//            g_ti.cbSize = sizeof(TOOLINFO);
//            g_ti.uFlags = TTF_TRACK | TTF_ABSOLUTE;
//            g_ti.hwnd = hWnd;
//            g_ti.hinst = hInst;
//            g_ti.lpszText = _T(""Hi there"");
            tmp-&gt;tInfo.cbSize = sizeof(TOOLINFO);
            tmp-&gt;tInfo.uFlags = TTF_TRACK | TTF_ABSOLUTE;
            tmp-&gt;tInfo.hwnd = hWnd;
            tmp-&gt;tInfo.hinst = hInst;
            tmp-&gt;tInfo.lpszText = _T(""Hi there"");

//            if( ! SendMessage(g_hwndTT, TTM_ADDTOOL, 0, (LPARAM)&amp;g_ti) )
            if( ! SendMessage(tmp-&gt;hwnd, TTM_ADDTOOL, 0, (LPARAM)&amp;tmp-&gt;tInfo) )
                MessageBeep(0);  // just to have some error signal

            // subclass edit control
            SetWindowSubclass( hEdit, EditSubProc, 0, 0 );
        }
        return 0L;

        case WM_DESTROY:
            PostQuitMessage (0);       /* send a WM_QUIT to the message queue */
            break;
        default:                      /* for messages that we don't deal with */
            return DefWindowProc (hWnd, message, wParam, lParam);
    }

    return 0;
}

"
883,883,1403,Is it ok to use self-signed certificates for smtp transport?,"By ""by ok to use"" I mean:


are MTA agents receiving emails from my server going to reject my
email
if not, are they going to make other kind of bad treatment for my
emails (marking as spam, unsafe and so...)?


...or is it just better idea to stick with non-encrypted emails?
",Miloš Đakonović,https://serverfault.com/users/178855,"Like MadHatter said, at the moment encryption using a self-signed certificate is actually a step up in comparison to many other small time SMTPs if you are talking SMTP-relaying. 

There are a few drawbacks, however, but not of the kind you expect. The most important one being your SMTP-clients choking on encryption. There are many small SMTP-clients deployed in off-the-shelf solutions for common business problems that don't like SMTP encryption and fail -- often silently! So, if you are using standard software with built-in mail clients, check them before you switch. 

Other than that I'd say, if you are concernced about your mail being marked as spam, consider setting up SPF and DKIM. That helps very much.
",bjanssen,https://serverfault.com/users/210030,http://serverfault.com/questions/579138,TECHNOLOGY,serverfault.com,1.0,0.8888888888888888,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.3333333333333333,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.6666666666666666,0.0,1.0,0.8888888888888888,Can I use a self signed certificate for SMTP transmission?,"By ""by ok to use"" I mean:


are MTA agents receiving emails from my server going to reject my
email
if not, are they going to make other kind of bad treatment for my
emails (marking as spam, unsafe and so...)?


...or is it just better idea to stick with non-encrypted emails?
","Like MadHatter said, at the moment encryption using a self-signed certificate is actually a step up in comparison to many other small time SMTPs if you are talking SMTP-relaying. 

There are a few drawbacks, however, but not of the kind you expect. The most important one being your SMTP-clients choking on encryption. There are many small SMTP-clients deployed in off-the-shelf solutions for common business problems that don't like SMTP encryption and fail -- often silently! So, if you are using standard software with built-in mail clients, check them before you switch. 

Other than that I'd say, if you are concernced about your mail being marked as spam, consider setting up SPF and DKIM. That helps very much.
"
3144,3144,5009,Demonstrating the effect of aliasing,"How does the signal look when we don't use the Nyquist rate to remove aliasing from a signal during sampling?

Let's suppose the signal is sinusoidal, with a frequency of 500&nbsp;Hz and an amplitude of 2.

signal = 2*cos(2*pi*500*t)


If I sample it, (replacing t=nTs , Ts = sampling period and n represent number of samples) and plotting the sampled signals with a different sampling period using the subplot command in MATLAB, how could I identify the aliasing in a sampled signal?

Here is the example code that plotted two signals, one at the Nyquist rate while the other less than the Nyquist rate:

A = 2;
Fmax = 10;
Fs = 2*Fmax;
n = 0:1/Fs:1;
Cont = A*sin(2*pi*(Fmax/Fs)*n);
Cont1 = A*sin(2*pi*(Fmax/18)*n);
subplot(2,1,1)
stem(n,Cont)
hold on
stem(n,Cont1)


and here is the waveform:



I wasn't able to identify the aliasing. How did it affect the signal when Nyquist rate didn't use?
",Sufiyan Ghori,https://dsp.stackexchange.com/users/1324,"I think you need to increase frequency of the size or use far larger steps in the sampling.

The aliasing does not appears if you have a very smooth function. For example, a constant function does not yield aliasing whatever sampling you use.
",Libor,https://dsp.stackexchange.com/users/1031,http://dsp.stackexchange.com/questions/2326/demonstrating-the-effect-of-aliasing,TECHNOLOGY,dsp.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,1.0,1.0,1.0,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,1.0,0.8888888888888888,0.8,0.3333333333333333,0.6666666666666666,1.0,0.8888888888888888,Demonstrate the effect of aliasing,"How does the signal look when we don't use the Nyquist rate to remove aliasing from a signal during sampling?

Let's suppose the signal is sinusoidal, with a frequency of 500&nbsp;Hz and an amplitude of 2.

signal = 2*cos(2*pi*500*t)


If I sample it, (replacing t=nTs , Ts = sampling period and n represent number of samples) and plotting the sampled signals with a different sampling period using the subplot command in MATLAB, how could I identify the aliasing in a sampled signal?

Here is the example code that plotted two signals, one at the Nyquist rate while the other less than the Nyquist rate:

A = 2;
Fmax = 10;
Fs = 2*Fmax;
n = 0:1/Fs:1;
Cont = A*sin(2*pi*(Fmax/Fs)*n);
Cont1 = A*sin(2*pi*(Fmax/18)*n);
subplot(2,1,1)
stem(n,Cont)
hold on
stem(n,Cont1)


and here is the waveform:



I wasn't able to identify the aliasing. How did it affect the signal when Nyquist rate didn't use?
","I think you need to increase frequency of the size or use far larger steps in the sampling.

The aliasing does not appears if you have a very smooth function. For example, a constant function does not yield aliasing whatever sampling you use.
"
115,115,184,Similar phrases meaning 'give kudos',"See, in one of our employee evaluation systems, we would like to implement a feature by which any employee can show appreciation to another employee that he has got help from or whom he thinks to be a good performer, mentor etc., and it has to be done every month. So, to give a name to this action, one of the suggestions was the phrase 'give kudos', but we expect to have a better one with a similar meaning. Something interesting!!

Update: It is not mandatory that we should use the word 'give' or 'kudos'! when we rephrase it.

Can anyone help me on this?
",Rajesh Omanakuttan,https://english.stackexchange.com/users/65374,"Praise

Merriam-Webster: say or write good things about (someone or something): A good teacher praises students when they do well.

Macmillan: express strong approval or admiration for someone or something, especially in public: Mayor Dixon praised the efforts of those involved in the rescue.
",vladkornea merge me,https://english.stackexchange.com/users/128688,http://english.stackexchange.com/questions/261789/similar-phrases-meaning-give-kudos,CULTURE,english.stackexchange.com,1.0,0.3333333333333333,0.0,1.0,1.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.4,0.0,0.0,0.0,1.0,"A similar phrase means ""honor to others""","Please see, in one of our employee evaluation systems, we hope to realize a function through which any employee can express his thanks to other employees who have been helped or who he thinks are excellent executors, mentors, etc., and must do so every month. So, to name this action, one of the suggestions is the word ""to honor"", but we hope to have a better one with a similar meaning. Interesting things! !","Praise

Merriam-Webster: say or write good things about (someone or something): A good teacher praises students when they do well.

Macmillan: express strong approval or admiration for someone or something, especially in public: Mayor Dixon praised the efforts of those involved in the rescue.
"
6068,6068,9631,Goalkeeper Jumping Algorithm?,"This may be a ""best way to"" question, so may be susceptible to opinion-based answers (which is ok for me). But I would also like if there are any tutorials , research papers , etc.

I'm trying to make a 3D free kick game, and I want to decide on the Goalkeeper algorithm.

Usually (and in my game) the shot is a function of direction , power and swerve. Maybe wind can be a factor too. So the shots trajectory is pre-deterministic, i.e., the point that intersects the goal (or out) plane is determined as soon as the shot fires.

So what could be a good approach for the goalkeeper to jump (or walk) ?

I have two approaches in mind :

1- determine the point, and jump to there. 
2- when the ball is closer than a threshold distance, estimate the point by the ball's velocity vector, and jump to there.

The problem with the first approach is, goalkeeper will always save the shot, which I want to prevent. So there should be some kind of randomness, or the goalkeeper's ability to jump and walk will be restricted.

The problem with the second approach is, when there is a high amount of swerve, the goalkeeper will always fail to save the shot.

So how could these approaches be better?

Thanks for any help !

Edit:

if you want to play the game, click here
",jeff,https://gamedev.stackexchange.com/users/32639,"My team is working in a Football MMO and our approach is to attribute goal keepers (and other players) with several attributes, such as JUMP, PHYSIQUE, AGILITY, REACTION, REASON, POSITIONING, to name a few. The probability to perform a task is then a weighted sum of the attributes of the player related to that task. In your case, the task is to defend the shoot. You can model this as simple or complex as you like, depending on the quantity of skills used. You can also save presets of the skills set and use them depending on the difficulty, for example. Finally, to get some randomness, just simulate a dice and use it to check if the returned value is within the probability threshold. If it is, the shoot is defended. If not, it is a goal.   
",dsilva.vinicius,https://gamedev.stackexchange.com/users/34631,http://gamedev.stackexchange.com/questions/66769/goalkeeper-jumping-algorithm,TECHNOLOGY,gamedev.stackexchange.com,0.7777777777777778,0.4444444444444444,0.0,0.0,1.0,0.0,0.6666666666666666,0.4444444444444444,0.3333333333333333,0.0,0.6666666666666666,0.0,0.3333333333333333,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.0,1.0,1.0,0.5555555555555556,1.0,0.8888888888888888,0.7333333333333333,0.3333333333333333,0.3333333333333333,1.0,1.0,Goalkeeper jumping algorithm?,"This may be a ""best way to"" question, so may be susceptible to opinion-based answers (which is ok for me). But I would also like if there are any tutorials , research papers , etc.

I'm trying to make a 3D free kick game, and I want to decide on the Goalkeeper algorithm.

Usually (and in my game) the shot is a function of direction , power and swerve. Maybe wind can be a factor too. So the shots trajectory is pre-deterministic, i.e., the point that intersects the goal (or out) plane is determined as soon as the shot fires.

So what could be a good approach for the goalkeeper to jump (or walk) ?

I have two approaches in mind :

1- determine the point, and jump to there. 
2- when the ball is closer than a threshold distance, estimate the point by the ball's velocity vector, and jump to there.

The problem with the first approach is, goalkeeper will always save the shot, which I want to prevent. So there should be some kind of randomness, or the goalkeeper's ability to jump and walk will be restricted.

The problem with the second approach is, when there is a high amount of swerve, the goalkeeper will always fail to save the shot.

So how could these approaches be better?

Thanks for any help !

Edit:

if you want to play the game, click here
","My team is working in a football MMO. Our approach is to give goalkeepers (and other players) several attributes, such as jumping, physique, agility, reaction, rationality, positioning and so on. Then, the probability of executing a task is the weighted sum of the player's attributes related to the task. For you, the task is to defend and shoot. Depending on the number of skills you use, you can model them as simple or complex as you like. For example, you can also save presets for skill sets and use them based on difficulty. Finally, to get some randomness, just simulate a die and use it to check whether the return value is within the probability threshold. If so, we have to defend the shooting. If not, it's a goal."
1173,1173,1844,Are human males and females more genetically different than members of other species?,"I'm looking at this Ted talk about a Saudi Arabia woman who dared to drive a car in the last few years. This reminds me that until the last century or so, women (all over the world?) enjoyed less rights and might've been pigeonholed into roles predetermined by society. Those roles might've encouraged certain traits, and discouraged others. Those who did not conform might've been punished, like the woman in the talk above received death threats and was jailed.

This sounds to me like selective pressure, did it really exist, and did it have any effect on the genetics/traits of modern women?

This makes me interested in the question - compared to other species, are men and women more genetically different because of selective pressure put on women to conform to male-dominated world for thousands of years before 19th century?
",Alex Stone,https://biology.stackexchange.com/users/577,"Essentially, what makes a (mammalian) man a man is a small region on the Y-chromosome called SRY. If this region is deleted, a female phenotype having XY-chromosomes develops. If this region is translocated to an X-chromosome, a male phenotype with two X-chromosomes develops. Other than that, the Y-chromosome does not carry a lot of genes.

So apart from the Y chromosome, males and females are genetically very similar and more similar compared to other species.
",Eekhoorn,https://biology.stackexchange.com/users/852,http://biology.stackexchange.com/questions/8816/are-human-males-and-females-more-genetically-different-than-members-of-other-spe,SCIENCE,biology.stackexchange.com,1.0,0.7777777777777778,0.6666666666666666,0.0,1.0,0.0,0.8888888888888888,0.8888888888888888,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.8888888888888888,0.8888888888888888,0.4444444444444444,0.8888888888888888,0.8888888888888888,0.6666666666666667,0.0,0.0,1.0,1.0,Are men and women genetically different from members of other species?,"I'm reading this Ted speech about a Saudi woman who has dared to drive in the past few years. This reminds me that until the last century or so, women (the world?) Having fewer rights may be divided into social predetermined roles. These characters may encourage certain traits and discourage others. Those who do not comply may be punished, like the woman in the conversation above, by death threats and imprisonment.","Essentially, what makes a (mammalian) man a man is a small region on the Y-chromosome called SRY. If this region is deleted, a female phenotype having XY-chromosomes develops. If this region is translocated to an X-chromosome, a male phenotype with two X-chromosomes develops. Other than that, the Y-chromosome does not carry a lot of genes.

So apart from the Y chromosome, males and females are genetically very similar and more similar compared to other species.
"
4658,4658,7382,"'Trying to help someone, but the other party doesn't appreciate it'","What is a word that best describes trying to help someone, but the other party doesn't appreciate it?  

I'm looking for a word.  
",yuritsuki,https://english.stackexchange.com/users/21921,"unrequited  


  (of a feeling, especially love) not returned: Scion shared his wishes to learn more of the world first-hand to Kara unrequitedly.  


Though more commonly used in the context of, and paired with, love, the basic definition applies to any feeling or action, or even an object perhaps.  

Braden, Abraham Lincoln, Public Speaker, p.94


  Yet, if God wills that it continue, until all the wealth piled by the bondsman's two hundred and fifty years of unrequited toil shall be sunk, and until every drop of blood drawn with the lash, shall be paid by another drawn with the sword, &hellip;


Shoup, Public Finance, p.145  


  Types of unrequitted payment: Payments not made for a consideration are unrequited payments. When paid by the government to the private sector, they are subsidies or welfare payments. 

",Kris,https://english.stackexchange.com/users/14666,http://english.stackexchange.com/questions/149521/trying-to-help-someone-but-the-other-party-doesnt-appreciate-it,CULTURE,english.stackexchange.com,1.0,0.4444444444444444,0.0,1.0,0.3333333333333333,0.5,0.5555555555555556,0.6666666666666666,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.6666666666666666,0.7777777777777778,0.8333333333333334,0.8888888888888888,0.8888888888888888,0.6666666666666667,0.0,0.0,0.3333333333333333,0.8888888888888888,"""Want to help others, but they don't appreciate it""","What's the best word to describe trying to help others, but they don't appreciate it?","unrequited  


  (of a feeling, especially love) not returned: Scion shared his wishes to learn more of the world first-hand to Kara unrequitedly.  


Though more commonly used in the context of, and paired with, love, the basic definition applies to any feeling or action, or even an object perhaps.  

Braden, Abraham Lincoln, Public Speaker, p.94


  Yet, if God wills that it continue, until all the wealth piled by the bondsman's two hundred and fifty years of unrequited toil shall be sunk, and until every drop of blood drawn with the lash, shall be paid by another drawn with the sword, &hellip;


Shoup, Public Finance, p.145  


  Types of unrequitted payment: Payments not made for a consideration are unrequited payments. When paid by the government to the private sector, they are subsidies or welfare payments. 

"
1501,1501,2364,Scrabble variation: use double and triple word scores (but not double/triple letter scores) twice?,"Is there a popular Scrabble variation that: 


lets you play double/triple word scores twice, once vertically and 
once horizontally? 
does NOT let you play double/triple letter scores twice? 


This is how I've always played, so it surprised me to learn that 
official Scrabble rules do NOT permit using double/triple word scores 
twice. 

Perhaps this was true in an older version of Scrabble (I started 
playing in the 70s). 
",barrycarter,https://boardgames.stackexchange.com/users/639,"I have certainly played Scrabble games with people that though you could re-use bonus squares, though I haven't heard of the distinction you make between word and letter bonus squares. I think this is not so much a common variation as it is a common misconception (like Free Parking in Monopoly).

I have had reasonably-good success weaning people of their attachment to this non-rule by purposely making solid blocks of tiles that have to be carefully lifted and replaced for every word I play :-)
",Mark Bessey,https://boardgames.stackexchange.com/users/1191,http://boardgames.stackexchange.com/questions/9118/scrabble-variation-use-double-and-triple-word-scores-but-not-double-triple-let,CULTURE,boardgames.stackexchange.com,1.0,0.6666666666666666,0.3333333333333333,1.0,1.0,0.6666666666666666,0.5555555555555556,0.6666666666666666,0.3333333333333333,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.7777777777777778,0.6666666666666666,0.4444444444444444,0.8888888888888888,0.8888888888888888,0.6,0.0,0.0,0.3333333333333333,0.8888888888888888,Spelling change: use two and three word scores (not two / three letter scores) twice?,"Is there a popular Scrabble variation that: 


lets you play double/triple word scores twice, once vertically and 
once horizontally? 
does NOT let you play double/triple letter scores twice? 


This is how I've always played, so it surprised me to learn that 
official Scrabble rules do NOT permit using double/triple word scores 
twice. 

Perhaps this was true in an older version of Scrabble (I started 
playing in the 70s). 
","I have certainly played Scrabble games with people that though you could re-use bonus squares, though I haven't heard of the distinction you make between word and letter bonus squares. I think this is not so much a common variation as it is a common misconception (like Free Parking in Monopoly).

I have had reasonably-good success weaning people of their attachment to this non-rule by purposely making solid blocks of tiles that have to be carefully lifted and replaced for every word I play :-)
"
2138,2138,3406,GIS Software Choice for a small university research centre,"I need to choose a GIS system for a small university research centre. We are handling a broad range of data, (for example, numerical tidal analyses, weather data, poverty, isolated economic activity, skills availability and renewable energy resource availability) and operate primarily in countries with relatively poor existing data sets. 

We interact with other groups, some of which use ARCGIS. Do I have to wade through every GIS software descriptor on the web, or can someone please give an indication of likely candidates? 
",Alan Owen,https://gis.stackexchange.com/users/8127,"Desktop

For many users, GIS means ESRI ArcGIS.  While expensive in a commercial setting, they have rather generous educational licensing, including the provision of free copies to educators for distribution to students, one per licensed seat per year.  I would advise at least ticking this box; I don't think people who learned GIS in other ways are less capable, but they might be less employable given the keyword-filtering resumes go through these days.  The extensions to ArcGIS range from basic things that should be integrated into the main application to the amusingly archaic to essential tools for a certain niche.

The OSGeo stack is an obvious addition to this, but I don't think it's yet capable of being a full replacement in desktop GIS, at least not with the usability of Arc.  Due to constant complaining about ESRI's annoyances, I tried to replace it for an entire summer with mostly QGIS, and failed.  QGIS w/ plugins + GRASS + POSTGIS can be hacked around to achieve a lot of GIS functionality, I can believe that, but for learning GIS rapidly, I wouldn't recommend it.  There are a lot of different projects under the OSGeo heading, though - in all likelihood you'll find use for some of them even if you don't touch the desktop functionality.

I'm always seeing MapInfo installations mentioned, but the one I used wasn't really mature / feature-ful in the same sense ArcGIS has been.  The user interface was lacking, so perhaps it just hid the functionality from me.

Manifold has been highly regarded as an ArcGIS competitor that is at once commercially affordable, comprehensive, and extensively higher-performance than the sometimes antiquated ArcGIS code.  They seem to be dragging their feet on updates &amp; bug-fixes in the last few years, though.  At the least, if ArcGIS fails to operate on extreme datasets, try this.

RS

Remote sensing software is its own niche, with lots of features that aren't present in the ESRI stack.  I've been exposed to ERDAS, and heard about ENVI and PCI.  Those three constitute a majority share, but I'm aware that there are a decent number of options out there, some open source (I've heard good things about Opticks).  In my own research area, 3D remote sensing is rapidly becoming a thing, as well - LIDAR and automated photogrammetry would be short topics in any RS course I'd teach.  See: Meshlab, VSFM, &amp; Photoscan.

Carto

For static-map cartography, you'll ideally want Adobe Illustrator, but there are several less expensive commercial choices that may suffice.  My experience with Inkscape is a lot like my experience with QGIS - almost there, but missing crucial features like an effective layer dialog.

Scripting

In the field of data manipulation, you'll definitely want to look at a thorough exploration of Python w/ LabPy.  It's too versatile not to teach as a general tool at this point, there's the added inducement of ArcPy, and RPy adds the capability to use basically every statistical algorithm in the world.  In addition, very big datasets are typically more amenable to a scripting environment than desktop GIS.

CAD

CAD &amp; CAD-like GIS software, often used for surveyors / engineers, has a broad number of options led by Autocad which I'm not qualified to compare, but may not be necessary for a pure GIS program.

Client - Server

Hosting client-server stacks, which becomes important for some classes of GIS user, is the last niche I'm going to mention, but the requirements here are so varied as to make comparison difficult.  Other than ArcSDE, The software here is often free, but the server setup and sysadmin to use it is not.

EDIT: I've had the opportunity to revisit QGIS recently and it does seem to have considerably improved, going from 1.5 -> 1.8, in stability &amp; features.
",MappingTomorrow,https://gis.stackexchange.com/users/8027,http://gis.stackexchange.com/questions/27188/gis-software-choice-for-a-small-university-research-centre,TECHNOLOGY,gis.stackexchange.com,1.0,0.4444444444444444,0.0,1.0,0.6666666666666666,0.6666666666666666,0.4444444444444444,0.6666666666666666,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,1.0,0.8333333333333334,0.8333333333333334,0.8333333333333334,1.0,0.8,0.3333333333333333,0.0,1.0,0.8888888888888888,Selection of GIS software for research center of small University,"I need to choose a geographic information system for a small university research center. We are working on a wide range of data (e.g., numerical tidal analysis, weather data, poverty, isolated economic activity, skill availability and renewable energy availability), mainly in countries with relatively poor existing data sets.","Desktop

For many users, GIS means ESRI ArcGIS.  While expensive in a commercial setting, they have rather generous educational licensing, including the provision of free copies to educators for distribution to students, one per licensed seat per year.  I would advise at least ticking this box; I don't think people who learned GIS in other ways are less capable, but they might be less employable given the keyword-filtering resumes go through these days.  The extensions to ArcGIS range from basic things that should be integrated into the main application to the amusingly archaic to essential tools for a certain niche.

The OSGeo stack is an obvious addition to this, but I don't think it's yet capable of being a full replacement in desktop GIS, at least not with the usability of Arc.  Due to constant complaining about ESRI's annoyances, I tried to replace it for an entire summer with mostly QGIS, and failed.  QGIS w/ plugins + GRASS + POSTGIS can be hacked around to achieve a lot of GIS functionality, I can believe that, but for learning GIS rapidly, I wouldn't recommend it.  There are a lot of different projects under the OSGeo heading, though - in all likelihood you'll find use for some of them even if you don't touch the desktop functionality.

I'm always seeing MapInfo installations mentioned, but the one I used wasn't really mature / feature-ful in the same sense ArcGIS has been.  The user interface was lacking, so perhaps it just hid the functionality from me.

Manifold has been highly regarded as an ArcGIS competitor that is at once commercially affordable, comprehensive, and extensively higher-performance than the sometimes antiquated ArcGIS code.  They seem to be dragging their feet on updates &amp; bug-fixes in the last few years, though.  At the least, if ArcGIS fails to operate on extreme datasets, try this.

RS

Remote sensing software is its own niche, with lots of features that aren't present in the ESRI stack.  I've been exposed to ERDAS, and heard about ENVI and PCI.  Those three constitute a majority share, but I'm aware that there are a decent number of options out there, some open source (I've heard good things about Opticks).  In my own research area, 3D remote sensing is rapidly becoming a thing, as well - LIDAR and automated photogrammetry would be short topics in any RS course I'd teach.  See: Meshlab, VSFM, &amp; Photoscan.

Carto

For static-map cartography, you'll ideally want Adobe Illustrator, but there are several less expensive commercial choices that may suffice.  My experience with Inkscape is a lot like my experience with QGIS - almost there, but missing crucial features like an effective layer dialog.

Scripting

In the field of data manipulation, you'll definitely want to look at a thorough exploration of Python w/ LabPy.  It's too versatile not to teach as a general tool at this point, there's the added inducement of ArcPy, and RPy adds the capability to use basically every statistical algorithm in the world.  In addition, very big datasets are typically more amenable to a scripting environment than desktop GIS.

CAD

CAD &amp; CAD-like GIS software, often used for surveyors / engineers, has a broad number of options led by Autocad which I'm not qualified to compare, but may not be necessary for a pure GIS program.

Client - Server

Hosting client-server stacks, which becomes important for some classes of GIS user, is the last niche I'm going to mention, but the requirements here are so varied as to make comparison difficult.  Other than ArcSDE, The software here is often free, but the server setup and sysadmin to use it is not.

EDIT: I've had the opportunity to revisit QGIS recently and it does seem to have considerably improved, going from 1.5 -> 1.8, in stability &amp; features.
"
5654,5654,8963,Goalkeeper Jumping Algorithm?,"This may be a ""best way to"" question, so may be susceptible to opinion-based answers (which is ok for me). But I would also like if there are any tutorials , research papers , etc.

I'm trying to make a 3D free kick game, and I want to decide on the Goalkeeper algorithm.

Usually (and in my game) the shot is a function of direction , power and swerve. Maybe wind can be a factor too. So the shots trajectory is pre-deterministic, i.e., the point that intersects the goal (or out) plane is determined as soon as the shot fires.

So what could be a good approach for the goalkeeper to jump (or walk) ?

I have two approaches in mind :

1- determine the point, and jump to there. 
2- when the ball is closer than a threshold distance, estimate the point by the ball's velocity vector, and jump to there.

The problem with the first approach is, goalkeeper will always save the shot, which I want to prevent. So there should be some kind of randomness, or the goalkeeper's ability to jump and walk will be restricted.

The problem with the second approach is, when there is a high amount of swerve, the goalkeeper will always fail to save the shot.

So how could these approaches be better?

Thanks for any help !

Edit:

if you want to play the game, click here
",jeff,https://gamedev.stackexchange.com/users/32639,"The ways to handle this are different based on how you are assigning speed, swerve etc.  I'm assuming you have a skill challenge to do that (""stop the moving needle in the right part of the gauge""-type thing or something similar).  If so, then you want higher-swerve and higher-speed to equal higher-percentage chance of scoring.  If they are just chosen values, then they shouldn't have such a direct effect, or the player will always choose them to be high.

You could set a percentage of the time you want the goalkeeper to save (based on the speed and swerve), and simply pick a random number, if it's below that percentage, play the correct animation (diving the right way) for the save, if it's higher, play the wrong one and allow the score.  This is simple, but also a little ""cheating""-like.

You could set an amount of time for the goalie to read the direction the ball is going, and then start moving him in that direction, and constantly allow him to adjust for the swerve until the last X% of the time it takes the ball to arrive, at which point the goalie can dive for the ball if it's within a range of where he is (and outside ""move-to"" range).  ""Better"" goalies (higher levels?) will read sooner, move faster, and dive later(and further).  This is more complicated, but more flexible, and more simulation-like.
",Ryno,https://gamedev.stackexchange.com/users/30121,http://gamedev.stackexchange.com/questions/66769/goalkeeper-jumping-algorithm,TECHNOLOGY,gamedev.stackexchange.com,1.0,0.3333333333333333,0.0,0.0,1.0,0.0,0.5555555555555556,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,1.0,1.0,0.7333333333333333,0.3333333333333333,0.0,0.3333333333333333,1.0,Goalkeeper jumping algorithm?,"This may be a ""best way to"" question, so may be susceptible to opinion-based answers (which is ok for me). But I would also like if there are any tutorials , research papers , etc.

I'm trying to make a 3D free kick game, and I want to decide on the Goalkeeper algorithm.

Usually (and in my game) the shot is a function of direction , power and swerve. Maybe wind can be a factor too. So the shots trajectory is pre-deterministic, i.e., the point that intersects the goal (or out) plane is determined as soon as the shot fires.

So what could be a good approach for the goalkeeper to jump (or walk) ?

I have two approaches in mind :

1- determine the point, and jump to there. 
2- when the ball is closer than a threshold distance, estimate the point by the ball's velocity vector, and jump to there.

The problem with the first approach is, goalkeeper will always save the shot, which I want to prevent. So there should be some kind of randomness, or the goalkeeper's ability to jump and walk will be restricted.

The problem with the second approach is, when there is a high amount of swerve, the goalkeeper will always fail to save the shot.

So how could these approaches be better?

Thanks for any help !

Edit:

if you want to play the game, click here
","The ways to handle this are different based on how you are assigning speed, swerve etc.  I'm assuming you have a skill challenge to do that (""stop the moving needle in the right part of the gauge""-type thing or something similar).  If so, then you want higher-swerve and higher-speed to equal higher-percentage chance of scoring.  If they are just chosen values, then they shouldn't have such a direct effect, or the player will always choose them to be high.

You could set a percentage of the time you want the goalkeeper to save (based on the speed and swerve), and simply pick a random number, if it's below that percentage, play the correct animation (diving the right way) for the save, if it's higher, play the wrong one and allow the score.  This is simple, but also a little ""cheating""-like.

You could set an amount of time for the goalie to read the direction the ball is going, and then start moving him in that direction, and constantly allow him to adjust for the swerve until the last X% of the time it takes the ball to arrive, at which point the goalie can dive for the ball if it's within a range of where he is (and outside ""move-to"" range).  ""Better"" goalies (higher levels?) will read sooner, move faster, and dive later(and further).  This is more complicated, but more flexible, and more simulation-like.
"
5402,5402,8581,Login users/start session with PDO,"Im trying to create a login section on my website using PDO.

So far I've the following...

config.php
    

    // Connect to DB
    $username = 'user@site.co.uk';
    $password = 'pass';

    try {
        $conn = new PDO('mysql:host=localhost;dbname=db', $username, $password);    
        $conn-&gt;setAttribute(PDO::ATTR_ERRMODE, PDO::ERRMODE_EXCEPTION);
        } 
    catch(PDOException $e) {
        echo 'ERROR: ' . $e-&gt;getMessage();
        }

?&gt;


header.php 
    

// DB Config
include '/assets/config.php';

// User Session
$login = 'liam';
$pass = 'password';

$sth = $conn-&gt;prepare(""SELECT * FROM access_users WHERE login = ? AND pass = ?"");
$sth-&gt;bindParam(1, $login);
$sth-&gt;bindParam(2, $pass);
$sth-&gt;execute();

if ($sth-&gt;rowCount() &gt; 0)
{
  // session stuff,
 // refresh page
}  

?&gt;


My browser doesn't display the page however, and when I view my source theres no data contained within, can anybody see where im going wrong? 
",Liam,https://stackoverflow.com/users/766532,"try this:

// User Session
$login = 'liam';
$pass = 'password';
$sth = $conn-&gt;prepare(""SELECT * FROM users WHERE username = :username AND password = :password"");
$sth-&gt;execute(array("":username"" =&gt; $login,"":password"" =&gt; $pass));

if ($sth-&gt;rowCount() &gt; 0)
{
// session stuff,
// refresh page
  echo $sth-&gt;rowCount();
} 


make sure you have username ""liam"" and pass ""password"" in the database
",Dinesh,https://stackoverflow.com/users/1808187,http://stackoverflow.com/questions/13321769/login-users-start-session-with-pdo,STACKOVERFLOW,stackoverflow.com,1.0,0.6666666666666666,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,1.0,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.6666666666666666,0.3333333333333333,0.0,1.0,Login user / start session with PDO,"Im trying to create a login section on my website using PDO.

So far I've the following...

config.php
    

    // Connect to DB
    $username = 'user@site.co.uk';
    $password = 'pass';

    try {
        $conn = new PDO('mysql:host=localhost;dbname=db', $username, $password);    
        $conn-&gt;setAttribute(PDO::ATTR_ERRMODE, PDO::ERRMODE_EXCEPTION);
        } 
    catch(PDOException $e) {
        echo 'ERROR: ' . $e-&gt;getMessage();
        }

?&gt;


header.php 
    

// DB Config
include '/assets/config.php';

// User Session
$login = 'liam';
$pass = 'password';

$sth = $conn-&gt;prepare(""SELECT * FROM access_users WHERE login = ? AND pass = ?"");
$sth-&gt;bindParam(1, $login);
$sth-&gt;bindParam(2, $pass);
$sth-&gt;execute();

if ($sth-&gt;rowCount() &gt; 0)
{
  // session stuff,
 // refresh page
}  

?&gt;


My browser doesn't display the page however, and when I view my source theres no data contained within, can anybody see where im going wrong? 
","try this:

// User Session
$login = 'liam';
$pass = 'password';
$sth = $conn-&gt;prepare(""SELECT * FROM users WHERE username = :username AND password = :password"");
$sth-&gt;execute(array("":username"" =&gt; $login,"":password"" =&gt; $pass));

if ($sth-&gt;rowCount() &gt; 0)
{
// session stuff,
// refresh page
  echo $sth-&gt;rowCount();
} 


make sure you have username ""liam"" and pass ""password"" in the database
"
1175,1175,1846,Create and open file with one command?,"I want to create a text file and open it in a text editor with a single command.

I know touch file.txt creates a file and open file.txt opens the file, but is there a way to do this with a single command?
",Marcus McLean,https://unix.stackexchange.com/users/36377,"Like everyone is telling you, this depends on your editor. And if you don't like the way your editor handles this, that can probably be configured, as well.

With Emacs, emacs new_file.txt (for a nonexistent new_file.txt in the current directory) will bring up Emacs and display a buffer that refers to a new_file.txt. However, until you save, there will be no such file. If you don't do anything and quit, no file will have been created.

While this is certainly one way, I think an even better way is to always have an instance of Emacs running. So, whenever you feel the need for a new file, go to Emacs, hit C-x C-f (or M-x find-file RET), then write the path to the nonexistent file, and you're at the same point as after the CLI command (above, in the second paragraph).
",Emanuel Berg,https://unix.stackexchange.com/users/13136,http://unix.stackexchange.com/questions/70973/create-and-open-file-with-one-command,TECHNOLOGY,unix.stackexchange.com,0.8888888888888888,0.7777777777777778,0.0,0.3333333333333333,1.0,0.3333333333333333,0.4444444444444444,0.4444444444444444,0.6666666666666666,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,1.0,Create and open a file with one command?,"I want to create a text file and open it in a text editor with a single command.

I know touch file.txt creates a file and open file.txt opens the file, but is there a way to do this with a single command?
","Like everyone is telling you, this depends on your editor. And if you don't like the way your editor handles this, that can probably be configured, as well.

With Emacs, emacs new_file.txt (for a nonexistent new_file.txt in the current directory) will bring up Emacs and display a buffer that refers to a new_file.txt. However, until you save, there will be no such file. If you don't do anything and quit, no file will have been created.

While this is certainly one way, I think an even better way is to always have an instance of Emacs running. So, whenever you feel the need for a new file, go to Emacs, hit C-x C-f (or M-x find-file RET), then write the path to the nonexistent file, and you're at the same point as after the CLI command (above, in the second paragraph).
"
1792,1792,2846,What's wrong with my launchctl config?,"I'm trying to auto-run SickBeard on login

python /Applications/Sick-Beard/Sickbeard.py

&lt;?xml version=""1.0"" encoding=""UTF-8""?&gt;
&lt;!DOCTYPE plist PUBLIC -//Apple Computer//DTD PLIST 1.0//EN http://www.apple.com/DTDs/PropertyList-1.0.dtd &gt;
&lt;plist version=""1.0""&gt;
&lt;dict&gt;
  &lt;key&gt;Label&lt;/key&gt;
  &lt;string&gt;com.sickbeard.sickbeard&lt;/string&gt;
  &lt;key&gt;ProgramArguments&lt;/key&gt;
  &lt;array&gt;
       &lt;string&gt;/usr/bin/python&lt;/string&gt;
       &lt;string&gt;/Applications/Sick-Beard/SickBeard.py&lt;/string&gt;
       &lt;string&gt;-q&lt;/string&gt;
       &lt;string&gt;-d&lt;/string&gt;
  &lt;/array&gt;
  &lt;key&gt;RunAtLoad&lt;/key&gt;
  &lt;true/&gt;
&lt;/dict&gt;
&lt;/plist&gt;


When I run launchctl com.sickbeard.sickbeard.plist it gives me the message:


  launchctl load com.sickbeard.sickbeard.plist  launchctl: no plist was
  returned for: com.sickbeard.sickbeard.plist launchctl: no plist was
  returned for: com.sickbeard.sickbeard.plist nothing found to load

",Joao Costa,https://apple.stackexchange.com/users/20798,"I'm assuming the paths to the python script and its parameters are valid, otherwise you'd most likely be seeing errors in the Console instead.

The last time I saw that error was because there were spurious characters in the plist, e.g. extra spaces, causing syntax errors and therefore making it fail to load. If you run plutil -lint on your plist, this will check the syntax for you and also handily report back the line on which the error occurred.

plutil -lint com.sickbeard.sickbeard.plist

If that doesn't help, the (OSX) How To Start SickBeard at Login or boot on OSX thread on the sickbeard forums has a slightly different plist to yours (sickbeard running from /usr/local as opposed to /Applications - so it could be a permissions thing) and also some people with seemingly the same problem as you
",binarybob,https://apple.stackexchange.com/users/18202,http://apple.stackexchange.com/questions/46368/whats-wrong-with-my-launchctl-config,TECHNOLOGY,apple.stackexchange.com,1.0,0.3333333333333333,0.0,1.0,1.0,1.0,0.5,0.5,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.5,0.0,1.0,0.0,0.8333333333333334,0.6666666666666666,0.6666666666666666,0.8333333333333334,1.0,0.8,0.5,0.0,1.0,1.0,What's wrong with my launchctl configuration?,"I'm trying to auto-run SickBeard on login

python /Applications/Sick-Beard/Sickbeard.py

&lt;?xml version=""1.0"" encoding=""UTF-8""?&gt;
&lt;!DOCTYPE plist PUBLIC -//Apple Computer//DTD PLIST 1.0//EN http://www.apple.com/DTDs/PropertyList-1.0.dtd &gt;
&lt;plist version=""1.0""&gt;
&lt;dict&gt;
  &lt;key&gt;Label&lt;/key&gt;
  &lt;string&gt;com.sickbeard.sickbeard&lt;/string&gt;
  &lt;key&gt;ProgramArguments&lt;/key&gt;
  &lt;array&gt;
       &lt;string&gt;/usr/bin/python&lt;/string&gt;
       &lt;string&gt;/Applications/Sick-Beard/SickBeard.py&lt;/string&gt;
       &lt;string&gt;-q&lt;/string&gt;
       &lt;string&gt;-d&lt;/string&gt;
  &lt;/array&gt;
  &lt;key&gt;RunAtLoad&lt;/key&gt;
  &lt;true/&gt;
&lt;/dict&gt;
&lt;/plist&gt;


When I run launchctl com.sickbeard.sickbeard.plist it gives me the message:


  launchctl load com.sickbeard.sickbeard.plist  launchctl: no plist was
  returned for: com.sickbeard.sickbeard.plist launchctl: no plist was
  returned for: com.sickbeard.sickbeard.plist nothing found to load

","I'm assuming the paths to the python script and its parameters are valid, otherwise you'd most likely be seeing errors in the Console instead.

The last time I saw that error was because there were spurious characters in the plist, e.g. extra spaces, causing syntax errors and therefore making it fail to load. If you run plutil -lint on your plist, this will check the syntax for you and also handily report back the line on which the error occurred.

plutil -lint com.sickbeard.sickbeard.plist

If that doesn't help, the (OSX) How To Start SickBeard at Login or boot on OSX thread on the sickbeard forums has a slightly different plist to yours (sickbeard running from /usr/local as opposed to /Applications - so it could be a permissions thing) and also some people with seemingly the same problem as you
"
5081,5081,8086,Create pass through with Mule ESB 2.2.1,"I'm attempting to set up a config file for Mule ESB 2.2.1 that routes incoming requests to another box. This seems straight forward, but I am getting connection refused exceptions and I'm not sure why. 

Here is the model from my Mule configuration file:

&lt;model name=""ProxySample""&gt;
    &lt;service name=""HttpProxyService""&gt;
        &lt;inbound&gt;
            &lt;http:inbound-endpoint address=""http://localhost:8787"" synchronous=""true""/&gt;
        &lt;/inbound&gt;
        &lt;outbound&gt;
            &lt;pass-through-router&gt;
                &lt;outbound-endpoint address=""http://server2.xyz.com:8080#[header:http.request]"" synchronous=""true""/&gt;
            &lt;/pass-through-router&gt;
        &lt;/outbound&gt;
    &lt;/service&gt;
&lt;/model&gt;


I am browsing to http://localhost:8787/my-site in my browser, thinking that it will route to http://server2.xyz.com:8080/my-site, but I get a connection refused error.

Here is the console output from the Mule server:

**********************************************************************
* Mule ESB and Integration Platform                                  *
* Version: 2.2.1 Build: 14422                                        *
* MuleSource, Inc.                                                   *
* For more information go to http://mule.mulesource.org              *
*                                                                    *
* Server started: 1/19/10 10:43 AM                                   *
* Server ID: 6802537d-0511-11df-bb89-710580f6c729                    *
* JDK: 1.6.0_18 (mixed mode, sharing)                                *
* OS encoding: UTF-8, Mule encoding: UTF-8                           *
* OS: Windows XP - Service Pack 3 (5.1, x86)                         *
* Host:                                      *
*                                                                    *
* Agents Running: None                                               *
**********************************************************************
INFO  2010-01-19 10:43:50,681 [connector.http.0.receiver.2] org.mule.transport.http.HttpClientMessageDispatcher: Connected: endpoint.outbound.http://localhost:8080#[header:http.request]
ERROR 2010-01-19 10:43:54,665 [connector.http.0.receiver.2] org.mule.DefaultExceptionStrategy: 
********************************************************************************
Message               : Failed to route event via endpoint: org.mule.endpoint.DynamicURIOutboundEndpoint@6645e149. Message payload is of type: GetMethod
Type                  : org.mule.api.transport.DispatchException
Code                  : MULE_ERROR-42999
Payload               : org.apache.commons.httpclient.methods.GetMethod@d67067
JavaDoc               : http://www.mulesource.org/docs/site/current2/apidocs/org/mule/api/transport/DispatchException.html
********************************************************************************
Exception stack is:
1. Connection refused: connect (java.net.ConnectException)
  java.net.PlainSocketImpl:-2 (null)
2. Failed to route event via endpoint: org.mule.endpoint.DynamicURIOutboundEndpoint@6645e149. Message payload is of type: GetMethod (org.mule.api.transport.DispatchException)
  org.mule.transport.http.HttpClientMessageDispatcher:127 (http://www.mulesource.org/docs/site/current2/apidocs/org/mule/api/transport/DispatchException.html)
********************************************************************************
Root Exception stack trace:
java.net.ConnectException: Connection refused: connect
    at java.net.PlainSocketImpl.socketConnect(Native Method)
    at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:333)
    at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:195)
    at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:182)
    at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)
    at java.net.Socket.connect(Socket.java:525)
    at java.net.Socket.connect(Socket.java:475)
    at java.net.Socket.&lt;init&gt;(Socket.java:372)
    at java.net.Socket.&lt;init&gt;(Socket.java:246)
    at org.apache.commons.httpclient.protocol.DefaultProtocolSocketFactory.createSocket(DefaultProtocolSocketFactory.java:80)
    at org.apache.commons.httpclient.protocol.DefaultProtocolSocketFactory.createSocket(DefaultProtocolSocketFactory.java:122)
    at org.apache.commons.httpclient.HttpConnection.open(HttpConnection.java:707)
    at org.apache.commons.httpclient.MultiThreadedHttpConnectionManager$HttpConnectionAdapter.open(MultiThreadedHttpConnectionManager.java:1361)
    at org.apache.commons.httpclient.HttpMethodDirector.executeWithRetry(HttpMethodDirector.java:387)
    at org.apache.commons.httpclient.HttpMethodDirector.executeMethod(HttpMethodDirector.java:171)
    at org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:397)
    at org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:346)
    at org.mule.transport.http.HttpClientMessageDispatcher.execute(HttpClientMessageDispatcher.java:120)
    at org.mule.transport.http.HttpClientMessageDispatcher.doSend(HttpClientMessageDispatcher.java:258)
    at org.mule.transport.AbstractMessageDispatcher.send(AbstractMessageDispatcher.java:163)
    at org.mule.transport.AbstractConnector.send(AbstractConnector.java:2016)
    at org.mule.endpoint.DynamicURIOutboundEndpoint.send(DynamicURIOutboundEndpoint.java:178)
    at org.mule.DefaultMuleSession.sendEvent(DefaultMuleSession.java:327)
    at org.mule.DefaultMuleSession.sendEvent(DefaultMuleSession.java:213)
    at org.mule.routing.outbound.AbstractOutboundRouter$2.doInTransaction(AbstractOutboundRouter.java:152)
    at org.mule.transaction.TransactionTemplate.execute(TransactionTemplate.java:99)
    at org.mule.routing.outbound.AbstractOutboundRouter.send(AbstractOutboundRouter.java:159)
    at org.mule.routing.outbound.ChainingRouter.route(ChainingRouter.java:123)
    at org.mule.routing.outbound.DefaultOutboundRouterCollection$1.doInTransaction(DefaultOutboundRouterCollection.java:88)
    at org.mule.transaction.TransactionTemplate.execute(TransactionTemplate.java:45)
    at org.mule.routing.outbound.DefaultOutboundRouterCollection.route(DefaultOutboundRouterCollection.java:93)
    at org.mule.service.AbstractService.sendToOutboundRouter(AbstractService.java:892)
    at org.mule.model.seda.SedaService.doSend(SedaService.java:258)
    at org.mule.service.AbstractService.sendEvent(AbstractService.java:500)
    at org.mule.DefaultMuleSession.sendEvent(DefaultMuleSession.java:354)
    at org.mule.routing.inbound.DefaultInboundRouterCollection.send(DefaultInboundRouterCollection.java:228)
    at org.mule.routing.inbound.DefaultInboundRouterCollection.route(DefaultInboundRouterCollection.java:188)
    at org.mule.transport.AbstractMessageReceiver$DefaultInternalMessageListener.onMessage(AbstractMessageReceiver.java:364)
    at org.mule.transport.AbstractMessageReceiver.routeMessage(AbstractMessageReceiver.java:252)
    at org.mule.transport.AbstractMessageReceiver.routeMessage(AbstractMessageReceiver.java:193)
    at org.mule.transport.http.HttpMessageReceiver$HttpWorker.doRequest(HttpMessageReceiver.java:273)
    at org.mule.transport.http.HttpMessageReceiver$HttpWorker.processRequest(HttpMessageReceiver.java:227)
    at org.mule.transport.http.HttpMessageReceiver$HttpWorker.run(HttpMessageReceiver.java:190)
    at org.mule.work.WorkerContext.run(WorkerContext.java:310)
    at edu.emory.mathcs.backport.java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1061)
    at edu.emory.mathcs.backport.java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:575)
    at java.lang.Thread.run(Thread.java:619)

********************************************************************************

INFO  2010-01-19 10:43:54,665 [connector.http.0.receiver.2] org.mule.transaction.TransactionTemplate: Exception Caught in Transaction template.  Handing off to exception handler: org.mule.service.DefaultServiceExceptionStrategy@1412e75
ERROR 2010-01-19 10:43:54,665 [connector.http.0.receiver.2] org.mule.service.DefaultServiceExceptionStrategy: 
********************************************************************************
Message               : Failed to route event via endpoint: org.mule.endpoint.DynamicURIOutboundEndpoint@6645e149. Message payload is of type: GetMethod
Type                  : org.mule.api.transport.DispatchException
Code                  : MULE_ERROR-42999
Payload               : org.apache.commons.httpclient.methods.GetMethod@d67067
JavaDoc               : http://www.mulesource.org/docs/site/current2/apidocs/org/mule/api/transport/DispatchException.html
********************************************************************************
Exception stack is:
1. Connection refused: connect (java.net.ConnectException)
  java.net.PlainSocketImpl:-2 (null)
2. Failed to route event via endpoint: org.mule.endpoint.DynamicURIOutboundEndpoint@6645e149. Message payload is of type: GetMethod (org.mule.api.transport.DispatchException)
  org.mule.transport.http.HttpClientMessageDispatcher:127 (http://www.mulesource.org/docs/site/current2/apidocs/org/mule/api/transport/DispatchException.html)
********************************************************************************
Root Exception stack trace:
java.net.ConnectException: Connection refused: connect
    at java.net.PlainSocketImpl.socketConnect(Native Method)
    at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:333)
    at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:195)
    at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:182)
    at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)
    at java.net.Socket.connect(Socket.java:525)
    at java.net.Socket.connect(Socket.java:475)
    at java.net.Socket.&lt;init&gt;(Socket.java:372)
    at java.net.Socket.&lt;init&gt;(Socket.java:246)
    at org.apache.commons.httpclient.protocol.DefaultProtocolSocketFactory.createSocket(DefaultProtocolSocketFactory.java:80)
    at org.apache.commons.httpclient.protocol.DefaultProtocolSocketFactory.createSocket(DefaultProtocolSocketFactory.java:122)
    at org.apache.commons.httpclient.HttpConnection.open(HttpConnection.java:707)
    at org.apache.commons.httpclient.MultiThreadedHttpConnectionManager$HttpConnectionAdapter.open(MultiThreadedHttpConnectionManager.java:1361)
    at org.apache.commons.httpclient.HttpMethodDirector.executeWithRetry(HttpMethodDirector.java:387)
    at org.apache.commons.httpclient.HttpMethodDirector.executeMethod(HttpMethodDirector.java:171)
    at org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:397)
    at org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:346)
    at org.mule.transport.http.HttpClientMessageDispatcher.execute(HttpClientMessageDispatcher.java:120)
    at org.mule.transport.http.HttpClientMessageDispatcher.doSend(HttpClientMessageDispatcher.java:258)
    at org.mule.transport.AbstractMessageDispatcher.send(AbstractMessageDispatcher.java:163)
    at org.mule.transport.AbstractConnector.send(AbstractConnector.java:2016)
    at org.mule.endpoint.DynamicURIOutboundEndpoint.send(DynamicURIOutboundEndpoint.java:178)
    at org.mule.DefaultMuleSession.sendEvent(DefaultMuleSession.java:327)
    at org.mule.DefaultMuleSession.sendEvent(DefaultMuleSession.java:213)
    at org.mule.routing.outbound.AbstractOutboundRouter$2.doInTransaction(AbstractOutboundRouter.java:152)
    at org.mule.transaction.TransactionTemplate.execute(TransactionTemplate.java:99)
    at org.mule.routing.outbound.AbstractOutboundRouter.send(AbstractOutboundRouter.java:159)
    at org.mule.routing.outbound.ChainingRouter.route(ChainingRouter.java:123)
    at org.mule.routing.outbound.DefaultOutboundRouterCollection$1.doInTransaction(DefaultOutboundRouterCollection.java:88)
    at org.mule.transaction.TransactionTemplate.execute(TransactionTemplate.java:45)
    at org.mule.routing.outbound.DefaultOutboundRouterCollection.route(DefaultOutboundRouterCollection.java:93)
    at org.mule.service.AbstractService.sendToOutboundRouter(AbstractService.java:892)
    at org.mule.model.seda.SedaService.doSend(SedaService.java:258)
    at org.mule.service.AbstractService.sendEvent(AbstractService.java:500)
    at org.mule.DefaultMuleSession.sendEvent(DefaultMuleSession.java:354)
    at org.mule.routing.inbound.DefaultInboundRouterCollection.send(DefaultInboundRouterCollection.java:228)
    at org.mule.routing.inbound.DefaultInboundRouterCollection.route(DefaultInboundRouterCollection.java:188)
    at org.mule.transport.AbstractMessageReceiver$DefaultInternalMessageListener.onMessage(AbstractMessageReceiver.java:364)
    at org.mule.transport.AbstractMessageReceiver.routeMessage(AbstractMessageReceiver.java:252)
    at org.mule.transport.AbstractMessageReceiver.routeMessage(AbstractMessageReceiver.java:193)
    at org.mule.transport.http.HttpMessageReceiver$HttpWorker.doRequest(HttpMessageReceiver.java:273)
    at org.mule.transport.http.HttpMessageReceiver$HttpWorker.processRequest(HttpMessageReceiver.java:227)
    at org.mule.transport.http.HttpMessageReceiver$HttpWorker.run(HttpMessageReceiver.java:190)
    at org.mule.work.WorkerContext.run(WorkerContext.java:310)
    at edu.emory.mathcs.backport.java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1061)
    at edu.emory.mathcs.backport.java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:575)
    at java.lang.Thread.run(Thread.java:619)

********************************************************************************

ERROR 2010-01-19 10:43:54,665 [connector.http.0.receiver.2] org.mule.service.DefaultServiceExceptionStrategy: 
********************************************************************************
Message               : Failed to route event via endpoint: org.mule.endpoint.DynamicURIOutboundEndpoint@6645e149. Message payload is of type: GetMethod
Type                  : org.mule.api.transport.DispatchException
Code                  : MULE_ERROR-42999
Payload               : org.apache.commons.httpclient.methods.GetMethod@d67067
JavaDoc               : http://www.mulesource.org/docs/site/current2/apidocs/org/mule/api/transport/DispatchException.html
********************************************************************************
Exception stack is:
1. Connection refused: connect (java.net.ConnectException)
  java.net.PlainSocketImpl:-2 (null)
2. Failed to route event via endpoint: org.mule.endpoint.DynamicURIOutboundEndpoint@6645e149. Message payload is of type: GetMethod (org.mule.api.transport.DispatchException)
  org.mule.transport.http.HttpClientMessageDispatcher:127 (http://www.mulesource.org/docs/site/current2/apidocs/org/mule/api/transport/DispatchException.html)
********************************************************************************
Root Exception stack trace:
java.net.ConnectException: Connection refused: connect
    at java.net.PlainSocketImpl.socketConnect(Native Method)
    at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:333)
    at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:195)
    at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:182)
    at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)
    at java.net.Socket.connect(Socket.java:525)
    at java.net.Socket.connect(Socket.java:475)
    at java.net.Socket.&lt;init&gt;(Socket.java:372)
    at java.net.Socket.&lt;init&gt;(Socket.java:246)
    at org.apache.commons.httpclient.protocol.DefaultProtocolSocketFactory.createSocket(DefaultProtocolSocketFactory.java:80)
    at org.apache.commons.httpclient.protocol.DefaultProtocolSocketFactory.createSocket(DefaultProtocolSocketFactory.java:122)
    at org.apache.commons.httpclient.HttpConnection.open(HttpConnection.java:707)
    at org.apache.commons.httpclient.MultiThreadedHttpConnectionManager$HttpConnectionAdapter.open(MultiThreadedHttpConnectionManager.java:1361)
    at org.apache.commons.httpclient.HttpMethodDirector.executeWithRetry(HttpMethodDirector.java:387)
    at org.apache.commons.httpclient.HttpMethodDirector.executeMethod(HttpMethodDirector.java:171)
    at org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:397)
    at org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:346)
    at org.mule.transport.http.HttpClientMessageDispatcher.execute(HttpClientMessageDispatcher.java:120)
    at org.mule.transport.http.HttpClientMessageDispatcher.doSend(HttpClientMessageDispatcher.java:258)
    at org.mule.transport.AbstractMessageDispatcher.send(AbstractMessageDispatcher.java:163)
    at org.mule.transport.AbstractConnector.send(AbstractConnector.java:2016)
    at org.mule.endpoint.DynamicURIOutboundEndpoint.send(DynamicURIOutboundEndpoint.java:178)
    at org.mule.DefaultMuleSession.sendEvent(DefaultMuleSession.java:327)
    at org.mule.DefaultMuleSession.sendEvent(DefaultMuleSession.java:213)
    at org.mule.routing.outbound.AbstractOutboundRouter$2.doInTransaction(AbstractOutboundRouter.java:152)
    at org.mule.transaction.TransactionTemplate.execute(TransactionTemplate.java:99)
    at org.mule.routing.outbound.AbstractOutboundRouter.send(AbstractOutboundRouter.java:159)
    at org.mule.routing.outbound.ChainingRouter.route(ChainingRouter.java:123)
    at org.mule.routing.outbound.DefaultOutboundRouterCollection$1.doInTransaction(DefaultOutboundRouterCollection.java:88)
    at org.mule.transaction.TransactionTemplate.execute(TransactionTemplate.java:45)
    at org.mule.routing.outbound.DefaultOutboundRouterCollection.route(DefaultOutboundRouterCollection.java:93)
    at org.mule.service.AbstractService.sendToOutboundRouter(AbstractService.java:892)
    at org.mule.model.seda.SedaService.doSend(SedaService.java:258)
    at org.mule.service.AbstractService.sendEvent(AbstractService.java:500)
    at org.mule.DefaultMuleSession.sendEvent(DefaultMuleSession.java:354)
    at org.mule.routing.inbound.DefaultInboundRouterCollection.send(DefaultInboundRouterCollection.java:228)
    at org.mule.routing.inbound.DefaultInboundRouterCollection.route(DefaultInboundRouterCollection.java:188)
    at org.mule.transport.AbstractMessageReceiver$DefaultInternalMessageListener.onMessage(AbstractMessageReceiver.java:364)
    at org.mule.transport.AbstractMessageReceiver.routeMessage(AbstractMessageReceiver.java:252)
    at org.mule.transport.AbstractMessageReceiver.routeMessage(AbstractMessageReceiver.java:193)
    at org.mule.transport.http.HttpMessageReceiver$HttpWorker.doRequest(HttpMessageReceiver.java:273)
    at org.mule.transport.http.HttpMessageReceiver$HttpWorker.processRequest(HttpMessageReceiver.java:227)
    at org.mule.transport.http.HttpMessageReceiver$HttpWorker.run(HttpMessageReceiver.java:190)
    at org.mule.work.WorkerContext.run(WorkerContext.java:310)
    at edu.emory.mathcs.backport.java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1061)
    at edu.emory.mathcs.backport.java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:575)
    at java.lang.Thread.run(Thread.java:619)

********************************************************************************

",Dan Polites,https://stackoverflow.com/users/43365,"My project wasn't cleaning correctly in Eclipse. Once I ran the correct configuration file, the example above worked as intended.
",Dan Polites,https://stackoverflow.com/users/43365,http://stackoverflow.com/questions/2094757/create-pass-through-with-mule-esb-2-2-1,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.3333333333333333,0.0,0.5,1.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.3333333333333333,0.6666666666666666,0.3333333333333333,1.0,Create a pass using mule ESB 2.2.1,"I'm attempting to set up a config file for Mule ESB 2.2.1 that routes incoming requests to another box. This seems straight forward, but I am getting connection refused exceptions and I'm not sure why. 

Here is the model from my Mule configuration file:

&lt;model name=""ProxySample""&gt;
    &lt;service name=""HttpProxyService""&gt;
        &lt;inbound&gt;
            &lt;http:inbound-endpoint address=""http://localhost:8787"" synchronous=""true""/&gt;
        &lt;/inbound&gt;
        &lt;outbound&gt;
            &lt;pass-through-router&gt;
                &lt;outbound-endpoint address=""http://server2.xyz.com:8080#[header:http.request]"" synchronous=""true""/&gt;
            &lt;/pass-through-router&gt;
        &lt;/outbound&gt;
    &lt;/service&gt;
&lt;/model&gt;


I am browsing to http://localhost:8787/my-site in my browser, thinking that it will route to http://server2.xyz.com:8080/my-site, but I get a connection refused error.

Here is the console output from the Mule server:

**********************************************************************
* Mule ESB and Integration Platform                                  *
* Version: 2.2.1 Build: 14422                                        *
* MuleSource, Inc.                                                   *
* For more information go to http://mule.mulesource.org              *
*                                                                    *
* Server started: 1/19/10 10:43 AM                                   *
* Server ID: 6802537d-0511-11df-bb89-710580f6c729                    *
* JDK: 1.6.0_18 (mixed mode, sharing)                                *
* OS encoding: UTF-8, Mule encoding: UTF-8                           *
* OS: Windows XP - Service Pack 3 (5.1, x86)                         *
* Host:                                      *
*                                                                    *
* Agents Running: None                                               *
**********************************************************************
INFO  2010-01-19 10:43:50,681 [connector.http.0.receiver.2] org.mule.transport.http.HttpClientMessageDispatcher: Connected: endpoint.outbound.http://localhost:8080#[header:http.request]
ERROR 2010-01-19 10:43:54,665 [connector.http.0.receiver.2] org.mule.DefaultExceptionStrategy: 
********************************************************************************
Message               : Failed to route event via endpoint: org.mule.endpoint.DynamicURIOutboundEndpoint@6645e149. Message payload is of type: GetMethod
Type                  : org.mule.api.transport.DispatchException
Code                  : MULE_ERROR-42999
Payload               : org.apache.commons.httpclient.methods.GetMethod@d67067
JavaDoc               : http://www.mulesource.org/docs/site/current2/apidocs/org/mule/api/transport/DispatchException.html
********************************************************************************
Exception stack is:
1. Connection refused: connect (java.net.ConnectException)
  java.net.PlainSocketImpl:-2 (null)
2. Failed to route event via endpoint: org.mule.endpoint.DynamicURIOutboundEndpoint@6645e149. Message payload is of type: GetMethod (org.mule.api.transport.DispatchException)
  org.mule.transport.http.HttpClientMessageDispatcher:127 (http://www.mulesource.org/docs/site/current2/apidocs/org/mule/api/transport/DispatchException.html)
********************************************************************************
Root Exception stack trace:
java.net.ConnectException: Connection refused: connect
    at java.net.PlainSocketImpl.socketConnect(Native Method)
    at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:333)
    at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:195)
    at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:182)
    at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)
    at java.net.Socket.connect(Socket.java:525)
    at java.net.Socket.connect(Socket.java:475)
    at java.net.Socket.&lt;init&gt;(Socket.java:372)
    at java.net.Socket.&lt;init&gt;(Socket.java:246)
    at org.apache.commons.httpclient.protocol.DefaultProtocolSocketFactory.createSocket(DefaultProtocolSocketFactory.java:80)
    at org.apache.commons.httpclient.protocol.DefaultProtocolSocketFactory.createSocket(DefaultProtocolSocketFactory.java:122)
    at org.apache.commons.httpclient.HttpConnection.open(HttpConnection.java:707)
    at org.apache.commons.httpclient.MultiThreadedHttpConnectionManager$HttpConnectionAdapter.open(MultiThreadedHttpConnectionManager.java:1361)
    at org.apache.commons.httpclient.HttpMethodDirector.executeWithRetry(HttpMethodDirector.java:387)
    at org.apache.commons.httpclient.HttpMethodDirector.executeMethod(HttpMethodDirector.java:171)
    at org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:397)
    at org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:346)
    at org.mule.transport.http.HttpClientMessageDispatcher.execute(HttpClientMessageDispatcher.java:120)
    at org.mule.transport.http.HttpClientMessageDispatcher.doSend(HttpClientMessageDispatcher.java:258)
    at org.mule.transport.AbstractMessageDispatcher.send(AbstractMessageDispatcher.java:163)
    at org.mule.transport.AbstractConnector.send(AbstractConnector.java:2016)
    at org.mule.endpoint.DynamicURIOutboundEndpoint.send(DynamicURIOutboundEndpoint.java:178)
    at org.mule.DefaultMuleSession.sendEvent(DefaultMuleSession.java:327)
    at org.mule.DefaultMuleSession.sendEvent(DefaultMuleSession.java:213)
    at org.mule.routing.outbound.AbstractOutboundRouter$2.doInTransaction(AbstractOutboundRouter.java:152)
    at org.mule.transaction.TransactionTemplate.execute(TransactionTemplate.java:99)
    at org.mule.routing.outbound.AbstractOutboundRouter.send(AbstractOutboundRouter.java:159)
    at org.mule.routing.outbound.ChainingRouter.route(ChainingRouter.java:123)
    at org.mule.routing.outbound.DefaultOutboundRouterCollection$1.doInTransaction(DefaultOutboundRouterCollection.java:88)
    at org.mule.transaction.TransactionTemplate.execute(TransactionTemplate.java:45)
    at org.mule.routing.outbound.DefaultOutboundRouterCollection.route(DefaultOutboundRouterCollection.java:93)
    at org.mule.service.AbstractService.sendToOutboundRouter(AbstractService.java:892)
    at org.mule.model.seda.SedaService.doSend(SedaService.java:258)
    at org.mule.service.AbstractService.sendEvent(AbstractService.java:500)
    at org.mule.DefaultMuleSession.sendEvent(DefaultMuleSession.java:354)
    at org.mule.routing.inbound.DefaultInboundRouterCollection.send(DefaultInboundRouterCollection.java:228)
    at org.mule.routing.inbound.DefaultInboundRouterCollection.route(DefaultInboundRouterCollection.java:188)
    at org.mule.transport.AbstractMessageReceiver$DefaultInternalMessageListener.onMessage(AbstractMessageReceiver.java:364)
    at org.mule.transport.AbstractMessageReceiver.routeMessage(AbstractMessageReceiver.java:252)
    at org.mule.transport.AbstractMessageReceiver.routeMessage(AbstractMessageReceiver.java:193)
    at org.mule.transport.http.HttpMessageReceiver$HttpWorker.doRequest(HttpMessageReceiver.java:273)
    at org.mule.transport.http.HttpMessageReceiver$HttpWorker.processRequest(HttpMessageReceiver.java:227)
    at org.mule.transport.http.HttpMessageReceiver$HttpWorker.run(HttpMessageReceiver.java:190)
    at org.mule.work.WorkerContext.run(WorkerContext.java:310)
    at edu.emory.mathcs.backport.java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1061)
    at edu.emory.mathcs.backport.java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:575)
    at java.lang.Thread.run(Thread.java:619)

********************************************************************************

INFO  2010-01-19 10:43:54,665 [connector.http.0.receiver.2] org.mule.transaction.TransactionTemplate: Exception Caught in Transaction template.  Handing off to exception handler: org.mule.service.DefaultServiceExceptionStrategy@1412e75
ERROR 2010-01-19 10:43:54,665 [connector.http.0.receiver.2] org.mule.service.DefaultServiceExceptionStrategy: 
********************************************************************************
Message               : Failed to route event via endpoint: org.mule.endpoint.DynamicURIOutboundEndpoint@6645e149. Message payload is of type: GetMethod
Type                  : org.mule.api.transport.DispatchException
Code                  : MULE_ERROR-42999
Payload               : org.apache.commons.httpclient.methods.GetMethod@d67067
JavaDoc               : http://www.mulesource.org/docs/site/current2/apidocs/org/mule/api/transport/DispatchException.html
********************************************************************************
Exception stack is:
1. Connection refused: connect (java.net.ConnectException)
  java.net.PlainSocketImpl:-2 (null)
2. Failed to route event via endpoint: org.mule.endpoint.DynamicURIOutboundEndpoint@6645e149. Message payload is of type: GetMethod (org.mule.api.transport.DispatchException)
  org.mule.transport.http.HttpClientMessageDispatcher:127 (http://www.mulesource.org/docs/site/current2/apidocs/org/mule/api/transport/DispatchException.html)
********************************************************************************
Root Exception stack trace:
java.net.ConnectException: Connection refused: connect
    at java.net.PlainSocketImpl.socketConnect(Native Method)
    at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:333)
    at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:195)
    at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:182)
    at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)
    at java.net.Socket.connect(Socket.java:525)
    at java.net.Socket.connect(Socket.java:475)
    at java.net.Socket.&lt;init&gt;(Socket.java:372)
    at java.net.Socket.&lt;init&gt;(Socket.java:246)
    at org.apache.commons.httpclient.protocol.DefaultProtocolSocketFactory.createSocket(DefaultProtocolSocketFactory.java:80)
    at org.apache.commons.httpclient.protocol.DefaultProtocolSocketFactory.createSocket(DefaultProtocolSocketFactory.java:122)
    at org.apache.commons.httpclient.HttpConnection.open(HttpConnection.java:707)
    at org.apache.commons.httpclient.MultiThreadedHttpConnectionManager$HttpConnectionAdapter.open(MultiThreadedHttpConnectionManager.java:1361)
    at org.apache.commons.httpclient.HttpMethodDirector.executeWithRetry(HttpMethodDirector.java:387)
    at org.apache.commons.httpclient.HttpMethodDirector.executeMethod(HttpMethodDirector.java:171)
    at org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:397)
    at org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:346)
    at org.mule.transport.http.HttpClientMessageDispatcher.execute(HttpClientMessageDispatcher.java:120)
    at org.mule.transport.http.HttpClientMessageDispatcher.doSend(HttpClientMessageDispatcher.java:258)
    at org.mule.transport.AbstractMessageDispatcher.send(AbstractMessageDispatcher.java:163)
    at org.mule.transport.AbstractConnector.send(AbstractConnector.java:2016)
    at org.mule.endpoint.DynamicURIOutboundEndpoint.send(DynamicURIOutboundEndpoint.java:178)
    at org.mule.DefaultMuleSession.sendEvent(DefaultMuleSession.java:327)
    at org.mule.DefaultMuleSession.sendEvent(DefaultMuleSession.java:213)
    at org.mule.routing.outbound.AbstractOutboundRouter$2.doInTransaction(AbstractOutboundRouter.java:152)
    at org.mule.transaction.TransactionTemplate.execute(TransactionTemplate.java:99)
    at org.mule.routing.outbound.AbstractOutboundRouter.send(AbstractOutboundRouter.java:159)
    at org.mule.routing.outbound.ChainingRouter.route(ChainingRouter.java:123)
    at org.mule.routing.outbound.DefaultOutboundRouterCollection$1.doInTransaction(DefaultOutboundRouterCollection.java:88)
    at org.mule.transaction.TransactionTemplate.execute(TransactionTemplate.java:45)
    at org.mule.routing.outbound.DefaultOutboundRouterCollection.route(DefaultOutboundRouterCollection.java:93)
    at org.mule.service.AbstractService.sendToOutboundRouter(AbstractService.java:892)
    at org.mule.model.seda.SedaService.doSend(SedaService.java:258)
    at org.mule.service.AbstractService.sendEvent(AbstractService.java:500)
    at org.mule.DefaultMuleSession.sendEvent(DefaultMuleSession.java:354)
    at org.mule.routing.inbound.DefaultInboundRouterCollection.send(DefaultInboundRouterCollection.java:228)
    at org.mule.routing.inbound.DefaultInboundRouterCollection.route(DefaultInboundRouterCollection.java:188)
    at org.mule.transport.AbstractMessageReceiver$DefaultInternalMessageListener.onMessage(AbstractMessageReceiver.java:364)
    at org.mule.transport.AbstractMessageReceiver.routeMessage(AbstractMessageReceiver.java:252)
    at org.mule.transport.AbstractMessageReceiver.routeMessage(AbstractMessageReceiver.java:193)
    at org.mule.transport.http.HttpMessageReceiver$HttpWorker.doRequest(HttpMessageReceiver.java:273)
    at org.mule.transport.http.HttpMessageReceiver$HttpWorker.processRequest(HttpMessageReceiver.java:227)
    at org.mule.transport.http.HttpMessageReceiver$HttpWorker.run(HttpMessageReceiver.java:190)
    at org.mule.work.WorkerContext.run(WorkerContext.java:310)
    at edu.emory.mathcs.backport.java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1061)
    at edu.emory.mathcs.backport.java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:575)
    at java.lang.Thread.run(Thread.java:619)

********************************************************************************

ERROR 2010-01-19 10:43:54,665 [connector.http.0.receiver.2] org.mule.service.DefaultServiceExceptionStrategy: 
********************************************************************************
Message               : Failed to route event via endpoint: org.mule.endpoint.DynamicURIOutboundEndpoint@6645e149. Message payload is of type: GetMethod
Type                  : org.mule.api.transport.DispatchException
Code                  : MULE_ERROR-42999
Payload               : org.apache.commons.httpclient.methods.GetMethod@d67067
JavaDoc               : http://www.mulesource.org/docs/site/current2/apidocs/org/mule/api/transport/DispatchException.html
********************************************************************************
Exception stack is:
1. Connection refused: connect (java.net.ConnectException)
  java.net.PlainSocketImpl:-2 (null)
2. Failed to route event via endpoint: org.mule.endpoint.DynamicURIOutboundEndpoint@6645e149. Message payload is of type: GetMethod (org.mule.api.transport.DispatchException)
  org.mule.transport.http.HttpClientMessageDispatcher:127 (http://www.mulesource.org/docs/site/current2/apidocs/org/mule/api/transport/DispatchException.html)
********************************************************************************
Root Exception stack trace:
java.net.ConnectException: Connection refused: connect
    at java.net.PlainSocketImpl.socketConnect(Native Method)
    at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:333)
    at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:195)
    at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:182)
    at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)
    at java.net.Socket.connect(Socket.java:525)
    at java.net.Socket.connect(Socket.java:475)
    at java.net.Socket.&lt;init&gt;(Socket.java:372)
    at java.net.Socket.&lt;init&gt;(Socket.java:246)
    at org.apache.commons.httpclient.protocol.DefaultProtocolSocketFactory.createSocket(DefaultProtocolSocketFactory.java:80)
    at org.apache.commons.httpclient.protocol.DefaultProtocolSocketFactory.createSocket(DefaultProtocolSocketFactory.java:122)
    at org.apache.commons.httpclient.HttpConnection.open(HttpConnection.java:707)
    at org.apache.commons.httpclient.MultiThreadedHttpConnectionManager$HttpConnectionAdapter.open(MultiThreadedHttpConnectionManager.java:1361)
    at org.apache.commons.httpclient.HttpMethodDirector.executeWithRetry(HttpMethodDirector.java:387)
    at org.apache.commons.httpclient.HttpMethodDirector.executeMethod(HttpMethodDirector.java:171)
    at org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:397)
    at org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:346)
    at org.mule.transport.http.HttpClientMessageDispatcher.execute(HttpClientMessageDispatcher.java:120)
    at org.mule.transport.http.HttpClientMessageDispatcher.doSend(HttpClientMessageDispatcher.java:258)
    at org.mule.transport.AbstractMessageDispatcher.send(AbstractMessageDispatcher.java:163)
    at org.mule.transport.AbstractConnector.send(AbstractConnector.java:2016)
    at org.mule.endpoint.DynamicURIOutboundEndpoint.send(DynamicURIOutboundEndpoint.java:178)
    at org.mule.DefaultMuleSession.sendEvent(DefaultMuleSession.java:327)
    at org.mule.DefaultMuleSession.sendEvent(DefaultMuleSession.java:213)
    at org.mule.routing.outbound.AbstractOutboundRouter$2.doInTransaction(AbstractOutboundRouter.java:152)
    at org.mule.transaction.TransactionTemplate.execute(TransactionTemplate.java:99)
    at org.mule.routing.outbound.AbstractOutboundRouter.send(AbstractOutboundRouter.java:159)
    at org.mule.routing.outbound.ChainingRouter.route(ChainingRouter.java:123)
    at org.mule.routing.outbound.DefaultOutboundRouterCollection$1.doInTransaction(DefaultOutboundRouterCollection.java:88)
    at org.mule.transaction.TransactionTemplate.execute(TransactionTemplate.java:45)
    at org.mule.routing.outbound.DefaultOutboundRouterCollection.route(DefaultOutboundRouterCollection.java:93)
    at org.mule.service.AbstractService.sendToOutboundRouter(AbstractService.java:892)
    at org.mule.model.seda.SedaService.doSend(SedaService.java:258)
    at org.mule.service.AbstractService.sendEvent(AbstractService.java:500)
    at org.mule.DefaultMuleSession.sendEvent(DefaultMuleSession.java:354)
    at org.mule.routing.inbound.DefaultInboundRouterCollection.send(DefaultInboundRouterCollection.java:228)
    at org.mule.routing.inbound.DefaultInboundRouterCollection.route(DefaultInboundRouterCollection.java:188)
    at org.mule.transport.AbstractMessageReceiver$DefaultInternalMessageListener.onMessage(AbstractMessageReceiver.java:364)
    at org.mule.transport.AbstractMessageReceiver.routeMessage(AbstractMessageReceiver.java:252)
    at org.mule.transport.AbstractMessageReceiver.routeMessage(AbstractMessageReceiver.java:193)
    at org.mule.transport.http.HttpMessageReceiver$HttpWorker.doRequest(HttpMessageReceiver.java:273)
    at org.mule.transport.http.HttpMessageReceiver$HttpWorker.processRequest(HttpMessageReceiver.java:227)
    at org.mule.transport.http.HttpMessageReceiver$HttpWorker.run(HttpMessageReceiver.java:190)
    at org.mule.work.WorkerContext.run(WorkerContext.java:310)
    at edu.emory.mathcs.backport.java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1061)
    at edu.emory.mathcs.backport.java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:575)
    at java.lang.Thread.run(Thread.java:619)

********************************************************************************

","My project didn't clean up properly in eclipse. Once I run the correct configuration file, the above example will work."
661,661,1050,What is Cold Iron actually?,"It came up in Dresden Files, but is not limited to that game, you can find the term in DnD as well. I would like to know what it means. 

If you look for Cold Iron on Wikipedia, you only get iron: 
""Cold iron is a poetic and archaic term for iron.""
This would imply everything made mostly from Fe is cold iron. Clearly, this is not the case, in every game Cold Iron is something special, the every day sword is not made out of it. 

The Dresden Files rulebook is not very specific about it:


  something that anyone could reasonably get access to, but usually doesn’t carry on them (like cold iron) page 185.


What is cold iron?
How do I create cold iron?
How do I get cold iron?   

To make the question easier to understand, compare Cold Iron to Holy Water. You know how it is different from usual Water, you know how you get it or create it. 
",András,https://rpg.stackexchange.com/users/9552,"In the Dresden Files books, Cold Iron is just Iron, and things made mostly of Iron count as Cold Iron.

Steel is an alloy made out of Iron and Carbon. So I did some research as to how much of steel is actually iron and I found that the carbon content of steel is between 0.002% and 2.1% by weight. Essentially, anything that is made out of steel is somewhere around 98%-99% iron and in my opinion counts as Cold Iron for game purposes. This is why the ""Cold Iron"" catch is +2 or +3 (depending on the amount of powers connected to the Catch), because ""Cold Iron"" is pretty plentiful. Basically just about any sword or knife made from methods as far back as archaic blacksmithing up to and including modern manufacturing will count for satisfying the Cold Iron Catch.

I suppose you could run into an issue with Stainless Steel as it contains 10% chromium, but I'd personally rule that Stainless Steel which is around 88% iron would still work for satisfying the Catch.
",Ty-Bob-Reed,https://rpg.stackexchange.com/users/14916,http://rpg.stackexchange.com/questions/40826/what-is-cold-iron-actually,CULTURE,rpg.stackexchange.com,1.0,0.5555555555555556,0.0,1.0,1.0,1.0,0.5555555555555556,0.3333333333333333,0.3333333333333333,0.0,0.3333333333333333,0.0,0.0,0.0,0.6666666666666666,0.0,0.3333333333333333,0.0,0.3333333333333333,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,1.0,What is cold iron?,"It came up in Dresden Files, but is not limited to that game, you can find the term in DnD as well. I would like to know what it means. 

If you look for Cold Iron on Wikipedia, you only get iron: 
""Cold iron is a poetic and archaic term for iron.""
This would imply everything made mostly from Fe is cold iron. Clearly, this is not the case, in every game Cold Iron is something special, the every day sword is not made out of it. 

The Dresden Files rulebook is not very specific about it:


  something that anyone could reasonably get access to, but usually doesn’t carry on them (like cold iron) page 185.


What is cold iron?
How do I create cold iron?
How do I get cold iron?   

To make the question easier to understand, compare Cold Iron to Holy Water. You know how it is different from usual Water, you know how you get it or create it. 
","In the Dresden Files books, Cold Iron is just Iron, and things made mostly of Iron count as Cold Iron.

Steel is an alloy made out of Iron and Carbon. So I did some research as to how much of steel is actually iron and I found that the carbon content of steel is between 0.002% and 2.1% by weight. Essentially, anything that is made out of steel is somewhere around 98%-99% iron and in my opinion counts as Cold Iron for game purposes. This is why the ""Cold Iron"" catch is +2 or +3 (depending on the amount of powers connected to the Catch), because ""Cold Iron"" is pretty plentiful. Basically just about any sword or knife made from methods as far back as archaic blacksmithing up to and including modern manufacturing will count for satisfying the Cold Iron Catch.

I suppose you could run into an issue with Stainless Steel as it contains 10% chromium, but I'd personally rule that Stainless Steel which is around 88% iron would still work for satisfying the Catch.
"
564,564,887,Is an old mtb with replaced gear safe to buy?,"I believe this question to be on topic for this site, I want it to be more factual based than opinion, another similar question is this one. If its not feel free to close it.

I am looking at buying an older (10 yrs old) Giant NRS 1 MTB, it has very good reviews for the frame especially, but other parts have been replaced (it has a new front wheel, cables etc.). Should I be worried that other parts will be about to fall off, or are replacements a good thing?

EDIT: Ok so the wheel was replaced due to hitting a stump at night time, the cables were getting old, it has had plenty of action, but was well looked after. The rear sus has a tiny bit of play in the top bush (not enough to realise when riding)

It also has a leaking front fork, not a big issue (probably new seal, or not worry), but makes me wonder if it is worth it, will cost around $400 US ish, do you think it will have other issues?

cheers in advance!
",W1ll1amvl,https://bicycles.stackexchange.com/users/14123,"Aluminum fatigues.  A 10 year of bike with a lot of miles could be getting towards the end of it life.  

It has a modern headset.  

Full suspension has come a long way in 10 years.

But 26"" wheels.
I would rather have a hard tail 29"".  

You would have to judge the parts based on inspection.  

With a leaky fork I would not do it period. 
How do you know it is not a big issues? 
Do you have a quote that it is a cheap repair?  

To me that is not the kind of bike you put a lot of money into.
",Paparazzi,https://bicycles.stackexchange.com/users/7785,http://bicycles.stackexchange.com/questions/25691/is-an-old-mtb-with-replaced-gear-safe-to-buy,CULTURE,bicycles.stackexchange.com,0.7777777777777778,0.5555555555555556,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.8,0.0,0.0,1.0,0.8888888888888888,Can old subway with new equipment be purchased safely?,"I believe this question to be on topic for this site, I want it to be more factual based than opinion, another similar question is this one. If its not feel free to close it.

I am looking at buying an older (10 yrs old) Giant NRS 1 MTB, it has very good reviews for the frame especially, but other parts have been replaced (it has a new front wheel, cables etc.). Should I be worried that other parts will be about to fall off, or are replacements a good thing?

EDIT: Ok so the wheel was replaced due to hitting a stump at night time, the cables were getting old, it has had plenty of action, but was well looked after. The rear sus has a tiny bit of play in the top bush (not enough to realise when riding)

It also has a leaking front fork, not a big issue (probably new seal, or not worry), but makes me wonder if it is worth it, will cost around $400 US ish, do you think it will have other issues?

cheers in advance!
","Aluminum fatigues.  A 10 year of bike with a lot of miles could be getting towards the end of it life.  

It has a modern headset.  

Full suspension has come a long way in 10 years.

But 26"" wheels.
I would rather have a hard tail 29"".  

You would have to judge the parts based on inspection.  

With a leaky fork I would not do it period. 
How do you know it is not a big issues? 
Do you have a quote that it is a cheap repair?  

To me that is not the kind of bike you put a lot of money into.
"
5477,5477,8696,Was Erica Albright real?,"In the film The Social Network Mark breaks up with Erica Albright early on, this (through a series of steps) leads to him creating The Facebook.

However in real life Mark is married to Priscilla Chan who he met at Jewish fraternity at Harvard University in 2003 (Facebook was founded in 2004).

Does Erica Albright exist? If not why is she featured in the film and not Priscilla Chan?
",Liath,https://movies.stackexchange.com/users/574,"The EricaAlbright.com is a hoax web site. It is just someone trying to get attention on the Internet with a ""famous"" name. Erica Albright is a fictitious person created for the sake of drama, because movies need a romantic plot to make them more interesting to some audience.
",Sasha,https://movies.stackexchange.com/users/7945,http://movies.stackexchange.com/questions/13794/was-erica-albright-real,LIFE_ARTS,movies.stackexchange.com,1.0,0.6666666666666666,0.0,1.0,0.6666666666666666,1.0,0.7777777777777778,0.5555555555555556,0.6666666666666666,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,0.8888888888888888,Is Erica Albright real?,"In the film The Social Network Mark breaks up with Erica Albright early on, this (through a series of steps) leads to him creating The Facebook.

However in real life Mark is married to Priscilla Chan who he met at Jewish fraternity at Harvard University in 2003 (Facebook was founded in 2004).

Does Erica Albright exist? If not why is she featured in the film and not Priscilla Chan?
","Ericaalbright.com is a scam website. It's just that someone wants to use a ""famous"" name to get attention online. Erica Albright is a fictional person for drama, because the movie needs a romantic plot to make the audience more interested."
1554,1554,2439,Create heatmap with PSTricks or TikZ,"I have a huge amount of 2D-coordinates, associated with a value, e.g.:

  x   |   y   | value
27.50   52.15   12.51
61.83   13.32   57.56
36.23   21.83   41.73
40.46   85.67   25.20
...


The data is not tabular and I Want the points between two data-points to be interpolated in some way (which way is not really clear, yet)

I want to preset the data as heatmap like this:


Is there any ready-to-use package for PSTricks or TikZ to do it?
",user2033412,https://tex.stackexchange.com/users/35228,"You can also use pgfplots. I use the same data and the same number of point of Herbert, and the default matlab color map. You have to compile the following code with LuaLaTeX because it needs a lot of memory. It needs also a lot of time (about 2 minutes in my PC) so its better to compile it once and then insert the pdf file of your graph as an image.

\documentclass[border=10pt]{standalone}
\usepackage{pgfplots}
\usepackage{xcolor}

\pgfplotsset{compat=newest}

\begin{document}
\begin{tikzpicture}
\begin{axis}[
    colormap/jet,
    colorbar,
    view={0}{90}]
    \addplot3[surf,shader=flat] file {data-map.dat};
\end{axis}
\end{tikzpicture}
\end{document} 



",Red,https://tex.stackexchange.com/users/31093,http://tex.stackexchange.com/questions/133882/create-heatmap-with-pstricks-or-tikz,TECHNOLOGY,tex.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,1.0,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.0,0.0,0.6666666666666666,0.8333333333333334,0.6666666666666666,0.8333333333333334,1.0,0.9,0.0,0.0,0.0,0.7777777777777778,Creating a heat map with pstricks or tikz,"I have a huge amount of 2D-coordinates, associated with a value, e.g.:

  x   |   y   | value
27.50   52.15   12.51
61.83   13.32   57.56
36.23   21.83   41.73
40.46   85.67   25.20
...


The data is not tabular and I Want the points between two data-points to be interpolated in some way (which way is not really clear, yet)

I want to preset the data as heatmap like this:


Is there any ready-to-use package for PSTricks or TikZ to do it?
","You can also use pgfplots. I use the same data and the same number of point of Herbert, and the default matlab color map. You have to compile the following code with LuaLaTeX because it needs a lot of memory. It needs also a lot of time (about 2 minutes in my PC) so its better to compile it once and then insert the pdf file of your graph as an image.

\documentclass[border=10pt]{standalone}
\usepackage{pgfplots}
\usepackage{xcolor}

\pgfplotsset{compat=newest}

\begin{document}
\begin{tikzpicture}
\begin{axis}[
    colormap/jet,
    colorbar,
    view={0}{90}]
    \addplot3[surf,shader=flat] file {data-map.dat};
\end{axis}
\end{tikzpicture}
\end{document} 



"
2293,2293,3653,Is it copyright infringement by US copyright law if someone else modifies and uses my design?,"My company is in a small town and there are not any graphic designers but we have enough business in the town and the surrounding area to support us.  But because of the small town nature some business owners do not know all the laws.  And since I am starting this from a career in architecture I am not quite clear on copyrights.  So here is my problem.  

I created a sign that has an oval with scrolls and flowers in different colors on a field of turquoise.  The client did not want to spend the money on a logo design so I said that I will  just retain the rights so that she would have to come to me for the approval to use the logo on anything else.  So anyway everything seems to be fine, I do her business cards and now all of a sudden I see a sign at the street.  I quoted her on this job figuring in using the logo.  Apparently this company did for much less and you can tell by the quality.

But here is my problem.  She had a jpeg that I allowed her to have so she could create her own fliers and I was ok with that since it would not have made me much if any money.  Well I am looking at the sign that the other person did and all that was done is they made a longer oval since this sign is more rectangle and used a different font.  And put this over the design that I did.  To me this is copyright infringement since the client did not want to buy all the rights.  But who do I address?  The client or the person that did the sign?
",user15955,https://graphicdesign.stackexchange.com/users/15955,"Simply put, any copying of someone else's work is copyright infringement unless the copying is authorized by the owner of the work or the copying falls under a ""fair use"" exemption.

What it's going to come down to here, however, is who owns the work.

In a case of an employer-employee relationship, the owner of the work is usually the employer.

In the case of a client-service relationship, the owner of the work needs to be specified in the contract.

Lack of a contract is a bad idea for both parties as in practical terms it will become more difficult for either side to prove what the nature of the agreement was.  Circumstantial evidence such as the fact the client paid you a sum of money and that the design appears to have been created specifically for the client may suggest, but not prove, that the nature of the agreement was that the client bought the rights to the design.  Lack of a paper contract saying otherwise would be a bad thing if you wanted to pursue this further.
",thomasrutter,https://graphicdesign.stackexchange.com/users/5493,http://graphicdesign.stackexchange.com/questions/21905/is-it-copyright-infringement-by-us-copyright-law-if-someone-else-modifies-and-us,LIFE_ARTS,graphicdesign.stackexchange.com,0.8888888888888888,0.6666666666666666,0.0,0.6666666666666666,1.0,1.0,0.7777777777777778,0.7777777777777778,0.3333333333333333,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,0.8888888888888888,0.7333333333333333,0.0,0.0,1.0,0.7777777777777778,"If someone modifies and uses my design, does it violate American copyright law?","My company is in a small town and there are not any graphic designers but we have enough business in the town and the surrounding area to support us.  But because of the small town nature some business owners do not know all the laws.  And since I am starting this from a career in architecture I am not quite clear on copyrights.  So here is my problem.  

I created a sign that has an oval with scrolls and flowers in different colors on a field of turquoise.  The client did not want to spend the money on a logo design so I said that I will  just retain the rights so that she would have to come to me for the approval to use the logo on anything else.  So anyway everything seems to be fine, I do her business cards and now all of a sudden I see a sign at the street.  I quoted her on this job figuring in using the logo.  Apparently this company did for much less and you can tell by the quality.

But here is my problem.  She had a jpeg that I allowed her to have so she could create her own fliers and I was ok with that since it would not have made me much if any money.  Well I am looking at the sign that the other person did and all that was done is they made a longer oval since this sign is more rectangle and used a different font.  And put this over the design that I did.  To me this is copyright infringement since the client did not want to buy all the rights.  But who do I address?  The client or the person that did the sign?
","Simply put, any copying of someone else's work is copyright infringement unless the copying is authorized by the owner of the work or the copying falls under a ""fair use"" exemption.

What it's going to come down to here, however, is who owns the work.

In a case of an employer-employee relationship, the owner of the work is usually the employer.

In the case of a client-service relationship, the owner of the work needs to be specified in the contract.

Lack of a contract is a bad idea for both parties as in practical terms it will become more difficult for either side to prove what the nature of the agreement was.  Circumstantial evidence such as the fact the client paid you a sum of money and that the design appears to have been created specifically for the client may suggest, but not prove, that the nature of the agreement was that the client bought the rights to the design.  Lack of a paper contract saying otherwise would be a bad thing if you wanted to pursue this further.
"
5732,5732,9081,Scatterplots for subsets of multivariate data [Updated],"Update/Re-write

There has been a lot of ambiguity over what i'm am trying to do with this question so I have decided to give it a full rewrite. I'm really sorry for the confusion. If you want to see the background please see the edit history. I hope things are clearer now..

I have some data made up into the following fashion:

datac =
  {
   data1 = RandomReal[1, {7, 3}],
   data2 = RandomReal[1, {13, 3}],
   data3 = RandomReal[1, {19, 3}],
   data4 = RandomReal[1, {16, 3}],
   data5 = RandomReal[1, {5, 3}]
   };


data1 through data5 are subsets of a multivariate dataset with 3 independent variables. data1, for example, is composed of 7 individual data points (each with 3 variables).

If I use the following function: 

Needs[""StatisticalPlots`""]
pairwisecol[data_, col_] := 
PairwiseScatterPlot[data, 
                      PlotStyle -&gt; col, 
                      DataTicks -&gt; True,  
                      DataLabels -&gt; {""x"", ""y"", ""z""}]


I can create a combined plot comparing the various subsets. E.g.

Show[{pairwisecol[data1, Red], 
      pairwisecol[data2, Blue], 
      pairwisecol[data3, Green],  
      pairwisecol[data4, Purple], 
      pairwisecol[data5, Orange]}]




This curently has the major drawbacks that each subset has to be defined and have a colour explicitly assigned to it. Also, Show in this instance overlays all of the DataTicks etc, rather than just the elements from the first plot (as is normally the case with Show[{Plot1,Plot2}]).

What I'm looking for is a way to use the whole (partitioned) dataset datac to generate such a plot/diagram. i.e. something like,

Show[pairwisecol[#, Red] &amp; /@ datac]


but, with Red being replaced by a series of colours to represent each subset (like in the plot shown).

...Alternatively, starting with a 2-level list e.g.

datap = RandomReal[1, {60, 3}];


and a definition of sublist partitions,

parts = {7, 13, 19, 16, 5};


or

partspos = {[[1;;7]], [[8;;20]], [[21;;39]], [[40;;55]], [[56;;60]]};


then defining a function something like:

pairwiseP[data_, partlist_] := ...


that would partition datap into appropriate sublists, create a series of PairwiseScatterPlot's (each with a different plot colour) and then combine them using Show. 

Note that this example has n = 3 independent variables. I am looking for a method that works for 1 &lt; n &lt; ~20.

Can anyone suggest how to do this?
",geordie,https://mathematica.stackexchange.com/users/4626,"Problem with Ticks can be solved by fixing DataRange. I don't know what is the problem with color specification for You, I hope I have not missunderstood anything:

Needs[""StatisticalPlots`""]

datap = RandomReal[1, {60, 5}]; (*it works for any n*)
parts = {12, 13, 12, 13, 5}; (* remember that Total@parts == Length@datap *)
colors = {Red, Green, Orange, Blue, Black}; (*or some random, as You like*)

data = Take[datap, {1, 0} + #] &amp; /@ (Partition[Prepend[Accumulate@parts, 0], 2, 1])


Show[
     PairwiseScatterPlot[data[[ #]], DataRanges -&gt; {{0, 1}, {0, 1}}, DataTicks -&gt; True, 
                         PlotStyle -&gt; colors[[ #]], ImageSize -&gt; 500
                        ] &amp; /@ Range[Length@parts]
    ]




I suspect datap can be splitted in simpler way but I have blockout now in my head.
",Kuba,https://mathematica.stackexchange.com/users/5478,http://mathematica.stackexchange.com/questions/26595/scatterplots-for-subsets-of-multivariate-data-updated,TECHNOLOGY,mathematica.stackexchange.com,0.7777777777777778,0.4444444444444444,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.5555555555555556,0.8888888888888888,0.6666666666666666,1.0,0.8888888888888888,0.8,1.0,0.3333333333333333,0.3333333333333333,0.6666666666666666,Scatter diagram [update] of multivariate data subset,"Update/Re-write

There has been a lot of ambiguity over what i'm am trying to do with this question so I have decided to give it a full rewrite. I'm really sorry for the confusion. If you want to see the background please see the edit history. I hope things are clearer now..

I have some data made up into the following fashion:

datac =
  {
   data1 = RandomReal[1, {7, 3}],
   data2 = RandomReal[1, {13, 3}],
   data3 = RandomReal[1, {19, 3}],
   data4 = RandomReal[1, {16, 3}],
   data5 = RandomReal[1, {5, 3}]
   };


data1 through data5 are subsets of a multivariate dataset with 3 independent variables. data1, for example, is composed of 7 individual data points (each with 3 variables).

If I use the following function: 

Needs[""StatisticalPlots`""]
pairwisecol[data_, col_] := 
PairwiseScatterPlot[data, 
                      PlotStyle -&gt; col, 
                      DataTicks -&gt; True,  
                      DataLabels -&gt; {""x"", ""y"", ""z""}]


I can create a combined plot comparing the various subsets. E.g.

Show[{pairwisecol[data1, Red], 
      pairwisecol[data2, Blue], 
      pairwisecol[data3, Green],  
      pairwisecol[data4, Purple], 
      pairwisecol[data5, Orange]}]




This curently has the major drawbacks that each subset has to be defined and have a colour explicitly assigned to it. Also, Show in this instance overlays all of the DataTicks etc, rather than just the elements from the first plot (as is normally the case with Show[{Plot1,Plot2}]).

What I'm looking for is a way to use the whole (partitioned) dataset datac to generate such a plot/diagram. i.e. something like,

Show[pairwisecol[#, Red] &amp; /@ datac]


but, with Red being replaced by a series of colours to represent each subset (like in the plot shown).

...Alternatively, starting with a 2-level list e.g.

datap = RandomReal[1, {60, 3}];


and a definition of sublist partitions,

parts = {7, 13, 19, 16, 5};


or

partspos = {[[1;;7]], [[8;;20]], [[21;;39]], [[40;;55]], [[56;;60]]};


then defining a function something like:

pairwiseP[data_, partlist_] := ...


that would partition datap into appropriate sublists, create a series of PairwiseScatterPlot's (each with a different plot colour) and then combine them using Show. 

Note that this example has n = 3 independent variables. I am looking for a method that works for 1 &lt; n &lt; ~20.

Can anyone suggest how to do this?
","Problem with Ticks can be solved by fixing DataRange. I don't know what is the problem with color specification for You, I hope I have not missunderstood anything:

Needs[""StatisticalPlots`""]

datap = RandomReal[1, {60, 5}]; (*it works for any n*)
parts = {12, 13, 12, 13, 5}; (* remember that Total@parts == Length@datap *)
colors = {Red, Green, Orange, Blue, Black}; (*or some random, as You like*)

data = Take[datap, {1, 0} + #] &amp; /@ (Partition[Prepend[Accumulate@parts, 0], 2, 1])


Show[
     PairwiseScatterPlot[data[[ #]], DataRanges -&gt; {{0, 1}, {0, 1}}, DataTicks -&gt; True, 
                         PlotStyle -&gt; colors[[ #]], ImageSize -&gt; 500
                        ] &amp; /@ Range[Length@parts]
    ]




I suspect datap can be splitted in simpler way but I have blockout now in my head.
"
4359,4359,6934,Insert a Views Block into a node in Drupal 7,"[Drupal 7] 

I have a block I created in Views called ""handy_tips-block_1"".

Now I want to insert it into the body field of my node.

How do I do this?

I found a guide on here, which suggests to use the following code:

&lt;?php
print $block = module_invoke('views', 'block_view', 'handy_tips-block_1');
print render($block['content']['#content']);
?&gt;


However, all what is printed out are the words ""Array"".
(I have enabled the PHP input filter for the body field).

Note: in the posted code, I have also tried substituting 'views' with various items such as ""block"". I have used 'handy_tips-block_1' as the ID, because that is what is displayed on the configuration link of the block administration page. 
",big_smile,https://drupal.stackexchange.com/users/1606,"I realise this is an old thread now, but I was looking for this too and found the BlockReference module. It allows you to associate a block with a node as a field.

It works a treat!
",JMC,https://drupal.stackexchange.com/users/26101,http://drupal.stackexchange.com/questions/13297/insert-a-views-block-into-a-node-in-drupal-7,TECHNOLOGY,drupal.stackexchange.com,1.0,0.6666666666666666,0.0,1.0,1.0,1.0,0.5,0.3333333333333333,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.8333333333333334,0.8333333333333334,0.6666666666666666,1.0,1.0,0.8,0.0,0.5,0.0,0.8333333333333334,Inserting a view block into a node in Drupal 7,"[Drupal 7] 

I have a block I created in Views called ""handy_tips-block_1"".

Now I want to insert it into the body field of my node.

How do I do this?

I found a guide on here, which suggests to use the following code:

&lt;?php
print $block = module_invoke('views', 'block_view', 'handy_tips-block_1');
print render($block['content']['#content']);
?&gt;


However, all what is printed out are the words ""Array"".
(I have enabled the PHP input filter for the body field).

Note: in the posted code, I have also tried substituting 'views' with various items such as ""block"". I have used 'handy_tips-block_1' as the ID, because that is what is displayed on the configuration link of the block administration page. 
","I'm now aware that this is an old thread, but I'm also looking for this and I found the blockreference module. It allows you to associate blocks and nodes as fields."
1862,1862,2959,Why is a precoder necessary for DQPSK and what does it accomplish?,"I've implemented a soft-decoder for DQPSK using the wonderful answers I received here:

How to soft decode DQPSK?

To get the soft-decoder working properly I needed to precode the data I was sending out.  I implemented the precoder mentioned in this paper:

$I_k=\overline{u_k \oplus v_k}*(u_k \oplus I_{k-1})+(u_k \oplus v_k)*(v_k \oplus Q_{k-1})$
$Q_k=\overline{u_k \oplus v_k}*(v_k \oplus Q_{k-1})+(u_k \oplus v_k)*(u_k \oplus I_{k-1})$

I'd like to know why this precoder is necessary -- what does that complicated expression of XORs actually accomplish?  

Here's a table showing what the equation yields.  If ""to_encode"" is 00, the to_send symbol is the same as the previous (""prev"") symbol.  If the ""to_encode"" is 11, the to_send symbol is the previous symbol xor 11.  What is the meaning in other cases?


to_encode prev  to send
[ 0 0 ] [ 0 0 ] [ 0 0 ]
[ 0 1 ] [ 0 0 ] [ 1 0 ]
[ 1 0 ] [ 0 0 ] [ 0 1 ]
[ 1 1 ] [ 0 0 ] [ 1 1 ]
[ 0 0 ] [ 0 1 ] [ 0 1 ]
[ 0 1 ] [ 0 1 ] [ 0 0 ]
[ 1 0 ] [ 0 1 ] [ 1 1 ]
[ 1 1 ] [ 0 1 ] [ 1 0 ]
[ 0 0 ] [ 1 0 ] [ 1 0 ]
[ 0 1 ] [ 1 0 ] [ 1 1 ]
[ 1 0 ] [ 1 0 ] [ 0 0 ]
[ 1 1 ] [ 1 0 ] [ 0 1 ]
[ 0 0 ] [ 1 1 ] [ 1 1 ]
[ 0 1 ] [ 1 1 ] [ 0 1 ]
[ 1 0 ] [ 1 1 ] [ 1 0 ]
[ 1 1 ] [ 1 1 ] [ 0 0 ]

",Dan Sandberg,https://dsp.stackexchange.com/users/3435,"Differential encoder to the Gray mapping is to remove the 90 degree phase variance, e.g. the received constellations are 90 degree rotated. The receiver doesn't reply on the absolute phase of the QAM constellations but uses the transition between consecutive symbols to demodulate the data.  
",Phil Lin,https://dsp.stackexchange.com/users/16655,http://dsp.stackexchange.com/questions/8119/why-is-a-precoder-necessary-for-dqpsk-and-what-does-it-accomplish,TECHNOLOGY,dsp.stackexchange.com,1.0,0.7777777777777778,0.0,1.0,0.6666666666666666,1.0,0.5555555555555556,0.3333333333333333,1.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.0,1.0,1.0,Why does DQPSK need precoding? What does it accomplish?,"I've implemented a soft-decoder for DQPSK using the wonderful answers I received here:

How to soft decode DQPSK?

To get the soft-decoder working properly I needed to precode the data I was sending out.  I implemented the precoder mentioned in this paper:

$I_k=\overline{u_k \oplus v_k}*(u_k \oplus I_{k-1})+(u_k \oplus v_k)*(v_k \oplus Q_{k-1})$
$Q_k=\overline{u_k \oplus v_k}*(v_k \oplus Q_{k-1})+(u_k \oplus v_k)*(u_k \oplus I_{k-1})$

I'd like to know why this precoder is necessary -- what does that complicated expression of XORs actually accomplish?  

Here's a table showing what the equation yields.  If ""to_encode"" is 00, the to_send symbol is the same as the previous (""prev"") symbol.  If the ""to_encode"" is 11, the to_send symbol is the previous symbol xor 11.  What is the meaning in other cases?


to_encode prev  to send
[ 0 0 ] [ 0 0 ] [ 0 0 ]
[ 0 1 ] [ 0 0 ] [ 1 0 ]
[ 1 0 ] [ 0 0 ] [ 0 1 ]
[ 1 1 ] [ 0 0 ] [ 1 1 ]
[ 0 0 ] [ 0 1 ] [ 0 1 ]
[ 0 1 ] [ 0 1 ] [ 0 0 ]
[ 1 0 ] [ 0 1 ] [ 1 1 ]
[ 1 1 ] [ 0 1 ] [ 1 0 ]
[ 0 0 ] [ 1 0 ] [ 1 0 ]
[ 0 1 ] [ 1 0 ] [ 1 1 ]
[ 1 0 ] [ 1 0 ] [ 0 0 ]
[ 1 1 ] [ 1 0 ] [ 0 1 ]
[ 0 0 ] [ 1 1 ] [ 1 1 ]
[ 0 1 ] [ 1 1 ] [ 0 1 ]
[ 1 0 ] [ 1 1 ] [ 1 0 ]
[ 1 1 ] [ 1 1 ] [ 0 0 ]

","Differential encoder to the Gray mapping is to remove the 90 degree phase variance, e.g. the received constellations are 90 degree rotated. The receiver doesn't reply on the absolute phase of the QAM constellations but uses the transition between consecutive symbols to demodulate the data.  
"
2440,2440,3895,Magento (1.7) Bundled Product with FREE Product Option,"I'm looking to create a bundle offer where customers can buy two items from a collection (30 products with varying prices) and they get a fixed third item which is a FREE product.

As the final price will vary depending on what the customer chooses, how do I make the basket subtotal add the two items but ignore the third priced item?

Hope that makes sense 
",Joe,https://magento.stackexchange.com/users/16572,"Since the third item is fixed, you can use shopping cart price rules:


if cart contains at least two items of category X
then add product Y as a gift


However you need a small extension for the ""add product as a gift"" action in shopping cart price rules:

You can get it for free here: https://github.com/code4business/freeproduct

(Disclaimer: I was involved in the development of this extension)
",Fabian Schmengler,https://magento.stackexchange.com/users/243,http://magento.stackexchange.com/questions/66874/magento-1-7-bundled-product-with-free-product-option,TECHNOLOGY,magento.stackexchange.com,0.8888888888888888,0.4444444444444444,0.0,0.6666666666666666,0.6666666666666666,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.4444444444444444,0.8888888888888888,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.3333333333333333,0.8888888888888888,Magento (1.7) bundled products with free product options,"I'm looking to create a bundle offer where customers can buy two projects (30 products with different prices) from a collection, and they get a fixed third project, which is a free product.","Since the third item is fixed, you can use shopping cart price rules:


if cart contains at least two items of category X
then add product Y as a gift


However you need a small extension for the ""add product as a gift"" action in shopping cart price rules:

You can get it for free here: https://github.com/code4business/freeproduct

(Disclaimer: I was involved in the development of this extension)
"
2435,2435,3884,Setting a default placeholder image WITHOUT link,"Can anyone help?

I'm trying to show a default placeholder image on my posts when the user hasn't uploaded an image.

I have the below code BUT i need to rewrite it so that the link isn't applied to the placeholder image - only the uploaded image.

Unfortunately my PHP isn't great at all so would appreciate some help.. 

&lt;div class=""imageContainer""&gt;&lt;a href=""&lt;?php the_permalink(); ?&gt;""&gt;
           &lt;?php
    // Must be inside a loop.

    if ( has_post_thumbnail() ) {
        the_post_thumbnail('size-2');
    }
    else {
        echo '&lt;img src=""' . get_bloginfo( 'stylesheet_directory' ) . '/images/shared/placeholder.jpg"" /&gt;';
    }
    ?&gt;
            &lt;/a&gt;&lt;/div&gt;

",V Neal,https://wordpress.stackexchange.com/users/13998,"You can filter the thumbnail HTML before it is printed out. If it is empty – return the placeholder.

This should go into your theme’s functions.php:

add_filter( 'post_thumbnail_html', 'wpse_63591_default_thumb' );

function wpse_63591_default_thumb( $html )
{
    if ( '' !== $html )
    {
        return '&lt;a href=""' . get_permalink() . '""&gt;' . $html . '&lt;/a&gt;';
    }

    return '&lt;img src=""' . get_bloginfo( 'stylesheet_directory' ) . '/images/shared/placeholder.jpg"" /&gt;';    
}


In your template just use 

the_post_thumbnail('size-2');


No conditionals or complicated PHP needed anymore. :)
",fuxia,https://wordpress.stackexchange.com/users/73,http://wordpress.stackexchange.com/questions/63591/setting-a-default-placeholder-image-without-link,TECHNOLOGY,wordpress.stackexchange.com,0.7777777777777778,0.5555555555555556,0.0,0.0,1.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9,1.0,0.0,0.0,0.8888888888888888,Set default placeholder image without links,"Can anyone help?

I'm trying to show a default placeholder image on my posts when the user hasn't uploaded an image.

I have the below code BUT i need to rewrite it so that the link isn't applied to the placeholder image - only the uploaded image.

Unfortunately my PHP isn't great at all so would appreciate some help.. 

&lt;div class=""imageContainer""&gt;&lt;a href=""&lt;?php the_permalink(); ?&gt;""&gt;
           &lt;?php
    // Must be inside a loop.

    if ( has_post_thumbnail() ) {
        the_post_thumbnail('size-2');
    }
    else {
        echo '&lt;img src=""' . get_bloginfo( 'stylesheet_directory' ) . '/images/shared/placeholder.jpg"" /&gt;';
    }
    ?&gt;
            &lt;/a&gt;&lt;/div&gt;

","You can filter the thumbnail HTML before it is printed out. If it is empty – return the placeholder.

This should go into your theme’s functions.php:

add_filter( 'post_thumbnail_html', 'wpse_63591_default_thumb' );

function wpse_63591_default_thumb( $html )
{
    if ( '' !== $html )
    {
        return '&lt;a href=""' . get_permalink() . '""&gt;' . $html . '&lt;/a&gt;';
    }

    return '&lt;img src=""' . get_bloginfo( 'stylesheet_directory' ) . '/images/shared/placeholder.jpg"" /&gt;';    
}


In your template just use 

the_post_thumbnail('size-2');


No conditionals or complicated PHP needed anymore. :)
"
693,693,1093,Why doesn't Perl's Spreadsheet::ParseExcel never return from $parser->parse('test.xls')?,"The spreadsheet is Excel 97-2003 compatible and permissions 777

use strict;
use Spreadsheet::ParseExcel;
print ""Content-type: text/html\n\n"";   
my $parser   = Spreadsheet::ParseExcel-&gt;new();
print ""&lt;br&gt;gets here:"".__LINE__; 
my $workbook = $parser-&gt;parse('test.xls');
print ""&lt;br&gt;never gets here:"".__LINE__; 

",zzapper,https://stackoverflow.com/users/94335,"If it truly is never returning then it must be getting stuck in some kind of infinite loop. Try running your script on the command line using the Perl debugger.

~$ perl -d my_script.pl


Note that CGI scripts can also be read in this way, and that they accept command line arguments in the form KEY=VAL like so

~$ perl -d my_cgi.cgi var=foo var2=bar bananas=delicious


The perl debugger will tell you a list of commands it accepts if you type 'h', but the most important ones are:

n: go to the next line

s: step into the next line (if it is a sub, otherwise is identical to 'n')

v: view the next few lines (can be used repeatedly)

c: continue to a line or subroutine


If you find that there is some kind of infinite loop problem, then submit it as a bug on http://rt.cpan.org (specificially, here: https://rt.cpan.org/Public/Dist/Display.html?Name=Spreadsheet-ParseExcel)
",Kaoru,https://stackoverflow.com/users/259383,http://stackoverflow.com/questions/2191496/why-doesnt-perls-spreadsheetparseexcel-never-return-from-parser-parsetes,STACKOVERFLOW,stackoverflow.com,1.0,1.0,1.0,1.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.6666666666666666,1.0,0.8,1.0,0.0,1.0,1.0,Why does Perl's spreadsheet:: parseexcel never return from $Parser - > parse ('test. XLS')?,"The spreadsheet is Excel 97-2003 compatible and permissions 777

use strict;
use Spreadsheet::ParseExcel;
print ""Content-type: text/html\n\n"";   
my $parser   = Spreadsheet::ParseExcel-&gt;new();
print ""&lt;br&gt;gets here:"".__LINE__; 
my $workbook = $parser-&gt;parse('test.xls');
print ""&lt;br&gt;never gets here:"".__LINE__; 

","If it truly is never returning then it must be getting stuck in some kind of infinite loop. Try running your script on the command line using the Perl debugger.

~$ perl -d my_script.pl


Note that CGI scripts can also be read in this way, and that they accept command line arguments in the form KEY=VAL like so

~$ perl -d my_cgi.cgi var=foo var2=bar bananas=delicious


The perl debugger will tell you a list of commands it accepts if you type 'h', but the most important ones are:

n: go to the next line

s: step into the next line (if it is a sub, otherwise is identical to 'n')

v: view the next few lines (can be used repeatedly)

c: continue to a line or subroutine


If you find that there is some kind of infinite loop problem, then submit it as a bug on http://rt.cpan.org (specificially, here: https://rt.cpan.org/Public/Dist/Display.html?Name=Spreadsheet-ParseExcel)
"
2802,2802,4467,Law of Multiple Proportions: What is the significance of small whole numbers?,"I'm new to Chemistry and in my textbook, it describes the Law of Definite Proportions and then goes on to describe the Law of Multiple Proportions.

The example they give is carbon monoxide and carbon dioxide, where the mass ratio of oxygen to carbon in carbon dioxide is 2.67:1 and the mass ratio of oxygen to carbon in carbon monoxide is 1.33:1.

I understand the above example, and I understand that when you compare them in the following way:

2.67g (proportion of oxygen to 1g carbon in carbon dioxide)/ 1.33g (proportion of oxygen to 1g carbon in carbon monoxide) = 2.00, a small whole number.

$\frac{Mass~oxygen~to~1g~carbon~in~carbon~dioxide}{Mass~oxygen~to~1g~carbon~in~carbon~monoxide}$ = $\frac{2.67g}{1.33g}$ = 2.00

My textbook doesn't describe what a small whole number is, or what it means... just that, in this example, 2.00 is a small whole number.

What is the significance of the 2.00?

I understand that carbon dioxide has double the oxygen. Is this where the 2.00 plays a role?
",Melanie Shebel,https://chemistry.stackexchange.com/users/402,"The law of multiple proportions is largely obsolete these days because we all believe that atoms exist.  Prior to about 1900 this and similar laws were used to show that, for example, the ratio of oxygen in $\ce{CO}$ to oxygen in $\ce{CO2}$ is 2:1.

Of course that's trivially obvious when we write the formulas, but before we believed in atoms the ""small whole number"" ratios were used as an example of an experimental situation (the 2:1 ratio) could be explained by atoms (i.e. quantizing atomic masses.)

Today, the law causes more confusion than it cures.  Atoms are here to stay.
",Paul J. Gans,https://chemistry.stackexchange.com/users/675,http://chemistry.stackexchange.com/questions/3975/law-of-multiple-proportions-what-is-the-significance-of-small-whole-numbers,SCIENCE,chemistry.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.4444444444444444,0.6666666666666666,0.0,0.0,0.6666666666666666,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,1.0,0.0,0.7777777777777778,0.8888888888888888,0.5555555555555556,1.0,1.0,0.8666666666666666,0.0,0.0,1.0,0.8888888888888888,Law of multiple proportions: what is the meaning of small integers?,"I'm new to Chemistry and in my textbook, it describes the Law of Definite Proportions and then goes on to describe the Law of Multiple Proportions.

The example they give is carbon monoxide and carbon dioxide, where the mass ratio of oxygen to carbon in carbon dioxide is 2.67:1 and the mass ratio of oxygen to carbon in carbon monoxide is 1.33:1.

I understand the above example, and I understand that when you compare them in the following way:

2.67g (proportion of oxygen to 1g carbon in carbon dioxide)/ 1.33g (proportion of oxygen to 1g carbon in carbon monoxide) = 2.00, a small whole number.

$\frac{Mass~oxygen~to~1g~carbon~in~carbon~dioxide}{Mass~oxygen~to~1g~carbon~in~carbon~monoxide}$ = $\frac{2.67g}{1.33g}$ = 2.00

My textbook doesn't describe what a small whole number is, or what it means... just that, in this example, 2.00 is a small whole number.

What is the significance of the 2.00?

I understand that carbon dioxide has double the oxygen. Is this where the 2.00 plays a role?
","The law of multiple proportions is largely obsolete these days because we all believe that atoms exist.  Prior to about 1900 this and similar laws were used to show that, for example, the ratio of oxygen in $\ce{CO}$ to oxygen in $\ce{CO2}$ is 2:1.

Of course that's trivially obvious when we write the formulas, but before we believed in atoms the ""small whole number"" ratios were used as an example of an experimental situation (the 2:1 ratio) could be explained by atoms (i.e. quantizing atomic masses.)

Today, the law causes more confusion than it cures.  Atoms are here to stay.
"
1684,1684,2661,Putting Linux processes on certain CPU cores,"
  Possible Duplicate:
  How can I set the processor affinity of a process on Linux?  




Computer CPUs have many cores insde them nowadays.

I have always wondered if there is a way to, when I start a process on the Linux command line, specify which particular core or cores that process might use?

For example, can I start a massive grep task and say ""use ALL of CPU2 for yourself"".

Or could I start a find task and say ""never leave CPU3"".

Or maybe I could start a video decoding task and say ""use whatever is available on CPU1 and CPU2""

OR, is there no way to do this because it is not needed and the OS is doing this kind of stuff intelligently by itself (based on nice levels and general resource usage of the process etc)

IfyouknowwhatImean
",Daniel,https://unix.stackexchange.com/users/23149,"See the taskset utility.  Should be exactly what you're looking for. 
",Jim Paris,https://unix.stackexchange.com/users/21804,http://unix.stackexchange.com/questions/47704/putting-linux-processes-on-certain-cpu-cores,TECHNOLOGY,unix.stackexchange.com,1.0,0.4444444444444444,0.0,1.0,1.0,1.0,0.4444444444444444,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.8888888888888888,0.8888888888888888,0.5,1.0,1.0,0.8,0.6666666666666666,0.0,0.0,0.8888888888888888,Putting Linux processes on some CPU cores,"
  Possible Duplicate:
  How can I set the processor affinity of a process on Linux?  




Computer CPUs have many cores insde them nowadays.

I have always wondered if there is a way to, when I start a process on the Linux command line, specify which particular core or cores that process might use?

For example, can I start a massive grep task and say ""use ALL of CPU2 for yourself"".

Or could I start a find task and say ""never leave CPU3"".

Or maybe I could start a video decoding task and say ""use whatever is available on CPU1 and CPU2""

OR, is there no way to do this because it is not needed and the OS is doing this kind of stuff intelligently by itself (based on nice levels and general resource usage of the process etc)

IfyouknowwhatImean
","See the taskset utility.  Should be exactly what you're looking for. 
"
73,73,115,"Sorting the output of ""find""?","I need to be able to alphabetically sort the output of find before piping it to a command. Entering | sort | between didn't work, so what could I do?

find folder1 folder2 -name ""*.txt"" -print0 | xargs -0 myCommand

",Industrial,https://unix.stackexchange.com/users/3208,"I think you need the -n flag for sort#

According to man sort:

-n, --numeric-sort
    compare according to string numerical value


edit

The print0 may have something to do with this, I just tested this. Take the print0 out, you can null terminate the string in sort using the -z flag
",whoami,https://unix.stackexchange.com/users/3368,http://unix.stackexchange.com/questions/34325/sorting-the-output-of-find,TECHNOLOGY,unix.stackexchange.com,1.0,0.5555555555555556,0.0,0.5,1.0,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.8888888888888888,0.7777777777777778,0.5555555555555556,0.8888888888888888,1.0,0.8,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.8888888888888888,"Sort the output of ""find""?","I need to be able to sort the output of find alphabetically before sending it to the command. Sorting by typing in the middle doesn't work, so what should I do?","I think you need the -n flag for sort#

According to man sort:

-n, --numeric-sort
    compare according to string numerical value


edit

The print0 may have something to do with this, I just tested this. Take the print0 out, you can null terminate the string in sort using the -z flag
"
4218,4218,6727,"When and why will an OS initialise memory to 0xCD, 0xDD, etc. on malloc/free/new/delete?","I know that the OS will sometimes initialise memory with certain patterns such as 0xCD and 0xDD.  What I want to know is when and why this happens.

When

Is this specific to the compiler used?

Do malloc/new and free/delete work in the same way with regard to this?

Is it platform specific?

Will it occur on other operating systems, such as Linux or VxWorks?

Why

My understanding is this only occurs in Win32 debug configuration, and it is used to detect memory overruns and to help the compiler catch exceptions.

Can you give any practical examples as to how this initialisation is useful?

I remember reading something (maybe in Code Complete 2) that it is good to initialise memory to a known pattern when allocating it, and certain patterns will trigger interrupts in Win32 which will result in exceptions showing in the debugger.

How portable is this?
",LeopardSkinPillBoxHat,https://stackoverflow.com/users/22489,"It's compiler and OS specific, Visual studio sets different kinds of memory to different values so that in the debugger you can easily see if you have overun into into malloced memory, a fixed array or an uninitialised object.
Somebody will post the details while I am googling them...

http://msdn.microsoft.com/en-us/library/974tc9t1.aspx
",Martin Beckett,https://stackoverflow.com/users/10897,http://stackoverflow.com/questions/370195/when-and-why-will-an-os-initialise-memory-to-0xcd-0xdd-etc-on-malloc-free-new,STACKOVERFLOW,stackoverflow.com,1.0,0.3333333333333333,0.0,1.0,1.0,1.0,0.3333333333333333,0.3333333333333333,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.0,1.0,1.0,0.3333333333333333,0.6666666666666666,1.0,0.6,0.0,1.0,0.0,1.0,"When and why does the operating system initialize memory to 0xcd, 0xdd, etc. in malloc / free / new / delete?","I know that the OS will sometimes initialise memory with certain patterns such as 0xCD and 0xDD.  What I want to know is when and why this happens.

When

Is this specific to the compiler used?

Do malloc/new and free/delete work in the same way with regard to this?

Is it platform specific?

Will it occur on other operating systems, such as Linux or VxWorks?

Why

My understanding is this only occurs in Win32 debug configuration, and it is used to detect memory overruns and to help the compiler catch exceptions.

Can you give any practical examples as to how this initialisation is useful?

I remember reading something (maybe in Code Complete 2) that it is good to initialise memory to a known pattern when allocating it, and certain patterns will trigger interrupts in Win32 which will result in exceptions showing in the debugger.

How portable is this?
","It is specific to compiler and operating system. Visual studio sets different types of memory to different values, so that in debugger, you can easily see whether it is over run to malloc memory, fixed array or uninitialized objects."
1796,1796,2853,Is there a comprehensive life science techniques/methods database?,"There are so many techniques/methodologies in the life sciences that we can use to interrogate interesting questions. The thing is, most of us are completely unaware of the available methods we can employ. Rather, we go with the techniques we are familiar with or that are popular in our subdomains at the time. But that's pretty limiting.

So I'm wondering... we have databases for everything else... is there one for life sciences techniques/methods? Something like this could be immensely helpful in experimental planning. In particular, I think a comprehensive database would help scientists break outside of their spheres of familiarity and to employ less known (but potentially illuminating) methods to their questions.

I know there are journals that publish protocols and methods, but they are fragmented and don't encompass everything. 

Does what I'm looking for exist? If not, how might one go about creating such a tool? 
",Alex,https://biology.stackexchange.com/users/1909,"There's Benchfly, which is a video-based protocol library:

http://www.benchfly.com/video-protocols.php

There's also JOVE, which is a peer-reviewed video journal that sometimes covers protocols:

http://www.jove.com/
",Atticus29,https://biology.stackexchange.com/users/1906,http://biology.stackexchange.com/questions/7208/is-there-a-comprehensive-life-science-techniques-methods-database,SCIENCE,biology.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,0.5,1.0,0.5,0.6666666666666666,0.7777777777777778,0.6666666666666666,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,1.0,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.7333333333333333,0.0,0.0,0.3333333333333333,0.8888888888888888,Is there a comprehensive database of life science technology / methods?,"There are so many techniques/methodologies in the life sciences that we can use to interrogate interesting questions. The thing is, most of us are completely unaware of the available methods we can employ. Rather, we go with the techniques we are familiar with or that are popular in our subdomains at the time. But that's pretty limiting.

So I'm wondering... we have databases for everything else... is there one for life sciences techniques/methods? Something like this could be immensely helpful in experimental planning. In particular, I think a comprehensive database would help scientists break outside of their spheres of familiarity and to employ less known (but potentially illuminating) methods to their questions.

I know there are journals that publish protocols and methods, but they are fragmented and don't encompass everything. 

Does what I'm looking for exist? If not, how might one go about creating such a tool? 
","There's Benchfly, which is a video-based protocol library:

http://www.benchfly.com/video-protocols.php

There's also JOVE, which is a peer-reviewed video journal that sometimes covers protocols:

http://www.jove.com/
"
2296,2296,3660,SQL: Saving MIME-Type or Extension?,"What's the best way to store information about a BLOB in the DB? The File-Extension (.txt, .rar) or the MIME-Type?

Also, what's better: Store the Filename with or without extension (""file"" or ""file.txt"")?

What I'm primarily talking about is a Desktop-App, not a Web-Application.
",SeToY,https://stackoverflow.com/users/917465,"If we are talking about file upload storage for example I will always store the following fields:


File - varbinary(MAX) 
FileName - nvarchar(255) (including file extension, for example ""myfile.txt"") 
FileType - nvarchar(255) (the MIME type)


The MIME type is important if it is a web based application and you want to allow download of the files at some point. Having the MIME type allow you to tell the browser how to best handle the file.

So the direct answer to your question is to save both the MIME type and the Extension. The reason being that you cannot ensure the correct file extension has been supplied so you need the MIME type to identify the file type. But you should store the extension with the filename so as you can provide a valid filename at download time.
",musefan,https://stackoverflow.com/users/838807,http://stackoverflow.com/questions/10547530/sql-saving-mime-type-or-extension,STACKOVERFLOW,stackoverflow.com,1.0,0.3333333333333333,0.0,0.6666666666666666,0.3333333333333333,1.0,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,1.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.3333333333333333,0.0,0.3333333333333333,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.6666666666666666,0.0,0.3333333333333333,0.8888888888888888,SQL: save MIME type or extension?,"What's the best way to store information about a BLOB in the DB? The File-Extension (.txt, .rar) or the MIME-Type?

Also, what's better: Store the Filename with or without extension (""file"" or ""file.txt"")?

What I'm primarily talking about is a Desktop-App, not a Web-Application.
","If we are talking about file upload storage for example I will always store the following fields:


File - varbinary(MAX) 
FileName - nvarchar(255) (including file extension, for example ""myfile.txt"") 
FileType - nvarchar(255) (the MIME type)


The MIME type is important if it is a web based application and you want to allow download of the files at some point. Having the MIME type allow you to tell the browser how to best handle the file.

So the direct answer to your question is to save both the MIME type and the Extension. The reason being that you cannot ensure the correct file extension has been supplied so you need the MIME type to identify the file type. But you should store the extension with the filename so as you can provide a valid filename at download time.
"
825,825,1309,Will enclosing my porch keep my house warmer?,"Will enclosing my porches during the winter help keep my house warmer? There is a lot of wind hitting the house, and I'm afraid that is causing a drop in temperature.
",Anthony Powell,https://diy.stackexchange.com/users/27718,"Unlikely. If your house is too cold in the winter, ans especially if it's very windy, you need to start by sealing off places where cold air is coming in. That will often help a ton. The next time it's very windy, just go around the house feeling for drafts and air currents. 

After doing that, you can then start to improve your house's insulation. The attic floor is often low-hanging fruit since you can blow a bunch of cellulose onto the floor very inexpensively. If you have hollow walls, those can be blown full of cellulose as well (in the wall, it needs to be dense-packed) through holes cut in the top of the wall. Basement walls can also be a big win, but to do that properly, you need to add rigid foam insulation boards and make it airtight so moist air can't blow through the insulation boards touch the wall. After that, new windows or low-e storm windows can help.
",iLikeDirt,https://diy.stackexchange.com/users/15879,http://diy.stackexchange.com/questions/52440/will-enclosing-my-porch-keep-my-house-warmer,LIFE_ARTS,diy.stackexchange.com,1.0,1.0,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.5555555555555556,0.0,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.9333333333333332,0.6666666666666666,0.0,0.3333333333333333,0.8888888888888888,Can I warm my house by enclosing my porch?,"Does it help to warm my house in winter by surrounding my porch? There's a lot of wind blowing into the house, I'm afraid it will cause the temperature to drop.","Unlikely. If your house is too cold in the winter, ans especially if it's very windy, you need to start by sealing off places where cold air is coming in. That will often help a ton. The next time it's very windy, just go around the house feeling for drafts and air currents. 

After doing that, you can then start to improve your house's insulation. The attic floor is often low-hanging fruit since you can blow a bunch of cellulose onto the floor very inexpensively. If you have hollow walls, those can be blown full of cellulose as well (in the wall, it needs to be dense-packed) through holes cut in the top of the wall. Basement walls can also be a big win, but to do that properly, you need to add rigid foam insulation boards and make it airtight so moist air can't blow through the insulation boards touch the wall. After that, new windows or low-e storm windows can help.
"
2817,2817,4486,\jobname in Gummi,"The command \jobname usually print the file name without the path and extension, so inside a file called foo.tex will print just foo. With pdflatex foo.test or compiling from LaTeXila certainly I obtained this result. But from Gummi what I obtain is .foo.tex  

Does anyone know why Gummi compiles differently and how I could get the usual \jobname behavior in Gummi?

Edit:
Based on helpful answers of @JosephWright and @Herbert
I wonder if it is possible to do the \jobname correction in Gummi only if the source have the .swp extensión or .tex persist in \jobname. 

That is, I would like a solution like:

\makeatletter
\let\JobName\jobname
\ifthenelse{\equal{\detokenize{foo}}{\jobname}}
{}
{
\def\@JobName.#1.#2\@nil{#1}
\def\jobname{\expandafter\@JobName\JobName\@nil}
}
\makeatother


This conditional works to check if the jobname is foo or not, but I want a general solution, independent of the file name (not limited to the string foo). 
",Fran,https://tex.stackexchange.com/users/11604,"Taking a look at the 'Build Log' I get with a foo.tex test file, it seems Gummi actually compiles .foo.tex.swp, which is hidden on Unix due to the leading ., and which has extension .swp not .tex. So TeX is showing you the correct information. For example, with demo file

\documentclass{article}
\begin{document}
Hello world
\end{document}


saved as foo.tex I get log

This is pdfTeX, Version 3.1415926-2.4-1.40.13 (TeX Live 2012)
 \write18 enabled.
entering extended mode
(/home/joseph/Desktop/.foo.tex.swp
LaTeX2e &lt;2011/06/27&gt;
Babel &lt;v3.8m&gt; and hyphenation patterns for english, dumylang, nohyphenation, ge
rman-x-2012-05-30, ngerman-x-2012-05-30, afrikaans, ancientgreek, ibycus, arabi
c, armenian, basque, bulgarian, catalan, pinyin, coptic, croatian, czech, danis
h, dutch, ukenglish, usenglishmax, esperanto, estonian, ethiopic, farsi, finnis
h, french, friulan, galician, german, ngerman, swissgerman, monogreek, greek, h
ungarian, icelandic, assamese, bengali, gujarati, hindi, kannada, malayalam, ma
rathi, oriya, panjabi, tamil, telugu, indonesian, interlingua, irish, italian, 
kurmanji, latin, latvian, lithuanian, mongolian, mongolianlmc, bokmal, nynorsk,
 polish, portuguese, romanian, romansh, russian, sanskrit, serbian, serbianc, s
lovak, slovenian, spanish, swedish, turkish, turkmen, ukrainian, uppersorbian, 
welsh, loaded.
(/usr/local/texlive/2012/texmf-dist/tex/latex/base/article.cls
Document Class: article 2007/10/19 v1.4h Standard LaTeX document class
(/usr/local/texlive/2012/texmf-dist/tex/latex/base/size10.clo))
(/tmp/.foo.tex.aux) [1{/usr/local/texlive/2012/texmf-var/fonts/map/pdftex/updma
p/pdftex.map}] (/tmp/.foo.tex.aux) )&lt;/usr/local/texlive/2012/texmf-dist/fonts/t
ype1/public/amsfonts/cm/cmr10.pfb&gt;
Output written on /tmp/.foo.tex.pdf (1 page, 11541 bytes).
SyncTeX written on /tmp/.foo.tex.synctex.gz.
Transcript written on /tmp/.foo.tex.log.


I'm afraid I don't have a solution (other than 'use a different editor'), as there does not seem to be a Gummi setting to alter this behaviour.



The edited question asks for a 'flexible' approach based on Herbert's code. With the restriction that this assumes a simple case (the file name contains only a single . to separate the extension, except if it starts .where Gummi is in use):

\makeatletter
\begingroup
  \def\@jobname#1.#2\q@nil{%
    \ifx\relax#1\relax
      \expandafter\expandafter\expandafter\@@jobname
    \else
      \expandafter\@@@jobname
    \fi
      \jobname\q@nil
  }
  \def\@@jobname.#1.#2\q@nil{#1}
  \def\@@@jobname#1\q@nil{#1}
  \xdef\jobname{\expandafter\@jobname\jobname.\q@nil}
\endgroup
\makeatother

",Joseph Wright,https://tex.stackexchange.com/users/73,http://tex.stackexchange.com/questions/69434/jobname-in-gummi,TECHNOLOGY,tex.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.3333333333333333,0.6666666666666666,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,0.3333333333333333,0.8888888888888888,0.6666666666666666,1.0,1.0,0.9,0.6666666666666666,0.0,1.0,1.0,\Ganmi's job name,"The command \jobname usually print the file name without the path and extension, so inside a file called foo.tex will print just foo. With pdflatex foo.test or compiling from LaTeXila certainly I obtained this result. But from Gummi what I obtain is .foo.tex  

Does anyone know why Gummi compiles differently and how I could get the usual \jobname behavior in Gummi?

Edit:
Based on helpful answers of @JosephWright and @Herbert
I wonder if it is possible to do the \jobname correction in Gummi only if the source have the .swp extensión or .tex persist in \jobname. 

That is, I would like a solution like:

\makeatletter
\let\JobName\jobname
\ifthenelse{\equal{\detokenize{foo}}{\jobname}}
{}
{
\def\@JobName.#1.#2\@nil{#1}
\def\jobname{\expandafter\@JobName\JobName\@nil}
}
\makeatother


This conditional works to check if the jobname is foo or not, but I want a general solution, independent of the file name (not limited to the string foo). 
","Taking a look at the 'Build Log' I get with a foo.tex test file, it seems Gummi actually compiles .foo.tex.swp, which is hidden on Unix due to the leading ., and which has extension .swp not .tex. So TeX is showing you the correct information. For example, with demo file

\documentclass{article}
\begin{document}
Hello world
\end{document}


saved as foo.tex I get log

This is pdfTeX, Version 3.1415926-2.4-1.40.13 (TeX Live 2012)
 \write18 enabled.
entering extended mode
(/home/joseph/Desktop/.foo.tex.swp
LaTeX2e &lt;2011/06/27&gt;
Babel &lt;v3.8m&gt; and hyphenation patterns for english, dumylang, nohyphenation, ge
rman-x-2012-05-30, ngerman-x-2012-05-30, afrikaans, ancientgreek, ibycus, arabi
c, armenian, basque, bulgarian, catalan, pinyin, coptic, croatian, czech, danis
h, dutch, ukenglish, usenglishmax, esperanto, estonian, ethiopic, farsi, finnis
h, french, friulan, galician, german, ngerman, swissgerman, monogreek, greek, h
ungarian, icelandic, assamese, bengali, gujarati, hindi, kannada, malayalam, ma
rathi, oriya, panjabi, tamil, telugu, indonesian, interlingua, irish, italian, 
kurmanji, latin, latvian, lithuanian, mongolian, mongolianlmc, bokmal, nynorsk,
 polish, portuguese, romanian, romansh, russian, sanskrit, serbian, serbianc, s
lovak, slovenian, spanish, swedish, turkish, turkmen, ukrainian, uppersorbian, 
welsh, loaded.
(/usr/local/texlive/2012/texmf-dist/tex/latex/base/article.cls
Document Class: article 2007/10/19 v1.4h Standard LaTeX document class
(/usr/local/texlive/2012/texmf-dist/tex/latex/base/size10.clo))
(/tmp/.foo.tex.aux) [1{/usr/local/texlive/2012/texmf-var/fonts/map/pdftex/updma
p/pdftex.map}] (/tmp/.foo.tex.aux) )&lt;/usr/local/texlive/2012/texmf-dist/fonts/t
ype1/public/amsfonts/cm/cmr10.pfb&gt;
Output written on /tmp/.foo.tex.pdf (1 page, 11541 bytes).
SyncTeX written on /tmp/.foo.tex.synctex.gz.
Transcript written on /tmp/.foo.tex.log.


I'm afraid I don't have a solution (other than 'use a different editor'), as there does not seem to be a Gummi setting to alter this behaviour.



The edited question asks for a 'flexible' approach based on Herbert's code. With the restriction that this assumes a simple case (the file name contains only a single . to separate the extension, except if it starts .where Gummi is in use):

\makeatletter
\begingroup
  \def\@jobname#1.#2\q@nil{%
    \ifx\relax#1\relax
      \expandafter\expandafter\expandafter\@@jobname
    \else
      \expandafter\@@@jobname
    \fi
      \jobname\q@nil
  }
  \def\@@jobname.#1.#2\q@nil{#1}
  \def\@@@jobname#1\q@nil{#1}
  \xdef\jobname{\expandafter\@jobname\jobname.\q@nil}
\endgroup
\makeatother

"
5405,5405,8584,How do I chose a good camera for texture hunting?,"Texture hunting is the photography of walls, surfaces, artefacts, etc, typically outdoors, with the intention of using the photos in a computer game.  The photo could be of a brick or concrete wall, a chain link face, a door / window, or whatever.  It is also possible to photograph a white wall that has been damaged or stained in some way, process it in various ways, and use this as a mask on top of other textures, in order to get a new damaged variant.

Textures are typically lighting-neutral and extremely sharp.  The computer game will compute its own lighting and shadows.  One must avoid having a shadow across the subject, as this will only have to be removed in post-processing.  Typically, texture hunting is done on cloudy days where there is a uniform soft light from the sky.

1024×1024 is a reasonable size of the final texture, but it's usually photographed at a higher res, photoshopped considerably, and then sized down.  The subject of the photo could be something like 5 metres × 5 metres.  The idea is that every pixel is being used to the fullest effect to convey the character of the surface.  Textures are often photoshopped to become seamless so they can be repeated across a large surface in game.

Textures are usually shot perpendicular to the wall as much as possible, otherwise distortion correction is required.  Sometimes you can take a photo from further away and zoom in to get a better view of a high wall.

It is often quite hard to find a surface in the real world that has an interesting texture and is easy to photograph from the right angle.  In particular, taking photos of the floor is challenging because you need to be several metres above it, looking down.  Leaning out of windows / over bridges, or holding up a tripod are solutions.

One thing that concerns me is that some cameras do image processing on the digital image.  Really, the artist has to be doing all of the image processing offline, in photoshop or similar.  I often see digital camera photos with edge enhancement artefacts in high contrast areas.  Perhaps raw shooting mode is the answer to this?

Shooting digital photos with greater colour depth than ""8 bit per channel"" might also be useful to avoid banding when increasing contrast during post-processing.

Another thing is lens distortion — since we need to photograph flat surfaces.  Either the camera has to be good at it, or it should be possible to turn it off so the processing can be done manually by an artist.

How do I find a camera which meets these requirements?
",Spark,https://photo.stackexchange.com/users/6311,"Your main concerns are going to be:


As you say, the ability shoot in RAW.
Relatively noise-free output (but this requirement is mitigated by the ability to heavily post-process and downsize). 
A good, sharp, distortion-free lens.


For the resolution you suggest, you should be able to get good results from a high-quality point &amp; shoot (like the Canon G12 or similar). However, you'll get even better results from a larger-sensor interchangeable-lens camera — like a DSLR. I don't think you need anything expensive — an entry-level model should do. But you should look into spending some money for a very nice lens. Maybe a 70-200mm zoom or a 100mm macro. Probably an f/4 lens will be fine, rather than a more expensive f/2.8 version — since you'll probably want to stop down for sharpness and to increase depth of field and reduce focus error. If you can use a tripod, awesome, but having image stabilization will give more flexibility.

Pretty much any brand or model of DSLR should be fine for this purpose. They all give high-quality results and have the lenses you might need for this available. 
",mattdm,https://photo.stackexchange.com/users/1943,http://photo.stackexchange.com/questions/14871/how-do-i-chose-a-good-camera-for-texture-hunting,LIFE_ARTS,photo.stackexchange.com,1.0,0.8888888888888888,0.0,1.0,0.0,0.0,0.6666666666666666,0.4444444444444444,0.0,0.0,1.0,0.0,0.0,0.0,0.0,1.0,1.0,0.0,0.0,0.0,1.0,1.0,0.7777777777777778,1.0,1.0,1.0,1.0,0.0,1.0,1.0,How to choose a good camera for texture search?,"Texture hunting is the photography of walls, surfaces, artefacts, etc, typically outdoors, with the intention of using the photos in a computer game.  The photo could be of a brick or concrete wall, a chain link face, a door / window, or whatever.  It is also possible to photograph a white wall that has been damaged or stained in some way, process it in various ways, and use this as a mask on top of other textures, in order to get a new damaged variant.

Textures are typically lighting-neutral and extremely sharp.  The computer game will compute its own lighting and shadows.  One must avoid having a shadow across the subject, as this will only have to be removed in post-processing.  Typically, texture hunting is done on cloudy days where there is a uniform soft light from the sky.

1024×1024 is a reasonable size of the final texture, but it's usually photographed at a higher res, photoshopped considerably, and then sized down.  The subject of the photo could be something like 5 metres × 5 metres.  The idea is that every pixel is being used to the fullest effect to convey the character of the surface.  Textures are often photoshopped to become seamless so they can be repeated across a large surface in game.

Textures are usually shot perpendicular to the wall as much as possible, otherwise distortion correction is required.  Sometimes you can take a photo from further away and zoom in to get a better view of a high wall.

It is often quite hard to find a surface in the real world that has an interesting texture and is easy to photograph from the right angle.  In particular, taking photos of the floor is challenging because you need to be several metres above it, looking down.  Leaning out of windows / over bridges, or holding up a tripod are solutions.

One thing that concerns me is that some cameras do image processing on the digital image.  Really, the artist has to be doing all of the image processing offline, in photoshop or similar.  I often see digital camera photos with edge enhancement artefacts in high contrast areas.  Perhaps raw shooting mode is the answer to this?

Shooting digital photos with greater colour depth than ""8 bit per channel"" might also be useful to avoid banding when increasing contrast during post-processing.

Another thing is lens distortion — since we need to photograph flat surfaces.  Either the camera has to be good at it, or it should be possible to turn it off so the processing can be done manually by an artist.

How do I find a camera which meets these requirements?
","Your main concerns are going to be:


As you say, the ability shoot in RAW.
Relatively noise-free output (but this requirement is mitigated by the ability to heavily post-process and downsize). 
A good, sharp, distortion-free lens.


For the resolution you suggest, you should be able to get good results from a high-quality point &amp; shoot (like the Canon G12 or similar). However, you'll get even better results from a larger-sensor interchangeable-lens camera — like a DSLR. I don't think you need anything expensive — an entry-level model should do. But you should look into spending some money for a very nice lens. Maybe a 70-200mm zoom or a 100mm macro. Probably an f/4 lens will be fine, rather than a more expensive f/2.8 version — since you'll probably want to stop down for sharpness and to increase depth of field and reduce focus error. If you can use a tripod, awesome, but having image stabilization will give more flexibility.

Pretty much any brand or model of DSLR should be fine for this purpose. They all give high-quality results and have the lenses you might need for this available. 
"
948,948,1503,Any omitted word in this sentence?,"
  The dark guy took a week to fall down. He stumbled, caught himself, waved one arm, stumbled again. His hat fell off, and then he hit the floor with his face. After he hit it he might have been poured concrete for all the fuss he made.


I just guess the guy fell on the floor (by a gun-shot) wouldn't move like a concret cast???

Any missing word in this sentence, like a preposition?

It's a part of Red Wind by Raymond Chandler.
",user58207,https://english.stackexchange.com/users/58207,"Yes, ""might have been poured concrete"" does mean that he was immobile like a poured-concrete cast. 

The sentence could use a comma:


  After he hit it, he might ...


Also the part “been poured concrete” seems odd. I was half expecting it to end “... he might have been poured out and shaken up for all he could remember.”  In other words, coming after been, I tended to parse poured as a verb at first; its use as an adjective threw me briefly. 

But I can't think how one would improve that except by being more verbose, as in:


  ... have been made of poured concrete ...


That's two missing words, rather than one, and it seems to weaken the directness of the author's style. 
",Celery Man,https://english.stackexchange.com/users/103913,http://english.stackexchange.com/questions/220313/any-omitted-word-in-this-sentence,CULTURE,english.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,0.6666666666666666,1.0,1.0,0.5555555555555556,0.6666666666666666,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,0.8888888888888888,0.9333333333333332,0.0,0.0,0.6666666666666666,0.7777777777777778,Is there any missing word in this sentence?,"It took the nigger a week to fall. He stumbled, grabbed himself, waved and stumbled again. His hat fell off, and then his face hit the floor. After he hit it, he may have been concreted to cope with everything he did.","Yes, ""might have been poured concrete"" does mean that he was immobile like a poured-concrete cast. 

The sentence could use a comma:


  After he hit it, he might ...


Also the part “been poured concrete” seems odd. I was half expecting it to end “... he might have been poured out and shaken up for all he could remember.”  In other words, coming after been, I tended to parse poured as a verb at first; its use as an adjective threw me briefly. 

But I can't think how one would improve that except by being more verbose, as in:


  ... have been made of poured concrete ...


That's two missing words, rather than one, and it seems to weaken the directness of the author's style. 
"
2772,2772,4417,Is work experience necessary for tenure-track positions?,"In India, a minimum of 3 years of work experience is necessary to be appointed as an assistant professor in any of the IITs. (Years during the PhD or master's are not counted, but any year spent outside university after bachelor's will count.)

Is such a work experience a necessity even in US universities? If yes, how much will this weigh towards selection? If the candidate has only a post-bachelor's experience, what should be highlighted from that so as to enhance this application?
",Bravo,https://academia.stackexchange.com/users/411,"There are no universal rules regarding employment status and being hired at US universities. In some fields, such as engineering, graduate students may be hired before they have completed any post-graduate professional experience. In contrast, in departments such as physics, it may be required to complete several post-doctoral appointments before being considered for faculty positions.

There are some general guidelines, however:


In less ""applied"" STEM (science, technology, engineering, and mathematics) fields, more time is generally required in academic positions before earning a full-time faculty position.
In more ""applied"" fields, the time spent is reduced. Unfortunately, in some cases, although industrial experience is often seen as a good thing, it also has a tendency to make it difficult to jump back into a research field—unless one has been employed in an industrial research capacity.
In humanities fields, it's very difficult of to be able to continue to a faculty position after leaving academia. 

",aeismail,https://academia.stackexchange.com/users/53,http://academia.stackexchange.com/questions/2074/is-work-experience-necessary-for-tenure-track-positions,LIFE_ARTS,academia.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,1.0,1.0,1.0,0.6666666666666666,0.7777777777777778,1.0,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,0.7777777777777778,0.6666666666666666,0.8888888888888888,0.8888888888888888,0.9333333333333332,0.0,0.0,1.0,1.0,Do you need work experience for a lifelong position?,"In India, at least three years of working experience is a prerequisite for appointment as an assistant professor at any institute. (the number of years during the doctorate or master's period is not included, but any year after graduation from university will be included.)","There are no universal rules regarding employment status and being hired at US universities. In some fields, such as engineering, graduate students may be hired before they have completed any post-graduate professional experience. In contrast, in departments such as physics, it may be required to complete several post-doctoral appointments before being considered for faculty positions.

There are some general guidelines, however:


In less ""applied"" STEM (science, technology, engineering, and mathematics) fields, more time is generally required in academic positions before earning a full-time faculty position.
In more ""applied"" fields, the time spent is reduced. Unfortunately, in some cases, although industrial experience is often seen as a good thing, it also has a tendency to make it difficult to jump back into a research field—unless one has been employed in an industrial research capacity.
In humanities fields, it's very difficult of to be able to continue to a faculty position after leaving academia. 

"
1473,1473,2317,What largest websites are written in php?,"What are some of the largest and most popular websites in the world written in php? I know 1 - this is wikipedia, tell please another large website.
",ANOTHER,https://webmasters.stackexchange.com/users/20044,"Facebook is written in PHP too :)
",André Freitas,https://webmasters.stackexchange.com/users/20045,http://webmasters.stackexchange.com/questions/38030/what-largest-websites-are-written-in-php,TECHNOLOGY,webmasters.stackexchange.com,1.0,0.7777777777777778,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.8888888888888888,0.5555555555555556,1.0,0.7777777777777778,0.8,0.3333333333333333,0.0,0.0,0.7777777777777778,Which of the largest websites are written in PHP?,What are the world's largest and most popular websites written in PHP? I know this is Wikipedia. Please tell another big website.,"Facebook is written in PHP too :)
"
4982,4982,7933,How can I do some free design work?,"I am a designer that wants to do some free design work for people, but the problem is, how do I find people to do free work for? Is there any place online?

The reason behind this is that I am good at this, but I don't have any clients, or any previous experience and I am a freelancer, so this would look good on my portfolio.

My skills are very vast and include : 3D, 2D animation, 3D modeling, motion design, stop motion animation,video editing, game design, level design, FluidSIM, illustration, unreal engine 4, graphics design, editorial design, web design and I also know HTML5, CSS, JavaScript and jQuery.



By free work, I mean that the clients don't have to pay a single penny for the work that I do.
",Zach Roschack,https://graphicdesign.stackexchange.com/users/43164,"Forgive if I'm rude here.

Design is one of the profesions that has prostituted the most. Why do anyone has to pay a penny if there are always new insecure people who has no previus clients?


  ""so this would look good on my portfolio""


Your portafolio will look good if it has good work. So why don't you concentrate in making good work to show?

You say you are a designer. But I don't know if you have an idea what design is for. Do you belive in design? Do you belive that a good motion design video will help your client sell more? An impresive web page? A great business card will make a good impression?


  ""I don't have any clients""


But you don't belive it becouse you are not making any video to sell the idea of making videos. You are not making a web page to sell web page design.

One method to sell is ""Look this are my clients"". But the best selling argument is ""Imagine what I can make for you"". There are a lot of people willing to pay talented work. Period.


  ""By free work, I mean that the clients don't have to pay a single penny for the work that I do.""


We know what that means. But new designers have no idea what overall perception that makes! Design is worthless.

I have a question. Does your work worth one penny or less? Or it is good enough to recive real money.



Make a series of wallpapers with an idea of a clasical author, Ilustrate a poem, animate a folkloric tale, make a political statement, make logos out of plain words, make your corporative image and webpage and fool everyone to think is the greatest design firm.

That will get you clients.
",Rafael,https://graphicdesign.stackexchange.com/users/36888,http://graphicdesign.stackexchange.com/questions/51992/how-can-i-do-some-free-design-work,LIFE_ARTS,graphicdesign.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,0.3333333333333333,0.6666666666666666,0.0,0.8888888888888888,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.0,0.0,1.0,0.7777777777777778,0.3333333333333333,0.8888888888888888,0.8888888888888888,0.4,0.6666666666666666,0.0,0.6666666666666666,1.0,How can I do some free design work?,"I am a designer that wants to do some free design work for people, but the problem is, how do I find people to do free work for? Is there any place online?

The reason behind this is that I am good at this, but I don't have any clients, or any previous experience and I am a freelancer, so this would look good on my portfolio.

My skills are very vast and include : 3D, 2D animation, 3D modeling, motion design, stop motion animation,video editing, game design, level design, FluidSIM, illustration, unreal engine 4, graphics design, editorial design, web design and I also know HTML5, CSS, JavaScript and jQuery.



By free work, I mean that the clients don't have to pay a single penny for the work that I do.
","Forgive if I'm rude here.

Design is one of the profesions that has prostituted the most. Why do anyone has to pay a penny if there are always new insecure people who has no previus clients?


  ""so this would look good on my portfolio""


Your portafolio will look good if it has good work. So why don't you concentrate in making good work to show?

You say you are a designer. But I don't know if you have an idea what design is for. Do you belive in design? Do you belive that a good motion design video will help your client sell more? An impresive web page? A great business card will make a good impression?


  ""I don't have any clients""


But you don't belive it becouse you are not making any video to sell the idea of making videos. You are not making a web page to sell web page design.

One method to sell is ""Look this are my clients"". But the best selling argument is ""Imagine what I can make for you"". There are a lot of people willing to pay talented work. Period.


  ""By free work, I mean that the clients don't have to pay a single penny for the work that I do.""


We know what that means. But new designers have no idea what overall perception that makes! Design is worthless.

I have a question. Does your work worth one penny or less? Or it is good enough to recive real money.



Make a series of wallpapers with an idea of a clasical author, Ilustrate a poem, animate a folkloric tale, make a political statement, make logos out of plain words, make your corporative image and webpage and fool everyone to think is the greatest design firm.

That will get you clients.
"
1116,1116,1752,How is encapsulation used for safety?,"I am learning OOP. I have studied much about encapsulation but the more I read the more I became confused.

I understand we hide (by making private) data and expose it to user of class (other developers) as properties or methods. I also understand by encapsulation we hide details.

In an article (http://www.csharp-station.com/Tutorial/CSharp/lesson19) I read:

Abstract from article

When designing an object, you must think about how others could use it. In a best-case scenario any program using the object would be well designed and the code would never change. However, the reality is that programs do change often and in a team environment many people touch the same code at one time or another. Therefore, it is beneficial to consider what could go wrong as well as the pristine image of how the object should be used.

In the case of the BankAccount object, examine the situation where code outside of your object could access a decimal Amount field or a string CustomerName field. At the point of time that the code is written, everything would work well. However, later in the development cycle, you realize that the BankAccount object should keep track of an int CustomerID rather than string CustomerName because you don't want to duplicate relationships between information (or some other valid reason to alter the definition of internal state). Such changes cause a rippling effect in your code because it was built to use the BankAccount class, as originally designed (with CustomerName being a string), and you must now change code that accesses that state throughout your entire application.

The object-oriented principle of Encapsulation helps avoid such problems, allowing you to hide internal state and abstract access to it though type members such as methods, properties, and indexers. Encapsulation helps you reduce coupling between objects and increases the maintainability of your code. 

Question
How will encapsulation help when making changes in code and from its rippling effects.
For a data member, if I change its type from int to float, (even if I am exposing this using property) I will need to change variable type where I am using already using this code.

Kindly guide me how encapsulation will help with such changes.

Thanks for this help and guidance.
",haansi,https://programmers.stackexchange.com/users/54357,"
  How will encapsulation help when making changes in code and from its rippling effects.


Let me give you a typical and simplistic example. 
First, suppose you are not using encapsulation:
You have a set of data and use an array to store that data, and there is another part of your program that uses that array. Now, if at some point you decide that a linked list is a better choice for storing your data. If you replace array with linked list, what is going to happen? Your program will break, unless you make changes all over the place to replace the array-processing logic with linked-list-processing logic.

But, if you use OO/Encapsulation, then you probably partition your program into classes, one that store the data, and other, that uses the data. In the first class, you hide your implementation (encapsulation), and expose your services through methods like

size()
remove(int index)
add(int index, Object o)
get(int index)

...


In this second case, if you change the implementation of the storing class from array to linked list, or to any other thing, it will not affect your clients. No ripple effect.
",Nazar Merza,https://programmers.stackexchange.com/users/48157,http://programmers.stackexchange.com/questions/149041/how-is-encapsulation-used-for-safety,TECHNOLOGY,programmers.stackexchange.com,0.6666666666666666,0.3333333333333333,0.0,0.0,1.0,1.0,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.3333333333333333,1.0,0.8888888888888888,How to use encapsulation to ensure safety?,"I am learning OOP. I have studied much about encapsulation but the more I read the more I became confused.

I understand we hide (by making private) data and expose it to user of class (other developers) as properties or methods. I also understand by encapsulation we hide details.

In an article (http://www.csharp-station.com/Tutorial/CSharp/lesson19) I read:

Abstract from article

When designing an object, you must think about how others could use it. In a best-case scenario any program using the object would be well designed and the code would never change. However, the reality is that programs do change often and in a team environment many people touch the same code at one time or another. Therefore, it is beneficial to consider what could go wrong as well as the pristine image of how the object should be used.

In the case of the BankAccount object, examine the situation where code outside of your object could access a decimal Amount field or a string CustomerName field. At the point of time that the code is written, everything would work well. However, later in the development cycle, you realize that the BankAccount object should keep track of an int CustomerID rather than string CustomerName because you don't want to duplicate relationships between information (or some other valid reason to alter the definition of internal state). Such changes cause a rippling effect in your code because it was built to use the BankAccount class, as originally designed (with CustomerName being a string), and you must now change code that accesses that state throughout your entire application.

The object-oriented principle of Encapsulation helps avoid such problems, allowing you to hide internal state and abstract access to it though type members such as methods, properties, and indexers. Encapsulation helps you reduce coupling between objects and increases the maintainability of your code. 

Question
How will encapsulation help when making changes in code and from its rippling effects.
For a data member, if I change its type from int to float, (even if I am exposing this using property) I will need to change variable type where I am using already using this code.

Kindly guide me how encapsulation will help with such changes.

Thanks for this help and guidance.
","
  How will encapsulation help when making changes in code and from its rippling effects.


Let me give you a typical and simplistic example. 
First, suppose you are not using encapsulation:
You have a set of data and use an array to store that data, and there is another part of your program that uses that array. Now, if at some point you decide that a linked list is a better choice for storing your data. If you replace array with linked list, what is going to happen? Your program will break, unless you make changes all over the place to replace the array-processing logic with linked-list-processing logic.

But, if you use OO/Encapsulation, then you probably partition your program into classes, one that store the data, and other, that uses the data. In the first class, you hide your implementation (encapsulation), and expose your services through methods like

size()
remove(int index)
add(int index, Object o)
get(int index)

...


In this second case, if you change the implementation of the storing class from array to linked list, or to any other thing, it will not affect your clients. No ripple effect.
"
720,720,1141,ASP.net Website want debug to == false on IIS,"Have tried adding this to web.config 

&lt;compilation debug=""false"" targetFramework=""4.0""&gt;
&lt;/compilation&gt;


but website still executes code in #if DEBUG when it shouldn't

*Wierdly the inline statement &lt;% #if DEBUG %> on aspx files works but require also for .cs code. 

NB development and live website on same box
",user3231982,https://stackoverflow.com/users/3231982,"Ensure the compile configuration to release as well. In Visual Studio, Build Menu > Configuration Manager and make sure ""Release"" is selected for all your assemblies, and/or is the active solution configuration.
",Steven V,https://stackoverflow.com/users/254973,http://stackoverflow.com/questions/21438703/asp-net-website-want-debug-to-false-on-iis,STACKOVERFLOW,stackoverflow.com,0.6666666666666666,0.4444444444444444,0.0,1.0,0.6666666666666666,1.0,0.4444444444444444,0.4444444444444444,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,0.0,0.4444444444444444,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,1.0,1.0,0.0,0.0,0.7777777777777778,Asp.net website wants to debug on IIS as = false,"Have tried adding this to web.config 

&lt;compilation debug=""false"" targetFramework=""4.0""&gt;
&lt;/compilation&gt;


but website still executes code in #if DEBUG when it shouldn't

*Wierdly the inline statement &lt;% #if DEBUG %> on aspx files works but require also for .cs code. 

NB development and live website on same box
","Ensure the compile configuration to release as well. In Visual Studio, Build Menu > Configuration Manager and make sure ""Release"" is selected for all your assemblies, and/or is the active solution configuration.
"
170,170,268,Is there a console command to give vendors gold to help with selling?,"Last night, I made enough potions from ingredients in storage to be sold for approximately 900,000 septims. My practice in times past would be to go to fences in round-robin fashion in Markarth, Solitude, Windhelm, and Honningbrew Meadery to sell off items since they have 5,000 septims each. In the interest of saving and not wasting time, I used the command additem f 495000 on Mallus Maccius ""(0002ba8f) in the meadery and started selling potions, but once he gave me 5,000 septims, things got weird. Items can still be sold for him like normal, but my gold no longer increases, and his does not decrease below 495,000. The Wikia article Console Commands (Skyrim) has this to say about the command: Use on a merchant to set the amount of barter gold. This gold may not go to your inventory when selling items to the vendor.

Question: Is there a way to get around this problem? Is there another command or target on which to act that would allow me to accomplish what is being attempted?

Rejected Answers:


Remove the items and give yourself gold for the items [imprecise on gold calculations or time consuming; also has same problem with leveling up speech]
Continue what you are doing but give yourself gold when finished [while this allows leveling up speech, there is imprecision on gold calculations without being time consuming]
Keep going to your fences round-robin style to sell your items [this is to be avoided; the goal is to save time even if it breaks immersion slightly]
Download mod name_goes_here so merchants have more/infinite gold [my internet connection's proxy prevents such downloads; it is extremely inconvenient to access other internet connections]
Go to web_site_url to read/watch a tutorial on how to accomplish what you are trying to do [see last point; proxy probably blocks the web site, and it is close to impossible to get a different internet connection]

",Noctis Skytower,https://gaming.stackexchange.com/users/1245,"This approach works for me:

How to give a merchant A Lot of Gold


Write down how much gold you have for reference.
Give yourself A Lot of Gold.
Buy everything the shopkeeper owns
Sell it back to him at a tenth or so of the price.
Repeat 3 and 4 until you no longer have A Lot of Gold.
The merchant now has A Lot of Gold.
Set your own gold amount back to the number you wrote down in 1.

",Shadur,https://gaming.stackexchange.com/users/7864,http://gaming.stackexchange.com/questions/176374/is-there-a-console-command-to-give-vendors-gold-to-help-with-selling,CULTURE,gaming.stackexchange.com,1.0,0.7777777777777778,0.0,1.0,1.0,0.6666666666666666,0.5555555555555556,0.5555555555555556,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.0,0.0,1.0,0.6666666666666666,0.5555555555555556,0.8333333333333334,1.0,0.6,1.0,0.0,0.0,0.7777777777777778,Is there a console command to give gold to suppliers to help sales?,"Last night, I made enough potions from ingredients in storage to be sold for approximately 900,000 septims. My practice in times past would be to go to fences in round-robin fashion in Markarth, Solitude, Windhelm, and Honningbrew Meadery to sell off items since they have 5,000 septims each. In the interest of saving and not wasting time, I used the command additem f 495000 on Mallus Maccius ""(0002ba8f) in the meadery and started selling potions, but once he gave me 5,000 septims, things got weird. Items can still be sold for him like normal, but my gold no longer increases, and his does not decrease below 495,000. The Wikia article Console Commands (Skyrim) has this to say about the command: Use on a merchant to set the amount of barter gold. This gold may not go to your inventory when selling items to the vendor.

Question: Is there a way to get around this problem? Is there another command or target on which to act that would allow me to accomplish what is being attempted?

Rejected Answers:


Remove the items and give yourself gold for the items [imprecise on gold calculations or time consuming; also has same problem with leveling up speech]
Continue what you are doing but give yourself gold when finished [while this allows leveling up speech, there is imprecision on gold calculations without being time consuming]
Keep going to your fences round-robin style to sell your items [this is to be avoided; the goal is to save time even if it breaks immersion slightly]
Download mod name_goes_here so merchants have more/infinite gold [my internet connection's proxy prevents such downloads; it is extremely inconvenient to access other internet connections]
Go to web_site_url to read/watch a tutorial on how to accomplish what you are trying to do [see last point; proxy probably blocks the web site, and it is close to impossible to get a different internet connection]

","This approach works for me:

How to give a merchant A Lot of Gold


Write down how much gold you have for reference.
Give yourself A Lot of Gold.
Buy everything the shopkeeper owns
Sell it back to him at a tenth or so of the price.
Repeat 3 and 4 until you no longer have A Lot of Gold.
The merchant now has A Lot of Gold.
Set your own gold amount back to the number you wrote down in 1.

"
3466,3466,5520,Character values bounded away from zero,"Character values for a finite group are sums of nth roots of unity. I'm wondering if there are any results bounding nonzero values of irreducible characters away from zero. Or if not are there examples of natural sequences of groups where entries in the character table can be made arbitrarily close zero. I don't see anything like this in Isaacs book for example.

Added: Thanks for the answers below, I of course should have figured out the direct product once you have one of norm &lt;1. I guess the problem is more interesting for simple groups, for example the alternating groups the nonzero values are bounded away from zero.
",Curious about characters,https://mathoverflow.net/users/45929,"The dihedral group $D_{2n}$ has two dimensional irreducible representations for which the character values (on the cyclic group of order $n$) are $2\cos(2\pi k/n)$ for $1\le k\le n$.  Clearly these values get arbitrarily close to zero for large $n$ and $k$ close to $n/4$. See for example http://groupprops.subwiki.org/wiki/Linear_representation_theory_of_dihedral_groups .
",Lucia,https://mathoverflow.net/users/38624,http://mathoverflow.net/questions/155534,SCIENCE,mathoverflow.net,0.6666666666666666,0.3333333333333333,0.0,1.0,1.0,0.5,0.5,0.3333333333333333,0.5,0.0,0.0,0.5,0.0,0.0,0.0,0.5,0.5,0.0,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.8,0.5,0.0,0.0,1.0,Character value away from zero,"The eigenvalue of a finite group is the sum of n roots of a unit. I want to know if there is any result that limits the non-zero value of irreducible characters to zero. Or, if not, there is an example of a natural sequence of groups in which items in the character table can be arbitrarily close to zero. For example, I don't see such things in Isaacs' books.","The dihedral group $D_{2n}$ has two dimensional irreducible representations for which the character values (on the cyclic group of order $n$) are $2\cos(2\pi k/n)$ for $1\le k\le n$.  Clearly these values get arbitrarily close to zero for large $n$ and $k$ close to $n/4$. See for example http://groupprops.subwiki.org/wiki/Linear_representation_theory_of_dihedral_groups .
"
2741,2741,4371,"Are there English equivalents to the Japanese saying, “There’s a god who puts you down as well as a god who picks you up”?","There is an old Japanese saying, “捨てる神あれば、拾う神あり-Suterukami areba hirou kami ari,” meaning “There’s a god who puts you down as well as a god who picks up you.” In other words, “In this world, some people help you, and some people harm you” or “Fortune and misfortune come alternately.”

For example, when you are fired from an IT company, and then hired by its rival company with a higher salary three months later, your peers will say to you “You're a lucky man. There’s a god who throws you away as well as a god who picks you up.”

I’m curious to know if there are similar sayings in English to “Suterukami areba hirou kami ari.” 
",Yoichi Oishi,https://english.stackexchange.com/users/3119,"To translate this expression, you need to cope with the very different attitudes towards divinity of Japanese and 'Western' culture. When a Japanese expression talks about the kami, it's in a different atmosphere than when an English expression talks about God.

There are many kami, they come and go. The Japanese expression suggests that there are many powers in the world and that different ones are influential at different times.

The monotheistic view is very different: there's one deity. It's very different for the one and only deity to dish out varying results than for random encounters with different kami to result in different outcomes.

Thus, you might want to stick to expressions that don't involve God, but rather talk about fate, or luck, or use the passive. I think you're better off avoiding divinity altogether, as you lose a lot more translation quality by referencing the very different divinity than you gain by maintaining the reference to divinity at all.
",bmargulies,https://english.stackexchange.com/users/7765,http://english.stackexchange.com/questions/169134/are-there-english-equivalents-to-the-japanese-saying-there-s-a-god-who-puts-yo,CULTURE,english.stackexchange.com,1.0,1.0,0.0,1.0,1.0,0.6666666666666666,0.6666666666666666,0.7777777777777778,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,0.7777777777777778,0.5555555555555556,0.8888888888888888,0.7777777777777778,0.6,0.0,0.0,0.3333333333333333,1.0,"Is there a saying similar to Japanese in English that ""some god put you down and some god picked you up""?","There is an old Japanese saying, “捨てる神あれば、拾う神あり-Suterukami areba hirou kami ari,” meaning “There’s a god who puts you down as well as a god who picks up you.” In other words, “In this world, some people help you, and some people harm you” or “Fortune and misfortune come alternately.”

For example, when you are fired from an IT company, and then hired by its rival company with a higher salary three months later, your peers will say to you “You're a lucky man. There’s a god who throws you away as well as a god who picks you up.”

I’m curious to know if there are similar sayings in English to “Suterukami areba hirou kami ari.” 
","To translate this expression, you need to cope with the very different attitudes towards divinity of Japanese and 'Western' culture. When a Japanese expression talks about the kami, it's in a different atmosphere than when an English expression talks about God.

There are many kami, they come and go. The Japanese expression suggests that there are many powers in the world and that different ones are influential at different times.

The monotheistic view is very different: there's one deity. It's very different for the one and only deity to dish out varying results than for random encounters with different kami to result in different outcomes.

Thus, you might want to stick to expressions that don't involve God, but rather talk about fate, or luck, or use the passive. I think you're better off avoiding divinity altogether, as you lose a lot more translation quality by referencing the very different divinity than you gain by maintaining the reference to divinity at all.
"
4369,4369,6950,Dialog is partially shown when SoftKeyBoard is shown,"I have a custom Dialog as shown below:



When I click on the Edit Text, The dialog is shifted upwards but half of the dialog becomes invisible as shown below:


I verified the issue on Android ICS and Gingerbread but it doesn't happen on Android Lollipop.

I appreciate your help for figuring out why.

Here is the custom dialog layout XML:

&lt;LinearLayout xmlns:android=""http://schemas.android.com/apk/res/android""
android:id=""@+id/layoutChatInGame""
android:layout_width=""305dp""
android:layout_height=""190dp""
android:background=""@drawable/dialog_table_border""
android:orientation=""vertical""
android:visibility=""visible""&gt;

&lt;LinearLayout
    android:orientation=""horizontal""
    android:layout_width=""match_parent""
    android:layout_height=""wrap_content""
    android:background=""@color/roomlist_title_background""&gt;

    &lt;ProgressBar
        android:layout_width=""wrap_content""
        android:layout_height=""wrap_content""
        android:id=""@+id/progressBar""
        android:layout_margin=""5dp""/&gt;

    &lt;LinearLayout
        android:orientation=""horizontal""
        android:layout_width=""fill_parent""
        android:layout_height=""fill_parent""
        android:layout_gravity=""center""
        android:layout_margin=""5dp""&gt;

        &lt;LinearLayout
            android:orientation=""vertical""
            android:layout_width=""fill_parent""
            android:layout_height=""wrap_content""
            android:layout_gravity=""center_vertical""&gt;

            &lt;TextView
                android:layout_width=""fill_parent""
                android:layout_height=""fill_parent""
                android:text=""Game is on hold because the host paused the app""
                android:id=""@+id/lblOnHoldDialogMessage""
                android:textColor=""@color/progress_dialog_on_hold_text""
                android:textSize=""18dp""
                android:singleLine=""false""
                android:layout_gravity=""center_horizontal""/&gt;
        &lt;/LinearLayout&gt;
    &lt;/LinearLayout&gt;

&lt;/LinearLayout&gt;

&lt;TextView
    android:id=""@+id/lblChatHistoryGameOnHold""
    android:layout_width=""match_parent""
    android:layout_height=""fill_parent""
    android:layout_weight=""1""
    android:gravity=""bottom""
    android:maxLines=""5""
    android:scrollbars=""vertical""
    android:textColor=""@color/edit_text_general_text""
    android:textColorHint=""@color/edit_text_general_hint""
    android:paddingRight=""2dp""
    android:paddingLeft=""2dp""/&gt;

&lt;LinearLayout
    android:layout_width=""match_parent""
    android:layout_height=""wrap_content""&gt;

    &lt;EditText
        android:id=""@+id/textChatGameOnHold""
        android:layout_width=""0dp""
        android:layout_height=""wrap_content""
        android:layout_marginLeft=""2dp""
        android:layout_marginStart=""2dp""
        android:layout_weight=""1""
        android:ems=""10""
        android:hint=""@string/edit_text_send_chat_message""
        android:imeOptions=""flagNoExtractUi|actionDone""
        android:inputType=""text""
        android:maxLength=""100""
        android:maxLines=""1""
        android:textColor=""@color/edit_text_general_text""
        android:textColorHint=""@color/edit_text_general_hint""/&gt;

    &lt;Button
        android:id=""@+id/btnSendGameOnHold""
        style=""@style/lightboxButton.Blue""
        android:layout_width=""wrap_content""
        android:layout_height=""wrap_content""
        android:onClick=""sendChatMessageInGame""
        android:text=""@string/btn_send""/&gt;
&lt;/LinearLayout&gt;

&lt;/LinearLayout&gt; 

",E B,https://stackoverflow.com/users/4718314,"You can get the desired behavior by making adjustResize flag for the windowSoftInputMode of the dialog in the manifest if your dialog is declared as an activity.

Like This:

    android:windowSoftInputMode=""adjustResize|stateHidden""


You can also directly try something like this directly on the dialog:

alertDialog.getWindow().setSoftInputMode(
WindowManager.LayoutParams.SOFT_INPUT_ADJUST_RESIZE);

",androholic,https://stackoverflow.com/users/2019163,http://stackoverflow.com/questions/31895818/dialog-is-partially-shown-when-softkeyboard-is-shown,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.4444444444444444,0.0,1.0,1.0,1.0,0.5555555555555556,0.5555555555555556,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.0,0.7777777777777778,1.0,0.5555555555555556,0.8888888888888888,1.0,0.8,1.0,0.0,0.0,0.8888888888888888,Partial display dialog box when displaying soft keyboard,"I have a custom Dialog as shown below:



When I click on the Edit Text, The dialog is shifted upwards but half of the dialog becomes invisible as shown below:


I verified the issue on Android ICS and Gingerbread but it doesn't happen on Android Lollipop.

I appreciate your help for figuring out why.

Here is the custom dialog layout XML:

&lt;LinearLayout xmlns:android=""http://schemas.android.com/apk/res/android""
android:id=""@+id/layoutChatInGame""
android:layout_width=""305dp""
android:layout_height=""190dp""
android:background=""@drawable/dialog_table_border""
android:orientation=""vertical""
android:visibility=""visible""&gt;

&lt;LinearLayout
    android:orientation=""horizontal""
    android:layout_width=""match_parent""
    android:layout_height=""wrap_content""
    android:background=""@color/roomlist_title_background""&gt;

    &lt;ProgressBar
        android:layout_width=""wrap_content""
        android:layout_height=""wrap_content""
        android:id=""@+id/progressBar""
        android:layout_margin=""5dp""/&gt;

    &lt;LinearLayout
        android:orientation=""horizontal""
        android:layout_width=""fill_parent""
        android:layout_height=""fill_parent""
        android:layout_gravity=""center""
        android:layout_margin=""5dp""&gt;

        &lt;LinearLayout
            android:orientation=""vertical""
            android:layout_width=""fill_parent""
            android:layout_height=""wrap_content""
            android:layout_gravity=""center_vertical""&gt;

            &lt;TextView
                android:layout_width=""fill_parent""
                android:layout_height=""fill_parent""
                android:text=""Game is on hold because the host paused the app""
                android:id=""@+id/lblOnHoldDialogMessage""
                android:textColor=""@color/progress_dialog_on_hold_text""
                android:textSize=""18dp""
                android:singleLine=""false""
                android:layout_gravity=""center_horizontal""/&gt;
        &lt;/LinearLayout&gt;
    &lt;/LinearLayout&gt;

&lt;/LinearLayout&gt;

&lt;TextView
    android:id=""@+id/lblChatHistoryGameOnHold""
    android:layout_width=""match_parent""
    android:layout_height=""fill_parent""
    android:layout_weight=""1""
    android:gravity=""bottom""
    android:maxLines=""5""
    android:scrollbars=""vertical""
    android:textColor=""@color/edit_text_general_text""
    android:textColorHint=""@color/edit_text_general_hint""
    android:paddingRight=""2dp""
    android:paddingLeft=""2dp""/&gt;

&lt;LinearLayout
    android:layout_width=""match_parent""
    android:layout_height=""wrap_content""&gt;

    &lt;EditText
        android:id=""@+id/textChatGameOnHold""
        android:layout_width=""0dp""
        android:layout_height=""wrap_content""
        android:layout_marginLeft=""2dp""
        android:layout_marginStart=""2dp""
        android:layout_weight=""1""
        android:ems=""10""
        android:hint=""@string/edit_text_send_chat_message""
        android:imeOptions=""flagNoExtractUi|actionDone""
        android:inputType=""text""
        android:maxLength=""100""
        android:maxLines=""1""
        android:textColor=""@color/edit_text_general_text""
        android:textColorHint=""@color/edit_text_general_hint""/&gt;

    &lt;Button
        android:id=""@+id/btnSendGameOnHold""
        style=""@style/lightboxButton.Blue""
        android:layout_width=""wrap_content""
        android:layout_height=""wrap_content""
        android:onClick=""sendChatMessageInGame""
        android:text=""@string/btn_send""/&gt;
&lt;/LinearLayout&gt;

&lt;/LinearLayout&gt; 

","You can get the desired behavior by making adjustResize flag for the windowSoftInputMode of the dialog in the manifest if your dialog is declared as an activity.

Like This:

    android:windowSoftInputMode=""adjustResize|stateHidden""


You can also directly try something like this directly on the dialog:

alertDialog.getWindow().setSoftInputMode(
WindowManager.LayoutParams.SOFT_INPUT_ADJUST_RESIZE);

"
925,925,1462,ASP.net Website want debug to == false on IIS,"Have tried adding this to web.config 

&lt;compilation debug=""false"" targetFramework=""4.0""&gt;
&lt;/compilation&gt;


but website still executes code in #if DEBUG when it shouldn't

*Wierdly the inline statement &lt;% #if DEBUG %> on aspx files works but require also for .cs code. 

NB development and live website on same box
",user3231982,https://stackoverflow.com/users/3231982,"#if directives in backend .cs files are handled by the C# compiler, not ASP.Net.
Set your project to the Release configuration so that that symbol is not defined when compiling the DLL in VS.
",SLaks,https://stackoverflow.com/users/34397,http://stackoverflow.com/questions/21438703/asp-net-website-want-debug-to-false-on-iis,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.4444444444444444,0.0,0.6666666666666666,0.3333333333333333,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,0.8888888888888888,Asp.net website wants to debug on IIS as = false,"Have tried adding this to web.config 

&lt;compilation debug=""false"" targetFramework=""4.0""&gt;
&lt;/compilation&gt;


but website still executes code in #if DEBUG when it shouldn't

*Wierdly the inline statement &lt;% #if DEBUG %> on aspx files works but require also for .cs code. 

NB development and live website on same box
","#if directives in backend .cs files are handled by the C# compiler, not ASP.Net.
Set your project to the Release configuration so that that symbol is not defined when compiling the DLL in VS.
"
18,18,24,Fiber Channel SAN hooked up to 2 ESXi Hosts,"I have a PowerVault with 4 FC modules at 8gb/s. I don't want to jack the SAN into our 10/100/1000 switch because of the max 1gb/s speed.

My question is can I jack both ESXi host's FC into the SAN's FCs and have HV and vMotion?
",Frank,https://serverfault.com/users/95480,"The SAN itself doesn't need an Ethernet connection in this case, all it needs is FC to the ESXi hosts. The ESXi hosts will need GigE Ethernet. During VMotion, the source ESXi starts sending machine-state to the target ESXi host over the VMKernel connection in the virtual-switch. That's actually a connection between the two ESXi hosts over your physical Ethernet switch. Meanwhile, when state is fully transferred control of the VMDK files is passed over to the target server it it goes live. So, vMotion requires both FC and Ethernet.

HA (what I presume you meant by HV) requires vMotion to work, so should be available if vMotion is working. 

Unless you meant Hardware Virtualization, or direct LUN presentation. That can also work, but is trickier. The same volume needs to be presented to both ESXi hosts using exactly the same LUN number, if it doesn't have the same LUN number that volume won't be visible when the VM is on one or the other ESXi host. 
",sysadmin1138,https://serverfault.com/users/3038,http://serverfault.com/questions/314105,TECHNOLOGY,serverfault.com,0.7777777777777778,0.5555555555555556,0.0,1.0,0.6666666666666666,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.6666666666666666,0.0,0.8888888888888888,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.8888888888888888,0.9,0.3333333333333333,0.3333333333333333,0.6666666666666666,1.0,Fibre channel San connected to 2 esxi hosts,I have a PowerVault with four 8GB / s FC modules. I don't want to plug the San into our 10 / 100 / 1000 switch because its top speed is 1GB / s.,"In this case, the San itself does not need Ethernet connectivity, it only needs FC connectivity to the esxi host. Esxi hosts will need GigE Ethernet. During vmotion, the source esxi begins to send machine status to the target esxi host through the vmkernel connection in the virtual switch. This is actually a connection between two esxi hosts through a physical Ethernet switch. At the same time, when the state is fully transferred, the control of vmdk file is transferred to the target server, and it will start. Therefore, vmotion requires FC and Ethernet."
2335,2335,3722,WPF RichTextBox Image Link issue,"I am loading a .rtf file into a WPF Rich TextBox and my images that have links are getting this underline property added. I do not want the underline and cant seem to get rid of it.

              public MainWindow()
    {
        InitializeComponent();

        Assembly assembly = Assembly.GetExecutingAssembly();


        Stream s =  assembly.GetManifestResourceStream(""WPFRichTextIssue.Sigs.MSC.rtf"");
        using (s)
        {
             TextRange TR = new TextRange(RTB.Document.ContentStart, RTB.Document.ContentEnd);

        TR.Load(s, DataFormats.Rtf);
        }

    }


I have tired to find the underlined images with

  if (TR.GetPropertyValue(Inline.TextDecorationsProperty) == TextDecorations.Underline)
            {

            }
            else
            {
                // Do something
            }


But the Image is not Inline.Text so it does not find it... Any help would be great.

I also thought maybe i could overwrite the Rich Textbox default functionality that causes the underline of links but all i can seem to find to make that change is to the Inline Text nothing for the images and the images are not affected. 

The only other option i can think is if there was a way to change the .rtf file to make sure it did not have any underline attributes but unless I am missing something that does not seem to help either. 

Entire VS 2012 project issue sample... Download Project

thanks
",user2788554,https://stackoverflow.com/users/2788554,"Looking in your XAML, just after the RTB opening tag that looks something like this:

&lt;RichTextBox x:Name=""RTB_Reply"" HorizontalAlignment=""Left"" Height=""157"" Margin=""302,338,0,0"" VerticalAlignment=""Top"" Width=""488"" IsReadOnly=""True""&gt;


Paste this:

&lt;RichTextBox.Resources&gt;
    &lt;Style TargetType=""{x:Type Hyperlink}""&gt;
        &lt;Setter Property=""TextDecorations""  Value=""{x:Null}""/&gt;
    &lt;/Style&gt;
&lt;/RichTextBox.Resources&gt;


done deal. =D
",Adam Silzell,https://stackoverflow.com/users/2788916,http://stackoverflow.com/questions/18855588/wpf-richtextbox-image-link-issue,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.5555555555555556,0.0,0.5,1.0,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,1.0,0.0,0.6666666666666666,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,1.0,1.0,0.0,0.0,0.7777777777777778,WPF RichTextBox image link problem,"I am loading a .rtf file into a WPF Rich TextBox and my images that have links are getting this underline property added. I do not want the underline and cant seem to get rid of it.

              public MainWindow()
    {
        InitializeComponent();

        Assembly assembly = Assembly.GetExecutingAssembly();


        Stream s =  assembly.GetManifestResourceStream(""WPFRichTextIssue.Sigs.MSC.rtf"");
        using (s)
        {
             TextRange TR = new TextRange(RTB.Document.ContentStart, RTB.Document.ContentEnd);

        TR.Load(s, DataFormats.Rtf);
        }

    }


I have tired to find the underlined images with

  if (TR.GetPropertyValue(Inline.TextDecorationsProperty) == TextDecorations.Underline)
            {

            }
            else
            {
                // Do something
            }


But the Image is not Inline.Text so it does not find it... Any help would be great.

I also thought maybe i could overwrite the Rich Textbox default functionality that causes the underline of links but all i can seem to find to make that change is to the Inline Text nothing for the images and the images are not affected. 

The only other option i can think is if there was a way to change the .rtf file to make sure it did not have any underline attributes but unless I am missing something that does not seem to help either. 

Entire VS 2012 project issue sample... Download Project

thanks
","Looking in your XAML, just after the RTB opening tag that looks something like this:

&lt;RichTextBox x:Name=""RTB_Reply"" HorizontalAlignment=""Left"" Height=""157"" Margin=""302,338,0,0"" VerticalAlignment=""Top"" Width=""488"" IsReadOnly=""True""&gt;


Paste this:

&lt;RichTextBox.Resources&gt;
    &lt;Style TargetType=""{x:Type Hyperlink}""&gt;
        &lt;Setter Property=""TextDecorations""  Value=""{x:Null}""/&gt;
    &lt;/Style&gt;
&lt;/RichTextBox.Resources&gt;


done deal. =D
"
3392,3392,5410,Is 2N9013 a good replacement for 2N3904,"I needed 2N3904 transistors so I went to the few crappy electronics shops we find in my country. They didn't have those, but they gave me 2N9013 and stated that those were equivalent NPN transistors. Both in TO-92 packages.

I've searched for a datasheet and found one from Promax-Johnton (who?) with ""1W OUTPUT AMPLIFIER OF POTABLE RADIOS IN CLASS B PUSH-PULL OPERATION"" which is worst than Chinese to me :(

My questions are: 
1. Is if this part is a good replacement for my 2n3904? 
2. What additional considerations I need to be aware? 
3. Recommendations?

Thanks in advance.
",Havok,https://electronics.stackexchange.com/users/3365,"It is a little more powerful than the 2n3904. Most likely the current gain is less, and and maybe also the maximal voltages.

Depending on your application that may be OK, which is quite likely if it is not too demanding. The correct thing would for you to check the numbers in the data sheet.
",starblue,https://electronics.stackexchange.com/users/339,http://electronics.stackexchange.com/questions/13900/is-2n9013-a-good-replacement-for-2n3904,TECHNOLOGY,electronics.stackexchange.com,1.0,0.8333333333333334,0.0,1.0,1.0,1.0,0.6666666666666666,0.5,1.0,0.0,1.0,1.0,0.0,0.5,0.0,0.0,0.5,0.0,0.5,0.0,0.8333333333333334,0.5,0.5,1.0,0.8333333333333334,0.6,1.0,0.0,0.5,0.8333333333333334,Is 2n9013 a good substitute for 2N3904,"I needed 2N3904 transistors so I went to the few crappy electronics shops we find in my country. They didn't have those, but they gave me 2N9013 and stated that those were equivalent NPN transistors. Both in TO-92 packages.

I've searched for a datasheet and found one from Promax-Johnton (who?) with ""1W OUTPUT AMPLIFIER OF POTABLE RADIOS IN CLASS B PUSH-PULL OPERATION"" which is worst than Chinese to me :(

My questions are: 
1. Is if this part is a good replacement for my 2n3904? 
2. What additional considerations I need to be aware? 
3. Recommendations?

Thanks in advance.
","It is a little more powerful than the 2n3904. Most likely the current gain is less, and and maybe also the maximal voltages.

Depending on your application that may be OK, which is quite likely if it is not too demanding. The correct thing would for you to check the numbers in the data sheet.
"
1618,1618,2538,ArcMap 10.1 How to make mass (in bulk) update by attribute value,"I have feature class with 70,000+ records (file geodatabase). 
I want to make in bulk update on an attribute where the value is NULL.
Select by attribute shows that I have 5,000 records like that. Doing it one by one is going to be a pain.

In sql pseudo code it should be something like that:

 UPDATE &lt;MyAttributeName&gt; = 'NewValue'
 WHERE &lt;MyAttributeName&gt; IS NULL


How do I do that with ArcMap 10.1?
",mitaka,https://gis.stackexchange.com/users/17107,"May be an overkill, but I tried Python with the Field Calculator:


",mitaka,https://gis.stackexchange.com/users/17107,http://gis.stackexchange.com/questions/70434/making-mass-bulk-update-by-attribute-value-in-arcgis-desktop/70436,TECHNOLOGY,gis.stackexchange.com,1.0,0.6666666666666666,0.0,0.6666666666666666,0.3333333333333333,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.7777777777777778,0.8333333333333334,0.5,0.8333333333333334,0.8333333333333334,0.5,1.0,0.0,0.0,0.8333333333333334,How to update mass (batch) by attribute value in ArcMap 10.1,"I have feature class with 70,000+ records (file geodatabase). 
I want to make in bulk update on an attribute where the value is NULL.
Select by attribute shows that I have 5,000 records like that. Doing it one by one is going to be a pain.

In sql pseudo code it should be something like that:

 UPDATE &lt;MyAttributeName&gt; = 'NewValue'
 WHERE &lt;MyAttributeName&gt; IS NULL


How do I do that with ArcMap 10.1?
","May be an overkill, but I tried Python with the Field Calculator:


"
991,991,1566,Line wrapping long curried function definitions in Scala with Scala IDE,"This is a simple question, but I'm curious about the ""right"" way to line-wrap curried functions in Scala. For example, suppose I have the moderately long line (if it's not long enough, you can pretend there are more parameters):

  def executeFooBarCommand(ce: CommandExecutor)(implicit ec: ExecutionContext): Future[FooBar] = {
    //...
  }


I have two problems regarding wrapping the long definition:

First, I'm not sure what the accepted best practice is for wrapping such lines (or even longer ones.

Second, most reasonable ways of wrapping the line seem to result and in ""auto-rejoin"" of the wrapped lines when I format in eclipse. I set eclipse never to join wrapped lines in java, and there doesn't seem to be a relevant setting in the scala IDE formatting section that I can find, so I'm not sure how to prevent the format command from joining these wrapped lines.
",jonderry,https://stackoverflow.com/users/329781,"Eclipse is based on scalariform, and so far it doesn't have this option. However, it can split parameters in the same parameter list, so you could try formatting it as:


def executeFooBarCommand(
  ce: CommandExecutor)(implicit ec: ExecutionContext): Future[FooBar] = {
    //...
}

",Iulian Dragos,https://stackoverflow.com/users/265463,http://stackoverflow.com/questions/23839804/line-wrapping-long-curried-function-definitions-in-scala-with-scala-ide,STACKOVERFLOW,stackoverflow.com,1.0,0.5555555555555556,0.0,0.6666666666666666,0.3333333333333333,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.5555555555555556,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.0,0.0,0.8888888888888888,Using Scala ide to define curried function in Scala,"This is a simple question, but I'm curious about the ""right"" way to line-wrap curried functions in Scala. For example, suppose I have the moderately long line (if it's not long enough, you can pretend there are more parameters):

  def executeFooBarCommand(ce: CommandExecutor)(implicit ec: ExecutionContext): Future[FooBar] = {
    //...
  }


I have two problems regarding wrapping the long definition:

First, I'm not sure what the accepted best practice is for wrapping such lines (or even longer ones.

Second, most reasonable ways of wrapping the line seem to result and in ""auto-rejoin"" of the wrapped lines when I format in eclipse. I set eclipse never to join wrapped lines in java, and there doesn't seem to be a relevant setting in the scala IDE formatting section that I can find, so I'm not sure how to prevent the format command from joining these wrapped lines.
","Eclipse is based on scalariform, and so far it doesn't have this option. However, it can split parameters in the same parameter list, so you could try formatting it as:


def executeFooBarCommand(
  ce: CommandExecutor)(implicit ec: ExecutionContext): Future[FooBar] = {
    //...
}

"
28,28,40,What is Cold Iron actually?,"It came up in Dresden Files, but is not limited to that game, you can find the term in DnD as well. I would like to know what it means. 

If you look for Cold Iron on Wikipedia, you only get iron: 
""Cold iron is a poetic and archaic term for iron.""
This would imply everything made mostly from Fe is cold iron. Clearly, this is not the case, in every game Cold Iron is something special, the every day sword is not made out of it. 

The Dresden Files rulebook is not very specific about it:


  something that anyone could reasonably get access to, but usually doesn’t carry on them (like cold iron) page 185.


What is cold iron?
How do I create cold iron?
How do I get cold iron?   

To make the question easier to understand, compare Cold Iron to Holy Water. You know how it is different from usual Water, you know how you get it or create it. 
",András,https://rpg.stackexchange.com/users/9552,"Based on the events of Summer Knight cold iron is, in fact, just iron.  Dresden


   kills Aurora with hundreds of pixies wielding common hobby knives with plastic casings.  The book specifically mentions how the cold iron of the knife blades makes the relatively minor cuts deadly to the Summer Lady.


Referencing your quote, how much steel do you have on you right now?  Sure, some people still carry a Leatherman or a pocket knife but most don't in the US these days.  However, how easy is it to get one?  In Summer Knight Dresden specifically mentions needing to


   stop at Walmart prior to the climatic battle but not what he needs,


which is saved for the big reveal at the Stone Table.
",HerbN,https://rpg.stackexchange.com/users/14,http://rpg.stackexchange.com/questions/40826/what-is-cold-iron-actually,CULTURE,rpg.stackexchange.com,1.0,0.5555555555555556,0.0,0.6666666666666666,1.0,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.3333333333333333,0.0,0.6666666666666666,1.0,What is cold iron?,"It came up in Dresden Files, but is not limited to that game, you can find the term in DnD as well. I would like to know what it means. 

If you look for Cold Iron on Wikipedia, you only get iron: 
""Cold iron is a poetic and archaic term for iron.""
This would imply everything made mostly from Fe is cold iron. Clearly, this is not the case, in every game Cold Iron is something special, the every day sword is not made out of it. 

The Dresden Files rulebook is not very specific about it:


  something that anyone could reasonably get access to, but usually doesn’t carry on them (like cold iron) page 185.


What is cold iron?
How do I create cold iron?
How do I get cold iron?   

To make the question easier to understand, compare Cold Iron to Holy Water. You know how it is different from usual Water, you know how you get it or create it. 
","Based on the events of Summer Knight cold iron is, in fact, just iron.  Dresden


   kills Aurora with hundreds of pixies wielding common hobby knives with plastic casings.  The book specifically mentions how the cold iron of the knife blades makes the relatively minor cuts deadly to the Summer Lady.


Referencing your quote, how much steel do you have on you right now?  Sure, some people still carry a Leatherman or a pocket knife but most don't in the US these days.  However, how easy is it to get one?  In Summer Knight Dresden specifically mentions needing to


   stop at Walmart prior to the climatic battle but not what he needs,


which is saved for the big reveal at the Stone Table.
"
1563,1563,2453,So gravity turns things round,"It makes sense, since gravity tends to push the surface of a body towards it's center. Unless I'm mistaken, everything with mass has it's own gravity, every atom and for instance, our own bodies should also have their own gravity. The question is: how strong is our own gravitational pull? I know it must be extremely weak, but is there actually anything at all that gets attracted to us, like maybe, bacteria or molecules?

And finally (this will sound ridiculous, but I'd really want to get an answer or at least a way of calculating it myself): What size would a human body have to reach in order for it to collapse into a sphere?
",Pancho Saavedra,https://physics.stackexchange.com/users/22398,"Well, more or less, the size of a planet... :) There are fu*** big asteroids out there that aren't big enough to get spherical shape. Also, it will help if most of the planet is gas or liquid.

You can calculate the forces classically by Newton's expression for gravitational force: $$\vec F=-G\frac{Mm}{r^2}\vec u_r$$

$G$ is Newton's constant: $G\approx6.67\cdot 10 ^{-11}$ in IS units. You can see it's really week, compared to the constant of electrical force: $k\approx 9\cdot10^9$.
$M  $ and $m$ are the two masses between you want to calculate the force. $r$ is the distance between them. $-\vec u_r$ indicates the force is attractive.

So, the size of the person, well, a million things happens before the size is big enough to collapse in a sphere, like broken bones. You would need to know how resistent tissues are before they brake and so no, but I would go for a good approximation, that it's the order of the size of the moon (probably less than that), like 2 or 3 orders og magnitude smaller.
",MyUserIsThis,https://physics.stackexchange.com/users/17645,http://physics.stackexchange.com/questions/58023/so-gravity-turns-things-round,SCIENCE,physics.stackexchange.com,1.0,0.3333333333333333,0.0,0.6666666666666666,1.0,0.6666666666666666,0.7777777777777778,1.0,1.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8,0.6666666666666666,0.3333333333333333,1.0,0.8888888888888888,So gravity will change things,"This makes sense because gravity tends to push the surface of an object toward its center. Unless I'm wrong, everything with mass has its own gravity. Every atom, for example, our own body should have its own gravity. The question is: how strong is our own gravity? I know it must be weak, but is there anything that attracts us, such as bacteria or molecules?","Well, more or less, the size of a planet... :) There are fu*** big asteroids out there that aren't big enough to get spherical shape. Also, it will help if most of the planet is gas or liquid.

You can calculate the forces classically by Newton's expression for gravitational force: $$\vec F=-G\frac{Mm}{r^2}\vec u_r$$

$G$ is Newton's constant: $G\approx6.67\cdot 10 ^{-11}$ in IS units. You can see it's really week, compared to the constant of electrical force: $k\approx 9\cdot10^9$.
$M  $ and $m$ are the two masses between you want to calculate the force. $r$ is the distance between them. $-\vec u_r$ indicates the force is attractive.

So, the size of the person, well, a million things happens before the size is big enough to collapse in a sphere, like broken bones. You would need to know how resistent tissues are before they brake and so no, but I would go for a good approximation, that it's the order of the size of the moon (probably less than that), like 2 or 3 orders og magnitude smaller.
"
2513,2513,4009,Roots of this third degree polynomial,"I've got the following polynomial
$$
x^3-6x^2-2x+40
$$
and I want to find its roots. The only option I see at the moment is to compute all the divisors of $40$ and their inverse, and manually check if it's result is $0$. This works, because $4$ is a zero and now we can divide the polynomial by the factor $x-4$, resulting in a second degree polynomial (which is easier to solve).

I was wondering if there's any other method/idea to manually find the roots of this polynomial?
",ABC,https://math.stackexchange.com/users/91270,"For polynomial of degree $3$ you can use the following procedure. Assume that you guessed the solution $x_1=4$ (indeed $4^3-6\cdot 4^2-2\cdot 4+40 = 64 -96-8+40 =0)$. 

You can use Horner's method to get the polynomial $p(x)=p_2x^2+p_1x+p_0$ such that $(x-4)\cdot p(x) = x^3-6x^2-2x+40$. You want to do that because $p(x)$ will be a polynomial of degree $2$ and it is easy (see here ) to find the solutions of such polynomial. In your case you have (with Horner's method)

$$\begin{array}{|c|c|c|c|c|}\hline&amp;1&amp;-6&amp;-2&amp;40\\\hline 4&amp;0&amp;1\cdot 4=4&amp;-2\cdot 4=-8&amp;-10\cdot 4=-40\\\hline&amp;0+1=\color{blue}{\underbrace{1}_{:=p_2}}&amp;-6+4=\color{blue}{\underbrace{-2}_{:=p_1}}&amp;-2-8=\color{blue}{\underbrace{-10}_{:=p_0}}&amp;40-40=\color{red}0\\\hline\end{array}$$

So your polynomial becomes $p(x) = \color{blue}1\cdot x^2\color{blue}{-2}\cdot x\color{blue}{-10}= x^2-2x-10$. The remainder, as you can see, is $\color{red}0.$ The solutions to this polynomial are

$$x_{2,3}=\dfrac{2\pm2\sqrt{11}}{2}=1\pm11$$

The solutions are therefore $x_{1,2,3}=4,1+\sqrt{11},1-\sqrt{11}$.
",Bman72,https://math.stackexchange.com/users/119527,http://math.stackexchange.com/questions/962303/roots-of-this-third-degree-polynomial,SCIENCE,math.stackexchange.com,1.0,0.3333333333333333,0.0,0.3333333333333333,1.0,0.6666666666666666,0.7777777777777778,0.5555555555555556,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,1.0,0.3333333333333333,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.8,1.0,0.6666666666666666,0.0,0.8888888888888888,The root of this cubic polynomial,"I've got the following polynomial
$$
x^3-6x^2-2x+40
$$
and I want to find its roots. The only option I see at the moment is to compute all the divisors of $40$ and their inverse, and manually check if it's result is $0$. This works, because $4$ is a zero and now we can divide the polynomial by the factor $x-4$, resulting in a second degree polynomial (which is easier to solve).

I was wondering if there's any other method/idea to manually find the roots of this polynomial?
","For polynomial of degree $3$ you can use the following procedure. Assume that you guessed the solution $x_1=4$ (indeed $4^3-6\cdot 4^2-2\cdot 4+40 = 64 -96-8+40 =0)$. 

You can use Horner's method to get the polynomial $p(x)=p_2x^2+p_1x+p_0$ such that $(x-4)\cdot p(x) = x^3-6x^2-2x+40$. You want to do that because $p(x)$ will be a polynomial of degree $2$ and it is easy (see here ) to find the solutions of such polynomial. In your case you have (with Horner's method)

$$\begin{array}{|c|c|c|c|c|}\hline&amp;1&amp;-6&amp;-2&amp;40\\\hline 4&amp;0&amp;1\cdot 4=4&amp;-2\cdot 4=-8&amp;-10\cdot 4=-40\\\hline&amp;0+1=\color{blue}{\underbrace{1}_{:=p_2}}&amp;-6+4=\color{blue}{\underbrace{-2}_{:=p_1}}&amp;-2-8=\color{blue}{\underbrace{-10}_{:=p_0}}&amp;40-40=\color{red}0\\\hline\end{array}$$

So your polynomial becomes $p(x) = \color{blue}1\cdot x^2\color{blue}{-2}\cdot x\color{blue}{-10}= x^2-2x-10$. The remainder, as you can see, is $\color{red}0.$ The solutions to this polynomial are

$$x_{2,3}=\dfrac{2\pm2\sqrt{11}}{2}=1\pm11$$

The solutions are therefore $x_{1,2,3}=4,1+\sqrt{11},1-\sqrt{11}$.
"
3995,3995,6380,Is there a list of Mitzvot and their corresponding body parts?,"The Talmud (Makkot 23B)and the Zohar (1:170B - unverified English translation here) say that the 248 positive commandments correspond to the 248 limbs of the human body. (The Mishna (Ohalot 1:8) lists the 248 Halachic limbs). The Talmud also says that the 365 Negative commandments correspond to the days of the year.

The Zohar adds that the 365 negative commandments also correspond to the 365 sinews in the human body (See Yonatan Ben Uziel Bereshit 1:27), and connects them to the days of the year.

R' Chaim Vital, in Shaar HaKavanot (Shaar 1, Part 1) says that ""Each of the 248 spiritual limbs gets its nourishment from a particular mitzvah that corresponds to that limb. When a person fails to perform that particular mitzvah, the corresponding limb will lack its proper nourishment..."" (translation from here)

Is there any source which tells us which limb (and/or sinew) each Mitzvah corresponds to?

As an example, the Zohar referenced above (1:170B), connects Gid Hanasheh (sciatic nerve), one of the 365 sinews, to the prohibition of eating on Tisha B'av.
",Menachem,https://judaism.stackexchange.com/users/603,"Biblical mitzvos are in bold. Items that are minhagim or otherwise are not mitzvos are listed for completeness but are not bold. -- Each is followed by the corresponding (set of) body part(s)


30 days of blowing shofar (in Elul) -- 30 in the feet
10 offerings brought on Rosh Hashana -- 10 in the ankles
2 approaches to the aron(?) -- 2 in the shins
5 people called up to the Torah -- 5 in the knees
1 day of Rosh Hashana -- 1 in the thighs
3 types of shofar sound -- 3 in the hips(?)
11 sounds blown with the musaf -- 11 ribs
9 b'rachos in the amida of Rosh Hashana -- 9 in the arms
30 verses recited in that amida -- 30 in the palms
18 b'rachos in the daily amida -- 18 vertebrae
9 shofar sounds with the daily offering -- 9 in the head
8 shofar sounds with two bowings -- 8 in the neck
5 books of Torah -- 5 cavities
6 books of Mishna -- 6 in the heart



Disclaimers: This might be a partial list, a complete confound, or not what you're looking for. Some numbers may need to be doubled for dual limbs. The above most likely does not add up to 248. It comes from  מחזור רבא - נוסח ספרד - ראש השנה, published by שי למורא, on page 198 in my edition. It is part of an inserted piyut in the k'dusha of musaf. A very similar list appears in a number of other machzorim (example) and some translation assistance was provided by this machzor. 

Some of the items on this list are mitzvos, even if it is intended for a purpose other than explication of the statement of Rav Simla'i in Makos that you linked. If they don't count toward the general total then some body parts must double count. 
",WAF,https://judaism.stackexchange.com/users/3,http://judaism.stackexchange.com/questions/10406/is-there-a-list-of-mitzvot-and-their-corresponding-body-parts,CULTURE,judaism.stackexchange.com,1.0,0.7777777777777778,0.0,0.5,1.0,1.0,0.4444444444444444,0.4444444444444444,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.3333333333333333,0.6666666666666666,0.8888888888888888,Do you have a list of rite of passage and corresponding body parts?,"The Talmud (Makkot 23B)and the Zohar (1:170B - unverified English translation here) say that the 248 positive commandments correspond to the 248 limbs of the human body. (The Mishna (Ohalot 1:8) lists the 248 Halachic limbs). The Talmud also says that the 365 Negative commandments correspond to the days of the year.

The Zohar adds that the 365 negative commandments also correspond to the 365 sinews in the human body (See Yonatan Ben Uziel Bereshit 1:27), and connects them to the days of the year.

R' Chaim Vital, in Shaar HaKavanot (Shaar 1, Part 1) says that ""Each of the 248 spiritual limbs gets its nourishment from a particular mitzvah that corresponds to that limb. When a person fails to perform that particular mitzvah, the corresponding limb will lack its proper nourishment..."" (translation from here)

Is there any source which tells us which limb (and/or sinew) each Mitzvah corresponds to?

As an example, the Zohar referenced above (1:170B), connects Gid Hanasheh (sciatic nerve), one of the 365 sinews, to the prohibition of eating on Tisha B'av.
","Biblical mitzvos are in bold. Items that are minhagim or otherwise are not mitzvos are listed for completeness but are not bold. -- Each is followed by the corresponding (set of) body part(s)


30 days of blowing shofar (in Elul) -- 30 in the feet
10 offerings brought on Rosh Hashana -- 10 in the ankles
2 approaches to the aron(?) -- 2 in the shins
5 people called up to the Torah -- 5 in the knees
1 day of Rosh Hashana -- 1 in the thighs
3 types of shofar sound -- 3 in the hips(?)
11 sounds blown with the musaf -- 11 ribs
9 b'rachos in the amida of Rosh Hashana -- 9 in the arms
30 verses recited in that amida -- 30 in the palms
18 b'rachos in the daily amida -- 18 vertebrae
9 shofar sounds with the daily offering -- 9 in the head
8 shofar sounds with two bowings -- 8 in the neck
5 books of Torah -- 5 cavities
6 books of Mishna -- 6 in the heart



Disclaimers: This might be a partial list, a complete confound, or not what you're looking for. Some numbers may need to be doubled for dual limbs. The above most likely does not add up to 248. It comes from  מחזור רבא - נוסח ספרד - ראש השנה, published by שי למורא, on page 198 in my edition. It is part of an inserted piyut in the k'dusha of musaf. A very similar list appears in a number of other machzorim (example) and some translation assistance was provided by this machzor. 

Some of the items on this list are mitzvos, even if it is intended for a purpose other than explication of the statement of Rav Simla'i in Makos that you linked. If they don't count toward the general total then some body parts must double count. 
"
3008,3008,4794,Can only access one of the router's web portal and the Internet,"On both wired and wireless connections, I can only access one of 192.168.1.1 (the router web portal) and the general Internet.  Which ""mode"" my devices are in is seemingly random.  This has persisted so far for 5 days (since I began using this network).

When connected to the Internet, I can go to 192.168.102.1 and I see a landing page for ""mikrotik routeros"", but I cannot go to 192.168.1.1. When connected to the router but not the Internet, 192.168.1.1 yields the router web portal, and 192.168.102.1 is inaccessible.

Attempted solutions


Upgrading router firmware  
Resetting router to factory settings  
Rebooting devices  
Fiddling with router settings (changing wireless security modes, removing wireless security, etc)  
Upgrading wireless drivers on computers  


Some data


Affects BlackBerry, Windows, Android and Ubuntu devices
All devices work properly on other networks
Devices may switch modes if they have been offline for a long time (eg: overnight), but restarting a device has no effect
Router is TP-Link TL-WR740N v4
Router firmware DD-WRT v24-sp2 (04/18/14) std - build 23919
Both wired and wireless connections are affected, but not necessarily simultaneously


I don't know anything about networking, but here's some info that seems helpful taken from my Ubuntu laptop.

With internet access (wired in this case, but it varies):

~ $ route -n
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
0.0.0.0         192.168.102.1   0.0.0.0         UG    0      0        0 eth0
192.168.102.0   0.0.0.0         255.255.254.0   U     1      0        0 eth0

~ $ ifconfig
eth0      Link encap:Ethernet  HWaddr 54:ee:75:0c:02:80  
          inet addr:192.168.103.232  Bcast:192.168.103.255  Mask:255.255.254.0
          inet6 addr: fe80::56ee:75ff:fe0c:280/64 Scope:Link
          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
          RX packets:3273 errors:0 dropped:0 overruns:0 frame:0
          TX packets:3035 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:1000 
          RX bytes:2276482 (2.2 MB)  TX bytes:517732 (517.7 KB)
          Interrupt:20 Memory:f0500000-f0520000 

lo        Link encap:Local Loopback  
          inet addr:127.0.0.1  Mask:255.0.0.0
          inet6 addr: ::1/128 Scope:Host
          UP LOOPBACK RUNNING  MTU:65536  Metric:1
          RX packets:4315 errors:0 dropped:0 overruns:0 frame:0
          TX packets:4315 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:0 
          RX bytes:342880 (342.8 KB)  TX bytes:342880 (342.8 KB)


With ""router access"" (wireless in this case, but it varies):

~ $ route -n
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
0.0.0.0         192.168.1.1     0.0.0.0         UG    0      0        0 wlan0
192.168.1.0     0.0.0.0         255.255.255.0   U     9      0        0 wlan0

~ $ ifconfig
eth0      Link encap:Ethernet  HWaddr 54:ee:75:0c:02:80  
          UP BROADCAST MULTICAST  MTU:1500  Metric:1
          RX packets:9422 errors:0 dropped:0 overruns:0 frame:0
          TX packets:7545 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:1000 
          RX bytes:6216683 (6.2 MB)  TX bytes:1399280 (1.3 MB)
          Interrupt:20 Memory:f0500000-f0520000 

lo        Link encap:Local Loopback  
          inet addr:127.0.0.1  Mask:255.0.0.0
          inet6 addr: ::1/128 Scope:Host
          UP LOOPBACK RUNNING  MTU:65536  Metric:1
          RX packets:4446 errors:0 dropped:0 overruns:0 frame:0
          TX packets:4446 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:0 
          RX bytes:353415 (353.4 KB)  TX bytes:353415 (353.4 KB)

wlan0     Link encap:Ethernet  HWaddr e8:2a:ea:60:31:4b  
          inet addr:192.168.1.105  Bcast:192.168.1.255  Mask:255.255.255.0
          inet6 addr: fe80::ea2a:eaff:fe60:314b/64 Scope:Link
          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
          RX packets:77013 errors:0 dropped:0 overruns:0 frame:0
          TX packets:49506 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:1000 
          RX bytes:25275438 (25.2 MB)  TX bytes:30355132 (30.3 MB)


With both (wired with wireless turned on):

~ $ route -n
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
0.0.0.0         192.168.102.1   0.0.0.0         UG    0      0        0 eth0
192.168.1.0     0.0.0.0         255.255.255.0   U     9      0        0 wlan0
192.168.102.0   0.0.0.0         255.255.254.0   U     1      0        0 eth0

",William,https://superuser.com/users/367462,"The fact that your are getting assigned IPs on two different subnets implies you have two DHCP servers on the directly attached network.

Usually, I'd recommend using something like dhcp_probe -f eth0 or roguechecker to find out which IPs on your network are serving DHCP but you already know which they are. Namely, 192.168.1.1 and 192.168.102.1. 

You have two options to get internet connectivity AND be able to connect to the 192.168.1.0 network at the same time. Both will require disabling or removing the DHCP server on 192.168.1.1 and letting 192.168.102.1 assign you an IP for internet access.

Methods follow:

1) Add a static routing entry to the linux box that tells it that 192.168.1.0 is directly attached.

route add -net 192.168.1.0/24 wlan0 should work for this.

2) Add a static routing entry to the router that tells it 192.168.1.0 is directly attached.

This would be specific to your router/firmware, but since you're running DD-WRT you can easily find the information on adding a static route. As a note, your gateway should be 0.0.0.0 for directly connected nets.
",ssnobody,https://superuser.com/users/278912,http://superuser.com/questions/810510,TECHNOLOGY,superuser.com,0.7777777777777778,0.6666666666666666,0.0,1.0,1.0,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,1.0,0.8888888888888888,Only one web portal and Internet of router can be accessed,"On both wired and wireless connections, I can only access one of 192.168.1.1 (the router web portal) and the general Internet.  Which ""mode"" my devices are in is seemingly random.  This has persisted so far for 5 days (since I began using this network).

When connected to the Internet, I can go to 192.168.102.1 and I see a landing page for ""mikrotik routeros"", but I cannot go to 192.168.1.1. When connected to the router but not the Internet, 192.168.1.1 yields the router web portal, and 192.168.102.1 is inaccessible.

Attempted solutions


Upgrading router firmware  
Resetting router to factory settings  
Rebooting devices  
Fiddling with router settings (changing wireless security modes, removing wireless security, etc)  
Upgrading wireless drivers on computers  


Some data


Affects BlackBerry, Windows, Android and Ubuntu devices
All devices work properly on other networks
Devices may switch modes if they have been offline for a long time (eg: overnight), but restarting a device has no effect
Router is TP-Link TL-WR740N v4
Router firmware DD-WRT v24-sp2 (04/18/14) std - build 23919
Both wired and wireless connections are affected, but not necessarily simultaneously


I don't know anything about networking, but here's some info that seems helpful taken from my Ubuntu laptop.

With internet access (wired in this case, but it varies):

~ $ route -n
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
0.0.0.0         192.168.102.1   0.0.0.0         UG    0      0        0 eth0
192.168.102.0   0.0.0.0         255.255.254.0   U     1      0        0 eth0

~ $ ifconfig
eth0      Link encap:Ethernet  HWaddr 54:ee:75:0c:02:80  
          inet addr:192.168.103.232  Bcast:192.168.103.255  Mask:255.255.254.0
          inet6 addr: fe80::56ee:75ff:fe0c:280/64 Scope:Link
          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
          RX packets:3273 errors:0 dropped:0 overruns:0 frame:0
          TX packets:3035 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:1000 
          RX bytes:2276482 (2.2 MB)  TX bytes:517732 (517.7 KB)
          Interrupt:20 Memory:f0500000-f0520000 

lo        Link encap:Local Loopback  
          inet addr:127.0.0.1  Mask:255.0.0.0
          inet6 addr: ::1/128 Scope:Host
          UP LOOPBACK RUNNING  MTU:65536  Metric:1
          RX packets:4315 errors:0 dropped:0 overruns:0 frame:0
          TX packets:4315 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:0 
          RX bytes:342880 (342.8 KB)  TX bytes:342880 (342.8 KB)


With ""router access"" (wireless in this case, but it varies):

~ $ route -n
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
0.0.0.0         192.168.1.1     0.0.0.0         UG    0      0        0 wlan0
192.168.1.0     0.0.0.0         255.255.255.0   U     9      0        0 wlan0

~ $ ifconfig
eth0      Link encap:Ethernet  HWaddr 54:ee:75:0c:02:80  
          UP BROADCAST MULTICAST  MTU:1500  Metric:1
          RX packets:9422 errors:0 dropped:0 overruns:0 frame:0
          TX packets:7545 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:1000 
          RX bytes:6216683 (6.2 MB)  TX bytes:1399280 (1.3 MB)
          Interrupt:20 Memory:f0500000-f0520000 

lo        Link encap:Local Loopback  
          inet addr:127.0.0.1  Mask:255.0.0.0
          inet6 addr: ::1/128 Scope:Host
          UP LOOPBACK RUNNING  MTU:65536  Metric:1
          RX packets:4446 errors:0 dropped:0 overruns:0 frame:0
          TX packets:4446 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:0 
          RX bytes:353415 (353.4 KB)  TX bytes:353415 (353.4 KB)

wlan0     Link encap:Ethernet  HWaddr e8:2a:ea:60:31:4b  
          inet addr:192.168.1.105  Bcast:192.168.1.255  Mask:255.255.255.0
          inet6 addr: fe80::ea2a:eaff:fe60:314b/64 Scope:Link
          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
          RX packets:77013 errors:0 dropped:0 overruns:0 frame:0
          TX packets:49506 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:1000 
          RX bytes:25275438 (25.2 MB)  TX bytes:30355132 (30.3 MB)


With both (wired with wireless turned on):

~ $ route -n
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
0.0.0.0         192.168.102.1   0.0.0.0         UG    0      0        0 eth0
192.168.1.0     0.0.0.0         255.255.255.0   U     9      0        0 wlan0
192.168.102.0   0.0.0.0         255.255.254.0   U     1      0        0 eth0

","The fact that your are getting assigned IPs on two different subnets implies you have two DHCP servers on the directly attached network.

Usually, I'd recommend using something like dhcp_probe -f eth0 or roguechecker to find out which IPs on your network are serving DHCP but you already know which they are. Namely, 192.168.1.1 and 192.168.102.1. 

You have two options to get internet connectivity AND be able to connect to the 192.168.1.0 network at the same time. Both will require disabling or removing the DHCP server on 192.168.1.1 and letting 192.168.102.1 assign you an IP for internet access.

Methods follow:

1) Add a static routing entry to the linux box that tells it that 192.168.1.0 is directly attached.

route add -net 192.168.1.0/24 wlan0 should work for this.

2) Add a static routing entry to the router that tells it 192.168.1.0 is directly attached.

This would be specific to your router/firmware, but since you're running DD-WRT you can easily find the information on adding a static route. As a note, your gateway should be 0.0.0.0 for directly connected nets.
"
3959,3959,6320,What happens to light and mass in the center of a black hole?,"I know that black holes are ""black"" because nothing can escape it due to the massive gravity, but I am wondering if there are any theories as to what happens to the light or mass that enters a black hole and cannot escape. 
",Annika Peterson,https://physics.stackexchange.com/users/4179,"Simply put: we don't know. From our perspective a black hole cuts off its interior from the rest of the Universe, the only aspects of a black hole that remain are mass, charge, and spin. In truth, even barely understanding what happens inside the event horizon will depend on an understanding of quantum gravity, something which we do not yet have. And even then it will still be largely theoretical since we have no way of interacting with the interior of a black hole.
",Wedge,https://physics.stackexchange.com/users/4578,http://physics.stackexchange.com/questions/26704/what-happens-to-light-and-mass-in-the-center-of-a-black-hole,SCIENCE,physics.stackexchange.com,1.0,0.8888888888888888,0.0,0.0,1.0,0.3333333333333333,0.8888888888888888,0.8888888888888888,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,1.0,0.5555555555555556,1.0,1.0,1.0,0.0,0.0,1.0,1.0,What happens to the light and mass at the center of a black hole?,"I know that black holes are ""black"" because nothing can escape them because of the huge gravity, but I want to know if there is any theory that can explain what happened to the light or mass entering the black hole, and cannot escape.","Simply put: we don't know. From our perspective a black hole cuts off its interior from the rest of the Universe, the only aspects of a black hole that remain are mass, charge, and spin. In truth, even barely understanding what happens inside the event horizon will depend on an understanding of quantum gravity, something which we do not yet have. And even then it will still be largely theoretical since we have no way of interacting with the interior of a black hole.
"
469,469,731,Can I expect my e-mail to be routed securely?,"If I connect to my e-mail server via SSL (SMTP/SSL) and the recipient also only checks his e-mail via SSL (web/https or IMAP/SSL), does this - generally speaking - increase the security for the message content in any way? 

That is, will the communication between my providers e-mail server and the recipients e-mail server be ""secure""(*), or will the e-mail be delivered plain text between the servers? 

(*) Secure in the context of: encrypted throughout it's transit. Not secure in the sense that I'd put any really sensitive info in there.
",Martin,https://security.stackexchange.com/users/3785,"The SMTP servers may (probably will) still transfer the email as plain text. Sometimes SSL is used, but you cannot count on this being the case unless you specifically know the configuration of the specific servers on both ends. This means that in your scenario, an adversary capable of monitoring Internet backbone traffic could intercept the email. (Generally adversaries with this level of capability are state actors.)

SSL is still important on both ends to protect account credentials, and it will protect you against adversaries monitoring the traffic on your local network. Many attacks are going to be at this level - someone on the same wireless network as you, for instance, or who has compromised a local server on your LAN. However, SSL will do nothing to protect you against a compromised SMTP server. Message-level encryption is required if you want to avoid any transmission of the message in plaintext, and importantly means that the message will not be stored in plaintext on either server. For non-state adversaries this is the biggest attack vector - just compromise the SMTP server on either end and you can read all the plaintext mail even if every transmission along the way used SSL.

S/MIME and PGP (GnuPG) are the two standards for doing this. Even then, the message envelope will be visible. You cannot prevent an adversary who can sniff the traffic between the SMTP servers from reading the envelope, so they would know things such as the to, from, and subject line.

To directly answer your question, both parties using SSL to send and retrieve their email does improve your security - and it improves your security versus non-state adversaries a lot - but to secure the message content as much as possible you should use message-level encryption to fully encrypt the message body, and accept that the email headers will still be transmitted in the clear. An adversary capable of seeing the traffic between the SMTP servers would still be able to tell who you were emailing and what the subject line was - there's no way around that besides ""don't use email"" - but they would not be able to read the body of the message.
",Ian,https://security.stackexchange.com/users/3089,http://security.stackexchange.com/questions/8289/can-i-expect-my-e-mail-to-be-routed-securely,TECHNOLOGY,security.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,1.0,1.0,1.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.8888888888888888,0.8888888888888888,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,1.0,Can I count on my email to be delivered safely?,"If I connect to my e-mail server via SSL (SMTP/SSL) and the recipient also only checks his e-mail via SSL (web/https or IMAP/SSL), does this - generally speaking - increase the security for the message content in any way? 

That is, will the communication between my providers e-mail server and the recipients e-mail server be ""secure""(*), or will the e-mail be delivered plain text between the servers? 

(*) Secure in the context of: encrypted throughout it's transit. Not secure in the sense that I'd put any really sensitive info in there.
","The SMTP servers may (probably will) still transfer the email as plain text. Sometimes SSL is used, but you cannot count on this being the case unless you specifically know the configuration of the specific servers on both ends. This means that in your scenario, an adversary capable of monitoring Internet backbone traffic could intercept the email. (Generally adversaries with this level of capability are state actors.)

SSL is still important on both ends to protect account credentials, and it will protect you against adversaries monitoring the traffic on your local network. Many attacks are going to be at this level - someone on the same wireless network as you, for instance, or who has compromised a local server on your LAN. However, SSL will do nothing to protect you against a compromised SMTP server. Message-level encryption is required if you want to avoid any transmission of the message in plaintext, and importantly means that the message will not be stored in plaintext on either server. For non-state adversaries this is the biggest attack vector - just compromise the SMTP server on either end and you can read all the plaintext mail even if every transmission along the way used SSL.

S/MIME and PGP (GnuPG) are the two standards for doing this. Even then, the message envelope will be visible. You cannot prevent an adversary who can sniff the traffic between the SMTP servers from reading the envelope, so they would know things such as the to, from, and subject line.

To directly answer your question, both parties using SSL to send and retrieve their email does improve your security - and it improves your security versus non-state adversaries a lot - but to secure the message content as much as possible you should use message-level encryption to fully encrypt the message body, and accept that the email headers will still be transmitted in the clear. An adversary capable of seeing the traffic between the SMTP servers would still be able to tell who you were emailing and what the subject line was - there's no way around that besides ""don't use email"" - but they would not be able to read the body of the message.
"
5243,5243,8334,Can I restrict a vhost to only a local IP?,"I have a subdomain I'd like to only be accessible by a local IP address.  Is it possible to specify this in the vhost?  I'm thinking it's not since I haven't found much on Google.  If not, what's the best way to do this on an apache level?  I forget the version of Linux we're using... but we have Samba running on it.

The site I'm trying to restrict is our site's documentation.
",Webnet,https://serverfault.com/users/37222,"Default Apache VirtualHost configuration has alias for /doc/ that redirects to Apache's documentation and access is restricted only to localhost. I think that is what you are looking for. Look at the Deny and Allow lines.

Alias /doc/ ""/usr/share/doc/""
&lt;Directory ""/usr/share/doc/""&gt;
    Options Indexes MultiViews FollowSymLinks
    AllowOverride None
    Order deny,allow
    Deny from all
    Allow from 127.0.0.0/255.0.0.0 ::1/128
&lt;/Directory&gt;

",0xFF,https://serverfault.com/users/98592,http://serverfault.com/questions/323610,TECHNOLOGY,serverfault.com,1.0,0.7777777777777778,0.0,1.0,0.3333333333333333,1.0,0.6666666666666666,0.3333333333333333,1.0,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.0,0.0,0.8888888888888888,Can I limit Vhost to local IP only?,"I have a subdomain, which I hope can only be accessed through the local IP address. Can I specify it in Vhost? I don't think it's because I didn't find anything on Google. If not, what's the best way to do it at the Apache level? I forgot the Linux version we were using... But there's Samba on it.","Default Apache VirtualHost configuration has alias for /doc/ that redirects to Apache's documentation and access is restricted only to localhost. I think that is what you are looking for. Look at the Deny and Allow lines.

Alias /doc/ ""/usr/share/doc/""
&lt;Directory ""/usr/share/doc/""&gt;
    Options Indexes MultiViews FollowSymLinks
    AllowOverride None
    Order deny,allow
    Deny from all
    Allow from 127.0.0.0/255.0.0.0 ::1/128
&lt;/Directory&gt;

"
997,997,1574,Any omitted word in this sentence?,"
  The dark guy took a week to fall down. He stumbled, caught himself, waved one arm, stumbled again. His hat fell off, and then he hit the floor with his face. After he hit it he might have been poured concrete for all the fuss he made.


I just guess the guy fell on the floor (by a gun-shot) wouldn't move like a concret cast???

Any missing word in this sentence, like a preposition?

It's a part of Red Wind by Raymond Chandler.
",user58207,https://english.stackexchange.com/users/58207,"Chandler's style works to describe the scene and actions but grammatically there are several redundancies such as ""fall (down)"", ""after he hit (it) (he)"", ""for all the fuss (he) made"". All of these point to possible improvements. Also the floor-hitting face should be reversed to ""then his face hit the floor"". So, in my opinion, there are no missing words but several extra could be eliminated.
",tonenotvolume,https://english.stackexchange.com/users/105350,http://english.stackexchange.com/questions/220313/any-omitted-word-in-this-sentence,CULTURE,english.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.4444444444444444,0.6666666666666666,0.0,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.0,1.0,0.8888888888888888,Is there any missing word in this sentence?,"It took the nigger a week to fall. He stumbled, grabbed himself, waved and stumbled again. His hat fell off, and then his face hit the floor. After he hit it, he may have been concreted to cope with everything he did.","Chandler's style works to describe the scene and actions but grammatically there are several redundancies such as ""fall (down)"", ""after he hit (it) (he)"", ""for all the fuss (he) made"". All of these point to possible improvements. Also the floor-hitting face should be reversed to ""then his face hit the floor"". So, in my opinion, there are no missing words but several extra could be eliminated.
"
507,507,790,What is Cold Iron actually?,"It came up in Dresden Files, but is not limited to that game, you can find the term in DnD as well. I would like to know what it means. 

If you look for Cold Iron on Wikipedia, you only get iron: 
""Cold iron is a poetic and archaic term for iron.""
This would imply everything made mostly from Fe is cold iron. Clearly, this is not the case, in every game Cold Iron is something special, the every day sword is not made out of it. 

The Dresden Files rulebook is not very specific about it:


  something that anyone could reasonably get access to, but usually doesn’t carry on them (like cold iron) page 185.


What is cold iron?
How do I create cold iron?
How do I get cold iron?   

To make the question easier to understand, compare Cold Iron to Holy Water. You know how it is different from usual Water, you know how you get it or create it. 
",András,https://rpg.stackexchange.com/users/9552,"“Cold iron” historically is just a poetic way of saying “iron.” Worked iron (including steel) is traditionally something that the fairy folk shy away from, and many fantasy works have embraced this—but each does it their own way.

The Dresden Files universe is a very practical and down-to-earth place when it comes to magical reagents. In a world where magic is about faith and effort, where ritual is just a convenient way to focus one's will, you don't have to do anything in particular to make iron nasty for the fey. Iron and fairies just don't mix: pretty much any iron/steel will make the fey folk unhappy. (By contrast D&amp;D 3.5 says cold iron is special stuff, defined both by where it’s mined and how it’s forged. We could speculate about whether that's more due to flavour or balance, but I digress.)

The very presence of iron in any form is uncomfortable for Dresden Files fey, and bringing steel into a fey demesne is profane, but most people don’t casually carry enough iron to be a convenient weapon against the fey. Wounds inflicted on fairies by iron weapons—including nails, boxcutters, and steel-jacketed bullets—are slow to heal, and are spiritual as well as physical. You could also try hitting one with your car, or using a staple gun--neither of which are designed for precision violence.

If this seems imbalanced, well. It is. DFRPG is more narratively balanced than it is mechanically. Since fey find iron so offensive, they go on the offensive when confronted with it. Possessing an iron weapon has major drawbacks in a fey-heavy campaign, because it makes you a target for suspicion and possibly pre-emptive elimination. But--remember that your average handgun bullets don't have steel jackets.

…the fairies are very glad we’re using so much more plastic these days.

(There is also a real-world forging technique called “cold forging.” It means the metal wasn’t heated as much as many techniques call for, and the resulting piece has different qualities of hardness than a hot-forged piece. This is irrelevant to DFRPG’s definition of cold iron, though other settings sometimes mean this when they talk about “cold iron.”)
",BESW,https://rpg.stackexchange.com/users/4398,http://rpg.stackexchange.com/questions/40826/what-is-cold-iron-actually,CULTURE,rpg.stackexchange.com,1.0,0.4444444444444444,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.3333333333333333,1.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.0,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8,0.0,0.0,1.0,0.8888888888888888,What is cold iron?,"It came up in Dresden Files, but is not limited to that game, you can find the term in DnD as well. I would like to know what it means. 

If you look for Cold Iron on Wikipedia, you only get iron: 
""Cold iron is a poetic and archaic term for iron.""
This would imply everything made mostly from Fe is cold iron. Clearly, this is not the case, in every game Cold Iron is something special, the every day sword is not made out of it. 

The Dresden Files rulebook is not very specific about it:


  something that anyone could reasonably get access to, but usually doesn’t carry on them (like cold iron) page 185.


What is cold iron?
How do I create cold iron?
How do I get cold iron?   

To make the question easier to understand, compare Cold Iron to Holy Water. You know how it is different from usual Water, you know how you get it or create it. 
","“Cold iron” historically is just a poetic way of saying “iron.” Worked iron (including steel) is traditionally something that the fairy folk shy away from, and many fantasy works have embraced this—but each does it their own way.

The Dresden Files universe is a very practical and down-to-earth place when it comes to magical reagents. In a world where magic is about faith and effort, where ritual is just a convenient way to focus one's will, you don't have to do anything in particular to make iron nasty for the fey. Iron and fairies just don't mix: pretty much any iron/steel will make the fey folk unhappy. (By contrast D&amp;D 3.5 says cold iron is special stuff, defined both by where it’s mined and how it’s forged. We could speculate about whether that's more due to flavour or balance, but I digress.)

The very presence of iron in any form is uncomfortable for Dresden Files fey, and bringing steel into a fey demesne is profane, but most people don’t casually carry enough iron to be a convenient weapon against the fey. Wounds inflicted on fairies by iron weapons—including nails, boxcutters, and steel-jacketed bullets—are slow to heal, and are spiritual as well as physical. You could also try hitting one with your car, or using a staple gun--neither of which are designed for precision violence.

If this seems imbalanced, well. It is. DFRPG is more narratively balanced than it is mechanically. Since fey find iron so offensive, they go on the offensive when confronted with it. Possessing an iron weapon has major drawbacks in a fey-heavy campaign, because it makes you a target for suspicion and possibly pre-emptive elimination. But--remember that your average handgun bullets don't have steel jackets.

…the fairies are very glad we’re using so much more plastic these days.

(There is also a real-world forging technique called “cold forging.” It means the metal wasn’t heated as much as many techniques call for, and the resulting piece has different qualities of hardness than a hot-forged piece. This is irrelevant to DFRPG’s definition of cold iron, though other settings sometimes mean this when they talk about “cold iron.”)
"
1480,1480,2327,"Is the following usage of ""matter-of-factly"" correct?","Most of the usage of ""matter-of-factly"" that I've seen is to describe a manner of speaking - ""He said, matter of factly,..."", etc.

A friend brought up the following usage, which seems wrong, but I can't pinpoint exactly what is wrong. ""Matter of factly, I don't know. I know from my dad's experience.""

What's the view on this?

Couple of points:


The adjective form ""As a matter of fact, I don't know. ..."" seems correct.
Similar usage of literally works: ""I literally don't know."" or ""Literally, I don't know""

",ak86,https://english.stackexchange.com/users/3850,"I've never heard it, and BYU's COCA has but one example of it (and q.v., as I'm not sure even it's in this sense). So, short answer, maybe it's an up-and-coming usage or maybe it's a one-off your friend heard, but in any event don't put it in your written work &mdash; yet.
",msh210,https://english.stackexchange.com/users/3461,http://english.stackexchange.com/questions/9361/is-the-following-usage-of-matter-of-factly-correct,CULTURE,english.stackexchange.com,1.0,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,1.0,0.6666666666666666,0.8888888888888888,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.8888888888888888,0.7777777777777778,0.6666666666666666,1.0,0.8888888888888888,0.7333333333333333,0.0,0.3333333333333333,0.6666666666666666,0.8888888888888888,"Is the following ""be realistic"" correct?","Most of the usage of ""matter-of-factly"" that I've seen is to describe a manner of speaking - ""He said, matter of factly,..."", etc.

A friend brought up the following usage, which seems wrong, but I can't pinpoint exactly what is wrong. ""Matter of factly, I don't know. I know from my dad's experience.""

What's the view on this?

Couple of points:


The adjective form ""As a matter of fact, I don't know. ..."" seems correct.
Similar usage of literally works: ""I literally don't know."" or ""Literally, I don't know""

","I've never heard it, and BYU's COCA has but one example of it (and q.v., as I'm not sure even it's in this sense). So, short answer, maybe it's an up-and-coming usage or maybe it's a one-off your friend heard, but in any event don't put it in your written work &mdash; yet.
"
3745,3745,5966,Setting a basic footer to a UITableView,"How is a basic footer set to a UITableView programmatically? 

Just a centered text?

EDIT: 

How can the bar color be set and the footer bar position fixed to the bottom of the screen or if the thumbs dont fill a screen, the footer isnt above the bottom of the screen.


",jarryd,https://stackoverflow.com/users/356387,"viewForFooterInSection sets the section's footer. To set the table's footer, you want to set

self.tableView.tableFooterView = myCustomFooterView


where myCustomFooterView is something you setup elsewhere. You'd probably set that in viewDidLoad.
",Nick Curran,https://stackoverflow.com/users/570524,http://stackoverflow.com/questions/5111748/setting-a-basic-footer-to-a-uitableview,STACKOVERFLOW,stackoverflow.com,1.0,0.4444444444444444,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,1.0,Set base footer to uitableview,"How is a basic footer set to a UITableView programmatically? 

Just a centered text?

EDIT: 

How can the bar color be set and the footer bar position fixed to the bottom of the screen or if the thumbs dont fill a screen, the footer isnt above the bottom of the screen.


","viewForFooterInSection sets the section's footer. To set the table's footer, you want to set

self.tableView.tableFooterView = myCustomFooterView


where myCustomFooterView is something you setup elsewhere. You'd probably set that in viewDidLoad.
"
732,732,1165,What abilities can be blocked by sivir's/nocturne's spell shield?,"Mainly, im wondering what ultimates would be blocked, and other spells that have long casts. But if you have a list that would be nice.
",Peter Jessen,https://gaming.stackexchange.com/users/34312,"Every attack! Even basic attacks like NASUS's Q, hope this was a good helper!
",RiotPhreak,https://gaming.stackexchange.com/users/61465,http://gaming.stackexchange.com/questions/105682/what-abilities-can-be-blocked-by-sivirs-nocturnes-spell-shield,CULTURE,gaming.stackexchange.com,0.8888888888888888,0.8888888888888888,0.0,1.0,1.0,1.0,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.8888888888888888,0.5555555555555556,1.0,1.0,0.9333333333333332,0.0,0.0,0.3333333333333333,0.6666666666666666,What ability can be blocked by the magic shield of sylvier / Nocturne?,"Basically, I want to know what ultimatums are blocked, and other spells that have a long cast time. But it would be great if you had a list.","Every attack! Even basic attacks like NASUS's Q, hope this was a good helper!
"
4739,4739,7517,What is the purpose of active and passive voice?,"In both passive and active voice, the meaning of the sentence is same. 

So what is the purpose of passive and active as by two different names?
",john michal,https://ell.stackexchange.com/users/4123,"I would like to invite us to consider what would happen if the passive voice did not exist.

To summary StoneyB's answer, the passive voice allows us to not have to mention the Agent (the person who performed the action). This is useful when the Agent is less important, unknown, or someone or something you don't want to mention.

What if we don't have the passive voice?

Consider this text from a Wikipedia page, Merchant of Venice:


  Though classified as a comedy in the First Folio and sharing certain aspects with Shakespeare's other romantic comedies, the play is perhaps most remembered for its dramatic scenes, and is best known for Shylock and the famous ""Hath not a Jew eyes?"" speech.


Who classified it (the play)? Who remembers it? Who knows it?

It's unclear who did and does (or do) so. The passive voice allows this. Without the passive voice, we would be forced to state the subjects of those clauses explicitly. (And, who forced us so?) The most practical way to rephrase that sentence in active voice is to assume either ""we"" or ""people"" as the subject. Let's see what happened if I rewrite the sentence in active voice,


  Though people classify the play as a comedy in the First Folio and the play shares certain aspects with Shakespeare's other romantic comedies, people perhaps remember the play most for its dramatic scenes, and know it best for Shylock and the famous ""Hath not a Jew eyes?"" speech.


And that is quite awkward.

Let's consider another sentence.
(the credit goes to Cerberus, who give me this great example sentence in our ELL chat room)


  When the dam collapsed, the water was released into the valley.


Who released the water?
The incident? The dam itself? The officers who are responsible for the dam?

And because I don't know who released it, I think we are lucky to have the passive voice around.
",Damkerng T.,https://ell.stackexchange.com/users/3281,http://ell.stackexchange.com/questions/16406/what-is-the-purpose-of-active-and-passive-voice,CULTURE,ell.stackexchange.com,0.7777777777777778,0.7777777777777778,0.0,1.0,1.0,1.0,0.6666666666666666,0.7777777777777778,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.6666666666666666,0.5555555555555556,0.8888888888888888,0.6666666666666666,0.5333333333333333,0.0,0.0,0.6666666666666666,0.6666666666666666,What is the purpose of active voice and passive voice?,The meaning of a sentence is the same whether it is a passive voice or an active voice.,"I would like to invite us to consider what would happen if the passive voice did not exist.

To summary StoneyB's answer, the passive voice allows us to not have to mention the Agent (the person who performed the action). This is useful when the Agent is less important, unknown, or someone or something you don't want to mention.

What if we don't have the passive voice?

Consider this text from a Wikipedia page, Merchant of Venice:


  Though classified as a comedy in the First Folio and sharing certain aspects with Shakespeare's other romantic comedies, the play is perhaps most remembered for its dramatic scenes, and is best known for Shylock and the famous ""Hath not a Jew eyes?"" speech.


Who classified it (the play)? Who remembers it? Who knows it?

It's unclear who did and does (or do) so. The passive voice allows this. Without the passive voice, we would be forced to state the subjects of those clauses explicitly. (And, who forced us so?) The most practical way to rephrase that sentence in active voice is to assume either ""we"" or ""people"" as the subject. Let's see what happened if I rewrite the sentence in active voice,


  Though people classify the play as a comedy in the First Folio and the play shares certain aspects with Shakespeare's other romantic comedies, people perhaps remember the play most for its dramatic scenes, and know it best for Shylock and the famous ""Hath not a Jew eyes?"" speech.


And that is quite awkward.

Let's consider another sentence.
(the credit goes to Cerberus, who give me this great example sentence in our ELL chat room)


  When the dam collapsed, the water was released into the valley.


Who released the water?
The incident? The dam itself? The officers who are responsible for the dam?

And because I don't know who released it, I think we are lucky to have the passive voice around.
"
2114,2114,3367,Using VBA to change Picture,"I am trying to use VBA to automate the Change Picture function when you right click a Shape in Excel/Word/Powerpoint.

However, I am not able to find any reference, can you assist?
",PlayKid,https://stackoverflow.com/users/52590,"What I've done in the past is create several image controls on the form and lay them on top of each other. Then you programmatically set all images .visible = false except the one you want to show.  
",user4024676,https://stackoverflow.com/users/4024676,http://stackoverflow.com/questions/10169011/using-vba-to-change-picture,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.6666666666666666,0.0,1.0,0.3333333333333333,1.0,0.6666666666666666,0.4444444444444444,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,0.8888888888888888,Change pictures with VBA,"When you right-click a shape in Excel / word / Powerpoint, I'm trying to use VBA to automatically change pictures.","What I've done in the past is create several image controls on the form and lay them on top of each other. Then you programmatically set all images .visible = false except the one you want to show.  
"
5992,5992,9499,JavaScript: Call base function from prototyped inheritance,"var super_class = function(p) {
    this.p = p + 1;
    this.method = function(a, b) {
        // some code
    };
};

var base_class = function(o) {
    this.o = o;
    super_class.call(this, o);
    this.method = function(a, b) {
        // call super_class .method();
        // some code
    }
}

base_class.prototype = new super_class();

var bc = new base_class(0);
var v1 = bc.o; // 0
var v2 = bc.p; // 1


How can I call the super_class method when the name and properties are supposed to be identical. If I changed the name, I would just call this.method(3, 4); from within another function. I'm creating an extension class to another extension class, so changing the name of the function will not help me.

Also, storing the function in a private variable var pmethod = this.method; is sloppy at best.
",Brian Graham,https://stackoverflow.com/users/711416,"var super_class = function(p) {
    this.p = p + 1;
    this.method = function(a, b) {
        // some code
    };
};

var base_class = function(o) {
    this.o = o;
    super_class(o); // remove ""this""
    this.method = function(a, b) {
         // call base.method();
         // some code
    }
}

base_class.prototype = new super_class();

base_class.prototype.constructor = base_class;  //important: pointing the constructor back to the base class.


This is what the basic inheritance is done in JavaScript. If you want to get something fancy , use 

function object(o) {
    function F() {}
    F.prototype = o;
    return new F();
}


See http://javascript.crockford.com/prototypal.html for more information. 
",Grace Shao,https://stackoverflow.com/users/541137,http://stackoverflow.com/questions/8994580/javascript-call-base-function-from-prototyped-inheritance,STACKOVERFLOW,stackoverflow.com,0.6666666666666666,0.3333333333333333,0.0,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.7777777777777778,0.8333333333333334,0.5,1.0,1.0,0.7,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.7777777777777778,Javascript: call base function from prototype inheritance,"var super_class = function(p) {
    this.p = p + 1;
    this.method = function(a, b) {
        // some code
    };
};

var base_class = function(o) {
    this.o = o;
    super_class.call(this, o);
    this.method = function(a, b) {
        // call super_class .method();
        // some code
    }
}

base_class.prototype = new super_class();

var bc = new base_class(0);
var v1 = bc.o; // 0
var v2 = bc.p; // 1


How can I call the super_class method when the name and properties are supposed to be identical. If I changed the name, I would just call this.method(3, 4); from within another function. I'm creating an extension class to another extension class, so changing the name of the function will not help me.

Also, storing the function in a private variable var pmethod = this.method; is sloppy at best.
","var super_class = function(p) {
    this.p = p + 1;
    this.method = function(a, b) {
        // some code
    };
};

var base_class = function(o) {
    this.o = o;
    super_class(o); // remove ""this""
    this.method = function(a, b) {
         // call base.method();
         // some code
    }
}

base_class.prototype = new super_class();

base_class.prototype.constructor = base_class;  //important: pointing the constructor back to the base class.


This is what the basic inheritance is done in JavaScript. If you want to get something fancy , use 

function object(o) {
    function F() {}
    F.prototype = o;
    return new F();
}


See http://javascript.crockford.com/prototypal.html for more information. 
"
3687,3687,5876,"Looking for a word with a more positive connotation than ""infectious""","I recently was attempting to describe someone's smile. I wanted to describe it as being very 'infectious', or that it spreads very quickly and is contagious. However, as hard as I could try, I could only come up with words that have to do with infections or words that have a negative connotation. 

How could I describe a person's smile if it has the ability to 'spread' to other people, as denoted above?

Thanks!
",Conner,https://english.stackexchange.com/users/82110,"""Contagious smile"" and ""infectious smiles"" are very strong collocations which have a positive connotation. I don't think we really have much choice but to use these expressions when describing an amazing smile that makes others smile, too.
",Louel,https://english.stackexchange.com/users/64451,http://english.stackexchange.com/questions/236329/looking-for-a-word-with-a-more-positive-connotation-than-infectious,CULTURE,english.stackexchange.com,1.0,1.0,0.0,1.0,1.0,0.3333333333333333,0.6666666666666666,1.0,0.6666666666666666,0.0,0.6666666666666666,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.7777777777777778,0.8888888888888888,1.0,1.0,0.7333333333333333,0.0,0.0,0.0,1.0,"Find a more positive word than ""infectious""","I recently tried to describe someone's smile. I want to describe it as very ""infectious,"" or that it spreads very quickly and is infectious. However, to the best of my ability, I can only come up with some words related to infection, or words with negative meanings.","""Contagious smile"" and ""infectious smiles"" are very strong collocations which have a positive connotation. I don't think we really have much choice but to use these expressions when describing an amazing smile that makes others smile, too.
"
406,406,632,Spokes keep breaking - bad hub or bad build?,"Background information

A bit of background information (I'll try keep it brief): Last year I bought an old but unused bike, 5 speeds with internal gearing.

Apparently the shop bought a lot of bikes somewhere in the 90's (not sure), but never got around to selling them. When I bought it, it was wrapped in plastic, had been stored in the shop's stock house for about 20 years and free of corrosion.

I'm about 95 kilos, thread quite hard but rides exclusive to paved bike paths. The original, 20(?) year-old wheel lasted me a year with no problems. The front wheel is still fine and true. 

Spokes breaking - and getting replaced

After a little under a year, I suddenly noticed that a few spokes had broken. On closer inspection, quite a few were too loose. Should have noticed sooner but didn't.

I took it to a shop, where they advised me to have the wheel rebuilt which I paid them to do. The gearing being internal, the new rims and spokes were built on the existing hub.

After just two weeks, the back wheel suddenly began to feel wobbly on my way to work. As careful as I could, I drove the bike back to the shop. Almost all spokes were terribly loose.

They retensioned the wheel free of charge (of course) and sent me on my way. The following weeks, I periodically checked that all spokes were still tensioned.

2,5 months later, I noticed three of the spokes were broken close to the hub. Went back to the shop and had the spokes replaced (free or charge). 1 month later I noticed 2 broken spokes and had those replaced as well. They seemed less eager to keep fixing the wheel free of charge, and when I asked why the spokes kept breaking, the guy muttered something about the hub holes maybe had burrs due to wear.

Now, a few weeks later, I find another spoke broken.

My gut tells me this all stems from a bad build, that quickly lost tension and thus damaged the spokes. I find the explanation about a worn hub a bit far fetched, but I don't have the knowledge to dismiss the theory.

Questions

Is there any way this is not the shop's fault? - A bad build? Cheap spokes? Improperly tensioned?

Given the wheel's history, is there any point in keep replacing spokes, a couple at a time, or should I get the wheel rebuilt (preferably at the shop's expense)?

Could the hub in any way be to blame for this?

Thank you!

Update Oct 24th

I've been trying to get in touch with the manager of the shop throughout the week. Failed again to reach him this morning, so I figured I'd have a chat about my problem with one of the guys on the floor.

Tried to get him to provide at least a theory of why my spokes keep breaking, but not much came out of it really. He mentioned that he've seen, on rare occasaions, that a worn hub could cut the spokes (could be the same guy as I spoke to last time).

I'll check the hubs as soon as possible, as @Daniel R Hicks suggested. Due to plumbing work in our appartment, I haven't been home or able to check my bike all week.

If I don't see any indicatations that the spokes were put in the wrong way, I'm going to follow the advice most of you have, and take my bike to another shop for advice and repair.

Thanks so far! - I'll update you after I've payed the other shop a visit.

Update Nov 3rd

Took the bike to the other shop, told them the story. Let them decide to replace the broken spoke or them all.

They decided to replace just the broken spoke with a DT spoke (what ever that means). They also trued the wheel, which had gotten a slight ""eggy"" shape.

My fingers are crossed that this wheel will last now.

Once again, thank you all for your input!

Anecdotal Update

In case anyone follows... Since the last repair at the other shop, the wheel kept being in good shape. Finally, my spokes stayed tensioned, wheels stiff and true - the long struggle was finally over. Alas, the joy didn't even last a month...

Going home from a company party, I returned to my bike I parked at the train station, only to find out that some punk kids had apparently tossed it to the ground, and jumped both wheels badly out of shape. Front wheel had to be replaced and back wheel was in desperate need for a trueing. sigh

Sorry for the melodrama, just thought I'd update you the faith of my bike ;-).
",abstrask,https://bicycles.stackexchange.com/users/3123,"""Burrs on the hub"" sounds bogus to me.  Could be the case with a new hub, but burrs would be worn away with use.

It seems most likely that the hub was reassembled by ""unskilled labor"" (the new/careless guy in the shop) and he didn't notice that the hub holes are directional -- there is a countersink on one side of the hole and not the other -- or didn't understand how you put spokes in such a hub.

When the holes are directional, you put the head of the spoke on the non-countersunk side, so that the curve of the spoke mates with the smooth countersink.  Placing spokes the opposite way will result in the curve of the spoke being against the sharp corner of the hole (and a broken spoke).

To check this, look at any hole where a spoke is broken.  If the two sides the hole are different, the side with the smooth rounded countersunk shape should be matched with the bend in the spoke, and the head should be on the other side.

Another possibility is that machine spokes were used.  These spokes have a longer distance between the head and the bend, to simplify things for lacing machines.  But these are bad for hand lacing, as there is too much ""lever arm"" unsupported by the spoke hole, and the heads will tend to pop off.  If such spokes are used one must use small spacer washers on the head side to pull the bend tightly to the curve of the spoke hole.

Or, of course, they could be lousy spokes.

(If they were breaking at the rim end this would be due to the way the rim is drilled and possible missassembly placing left-facing drilled holes with a right-facing spoke, or simply spokes that aren't strong enough to stand up to the stress of being slightly bent at the nipple.)
",Daniel R Hicks,https://bicycles.stackexchange.com/users/1584,http://bicycles.stackexchange.com/questions/12756/spokes-keep-breaking-bad-hub-or-bad-build,CULTURE,bicycles.stackexchange.com,0.7777777777777778,0.5555555555555556,0.0,1.0,1.0,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,1.0,1.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,1.0,Broken spokes - broken hub or broken construction?,"Background information

A bit of background information (I'll try keep it brief): Last year I bought an old but unused bike, 5 speeds with internal gearing.

Apparently the shop bought a lot of bikes somewhere in the 90's (not sure), but never got around to selling them. When I bought it, it was wrapped in plastic, had been stored in the shop's stock house for about 20 years and free of corrosion.

I'm about 95 kilos, thread quite hard but rides exclusive to paved bike paths. The original, 20(?) year-old wheel lasted me a year with no problems. The front wheel is still fine and true. 

Spokes breaking - and getting replaced

After a little under a year, I suddenly noticed that a few spokes had broken. On closer inspection, quite a few were too loose. Should have noticed sooner but didn't.

I took it to a shop, where they advised me to have the wheel rebuilt which I paid them to do. The gearing being internal, the new rims and spokes were built on the existing hub.

After just two weeks, the back wheel suddenly began to feel wobbly on my way to work. As careful as I could, I drove the bike back to the shop. Almost all spokes were terribly loose.

They retensioned the wheel free of charge (of course) and sent me on my way. The following weeks, I periodically checked that all spokes were still tensioned.

2,5 months later, I noticed three of the spokes were broken close to the hub. Went back to the shop and had the spokes replaced (free or charge). 1 month later I noticed 2 broken spokes and had those replaced as well. They seemed less eager to keep fixing the wheel free of charge, and when I asked why the spokes kept breaking, the guy muttered something about the hub holes maybe had burrs due to wear.

Now, a few weeks later, I find another spoke broken.

My gut tells me this all stems from a bad build, that quickly lost tension and thus damaged the spokes. I find the explanation about a worn hub a bit far fetched, but I don't have the knowledge to dismiss the theory.

Questions

Is there any way this is not the shop's fault? - A bad build? Cheap spokes? Improperly tensioned?

Given the wheel's history, is there any point in keep replacing spokes, a couple at a time, or should I get the wheel rebuilt (preferably at the shop's expense)?

Could the hub in any way be to blame for this?

Thank you!

Update Oct 24th

I've been trying to get in touch with the manager of the shop throughout the week. Failed again to reach him this morning, so I figured I'd have a chat about my problem with one of the guys on the floor.

Tried to get him to provide at least a theory of why my spokes keep breaking, but not much came out of it really. He mentioned that he've seen, on rare occasaions, that a worn hub could cut the spokes (could be the same guy as I spoke to last time).

I'll check the hubs as soon as possible, as @Daniel R Hicks suggested. Due to plumbing work in our appartment, I haven't been home or able to check my bike all week.

If I don't see any indicatations that the spokes were put in the wrong way, I'm going to follow the advice most of you have, and take my bike to another shop for advice and repair.

Thanks so far! - I'll update you after I've payed the other shop a visit.

Update Nov 3rd

Took the bike to the other shop, told them the story. Let them decide to replace the broken spoke or them all.

They decided to replace just the broken spoke with a DT spoke (what ever that means). They also trued the wheel, which had gotten a slight ""eggy"" shape.

My fingers are crossed that this wheel will last now.

Once again, thank you all for your input!

Anecdotal Update

In case anyone follows... Since the last repair at the other shop, the wheel kept being in good shape. Finally, my spokes stayed tensioned, wheels stiff and true - the long struggle was finally over. Alas, the joy didn't even last a month...

Going home from a company party, I returned to my bike I parked at the train station, only to find out that some punk kids had apparently tossed it to the ground, and jumped both wheels badly out of shape. Front wheel had to be replaced and back wheel was in desperate need for a trueing. sigh

Sorry for the melodrama, just thought I'd update you the faith of my bike ;-).
","""Burrs on the hub"" sounds bogus to me.  Could be the case with a new hub, but burrs would be worn away with use.

It seems most likely that the hub was reassembled by ""unskilled labor"" (the new/careless guy in the shop) and he didn't notice that the hub holes are directional -- there is a countersink on one side of the hole and not the other -- or didn't understand how you put spokes in such a hub.

When the holes are directional, you put the head of the spoke on the non-countersunk side, so that the curve of the spoke mates with the smooth countersink.  Placing spokes the opposite way will result in the curve of the spoke being against the sharp corner of the hole (and a broken spoke).

To check this, look at any hole where a spoke is broken.  If the two sides the hole are different, the side with the smooth rounded countersunk shape should be matched with the bend in the spoke, and the head should be on the other side.

Another possibility is that machine spokes were used.  These spokes have a longer distance between the head and the bend, to simplify things for lacing machines.  But these are bad for hand lacing, as there is too much ""lever arm"" unsupported by the spoke hole, and the heads will tend to pop off.  If such spokes are used one must use small spacer washers on the head side to pull the bend tightly to the curve of the spoke hole.

Or, of course, they could be lousy spokes.

(If they were breaking at the rim end this would be due to the way the rim is drilled and possible missassembly placing left-facing drilled holes with a right-facing spoke, or simply spokes that aren't strong enough to stand up to the stress of being slightly bent at the nipple.)
"
827,827,1316,Front end submit form with jquery form plugin,"Maybe someone can help me with a small problem I'm having. I'm trying to use this: http://jquery.malsup.com/form/ to create a submit form for Wordpress. I've tested it on a regular site(not WP) and it works. I can't figure out why it won't work in wp.

This is my form. I've created two page templates, one has the form, the other has the wp_insert_post code. If I change the form action to action=""http://mysite.com/page.php"" it works, if I point it to a page template it doesn't. I need it to point to a page template for the wp_insert_post code to work. 

This is on one first page:

&lt;form id=""myForm"" action=""http://mysite.com/submitest"" method=""post""&gt; 
Name: &lt;input type=""text"" name=""name"" /&gt; 
Comment: &lt;textarea name=""comment""&gt;&lt;/textarea&gt; 
&lt;input type=""submit"" value=""Submit Comment"" /&gt; 




Thanks
",Ciprian,https://wordpress.stackexchange.com/users/9869,"Leave the action value as blank. Give the submit button a name as name='form_sub'. Then add the following code to your functions.php file. Check the codex for init hook. 
You can create a 'Thank You' page, or a confirmation page where the user should go after successful submission.

&lt;?php
add_action('init', 'form_submit');

function form_submit(){
    if(isset($_POST['form_sub']))
    {
        //here you'll have your form data in a $_POST array, you can check it using a print_r. parse the form and insert the post
        $title = $_POST['name'];
        $content = $_POST['comment'];

        //change the category and author as you want
        $post_obj = array(
                        'post_title' =&gt; $title,
                        'post_content' =&gt; $content,
                        'post_category' =&gt; array(1), //Uncategorized
                        'post_status' =&gt; 'draft',
                        'post_author' =&gt; 1 //Admin
                       );
        $id = wp_insert_post($post_obj);

        //check if successfully submitted
        if(isset($id) &amp;&amp; !is_wp_error($id))
        {
            //redirect to a thank you page, make sure the slug is 'thank-you'
            wp_redirect(home_url('/thank-you'));
            exit;
        } 
    }
}
?&gt;


Try this. Let me know if you are stuck.

Edit:
This is how the form template should be. The submit button should have the name attribute, not the form.

&lt;?php /* Template Name: Submit */ ?&gt; 
&lt;?php get_header(); ?&gt; 
Form this: 
&lt;form action="""" method=""post""&gt; 
    Name: &lt;input type=""text"" name=""name"" /&gt; 
    Comment: &lt;textarea name=""comment""&gt;&lt;/textarea&gt;
    &lt;input type=""submit"" value=""Submit"" name=""form_sub"" /&gt;
&lt;/form&gt;
&lt;?php get_footer(); ?&gt;

",Rutwick Gangurde,https://wordpress.stackexchange.com/users/4740,http://wordpress.stackexchange.com/questions/33896/front-end-submit-form-with-jquery-form-plugin,TECHNOLOGY,wordpress.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,0.5,1.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.6666666666666666,0.3333333333333333,0.8888888888888888,Front end submit form with jQuery form plug-in,"Maybe someone can help me with a small problem I'm having. I'm trying to use this: http://jquery.malsup.com/form/ to create a submit form for Wordpress. I've tested it on a regular site(not WP) and it works. I can't figure out why it won't work in wp.

This is my form. I've created two page templates, one has the form, the other has the wp_insert_post code. If I change the form action to action=""http://mysite.com/page.php"" it works, if I point it to a page template it doesn't. I need it to point to a page template for the wp_insert_post code to work. 

This is on one first page:

&lt;form id=""myForm"" action=""http://mysite.com/submitest"" method=""post""&gt; 
Name: &lt;input type=""text"" name=""name"" /&gt; 
Comment: &lt;textarea name=""comment""&gt;&lt;/textarea&gt; 
&lt;input type=""submit"" value=""Submit Comment"" /&gt; 




Thanks
","Leave the action value as blank. Give the submit button a name as name='form_sub'. Then add the following code to your functions.php file. Check the codex for init hook. 
You can create a 'Thank You' page, or a confirmation page where the user should go after successful submission.

&lt;?php
add_action('init', 'form_submit');

function form_submit(){
    if(isset($_POST['form_sub']))
    {
        //here you'll have your form data in a $_POST array, you can check it using a print_r. parse the form and insert the post
        $title = $_POST['name'];
        $content = $_POST['comment'];

        //change the category and author as you want
        $post_obj = array(
                        'post_title' =&gt; $title,
                        'post_content' =&gt; $content,
                        'post_category' =&gt; array(1), //Uncategorized
                        'post_status' =&gt; 'draft',
                        'post_author' =&gt; 1 //Admin
                       );
        $id = wp_insert_post($post_obj);

        //check if successfully submitted
        if(isset($id) &amp;&amp; !is_wp_error($id))
        {
            //redirect to a thank you page, make sure the slug is 'thank-you'
            wp_redirect(home_url('/thank-you'));
            exit;
        } 
    }
}
?&gt;


Try this. Let me know if you are stuck.

Edit:
This is how the form template should be. The submit button should have the name attribute, not the form.

&lt;?php /* Template Name: Submit */ ?&gt; 
&lt;?php get_header(); ?&gt; 
Form this: 
&lt;form action="""" method=""post""&gt; 
    Name: &lt;input type=""text"" name=""name"" /&gt; 
    Comment: &lt;textarea name=""comment""&gt;&lt;/textarea&gt;
    &lt;input type=""submit"" value=""Submit"" name=""form_sub"" /&gt;
&lt;/form&gt;
&lt;?php get_footer(); ?&gt;

"
1941,1941,3095,CAML query with Five Condtion throws an Microsoft.Sharepoint.SPException,"         string query = &lt;Where&gt; 
                           &lt;And&gt;    
                              &lt;And&gt;       
                                 &lt;And&gt;          
                                      &lt;Eq&gt;&lt;/Eq&gt;
                                      &lt;Eq&gt;&lt;/Eq&gt;
                                 &lt;/And&gt;
                                   &lt;Geq&gt;&lt;/Geq&gt;
                                   &lt;Leq&gt;&lt;/Leq&gt;
                              &lt;/And&gt;       
                                &lt;Eq&gt;&lt;/Eq&gt;
                           &lt;/And&gt;
                        &lt;/Where&gt;


In SharePoint foundation development, i have used this CAML query to query a SharePoint list. This query contains five conditions. After above query gets executed, it throws an Microsoft.Sharepoint.SPException exception. I tried but couldn't figure it out. Is there any mistake in above CAML query. Any help is appreciated.
",Nera,https://sharepoint.stackexchange.com/users/18118,"You have 3 child elements under the second And element: And, Geq and Leq. 
It is not supported. Wrap Geq and Leq elements with an additional And parent element and it will work. 

Or, as suggested in other answers, use CAML query builder to generate your queries.
",Tim,https://sharepoint.stackexchange.com/users/10671,http://sharepoint.stackexchange.com/questions/80642/caml-query-with-five-condtion-throws-an-microsoft-sharepoint-spexception,TECHNOLOGY,sharepoint.stackexchange.com,0.5,0.3333333333333333,0.0,0.5,1.0,0.5,0.5,0.3333333333333333,0.5,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.5,0.0,0.5,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.8333333333333334,0.6,0.5,0.5,0.5,0.6666666666666666,A CAML query with five conditions throws a microsoft.sharepoint.spexception,"         string query = &lt;Where&gt; 
                           &lt;And&gt;    
                              &lt;And&gt;       
                                 &lt;And&gt;          
                                      &lt;Eq&gt;&lt;/Eq&gt;
                                      &lt;Eq&gt;&lt;/Eq&gt;
                                 &lt;/And&gt;
                                   &lt;Geq&gt;&lt;/Geq&gt;
                                   &lt;Leq&gt;&lt;/Leq&gt;
                              &lt;/And&gt;       
                                &lt;Eq&gt;&lt;/Eq&gt;
                           &lt;/And&gt;
                        &lt;/Where&gt;


In SharePoint foundation development, i have used this CAML query to query a SharePoint list. This query contains five conditions. After above query gets executed, it throws an Microsoft.Sharepoint.SPException exception. I tried but couldn't figure it out. Is there any mistake in above CAML query. Any help is appreciated.
","You have 3 child elements under the second And element: And, Geq and Leq. 
It is not supported. Wrap Geq and Leq elements with an additional And parent element and it will work. 

Or, as suggested in other answers, use CAML query builder to generate your queries.
"
5713,5713,9053,Is there a comprehensive life science techniques/methods database?,"There are so many techniques/methodologies in the life sciences that we can use to interrogate interesting questions. The thing is, most of us are completely unaware of the available methods we can employ. Rather, we go with the techniques we are familiar with or that are popular in our subdomains at the time. But that's pretty limiting.

So I'm wondering... we have databases for everything else... is there one for life sciences techniques/methods? Something like this could be immensely helpful in experimental planning. In particular, I think a comprehensive database would help scientists break outside of their spheres of familiarity and to employ less known (but potentially illuminating) methods to their questions.

I know there are journals that publish protocols and methods, but they are fragmented and don't encompass everything. 

Does what I'm looking for exist? If not, how might one go about creating such a tool? 
",Alex,https://biology.stackexchange.com/users/1909,"My personal favourite is OpenWetWare. Think wikipedia for scientific protocols and an open access lab notebook.

There's a problem with this things. Despite the common stereotype of scientist being open and good at sharing, my experience is the opposite. Many laboratories are not good at all in sharing their techniques/secrets. They will share the basic stuff that you can find online, no problem, but that's about it.

Seems they're afraid that everyone's else after them, trying to scoop them. I have suggested OpenWetWare to some other labs and they refused for that same reason. Even though some will use it to find protocols, they don't see a reason to share back.
",carandraug,https://biology.stackexchange.com/users/1303,http://biology.stackexchange.com/questions/7208/is-there-a-comprehensive-life-science-techniques-methods-database,SCIENCE,biology.stackexchange.com,0.8888888888888888,0.4444444444444444,0.0,0.0,1.0,0.3333333333333333,0.8888888888888888,0.8888888888888888,0.6666666666666666,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.6666666666666666,0.0,0.3333333333333333,1.0,Is there a comprehensive database of life science technology / methods?,"There are so many techniques/methodologies in the life sciences that we can use to interrogate interesting questions. The thing is, most of us are completely unaware of the available methods we can employ. Rather, we go with the techniques we are familiar with or that are popular in our subdomains at the time. But that's pretty limiting.

So I'm wondering... we have databases for everything else... is there one for life sciences techniques/methods? Something like this could be immensely helpful in experimental planning. In particular, I think a comprehensive database would help scientists break outside of their spheres of familiarity and to employ less known (but potentially illuminating) methods to their questions.

I know there are journals that publish protocols and methods, but they are fragmented and don't encompass everything. 

Does what I'm looking for exist? If not, how might one go about creating such a tool? 
","My personal favourite is OpenWetWare. Think wikipedia for scientific protocols and an open access lab notebook.

There's a problem with this things. Despite the common stereotype of scientist being open and good at sharing, my experience is the opposite. Many laboratories are not good at all in sharing their techniques/secrets. They will share the basic stuff that you can find online, no problem, but that's about it.

Seems they're afraid that everyone's else after them, trying to scoop them. I have suggested OpenWetWare to some other labs and they refused for that same reason. Even though some will use it to find protocols, they don't see a reason to share back.
"
1911,1911,3043,Computing best subset of predictors for linear regression,"For the selection of predictors in multivariate linear regression with $p$ suitable predictors, what methods are available to find an 'optimal' subset of the predictors without explicitly testing all $2^p$ subsets? In 'Applied Survival Analysis,' Hosmer &amp; Lemeshow make reference to Kuk's method, but I cannot find the original paper. Can anyone describe this method, or, even better, a more modern technique? One may assume normally distributed errors.
",shabbychef,https://stats.stackexchange.com/users/795,"What I learned it that firstly use Best Subsets Approach as a screening tool, then the stepwise selection procedures can help you finally decide which models might be best subset models (at this time the number of those models is pretty small to handle). If one of the models meets the model conditions, does a good job of summarizing the trend in the data, and most importantly allows you to answer your research question, then congrats your job is done.
",Rosie Luo,https://stats.stackexchange.com/users/52567,http://stats.stackexchange.com/questions/2111/computing-best-subset-of-predictors-for-linear-regression,SCIENCE,stats.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.5555555555555556,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.7777777777777778,0.6666666666666666,0.6666666666666666,0.6666666666666666,1.0,0.8,0.6666666666666666,0.6666666666666666,0.0,1.0,The best subset calculation of linear regression prediction factors,"For selecting predictors with $p $appropriate predictors in multiple linear regression, which methods can find the ""optimal"" subset of predictors without explicitly testing all $2 ^ p $subsets? In applied survival analysis, horsmer and lemeshow mentioned cook's method, but I couldn't find the original. Can anyone describe this method, or, better yet, a more modern technology? We can assume the error of normal distribution.","What I learned it that firstly use Best Subsets Approach as a screening tool, then the stepwise selection procedures can help you finally decide which models might be best subset models (at this time the number of those models is pretty small to handle). If one of the models meets the model conditions, does a good job of summarizing the trend in the data, and most importantly allows you to answer your research question, then congrats your job is done.
"
4347,4347,6922,Wireless link frequency choice (900Mhz vs 5.8Ghz) for 2-3km distance,"I have recently been contracted by a client of mine to facilitate the wireless communication of his ""home"" offices and a secondary site. 

The primary site is the top two floors of a 5-story office building (15m height more or less) an the secondary is one of two open ""lots"" (which one is TBD by management). The ground distance from the secondary sites is a little more than 2km for the one closer and around 2.9km for the one furthest. 

The link will be used to transmit the video feed of 1 (or even possibly two) IP cameras and some kind of Ethernet-enabled environmental or weather sensor. I have checked the necessary b/w for the cameras and both 900Mhz and 5.8Ghz are more than adequate for even 4 of them, much more for 2. I have also verified that there is clear line-of-sight to both possible installation points and that the 60% Fresnel Zone clearance is more than covered. Bear in mind that this is my first long distance link (long with or without quotes) and I hate to admit that wireless physics is far from my strong suit.

The ultimate point of my question is that although I have read a lot about frequency choice the last few days, I continue to find some ambiguity (I know it is just me that finds it ambiguous). Most sources, like this one, agree that although the lower frequencies have less losses over a given distance (free-space-loss I learned it is called) they need larger antennae for the same ""strength"" of trasmission (is ""gain"" really the same as ""strength""?). 

So, for the given distance of 2-3km and given also that all typical requirements are met, which is preferable (or do I dare say ""better"") frequency? Should I choose 900Mhz with a relatively ""small"" antenna on the basis that 3km is not really ""long distance"" and that it will provide a link with less attenuation ergo less retransmits ergo higher overall speed? Or should I choose the 5.8Ghz option for the superior b/w (I am still not very sure about this, please correct me if wrong) on the basis that at this distance there is no real difference so why not take the ""better"" one?

On a side note, should I stay to the beaten path of true WiFi or should I consider proprietary bridging solutions like the ones from Ubiquiti? I have a lot of experience with their Access Points and am really satisfied, so I would not mind integrating one more of their products in my client. In any case, I am looking for an optimal solution, choice of vendor is of very little concern at this point.

Forgive my ignorance and the possible mistaken use of language. 

UPDATE:
I arranged to have a spectrum analyzer on loan for a couple of days. I will make sure that the 900Mhz band is reasonably clear and proceed down that way.

UPDATE 2:
I had the aforementioned equipment available to play with for a day and a half. The conclusive finding is that the 9Mhz band is almost ""empty"" in the area, as one suggested here, so that takes care for the frequency choice issue. 

Concerning the equipment now, I am going with Ubiquiti AirMax Yagi antennae and matching RM900 2x2 radios. Preliminary testing on my part and from the client's employees shows that performance exceeds expectations. 

On a side note, the chosen ""lot"" is the one that is 3km away. 
",dsljanus,https://serverfault.com/users/181235,"Chris S's answer is incorrect in several areas.

3km is not approaching the limit of 5.8GHz.  Similarly, that's not as big of a distance as for 2.4GHz wifi either.  Chris says 10X, I say 100X the distance is possible.  The longest range 5.8GHz wifi that I've heard of is 304KM with a 1.2M hand made antenna (See: Long Range Wifi).  I believe it went over water so there were not any thing in the way of the signal.  It used Ubiquity radios.  I don't know if it was reliable, but to get a connection and send data over that distance is nothing short of amazing.  

I used to work for a wisp carrier and had wifi radios about twice the size of your hand easily going 10KM with good line of site.  I personally had wifi on my house going 8KM without any issues.  Amazingly, they were only 500mW.  

We were using 5GHz radios and a mixture of Ubiquity and Microtik hardware.  They work almost flawlessly.

While it is true that with lower frequencies you need bigger antennas.  You'll notice that your home wifi doesn't have large antennas.  Neither do 5GHz ones.

In reality, 2.4GHz should perform better, but 5GHz in my experience works just as well.
In theory, 5GHz could be affected by rain fade, but I didn't find that even over the 8KM link.

As for 2.4GHz and other devices like microwaves and cordless phones inside the office, it doesn't even factor in.  The reason it doesn't factor in is that you'll be using directional antennas.  Better still, if the antenna is on an iron roof you will be shielded from all that noise coming from inside the office/house. 

Having said all of that, I will say that it's not perfect for every situation.
You need:


Line of site between the two buildings. Factoring in the freznel zone (good open clearance)  
A suitable place to mount the antenna to achieve point 1.
Hopefully not much wifi traffic facing your directional antennas (no gaurantees there, but it should be workable) even in a reasonably crowded wifi space.


Freznel zone looks like this:

By the way, I've had trees in the way of the freznel zone and in some cases right in the middle and it still worked, although it does affect the performance a lot.  Install your antennas as high as practical/possible.

You can still get interference issues.  Usually because of other devices transmitting in your direction at the same frequency.  So it's not perfect.  Directional antennas help a lot with that.

I can recommend the 5.8GHz radios simply because I know they work well. And yes, provide good bandwidth! From memory I used a Ubiquity Bullet M5 with a patch antenna (another brand).  The other end was a less directional antenna feeding multiple clients but used a similar Microtik radio.

I don't know of anyone who uses 900MHz.  But I do see you can buy them at around 3X the cost than 2.4 or 5.8.  Stick away from it, it seems uncommon.  In several countries the 900MHz spectrum is quite crowded anyway.



Update: You've been looking at the airmax antennas and the 900MHz radios.  While I think performance should be great.  I think you may be spending much more than you need to... perhaps a little overkill!?  3KM is not a long distance.  I'd try some of these if you can.

http://www.gowifi.co.nz/antennas/5-ghz/directional/5.8-ghz-27-dbi-cast-reflector-grid-antenna.html combined with a Bullet M5.



Update2: You can also mitigate interference issues using polarized antennas.  Here's a good write up that explains the concept.  From memory, we used horizontal polarization.  As I recall sometimes if I set the client radio to vertical polarization I could see maybe 12 AP's.  But when setting it to horizontal I only saw 3 or 4 and half of them were ours.  
",Matt,https://serverfault.com/users/14631,http://serverfault.com/questions/535403,TECHNOLOGY,serverfault.com,0.8888888888888888,0.3333333333333333,0.0,1.0,0.3333333333333333,1.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.3333333333333333,0.3333333333333333,0.6666666666666666,1.0,Radio link frequency selection for 2-3km distance (900MHz and 5.8GHz),"I have recently been contracted by a client of mine to facilitate the wireless communication of his ""home"" offices and a secondary site. 

The primary site is the top two floors of a 5-story office building (15m height more or less) an the secondary is one of two open ""lots"" (which one is TBD by management). The ground distance from the secondary sites is a little more than 2km for the one closer and around 2.9km for the one furthest. 

The link will be used to transmit the video feed of 1 (or even possibly two) IP cameras and some kind of Ethernet-enabled environmental or weather sensor. I have checked the necessary b/w for the cameras and both 900Mhz and 5.8Ghz are more than adequate for even 4 of them, much more for 2. I have also verified that there is clear line-of-sight to both possible installation points and that the 60% Fresnel Zone clearance is more than covered. Bear in mind that this is my first long distance link (long with or without quotes) and I hate to admit that wireless physics is far from my strong suit.

The ultimate point of my question is that although I have read a lot about frequency choice the last few days, I continue to find some ambiguity (I know it is just me that finds it ambiguous). Most sources, like this one, agree that although the lower frequencies have less losses over a given distance (free-space-loss I learned it is called) they need larger antennae for the same ""strength"" of trasmission (is ""gain"" really the same as ""strength""?). 

So, for the given distance of 2-3km and given also that all typical requirements are met, which is preferable (or do I dare say ""better"") frequency? Should I choose 900Mhz with a relatively ""small"" antenna on the basis that 3km is not really ""long distance"" and that it will provide a link with less attenuation ergo less retransmits ergo higher overall speed? Or should I choose the 5.8Ghz option for the superior b/w (I am still not very sure about this, please correct me if wrong) on the basis that at this distance there is no real difference so why not take the ""better"" one?

On a side note, should I stay to the beaten path of true WiFi or should I consider proprietary bridging solutions like the ones from Ubiquiti? I have a lot of experience with their Access Points and am really satisfied, so I would not mind integrating one more of their products in my client. In any case, I am looking for an optimal solution, choice of vendor is of very little concern at this point.

Forgive my ignorance and the possible mistaken use of language. 

UPDATE:
I arranged to have a spectrum analyzer on loan for a couple of days. I will make sure that the 900Mhz band is reasonably clear and proceed down that way.

UPDATE 2:
I had the aforementioned equipment available to play with for a day and a half. The conclusive finding is that the 9Mhz band is almost ""empty"" in the area, as one suggested here, so that takes care for the frequency choice issue. 

Concerning the equipment now, I am going with Ubiquiti AirMax Yagi antennae and matching RM900 2x2 radios. Preliminary testing on my part and from the client's employees shows that performance exceeds expectations. 

On a side note, the chosen ""lot"" is the one that is 3km away. 
","Chris S's answer is incorrect in several areas.

3km is not approaching the limit of 5.8GHz.  Similarly, that's not as big of a distance as for 2.4GHz wifi either.  Chris says 10X, I say 100X the distance is possible.  The longest range 5.8GHz wifi that I've heard of is 304KM with a 1.2M hand made antenna (See: Long Range Wifi).  I believe it went over water so there were not any thing in the way of the signal.  It used Ubiquity radios.  I don't know if it was reliable, but to get a connection and send data over that distance is nothing short of amazing.  

I used to work for a wisp carrier and had wifi radios about twice the size of your hand easily going 10KM with good line of site.  I personally had wifi on my house going 8KM without any issues.  Amazingly, they were only 500mW.  

We were using 5GHz radios and a mixture of Ubiquity and Microtik hardware.  They work almost flawlessly.

While it is true that with lower frequencies you need bigger antennas.  You'll notice that your home wifi doesn't have large antennas.  Neither do 5GHz ones.

In reality, 2.4GHz should perform better, but 5GHz in my experience works just as well.
In theory, 5GHz could be affected by rain fade, but I didn't find that even over the 8KM link.

As for 2.4GHz and other devices like microwaves and cordless phones inside the office, it doesn't even factor in.  The reason it doesn't factor in is that you'll be using directional antennas.  Better still, if the antenna is on an iron roof you will be shielded from all that noise coming from inside the office/house. 

Having said all of that, I will say that it's not perfect for every situation.
You need:


Line of site between the two buildings. Factoring in the freznel zone (good open clearance)  
A suitable place to mount the antenna to achieve point 1.
Hopefully not much wifi traffic facing your directional antennas (no gaurantees there, but it should be workable) even in a reasonably crowded wifi space.


Freznel zone looks like this:

By the way, I've had trees in the way of the freznel zone and in some cases right in the middle and it still worked, although it does affect the performance a lot.  Install your antennas as high as practical/possible.

You can still get interference issues.  Usually because of other devices transmitting in your direction at the same frequency.  So it's not perfect.  Directional antennas help a lot with that.

I can recommend the 5.8GHz radios simply because I know they work well. And yes, provide good bandwidth! From memory I used a Ubiquity Bullet M5 with a patch antenna (another brand).  The other end was a less directional antenna feeding multiple clients but used a similar Microtik radio.

I don't know of anyone who uses 900MHz.  But I do see you can buy them at around 3X the cost than 2.4 or 5.8.  Stick away from it, it seems uncommon.  In several countries the 900MHz spectrum is quite crowded anyway.



Update: You've been looking at the airmax antennas and the 900MHz radios.  While I think performance should be great.  I think you may be spending much more than you need to... perhaps a little overkill!?  3KM is not a long distance.  I'd try some of these if you can.

http://www.gowifi.co.nz/antennas/5-ghz/directional/5.8-ghz-27-dbi-cast-reflector-grid-antenna.html combined with a Bullet M5.



Update2: You can also mitigate interference issues using polarized antennas.  Here's a good write up that explains the concept.  From memory, we used horizontal polarization.  As I recall sometimes if I set the client radio to vertical polarization I could see maybe 12 AP's.  But when setting it to horizontal I only saw 3 or 4 and half of them were ours.  
"
2458,2458,3921,Triac circuit confusion,"X1Iz.png

I have the following questions about the above circuit:

-Why are we even using a trica/diac combo above. Why would a circuit consisting of just the fuse, switch and primary not be sufficient for charging the battery?

-If we do go ahead with the above combo, what is the use of the resistor/capacitor combo attached in parallel above the triac?

Thanks
giv
",givknow,https://electronics.stackexchange.com/users/62399,"As Gabe already indicated, the circuit shown is a standard chopper/dimmer circuit, as is also commonly used in lighting applications. The goal of the circuit is to control the current supplied to the battery, as indicated in the problem statement. To achieve this goal, it does not matter whether one controls the power into the transformer/rectifier combination, or one controls the amount of power going from the rectifier to the battery.

You asked in a comment why you need to reduce the power to the transformer. The easy answer is: Because the problem tells you that the power to the battery should be controlled. The complicated answer involves battery charging algorithms and explains why you would want to control power to the battery. I consider that answer out-of-scope.

You also asked in a comment, why you don't use a simple resistor. That's actually a good question, as a resistor could provide similar results. But the circuit shown is far more efficient. The circuit shown has the pass element, in this case the triac, either open (like an open switch, a very high resistance one can assume to be infinity) or closed (like a closed switch, which can be treated like a short circuit between the terminals as a very coarse approach).


While the triac is turned off, there is no loss (voltage multiplied by current) in the triac, as the current is zero.
While the triac is turned on, there is low loss in the triac, as the voltage is quite low (likely 1 to 2 volts). In the extremely simplified version of a short circuit for the triac after ignition, there would be no loss, as the voltage is zero.


If the output power should be reduced to the half of what you get if the triac circuit was not there, the triac would be on 50% of the time and off 50% of the time.

In a resistor-based solution to that problem, to reduce the current, one would need to permanently remove the excess voltage on the primary side (it would work on the secondary as well) by dropping it across the resistor. In this case, the resistor is the ""pass element"" and has a considerable voltage and current at the same time, so it causes losses. (I.e. the resistor gets hot, and you built yourself not just a battery charger, but also an electric heater).

Basically, what you see in that circuit is a very simple form of a switching or switch-mode power reduction circuit which is more efficient thant the typical linear power reduction methode obtained by using a resistor.

You furthermore ask in your question about the R/C-combination to the right. That combination is a snubber circuit. You need it because every real transformer (and even idealised transformers in most cases) have an inductance. The triac turns off each cycle shortly before the current through the transformer reaches zero. The inductance of the transformer tries to keep the current flowing, and would create the well-known inductive voltage spike if there was no way for the current to go. That's what the capacitor is for: it catches the excess current when the switch is off. The resistor is to waste the energy that comes from the transformer due to its inductance. If it were missing, you would get an LC tank circuit that oscillates (and might cause electo-magnetic interference).

Finally, you might wonder why one would perform power-control on the primary side of the transformer instead of the secondary side. There are two considerations:


The ""diac-triac""-dimmer only works on AC current, as it is about cutting AC line cycles, so you can't put this kind of circuit past the rectifier
The typical diac breakdown voltage is 33V, so to get good performance out of that circuit, you need an input voltage that exceeds 33V significantly. You don't have such high voltages on the secondary side in typical charger applications. Also, losses of the dimmer circuit are dominated by the triac pass voltage, which is not that much dependent on current. So a lower current causes lower losses. As the primary side (typically) operates at a higher voltage, you have less current and thus less losses on the primary side.

",Michael Karcher,https://electronics.stackexchange.com/users/63977,http://electronics.stackexchange.com/questions/158662/triac-circuit-confusion,TECHNOLOGY,electronics.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,0.3333333333333333,1.0,1.0,0.6666666666666666,0.4444444444444444,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,0.8888888888888888,Triac circuit confusion,"X1Iz.png

I have the following questions about the above circuit:

-Why are we even using a trica/diac combo above. Why would a circuit consisting of just the fuse, switch and primary not be sufficient for charging the battery?

-If we do go ahead with the above combo, what is the use of the resistor/capacitor combo attached in parallel above the triac?

Thanks
giv
","As Gabe already indicated, the circuit shown is a standard chopper/dimmer circuit, as is also commonly used in lighting applications. The goal of the circuit is to control the current supplied to the battery, as indicated in the problem statement. To achieve this goal, it does not matter whether one controls the power into the transformer/rectifier combination, or one controls the amount of power going from the rectifier to the battery.

You asked in a comment why you need to reduce the power to the transformer. The easy answer is: Because the problem tells you that the power to the battery should be controlled. The complicated answer involves battery charging algorithms and explains why you would want to control power to the battery. I consider that answer out-of-scope.

You also asked in a comment, why you don't use a simple resistor. That's actually a good question, as a resistor could provide similar results. But the circuit shown is far more efficient. The circuit shown has the pass element, in this case the triac, either open (like an open switch, a very high resistance one can assume to be infinity) or closed (like a closed switch, which can be treated like a short circuit between the terminals as a very coarse approach).


While the triac is turned off, there is no loss (voltage multiplied by current) in the triac, as the current is zero.
While the triac is turned on, there is low loss in the triac, as the voltage is quite low (likely 1 to 2 volts). In the extremely simplified version of a short circuit for the triac after ignition, there would be no loss, as the voltage is zero.


If the output power should be reduced to the half of what you get if the triac circuit was not there, the triac would be on 50% of the time and off 50% of the time.

In a resistor-based solution to that problem, to reduce the current, one would need to permanently remove the excess voltage on the primary side (it would work on the secondary as well) by dropping it across the resistor. In this case, the resistor is the ""pass element"" and has a considerable voltage and current at the same time, so it causes losses. (I.e. the resistor gets hot, and you built yourself not just a battery charger, but also an electric heater).

Basically, what you see in that circuit is a very simple form of a switching or switch-mode power reduction circuit which is more efficient thant the typical linear power reduction methode obtained by using a resistor.

You furthermore ask in your question about the R/C-combination to the right. That combination is a snubber circuit. You need it because every real transformer (and even idealised transformers in most cases) have an inductance. The triac turns off each cycle shortly before the current through the transformer reaches zero. The inductance of the transformer tries to keep the current flowing, and would create the well-known inductive voltage spike if there was no way for the current to go. That's what the capacitor is for: it catches the excess current when the switch is off. The resistor is to waste the energy that comes from the transformer due to its inductance. If it were missing, you would get an LC tank circuit that oscillates (and might cause electo-magnetic interference).

Finally, you might wonder why one would perform power-control on the primary side of the transformer instead of the secondary side. There are two considerations:


The ""diac-triac""-dimmer only works on AC current, as it is about cutting AC line cycles, so you can't put this kind of circuit past the rectifier
The typical diac breakdown voltage is 33V, so to get good performance out of that circuit, you need an input voltage that exceeds 33V significantly. You don't have such high voltages on the secondary side in typical charger applications. Also, losses of the dimmer circuit are dominated by the triac pass voltage, which is not that much dependent on current. So a lower current causes lower losses. As the primary side (typically) operates at a higher voltage, you have less current and thus less losses on the primary side.

"
2756,2756,4393,How does weight affect the game?,"I'm seeing weight of guns, armor, and even coins listed, but no rules seem to really make weight have any effect - other than on someone's speed.

For example: When you are drowning. I can tell you that swimming is pretty much easier when you are naked than when you are wearing heavy armor. However, the rules don't seem to care what armor do you use. Just simple DC 10/15/20 check.

So, in what situations does weight really matter? Or is it just fancy gimmicks?
",Realdeo,https://rpg.stackexchange.com/users/12117,"Basically, weight is used to calculate one thing. Whether or not your adventurer is overburdened with all the stuff he is carrying. 

How much you can carry is determined by the following formulas: 


  Normal Load: Multiply the creature’s Strength score by 10. The result is the weight, in pounds, that the creature can carry around without penalty.
  
  Heavy Load: Double the normal load number (that is, Strength × 20) to find a creature’s heavy load, the maximum weight it can lift off the ground. While a creature is carrying more than its normal load, it is slowed. Carrying such a load requires both hands.
  
  Maximum Drag Load: Five times a creature’s normal load (that is, Strength × 50) is the most weight it can push or drag along the ground. The creature is slowed if it pushes or drags more weight than its normal load, and it can’t push or drag more than its heavy load over difficult terrain.


So basically, if you have too much stuff (but not more than your heavy load), your adventurer is slowed. This is a big problem. For most adventurers this isn't much of an issue, fairly early on in your career you should be able to pick up a Bag of Holding, and not have to worry about load except for the gear your wearing or actively using. 

It's been pointed out in the comments that there are a couple of game mechanics that do use the weight of an item. Prestidigitation can lift up to a pound, Mage Hand can lift up to 20 (Psions and Wild Talent Masters have similar powers). So it comes into play occasionally on this stuff as well.
",wax eagle,https://rpg.stackexchange.com/users/1084,http://rpg.stackexchange.com/questions/39482/how-does-weight-affect-the-game,CULTURE,rpg.stackexchange.com,0.7777777777777778,0.4444444444444444,0.0,1.0,1.0,1.0,0.7777777777777778,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,0.8888888888888888,What's the effect of weight on the game?,"I'm seeing weight of guns, armor, and even coins listed, but no rules seem to really make weight have any effect - other than on someone's speed.

For example: When you are drowning. I can tell you that swimming is pretty much easier when you are naked than when you are wearing heavy armor. However, the rules don't seem to care what armor do you use. Just simple DC 10/15/20 check.

So, in what situations does weight really matter? Or is it just fancy gimmicks?
","Basically, weight is used to calculate one thing. Whether or not your adventurer is overburdened with all the stuff he is carrying. 

How much you can carry is determined by the following formulas: 


  Normal Load: Multiply the creature’s Strength score by 10. The result is the weight, in pounds, that the creature can carry around without penalty.
  
  Heavy Load: Double the normal load number (that is, Strength × 20) to find a creature’s heavy load, the maximum weight it can lift off the ground. While a creature is carrying more than its normal load, it is slowed. Carrying such a load requires both hands.
  
  Maximum Drag Load: Five times a creature’s normal load (that is, Strength × 50) is the most weight it can push or drag along the ground. The creature is slowed if it pushes or drags more weight than its normal load, and it can’t push or drag more than its heavy load over difficult terrain.


So basically, if you have too much stuff (but not more than your heavy load), your adventurer is slowed. This is a big problem. For most adventurers this isn't much of an issue, fairly early on in your career you should be able to pick up a Bag of Holding, and not have to worry about load except for the gear your wearing or actively using. 

It's been pointed out in the comments that there are a couple of game mechanics that do use the weight of an item. Prestidigitation can lift up to a pound, Mage Hand can lift up to 20 (Psions and Wild Talent Masters have similar powers). So it comes into play occasionally on this stuff as well.
"
4856,4856,7726,How can I get my main class returned?,"This main class is initialized by the Bukkit framework and cannot be initialized again.

public class Demo extends JavaPlugin {
    public void onEnable() {

    }
}


How do I access its unique instance from other classes?

public class CoolDown extends BukkitRunnable {
    public CoolDown(Demo mainClass, int time) {

    }
    public void run() {

    }
}

",Ender_Coder,https://stackoverflow.com/users/4602815,"If you want to use the OOP way:
In your CoolDown class, have a field with the type of Demo (or your JavaPlugin-extending class). You may also create any other fields you will pass in the constructor here. 

private Demo plugin;
private int time;


Then instantiate the fields using the CoolDown's constructor

public CoolDown(Demo plugin, int time) {
    this.plugin = plugin;
    this.time = time;
}


Now you can use the plugin field for your needs. Example:

public void run() {
    plugin.fooBar();
}


If you want to use the Static Programming way (not recommended, you are in a OOP language being Java!): In your Demo class, have a public, static field of type Demo, without any value (this is after the class decleration, by the way).

public static Demo instance;


In your plugin's enable method (I suggest to put this at the very first line of the method invokation):

instance = this;


Then you can use, in your CoolDown's run() method invokation:

Demo.instance.fooBar();


Once again, I do not suggest using static programming in Java. It's a lazy and bad practice in general.

Here is a full example, in your case, in OOP programming:

public class Demo extends JavaPlugin {
    public void onEnable() {
        Bukkit.getScheduler.scheduleMyEpicCooldown(new CoolDown(this, time), time);
    }
}


public class CoolDown extends BukkitRunnable {
    private Demo plugin;
    private int time;

    public CoolDown(Demo plugin, int time) {
        this.plugin = plugin;
        this.time = time;
    } 

    public void run() {
        plugin.fooBar();
    }
}

",Momo,https://stackoverflow.com/users/3902473,http://stackoverflow.com/questions/31880189/how-can-i-get-my-main-class-returned,STACKOVERFLOW,stackoverflow.com,0.6666666666666666,0.6666666666666666,0.0,0.5,1.0,1.0,0.5,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.5,0.0,0.8333333333333334,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.5,1.0,How can I return the main lesson?,"This main class is initialized by the Bukkit framework and cannot be initialized again.

public class Demo extends JavaPlugin {
    public void onEnable() {

    }
}


How do I access its unique instance from other classes?

public class CoolDown extends BukkitRunnable {
    public CoolDown(Demo mainClass, int time) {

    }
    public void run() {

    }
}

","If you want to use the OOP way:
In your CoolDown class, have a field with the type of Demo (or your JavaPlugin-extending class). You may also create any other fields you will pass in the constructor here. 

private Demo plugin;
private int time;


Then instantiate the fields using the CoolDown's constructor

public CoolDown(Demo plugin, int time) {
    this.plugin = plugin;
    this.time = time;
}


Now you can use the plugin field for your needs. Example:

public void run() {
    plugin.fooBar();
}


If you want to use the Static Programming way (not recommended, you are in a OOP language being Java!): In your Demo class, have a public, static field of type Demo, without any value (this is after the class decleration, by the way).

public static Demo instance;


In your plugin's enable method (I suggest to put this at the very first line of the method invokation):

instance = this;


Then you can use, in your CoolDown's run() method invokation:

Demo.instance.fooBar();


Once again, I do not suggest using static programming in Java. It's a lazy and bad practice in general.

Here is a full example, in your case, in OOP programming:

public class Demo extends JavaPlugin {
    public void onEnable() {
        Bukkit.getScheduler.scheduleMyEpicCooldown(new CoolDown(this, time), time);
    }
}


public class CoolDown extends BukkitRunnable {
    private Demo plugin;
    private int time;

    public CoolDown(Demo plugin, int time) {
        this.plugin = plugin;
        this.time = time;
    } 

    public void run() {
        plugin.fooBar();
    }
}

"
5322,5322,8454,Demonstrating the effect of aliasing,"How does the signal look when we don't use the Nyquist rate to remove aliasing from a signal during sampling?

Let's suppose the signal is sinusoidal, with a frequency of 500&nbsp;Hz and an amplitude of 2.

signal = 2*cos(2*pi*500*t)


If I sample it, (replacing t=nTs , Ts = sampling period and n represent number of samples) and plotting the sampled signals with a different sampling period using the subplot command in MATLAB, how could I identify the aliasing in a sampled signal?

Here is the example code that plotted two signals, one at the Nyquist rate while the other less than the Nyquist rate:

A = 2;
Fmax = 10;
Fs = 2*Fmax;
n = 0:1/Fs:1;
Cont = A*sin(2*pi*(Fmax/Fs)*n);
Cont1 = A*sin(2*pi*(Fmax/18)*n);
subplot(2,1,1)
stem(n,Cont)
hold on
stem(n,Cont1)


and here is the waveform:



I wasn't able to identify the aliasing. How did it affect the signal when Nyquist rate didn't use?
",Sufiyan Ghori,https://dsp.stackexchange.com/users/1324,"You have the right idea, but a key mistake was messing up your results.

n=0:1/Fs:1;


By making the time increments 1/Fs you are implicitly making the time units seconds.  In other words, ""0"" is 0 seconds, and ""1"" is 1 second.

Cont = A*sin(2*pi*(Fmax/Fs)*n);


By normalizing the sinusoid frequency by Fs you are implicitly assuming that the sample unit is 1/Fs seconds.  That is why you were getting lots of samples for a single sinusoid cycle when you intended to just have two samples per cycle (the Nyquist rate).  By the way, either sample unit is fine (1 second or 1/Fs second), you just need to be consistent.

Here is my attempt at what I think you intended.

A = 2;
Fmax = 10;
Fs = 2*Fmax;
n=0:1/Fs:1;
Cont = A*cos(2*pi*Fmax*n);
Cont1 = A*cos(2*pi*Fmax*(20/18)*n);
subplot(2,1,1)
stem(n,Cont)
subplot(2,1,2)
stem(n,Cont1)


I changed the ""sin"" to ""cos"" because it was hitting all the sinusoid zero points instead of the peaks.

",Jim Clay,https://dsp.stackexchange.com/users/923,http://dsp.stackexchange.com/questions/2326/demonstrating-the-effect-of-aliasing,TECHNOLOGY,dsp.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.6666666666666666,0.0,0.6666666666666666,0.8888888888888888,Demonstrate the effect of aliasing,"How does the signal look when we don't use the Nyquist rate to remove aliasing from a signal during sampling?

Let's suppose the signal is sinusoidal, with a frequency of 500&nbsp;Hz and an amplitude of 2.

signal = 2*cos(2*pi*500*t)


If I sample it, (replacing t=nTs , Ts = sampling period and n represent number of samples) and plotting the sampled signals with a different sampling period using the subplot command in MATLAB, how could I identify the aliasing in a sampled signal?

Here is the example code that plotted two signals, one at the Nyquist rate while the other less than the Nyquist rate:

A = 2;
Fmax = 10;
Fs = 2*Fmax;
n = 0:1/Fs:1;
Cont = A*sin(2*pi*(Fmax/Fs)*n);
Cont1 = A*sin(2*pi*(Fmax/18)*n);
subplot(2,1,1)
stem(n,Cont)
hold on
stem(n,Cont1)


and here is the waveform:



I wasn't able to identify the aliasing. How did it affect the signal when Nyquist rate didn't use?
","You have the right idea, but a key mistake was messing up your results.

n=0:1/Fs:1;


By making the time increments 1/Fs you are implicitly making the time units seconds.  In other words, ""0"" is 0 seconds, and ""1"" is 1 second.

Cont = A*sin(2*pi*(Fmax/Fs)*n);


By normalizing the sinusoid frequency by Fs you are implicitly assuming that the sample unit is 1/Fs seconds.  That is why you were getting lots of samples for a single sinusoid cycle when you intended to just have two samples per cycle (the Nyquist rate).  By the way, either sample unit is fine (1 second or 1/Fs second), you just need to be consistent.

Here is my attempt at what I think you intended.

A = 2;
Fmax = 10;
Fs = 2*Fmax;
n=0:1/Fs:1;
Cont = A*cos(2*pi*Fmax*n);
Cont1 = A*cos(2*pi*Fmax*(20/18)*n);
subplot(2,1,1)
stem(n,Cont)
subplot(2,1,2)
stem(n,Cont1)


I changed the ""sin"" to ""cos"" because it was hitting all the sinusoid zero points instead of the peaks.

"
1540,1540,2418,"What is the difference between unicast, anycast, broadcast and multicast traffic?","I have never had the privilege of working in an environment that required complicated routing or if it did require it, it was handled upstream of me. I've always used very simple static routing configurations and never needed to do any multipath routing -- hence my general confusion regarding this subject. I would like to understand multicasting and anycasting better. 


What is the difference between unicast, anycast, broadcast and multicast traffic?
What situations are they generally used in and why (e.g., what applications use which method)?
How do you calculate how much broadcast traffic is too much for a given network segment or broadcast domain?
What are the security implications of allowing broadcast and multicast traffic?

",kce,https://serverfault.com/users/62491,"Anycast is not a widely accepted type of communication in IPv4, but it is present in IPv6.

Three type of communication in IPv4 are 1) Unicast, 2) Multicast 3) Broadcast.

1) IPv4 Unicast One-to-One type of communication. A network device communicates with another network device. Layer 3 address used for Unicast is IPv4 Class A, Class B, Class C addresses. Layer 2 address is a unicast MAC address.

Example: Browse a website, Download file using FTP, Connect to another device using SSH (Secure Shell) etc.

2) IPv4 Multicast One-to-many type of communication. A network device send an IPv4 data packet and it is delivered to the devices who are interested in that traffic. Layer 3 address  used for IPv4 multicast is Class D IPv4 addresses (starts from 224 to 239) Layer 2 address for IPv4 multicast starts with ""01:00:5e"".

Example: IPTV, OSPF Hello messages, EIGRP Hello messages, RIPv2 Route Updates.

3) IPv4 Broadcast One-to-All type of communication. A network device send an IPv4 data packet and it will be delivered all devices in that LAN Segment. Problem with broadcast traffic is, broadcasts disturb all devices in LAN and cause bandwidth wastage.

Example: DHCPv4 Discover messages

In IPv6, we have Unicast, Multicast and Anycast. The concept of Unicast and Multicast are same in IPv4 and IPv6, except the changes in IPv6 Layer 3 addresses used for broadcast &amp; multicast and the Layer 2 address used for multicast. Layer 2 address used for IPv6 multicast traffic starts from ""33:33:"" (in Ipv4, it is ""01:00:5e""). 

IPv6 Anycast IPv6 Anycast type of communication is used to identify an interface from a group of interfaces, which provide the same service, but near to the client in routing distance (we can compare routing distance similar to geographical distance). Anycast is possible only with the help of routing protocols.

Check the below link for more clear explanation about IPv6 Anycast.

http://www.omnisecu.com/tcpip/ipv6/unicast-multicast-anycast-types-of-network-communication-in-ipv6.php

Example,  My home is located in India, and I want to resolve the FQDN ""www.serverfault.com"" to an IP address. Consider I have three DNS servers, one located in USA, other in Canada, and other in India, all providing the same service. Better choice is the DNS server from India, because it is located near to my home. I will get a faster reply and cause less network traffic if I use the service near my place.  Anycast can find the Server which is near to my home and get the service from that Server.
",Tweakit,https://serverfault.com/users/208797,http://serverfault.com/questions/279482,TECHNOLOGY,serverfault.com,0.8888888888888888,0.5555555555555556,0.0,0.3333333333333333,1.0,1.0,0.5555555555555556,0.4444444444444444,0.6666666666666666,0.0,0.6666666666666666,0.0,0.3333333333333333,0.0,0.3333333333333333,0.0,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.0,1.0,0.8888888888888888,1.0,1.0,0.8888888888888888,0.8,0.3333333333333333,0.3333333333333333,1.0,0.8888888888888888,"What is the difference between unicast, anycast, broadcast and multicast communication?","I have never had the privilege of working in an environment that required complicated routing or if it did require it, it was handled upstream of me. I've always used very simple static routing configurations and never needed to do any multipath routing -- hence my general confusion regarding this subject. I would like to understand multicasting and anycasting better. 


What is the difference between unicast, anycast, broadcast and multicast traffic?
What situations are they generally used in and why (e.g., what applications use which method)?
How do you calculate how much broadcast traffic is too much for a given network segment or broadcast domain?
What are the security implications of allowing broadcast and multicast traffic?

","Anycast is not a widely accepted type of communication in IPv4, but it is present in IPv6.

Three type of communication in IPv4 are 1) Unicast, 2) Multicast 3) Broadcast.

1) IPv4 Unicast One-to-One type of communication. A network device communicates with another network device. Layer 3 address used for Unicast is IPv4 Class A, Class B, Class C addresses. Layer 2 address is a unicast MAC address.

Example: Browse a website, Download file using FTP, Connect to another device using SSH (Secure Shell) etc.

2) IPv4 Multicast One-to-many type of communication. A network device send an IPv4 data packet and it is delivered to the devices who are interested in that traffic. Layer 3 address  used for IPv4 multicast is Class D IPv4 addresses (starts from 224 to 239) Layer 2 address for IPv4 multicast starts with ""01:00:5e"".

Example: IPTV, OSPF Hello messages, EIGRP Hello messages, RIPv2 Route Updates.

3) IPv4 Broadcast One-to-All type of communication. A network device send an IPv4 data packet and it will be delivered all devices in that LAN Segment. Problem with broadcast traffic is, broadcasts disturb all devices in LAN and cause bandwidth wastage.

Example: DHCPv4 Discover messages

In IPv6, we have Unicast, Multicast and Anycast. The concept of Unicast and Multicast are same in IPv4 and IPv6, except the changes in IPv6 Layer 3 addresses used for broadcast &amp; multicast and the Layer 2 address used for multicast. Layer 2 address used for IPv6 multicast traffic starts from ""33:33:"" (in Ipv4, it is ""01:00:5e""). 

IPv6 Anycast IPv6 Anycast type of communication is used to identify an interface from a group of interfaces, which provide the same service, but near to the client in routing distance (we can compare routing distance similar to geographical distance). Anycast is possible only with the help of routing protocols.

Check the below link for more clear explanation about IPv6 Anycast.

http://www.omnisecu.com/tcpip/ipv6/unicast-multicast-anycast-types-of-network-communication-in-ipv6.php

Example,  My home is located in India, and I want to resolve the FQDN ""www.serverfault.com"" to an IP address. Consider I have three DNS servers, one located in USA, other in Canada, and other in India, all providing the same service. Better choice is the DNS server from India, because it is located near to my home. I will get a faster reply and cause less network traffic if I use the service near my place.  Anycast can find the Server which is near to my home and get the service from that Server.
"
4650,4650,7373,Is it necessary to run own DNS server?,"I would like to buy a second-level domain name (e.g. example.com) and I will
run web server on my own machine (named www, having public IP address).

Is this sufficient for my machine to be accessible by visitors via browser
with http://www.example.com?

I expect that every visitor machine accessing http://www.example.com will first ask
it's DNS server if it knows the IP address of www.example.com.
If it doesn't know. The DNS server will ask the root server on the address of .com
top-level domain. Then it will ask .com top-level domain if it knows the IP address
of www.example.com and it should be there because I bought it. So finally it will send the IP address to the visitor's DNS server and then visitor's DNS server will send the IP
address to visitor's machine?

I would like to avoid installing and configuring own DNS server (I have only one laptop). Is my expectation correct that I don't need to install own DNS server?

If yes/no, please describe a little the reasoning behind the scene.
",xralf,https://webmasters.stackexchange.com/users/6231,"Your domain name registrar should be hosting your DNS records. This is not something you have to do or worry too much about. In fact, you are far better off not running a DNS server because of the security implications. When you register your domain name many registrars will host your DNS records free of charge. Some do charge a small fee. If your registrar for some extremely odd reason cannot host your DNS records, there are DNS hosts. So there are plenty of options. I suggest making this a question you ask the registrar prior to registering your domain name.
",closetnoc,https://webmasters.stackexchange.com/users/36029,http://webmasters.stackexchange.com/questions/76991/is-it-necessary-to-run-own-dns-server,TECHNOLOGY,webmasters.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,0.3333333333333333,1.0,0.6666666666666666,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.3333333333333333,0.0,1.0,0.8888888888888888,Is it necessary to run your own DNS server?,"I would like to buy a second-level domain name (e.g. example.com) and I will
run web server on my own machine (named www, having public IP address).

Is this sufficient for my machine to be accessible by visitors via browser
with http://www.example.com?

I expect that every visitor machine accessing http://www.example.com will first ask
it's DNS server if it knows the IP address of www.example.com.
If it doesn't know. The DNS server will ask the root server on the address of .com
top-level domain. Then it will ask .com top-level domain if it knows the IP address
of www.example.com and it should be there because I bought it. So finally it will send the IP address to the visitor's DNS server and then visitor's DNS server will send the IP
address to visitor's machine?

I would like to avoid installing and configuring own DNS server (I have only one laptop). Is my expectation correct that I don't need to install own DNS server?

If yes/no, please describe a little the reasoning behind the scene.
","Your domain name registrar should host your DNS records. It's not something you have to do or worry about too much. In fact, it's best not to run a DNS server because of security issues. When you register your domain name, many registrants will host your DNS records for free. Some do charge a small fee. If your registrar is unable to host your DNS records for some very strange reason, there is a DNS host. So there are many options. I suggest that you ask the Registrar this question before registering your domain name."
5145,5145,8179,should have done vs should had done (sequence of tenses),"imagine you want to use ""should have done"" in a subordinate clause when there's some past tense in the main clause.

e.g.: ""He said I should have(had?) done it.""

which one is correct? 
or should i use some other modal verb for this purpose?
thanks
",Max Black,https://english.stackexchange.com/users/116742,"*should had done 

is totally off (* means incorrect). 

In how many great writers' work have you found it? In how many grammars? Well?
",Marius Hancu,https://english.stackexchange.com/users/114515,http://english.stackexchange.com/questions/238682/should-have-done-vs-should-had-done-sequence-of-tenses,CULTURE,english.stackexchange.com,1.0,0.5555555555555556,0.0,0.6666666666666666,0.6666666666666666,1.0,0.5555555555555556,0.7777777777777778,0.6666666666666666,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.7777777777777778,0.4444444444444444,0.7777777777777778,0.7777777777777778,0.6,0.0,0.0,0.3333333333333333,0.7777777777777778,Should do vs should do (temporal sequence),"imagine you want to use ""should have done"" in a subordinate clause when there's some past tense in the main clause.

e.g.: ""He said I should have(had?) done it.""

which one is correct? 
or should i use some other modal verb for this purpose?
thanks
","*should had done 

is totally off (* means incorrect). 

In how many great writers' work have you found it? In how many grammars? Well?
"
4969,4969,7915,Performance of SQL query with condition vs. without where clause,"Which SQL-query will be executed with less time — query with WHERE-clause or without, when:


WHERE-clause deals with indexed field (e.g. primary key field)
WHERE-clause deals with non-indexed field


I suppose when we're working with indexed fields, thus query with WHERE will be faster.
Am I right?

Thanks!
",Mike B.,https://stackoverflow.com/users/462347,"It may depend on the type of where clause you are writing. In a simple where clause, it is generally better to have an index on the field you are using (and uindexes can and should be built on more than the PK). However, you have to write a saragble where clause for the index to make any difference. See this question for some guidelines on sarability:

What makes a SQL statement sargable?
",HLGEM,https://stackoverflow.com/users/9034,http://stackoverflow.com/questions/11802884/performance-of-sql-query-with-condition-vs-without-where-clause,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.6666666666666666,0.0,0.3333333333333333,1.0,0.6666666666666666,0.6666666666666666,0.4444444444444444,0.3333333333333333,0.0,0.3333333333333333,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.0,0.8888888888888888,0.8888888888888888,0.5555555555555556,1.0,1.0,0.7333333333333333,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.8888888888888888,Performance comparison of SQL query with and without where clause,"Which SQL-query will be executed with less time — query with WHERE-clause or without, when:


WHERE-clause deals with indexed field (e.g. primary key field)
WHERE-clause deals with non-indexed field


I suppose when we're working with indexed fields, thus query with WHERE will be faster.
Am I right?

Thanks!
","This may depend on the type of where clause you are writing. In a simple where clause, it's best to have an index on the field you use (UINDEX can and should be built on PK). However, you must write a saragble where clause to make the index different. For some guidelines on recyclability, see this question:"
4972,4972,7919,"Does Thailand have islands like those in ""Bridget Jones: The Edge of Reason""?","In the movie, you can see some islands that look like those from Vietnam or China: they come out suddenly from the water, and the bottom of them look like solid rock.

Do such islands occur in Thailand? Also, is there a term for such islands?
",Andrew Grimm,https://travel.stackexchange.com/users/324,"I originally thought the movie had made it up, but they do exist. From 10 Islands for a Perfect Trip to Thailand:


",Andrew Grimm,https://travel.stackexchange.com/users/324,http://travel.stackexchange.com/questions/50532/does-thailand-have-islands-like-those-in-bridget-jones-the-edge-of-reason,CULTURE,travel.stackexchange.com,1.0,0.3333333333333333,0.0,1.0,1.0,1.0,0.6666666666666666,0.6666666666666666,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.7777777777777778,0.3333333333333333,0.7777777777777778,0.7777777777777778,0.4666666666666667,0.0,0.0,0.0,0.6666666666666666,Is there an island in Thailand like Bridget Jones: the edge of reason?,"In the movie, you can see some islands that look like Vietnam or China: they suddenly come out of the water and the bottom looks like solid rock.","I thought the film was made up, but they do exist. From 10 islands to Thailand:"
1701,1701,2696,Can I set the Brick Texture Node horizontal mortar size to be equivalent to the vertical mortar size?,"I'm using Blender 2.73 and I'm trying to create tiles using the brick texture node.  The problem I'm having is that the horizontal mortar size is smaller than the vertical.

Is it possible to have them be equivalent sizes?
",Mario,https://blender.stackexchange.com/users/11417,"The main reason of this answer is to combat the erroneous views as to why the brick texture is distorted.

The mortar attribute is a constant set by the Mortar Size option, not a percentage.



This issue is caused by scaling the mesh that the texture is applied to. Applying the scale will not change anything, as the generated UV's for the brick texture still remain the same. You need to UV unwrap your mesh properly and use that to drive the brick texture UV coordinates.

A default plane will give this result:


While a scaled one will give this result:


Again, applying scale does nothing. I tried it, several times. Instead, UV unwrap the mesh and set up your nodes like this (or try @chebhou's suggestion):



Now you can change the UV unwrapping and the mortar will change in width as well. You may need to change the size of your bricks once you have the mortar size correct.
",VRM,https://blender.stackexchange.com/users/6204,http://blender.stackexchange.com/questions/24277/can-i-set-the-brick-texture-node-horizontal-mortar-size-to-be-equivalent-to-the,TECHNOLOGY,blender.stackexchange.com,0.7777777777777778,0.6666666666666666,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.4444444444444444,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.3333333333333333,1.0,0.6666666666666666,0.7777777777777778,Can I set the horizontal mortar size of the brick texture node to be equal to the vertical mortar size?,I'm using blender2.73 and trying to create a tile using the brick texture node. The problem I have is that the horizontal mortar is smaller than the vertical one.,"The main reason of this answer is to combat the erroneous views as to why the brick texture is distorted.

The mortar attribute is a constant set by the Mortar Size option, not a percentage.



This issue is caused by scaling the mesh that the texture is applied to. Applying the scale will not change anything, as the generated UV's for the brick texture still remain the same. You need to UV unwrap your mesh properly and use that to drive the brick texture UV coordinates.

A default plane will give this result:


While a scaled one will give this result:


Again, applying scale does nothing. I tried it, several times. Instead, UV unwrap the mesh and set up your nodes like this (or try @chebhou's suggestion):



Now you can change the UV unwrapping and the mortar will change in width as well. You may need to change the size of your bricks once you have the mortar size correct.
"
1888,1888,3005,How to solve this stochastic integrals?,"how can I solve these two stochastic integrals? 

$$\int_0^T B_t\,dB_t$$
$$\int_0^T f(B_t)\,dB_t$$

where B_t is the BM. 

Thank you very very much!
",Jorko,https://math.stackexchange.com/users/80606,"Besides applying the Itô formula, there is also the possibility to calculate a stochastic integral using approximation by step functions. It works fine for the integral $\int_0^T B_t \, dB_t$:

Let

$$f_n(t,\omega) := \sum_{j=1}^n 1_{[t_{j-1},t_{j})}(t) \cdot B_{t_{j-1}}(\omega)$$

where $\Pi_n$ is a partition of $[0,T]$ such that $$\max_{t_j \in \Pi_n} |t_j-t_{j+1}| \to 0 \qquad (n \to \infty)$$

Since the Brownian motion has continuous paths, it's not difficult to show that $(f_n)_{n \in \mathbb{N}}$ is an approximating sequence as required in the definition of the stochastic integral, therefore

$$\int_0^T f_n(t) \, dB_t \stackrel{L^2}{\to} \int_0^T B_t \, dB_t \qquad (n \to \infty)$$

By definition, it's easy to calculate the stochastic integral of step functions:

$$\int_0^T f_n(t) \, dB_t = \sum_{j=1}^n B_{t_{j-1}} \cdot (B_{t_{j}}-B_{t_{j-1}}) \tag{1} $$

On the other hand, we have

$$\begin{align} B_T^2 &amp;= \left( \sum_{j=1}^n B_{t_j}-B_{t_{j-1}} \right) \cdot \left( \sum_{k=1}^n B_{t_k}-B_{t_{k-1}} \right) =\underbrace{\sum_{j=1}^n (B_{t_j}-B_{t_{j-1}})^2}_{\stackrel{L^2}{\to} T} + 2 \underbrace{\sum_{j=1}^n B_{t_{j-1}} \cdot (B_{t_j}-B_{t_{j-1}})}_{\stackrel{(1)}{\to} \int_0^T B_t \, dB_t}. \end{align}$$

Thus, $$B_T^2 = T +  2 \int_0^T B_t \, dB_t.$$
",saz,https://math.stackexchange.com/users/36150,http://math.stackexchange.com/questions/408918/how-to-solve-this-stochastic-integrals,SCIENCE,math.stackexchange.com,1.0,0.5555555555555556,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.3333333333333333,1.0,How to solve this random integral?,"how can I solve these two stochastic integrals? 

$$\int_0^T B_t\,dB_t$$
$$\int_0^T f(B_t)\,dB_t$$

where B_t is the BM. 

Thank you very very much!
","Besides applying the Itô formula, there is also the possibility to calculate a stochastic integral using approximation by step functions. It works fine for the integral $\int_0^T B_t \, dB_t$:

Let

$$f_n(t,\omega) := \sum_{j=1}^n 1_{[t_{j-1},t_{j})}(t) \cdot B_{t_{j-1}}(\omega)$$

where $\Pi_n$ is a partition of $[0,T]$ such that $$\max_{t_j \in \Pi_n} |t_j-t_{j+1}| \to 0 \qquad (n \to \infty)$$

Since the Brownian motion has continuous paths, it's not difficult to show that $(f_n)_{n \in \mathbb{N}}$ is an approximating sequence as required in the definition of the stochastic integral, therefore

$$\int_0^T f_n(t) \, dB_t \stackrel{L^2}{\to} \int_0^T B_t \, dB_t \qquad (n \to \infty)$$

By definition, it's easy to calculate the stochastic integral of step functions:

$$\int_0^T f_n(t) \, dB_t = \sum_{j=1}^n B_{t_{j-1}} \cdot (B_{t_{j}}-B_{t_{j-1}}) \tag{1} $$

On the other hand, we have

$$\begin{align} B_T^2 &amp;= \left( \sum_{j=1}^n B_{t_j}-B_{t_{j-1}} \right) \cdot \left( \sum_{k=1}^n B_{t_k}-B_{t_{k-1}} \right) =\underbrace{\sum_{j=1}^n (B_{t_j}-B_{t_{j-1}})^2}_{\stackrel{L^2}{\to} T} + 2 \underbrace{\sum_{j=1}^n B_{t_{j-1}} \cdot (B_{t_j}-B_{t_{j-1}})}_{\stackrel{(1)}{\to} \int_0^T B_t \, dB_t}. \end{align}$$

Thus, $$B_T^2 = T +  2 \int_0^T B_t \, dB_t.$$
"
4044,4044,6456,Is there a list of Mitzvot and their corresponding body parts?,"The Talmud (Makkot 23B)and the Zohar (1:170B - unverified English translation here) say that the 248 positive commandments correspond to the 248 limbs of the human body. (The Mishna (Ohalot 1:8) lists the 248 Halachic limbs). The Talmud also says that the 365 Negative commandments correspond to the days of the year.

The Zohar adds that the 365 negative commandments also correspond to the 365 sinews in the human body (See Yonatan Ben Uziel Bereshit 1:27), and connects them to the days of the year.

R' Chaim Vital, in Shaar HaKavanot (Shaar 1, Part 1) says that ""Each of the 248 spiritual limbs gets its nourishment from a particular mitzvah that corresponds to that limb. When a person fails to perform that particular mitzvah, the corresponding limb will lack its proper nourishment..."" (translation from here)

Is there any source which tells us which limb (and/or sinew) each Mitzvah corresponds to?

As an example, the Zohar referenced above (1:170B), connects Gid Hanasheh (sciatic nerve), one of the 365 sinews, to the prohibition of eating on Tisha B'av.
",Menachem,https://judaism.stackexchange.com/users/603,"The Luz bone corresponds to the Mitzvah of Melaveh Malka. (Wikipedia quotes the Kaf haChaim (300:1-2) as saying this, although I thought that this was first stated earlier than him)
",Adam Mosheh,https://judaism.stackexchange.com/users/1059,http://judaism.stackexchange.com/questions/10406/is-there-a-list-of-mitzvot-and-their-corresponding-body-parts,CULTURE,judaism.stackexchange.com,0.8888888888888888,0.7777777777777778,0.0,0.6666666666666666,1.0,1.0,0.5555555555555556,0.5555555555555556,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.8888888888888888,0.7777777777777778,0.5555555555555556,0.8888888888888888,0.8888888888888888,0.5333333333333333,0.0,0.0,1.0,0.8888888888888888,Do you have a list of rite of passage and corresponding body parts?,"The Talmud (Makkot 23B)and the Zohar (1:170B - unverified English translation here) say that the 248 positive commandments correspond to the 248 limbs of the human body. (The Mishna (Ohalot 1:8) lists the 248 Halachic limbs). The Talmud also says that the 365 Negative commandments correspond to the days of the year.

The Zohar adds that the 365 negative commandments also correspond to the 365 sinews in the human body (See Yonatan Ben Uziel Bereshit 1:27), and connects them to the days of the year.

R' Chaim Vital, in Shaar HaKavanot (Shaar 1, Part 1) says that ""Each of the 248 spiritual limbs gets its nourishment from a particular mitzvah that corresponds to that limb. When a person fails to perform that particular mitzvah, the corresponding limb will lack its proper nourishment..."" (translation from here)

Is there any source which tells us which limb (and/or sinew) each Mitzvah corresponds to?

As an example, the Zohar referenced above (1:170B), connects Gid Hanasheh (sciatic nerve), one of the 365 sinews, to the prohibition of eating on Tisha B'av.
","The Luz bone corresponds to the Mitzvah of Melaveh Malka. (Wikipedia quotes the Kaf haChaim (300:1-2) as saying this, although I thought that this was first stated earlier than him)
"
1250,1250,1965,SQL Server: update table from xml string,"this is the first time I am working with an XML input in SQL. 

I created the following procedure to insert all records from my XML string into my table which works well so far. 

Can someone tell me how I have to change this so that it only inserts a record as new if the itemID (every record in my XML has this as well) does not yet exist in my table, column itemID - otherwise it should update the existing record with the new data from the XML. 

I know how to use IF NOT EXISTS and UPDATE in general but am not sure how to realise this with an XML string as the input. 

My procedure (so far): 

ALTER PROCEDURE [dbo].[editor_UpdateQuestions]
    @xml xml
AS
BEGIN
    SET NOCOUNT ON;

    INSERT INTO editor_Questions
        (
            categoryID,
            question,
            sortID,
            modDate,
            modBy       
        )
    SELECT  ParamValues.x1.value('categoryID[1]', 'int'),
            ParamValues.x1.value('question[1]', 'nvarchar(1000)'),
            ParamValues.x1.value('sortID[1]', 'int'),
            GETDATE(),
            ParamValues.x1.value('modBy[1]', 'varchar(50)')
    FROM    @xml.nodes('/ranks/item') AS ParamValues(x1)

END


Example XML input:

&lt;ranks&gt;
    &lt;item&gt;&lt;itemID&gt;25&lt;/itemID&gt;&lt;categoryID&gt;1&lt;/categoryID&gt;&lt;question&gt;some text&lt;/question&gt;&lt;sortID&gt;1&lt;/sortID&gt;&lt;modBy&gt;abc&lt;/modBy&gt;&lt;/item&gt;
    &lt;item&gt;&lt;itemID&gt;12&lt;/itemID&gt;&lt;categoryID&gt;1&lt;/categoryID&gt;&lt;question&gt;some text 2&lt;/question&gt;&lt;sortID&gt;2&lt;/sortID&gt;&lt;modBy&gt;abc&lt;/modBy&gt;&lt;/item&gt;
    &lt;item&gt;&lt;itemID&gt;9&lt;/itemID&gt;&lt;categoryID&gt;1&lt;/categoryID&gt;&lt;question&gt;some text 3&lt;/question&gt;&lt;sortID&gt;3&lt;/sortID&gt;&lt;modBy&gt;abc&lt;/modBy&gt;&lt;/item&gt;
&lt;/ranks&gt;


Many thanks in advance for any help with this, Tim.
",user2571510,https://stackoverflow.com/users/2571510,";WITH new_Questions AS (
    SELECT  ParamValues.x1.value('itemID[1]'    , 'int'           ) AS itemID,
            ParamValues.x1.value('categoryID[1]', 'int'           ) AS categoryID,
            ParamValues.x1.value('question[1]'  , 'nvarchar(1000)') AS question,
            ParamValues.x1.value('sortID[1]'    , 'int'           ) AS sortID,
            GETDATE()                                               AS date,
            ParamValues.x1.value('modBy[1]'     , 'varchar(50)'   ) AS modBy
    FROM    @xml.nodes('/ranks/item') AS ParamValues(x1)
)
MERGE INTO editor_Questions AS old
USING new_Questions AS new
  ON (new.itemID = old.itemID)
WHEN MATCHED THEN UPDATE SET
  old.categoryID = new.categoryID,
  old.question   = new.question  ,
  old.date       = new.date      ,
  old.sortID     = new.sortID    ,
  old.modBy      = new.modBy
WHEN NOT MATCHED THEN 
  INSERT (    itemId,    categoryID,    question,    date,    sortID,    modBy)
  VALUES (new.itemId,new.categoryID,new.question,new.date,new.sortID,new.modBy);

",Anon,https://stackoverflow.com/users/1155057,http://stackoverflow.com/questions/24167421/sql-server-update-table-from-xml-string,STACKOVERFLOW,stackoverflow.com,1.0,0.4444444444444444,0.0,0.6666666666666666,0.3333333333333333,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.5555555555555556,0.8888888888888888,0.5,0.8888888888888888,1.0,0.8,1.0,0.0,0.0,0.6666666666666666,SQL Server: updating tables from XML strings,"this is the first time I am working with an XML input in SQL. 

I created the following procedure to insert all records from my XML string into my table which works well so far. 

Can someone tell me how I have to change this so that it only inserts a record as new if the itemID (every record in my XML has this as well) does not yet exist in my table, column itemID - otherwise it should update the existing record with the new data from the XML. 

I know how to use IF NOT EXISTS and UPDATE in general but am not sure how to realise this with an XML string as the input. 

My procedure (so far): 

ALTER PROCEDURE [dbo].[editor_UpdateQuestions]
    @xml xml
AS
BEGIN
    SET NOCOUNT ON;

    INSERT INTO editor_Questions
        (
            categoryID,
            question,
            sortID,
            modDate,
            modBy       
        )
    SELECT  ParamValues.x1.value('categoryID[1]', 'int'),
            ParamValues.x1.value('question[1]', 'nvarchar(1000)'),
            ParamValues.x1.value('sortID[1]', 'int'),
            GETDATE(),
            ParamValues.x1.value('modBy[1]', 'varchar(50)')
    FROM    @xml.nodes('/ranks/item') AS ParamValues(x1)

END


Example XML input:

&lt;ranks&gt;
    &lt;item&gt;&lt;itemID&gt;25&lt;/itemID&gt;&lt;categoryID&gt;1&lt;/categoryID&gt;&lt;question&gt;some text&lt;/question&gt;&lt;sortID&gt;1&lt;/sortID&gt;&lt;modBy&gt;abc&lt;/modBy&gt;&lt;/item&gt;
    &lt;item&gt;&lt;itemID&gt;12&lt;/itemID&gt;&lt;categoryID&gt;1&lt;/categoryID&gt;&lt;question&gt;some text 2&lt;/question&gt;&lt;sortID&gt;2&lt;/sortID&gt;&lt;modBy&gt;abc&lt;/modBy&gt;&lt;/item&gt;
    &lt;item&gt;&lt;itemID&gt;9&lt;/itemID&gt;&lt;categoryID&gt;1&lt;/categoryID&gt;&lt;question&gt;some text 3&lt;/question&gt;&lt;sortID&gt;3&lt;/sortID&gt;&lt;modBy&gt;abc&lt;/modBy&gt;&lt;/item&gt;
&lt;/ranks&gt;


Many thanks in advance for any help with this, Tim.
",";WITH new_Questions AS (
    SELECT  ParamValues.x1.value('itemID[1]'    , 'int'           ) AS itemID,
            ParamValues.x1.value('categoryID[1]', 'int'           ) AS categoryID,
            ParamValues.x1.value('question[1]'  , 'nvarchar(1000)') AS question,
            ParamValues.x1.value('sortID[1]'    , 'int'           ) AS sortID,
            GETDATE()                                               AS date,
            ParamValues.x1.value('modBy[1]'     , 'varchar(50)'   ) AS modBy
    FROM    @xml.nodes('/ranks/item') AS ParamValues(x1)
)
MERGE INTO editor_Questions AS old
USING new_Questions AS new
  ON (new.itemID = old.itemID)
WHEN MATCHED THEN UPDATE SET
  old.categoryID = new.categoryID,
  old.question   = new.question  ,
  old.date       = new.date      ,
  old.sortID     = new.sortID    ,
  old.modBy      = new.modBy
WHEN NOT MATCHED THEN 
  INSERT (    itemId,    categoryID,    question,    date,    sortID,    modBy)
  VALUES (new.itemId,new.categoryID,new.question,new.date,new.sortID,new.modBy);

"
2199,2199,3506,Securely Connecting to SQL Azure,"According to this page, 


  All communications between Microsoft Azure SQL Database and your
  application require encryption (SSL) at all times.


If this is the case, what is the difference between using the standard connection string of: 

server.database.windows.net


and requiring security and using the ""Secure Connection String"" of:

server.database.secure.windows.net

",KevenDenen,https://stackoverflow.com/users/116927,"The link you posted talks about validating the SSL Certificates used to make the Sql Connection to validate that a ""man in the middle"" attack cannot get your Sql UserName/Password.

http://en.wikipedia.org/wiki/Man-in-the-middle_attack

It is your application that needs to validate the SSL Certificate to validate it is coming from SqlAzure. I don't see how changing the hostname and not requiring security will keep you safe.
",Mike Burdick,https://stackoverflow.com/users/4283637,http://stackoverflow.com/questions/27867023/securely-connecting-to-sql-azure,STACKOVERFLOW,stackoverflow.com,1.0,0.3333333333333333,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.8888888888888888,0.5555555555555556,0.8888888888888888,1.0,0.7333333333333333,0.0,0.0,0.6666666666666666,1.0,Secure connection to SQL azure,"According to this page, 


  All communications between Microsoft Azure SQL Database and your
  application require encryption (SSL) at all times.


If this is the case, what is the difference between using the standard connection string of: 

server.database.windows.net


and requiring security and using the ""Secure Connection String"" of:

server.database.secure.windows.net

","The link you posted talks about validating the SSL Certificates used to make the Sql Connection to validate that a ""man in the middle"" attack cannot get your Sql UserName/Password.

http://en.wikipedia.org/wiki/Man-in-the-middle_attack

It is your application that needs to validate the SSL Certificate to validate it is coming from SqlAzure. I don't see how changing the hostname and not requiring security will keep you safe.
"
2424,2424,3865,Date cannot be within x working days of today,"I need a validation rule that checks the date of a field is not within 4 working days of today's date. Is it possible to do this, what would the formula look like?
",Bartley,https://salesforce.stackexchange.com/users/2892,"Basically you'd need to combine these two validation rules:

My_Date__c - TODAY() &gt; 4


and 

CASE(MOD( My_Date__c - DATE(1900, 1, 7), 7),
0, 0,
6, 0,
1) = 0


The first obviously gives you a date that's more than 4 days from today. The 2nd gives you weekdays since the start of the year 1900. You might need to first check to see which day of the week it was, then change your criteria for My_Date__c - TODAY() &gt; 4 to My_Date__c - TODAY() &gt; 5 or 6 if its either a Tuesday or Wednesday. 

I don't know if TODAY() is allowed to be a Sat or Sun, but clearly, My_Date__c - TODAY() &gt; 4 works for that condition, so the main thing you need to check for is if TODAY() is a Tues or Wed then adjust accordingly. 
",crmprogdev,https://salesforce.stackexchange.com/users/2212,http://salesforce.stackexchange.com/questions/40853/date-cannot-be-within-x-working-days-of-today,TECHNOLOGY,salesforce.stackexchange.com,1.0,0.4444444444444444,0.0,1.0,0.6666666666666666,1.0,0.4444444444444444,0.4444444444444444,0.3333333333333333,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.9333333333333332,1.0,0.3333333333333333,0.0,0.8888888888888888,Date cannot be within X working days today,"I need a validation rule to check the field date, which is not within 4 working days of today's date. Is it possible to do so? What is the formula like?","Basically you'd need to combine these two validation rules:

My_Date__c - TODAY() &gt; 4


and 

CASE(MOD( My_Date__c - DATE(1900, 1, 7), 7),
0, 0,
6, 0,
1) = 0


The first obviously gives you a date that's more than 4 days from today. The 2nd gives you weekdays since the start of the year 1900. You might need to first check to see which day of the week it was, then change your criteria for My_Date__c - TODAY() &gt; 4 to My_Date__c - TODAY() &gt; 5 or 6 if its either a Tuesday or Wednesday. 

I don't know if TODAY() is allowed to be a Sat or Sun, but clearly, My_Date__c - TODAY() &gt; 4 works for that condition, so the main thing you need to check for is if TODAY() is a Tues or Wed then adjust accordingly. 
"
3422,3422,5446,"'Trying to help someone, but the other party doesn't appreciate it'","What is a word that best describes trying to help someone, but the other party doesn't appreciate it?  

I'm looking for a word.  
",yuritsuki,https://english.stackexchange.com/users/21921,"A thankless task.
Not sure there's a single noun that covers it. The obvious adjective would be unappreciated.
",Leon Conrad,https://english.stackexchange.com/users/64481,http://english.stackexchange.com/questions/149521/trying-to-help-someone-but-the-other-party-doesnt-appreciate-it,CULTURE,english.stackexchange.com,0.7777777777777778,0.4444444444444444,0.3333333333333333,1.0,0.6666666666666666,0.5,0.6666666666666666,0.7777777777777778,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.3333333333333333,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.0,0.6666666666666666,0.8888888888888888,"""Want to help others, but they don't appreciate it""","What's the best word to describe trying to help others, but they don't appreciate it?","A thankless task.
Not sure there's a single noun that covers it. The obvious adjective would be unappreciated.
"
5949,5949,9425,"How to Solve the ""Unidentified network"" in Windows 7","
  Possible Duplicate:
  Windows 7 unidentified network direct cable connection  




I connect the internet through Ad-hoc network, My machine uses win7 and another uses winows xp, There's no problem when I connect the XP machine, but if i disconnect and reconnect the net, then my local network is marked as ""Unidentified network"",unless restart the XP machine, I don't know why? 
",gylns,https://superuser.com/users/31662,"Could you clarify which computer has the internet connection? If the Windows 7 computer is the one sharing the ad-hoc network to the Windows XP computer, you might want to look into using Connectify instead of running an ad-hoc with internet connection sharing. Connectify uses windows 7's built-in support for emulating an access point to allow you to share an internet connection with just a laptop wireless card, but appear as a regular AP, not an ad-hoc. It is much less buggy than ICS, in my experience. I haven't used it since the beta, but it's free, and I recall it working pretty well even back then.
",nhinkle,https://superuser.com/users/20088,http://superuser.com/questions/121831,TECHNOLOGY,superuser.com,0.8888888888888888,0.6666666666666666,0.0,1.0,1.0,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.5555555555555556,0.8888888888888888,0.6666666666666666,1.0,1.0,0.9,0.6666666666666666,0.0,0.0,0.8888888888888888,"How to solve ""unknown network"" in Windows 7","
  Possible Duplicate:
  Windows 7 unidentified network direct cable connection  




I connect the internet through Ad-hoc network, My machine uses win7 and another uses winows xp, There's no problem when I connect the XP machine, but if i disconnect and reconnect the net, then my local network is marked as ""Unidentified network"",unless restart the XP machine, I don't know why? 
","Can you explain which computer has an Internet connection? If a Windows 7 computer is a computer sharing an ad hoc network with a Windows XP computer, you may need to consider using connect instead of running an ad hoc with internet connection sharing. Connectify uses Windows 7's built-in support to simulate an access point, so that you can share an Internet connection with only one laptop wireless network card, but it is displayed as an ordinary AP rather than a special AP. In my experience, it is much less than ICS. I haven't used it since beta, but it's free, and I remember it worked well even then."
5703,5703,9040,Reverse a month name to month number conversion,"Hello I'm trying to do opposite stuff to this, because now it change from 2015/Sau/01 to 2015/01/01 I don't know how to change back to 2015/Sau/01, how can I do this with this script, because I need to keep locale language, please help me. 

var date = f.task_end_date.value.split(""/"");
var months = ['Sau', 'Vas', 'Kov', 'Bal', 'Geg', 'Bir','Lie', 'Rgp', 'Rgs', 'Spa', 'Lap', 'Grd'];
for(var j=0;j&lt;months.length;j++){
    if(date[1]==months[j]){
         date[1]=months.indexOf(months[j])+1;
     }                      
} 
if(date[1]&lt;10){
    date[1]='0'+date[1];
}                        
var formattedDate = date[0]+date[1]+date[2];

",McLaren,https://stackoverflow.com/users/5039309,"You should just be able to replace:

for(var j=0;j&lt;months.length;j++){
    if(date[1]==months[j]){
         date[1]=months.indexOf(months[j])+1;
     }                      
} 
if(date[1]&lt;10){
    date[1]='0'+date[1];
}           


with:

date[1] = months[parseInt(date[1],10)-1];


The parseInt will take your string 01 through 12 and give you the integral value, then you subtract one to get the index and look up the equivalent month name (I guess, though I'm not familiar with that specific language).

In other words, the final code would be:

var date = f.task_end_date.value.split(""/"");
var months = ['Sau', 'Vas', 'Kov', 'Bal', 'Geg', 'Bir','Lie', 'Rgp', 'Rgs', 'Spa', 'Lap', 'Grd'];
date[1] = months[parseInt(date[1],10)-1];
var formattedDate = date[0] + date[1] + date[2];




You can also avoid parseInt() if you wish since Javascript will treat a string as a number (via the ToNumber operation) when you subtract one:

date[1] = months[date[1]-1];


It probably won't reduce the actual work being done since the conversion from string to numeric has to be done whether explicit or implicit (it may even be slower since the implicit conversion has to handle the possibility of hex values but it's unlikely to matter a lot either way).

So, if you value succinctness of code, it's certainly an option. I prefer the explicit version myself but you may have other priorities.
",paxdiablo,https://stackoverflow.com/users/14860,http://stackoverflow.com/questions/31449566/reverse-a-month-name-to-month-number-conversion,STACKOVERFLOW,stackoverflow.com,1.0,0.7777777777777778,0.0,1.0,1.0,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,1.0,0.8888888888888888,1.0,1.0,1.0,0.6666666666666666,0.0,0.6666666666666666,1.0,Convert month name to month number,"Hello I'm trying to do opposite stuff to this, because now it change from 2015/Sau/01 to 2015/01/01 I don't know how to change back to 2015/Sau/01, how can I do this with this script, because I need to keep locale language, please help me. 

var date = f.task_end_date.value.split(""/"");
var months = ['Sau', 'Vas', 'Kov', 'Bal', 'Geg', 'Bir','Lie', 'Rgp', 'Rgs', 'Spa', 'Lap', 'Grd'];
for(var j=0;j&lt;months.length;j++){
    if(date[1]==months[j]){
         date[1]=months.indexOf(months[j])+1;
     }                      
} 
if(date[1]&lt;10){
    date[1]='0'+date[1];
}                        
var formattedDate = date[0]+date[1]+date[2];

","You should just be able to replace:

for(var j=0;j&lt;months.length;j++){
    if(date[1]==months[j]){
         date[1]=months.indexOf(months[j])+1;
     }                      
} 
if(date[1]&lt;10){
    date[1]='0'+date[1];
}           


with:

date[1] = months[parseInt(date[1],10)-1];


The parseInt will take your string 01 through 12 and give you the integral value, then you subtract one to get the index and look up the equivalent month name (I guess, though I'm not familiar with that specific language).

In other words, the final code would be:

var date = f.task_end_date.value.split(""/"");
var months = ['Sau', 'Vas', 'Kov', 'Bal', 'Geg', 'Bir','Lie', 'Rgp', 'Rgs', 'Spa', 'Lap', 'Grd'];
date[1] = months[parseInt(date[1],10)-1];
var formattedDate = date[0] + date[1] + date[2];




You can also avoid parseInt() if you wish since Javascript will treat a string as a number (via the ToNumber operation) when you subtract one:

date[1] = months[date[1]-1];


It probably won't reduce the actual work being done since the conversion from string to numeric has to be done whether explicit or implicit (it may even be slower since the implicit conversion has to handle the possibility of hex values but it's unlikely to matter a lot either way).

So, if you value succinctness of code, it's certainly an option. I prefer the explicit version myself but you may have other priorities.
"
2316,2316,3694,Will enclosing my porch keep my house warmer?,"Will enclosing my porches during the winter help keep my house warmer? There is a lot of wind hitting the house, and I'm afraid that is causing a drop in temperature.
",Anthony Powell,https://diy.stackexchange.com/users/27718,"If your porch gets any sun, it should help. My dad enclosed his each fall and opened it back up in the spring to let the breeze through. Worked great, but this was in the high desert where it would be sunny and below freezing at the same time.
",scollier,https://diy.stackexchange.com/users/27719,http://diy.stackexchange.com/questions/52440/will-enclosing-my-porch-keep-my-house-warmer,LIFE_ARTS,diy.stackexchange.com,1.0,1.0,0.0,1.0,1.0,1.0,0.6666666666666666,0.7777777777777778,0.0,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8,0.0,0.0,1.0,0.8888888888888888,Can I warm my house by enclosing my porch?,"Does it help to warm my house in winter by surrounding my porch? There's a lot of wind blowing into the house, I'm afraid it will cause the temperature to drop.","If your porch gets any sun, it should help. My dad enclosed his each fall and opened it back up in the spring to let the breeze through. Worked great, but this was in the high desert where it would be sunny and below freezing at the same time.
"
3006,3006,4790,Apache ErrorDocument directive not working,"I can't get a custom error document to work for 400 Bad Request. It's a CentOS LAMP server.

ErrorDocument 400 /badrdoc.html


I've tried using the above in:


Apache http.conf
Apache httpd-vhosts.conf (in each vhost)
.htaccess in the root htdocs of the site


None of them are working. Apache is serving its default 400 Bad Request page.

Can anyone shed any light on this?

Edit: forgot to mention, I have restarted Apache after changes.
",ServerBloke,https://serverfault.com/users/116123,"I had quite some trouble getting a custom 400 error document to work.  I added this to the top level of my Apache conf:

ErrorDocument 404 /404.html
ErrorDocument 400 /400.html


And created the two error documents in the DocumentRoot.  First, I tested the 404 with:

echo -en ""GET /foo HTTP/1.0\n\n"" | nc 127.0.0.1 80


This returned my custom 404.

Then the 400 (Note that the leading slash is missing):

echo -en ""GET foo HTTP/1.0\n\n"" | nc 127.0.0.1 80


The response was the default Apache 400.

I did manage to get my custom 400 back by talking HTTP to an HTTPS vhost:

echo -en ""GET / HTTP/1.0\n\n"" | nc 127.0.0.1 443


You still get the same custom 400 back, even if you make an invalid request:

echo -en ""GET foo HTTP/1.0\n\n"" | nc 127.0.0.1 443


Unfortunately for your testing, talking SSL to a non-ssl vhost doesn't result in a 400 of any sort.  I still haven't figured out how to get a custom ErrorDocuemnt 400 to be sent back on port 80.

P.S.  I remember reading somewhere that an ErrorDocument 400 won't work inside a .htaccess file as it may not be possible to even determine the correct DocumentRoot if the request is malformed.  The same probably applies to name based virtualhosts.
",Ladadadada,https://serverfault.com/users/26130,http://serverfault.com/questions/375338,TECHNOLOGY,serverfault.com,0.5,0.5,0.0,0.5,1.0,1.0,0.6666666666666666,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,1.0,0.0,0.0,0.6666666666666666,0.8333333333333334,0.8333333333333334,0.8333333333333334,1.0,0.9,0.0,0.5,0.5,0.8333333333333334,Apache ErrorDocument directive does not work,"I can't get a custom error document to work for 400 Bad Request. It's a CentOS LAMP server.

ErrorDocument 400 /badrdoc.html


I've tried using the above in:


Apache http.conf
Apache httpd-vhosts.conf (in each vhost)
.htaccess in the root htdocs of the site


None of them are working. Apache is serving its default 400 Bad Request page.

Can anyone shed any light on this?

Edit: forgot to mention, I have restarted Apache after changes.
","I had quite some trouble getting a custom 400 error document to work.  I added this to the top level of my Apache conf:

ErrorDocument 404 /404.html
ErrorDocument 400 /400.html


And created the two error documents in the DocumentRoot.  First, I tested the 404 with:

echo -en ""GET /foo HTTP/1.0\n\n"" | nc 127.0.0.1 80


This returned my custom 404.

Then the 400 (Note that the leading slash is missing):

echo -en ""GET foo HTTP/1.0\n\n"" | nc 127.0.0.1 80


The response was the default Apache 400.

I did manage to get my custom 400 back by talking HTTP to an HTTPS vhost:

echo -en ""GET / HTTP/1.0\n\n"" | nc 127.0.0.1 443


You still get the same custom 400 back, even if you make an invalid request:

echo -en ""GET foo HTTP/1.0\n\n"" | nc 127.0.0.1 443


Unfortunately for your testing, talking SSL to a non-ssl vhost doesn't result in a 400 of any sort.  I still haven't figured out how to get a custom ErrorDocuemnt 400 to be sent back on port 80.

P.S.  I remember reading somewhere that an ErrorDocument 400 won't work inside a .htaccess file as it may not be possible to even determine the correct DocumentRoot if the request is malformed.  The same probably applies to name based virtualhosts.
"
1091,1091,1721,What are the implications of Emmet's autonomous movement?,"During The Lego Movie we learn that the whole LEGO world is actually a universe existing within ours, or to be precise, in the basement of a real human family and that the whole story is actually played out by a little boy named Finn and a way for him to cope with the conflict of his strict and fantasy-inhibiting father. And indeed this is again strengthened when we see that the actions as performed by his father when supposedly ""repairing the mess"" that Finn created are directly represented by Lord Business' micromanagers performing them inside the in-universe viewpoint of the other LEGO figures.

Upto this point that is a reasonable and obvious representation to me and even Emmet's direct witness of the universe behind his, our real world, is nothing but him seeing the strips behind the course of his own universe, however he managed to overcome this boundary between dimensions. But the single-most action that completely shatters this whole viewpoint is the incident, when Emmet manages to move completely on his own, thus directly interfering with our universe on his own and it seems to me that there is no way to bring this in congruence to our own physical reality, not even when accepting the LEGO world and its course as an emanation of Finn's fantasy, since Finn didn't do anything at all.

So what are we to make of this incident? Does it have any deeper implications for the depicted realities? Does this establish the LEGO figures as existent and sentient within our physical reality outside of our mere fantasy? Does it have any further signficance for the meaning of the whole story and actually extend the rather simple and obvious kid's fantasy interpretation of the story in a much more elaborate way I have missed? Or is this just to be brushed off as nothing of relevance?
",Napoleon Wilson,https://movies.stackexchange.com/users/49,"The way I took it as that both universes exist side by side (and not subservient to each other) and incidents in one universe affect the other. The causality traffic might seem a bit heavy sided towards Finn's universe being the dominant one, but on closer look you see that this isn't completely true. The Man Upstairs' LEGO policies have certainly shaped Emmet's universe greatly. But Emmet, being Finn's chosen one, has reversed the flow of effects. Not only was he able to cross between his world to Finn's (and back again), but his reformation of President Business has also somehow triggered The Man Upstairs to look differently at his hobby.

In short, Emmet's world is not a fantasy or part of Finn's world, but a distinct one that has a border with Finn's world where cause and effect can cross.
",System Down,https://movies.stackexchange.com/users/29,http://movies.stackexchange.com/questions/27924/what-are-the-implications-of-emmets-autonomous-movement,LIFE_ARTS,movies.stackexchange.com,1.0,0.5555555555555556,0.6666666666666666,0.5,0.3333333333333333,0.0,0.4444444444444444,0.3333333333333333,1.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.0,1.0,0.8888888888888888,What does Emmett's autonomous movement mean?,"During The Lego Movie we learn that the whole LEGO world is actually a universe existing within ours, or to be precise, in the basement of a real human family and that the whole story is actually played out by a little boy named Finn and a way for him to cope with the conflict of his strict and fantasy-inhibiting father. And indeed this is again strengthened when we see that the actions as performed by his father when supposedly ""repairing the mess"" that Finn created are directly represented by Lord Business' micromanagers performing them inside the in-universe viewpoint of the other LEGO figures.

Upto this point that is a reasonable and obvious representation to me and even Emmet's direct witness of the universe behind his, our real world, is nothing but him seeing the strips behind the course of his own universe, however he managed to overcome this boundary between dimensions. But the single-most action that completely shatters this whole viewpoint is the incident, when Emmet manages to move completely on his own, thus directly interfering with our universe on his own and it seems to me that there is no way to bring this in congruence to our own physical reality, not even when accepting the LEGO world and its course as an emanation of Finn's fantasy, since Finn didn't do anything at all.

So what are we to make of this incident? Does it have any deeper implications for the depicted realities? Does this establish the LEGO figures as existent and sentient within our physical reality outside of our mere fantasy? Does it have any further signficance for the meaning of the whole story and actually extend the rather simple and obvious kid's fantasy interpretation of the story in a much more elaborate way I have missed? Or is this just to be brushed off as nothing of relevance?
","The way I took it as that both universes exist side by side (and not subservient to each other) and incidents in one universe affect the other. The causality traffic might seem a bit heavy sided towards Finn's universe being the dominant one, but on closer look you see that this isn't completely true. The Man Upstairs' LEGO policies have certainly shaped Emmet's universe greatly. But Emmet, being Finn's chosen one, has reversed the flow of effects. Not only was he able to cross between his world to Finn's (and back again), but his reformation of President Business has also somehow triggered The Man Upstairs to look differently at his hobby.

In short, Emmet's world is not a fantasy or part of Finn's world, but a distinct one that has a border with Finn's world where cause and effect can cross.
"
1340,1340,2113,Doctors working on Shabbat,"What are some general guidelines regarding the halakhic permissibility for Jewish doctors to work on Shabbat?  I know that saving lives generally overrides Shabbat, but I am curious about less black-and-white situations that may occur on Shabbat, such as having a shift where one must be in the hospital or be on call, receiving medical training, etc.  Also, in a practical halakhic sense, are there any situations in which the appropriateness of violating Shabbat would depend on whether the patients are Jewish?  I'm sure that these are not simple questions and that there are likely multiple opinions on various issues, but some insight into this topic would be welcome.
",Sam,https://judaism.stackexchange.com/users/9,"First of all, being a doctor and healing the sick is not considered a Malacha (work on Shabbos). It is considered a Chachma, a gift, not a trade. See Rambam Hichos Refuah.

There is a fantastic Steera (contradiction) found in the Rambam which points this out. In Hilchos Shabbos, the Rambam holds that one is prohibited from carrying an amulet, since (medically speaking) they are of no use. However, in Hilchos Refuah, Rambam states that one can use (carry) an amulet since the ill person believes in this amulet (an amulet must be considered Mumcha, one which has been proven by healing the sick already), and healing is 60% in the mind, therefore the ill will be healed. As you can hear, the Rambam didn't sound like he was in favor of using tricks or the like. But if it works, any port in the storm!

Next question, is one allowed to transgress the Shabbos to heal a Goy? Technically no. However the Chachamim stressed that if they knew this they would kill us, therefore it is in our best interest to heal them (""משום איבה""). I fear to add this but Halacha is just that.

So, can one heal an animal on Shabbos? Basically no. However, one can make the animal comfortable until a doctor can administer to the animal. There is a wonderful book Sefer Tsar Balay Chaim by R' Itchak Nachman Eshkoli written in the last 10 years which deals with anything &amp; everything to do with animal suffering. My son-in-law used this while writing a paper on Feeding Animals on Shabbos while in YU. I highly recommend this sefer to anyone who has an animal, especially since Tzar Balay Chaim is a Torah Issur and it is important to know what one can or shouldn't do.

Medical Halacha is well researched by the likes of Dr. Fred Rosner, Rabbi Dr. Abraham S Abraham (Nishmas Avraham), and many more. There are many Rabbis who write on medical halacha. Although that is a subject for another time indeed!
",Rabbi Shimon,https://judaism.stackexchange.com/users/7000,http://judaism.stackexchange.com/questions/315/doctors-working-on-shabbat,CULTURE,judaism.stackexchange.com,1.0,0.4444444444444444,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,0.7777777777777778,0.3333333333333333,0.0,1.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,1.0,1.0,0.8333333333333334,0.8888888888888888,1.0,0.8,0.0,0.0,1.0,1.0,Doctor studying Sabat,"What are the general guidelines for halakik's permission for Jewish doctors to work in Sabah? I know that saving lives usually trumps al Shabab, but I'm curious about the black and white situations that may arise in Al Shabab, such as having to change shifts in hospitals or places on call, receiving medical training, etc. Moreover, in the practical sense of harak, is there any case where the appropriateness of violating al Shabab will depend on whether the patient is Jewish or not? I believe these are not simple questions. There may be different opinions on different issues, but some opinions on this topic will be welcomed.","First of all, being a doctor and healing the sick is not considered a Malacha (work on Shabbos). It is considered a Chachma, a gift, not a trade. See Rambam Hichos Refuah.

There is a fantastic Steera (contradiction) found in the Rambam which points this out. In Hilchos Shabbos, the Rambam holds that one is prohibited from carrying an amulet, since (medically speaking) they are of no use. However, in Hilchos Refuah, Rambam states that one can use (carry) an amulet since the ill person believes in this amulet (an amulet must be considered Mumcha, one which has been proven by healing the sick already), and healing is 60% in the mind, therefore the ill will be healed. As you can hear, the Rambam didn't sound like he was in favor of using tricks or the like. But if it works, any port in the storm!

Next question, is one allowed to transgress the Shabbos to heal a Goy? Technically no. However the Chachamim stressed that if they knew this they would kill us, therefore it is in our best interest to heal them (""משום איבה""). I fear to add this but Halacha is just that.

So, can one heal an animal on Shabbos? Basically no. However, one can make the animal comfortable until a doctor can administer to the animal. There is a wonderful book Sefer Tsar Balay Chaim by R' Itchak Nachman Eshkoli written in the last 10 years which deals with anything &amp; everything to do with animal suffering. My son-in-law used this while writing a paper on Feeding Animals on Shabbos while in YU. I highly recommend this sefer to anyone who has an animal, especially since Tzar Balay Chaim is a Torah Issur and it is important to know what one can or shouldn't do.

Medical Halacha is well researched by the likes of Dr. Fred Rosner, Rabbi Dr. Abraham S Abraham (Nishmas Avraham), and many more. There are many Rabbis who write on medical halacha. Although that is a subject for another time indeed!
"
3381,3381,5391,"Can one meet criteria, or satisfy requirements?","I usually see 'satisfy the criteria' and 'meet the requirements', but is it acceptable to use 'meet the criteria', or 'satisfy the requirements'?
",Superstringcheese,https://english.stackexchange.com/users/8909,"I see no problem with using either of the proposed phases. In fact, I think I almost prefer meet the criteria and satisfy the requirements.
",SigueSigueBen,https://english.stackexchange.com/users/15621,http://english.stackexchange.com/questions/67349/can-one-meet-criteria-or-satisfy-requirements,CULTURE,english.stackexchange.com,1.0,0.3333333333333333,0.6666666666666666,1.0,0.3333333333333333,0.6666666666666666,0.4444444444444444,0.5555555555555556,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.6666666666666666,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,0.0,1.0,Can one meet the standard or the requirement?,"I usually see ""meet standards"" and ""meet requirements"", but is it acceptable to use ""meet standards"" or ""meet requirements""?","I see no problem with using either of the proposed phases. In fact, I think I almost prefer meet the criteria and satisfy the requirements.
"
2326,2326,3709,CAML query with Five Condtion throws an Microsoft.Sharepoint.SPException,"         string query = &lt;Where&gt; 
                           &lt;And&gt;    
                              &lt;And&gt;       
                                 &lt;And&gt;          
                                      &lt;Eq&gt;&lt;/Eq&gt;
                                      &lt;Eq&gt;&lt;/Eq&gt;
                                 &lt;/And&gt;
                                   &lt;Geq&gt;&lt;/Geq&gt;
                                   &lt;Leq&gt;&lt;/Leq&gt;
                              &lt;/And&gt;       
                                &lt;Eq&gt;&lt;/Eq&gt;
                           &lt;/And&gt;
                        &lt;/Where&gt;


In SharePoint foundation development, i have used this CAML query to query a SharePoint list. This query contains five conditions. After above query gets executed, it throws an Microsoft.Sharepoint.SPException exception. I tried but couldn't figure it out. Is there any mistake in above CAML query. Any help is appreciated.
",Nera,https://sharepoint.stackexchange.com/users/18118,"I'm in a hurry, to avoid errors in CAML query, try to build the query using CAML Query Builder.

Hope this helps you.
",Karthik Jaganathan,https://sharepoint.stackexchange.com/users/10555,http://sharepoint.stackexchange.com/questions/80642/caml-query-with-five-condtion-throws-an-microsoft-sharepoint-spexception,TECHNOLOGY,sharepoint.stackexchange.com,1.0,0.3333333333333333,0.0,0.0,1.0,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,1.0,1.0,0.3333333333333333,1.0,0.6666666666666666,0.6,1.0,0.0,0.0,1.0,A CAML query with five conditions throws a microsoft.sharepoint.spexception,"         string query = &lt;Where&gt; 
                           &lt;And&gt;    
                              &lt;And&gt;       
                                 &lt;And&gt;          
                                      &lt;Eq&gt;&lt;/Eq&gt;
                                      &lt;Eq&gt;&lt;/Eq&gt;
                                 &lt;/And&gt;
                                   &lt;Geq&gt;&lt;/Geq&gt;
                                   &lt;Leq&gt;&lt;/Leq&gt;
                              &lt;/And&gt;       
                                &lt;Eq&gt;&lt;/Eq&gt;
                           &lt;/And&gt;
                        &lt;/Where&gt;


In SharePoint foundation development, i have used this CAML query to query a SharePoint list. This query contains five conditions. After above query gets executed, it throws an Microsoft.Sharepoint.SPException exception. I tried but couldn't figure it out. Is there any mistake in above CAML query. Any help is appreciated.
","I'm in a hurry, to avoid errors in CAML query, try to build the query using CAML Query Builder.

Hope this helps you.
"
504,504,785,Setting a basic footer to a UITableView,"How is a basic footer set to a UITableView programmatically? 

Just a centered text?

EDIT: 

How can the bar color be set and the footer bar position fixed to the bottom of the screen or if the thumbs dont fill a screen, the footer isnt above the bottom of the screen.


",jarryd,https://stackoverflow.com/users/356387,"You can use UITableViewDataSource callback (just text):

- (NSString *)tableView:(UITableView *)tableView titleForFooterInSection:(NSInteger)section


Or UITableViewDelegate (any custom view you like):

- (UIView *)tableView:(UITableView *)tableView viewForFooterInSection:(NSInteger)section

",Max,https://stackoverflow.com/users/588809,http://stackoverflow.com/questions/5111748/setting-a-basic-footer-to-a-uitableview,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.3333333333333333,0.0,0.5,1.0,1.0,0.5555555555555556,0.4444444444444444,1.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,0.8888888888888888,0.6666666666666666,1.0,0.8888888888888888,0.9,1.0,0.3333333333333333,0.3333333333333333,0.7777777777777778,Set base footer to uitableview,"How is a basic footer set to a UITableView programmatically? 

Just a centered text?

EDIT: 

How can the bar color be set and the footer bar position fixed to the bottom of the screen or if the thumbs dont fill a screen, the footer isnt above the bottom of the screen.


","You can use UITableViewDataSource callback (just text):

- (NSString *)tableView:(UITableView *)tableView titleForFooterInSection:(NSInteger)section


Or UITableViewDelegate (any custom view you like):

- (UIView *)tableView:(UITableView *)tableView viewForFooterInSection:(NSInteger)section

"
1564,1564,2456,Planet orbits: what's the difference between gravity and centripetal force?,"My physics teacher says that centripetal force is caused by gravity. I'm not entirely sure how this works? How can force cause another in space (ie where there's nothing). 

My astronomy teacher says that gravity is (note: not like) a 3D blanket and when you put mass on it, the mass causes a dip/dent in the blanket and so if you put another object with less mass it will roll down the dip onto the bigger mass. Is this true and is this what causes the centripetal force. 
",Jonathan.,https://physics.stackexchange.com/users/4,"A centripetal force is a force directed towards the centre. It's just a characterisation of an existing force. ""Centripetal"" means ""towards the centre"" in Greek.

So, in the solar system, the sun exerts a gravitational force towards itself, and it is a centripetal force.

Regarding your other question: how does gravity work? According to general relativity, energetic or massive objects distort space, so that other objects passing through the distorted space do not go straight, but bend their trajectory. From their point of view, they experience a force (gravity), and consequentially an acceleration which changes their trajectory.
So according to general relativity the medium through which gravity acts is actually the distortion of space.
This is what your astronomy teacher called ""a 3D blanket"".

Instead, according to Quantum Field Theory, forces are mediated by appropriate particles actually moving through space. Gravity would be carried by particles known as gravitons.

In both these theories, there is no action-at-a-distance, so body don't exert forces on one another instantaneously, but there's always something ""in the middle"" that carries or represents the force.
",Sklivvz,https://physics.stackexchange.com/users/66,http://physics.stackexchange.com/questions/321/planet-orbits-whats-the-difference-between-gravity-and-centripetal-force,SCIENCE,physics.stackexchange.com,0.7777777777777778,1.0,0.0,0.0,1.0,1.0,0.6666666666666666,0.5555555555555556,0.3333333333333333,0.0,0.0,0.0,0.6666666666666666,0.0,0.6666666666666666,0.0,0.0,0.0,0.3333333333333333,0.0,0.8888888888888888,0.7777777777777778,0.5555555555555556,0.8888888888888888,1.0,0.5333333333333333,0.0,0.0,0.3333333333333333,0.8888888888888888,Planetary orbit: what's the difference between gravity and centripetal force?,"My physics teacher says that centripetal force is caused by gravity. I'm not entirely sure how this works? How can force cause another in space (ie where there's nothing). 

My astronomy teacher says that gravity is (note: not like) a 3D blanket and when you put mass on it, the mass causes a dip/dent in the blanket and so if you put another object with less mass it will roll down the dip onto the bigger mass. Is this true and is this what causes the centripetal force. 
","A centripetal force is a force directed towards the centre. It's just a characterisation of an existing force. ""Centripetal"" means ""towards the centre"" in Greek.

So, in the solar system, the sun exerts a gravitational force towards itself, and it is a centripetal force.

Regarding your other question: how does gravity work? According to general relativity, energetic or massive objects distort space, so that other objects passing through the distorted space do not go straight, but bend their trajectory. From their point of view, they experience a force (gravity), and consequentially an acceleration which changes their trajectory.
So according to general relativity the medium through which gravity acts is actually the distortion of space.
This is what your astronomy teacher called ""a 3D blanket"".

Instead, according to Quantum Field Theory, forces are mediated by appropriate particles actually moving through space. Gravity would be carried by particles known as gravitons.

In both these theories, there is no action-at-a-distance, so body don't exert forces on one another instantaneously, but there's always something ""in the middle"" that carries or represents the force.
"
611,611,956,jQuery - Adding a hyphen inside string,"I am pulling the text from a select box's options. Now I pass this string value to an append() function, but I want to add a hyphen to the string, for calling an image name:

HTML:

&lt;select&gt;
    &lt;option&gt;Demo Cars&lt;/option&gt;
    &lt;option&gt;New Cars&lt;/option&gt;
    &lt;option&gt;Used Cars&lt;/option&gt;
    &lt;option&gt;Other&lt;/option&gt;
&lt;/select&gt;




var p = 'http://myurl.com/images/';
$('select').eq(0).on('change',function(){
    $('#productQuote').empty();
    var j = $(this).children(':selected').val(); 
    $('#productQuote').append('&lt;img src=""'+ p + j + '.jpg' '"" /&gt;');
}); 


For example:

If I choose the first select option, the string will be: ""Demo Cars"", and thus, j == ""Demo Cars"".

But now I want to call its image, and my image names are not allowed to have spaces inside them. 
So, this begs the question, how do I add a hyphen between Demo and Cars?    
",DextrousDave,https://stackoverflow.com/users/1140828,"Please refer
http://jsfiddle.net/2dJAN/6/

&lt;div class=""btn-post""&gt;button text&lt;/div&gt;
&lt;div id='test'&gt; &lt;/div&gt;


$(document).ready(function(){
 $('#test').html($('.btn-post').text().replace("" "", ""-""));
});


I hope this will helpful to you to achieve your request.
",vinothini,https://stackoverflow.com/users/792302,http://stackoverflow.com/questions/16278701/jquery-adding-a-hyphen-inside-string,STACKOVERFLOW,stackoverflow.com,1.0,0.3333333333333333,0.0,1.0,1.0,1.0,0.6666666666666666,0.7777777777777778,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.7777777777777778,0.4444444444444444,0.7777777777777778,0.7777777777777778,0.7333333333333333,1.0,0.0,0.0,0.7777777777777778,JQuery - add hyphens to strings,"I am pulling the text from a select box's options. Now I pass this string value to an append() function, but I want to add a hyphen to the string, for calling an image name:

HTML:

&lt;select&gt;
    &lt;option&gt;Demo Cars&lt;/option&gt;
    &lt;option&gt;New Cars&lt;/option&gt;
    &lt;option&gt;Used Cars&lt;/option&gt;
    &lt;option&gt;Other&lt;/option&gt;
&lt;/select&gt;




var p = 'http://myurl.com/images/';
$('select').eq(0).on('change',function(){
    $('#productQuote').empty();
    var j = $(this).children(':selected').val(); 
    $('#productQuote').append('&lt;img src=""'+ p + j + '.jpg' '"" /&gt;');
}); 


For example:

If I choose the first select option, the string will be: ""Demo Cars"", and thus, j == ""Demo Cars"".

But now I want to call its image, and my image names are not allowed to have spaces inside them. 
So, this begs the question, how do I add a hyphen between Demo and Cars?    
","Please refer
http://jsfiddle.net/2dJAN/6/

&lt;div class=""btn-post""&gt;button text&lt;/div&gt;
&lt;div id='test'&gt; &lt;/div&gt;


$(document).ready(function(){
 $('#test').html($('.btn-post').text().replace("" "", ""-""));
});


I hope this will helpful to you to achieve your request.
"
4287,4287,6829,How can I do some free design work?,"I am a designer that wants to do some free design work for people, but the problem is, how do I find people to do free work for? Is there any place online?

The reason behind this is that I am good at this, but I don't have any clients, or any previous experience and I am a freelancer, so this would look good on my portfolio.

My skills are very vast and include : 3D, 2D animation, 3D modeling, motion design, stop motion animation,video editing, game design, level design, FluidSIM, illustration, unreal engine 4, graphics design, editorial design, web design and I also know HTML5, CSS, JavaScript and jQuery.



By free work, I mean that the clients don't have to pay a single penny for the work that I do.
",Zach Roschack,https://graphicdesign.stackexchange.com/users/43164,"I started out much like you my friend, I had a lot of talent and skills and no real knowledge of how to put these things to use, obviously I had a little bit of learning to do so what I did in my spare time was contact companies in my local area that I was interested in, and either did some work on my own, and brought it in to ask what they think, or id reach out to them and simply ask them if they needed any work done. This will go a long with in both establishing a client base, or atleast a group of people who are familiar with you and who can provide your name to someone they know needing the services in the future and it will also teach you a lot about how to work with clients, and probably the best part of all, you get to meet new people in your community and lend a helping hand!
",Nick Apromollo,https://graphicdesign.stackexchange.com/users/43110,http://graphicdesign.stackexchange.com/questions/51992/how-can-i-do-some-free-design-work,LIFE_ARTS,graphicdesign.stackexchange.com,1.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.3333333333333333,0.0,0.5555555555555556,0.5555555555555556,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.3333333333333333,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.3333333333333333,0.0,0.3333333333333333,0.6666666666666666,How can I do some free design work?,"I am a designer that wants to do some free design work for people, but the problem is, how do I find people to do free work for? Is there any place online?

The reason behind this is that I am good at this, but I don't have any clients, or any previous experience and I am a freelancer, so this would look good on my portfolio.

My skills are very vast and include : 3D, 2D animation, 3D modeling, motion design, stop motion animation,video editing, game design, level design, FluidSIM, illustration, unreal engine 4, graphics design, editorial design, web design and I also know HTML5, CSS, JavaScript and jQuery.



By free work, I mean that the clients don't have to pay a single penny for the work that I do.
","I like you very much at the beginning, my friend. I have many talents and skills. I don't have real knowledge about how to use these things. Obviously, I have a little learning. What I do in my spare time is to contact the local companies I am interested in, or do some work by myself, and then bring in to ask them how they think, or I contact them to ask if they need to do any work. Whether it's to build a customer base or at least a group of people who are familiar with you, they can provide your name to the people they know need to serve in the future, which will be a long process, it will also teach you how to work with customers, perhaps the best part, you can make new friends in your community and reach out to help!"
5851,5851,9269,Forward slashes: are they acceptable in Commonwealth English prose?,"In Commonwealth English is it acceptable to write this in a magazine article:


  If there are there any nearby towns/villages …

",Wendy,https://english.stackexchange.com/users/24940,"Punctuation of that kind would be unhelpful in any kind of English. It is much clearer to write If there are there any nearby towns or villages or If there are there any nearby towns and villages, as appropriate. What, incidentally, do you mean by ‘Commonwealth English’?
",Barrie England,https://english.stackexchange.com/users/12952,http://english.stackexchange.com/questions/78446/forward-slashes-are-they-acceptable-in-commonwealth-english-prose,CULTURE,english.stackexchange.com,1.0,0.8888888888888888,0.0,1.0,0.6666666666666666,1.0,0.6666666666666666,0.7777777777777778,0.0,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.8666666666666666,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.8888888888888888,Slash: is it acceptable in Commonwealth English prose?,Is writing this article in Commonwealth English acceptable in magazines:,"This kind of punctuation is useless in any kind of English. If there are towns or villages nearby, or there are towns or villages nearby, write more clearly. By the way, what does ""Commonwealth English"" mean?"
2173,2173,3465,Private IP getting routed over Internet,"We are setting up an internal program, on an internal server that uses the private 172.30.x.x subnet... when we ping the address 172.30.138.2, it routes across the internet: 

C:\&gt;tracert 172.30.138.2
Tracing route to 172.30.138.2 over a maximum of 30 hops

  1     6 ms     1 ms     1 ms  xxxx.xxxxxxxxxxxxxxx.org [192.168.28.1]
  2     *        *        *     Request timed out.
  3    12 ms    13 ms     9 ms  xxxxxxxxxxx.xxxxxx.xx.xxx.xxxxxxx.net [68.85.xx.xx]
  4    15 ms    11 ms    55 ms  te-7-3-ar01.salisbury.md.bad.comcast.net [68.87.xx.xx]
  5    13 ms    14 ms    18 ms  xe-11-0-3-0-ar04.capitolhghts.md.bad.comcast.net [68.85.xx.xx]
  6    19 ms    18 ms    14 ms  te-1-0-0-4-cr01.denver.co.ibone.comcast.net [68.86.xx.xx]
  7    28 ms    30 ms    30 ms  pos-4-12-0-0-cr01.atlanta.ga.ibone.comcast.net [68.86.xx.xx]
  8    30 ms    43 ms    30 ms  68.86.xx.xx
  9    30 ms    29 ms    31 ms  172.30.138.2

Trace complete.


This has a number of us confused. If we had a VPN setup, it wouldn't show up as being routed across the internet. If it hit an internet server, Private IP's (such as 192.168) shouldn't get routed.

What would let a private IP address get routed across servers? would the fact that it's all comcast mean that they have their routers setup wrong?
",WernerCD,https://serverfault.com/users/53719,"
  What would let a private IP address get routed across servers?


Let's define what a private IP address is first: It's an address that, by convention, is agreed to not be routed on the Internet. That means that we agree as a community to never advertise those routes over BGP. It also means that that an ISP will probably kill those routes at the borders to their network to prevent them from possibly propagating.

That doesn't mean, however, that a private IP can't cross routers. It is very possible and even highly likely that Comcast uses private IP address ranges for networking equipment that isn't ever supposed to communicate with the Internet as a whole. Those routes may be forwarded by interior routing protocols throughout the entire Comcast network.

All in all, I'm going to guess that it's the case that your router performs NAT translation and then default-routes all traffic that isn't local to the next hop router, including private IP space. It's not very likely, though, that there are many Comcast routers sporting default routes that accidentally go all the way to a responding host with a private IP. It's my strong assumption that this is something purposeful. It might be a temperature sensor with remote monitoring or some other equally innocuous device that never needs to be talked to by anybody outside of Comcast.


  Would the fact that it's all Comcast mean that they have their routers setup wrong?


Since your traceroute shows that all the packets remain within the Comcast network, it's actually not a very surprising circumstance that you've run into. It's staying within a single autonomous system and not violating any standards.
",Jeff Ferland,https://serverfault.com/users/3139,http://serverfault.com/questions/374126,TECHNOLOGY,serverfault.com,0.4444444444444444,0.3333333333333333,0.0,0.3333333333333333,1.0,1.0,0.4444444444444444,0.3333333333333333,1.0,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,1.0,Private IP routed over the Internet,"We are setting up an internal program, on an internal server that uses the private 172.30.x.x subnet... when we ping the address 172.30.138.2, it routes across the internet: 

C:\&gt;tracert 172.30.138.2
Tracing route to 172.30.138.2 over a maximum of 30 hops

  1     6 ms     1 ms     1 ms  xxxx.xxxxxxxxxxxxxxx.org [192.168.28.1]
  2     *        *        *     Request timed out.
  3    12 ms    13 ms     9 ms  xxxxxxxxxxx.xxxxxx.xx.xxx.xxxxxxx.net [68.85.xx.xx]
  4    15 ms    11 ms    55 ms  te-7-3-ar01.salisbury.md.bad.comcast.net [68.87.xx.xx]
  5    13 ms    14 ms    18 ms  xe-11-0-3-0-ar04.capitolhghts.md.bad.comcast.net [68.85.xx.xx]
  6    19 ms    18 ms    14 ms  te-1-0-0-4-cr01.denver.co.ibone.comcast.net [68.86.xx.xx]
  7    28 ms    30 ms    30 ms  pos-4-12-0-0-cr01.atlanta.ga.ibone.comcast.net [68.86.xx.xx]
  8    30 ms    43 ms    30 ms  68.86.xx.xx
  9    30 ms    29 ms    31 ms  172.30.138.2

Trace complete.


This has a number of us confused. If we had a VPN setup, it wouldn't show up as being routed across the internet. If it hit an internet server, Private IP's (such as 192.168) shouldn't get routed.

What would let a private IP address get routed across servers? would the fact that it's all comcast mean that they have their routers setup wrong?
","
  What would let a private IP address get routed across servers?


Let's define what a private IP address is first: It's an address that, by convention, is agreed to not be routed on the Internet. That means that we agree as a community to never advertise those routes over BGP. It also means that that an ISP will probably kill those routes at the borders to their network to prevent them from possibly propagating.

That doesn't mean, however, that a private IP can't cross routers. It is very possible and even highly likely that Comcast uses private IP address ranges for networking equipment that isn't ever supposed to communicate with the Internet as a whole. Those routes may be forwarded by interior routing protocols throughout the entire Comcast network.

All in all, I'm going to guess that it's the case that your router performs NAT translation and then default-routes all traffic that isn't local to the next hop router, including private IP space. It's not very likely, though, that there are many Comcast routers sporting default routes that accidentally go all the way to a responding host with a private IP. It's my strong assumption that this is something purposeful. It might be a temperature sensor with remote monitoring or some other equally innocuous device that never needs to be talked to by anybody outside of Comcast.


  Would the fact that it's all Comcast mean that they have their routers setup wrong?


Since your traceroute shows that all the packets remain within the Comcast network, it's actually not a very surprising circumstance that you've run into. It's staying within a single autonomous system and not violating any standards.
"
2716,2716,4329,"Getting rid of ""Tethering Detected"" popup on Android ICS 4.0?","I just got a Samsung Galaxy S3 that runs Android ICS 4.0.8. When I connect the Galaxy S3 to my Mac laptop and use PDAnet to tether, I often get this popup on the Galaxy S3 screen:



Tethering via PDAnet works great, but the popup can get annoying. I can close the popup, but it comes back a few seconds later. 
How can I get rid of this popup permanently?
",solvingPuzzles,https://android.stackexchange.com/users/25730,"This to me looks like something your provider has added in to stop you getting free tethering on your data plan.

If you are rooted (which I assume you are as you are using a tethering app), then you can attempt to freeze the app that is responsible for this, using an app freezer such as App Quarantine ROOT.

If it isn't an app, then it may be part of the ROM directly, in which case you would have to install a custom ROM such as CyanogenMod. You should look at forums such as XDA-Developers to find a ROM for your device.

Using a custom ROM will definitely remove the message.
",Liam W,https://android.stackexchange.com/users/11209,http://android.stackexchange.com/questions/36313/getting-rid-of-tethering-detected-popup-on-android-ics-4-0,TECHNOLOGY,android.stackexchange.com,1.0,0.8888888888888888,0.0,0.5,1.0,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.8888888888888888,"Remove the ""tether detected"" pop-up on Android ICs 4.0?","I just bought a Samsung Galaxy S3 running Android ICs 4.0.8. When I connect Galaxy S3 to my Mac laptop and use PdaNet connection, I often see such a pop-up window on the galaxy S3 screen:","This to me looks like something your provider has added in to stop you getting free tethering on your data plan.

If you are rooted (which I assume you are as you are using a tethering app), then you can attempt to freeze the app that is responsible for this, using an app freezer such as App Quarantine ROOT.

If it isn't an app, then it may be part of the ROM directly, in which case you would have to install a custom ROM such as CyanogenMod. You should look at forums such as XDA-Developers to find a ROM for your device.

Using a custom ROM will definitely remove the message.
"
5702,5702,9037,Is it better for a beginner to start with black and white photography?,"I'm quite a beginner in photography with no real experience in visual art. I became interested in it about 10 months ago. 

I inferred from the literature to avoid color photography for 2 to 3 years, or until I have a strong feeling for composition. 

It seems reasonable that first you should know to spot your interest in subject and express it on final print, a task in which colors may confuse a beginner. Besides I'm afraid that with no skill of actual seeing and analyzing I may end up with ugly oversaturated and dull images. Is there a professional opinion on subject, or I'm just inventing limitations of my own?
",J-unior,https://photo.stackexchange.com/users/28106,"Quite apart from the historical cost advantage (when using film of course), there's another big advantage
B&amp;W takes away the colour, forcing you to focus your attention on composition and lighting, rather than relying on a brilliant array of colours to hide flaws in those.

I never regretted starting out with black and white film, even though colour film was available (but more expensive at the time). It led me to pay much more attention to composition and light at all times, as well as the cost (which was still high) forcing me to think more before exposing the frame, rather than just shooting off a dozen frames hoping something good would come out.
",jwenting,https://photo.stackexchange.com/users/4000,http://photo.stackexchange.com/questions/56566/is-it-better-for-a-beginner-to-start-with-black-and-white-photography,LIFE_ARTS,photo.stackexchange.com,0.8888888888888888,0.6666666666666666,0.0,0.0,0.0,0.0,0.6666666666666666,0.6666666666666666,1.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.8888888888888888,0.7777777777777778,0.6666666666666666,0.8888888888888888,0.8888888888888888,0.7333333333333333,0.0,0.0,0.6666666666666666,0.8888888888888888,Is it better for beginners to start with black-and-white photography?,"I'm quite a beginner in photography with no real experience in visual art. I became interested in it about 10 months ago. 

I inferred from the literature to avoid color photography for 2 to 3 years, or until I have a strong feeling for composition. 

It seems reasonable that first you should know to spot your interest in subject and express it on final print, a task in which colors may confuse a beginner. Besides I'm afraid that with no skill of actual seeing and analyzing I may end up with ugly oversaturated and dull images. Is there a professional opinion on subject, or I'm just inventing limitations of my own?
","Quite apart from the historical cost advantage (when using film of course), there's another big advantage
B&amp;W takes away the colour, forcing you to focus your attention on composition and lighting, rather than relying on a brilliant array of colours to hide flaws in those.

I never regretted starting out with black and white film, even though colour film was available (but more expensive at the time). It led me to pay much more attention to composition and light at all times, as well as the cost (which was still high) forcing me to think more before exposing the frame, rather than just shooting off a dozen frames hoping something good would come out.
"
3000,3000,4781,Similar phrases meaning 'give kudos',"See, in one of our employee evaluation systems, we would like to implement a feature by which any employee can show appreciation to another employee that he has got help from or whom he thinks to be a good performer, mentor etc., and it has to be done every month. So, to give a name to this action, one of the suggestions was the phrase 'give kudos', but we expect to have a better one with a similar meaning. Something interesting!!

Update: It is not mandatory that we should use the word 'give' or 'kudos'! when we rephrase it.

Can anyone help me on this?
",Rajesh Omanakuttan,https://english.stackexchange.com/users/65374,"Thumbs-up might be fun. They can give out thumbs-up ""cards"" for example, whenever an employee merits one; then add them up at the end of the month. (Much like grade-school teachers give those gold paper stars out to their pupils -or just use those same little stars!) Maybe there could be a small prize or other incentive at the end of the month to make it more interesting?
",W9WBH,https://english.stackexchange.com/users/127818,http://english.stackexchange.com/questions/261789/similar-phrases-meaning-give-kudos,CULTURE,english.stackexchange.com,1.0,1.0,0.0,1.0,0.3333333333333333,0.0,0.8888888888888888,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.8888888888888888,0.8888888888888888,1.0,1.0,0.9333333333333332,0.6666666666666666,0.0,0.0,1.0,"A similar phrase means ""honor to others""","Please see, in one of our employee evaluation systems, we hope to realize a function through which any employee can express his thanks to other employees who have been helped or who he thinks are excellent executors, mentors, etc., and must do so every month. So, to name this action, one of the suggestions is the word ""to honor"", but we hope to have a better one with a similar meaning. Interesting things! !","Thumbs-up might be fun. They can give out thumbs-up ""cards"" for example, whenever an employee merits one; then add them up at the end of the month. (Much like grade-school teachers give those gold paper stars out to their pupils -or just use those same little stars!) Maybe there could be a small prize or other incentive at the end of the month to make it more interesting?
"
3210,3210,5119,Login users/start session with PDO,"Im trying to create a login section on my website using PDO.

So far I've the following...

config.php
    

    // Connect to DB
    $username = 'user@site.co.uk';
    $password = 'pass';

    try {
        $conn = new PDO('mysql:host=localhost;dbname=db', $username, $password);    
        $conn-&gt;setAttribute(PDO::ATTR_ERRMODE, PDO::ERRMODE_EXCEPTION);
        } 
    catch(PDOException $e) {
        echo 'ERROR: ' . $e-&gt;getMessage();
        }

?&gt;


header.php 
    

// DB Config
include '/assets/config.php';

// User Session
$login = 'liam';
$pass = 'password';

$sth = $conn-&gt;prepare(""SELECT * FROM access_users WHERE login = ? AND pass = ?"");
$sth-&gt;bindParam(1, $login);
$sth-&gt;bindParam(2, $pass);
$sth-&gt;execute();

if ($sth-&gt;rowCount() &gt; 0)
{
  // session stuff,
 // refresh page
}  

?&gt;


My browser doesn't display the page however, and when I view my source theres no data contained within, can anybody see where im going wrong? 
",Liam,https://stackoverflow.com/users/766532,"You have set PDO::ERRMODE_EXCEPTION. This means, you should wrap your statements in a try/catch block and test execute()s return code:

try {
    $sth = $conn-&gt;prepare(""SELECT * FROM access_users WHERE login = ? AND pass = ?"");
    $sth-&gt;bindParam(1, $login);
    $sth-&gt;bindParam(2, $pass);
    if (!$sth-&gt;execute()) {
        $info = $sth-&gt;errorInfo();
        echo 'Error: ' . $sth-&gt;errorCode() . ' (' . $info[2] . "")\n"";
    } elseif ($sth-&gt;rowCount() &gt; 0)
    {
        // session stuff,
        // refresh page
    }
} catch (PDOException $e) {
    echo 'Exception: ' . $e-&gt;getMessage() . ""\n"";
}


and put some trace statements in, of course.
",Olaf Dietsche,https://stackoverflow.com/users/1741542,http://stackoverflow.com/questions/13321769/login-users-start-session-with-pdo,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.4444444444444444,0.0,1.0,0.6666666666666666,1.0,0.4444444444444444,0.4444444444444444,0.3333333333333333,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.6666666666666666,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.6666666666666666,1.0,Login user / start session with PDO,"Im trying to create a login section on my website using PDO.

So far I've the following...

config.php
    

    // Connect to DB
    $username = 'user@site.co.uk';
    $password = 'pass';

    try {
        $conn = new PDO('mysql:host=localhost;dbname=db', $username, $password);    
        $conn-&gt;setAttribute(PDO::ATTR_ERRMODE, PDO::ERRMODE_EXCEPTION);
        } 
    catch(PDOException $e) {
        echo 'ERROR: ' . $e-&gt;getMessage();
        }

?&gt;


header.php 
    

// DB Config
include '/assets/config.php';

// User Session
$login = 'liam';
$pass = 'password';

$sth = $conn-&gt;prepare(""SELECT * FROM access_users WHERE login = ? AND pass = ?"");
$sth-&gt;bindParam(1, $login);
$sth-&gt;bindParam(2, $pass);
$sth-&gt;execute();

if ($sth-&gt;rowCount() &gt; 0)
{
  // session stuff,
 // refresh page
}  

?&gt;


My browser doesn't display the page however, and when I view my source theres no data contained within, can anybody see where im going wrong? 
","You have set PDO::ERRMODE_EXCEPTION. This means, you should wrap your statements in a try/catch block and test execute()s return code:

try {
    $sth = $conn-&gt;prepare(""SELECT * FROM access_users WHERE login = ? AND pass = ?"");
    $sth-&gt;bindParam(1, $login);
    $sth-&gt;bindParam(2, $pass);
    if (!$sth-&gt;execute()) {
        $info = $sth-&gt;errorInfo();
        echo 'Error: ' . $sth-&gt;errorCode() . ' (' . $info[2] . "")\n"";
    } elseif ($sth-&gt;rowCount() &gt; 0)
    {
        // session stuff,
        // refresh page
    }
} catch (PDOException $e) {
    echo 'Exception: ' . $e-&gt;getMessage() . ""\n"";
}


and put some trace statements in, of course.
"
3347,3347,5339,Adding custom icon and marker data together using Mapbox,"I am new to mapbox and I have a simple question. I have made a feature layer and a list of custom icons. How do I add the two together?

My feature layer is formatted as below:

L.mapbox.featureLayer({
     ""type"": ""Feature"",
     ""geometry"": {
     ""coordinates"": [
     '.$long.','.$lat.'
     ],
     ""type"": ""Point""
     },
     ""properties"": {
     ""title"": ""'.$business_name.'"",
     ""description"": ""'.$address_1.', '.$address_2.', '.$address_3 .', '.$postcode .'""
     }
     }).addTo(map);


And example of my custom marker is below

var accomodation = L.icon({
    iconUrl: '/img/pins/day-and-night/accommodation.png',
    iconSize: [46, 62],
    iconAnchor: [8, 60],
    });


Any help would be perfect.

Thanks
",Axel Hunter,https://stackoverflow.com/users/2822683,"From your code, I assume you are talking about mapbox.js, which is a derivative of leaflet.js

If so, I think what you are looking for is leaflet layer groups

So, in your case...

var featureLayer = L.mapbox.featureLayer({
   ""type"": ""Feature"",
   ""geometry"": {
   ""coordinates"": [
      '.$long.','.$lat.'
   ],
   ""type"": ""Point""
   },
   ""properties"": {
      ""title"": ""'.$business_name.'"",
      ""description"": ""'.$address_1.', '.$address_2.', '.$address_3 .', '.$postcode .'""
   }
   });

var accomodation = L.icon({
   iconUrl: '/img/pins/day-and-night/accommodation.png',
   iconSize: [46, 62],
   iconAnchor: [8, 60],
});

var layergroup = L.layerGroup([featureLayer, accomodation]);

layergroup.addTo(map);

",dkniffin,https://stackoverflow.com/users/1202488,http://stackoverflow.com/questions/26324752/adding-custom-icon-and-marker-data-together-using-mapbox,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.4444444444444444,0.0,1.0,0.3333333333333333,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,1.0,Use mapbox to add custom icons and tag data together,"I am new to mapbox and I have a simple question. I have made a feature layer and a list of custom icons. How do I add the two together?

My feature layer is formatted as below:

L.mapbox.featureLayer({
     ""type"": ""Feature"",
     ""geometry"": {
     ""coordinates"": [
     '.$long.','.$lat.'
     ],
     ""type"": ""Point""
     },
     ""properties"": {
     ""title"": ""'.$business_name.'"",
     ""description"": ""'.$address_1.', '.$address_2.', '.$address_3 .', '.$postcode .'""
     }
     }).addTo(map);


And example of my custom marker is below

var accomodation = L.icon({
    iconUrl: '/img/pins/day-and-night/accommodation.png',
    iconSize: [46, 62],
    iconAnchor: [8, 60],
    });


Any help would be perfect.

Thanks
","From your code, I assume you are talking about mapbox.js, which is a derivative of leaflet.js

If so, I think what you are looking for is leaflet layer groups

So, in your case...

var featureLayer = L.mapbox.featureLayer({
   ""type"": ""Feature"",
   ""geometry"": {
   ""coordinates"": [
      '.$long.','.$lat.'
   ],
   ""type"": ""Point""
   },
   ""properties"": {
      ""title"": ""'.$business_name.'"",
      ""description"": ""'.$address_1.', '.$address_2.', '.$address_3 .', '.$postcode .'""
   }
   });

var accomodation = L.icon({
   iconUrl: '/img/pins/day-and-night/accommodation.png',
   iconSize: [46, 62],
   iconAnchor: [8, 60],
});

var layergroup = L.layerGroup([featureLayer, accomodation]);

layergroup.addTo(map);

"
3773,3773,6006,Flying and sorcery,"Rashi (Sanhedrin 44b, s.v. D'ba'ya) relates the story of Shimon ben Shetach's capture of 80 witches. He instructed his students to pick up the witches because the sorcery would be powerless against the students if the witches were ungrounded. Is this to say that sorcery does not work unless the practitioner is grounded?

If so, how can we interpret the Midrash (Bamidbar Rabba, 20:20) that states that Bilaam used sorcery to fly through the air?
",Fred,https://judaism.stackexchange.com/users/1442,"Perhaps one need be grounded only to cast the spell (as @DoubleAA said here). If so, Bilaam could have cast the spell on the ground. They were then able to fly, which they did.
",Menachem,https://judaism.stackexchange.com/users/603,http://judaism.stackexchange.com/questions/16216/flying-and-sorcery,CULTURE,judaism.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,0.0,1.0,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,1.0,0.0,1.0,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.8,0.0,0.0,1.0,1.0,Flying and witchcraft,"Sanhedrin 44B (s.v.d'ba'ya) tells the story of Simon Ben shetak's capture of 80 witches. He instructs his students to pick up the witch, because if the witch doesn't, witchcraft can't help the students. Does this mean that unless the practitioner is banned, witchcraft will not work?","Perhaps one need be grounded only to cast the spell (as @DoubleAA said here). If so, Bilaam could have cast the spell on the ground. They were then able to fly, which they did.
"
5942,5942,9416,"Java access to protected member in subclass in different package, using object reference of parent type","I have the following code in two separate files.

package animal;

public class Frog
{
    protected void ribbit()
    {
        System.out.println(""In Frog class!"");
    }
}





package other;

import animal.*;

public class Tadpole extends Frog

{
    protected void ribbit()
    {
        System.out.println(""In Tadpole class!"");
    }

    public static void main(String[] args)
    {
        Tadpole t = new Tadpole();
        t.ribbit();

        Frog f = new Tadpole();
        f.ribbit(); // Does not compile
    }
}


The first Tadpole object assigned to Tadpole type obviously compiles fine and the call to ribbit() will be to the Tadpole's ribbit() implementation. The second Tadpole object that is created and assigned to a Frog reference. However, the call to ribbit() results in a compiler error. 

I know that if you create a subclass object in the subclass and assign to a superclass reference that is outside of the subclass's package and try to call a superclass method, this is not allowed. But in this case, shouldn't polymorphism make the object reference ""f"" call the Tadpole's ribbit() method since a Tadpole object was assigned to it? Why does this cause a compiler error and why is this is not allowed?
",Index Hacker,https://stackoverflow.com/users/1163968,"Protected Access Modifier - Variables, methods and constructors which are declared protected in a superclass can be accessed only by the subclasses in other package or any class within the package of the protected members' class.
",Mohammad tanvirul islam,https://stackoverflow.com/users/2978795,http://stackoverflow.com/questions/31995632/java-access-to-protected-member-in-subclass-in-different-package-using-object-r,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.3333333333333333,0.0,1.0,1.0,0.5,0.6666666666666666,1.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.0,1.0,1.0,Java access to protected members in subclasses of different packages using object references of the parent type,"I have the following code in two separate files.

package animal;

public class Frog
{
    protected void ribbit()
    {
        System.out.println(""In Frog class!"");
    }
}





package other;

import animal.*;

public class Tadpole extends Frog

{
    protected void ribbit()
    {
        System.out.println(""In Tadpole class!"");
    }

    public static void main(String[] args)
    {
        Tadpole t = new Tadpole();
        t.ribbit();

        Frog f = new Tadpole();
        f.ribbit(); // Does not compile
    }
}


The first Tadpole object assigned to Tadpole type obviously compiles fine and the call to ribbit() will be to the Tadpole's ribbit() implementation. The second Tadpole object that is created and assigned to a Frog reference. However, the call to ribbit() results in a compiler error. 

I know that if you create a subclass object in the subclass and assign to a superclass reference that is outside of the subclass's package and try to call a superclass method, this is not allowed. But in this case, shouldn't polymorphism make the object reference ""f"" call the Tadpole's ribbit() method since a Tadpole object was assigned to it? Why does this cause a compiler error and why is this is not allowed?
","Protected access modifier - declare in a superclass that protected variables, methods, and constructors can only be accessed by any class in a subclass or package of a protected member class in another package."
3713,3713,5922,Moving a WP Multisite to a subdirectory,"Firstly, I've read a number of posts on this process. However, for various reasons, the process remains difficult to implement or troubleshoot for lack of even abstracted examples, or maybe too abstracted. And there's a few ""can not do"" posts, nearly always followed up by ""with 3.5, you now can"" caveats, so whether one can remains ambiguous, though no doubt non-trivial.

Summary:

How to move a wordpress multisite (WPMS) from root.com to root/blogs?

For this example, we're moving a WPMS from ""root.com"" to ""root.com/blogs""

I understand that I need to update the paths in the database and wp-config.php appropriately. It seems I may also have to update .htaccess? I'm also aware of the serialization issue with search/replace and mysql query updates.

I have a WPMS that I've updated to 3.5. I've found the following tables with domain and path info

Existing working configuration before move to subdirectory

1. wp_blogs

select blog_id, domain, path from wp_blogs;
+---------+-------------+--------+
| blog_id | domain      | path   |
+---------+-------------+--------+
|       1 | root.com    | /      |
|       2 | root.com    | /matt/ |
+---------+-------------+--------+


2. wp_site

select * in wp_site;
+----+-------------+------+
| id | domain      | path |
+----+-------------+------+
|  1 | root.com    | /    |
+----+-------------+------+


3. The blog_id corresponds to the wp_#_options tables which contain:

select option_name,option_value from wp_2_options 
where option_name = 'home' or option_name = 'siteurl';
+-------------+--------------------------+
| option_name | option_value             |
+-------------+--------------------------+
| home        | http://root.com/matt/    |
| siteurl     | http://root.com/matt/    |
+-------------+--------------------------+


4. In my wp-config.php I have the following WPMS-specific lines:

define('WP_ALLOW_MULTISITE', true);
define( 'MULTISITE', true );
define( 'SUBDOMAIN_INSTALL', false);
$base = '/';
define( 'DOMAIN_CURRENT_SITE', 'root.com' );
define( 'PATH_CURRENT_SITE', '/' );
define( 'SITE_ID_CURRENT_SITE', 1 );
define( 'BLOG_ID_CURRENT_SITE', 1 );


5. Lastly, in my .htaccess, I have:

RewriteEngine On
RewriteBase /
RewriteRule ^index\.php$ - [L]

# uploaded files
RewriteRule ^([_0-9a-zA-Z-]+/)?files/(.+) wp-includes/ms-files.php?file=$2 [L]

# add a trailing slash to /wp-admin
RewriteRule ^([_0-9a-zA-Z-]+/)?wp-admin$ $1wp-admin/ [R=301,L]

RewriteCond %{REQUEST_FILENAME} -f [OR]
RewriteCond %{REQUEST_FILENAME} -d
RewriteRule ^ - [L]
RewriteRule  ^[_0-9a-zA-Z-]+/(wp-(content|admin|includes).*) $1 [L]
RewriteRule  ^[_0-9a-zA-Z-]+/(.*\.php)$ $1 [L]
RewriteRule . index.php [L]


Updates required to move the site

It seems to me that in order to move my site to the /blogs , I would:

1. Update wp_blogs to

mysql&gt; update wp_blogs set domain=concat(domain, '/blogs'), path=concat(path, 'blogs/');
select blog_id, domain, path from wp_blogs where blog_id &lt; 3;
+---------+-------------+--------------+
| blog_id | domain      | path         |
+---------+-------------+--------------+
|       1 | root.com    | /blogs/      |
|       2 | root.com    | /blogs/matt/ |
+---------+-------------+--------------+


2. Update wp_site to

update wp_site set domain=concat(domain, '/blogs'), path=concat(path, 'blogs/');
select * from  wp_site;
+----+-------------+------------+
| id | domain      | path       |
+----+-------------+------------+
|  1 | root.com    | /blogs/    |
+----+-------------+------------+


3. wp_#_options

+-------------+--------------------------------+
| option_name | option_value                   |
+-------------+--------------------------------+
| home        | http://root.com/blogs/matt/    |
| siteurl     | http://root.com/blogs/matt/    |
+-------------+--------------------------------+


4. wp_config.php

define('WP_ALLOW_MULTISITE', true);
define( 'MULTISITE', true );
define( 'SUBDOMAIN_INSTALL', false);
$base = '/blogs/';
define( 'DOMAIN_CURRENT_SITE', 'root.com' );
define( 'PATH_CURRENT_SITE', '/blogs/' );
define( 'SITE_ID_CURRENT_SITE', 1 );
define( 'BLOG_ID_CURRENT_SITE', 1 );


note: I'm not clear how this step is appropriately updated

5. .htaccess

I found vague ""update .htaccess appropriately"" instructions, but not specifics. Update RewriteBase? Which lines in .htaccess to I update when I move root.com to root.com/blogs?

Missing from the above process will be the paths founds in posts. My druthers are to use the search and replace tool for that, after I've made this more fundamental updates; or am I wrong?

Update bungeshea suggests that, yes, I point RewriteBase to the ""blogs"" subdirectory, i.e.,

RewriteBase /Blogs


Finally, if you don't know about http://interconnectit.com/products/search-and-replace-for-wordpress-databases/ you should. It's excellent.
",Screenack,https://wordpress.stackexchange.com/users/18155,"i know its old but i fixed it! i installed WP MU in a subfolder.
htaccess:

RewriteEngine On
RewriteBase /YOUR_SUBFOLDER
RewriteRule ^index\.php$ - [L]

# add a trailing slash to /wp-admin
RewriteRule ^([_0-9a-zA-Z-]+/)?wp-admin$ $1wp-admin/ [R=301,L]

RewriteCond %{REQUEST_FILENAME} -f [OR]
RewriteCond %{REQUEST_FILENAME} -d
RewriteRule ^ - [L]
RewriteRule ^([_0-9a-zA-Z-]+/)?(wp-(content|admin|includes).*) $2 [L]
RewriteRule ^([_0-9a-zA-Z-]+/)?(.*\.php)$ $2 [L]
RewriteRule ^(.*\.php)$ YOUR_SUBFOLDER/$1 [L]
RewriteRule . index.php [L]


wp-config.php

define( 'WP_ALLOW_MULTISITE', true ); 
define('MULTISITE', true);
define('SUBDOMAIN_INSTALL', false);
define('DOMAIN_CURRENT_SITE', 'localhost'); // or your host
define('PATH_CURRENT_SITE', '');
define('SITE_ID_CURRENT_SITE', 1);
define('BLOG_ID_CURRENT_SITE', 1);


wp_site
domain: localhost (OR your domain but no subdirectory!)
path: /

wp_blogs
domain: localhost (OR your domain but no subdirectory in each blog_id!)
path: /

wp_sitemeta
siteurl: http://localhost/YOUR_SUBFOLDER (replace localhost with your host)
",nicmare,https://wordpress.stackexchange.com/users/74101,http://wordpress.stackexchange.com/questions/76913/moving-a-wp-multisite-to-a-subdirectory,TECHNOLOGY,wordpress.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,0.6666666666666666,0.3333333333333333,1.0,0.5555555555555556,0.3333333333333333,0.6666666666666666,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,0.8888888888888888,Move WP multisite to subdirectory,"Firstly, I've read a number of posts on this process. However, for various reasons, the process remains difficult to implement or troubleshoot for lack of even abstracted examples, or maybe too abstracted. And there's a few ""can not do"" posts, nearly always followed up by ""with 3.5, you now can"" caveats, so whether one can remains ambiguous, though no doubt non-trivial.

Summary:

How to move a wordpress multisite (WPMS) from root.com to root/blogs?

For this example, we're moving a WPMS from ""root.com"" to ""root.com/blogs""

I understand that I need to update the paths in the database and wp-config.php appropriately. It seems I may also have to update .htaccess? I'm also aware of the serialization issue with search/replace and mysql query updates.

I have a WPMS that I've updated to 3.5. I've found the following tables with domain and path info

Existing working configuration before move to subdirectory

1. wp_blogs

select blog_id, domain, path from wp_blogs;
+---------+-------------+--------+
| blog_id | domain      | path   |
+---------+-------------+--------+
|       1 | root.com    | /      |
|       2 | root.com    | /matt/ |
+---------+-------------+--------+


2. wp_site

select * in wp_site;
+----+-------------+------+
| id | domain      | path |
+----+-------------+------+
|  1 | root.com    | /    |
+----+-------------+------+


3. The blog_id corresponds to the wp_#_options tables which contain:

select option_name,option_value from wp_2_options 
where option_name = 'home' or option_name = 'siteurl';
+-------------+--------------------------+
| option_name | option_value             |
+-------------+--------------------------+
| home        | http://root.com/matt/    |
| siteurl     | http://root.com/matt/    |
+-------------+--------------------------+


4. In my wp-config.php I have the following WPMS-specific lines:

define('WP_ALLOW_MULTISITE', true);
define( 'MULTISITE', true );
define( 'SUBDOMAIN_INSTALL', false);
$base = '/';
define( 'DOMAIN_CURRENT_SITE', 'root.com' );
define( 'PATH_CURRENT_SITE', '/' );
define( 'SITE_ID_CURRENT_SITE', 1 );
define( 'BLOG_ID_CURRENT_SITE', 1 );


5. Lastly, in my .htaccess, I have:

RewriteEngine On
RewriteBase /
RewriteRule ^index\.php$ - [L]

# uploaded files
RewriteRule ^([_0-9a-zA-Z-]+/)?files/(.+) wp-includes/ms-files.php?file=$2 [L]

# add a trailing slash to /wp-admin
RewriteRule ^([_0-9a-zA-Z-]+/)?wp-admin$ $1wp-admin/ [R=301,L]

RewriteCond %{REQUEST_FILENAME} -f [OR]
RewriteCond %{REQUEST_FILENAME} -d
RewriteRule ^ - [L]
RewriteRule  ^[_0-9a-zA-Z-]+/(wp-(content|admin|includes).*) $1 [L]
RewriteRule  ^[_0-9a-zA-Z-]+/(.*\.php)$ $1 [L]
RewriteRule . index.php [L]


Updates required to move the site

It seems to me that in order to move my site to the /blogs , I would:

1. Update wp_blogs to

mysql&gt; update wp_blogs set domain=concat(domain, '/blogs'), path=concat(path, 'blogs/');
select blog_id, domain, path from wp_blogs where blog_id &lt; 3;
+---------+-------------+--------------+
| blog_id | domain      | path         |
+---------+-------------+--------------+
|       1 | root.com    | /blogs/      |
|       2 | root.com    | /blogs/matt/ |
+---------+-------------+--------------+


2. Update wp_site to

update wp_site set domain=concat(domain, '/blogs'), path=concat(path, 'blogs/');
select * from  wp_site;
+----+-------------+------------+
| id | domain      | path       |
+----+-------------+------------+
|  1 | root.com    | /blogs/    |
+----+-------------+------------+


3. wp_#_options

+-------------+--------------------------------+
| option_name | option_value                   |
+-------------+--------------------------------+
| home        | http://root.com/blogs/matt/    |
| siteurl     | http://root.com/blogs/matt/    |
+-------------+--------------------------------+


4. wp_config.php

define('WP_ALLOW_MULTISITE', true);
define( 'MULTISITE', true );
define( 'SUBDOMAIN_INSTALL', false);
$base = '/blogs/';
define( 'DOMAIN_CURRENT_SITE', 'root.com' );
define( 'PATH_CURRENT_SITE', '/blogs/' );
define( 'SITE_ID_CURRENT_SITE', 1 );
define( 'BLOG_ID_CURRENT_SITE', 1 );


note: I'm not clear how this step is appropriately updated

5. .htaccess

I found vague ""update .htaccess appropriately"" instructions, but not specifics. Update RewriteBase? Which lines in .htaccess to I update when I move root.com to root.com/blogs?

Missing from the above process will be the paths founds in posts. My druthers are to use the search and replace tool for that, after I've made this more fundamental updates; or am I wrong?

Update bungeshea suggests that, yes, I point RewriteBase to the ""blogs"" subdirectory, i.e.,

RewriteBase /Blogs


Finally, if you don't know about http://interconnectit.com/products/search-and-replace-for-wordpress-databases/ you should. It's excellent.
","i know its old but i fixed it! i installed WP MU in a subfolder.
htaccess:

RewriteEngine On
RewriteBase /YOUR_SUBFOLDER
RewriteRule ^index\.php$ - [L]

# add a trailing slash to /wp-admin
RewriteRule ^([_0-9a-zA-Z-]+/)?wp-admin$ $1wp-admin/ [R=301,L]

RewriteCond %{REQUEST_FILENAME} -f [OR]
RewriteCond %{REQUEST_FILENAME} -d
RewriteRule ^ - [L]
RewriteRule ^([_0-9a-zA-Z-]+/)?(wp-(content|admin|includes).*) $2 [L]
RewriteRule ^([_0-9a-zA-Z-]+/)?(.*\.php)$ $2 [L]
RewriteRule ^(.*\.php)$ YOUR_SUBFOLDER/$1 [L]
RewriteRule . index.php [L]


wp-config.php

define( 'WP_ALLOW_MULTISITE', true ); 
define('MULTISITE', true);
define('SUBDOMAIN_INSTALL', false);
define('DOMAIN_CURRENT_SITE', 'localhost'); // or your host
define('PATH_CURRENT_SITE', '');
define('SITE_ID_CURRENT_SITE', 1);
define('BLOG_ID_CURRENT_SITE', 1);


wp_site
domain: localhost (OR your domain but no subdirectory!)
path: /

wp_blogs
domain: localhost (OR your domain but no subdirectory in each blog_id!)
path: /

wp_sitemeta
siteurl: http://localhost/YOUR_SUBFOLDER (replace localhost with your host)
"
2360,2360,3762,Any disadvantages to single-supply mode?,"I am using the ATMEL ARM SAM4S MCU for a project. It supports a single-supply mode where an internal voltage regulator provides the 1.08-1.32V necessary for VDDCORE and we need only provide 1.62-3.6V to VDDIO. 

I'm just interested to know if there is any situation where one might NOT take advantage of this feature and supply the core externally as well?
",routeburn,https://electronics.stackexchange.com/users/11097,"The main reason would be for power efficiency. The voltage regulator inside the chip is a linear one, which means that its efficiency is: (VDDCORE/VDDIO). So if your VDDIO is 3.6v, then your efficiency might be only 33%! This is a terrible waste of energy, especially in a battery powered portable device where a long battery life is an important selling point for the device.

Poor power efficiency not only leads to a shorter battery life, it also generates heat. In this case it doesn't seem like much, but it can make all the difference. In a hot environment, that extra heat might push the chip over its specified operating conditions, leading to failure. In some applications, you might have lots of chips, which could create quite a lot of heat. In one application, we had 20 ET1200 chips, all using their internal regulators. Each chip's core uses just 75mA. But 20 chips means 1.5A on the cores, and a total of 1.2W of power dissipated just as wasted heat. The inside of the enclosure got pretty hot.
",Rocketmagnet,https://electronics.stackexchange.com/users/1024,http://electronics.stackexchange.com/questions/59820/any-disadvantages-to-single-supply-mode,TECHNOLOGY,electronics.stackexchange.com,1.0,0.5555555555555556,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.6666666666666666,1.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,1.0,What are the disadvantages of single power supply mode?,"I use ATMEL arm sam4s MCU in a project. It supports single power mode, in which the internal voltage regulator provides 1.08-1.32v voltage required by vddcore, and we only need to provide 1.62-3.6v voltage to VDDIO.","The main reason would be for power efficiency. The voltage regulator inside the chip is a linear one, which means that its efficiency is: (VDDCORE/VDDIO). So if your VDDIO is 3.6v, then your efficiency might be only 33%! This is a terrible waste of energy, especially in a battery powered portable device where a long battery life is an important selling point for the device.

Poor power efficiency not only leads to a shorter battery life, it also generates heat. In this case it doesn't seem like much, but it can make all the difference. In a hot environment, that extra heat might push the chip over its specified operating conditions, leading to failure. In some applications, you might have lots of chips, which could create quite a lot of heat. In one application, we had 20 ET1200 chips, all using their internal regulators. Each chip's core uses just 75mA. But 20 chips means 1.5A on the cores, and a total of 1.2W of power dissipated just as wasted heat. The inside of the enclosure got pretty hot.
"
5376,5376,8537,Most effective way to increase programmer salary besides just doing your job?,"If you have the time and resources, what would be the most effective way to increase your salary as a full-time programmer, outside of just doing your job? 

By ""salary"" here, I mean salary (adjusted for location cost-of-living) coming from a single programming job. 
",T. Webster,https://programmers.stackexchange.com/users/19936,"There are broadly 4 ways:

Build Seniority

If you're happy with your current company and want to stay there, a good way to be able to demand more is to become the senior resident expert at a vital technology and/or internal code base. I've watched people do this at several companies I've worked at. They became so obviously and publicly super-productive and good at what they do (and the thing they do was important) that they naturally gained a ""senior"" status - even without necessarily getting team leading or managerial responsibility per se.

I can only presume that they had more ammunition to ask for better raises at performance review time, and for some I knew for a fact that they were better paid than average.

Also, see this answer.

Change Employers

This is essentially this answer. You have to be careful with this one though. Lots of very short stints don't look good on a CV, even if there are reasonably good explanations for the moves. For contracts with fixed terms, it's not so bad, but you don't want to have a whole string of permanent salaried positions on your CV that are all under 1-2 years or so. 3-4 years and up is probably okay though, as an average.

Go Contracting/Consulting

This one is, in a way, Change Employers on steroids. If you find a good niche which has a shortage of qualified engineers and quite a bit of short term project work that needs doing, this can be an excellent option. But it's quite a different mindset and lifestyle than having normal permanent salaried jobs (I've never done it personally, but I've known lots of people who did). 

Vertical Movement

I know you asked about ""programmer salary"", but it still feels like this is obligatory to mention. Rising to team leader and/or management roles is always a possible option. Note that this is often tied with the first option (Gain Seniority), but it doesn't always have to be. Sometimes it's a natural byproduct of being at a company long enough, taking ownership of things you were working on, and knowing all the people and processes well.
",Bobby Tables,https://programmers.stackexchange.com/users/5064,http://programmers.stackexchange.com/questions/76254/most-effective-way-to-increase-programmer-salary-besides-just-doing-your-job,TECHNOLOGY,programmers.stackexchange.com,1.0,1.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.6666666666666666,0.5555555555555556,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,1.0,"In addition to work, what is the most effective way to raise the salary of programmers?","If you have time and resources, what is the most effective way to increase your salary as a full-time programmer besides doing your job?","There are broadly 4 ways:

Build Seniority

If you're happy with your current company and want to stay there, a good way to be able to demand more is to become the senior resident expert at a vital technology and/or internal code base. I've watched people do this at several companies I've worked at. They became so obviously and publicly super-productive and good at what they do (and the thing they do was important) that they naturally gained a ""senior"" status - even without necessarily getting team leading or managerial responsibility per se.

I can only presume that they had more ammunition to ask for better raises at performance review time, and for some I knew for a fact that they were better paid than average.

Also, see this answer.

Change Employers

This is essentially this answer. You have to be careful with this one though. Lots of very short stints don't look good on a CV, even if there are reasonably good explanations for the moves. For contracts with fixed terms, it's not so bad, but you don't want to have a whole string of permanent salaried positions on your CV that are all under 1-2 years or so. 3-4 years and up is probably okay though, as an average.

Go Contracting/Consulting

This one is, in a way, Change Employers on steroids. If you find a good niche which has a shortage of qualified engineers and quite a bit of short term project work that needs doing, this can be an excellent option. But it's quite a different mindset and lifestyle than having normal permanent salaried jobs (I've never done it personally, but I've known lots of people who did). 

Vertical Movement

I know you asked about ""programmer salary"", but it still feels like this is obligatory to mention. Rising to team leader and/or management roles is always a possible option. Note that this is often tied with the first option (Gain Seniority), but it doesn't always have to be. Sometimes it's a natural byproduct of being at a company long enough, taking ownership of things you were working on, and knowing all the people and processes well.
"
5168,5168,8211,Finding columns that do not match existing primary key,"I'm trying to add a Foreign Key to a table, but database, Sql Server 2005, does not like it.

It says that columns do not match an existing primary key or unique constraint. 

How can I find the columns in question so I can delete/change them and add the foreign key?
",Chin,https://stackoverflow.com/users/135687,"SELECT *
  FROM FK_Table
 WHERE ForeignKey NOT IN (SELECT PrimaryKey FROM PK_Table);


This works as written for single-column keys.  It can also work for multi-column keys if your DBMS allows the notation:

SELECT *
  FROM FK_Table
 WHERE (FK_Col1, FK_Col2) NOT IN (SELECT PK_Col1, PK_Col2 FROM PK_Table);


Not every DBMS supports this, though.  This formulation with NOT EXISTS should work most places:

SELECT *
  FROM FK_Table
 WHERE NOT EXISTS (SELECT 1
                     FROM PK_Table
                     WHERE FK_Col1 = PK_Col1 AND FK_Col2 = PK_Col2
                  );

",Jonathan Leffler,https://stackoverflow.com/users/15168,http://stackoverflow.com/questions/1178377/finding-columns-that-do-not-match-existing-primary-key,STACKOVERFLOW,stackoverflow.com,1.0,0.5555555555555556,0.0,1.0,0.6666666666666666,1.0,0.6666666666666666,0.4444444444444444,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,0.8888888888888888,Find columns that do not match the existing primary key,"I'm trying to add a Foreign Key to a table, but database, Sql Server 2005, does not like it.

It says that columns do not match an existing primary key or unique constraint. 

How can I find the columns in question so I can delete/change them and add the foreign key?
","SELECT *
  FROM FK_Table
 WHERE ForeignKey NOT IN (SELECT PrimaryKey FROM PK_Table);


This works as written for single-column keys.  It can also work for multi-column keys if your DBMS allows the notation:

SELECT *
  FROM FK_Table
 WHERE (FK_Col1, FK_Col2) NOT IN (SELECT PK_Col1, PK_Col2 FROM PK_Table);


Not every DBMS supports this, though.  This formulation with NOT EXISTS should work most places:

SELECT *
  FROM FK_Table
 WHERE NOT EXISTS (SELECT 1
                     FROM PK_Table
                     WHERE FK_Col1 = PK_Col1 AND FK_Col2 = PK_Col2
                  );

"
463,463,719,GIS Software Choice for a small university research centre,"I need to choose a GIS system for a small university research centre. We are handling a broad range of data, (for example, numerical tidal analyses, weather data, poverty, isolated economic activity, skills availability and renewable energy resource availability) and operate primarily in countries with relatively poor existing data sets. 

We interact with other groups, some of which use ARCGIS. Do I have to wade through every GIS software descriptor on the web, or can someone please give an indication of likely candidates? 
",Alan Owen,https://gis.stackexchange.com/users/8127,"Since most have mentioned open-source such as GRASS, I'll assume you have a few thousand for annual licenses within your department.  Excelis ENVI+IDL, ERDAS Imagine, and possibly ArcGis Desktop (ArcInfo 10.1).  Envi, Imagine, and ArcGis Desktop are all major, international providers of GIS software.  Imagine is said to be the rosetta stone of GIS as it interfaces with just about every GIS format imaginable.  I'm most familiar with ENVI+IDL myself and have had a good experience with it.  There are also several, smaller utilities available that are free and useful.  HDFView, Freelook (which is a free version of envi that's hard to find nowadays), Corpscon, 6S, etc.  You'll have to prioritize and look at pricing as well as features &amp; functionalities of each option.  Good luck!
",nhunsaker,https://gis.stackexchange.com/users/9302,http://gis.stackexchange.com/questions/27188/gis-software-choice-for-a-small-university-research-centre,TECHNOLOGY,gis.stackexchange.com,1.0,0.6666666666666666,0.0,0.0,1.0,0.0,0.6666666666666666,0.5,0.0,0.0,1.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.8,0.0,0.0,1.0,1.0,Selection of GIS software for research center of small University,"I need to choose a geographic information system for a small university research center. We are working on a wide range of data (e.g., numerical tidal analysis, weather data, poverty, isolated economic activity, skill availability and renewable energy availability), mainly in countries with relatively poor existing data sets.","Since most have mentioned open-source such as GRASS, I'll assume you have a few thousand for annual licenses within your department.  Excelis ENVI+IDL, ERDAS Imagine, and possibly ArcGis Desktop (ArcInfo 10.1).  Envi, Imagine, and ArcGis Desktop are all major, international providers of GIS software.  Imagine is said to be the rosetta stone of GIS as it interfaces with just about every GIS format imaginable.  I'm most familiar with ENVI+IDL myself and have had a good experience with it.  There are also several, smaller utilities available that are free and useful.  HDFView, Freelook (which is a free version of envi that's hard to find nowadays), Corpscon, 6S, etc.  You'll have to prioritize and look at pricing as well as features &amp; functionalities of each option.  Good luck!
"
2658,2658,4230,How to prevent empty page after \maketitle?,"I have a few pages that I've texed. I wanted to start the document with a title page but if I do that it produces an empty page numbered '1' between the title page and the first section. How to prevent that? I tried document classes report, article and book, \maketitle as well as \begin{titlepage}/ \end{titlepage}.
 The code looks like this:

\documentclass{report}
\usepackage{amsmath}
\usepackage{amssymb}
\begin{document}
\textwidth 13cm
\title{Author: My title}
\author{a. name}
\maketitle
\hfill
\chapter{Chapter title}
\section{section title}
\end{document}


Thanks for your help.
",Matt N.,https://tex.stackexchange.com/users/18640,"Remove \hfill.

\documentclass{report}
\usepackage{amsmath}
\usepackage{amssymb}
\begin{document}
\textwidth 13cm
\title{Author: My title}
\author{a. name}
\maketitle
% \hfill
\chapter{Chapter title}
\section{section title}
\end{document}


EDIT: If you also want to align the title near the top of the page, follow Marco Daniel's advice and use the notitlepage class option. (You may still remove \hfill in that case.) Note that the page containing the title will be numbered as ""1"", and the first chapter will start at page 2.
",lockstep,https://tex.stackexchange.com/users/510,http://tex.stackexchange.com/questions/83226/how-to-prevent-empty-page-after-maketitle,TECHNOLOGY,tex.stackexchange.com,0.6666666666666666,0.8333333333333334,0.0,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.5,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,0.8333333333333334,1.0,0.9,0.5,0.5,0.0,1.0,"How to prevent blank pages after ""\ maketitle""?","I have a few pages. I want to start the document with a title page, but if I do, it will generate an empty page numbered ""1"" between the title page and the first section. How to prevent? I tried the document classes report, article and book, maketitle, and begin {titlepage} / \ end {titlepage}.","Remove \hfill.

\documentclass{report}
\usepackage{amsmath}
\usepackage{amssymb}
\begin{document}
\textwidth 13cm
\title{Author: My title}
\author{a. name}
\maketitle
% \hfill
\chapter{Chapter title}
\section{section title}
\end{document}


EDIT: If you also want to align the title near the top of the page, follow Marco Daniel's advice and use the notitlepage class option. (You may still remove \hfill in that case.) Note that the page containing the title will be numbered as ""1"", and the first chapter will start at page 2.
"
4353,4353,6928,Get REQUEST_URI and don't overwrite,"I tried storing the REQUEST_URI in a session with the code below. I need to store the very first REQUEST_URI when a visitor lands on a page on our site and not have it overwritten when they begin browsing pages. This isn't working as I browse the site i'm seeing a new URI displayed by the echo.

session_start();
if ( !isset( $_SESSION['theuri'] ) ) {
    if ( !empty( $_SERVER['REQUEST_URI'] ) ) {
        $_SESSION['theuri'] = $_SERVER['REQUEST_URI'];
    }
}

echo $_SESSION['theuri'];

",Anagio,https://stackoverflow.com/users/804087,"Clear your cookie and try again.  It was probably set the first time when you never had the !empty() conditional and never changed since
",fmrk,https://stackoverflow.com/users/2029710,http://stackoverflow.com/questions/14636716/get-request-uri-and-dont-overwrite,STACKOVERFLOW,stackoverflow.com,1.0,0.3333333333333333,0.0,1.0,0.6666666666666666,1.0,0.6666666666666666,0.4444444444444444,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,0.9,1.0,0.0,1.0,0.8888888888888888,Get request URI and do not overwrite,"I try to store the request URI in the session with the following code. When visitors log on to a page of our website, I need to store the first request URI and do not overwrite it when they start browsing the page. This doesn't work because I'm browsing the site and I see an echo of a new URI display.",Clear your cookies and try again. It may have been set the first time you didn't! Empty() conditional and self

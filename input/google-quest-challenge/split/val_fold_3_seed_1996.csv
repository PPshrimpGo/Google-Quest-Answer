,Unnamed: 0,qa_id,question_title,question_body,question_user_name,question_user_page,answer,answer_user_name,answer_user_page,url,category,host,question_asker_intent_understanding,question_body_critical,question_conversational,question_expect_short_answer,question_fact_seeking,question_has_commonly_accepted_answer,question_interestingness_others,question_interestingness_self,question_multi_intent,question_not_really_a_question,question_opinion_seeking,question_type_choice,question_type_compare,question_type_consequence,question_type_definition,question_type_entity,question_type_instructions,question_type_procedure,question_type_reason_explanation,question_type_spelling,question_well_written,answer_helpful,answer_level_of_information,answer_plausible,answer_relevance,answer_satisfaction,answer_type_instructions,answer_type_procedure,answer_type_reason_explanation,answer_well_written,t_aug,q_aug,a_aug
723,723,1147,"Clicking ""Add comment"" fails review audit","I just failed these review audits in First Post, I read the question and thought it seemed reasonable but the user was deleted so to be on the safe side I clicked add comment and I failed the audit.

I'm not sure why adding a comment would be considered a negative action, is the correct option to click No Action Needed or edit?

What was I supposed to do in this situation?  Adding a comment should not be a review audit fail.
",Aboutblank,https://meta.stackexchange.com/users/214833,"I understand the problem with people cheating the first post review audits by simply clicking the add comment button, but there really has to be a more graceful way to handle it.

It should be as simple as forcing the person to actually write the comment and submit it which will make it less abusable, and if they are abusing the system, they'll be caught quick because they'll actually be posting their (presumably canned) comments on real questions.

and if the comments actually aren't canned and relevant to the question anyway, than it's really not that harmful that people are doing it.

Both edit and add comment are neutral actions, and it doesn't make sense for someone to fail an audit regardless of whether the post is good or bad(unless it's a blatant spam post or something)
",Sam I am,https://meta.stackexchange.com/users/181798,http://meta.stackexchange.com/questions/188885/clicking-add-comment-fails-review-audit,TECHNOLOGY,meta.stackexchange.com,0.6666666666666666,1.0,0.0,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,1.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,0.6666666666666666,1.0,0.6666666666666666,1.0,0.6,1.0,0.0,1.0,1.0,"Click ""add comment"" to review failed","I just failed to pass these reviews in the first article. I read this question and thought it seemed reasonable, but the user was deleted, so for the sake of security, I clicked to add comments, and I failed to pass the review.","I understand the problem with people cheating the first post review audits by simply clicking the add comment button, but there really has to be a more graceful way to handle it.

It should be as simple as forcing the person to actually write the comment and submit it which will make it less abusable, and if they are abusing the system, they'll be caught quick because they'll actually be posting their (presumably canned) comments on real questions.

and if the comments actually aren't canned and relevant to the question anyway, than it's really not that harmful that people are doing it.

Both edit and add comment are neutral actions, and it doesn't make sense for someone to fail an audit regardless of whether the post is good or bad(unless it's a blatant spam post or something)
"
5669,5669,8990,How can pKas differ across similar protons of the same atom?,"For example, citric acid has three acidic protons, all of which are carboxylic acids. Despite being part of the same functional groups, they all have very different pKas. Why (and how?) is this?
",peglegosaurus,https://chemistry.stackexchange.com/users/13183,"Let's begin this discussion with the simpler oxalic acid.  

     O
     #
HO-C-C-OH
   #
   O


There are two carboxylic acid functional groups, and there are two different pKa's.  This is because double deprotonation does not happen simulateneously.  One gets deprotonated first, then the other.  After the first deprotonation, the residual molecule has a negative charge.  The result:

     O
     #
HO-C-C-O~
   #
   O


Is much less acidic because the presences of the carboxylate functional group changes the acidity.

Let's continue the discussion with the (still simpler) alpha-chlorosuccinic acid:

    Cl H O
     | | #
HO-C-C-C-C-OH
   # | |
   O H H


The acid closer to the chlorine is more acidic because the chlorine is strongly electron withdrawing, and 'pulls' the electrons out of the carboxylate function, which then 'pulls' electrons away from the hydrogen, making it more acidic.  This effect decreases with distance, so the chlorine pulls on the acid function farther away less strongly.

In a more generalized way, remote groups will modify acidity because of electron withdrawing or donating effects, but the farther away from the acid function, the less effect there is.

For citric acid, there are actually two different flavors of acid function, so one of the kinds will be intrinsically more acidic before deprotonation because of the remove effect.  However, because of the sequential deprotonation discussed above, all three will have different pKa's
",Lighthart,https://chemistry.stackexchange.com/users/1285,http://chemistry.stackexchange.com/questions/26366/how-can-pkas-differ-across-similar-protons-of-the-same-atom,SCIENCE,chemistry.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,0.6666666666666666,0.6666666666666666,1.0,0.5555555555555556,0.4444444444444444,0.6666666666666666,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.3333333333333333,1.0,0.8888888888888888,What's the difference in pKas between protons of the same atom?,"For example, citric acid has three acid protons, all of which are carboxylic acids. Although they are part of the same functional group, their pKas are very different. Why (and how?) Is that right?","Let's begin this discussion with the simpler oxalic acid.  

     O
     #
HO-C-C-OH
   #
   O


There are two carboxylic acid functional groups, and there are two different pKa's.  This is because double deprotonation does not happen simulateneously.  One gets deprotonated first, then the other.  After the first deprotonation, the residual molecule has a negative charge.  The result:

     O
     #
HO-C-C-O~
   #
   O


Is much less acidic because the presences of the carboxylate functional group changes the acidity.

Let's continue the discussion with the (still simpler) alpha-chlorosuccinic acid:

    Cl H O
     | | #
HO-C-C-C-C-OH
   # | |
   O H H


The acid closer to the chlorine is more acidic because the chlorine is strongly electron withdrawing, and 'pulls' the electrons out of the carboxylate function, which then 'pulls' electrons away from the hydrogen, making it more acidic.  This effect decreases with distance, so the chlorine pulls on the acid function farther away less strongly.

In a more generalized way, remote groups will modify acidity because of electron withdrawing or donating effects, but the farther away from the acid function, the less effect there is.

For citric acid, there are actually two different flavors of acid function, so one of the kinds will be intrinsically more acidic before deprotonation because of the remove effect.  However, because of the sequential deprotonation discussed above, all three will have different pKa's
"
3750,3750,5974,Techniques for creating melodies,"I've posted this question:

Learning to create melodies

I've got a few ideas of techniques towards creating melodies but wanted to ask if there are any specific methods to help get better. I've read: The Complete's Idiot's Guide To Music Composition which explained a lot of details but I still find it difficult to create something 'good', whenever I play on my keyboard, it sounds rubbish. Is it something that comes with ample practice? What can I do to become better?
",MJohnson52,https://music.stackexchange.com/users/12211,"In my experience, unfortunately, writing melodies is one of the most ""magical"" parts of writing music. Some melodies just sound great, some just don't. There are, however, a few things to keep in mind that can help you deliberately write a melody for a particular emotion or style and help you understand why a particular melody sounds good.

Intervallic and Stepwise Motion:
Some melodies have large jumps in-between consecutive notes, and others move up or down consecutive notes in a scale. The former usually sounds more grand, especially with slow rhythms, and the latter, smoother.

Rising and Falling Motion:
Whether the notes in a melody generally get higher, get lower, or stay in the same range can have a big effect on the melody's emotion.

Rhythm:
The melody you pick for a rhythm makes a huge difference. Is it syncopated or straight? Fast or slow? Complex or simple? Does it use distinctive tricks like hemiola or tuplets? What beats does it start and end on?

Instrumentation:
In my experience, the instrument playing a melody makes a big difference. In one electronic song I've heard, the main melody is played by a number of bold, powerful synths, giving the melody a driving emotion. Then, at the end of the song, a lone acoustic guitar plays the same melody, which suddenly becomes very sad.

Major/Minor Quality:
Of course, whether a melody is written in a major or minor key makes a big difference.

And the list can go on forever: tonal center, articulation, etc. The important thing isn't that every melody can be broken apart like this. Instead, you can pick out a few qualities you know you would like a melody to have based on which emotion you want to portray.

For example, perhaps you need to write the leitmotif for the bad guy. It's probably going to be in a minor key, because he's so evil. Likewise, it might be played in a lower register on an instrument like a bassoon, not on a lighter instrument like a flute. And although the motif will be centered around a particular key, it might use a lot of chromatic, dissonant notes. You can play with all the other attributes of a melody while you try to figure out what you're ultimately going to go with, but starting with a plan like this might make it easier to begin writing a melody.
",Kevin,https://music.stackexchange.com/users/3265,http://music.stackexchange.com/questions/23048/techniques-for-creating-melodies,LIFE_ARTS,music.stackexchange.com,1.0,0.4444444444444444,0.6666666666666666,0.0,1.0,0.3333333333333333,0.6666666666666666,0.7777777777777778,1.0,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,1.0,0.8888888888888888,1.0,1.0,1.0,1.0,0.6666666666666666,0.0,1.0,1.0,Techniques of creating melody,"I've posted this question:

Learning to create melodies

I've got a few ideas of techniques towards creating melodies but wanted to ask if there are any specific methods to help get better. I've read: The Complete's Idiot's Guide To Music Composition which explained a lot of details but I still find it difficult to create something 'good', whenever I play on my keyboard, it sounds rubbish. Is it something that comes with ample practice? What can I do to become better?
","In my experience, unfortunately, writing melodies is one of the most ""magical"" parts of writing music. Some melodies just sound great, some just don't. There are, however, a few things to keep in mind that can help you deliberately write a melody for a particular emotion or style and help you understand why a particular melody sounds good.

Intervallic and Stepwise Motion:
Some melodies have large jumps in-between consecutive notes, and others move up or down consecutive notes in a scale. The former usually sounds more grand, especially with slow rhythms, and the latter, smoother.

Rising and Falling Motion:
Whether the notes in a melody generally get higher, get lower, or stay in the same range can have a big effect on the melody's emotion.

Rhythm:
The melody you pick for a rhythm makes a huge difference. Is it syncopated or straight? Fast or slow? Complex or simple? Does it use distinctive tricks like hemiola or tuplets? What beats does it start and end on?

Instrumentation:
In my experience, the instrument playing a melody makes a big difference. In one electronic song I've heard, the main melody is played by a number of bold, powerful synths, giving the melody a driving emotion. Then, at the end of the song, a lone acoustic guitar plays the same melody, which suddenly becomes very sad.

Major/Minor Quality:
Of course, whether a melody is written in a major or minor key makes a big difference.

And the list can go on forever: tonal center, articulation, etc. The important thing isn't that every melody can be broken apart like this. Instead, you can pick out a few qualities you know you would like a melody to have based on which emotion you want to portray.

For example, perhaps you need to write the leitmotif for the bad guy. It's probably going to be in a minor key, because he's so evil. Likewise, it might be played in a lower register on an instrument like a bassoon, not on a lighter instrument like a flute. And although the motif will be centered around a particular key, it might use a lot of chromatic, dissonant notes. You can play with all the other attributes of a melody while you try to figure out what you're ultimately going to go with, but starting with a plan like this might make it easier to begin writing a melody.
"
4803,4803,7632,Looking for tool to show IP packets (and do analysis) sent/received from/to my machine (want to debug why can't mount network drive),"fiddler2 comes close but this only deals with web browsers it seems.

I need this tool to debug why I can't mount a common standard network/NAS drive (e.g. via SMB/SAMBA) in Windows 7 Pro and Home.

Looking for definitive answer to accessing a network drive/NAS/SMB drive via Windows 7 HOME and Windows 7 Professional. Is it possible and how?
",therobyouknow,https://superuser.com/users/21353,"Use the Wireshark packet analyzer. It has special support for many protocols and can help you with debugging issues by decoding SMB messages.
",Daniel Beck,https://superuser.com/users/22317,http://superuser.com/questions/308432,TECHNOLOGY,superuser.com,1.0,0.8888888888888888,0.0,0.6666666666666666,0.3333333333333333,1.0,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,1.0,1.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.3333333333333333,0.0,0.6666666666666666,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8666666666666666,0.6666666666666666,0.0,0.0,0.8888888888888888,Looking for tools to display (and analyze) IP packets sent / received from / to my computer (to debug why network drives cannot be installed),"fiddler2 comes close but this only deals with web browsers it seems.

I need this tool to debug why I can't mount a common standard network/NAS drive (e.g. via SMB/SAMBA) in Windows 7 Pro and Home.

Looking for definitive answer to accessing a network drive/NAS/SMB drive via Windows 7 HOME and Windows 7 Professional. Is it possible and how?
",Use Wireshark packet analyzer. It has special support for many protocols and can help you debug problems by decoding SMB messages.
608,608,951,What table tools/packages do you use?,"Making tables in LaTeX can be painful. All you need is a semi complex table with cells that have to span multiple rows/columns. What tools do you use to get around this complexity? Tabular? Tabularx? Are there others?
",levesque,https://tex.stackexchange.com/users/10,"Using AUCTeX in Emacs also allows for easy editing of tabular enviroments in LaTeX. Here's a brief illustration/explanation I worked up: http://babbagefiles.blogspot.com/2011/01/latex-table-manipulation-using.html

Preview: 
",emacsomancer,https://tex.stackexchange.com/users/1135,http://tex.stackexchange.com/questions/214/what-table-tools-packages-do-you-use,TECHNOLOGY,tex.stackexchange.com,0.8888888888888888,0.4444444444444444,0.3333333333333333,1.0,1.0,0.0,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,0.0,0.8888888888888888,What table tools / bags do you use?,Making tables out of latex can be painful. You only need a semi complex table in which cells must span multiple rows / columns. What tools do you use to circumvent this complexity? Form? Form? Anything else?,"Using AUCTeX in Emacs also allows for easy editing of tabular enviroments in LaTeX. Here's a brief illustration/explanation I worked up: http://babbagefiles.blogspot.com/2011/01/latex-table-manipulation-using.html

Preview: 
"
2854,2854,4543,od emulation for directories,"I was wondering why od(1) used to work in UNIX but doesn't work in GNU/Linux. There is a nice answer on serverfault. The next question is, are you aware of any tools that can emulate od behavior to support dumping directory data in GNU/Linux?
",ierax,https://unix.stackexchange.com/users/5661,"Linux doesn't let you do a plain read(dir_name, buffer, sizeof(buffer) - it always returns -1 and puts EISDIR in errno.  This is probably rational, as not all filesystems have directories as files.  The commonly-used reiserfs does not, for example.

You can use the open() system call from a C program to get a file descriptor of a directory, but things like readdir(3) (from libc) call getdents(2) to actually retrieve directory entries.  There's probably code in each filesystem implementation to create struct linux_dirent from whatever (a file, a database, an on-disk B-tree) that filesystem uses to store directory entries.
",Bruce Ediger,https://unix.stackexchange.com/users/732,http://unix.stackexchange.com/questions/43056/od-emulation-for-directories,TECHNOLOGY,unix.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,1.0,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.6666666666666666,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,1.0,0.0,0.7777777777777778,1.0,0.3333333333333333,0.8333333333333334,0.8333333333333334,0.6,0.6666666666666666,0.0,0.6666666666666666,1.0,Od simulation of directory,"I want to know why OD (1) used to work in UNIX, but not in GNU / Linux. There is a good answer on the server fault. The next question is, do you know of any tool that can simulate od behavior to support dumping catalog data in GNU / Linux?","Linux doesn't let you do a plain read(dir_name, buffer, sizeof(buffer) - it always returns -1 and puts EISDIR in errno.  This is probably rational, as not all filesystems have directories as files.  The commonly-used reiserfs does not, for example.

You can use the open() system call from a C program to get a file descriptor of a directory, but things like readdir(3) (from libc) call getdents(2) to actually retrieve directory entries.  There's probably code in each filesystem implementation to create struct linux_dirent from whatever (a file, a database, an on-disk B-tree) that filesystem uses to store directory entries.
"
456,456,710,Helpless opponent & Coup de Grace,"I had a question about Coup de Grace.

It says you can use it against a helpless opponent. Helpless opponent is defined as ""Paralyzed, held, bound, sleeping, unconscious, or otherwise completely at an opponent's mercy."" 

Now, if I was invisible and behind an unwary opponent, could I use a Coup de Grace because he'd be 'completely at my mercy'?

I've read things in places that this might indicate a yes, but I wanted a definitive answer.

Thanks!

EDIT: I was just using invisibility to set the stage. The point was that the victim has no idea I'm there. Invisible, or not, I just wanted to know if this situation counted as a coup de grace.
",Zaniel,https://rpg.stackexchange.com/users/4345,"No.  You don't even automatically hit when invisible, it does not count as a coup de grace.
",mxyzplk,https://rpg.stackexchange.com/users/140,http://rpg.stackexchange.com/questions/16506/helpless-opponent-coup-de-grace,CULTURE,rpg.stackexchange.com,1.0,0.3333333333333333,0.0,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,0.0,1.0,A helpless opponent & Grace coup,"I had a question about Coup de Grace.

It says you can use it against a helpless opponent. Helpless opponent is defined as ""Paralyzed, held, bound, sleeping, unconscious, or otherwise completely at an opponent's mercy."" 

Now, if I was invisible and behind an unwary opponent, could I use a Coup de Grace because he'd be 'completely at my mercy'?

I've read things in places that this might indicate a yes, but I wanted a definitive answer.

Thanks!

EDIT: I was just using invisibility to set the stage. The point was that the victim has no idea I'm there. Invisible, or not, I just wanted to know if this situation counted as a coup de grace.
","No.  You don't even automatically hit when invisible, it does not count as a coup de grace.
"
904,904,1436,Setting text of UITextField from caller view,"I have a barcode scanner on one view, and after the user has scanned the barcode, the app takes them to another view (BoilerDetails) where the barcode text field has been pre-filled.

I understand that the viewcontroller is null when it hasn't come into view and I can'tchange the UITextField text directly. This so far has given me an error.. How can I fix this?

BarcodeScannerViewController.m

BoilerDetailsViewController *viewCtrl = [[BoilerDetailsViewController alloc] initWithNibName:nil bundle:nil];
[viewCtrl setBarcode:strBarcode];
[self.navigationController pushViewController:viewCtrl animated:YES];


BoilerDetailsViewController.h

@interface BoilerDetailsViewController : SubViewControllerBase
@property (retain, nonatomic) NSString *barcode;
@property (retain, nonatomic) IBOutlet UITextField *barcodeField;
- (void)setBarcode:(NSString*)strBarcode;
@end


BoilerDetailsViewController.m

-(void)setBarcode:(NSString *)strBarcode
{
    self.barcode = strBarcode;
}

- (void)viewDidLoad
{
    [super viewDidLoad];
    [_barcodeField setText:self.barcode];
    // Do any additional setup after loading the view from its nib.
}

",Freeman Latif,https://stackoverflow.com/users/823152,"First of all, this is wrong

-(void)setBarcode:(NSString *)strBarcode
{
    self.barcode = strBarcode;
}


self.barcode = strBarcode; itself calls the setter.

depending on your ios version you shud write:

//for ARC environment
-(void)setBarcode:(NSString *)strBarcode
{
    _barcode = strBarcode;
}
//since default association in ARC is strong


before this do @synthesize barcode = _barcode;

//and for non-ARC environment, since your property is retain type
-(void)setBarcode:(NSString *)strBarcode
{
    if (_barcode != barcode) {
        [_barcode release];
        _barcode = [barcode retain];
    }
}


And you will be OK.
",croyneaus4u,https://stackoverflow.com/users/1554361,http://stackoverflow.com/questions/14960306/setting-text-of-uitextfield-from-caller-view,STACKOVERFLOW,stackoverflow.com,0.8333333333333334,0.5,0.0,0.5,0.5,1.0,0.5,0.3333333333333333,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.5,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,0.8333333333333334,Set the text of uitextfield from the caller view,"I have a barcode scanner on one view, and after the user has scanned the barcode, the app takes them to another view (BoilerDetails) where the barcode text field has been pre-filled.

I understand that the viewcontroller is null when it hasn't come into view and I can'tchange the UITextField text directly. This so far has given me an error.. How can I fix this?

BarcodeScannerViewController.m

BoilerDetailsViewController *viewCtrl = [[BoilerDetailsViewController alloc] initWithNibName:nil bundle:nil];
[viewCtrl setBarcode:strBarcode];
[self.navigationController pushViewController:viewCtrl animated:YES];


BoilerDetailsViewController.h

@interface BoilerDetailsViewController : SubViewControllerBase
@property (retain, nonatomic) NSString *barcode;
@property (retain, nonatomic) IBOutlet UITextField *barcodeField;
- (void)setBarcode:(NSString*)strBarcode;
@end


BoilerDetailsViewController.m

-(void)setBarcode:(NSString *)strBarcode
{
    self.barcode = strBarcode;
}

- (void)viewDidLoad
{
    [super viewDidLoad];
    [_barcodeField setText:self.barcode];
    // Do any additional setup after loading the view from its nib.
}

","First of all, this is wrong

-(void)setBarcode:(NSString *)strBarcode
{
    self.barcode = strBarcode;
}


self.barcode = strBarcode; itself calls the setter.

depending on your ios version you shud write:

//for ARC environment
-(void)setBarcode:(NSString *)strBarcode
{
    _barcode = strBarcode;
}
//since default association in ARC is strong


before this do @synthesize barcode = _barcode;

//and for non-ARC environment, since your property is retain type
-(void)setBarcode:(NSString *)strBarcode
{
    if (_barcode != barcode) {
        [_barcode release];
        _barcode = [barcode retain];
    }
}


And you will be OK.
"
93,93,154,Solving the recurrence relation $T(n)=4T\left(\frac{\sqrt{n}}{3}\right)+ \log^2n$,"How we calculate the answer of following recurrence?

$$T(n)=4T\left(\frac{\sqrt{n}}{3}\right)+ \log^2n.$$

Any nice solution would be highly appreciated.

My solution is:

$n=3^m \to T(3^m)=4T(\frac{3^{m/2}}{3})+log^2 3^m = O(Log^2 n log n log n)$ 
",Mouna Mokhiab,https://math.stackexchange.com/users/170408,"Introduce the auxiliary (sub)sequence $(S(k))$, defined for every $k\geqslant1$ by $$S(k)=4^{-k}\cdot T(3^{2^k-2}),$$ then the recursion on $(T(n))$ becomes $$S(k)=S(k-1)+4^{-k}\cdot(\log(3^{2^k-2}))^2,$$ for every $k\geqslant2$, that is, $$S(k)=S(k-1)+4^{-k}\cdot(\log3)^2\cdot(2^k-2)^2=S(k-1)+(\log3)^2\cdot(1-2^{-(k-1)})^2.$$ Since $(\log3)^2\cdot(1-2^{-(k-1)})^2\to(\log3)^2\ne0$ when $k\to\infty$, this yields $$S(k)\sim(\log3)^2\cdot k,$$ that is, $$T(3^{2^k-2})\sim(\log3)^2\cdot k\cdot4^k.$$
Let $n=3^{2^k-2}$, then $2^k=2+\log_3n$ hence $2^k\cdot\log3\sim\log n$, thus, $4^k\cdot(\log3)^2\sim(\log n)^2$, and $k\sim(\log\log n)/\log2$, hence $$T(n)\sim(\log\log n)(\log n)^2/(\log2),$$ in particular, $$T(n)=\Theta((\log\log n)(\log n)^2).$$ One sees that $T(n)$ is $O((\log\log n)(\log n)^2)$ and that $T(n)$ is not $O((\log n)^2)$.
",Did,https://math.stackexchange.com/users/6179,http://math.stackexchange.com/questions/902759/solving-the-recurrence-relation-tn-4t-left-frac-sqrtn3-right-log2n,SCIENCE,math.stackexchange.com,0.7777777777777778,0.8888888888888888,0.0,0.6666666666666666,1.0,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,1.0,Solve recursive relation $t (n) = 4T left (\ frac {\ sqrt {n} {3} \ right) + \ log ^ 2n$,"How we calculate the answer of following recurrence?

$$T(n)=4T\left(\frac{\sqrt{n}}{3}\right)+ \log^2n.$$

Any nice solution would be highly appreciated.

My solution is:

$n=3^m \to T(3^m)=4T(\frac{3^{m/2}}{3})+log^2 3^m = O(Log^2 n log n log n)$ 
","Introduce the auxiliary (sub)sequence $(S(k))$, defined for every $k\geqslant1$ by $$S(k)=4^{-k}\cdot T(3^{2^k-2}),$$ then the recursion on $(T(n))$ becomes $$S(k)=S(k-1)+4^{-k}\cdot(\log(3^{2^k-2}))^2,$$ for every $k\geqslant2$, that is, $$S(k)=S(k-1)+4^{-k}\cdot(\log3)^2\cdot(2^k-2)^2=S(k-1)+(\log3)^2\cdot(1-2^{-(k-1)})^2.$$ Since $(\log3)^2\cdot(1-2^{-(k-1)})^2\to(\log3)^2\ne0$ when $k\to\infty$, this yields $$S(k)\sim(\log3)^2\cdot k,$$ that is, $$T(3^{2^k-2})\sim(\log3)^2\cdot k\cdot4^k.$$
Let $n=3^{2^k-2}$, then $2^k=2+\log_3n$ hence $2^k\cdot\log3\sim\log n$, thus, $4^k\cdot(\log3)^2\sim(\log n)^2$, and $k\sim(\log\log n)/\log2$, hence $$T(n)\sim(\log\log n)(\log n)^2/(\log2),$$ in particular, $$T(n)=\Theta((\log\log n)(\log n)^2).$$ One sees that $T(n)$ is $O((\log\log n)(\log n)^2)$ and that $T(n)$ is not $O((\log n)^2)$.
"
5471,5471,8688,On the definition of weakly compact cardinals,"I am reading in Jech's Set Theory the chapter about large cardinals. After discussing measurable cardinals he moves on to weakly-compact cardinals, which have been discussed far earlier in the book.
I went back to the chapter dealing with weakly-compact cardinals and began retracing the definition.

Eventually, it came into this:

We denote $[k]^n = \{X \subseteq \kappa\mid |X| = n\}$. If $\lambda$ is a cardinal, we denote $\kappa \to (\lambda)^2$ when for every partition of $[\kappa]^2$ into $2$ we have $H \subseteq \kappa$ that is of cardinality $\lambda$, and for which $[H]^2$ is strictly in one part.

And we say that $\kappa$ is weakly-compact if it satisfies the property $\kappa \to (\kappa)^2$.

The problem is that I'm a bit lost in all those definitions, and not even sure about the $\kappa \to (\lambda)^2$ notation. 

My questions are, if so, can someone help me make some sense into those definitions, and is there an equivalent definition for weakly-compact cardinals which can help me understand their properties better?
",Asaf Karagila,https://math.stackexchange.com/users/622,"Let me add to Ivan's answer another equivalent
characterization of weak compactness, which might appeal to
you, as it makes them resemble miniature measurable
cardinals.

Namely, if $\kappa$ is a cardinal and
$\kappa^{&lt;\kappa}=\kappa$, then $\kappa$ is weakly compact
if and only if for every transitive set $M$ of size
$\kappa$ with $\kappa\in M$, there is another transitive
set $N$ and an elementary embedding $j:M\to N$ having
critical point $\kappa$.

This embedding characterization admits myriad forms. For
example, one can insist that $M\models ZF^-$ or even
$M\models ZFC$, and that $M^{&lt;\kappa}\subset M$, or that
every $A\subset \kappa$ can be placed into such an $M$, and so
on. One can even insist that $j\in N$, a property known as
the Hauser property.

These various embedding formulations of weak compactness
allow one to borrow many of the methods and techniques from
much larger large cardinals, which are most often described
in terms of embeddings, and apply them with weakly compact
cardinals. For example, using Easton support forcing
iterations, one can control the value of $2^\kappa$ while
preserving the weak compactness of $\kappa$.
",JDH,https://math.stackexchange.com/users/413,http://math.stackexchange.com/questions/4198/on-the-definition-of-weakly-compact-cardinals,SCIENCE,math.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,0.5,1.0,0.5,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.0,0.6666666666666666,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,1.0,0.0,0.8888888888888888,1.0,0.6666666666666666,0.8333333333333334,1.0,0.7,0.0,0.0,1.0,1.0,On the definition of weak compact cardinality,"I am reading in Jech's Set Theory the chapter about large cardinals. After discussing measurable cardinals he moves on to weakly-compact cardinals, which have been discussed far earlier in the book.
I went back to the chapter dealing with weakly-compact cardinals and began retracing the definition.

Eventually, it came into this:

We denote $[k]^n = \{X \subseteq \kappa\mid |X| = n\}$. If $\lambda$ is a cardinal, we denote $\kappa \to (\lambda)^2$ when for every partition of $[\kappa]^2$ into $2$ we have $H \subseteq \kappa$ that is of cardinality $\lambda$, and for which $[H]^2$ is strictly in one part.

And we say that $\kappa$ is weakly-compact if it satisfies the property $\kappa \to (\kappa)^2$.

The problem is that I'm a bit lost in all those definitions, and not even sure about the $\kappa \to (\lambda)^2$ notation. 

My questions are, if so, can someone help me make some sense into those definitions, and is there an equivalent definition for weakly-compact cardinals which can help me understand their properties better?
","Let me add to Ivan's answer another equivalent
characterization of weak compactness, which might appeal to
you, as it makes them resemble miniature measurable
cardinals.

Namely, if $\kappa$ is a cardinal and
$\kappa^{&lt;\kappa}=\kappa$, then $\kappa$ is weakly compact
if and only if for every transitive set $M$ of size
$\kappa$ with $\kappa\in M$, there is another transitive
set $N$ and an elementary embedding $j:M\to N$ having
critical point $\kappa$.

This embedding characterization admits myriad forms. For
example, one can insist that $M\models ZF^-$ or even
$M\models ZFC$, and that $M^{&lt;\kappa}\subset M$, or that
every $A\subset \kappa$ can be placed into such an $M$, and so
on. One can even insist that $j\in N$, a property known as
the Hauser property.

These various embedding formulations of weak compactness
allow one to borrow many of the methods and techniques from
much larger large cardinals, which are most often described
in terms of embeddings, and apply them with weakly compact
cardinals. For example, using Easton support forcing
iterations, one can control the value of $2^\kappa$ while
preserving the weak compactness of $\kappa$.
"
5514,5514,8748,How to show the integers have same cardinality as the natural numbers?,"How would I show the following have a bijection. Which is one to one and onto ofcourse.

$\mathbb{Z}\rightarrow \mathbb{N}$

I know I need to find a function. But I do not see the pattern that makes integer go to natural. I already did this problem from natural to integer but now I want to see it done this way.

I have listed some numbers

$,..,-4,-3,-2,-1,0,1,2,3,4,5,6,7,8,9,..$

$1,2,3,4,5,6,7,8,9,10,11,12,13,14,.$
",Fernando Martinez,https://math.stackexchange.com/users/37244,"Your list has absolutely no pattern, because you're doing it ""wrong"", in the sense that you are not writing it in a way that a pattern emerges. 

Of course there is no order preserving function, so writing both sets with their natural order will promise you that there is no reasonable pattern. Instead write the natural numbers, and then try to write the integers:

$$\begin{array}
&amp; 1 &amp; 2&amp;  3&amp;  4&amp;  5&amp; 6&amp;  7&amp; 8&amp;\ldots\\
  0 &amp; 1&amp; -1&amp; 2&amp; -2&amp;  3&amp; -3&amp; 4&amp;\ldots
\end{array}$$

This gives rise to a bijection from $\Bbb N$ onto $\Bbb Z$. Now just find its inverse.

(Note that it is in general easier to find ""pattern"" when $\Bbb N$ is the domain, because the list does not require you to go into two directions.)
",Asaf Karagila,https://math.stackexchange.com/users/622,http://math.stackexchange.com/questions/873927/how-to-show-the-integers-have-same-cardinality-as-the-natural-numbers,SCIENCE,math.stackexchange.com,0.6666666666666666,0.3333333333333333,0.0,0.3333333333333333,1.0,0.3333333333333333,0.6666666666666666,0.4444444444444444,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,0.8888888888888888,0.8888888888888888,0.7333333333333333,0.3333333333333333,0.6666666666666666,1.0,0.8888888888888888,How to show that integers have the same cardinality as natural numbers?,"How would I show the following have a bijection. Which is one to one and onto ofcourse.

$\mathbb{Z}\rightarrow \mathbb{N}$

I know I need to find a function. But I do not see the pattern that makes integer go to natural. I already did this problem from natural to integer but now I want to see it done this way.

I have listed some numbers

$,..,-4,-3,-2,-1,0,1,2,3,4,5,6,7,8,9,..$

$1,2,3,4,5,6,7,8,9,10,11,12,13,14,.$
","Your list has absolutely no pattern, because you're doing it ""wrong"", in the sense that you are not writing it in a way that a pattern emerges. 

Of course there is no order preserving function, so writing both sets with their natural order will promise you that there is no reasonable pattern. Instead write the natural numbers, and then try to write the integers:

$$\begin{array}
&amp; 1 &amp; 2&amp;  3&amp;  4&amp;  5&amp; 6&amp;  7&amp; 8&amp;\ldots\\
  0 &amp; 1&amp; -1&amp; 2&amp; -2&amp;  3&amp; -3&amp; 4&amp;\ldots
\end{array}$$

This gives rise to a bijection from $\Bbb N$ onto $\Bbb Z$. Now just find its inverse.

(Note that it is in general easier to find ""pattern"" when $\Bbb N$ is the domain, because the list does not require you to go into two directions.)
"
2230,2230,3556,HowTo: Add Class to Sidebar Widget List-Items,"The newest version of Bootstrap (v3.0) adds a new List Group component which has the following structure:

&lt;ul class=""list-group""&gt;
  &lt;li class=""list-group-item""&gt;Cras justo odio&lt;/li&gt;
  &lt;li class=""list-group-item""&gt;Dapibus ac facilisis in&lt;/li&gt;
  &lt;li class=""list-group-item""&gt;Morbi leo risus&lt;/li&gt;
  &lt;li class=""list-group-item""&gt;Porta ac consectetur ac&lt;/li&gt;
  &lt;li class=""list-group-item""&gt;Vestibulum at eros&lt;/li&gt;
&lt;/ul&gt;



I would like to be able to add a class to the ul (i.e. &lt;ul class=""list-group""&gt;)
I would like to style my Category sidebar widget to support this new component, but as you see, this requires classes on each li item.


In reading some similar posts, one option I found is to use jQuery to add the class to each li, but I am concerned about the dreaded FOUC. 

Is there some WordPress function that gets me to my goal?

Please advise,

Update: 

I was able to add classes to the individual li's by creating a Custom Walker which extends Walker_Category (see code below), but this still does not get me to the ul which also needs a class added (eg &lt;ul class=""list-group""&gt;). 

class Walker_Category_BS extends Walker_Category {
    function start_el( &amp;$output, $category, $depth = 0, $args = array() ) {
        extract($args);

        $cat_name = esc_attr( $category-&gt;name );
        $cat_name = apply_filters( 'list_cats', $cat_name, $category );
        $link = '&lt;a href=""' . esc_url( get_term_link($category) ) . '"" ';
        if ( $use_desc_for_title == 0 || empty($category-&gt;description) )
            $link .= 'title=""' . esc_attr( sprintf(__( 'View all posts filed under %s' ), $cat_name) ) . '""';
        else
            $link .= 'title=""' . esc_attr( strip_tags( apply_filters( 'category_description', $category-&gt;description, $category ) ) ) . '""';
        $link .= '&gt;';
        $link .= $cat_name . '&lt;/a&gt;';

        if ( !empty($feed_image) || !empty($feed) ) {
            $link .= ' ';

            if ( empty($feed_image) )
                $link .= '(';

            $link .= '&lt;a href=""' . esc_url( get_term_feed_link( $category-&gt;term_id, $category-&gt;taxonomy, $feed_type ) ) . '""';

            if ( empty($feed) ) {
                $alt = ' alt=""' . sprintf(__( 'Feed for all posts filed under %s' ), $cat_name ) . '""';
            } else {
                $title = ' title=""' . $feed . '""';
                $alt = ' alt=""' . $feed . '""';
                $name = $feed;
                $link .= $title;
            }

            $link .= '&gt;';

            if ( empty($feed_image) )
                $link .= $name;
            else
                $link .= ""&lt;img src='$feed_image'$alt$title"" . ' /&gt;';

            $link .= '&lt;/a&gt;';

            if ( empty($feed_image) )
                $link .= ')';
        }

        if ( !empty($show_count) )
            $link .= ' (' . intval($category-&gt;count) . ')';

        if ( 'list' == $args['style'] ) {
            $output .= ""\t&lt;li"";
            $class = 'list-group-item cat-item cat-item-' . $category-&gt;term_id;
            if ( !empty($current_category) ) {
                $_current_category = get_term( $current_category, $category-&gt;taxonomy );
                if ( $category-&gt;term_id == $current_category )
                    $class .=  ' current-cat';
                elseif ( $category-&gt;term_id == $_current_category-&gt;parent )
                    $class .=  ' current-cat-parent';
            }
            $output .=  ' class=""' . $class . '""';
            $output .= ""&gt;$link\n"";
        } else {
            $output .= ""\t$link&lt;br /&gt;\n"";
        }
    } /* end start_el */

} /* end Walker_Category_BS */


Update 02: 

After viewing default-widgets.php in the core, I decided to create a new widget (WP_Widget_Categories_BS, see code below) wherein I basically, copied all the code from the default category widget and simply modified the the UL to add the necessary class. 

&lt;?php 

/**
 * Categories widget class
 *
 * @since 2.8.0
 */
class WP_Widget_Categories_BS extends WP_Widget {

    function __construct() {
        $widget_ops = array( 'classname' =&gt; 'widget_categories_bs', 'description' =&gt; __( ""A list or dropdown of categories for Bootstrap 3.0"" ) );
        parent::__construct('categories', __('Boostrap Categories'), $widget_ops);
    }

    function widget( $args, $instance ) {
        extract( $args );

        $title = apply_filters('widget_title', empty( $instance['title'] ) ? __( 'Categories' ) : $instance['title'], $instance, $this-&gt;id_base);
        $c = ! empty( $instance['count'] ) ? '1' : '0';
        $h = ! empty( $instance['hierarchical'] ) ? '1' : '0';
        $d = ! empty( $instance['dropdown'] ) ? '1' : '0';

        echo $before_widget;
        if ( $title )
            echo $before_title . $title . $after_title;

        $cat_args = array('orderby' =&gt; 'name', 'show_count' =&gt; $c, 'hierarchical' =&gt; $h);
        if ( $d ) {
            $cat_args['show_option_none'] = __('Select Category');
            wp_dropdown_categories(apply_filters('widget_categories_dropdown_args', $cat_args));
?&gt;

&lt;script type='text/javascript'&gt;
/* &lt;![CDATA[ */
    var dropdown = document.getElementById(""cat"");
    function onCatChange() {
        if ( dropdown.options[dropdown.selectedIndex].value &gt; 0 ) {
            location.href = ""&lt;?php echo home_url(); ?&gt;/?cat=""+dropdown.options[dropdown.selectedIndex].value;
        }
    }
    dropdown.onchange = onCatChange;
/* ]]&gt; */
&lt;/script&gt;

&lt;?php
        } else {
?&gt;
        &lt;ul class=""list-group""&gt;
&lt;?php
        $cat_args['title_li'] = '';
        wp_list_categories(apply_filters('widget_categories_args', $cat_args));
?&gt;
        &lt;/ul&gt;
&lt;?php
        }

        echo $after_widget;
    }

    function update( $new_instance, $old_instance ) {
        $instance = $old_instance;
        $instance['title'] = strip_tags($new_instance['title']);
        $instance['count'] = !empty($new_instance['count']) ? 1 : 0;
        $instance['hierarchical'] = !empty($new_instance['hierarchical']) ? 1 : 0;
        $instance['dropdown'] = !empty($new_instance['dropdown']) ? 1 : 0;

        return $instance;
    }

    function form( $instance ) {
        //Defaults
        $instance = wp_parse_args( (array) $instance, array( 'title' =&gt; '') );
        $title = esc_attr( $instance['title'] );
        $count = isset($instance['count']) ? (bool) $instance['count'] :false;
        $hierarchical = isset( $instance['hierarchical'] ) ? (bool) $instance['hierarchical'] : false;
        $dropdown = isset( $instance['dropdown'] ) ? (bool) $instance['dropdown'] : false;
?&gt;
        &lt;p&gt;&lt;label for=""&lt;?php echo $this-&gt;get_field_id('title'); ?&gt;""&gt;&lt;?php _e( 'Title:' ); ?&gt;&lt;/label&gt;
        &lt;input class=""widefat"" id=""&lt;?php echo $this-&gt;get_field_id('title'); ?&gt;"" name=""&lt;?php echo $this-&gt;get_field_name('title'); ?&gt;"" type=""text"" value=""&lt;?php echo $title; ?&gt;"" /&gt;&lt;/p&gt;

        &lt;p&gt;&lt;input type=""checkbox"" class=""checkbox"" id=""&lt;?php echo $this-&gt;get_field_id('dropdown'); ?&gt;"" name=""&lt;?php echo $this-&gt;get_field_name('dropdown'); ?&gt;""&lt;?php checked( $dropdown ); ?&gt; /&gt;
        &lt;label for=""&lt;?php echo $this-&gt;get_field_id('dropdown'); ?&gt;""&gt;&lt;?php _e( 'Display as dropdown' ); ?&gt;&lt;/label&gt;&lt;br /&gt;

        &lt;input type=""checkbox"" class=""checkbox"" id=""&lt;?php echo $this-&gt;get_field_id('count'); ?&gt;"" name=""&lt;?php echo $this-&gt;get_field_name('count'); ?&gt;""&lt;?php checked( $count ); ?&gt; /&gt;
        &lt;label for=""&lt;?php echo $this-&gt;get_field_id('count'); ?&gt;""&gt;&lt;?php _e( 'Show post counts' ); ?&gt;&lt;/label&gt;&lt;br /&gt;

        &lt;input type=""checkbox"" class=""checkbox"" id=""&lt;?php echo $this-&gt;get_field_id('hierarchical'); ?&gt;"" name=""&lt;?php echo $this-&gt;get_field_name('hierarchical'); ?&gt;""&lt;?php checked( $hierarchical ); ?&gt; /&gt;
        &lt;label for=""&lt;?php echo $this-&gt;get_field_id('hierarchical'); ?&gt;""&gt;&lt;?php _e( 'Show hierarchy' ); ?&gt;&lt;/label&gt;&lt;/p&gt;
&lt;?php
    }

} // end WP_Widget_Categories_BS


Combined with a Custom Walker I created (Walker_Category_BS) I now have what I wanted. 

Analysis

Is this the best way to do it? Don't know as I have have received zero feedback so far, and this is the first time i've done this (hence the question), but ...it works! I could use a review.

Debug Warning

Concerning my Custom Category Walker Walker_Category_BS, i'm seeing this message


  ""Strict standards: Declaration of Walker_Category_BS::start_el() should be compatible with Walker::start_el(&amp;$output, $object, $depth = 0, $args = Array, $current_object_id = 0) in C:\wamp\www\mysite\wp-content\themes\mytheme\assets\inc\Walker_Category_BS.php""


It appears to be a warning, of some sort.
",sleeper,https://wordpress.stackexchange.com/users/12116,"what about creating a seperate sidebar for this widget and adding class using register_sidebar funciton ?

register_sidebar(array(
    'name' =&gt; 'First_sidebar',
    'id' =&gt; 'sidebar-1',
    'class'         =&gt; 'ul-class-name',
    'before_widget' =&gt; '&lt;div class=""well""&gt;',
    'after_widget' =&gt; '&lt;/div&gt;',
    'before_title' =&gt; '&lt;h4&gt;',
    'after_title' =&gt; '&lt;/h4&gt;'
));

",codepixlabs,https://wordpress.stackexchange.com/users/36972,http://wordpress.stackexchange.com/questions/113233/howto-add-class-to-sidebar-widget-list-items,TECHNOLOGY,wordpress.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,0.0,1.0,0.6666666666666666,0.6666666666666666,0.4444444444444444,0.6666666666666666,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.6666666666666666,0.0,0.7777777777777778,0.8888888888888888,0.5,1.0,0.8888888888888888,0.7333333333333333,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.6666666666666666,How to: add a class to a sidebar widget list item,"The newest version of Bootstrap (v3.0) adds a new List Group component which has the following structure:

&lt;ul class=""list-group""&gt;
  &lt;li class=""list-group-item""&gt;Cras justo odio&lt;/li&gt;
  &lt;li class=""list-group-item""&gt;Dapibus ac facilisis in&lt;/li&gt;
  &lt;li class=""list-group-item""&gt;Morbi leo risus&lt;/li&gt;
  &lt;li class=""list-group-item""&gt;Porta ac consectetur ac&lt;/li&gt;
  &lt;li class=""list-group-item""&gt;Vestibulum at eros&lt;/li&gt;
&lt;/ul&gt;



I would like to be able to add a class to the ul (i.e. &lt;ul class=""list-group""&gt;)
I would like to style my Category sidebar widget to support this new component, but as you see, this requires classes on each li item.


In reading some similar posts, one option I found is to use jQuery to add the class to each li, but I am concerned about the dreaded FOUC. 

Is there some WordPress function that gets me to my goal?

Please advise,

Update: 

I was able to add classes to the individual li's by creating a Custom Walker which extends Walker_Category (see code below), but this still does not get me to the ul which also needs a class added (eg &lt;ul class=""list-group""&gt;). 

class Walker_Category_BS extends Walker_Category {
    function start_el( &amp;$output, $category, $depth = 0, $args = array() ) {
        extract($args);

        $cat_name = esc_attr( $category-&gt;name );
        $cat_name = apply_filters( 'list_cats', $cat_name, $category );
        $link = '&lt;a href=""' . esc_url( get_term_link($category) ) . '"" ';
        if ( $use_desc_for_title == 0 || empty($category-&gt;description) )
            $link .= 'title=""' . esc_attr( sprintf(__( 'View all posts filed under %s' ), $cat_name) ) . '""';
        else
            $link .= 'title=""' . esc_attr( strip_tags( apply_filters( 'category_description', $category-&gt;description, $category ) ) ) . '""';
        $link .= '&gt;';
        $link .= $cat_name . '&lt;/a&gt;';

        if ( !empty($feed_image) || !empty($feed) ) {
            $link .= ' ';

            if ( empty($feed_image) )
                $link .= '(';

            $link .= '&lt;a href=""' . esc_url( get_term_feed_link( $category-&gt;term_id, $category-&gt;taxonomy, $feed_type ) ) . '""';

            if ( empty($feed) ) {
                $alt = ' alt=""' . sprintf(__( 'Feed for all posts filed under %s' ), $cat_name ) . '""';
            } else {
                $title = ' title=""' . $feed . '""';
                $alt = ' alt=""' . $feed . '""';
                $name = $feed;
                $link .= $title;
            }

            $link .= '&gt;';

            if ( empty($feed_image) )
                $link .= $name;
            else
                $link .= ""&lt;img src='$feed_image'$alt$title"" . ' /&gt;';

            $link .= '&lt;/a&gt;';

            if ( empty($feed_image) )
                $link .= ')';
        }

        if ( !empty($show_count) )
            $link .= ' (' . intval($category-&gt;count) . ')';

        if ( 'list' == $args['style'] ) {
            $output .= ""\t&lt;li"";
            $class = 'list-group-item cat-item cat-item-' . $category-&gt;term_id;
            if ( !empty($current_category) ) {
                $_current_category = get_term( $current_category, $category-&gt;taxonomy );
                if ( $category-&gt;term_id == $current_category )
                    $class .=  ' current-cat';
                elseif ( $category-&gt;term_id == $_current_category-&gt;parent )
                    $class .=  ' current-cat-parent';
            }
            $output .=  ' class=""' . $class . '""';
            $output .= ""&gt;$link\n"";
        } else {
            $output .= ""\t$link&lt;br /&gt;\n"";
        }
    } /* end start_el */

} /* end Walker_Category_BS */


Update 02: 

After viewing default-widgets.php in the core, I decided to create a new widget (WP_Widget_Categories_BS, see code below) wherein I basically, copied all the code from the default category widget and simply modified the the UL to add the necessary class. 

&lt;?php 

/**
 * Categories widget class
 *
 * @since 2.8.0
 */
class WP_Widget_Categories_BS extends WP_Widget {

    function __construct() {
        $widget_ops = array( 'classname' =&gt; 'widget_categories_bs', 'description' =&gt; __( ""A list or dropdown of categories for Bootstrap 3.0"" ) );
        parent::__construct('categories', __('Boostrap Categories'), $widget_ops);
    }

    function widget( $args, $instance ) {
        extract( $args );

        $title = apply_filters('widget_title', empty( $instance['title'] ) ? __( 'Categories' ) : $instance['title'], $instance, $this-&gt;id_base);
        $c = ! empty( $instance['count'] ) ? '1' : '0';
        $h = ! empty( $instance['hierarchical'] ) ? '1' : '0';
        $d = ! empty( $instance['dropdown'] ) ? '1' : '0';

        echo $before_widget;
        if ( $title )
            echo $before_title . $title . $after_title;

        $cat_args = array('orderby' =&gt; 'name', 'show_count' =&gt; $c, 'hierarchical' =&gt; $h);
        if ( $d ) {
            $cat_args['show_option_none'] = __('Select Category');
            wp_dropdown_categories(apply_filters('widget_categories_dropdown_args', $cat_args));
?&gt;

&lt;script type='text/javascript'&gt;
/* &lt;![CDATA[ */
    var dropdown = document.getElementById(""cat"");
    function onCatChange() {
        if ( dropdown.options[dropdown.selectedIndex].value &gt; 0 ) {
            location.href = ""&lt;?php echo home_url(); ?&gt;/?cat=""+dropdown.options[dropdown.selectedIndex].value;
        }
    }
    dropdown.onchange = onCatChange;
/* ]]&gt; */
&lt;/script&gt;

&lt;?php
        } else {
?&gt;
        &lt;ul class=""list-group""&gt;
&lt;?php
        $cat_args['title_li'] = '';
        wp_list_categories(apply_filters('widget_categories_args', $cat_args));
?&gt;
        &lt;/ul&gt;
&lt;?php
        }

        echo $after_widget;
    }

    function update( $new_instance, $old_instance ) {
        $instance = $old_instance;
        $instance['title'] = strip_tags($new_instance['title']);
        $instance['count'] = !empty($new_instance['count']) ? 1 : 0;
        $instance['hierarchical'] = !empty($new_instance['hierarchical']) ? 1 : 0;
        $instance['dropdown'] = !empty($new_instance['dropdown']) ? 1 : 0;

        return $instance;
    }

    function form( $instance ) {
        //Defaults
        $instance = wp_parse_args( (array) $instance, array( 'title' =&gt; '') );
        $title = esc_attr( $instance['title'] );
        $count = isset($instance['count']) ? (bool) $instance['count'] :false;
        $hierarchical = isset( $instance['hierarchical'] ) ? (bool) $instance['hierarchical'] : false;
        $dropdown = isset( $instance['dropdown'] ) ? (bool) $instance['dropdown'] : false;
?&gt;
        &lt;p&gt;&lt;label for=""&lt;?php echo $this-&gt;get_field_id('title'); ?&gt;""&gt;&lt;?php _e( 'Title:' ); ?&gt;&lt;/label&gt;
        &lt;input class=""widefat"" id=""&lt;?php echo $this-&gt;get_field_id('title'); ?&gt;"" name=""&lt;?php echo $this-&gt;get_field_name('title'); ?&gt;"" type=""text"" value=""&lt;?php echo $title; ?&gt;"" /&gt;&lt;/p&gt;

        &lt;p&gt;&lt;input type=""checkbox"" class=""checkbox"" id=""&lt;?php echo $this-&gt;get_field_id('dropdown'); ?&gt;"" name=""&lt;?php echo $this-&gt;get_field_name('dropdown'); ?&gt;""&lt;?php checked( $dropdown ); ?&gt; /&gt;
        &lt;label for=""&lt;?php echo $this-&gt;get_field_id('dropdown'); ?&gt;""&gt;&lt;?php _e( 'Display as dropdown' ); ?&gt;&lt;/label&gt;&lt;br /&gt;

        &lt;input type=""checkbox"" class=""checkbox"" id=""&lt;?php echo $this-&gt;get_field_id('count'); ?&gt;"" name=""&lt;?php echo $this-&gt;get_field_name('count'); ?&gt;""&lt;?php checked( $count ); ?&gt; /&gt;
        &lt;label for=""&lt;?php echo $this-&gt;get_field_id('count'); ?&gt;""&gt;&lt;?php _e( 'Show post counts' ); ?&gt;&lt;/label&gt;&lt;br /&gt;

        &lt;input type=""checkbox"" class=""checkbox"" id=""&lt;?php echo $this-&gt;get_field_id('hierarchical'); ?&gt;"" name=""&lt;?php echo $this-&gt;get_field_name('hierarchical'); ?&gt;""&lt;?php checked( $hierarchical ); ?&gt; /&gt;
        &lt;label for=""&lt;?php echo $this-&gt;get_field_id('hierarchical'); ?&gt;""&gt;&lt;?php _e( 'Show hierarchy' ); ?&gt;&lt;/label&gt;&lt;/p&gt;
&lt;?php
    }

} // end WP_Widget_Categories_BS


Combined with a Custom Walker I created (Walker_Category_BS) I now have what I wanted. 

Analysis

Is this the best way to do it? Don't know as I have have received zero feedback so far, and this is the first time i've done this (hence the question), but ...it works! I could use a review.

Debug Warning

Concerning my Custom Category Walker Walker_Category_BS, i'm seeing this message


  ""Strict standards: Declaration of Walker_Category_BS::start_el() should be compatible with Walker::start_el(&amp;$output, $object, $depth = 0, $args = Array, $current_object_id = 0) in C:\wamp\www\mysite\wp-content\themes\mytheme\assets\inc\Walker_Category_BS.php""


It appears to be a warning, of some sort.
","what about creating a seperate sidebar for this widget and adding class using register_sidebar funciton ?

register_sidebar(array(
    'name' =&gt; 'First_sidebar',
    'id' =&gt; 'sidebar-1',
    'class'         =&gt; 'ul-class-name',
    'before_widget' =&gt; '&lt;div class=""well""&gt;',
    'after_widget' =&gt; '&lt;/div&gt;',
    'before_title' =&gt; '&lt;h4&gt;',
    'after_title' =&gt; '&lt;/h4&gt;'
));

"
2265,2265,3609,Why do I have to explicitly add perl before the script for getops to run properly?,"When i run my script like so: 

C:\>perl script.pl -f file

It works fine. But, if I just do:

C:\>script.pl -f file

then I don't get any errors but getopts doesn't assign anything to $opt_f

This works just fine on perl 5.8 Windows XP, but it doesn't work on perl 5.12 on Windows 7.
There aren't any other versions of perl installed (its a new OS build).

Code:

use Getopt::Std;
our ($opt_f);
getopts('f:');
print ""input file is: $opt_f \n"";
print ""$0\n


Run with:

C:\&gt; perl get.pl -f sadf
input file is: sadf
get.pl


Run without:

C:\&gt;get.pl -f sadf
input file is:


Nothing!

EDIT:  fixed and this question was a repeat...
http://stackoverflow.com/questions/1695188/how-do-i-make-perl-scripts-recognize-parameters-in-the-win32-cmd-console

The OP of that post figured it out.
I had to do the same but also recreate the assoc in the gui (in addition to in the reg and on the command line with ftype.)  
",Alex,https://stackoverflow.com/users/8676,"fixed and this question was a repeat... http://stackoverflow.com/questions/1695188/how-do-i-make-perl-scripts-recognize-parameters-in-the-win32-cmd-console

The OP of that post figured it out.
I had to do the same but also recreate the assoc in the gui (in addition to in the reg and on the command line with ftype.)

Thanks everyone for your help!
",Alex,https://stackoverflow.com/users/8676,http://stackoverflow.com/questions/4065054/why-do-i-have-to-explicitly-add-perl-before-the-script-for-getops-to-run-properl,STACKOVERFLOW,stackoverflow.com,1.0,0.5555555555555556,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.3333333333333333,0.8888888888888888,Why add Perl explicitly before the getops script runs properly?,"When i run my script like so: 

C:\>perl script.pl -f file

It works fine. But, if I just do:

C:\>script.pl -f file

then I don't get any errors but getopts doesn't assign anything to $opt_f

This works just fine on perl 5.8 Windows XP, but it doesn't work on perl 5.12 on Windows 7.
There aren't any other versions of perl installed (its a new OS build).

Code:

use Getopt::Std;
our ($opt_f);
getopts('f:');
print ""input file is: $opt_f \n"";
print ""$0\n


Run with:

C:\&gt; perl get.pl -f sadf
input file is: sadf
get.pl


Run without:

C:\&gt;get.pl -f sadf
input file is:


Nothing!

EDIT:  fixed and this question was a repeat...
http://stackoverflow.com/questions/1695188/how-do-i-make-perl-scripts-recognize-parameters-in-the-win32-cmd-console

The OP of that post figured it out.
I had to do the same but also recreate the assoc in the gui (in addition to in the reg and on the command line with ftype.)  
","fixed and this question was a repeat... http://stackoverflow.com/questions/1695188/how-do-i-make-perl-scripts-recognize-parameters-in-the-win32-cmd-console

The OP of that post figured it out.
I had to do the same but also recreate the assoc in the gui (in addition to in the reg and on the command line with ftype.)

Thanks everyone for your help!
"
3846,3846,6115,display tag and c choose tag,"I use the following code. But it is always go to the otherwise condition. I checked the value , and those are correctly passed from java to the jsp. Any missing points?

&lt;c:when test=""${pCount &gt; 0}""&gt;
    &lt;display:column class=""colPCount"" property=""pCount "" title=""${titlePCount}"" sortable=""true"" headerClass=""sortable"" /&gt;
&lt;/c:when&gt;
&lt;c:otherwise&gt;
    &lt;display:column class=""colPCount"" title=""${titlePCount}""&gt;&amp;nbsp;-&amp;nbsp;&lt;/display:column&gt;
&lt;/c:otherwise&gt;


For the pcount>0 items, still displaying as  '-' in the display tag. Even I reverse the checking condition like pCount&lt;0 in the first condition checking, the display tag always show the otherwise condition. It always pointing to the otherwise condition for every value.

Edited: Full Code

    &lt;display:table class=""displayTable"" id=""itemList""
        name=""${sessionScope.itemList}"" requestURI=""listItem.action""
        pagesize=""15"" defaultsort=""2"" defaultorder=""ascending"" sort=""list""&gt;
        &lt;display:column class=""colItemName"" property=""name""
            title=""${titleItemName}"" sortable=""true"" headerClass=""sortable""/&gt;
        ...
        &lt;c:choose&gt;
        &lt;c:when test=""${pCount &gt; 0}""&gt;
            &lt;display:column class=""colPCount"" property=""pCount "" title=""${titlePCount}"" sortable=""true"" headerClass=""sortable"" /&gt;
        &lt;/c:when&gt;
        &lt;c:otherwise&gt;
            &lt;display:column class=""colPCount"" title=""${titlePCount}""&gt;&amp;nbsp;-&amp;nbsp;&lt;/display:column&gt;
        &lt;/c:otherwise&gt;
        &lt;/c:choose&gt;
    &lt;/display:table&gt;

",kitokid,https://stackoverflow.com/users/751689,"I think you might be using the display tag library incorrectly.

It looks like what you are trying to do is to display row.pCount if the value is greater than zero, otherwise display -. But what you're actually doing is telling the library to display the entire column differently based on something (pCount, which probably does not exist in the scope you are referencing it... or you're going to have to show us some more code).

Try something like this:

&lt;display:column class=""colPCount"" title=""${titlePCount}"" sortable=""true"" headerClass=""sortable""&gt;
    &lt;c:choose&gt;
        &lt;c:when test=""${row.pCount &gt; 0}""&gt;
            &lt;c:out value=""${row.pCount}"" /&gt;
        &lt;/c:when&gt;
        &lt;c:otherwise&gt;
            &amp;nbsp;-&amp;nbsp;
        &lt;/c:otherwise&gt;
    &lt;/c:choose&gt;
&lt;/display:column&gt;

",Beau Grantham,https://stackoverflow.com/users/1049915,http://stackoverflow.com/questions/12831136/display-tag-and-c-choose-tag,STACKOVERFLOW,stackoverflow.com,0.5555555555555556,0.4444444444444444,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.0,0.6666666666666666,0.8888888888888888,Show tags and select Tags,"I use the following code. But it is always go to the otherwise condition. I checked the value , and those are correctly passed from java to the jsp. Any missing points?

&lt;c:when test=""${pCount &gt; 0}""&gt;
    &lt;display:column class=""colPCount"" property=""pCount "" title=""${titlePCount}"" sortable=""true"" headerClass=""sortable"" /&gt;
&lt;/c:when&gt;
&lt;c:otherwise&gt;
    &lt;display:column class=""colPCount"" title=""${titlePCount}""&gt;&amp;nbsp;-&amp;nbsp;&lt;/display:column&gt;
&lt;/c:otherwise&gt;


For the pcount>0 items, still displaying as  '-' in the display tag. Even I reverse the checking condition like pCount&lt;0 in the first condition checking, the display tag always show the otherwise condition. It always pointing to the otherwise condition for every value.

Edited: Full Code

    &lt;display:table class=""displayTable"" id=""itemList""
        name=""${sessionScope.itemList}"" requestURI=""listItem.action""
        pagesize=""15"" defaultsort=""2"" defaultorder=""ascending"" sort=""list""&gt;
        &lt;display:column class=""colItemName"" property=""name""
            title=""${titleItemName}"" sortable=""true"" headerClass=""sortable""/&gt;
        ...
        &lt;c:choose&gt;
        &lt;c:when test=""${pCount &gt; 0}""&gt;
            &lt;display:column class=""colPCount"" property=""pCount "" title=""${titlePCount}"" sortable=""true"" headerClass=""sortable"" /&gt;
        &lt;/c:when&gt;
        &lt;c:otherwise&gt;
            &lt;display:column class=""colPCount"" title=""${titlePCount}""&gt;&amp;nbsp;-&amp;nbsp;&lt;/display:column&gt;
        &lt;/c:otherwise&gt;
        &lt;/c:choose&gt;
    &lt;/display:table&gt;

","I think you might be using the display tag library incorrectly.

It looks like what you are trying to do is to display row.pCount if the value is greater than zero, otherwise display -. But what you're actually doing is telling the library to display the entire column differently based on something (pCount, which probably does not exist in the scope you are referencing it... or you're going to have to show us some more code).

Try something like this:

&lt;display:column class=""colPCount"" title=""${titlePCount}"" sortable=""true"" headerClass=""sortable""&gt;
    &lt;c:choose&gt;
        &lt;c:when test=""${row.pCount &gt; 0}""&gt;
            &lt;c:out value=""${row.pCount}"" /&gt;
        &lt;/c:when&gt;
        &lt;c:otherwise&gt;
            &amp;nbsp;-&amp;nbsp;
        &lt;/c:otherwise&gt;
    &lt;/c:choose&gt;
&lt;/display:column&gt;

"
4215,4215,6720,Ma'ayanah Shel Torah on the Festivals and 613 Mitzvot?,"On the title page of Ma'ayanah Shel Torah, it says that the series covers the Parshiot, Haftarot, Festivals, and 613 Commandments. I have the 5 volumes on the Parshiot and Haftarot, but they do not cover the Festivals. There is no section for the 613 Commandments either, but some are covered in the Parsha.

Is there a Ma'ayanah Shel Torah on the Festivals?
",Menachem,https://judaism.stackexchange.com/users/603,"Seemingly not. The Hebrew and English Wikipedia articles say that תורה קוואל and its translation מעינה של תורה cover the parashiyos and haftaros, implying that those are the only sections.

Those are all hebrewbooks.org has, too.
",msh210,https://judaism.stackexchange.com/users/170,http://judaism.stackexchange.com/questions/45183/maayanah-shel-torah-on-the-festivals-and-613-mitzvot,CULTURE,judaism.stackexchange.com,0.8888888888888888,0.4444444444444444,0.0,1.0,1.0,1.0,0.4444444444444444,0.4444444444444444,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,0.3333333333333333,1.0,Mayana sheltora on festivals and the 613 bar mitzvah?,"On the title page of mayana sheltora, it said the series covered priests, haftaro, festivals and 613 commandments. I have five books on priests and haftaro, but they don't include festivals. 613 commandments have no chapters, but some chapters are covered in Pasha.","It doesn't seem to be. Both Hebrew and English Wikipedia articles say that this is the only part, including palahijos and haftaros."
1201,1201,1888,Decompiler Bytecode and Obfuscators,"Can we completely reverse-engineer the source code from java bytecode ? Why this feature is allowed in Java and How successful are java decompilers against obfuscators.?
",Suraj Menon,https://stackoverflow.com/users/1662935,"
  Can we completely reverse-engineer the source code from java bytecode
  ?


The java class file is based on a spec so anyone can read into it. A tool like JD-GUI will tear into your source code easily. It is not a 'feature' per se. While 100% reverse-engineering is not possible, most of your code can be reverse engineered.


  How successful are java decompilers against obfuscators?


Depends. The point of the obfuscator is to remove any meaningful names and try to introduce confusion in the code without impacting performance. Most developers are great at obfuscating code themselves :) Pro-guard is pretty good at obfuscation.
",Deepak Bala,https://stackoverflow.com/users/830964,http://stackoverflow.com/questions/13098606/decompiler-bytecode-and-obfuscators,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.3333333333333333,0.0,0.3333333333333333,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.6666666666666666,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,0.8888888888888888,Decompiler bytecode and obfuscator,Can we completely reverse engineer the source code from Java bytecode? Why is this feature allowed in Java and how successful is java decompiler for obfuscator.?,"
  Can we completely reverse-engineer the source code from java bytecode
  ?


The java class file is based on a spec so anyone can read into it. A tool like JD-GUI will tear into your source code easily. It is not a 'feature' per se. While 100% reverse-engineering is not possible, most of your code can be reverse engineered.


  How successful are java decompilers against obfuscators?


Depends. The point of the obfuscator is to remove any meaningful names and try to introduce confusion in the code without impacting performance. Most developers are great at obfuscating code themselves :) Pro-guard is pretty good at obfuscation.
"
2295,2295,3659,using the new facebook payments reports API,"been trying to get data from the facebook payments reports API, since they say on november 7th no more reports will be sent by email.
tried php and got an error - ""SSL connection timeout"".
this is the php curl code i'm using:

$set_action_url = ""https://paymentreports.facebook.com/"".$company_id.""/report?date="".$date.""&amp;type="".$type.""&amp;access_token="".$company_token;
$ch = curl_init($set_action_url);
curl_setopt($ch, CURLOPT_RETURNTRANSFER, true);
curl_setopt($ch,CURLOPT_TIMEOUT,5);
curl_setopt($ch, CURLOPT_CONNECTTIMEOUT ,0);
curl_setopt($ch, CURLOPT_SSL_VERIFYPEER, false);
$result = curl_exec($ch);


i logged the url and query string just before the call, and if i use it in a browser
i do get the file.

what am i doing wrong?
",user1750618,https://stackoverflow.com/users/1750618,"to fetch the zip file, file_get_contents also works
",egiray,https://stackoverflow.com/users/403523,http://stackoverflow.com/questions/12919057/using-the-new-facebook-payments-reports-api,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.3333333333333333,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.6666666666666666,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.0,0.0,0.8888888888888888,Using the new Facebook payment reporting API,"been trying to get data from the facebook payments reports API, since they say on november 7th no more reports will be sent by email.
tried php and got an error - ""SSL connection timeout"".
this is the php curl code i'm using:

$set_action_url = ""https://paymentreports.facebook.com/"".$company_id.""/report?date="".$date.""&amp;type="".$type.""&amp;access_token="".$company_token;
$ch = curl_init($set_action_url);
curl_setopt($ch, CURLOPT_RETURNTRANSFER, true);
curl_setopt($ch,CURLOPT_TIMEOUT,5);
curl_setopt($ch, CURLOPT_CONNECTTIMEOUT ,0);
curl_setopt($ch, CURLOPT_SSL_VERIFYPEER, false);
$result = curl_exec($ch);


i logged the url and query string just before the call, and if i use it in a browser
i do get the file.

what am i doing wrong?
","to fetch the zip file, file_get_contents also works
"
3318,3318,5296,Is there any performance difference between ++i and i++ in C#?,"Is there any performance difference between using something like

for(int i = 0; i &lt; 10; i++) { ... }


and

for(int i = 0; i &lt; 10; ++i) { ... }


or is the compiler able to optimize in such a way that they are equally fast in the case where they are functionally equivalent?

Edit:
This was asked because I had a discussion with a co-worker about it, not because I think its a useful optimization in any practical sense. It is largely academic. 
",Anton,https://stackoverflow.com/users/341413,"In addition to other answers, there can be a difference if your i is not an int. In C++, if it is an object of a class that has operators ++() and ++(int) overloaded, then it can make a difference, and possibly a side effect. Performance of ++i should be better in this case (dependant on the implementation).
",Hosam Aly,https://stackoverflow.com/users/41283,http://stackoverflow.com/questions/467322/is-there-any-performance-difference-between-i-and-i-in-c,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.8888888888888888,0.0,0.0,1.0,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.8888888888888888,0.8333333333333334,0.4444444444444444,0.8333333333333334,0.7777777777777778,0.5,0.0,0.0,0.3333333333333333,0.7777777777777778,Is there any performance difference between + + I and I + + in C + +?,"Is there any performance difference between using something like

for(int i = 0; i &lt; 10; i++) { ... }


and

for(int i = 0; i &lt; 10; ++i) { ... }


or is the compiler able to optimize in such a way that they are equally fast in the case where they are functionally equivalent?

Edit:
This was asked because I had a discussion with a co-worker about it, not because I think its a useful optimization in any practical sense. It is largely academic. 
","In addition to other answers, there can be a difference if your i is not an int. In C++, if it is an object of a class that has operators ++() and ++(int) overloaded, then it can make a difference, and possibly a side effect. Performance of ++i should be better in this case (dependant on the implementation).
"
4097,4097,6535,"Broker (AirTicket24) has changed part of flight, can i ask a full refund?","I have booked flight from broker, flight is from Riga RIX to Goa GOI, now part of my trip has changed.
3 9W2354H 24APR MAA GOI   1035  1315 (cancelled flight) 
 4 9W2305H 24APR MAA BLR   0820  0910   (new flight)

5 9W 498H 24APR  BLR GOI    1025  1140   (new flight)

6 9W 427H 05MAY GOI BOM    1855  2005  (cancelled flight)

7 9W2374H 05MAY GOI BOM   0545  0700  (new flight)
Broker offers only partial refund (full price was 550 Eur)

We would like to inform you that unfortunately the airline company does not accept the request for full refund in case of cancellation so according the airline's rules your e-ticket fare is non-refundable. The refundable amount is 85.62 € for both passengers. This amount will be reimbursed within a maximum of 30 working days after the airline's authorization. For any change or cancellation our agency charges 30.00 €.

Now we prefer not to take a flight at all, may i ask a full refund because a part of booking has be changed?
",Alex,https://travel.stackexchange.com/users/28153,"It's probably not the broker who changed the flight but the airline, which indeed has the right to cancel and/or reschedule flights. However it would seem that, according to the FAQ page from AirTicket24, you can ask for compensation in case of substantial changes:


  23. What happens if the airline changes its flights?
  
  The airlines are sometimes forced to modify the itineraries, hours and number of their flights. In this case we will try to inform you for any changes before the date of departure so that you adjust your program to these changes. These changes are usually of minor importance without significant impact on your trip. If significant changes occur related to your flight (for example change in departure time for more than 2 hours or change of departure airport) and you have no alternative that suits you then you can request compensation from the airline, according to the passenger's rights established by the European Union, unless you have been informed on time by the airline.


Hence I would go ahead and contact both your broker, quoting the FAQ, add well as your airline to see what can be arranged. 
",JoErNanO,https://travel.stackexchange.com/users/22140,http://travel.stackexchange.com/questions/45473/broker-airticket24-has-changed-part-of-flight-can-i-ask-a-full-refund,CULTURE,travel.stackexchange.com,1.0,0.6666666666666666,0.3333333333333333,1.0,0.3333333333333333,1.0,0.6666666666666666,0.7777777777777778,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.7333333333333333,0.3333333333333333,0.0,0.6666666666666666,1.0,Agent (ticket 24) changed some flights. Can I ask for a full refund?,"I have booked flight from broker, flight is from Riga RIX to Goa GOI, now part of my trip has changed.
3 9W2354H 24APR MAA GOI   1035  1315 (cancelled flight) 
 4 9W2305H 24APR MAA BLR   0820  0910   (new flight)

5 9W 498H 24APR  BLR GOI    1025  1140   (new flight)

6 9W 427H 05MAY GOI BOM    1855  2005  (cancelled flight)

7 9W2374H 05MAY GOI BOM   0545  0700  (new flight)
Broker offers only partial refund (full price was 550 Eur)

We would like to inform you that unfortunately the airline company does not accept the request for full refund in case of cancellation so according the airline's rules your e-ticket fare is non-refundable. The refundable amount is 85.62 € for both passengers. This amount will be reimbursed within a maximum of 30 working days after the airline's authorization. For any change or cancellation our agency charges 30.00 €.

Now we prefer not to take a flight at all, may i ask a full refund because a part of booking has be changed?
","It's probably not the broker who changed the flight but the airline, which indeed has the right to cancel and/or reschedule flights. However it would seem that, according to the FAQ page from AirTicket24, you can ask for compensation in case of substantial changes:


  23. What happens if the airline changes its flights?
  
  The airlines are sometimes forced to modify the itineraries, hours and number of their flights. In this case we will try to inform you for any changes before the date of departure so that you adjust your program to these changes. These changes are usually of minor importance without significant impact on your trip. If significant changes occur related to your flight (for example change in departure time for more than 2 hours or change of departure airport) and you have no alternative that suits you then you can request compensation from the airline, according to the passenger's rights established by the European Union, unless you have been informed on time by the airline.


Hence I would go ahead and contact both your broker, quoting the FAQ, add well as your airline to see what can be arranged. 
"
4129,4129,6592,97 Honda Civic dies in neutral,"I have a 97 Honda Civic that will occasionally die in neutral. This is what I have done so far:


Replace both O2 sensors
Replace MAP sensor
Replace Air filter
Added Lucas treatment to fuel tank 


Even after the above changes, occasionally when coasting in neutral the rpm's will eventually drop to 0 and the engine will die. It starts back up just fine. My engine and fuel mileage have definitively improved with all the changes, especially after using Lucas.
",BrandonG,https://mechanics.stackexchange.com/users/4549,"Try replacing the main relay, and the distributor cap and rotor is also a likely culprit.

http://www.amazon.com/Beck-Arnley-203-0129-Main-Relay/dp/B001KSEKCK

1999 Honda Accord Coupe Stalls After Warm Startup and Shaky Idle TSB
",Scott Hillson,https://mechanics.stackexchange.com/users/2336,http://mechanics.stackexchange.com/questions/8856/97-honda-civic-dies-in-neutral,CULTURE,mechanics.stackexchange.com,1.0,0.6666666666666666,0.0,0.0,0.3333333333333333,0.0,0.8888888888888888,0.6666666666666666,0.3333333333333333,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,1.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.6666666666666666,0.3333333333333333,0.6666666666666666,1.0,97 Honda Civic died in neutral,"I have a 97 Honda Civic that will occasionally die in neutral. This is what I have done so far:


Replace both O2 sensors
Replace MAP sensor
Replace Air filter
Added Lucas treatment to fuel tank 


Even after the above changes, occasionally when coasting in neutral the rpm's will eventually drop to 0 and the engine will die. It starts back up just fine. My engine and fuel mileage have definitively improved with all the changes, especially after using Lucas.
","Try replacing the main relay, and the distributor cap and rotor is also a likely culprit.

http://www.amazon.com/Beck-Arnley-203-0129-Main-Relay/dp/B001KSEKCK

1999 Honda Accord Coupe Stalls After Warm Startup and Shaky Idle TSB
"
4594,4594,7280,What does 'liberal to' mean here?,"
  Any state
  that makes its choices after most others do will find itself playing in the
  late innings of a game, as the West Virginia Supreme Court found in a
  case about whether car makers were responsible if their vehicles failed to
  protect people who negligently got into accidents:
  
  
    ...[I]n some world other than the one in which we live, where this Court
    were called upon to make national policy, we might very well take a meat
    ax to some current product liability rules. Therefore, we do not claim that
    our adoption of rules liberal to plaintiffs comports[,] necessarily, with some
    Platonic ideal of perfect justice.
  


Source: p 124, The Legal Analyst, Ward Farnsworth

My guess is Definition 1.1 below. Yet is this use right? 


  Favourable to or respectful of individual rights and freedoms:


The definition concerns 'right and freedoms', while the context is individuals (as plaintiffs)
",Canada - Area 51 Proposal,https://ell.stackexchange.com/users/8712,"from http://dictionary.reference.com/browse/liberal


  Synonyms
  
  
  progressive. 7. broad-minded, unprejudiced. 9. beneficent, charitable, openhanded, munificent, unstinting, lavish. See generous. 10. See ample.
  


http://dictionary.reference.com/browse/generous


  1.
  liberal in giving or sharing; unselfish: 


http://dictionary.reference.com/browse/charitable


  1.
  generous in donations or gifts ...
  2.
  kindly or lenient in judging people, acts, etc.


I'm going to have to go with definition 4 (with implications of 3 as well):


  3 (Especially of an interpretation of a law) broadly construed or understood; not strictly literal: they could have given the 1968 Act a more liberal interpretation
  
  4 Given, used, or occurring in generous amounts: liberal amounts of wine had been consumed


The judge is saying, ""Just because, with these rules, I'm giving the plaintiffs almost everything they're asking for by broadly construing rules in their favor, that doesn't mean I think it's a good idea. I don't get to make the law, I have to apply the law that's given to me via precedent.""

Now exactly what the word ""comports"" means, as a plural noun, is another question. I can't find a relevant definition. It seems to have a specific legal meaning of like ""demands"".
",Alex J.,https://ell.stackexchange.com/users/9054,http://ell.stackexchange.com/questions/31990/what-does-liberal-to-mean-here,CULTURE,ell.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.5555555555555556,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.8888888888888888,0.7777777777777778,0.8888888888888888,1.0,1.0,0.8,0.0,0.0,0.6666666666666666,0.7777777777777778,"What does ""freedom"" mean here?","
  Any state
  that makes its choices after most others do will find itself playing in the
  late innings of a game, as the West Virginia Supreme Court found in a
  case about whether car makers were responsible if their vehicles failed to
  protect people who negligently got into accidents:
  
  
    ...[I]n some world other than the one in which we live, where this Court
    were called upon to make national policy, we might very well take a meat
    ax to some current product liability rules. Therefore, we do not claim that
    our adoption of rules liberal to plaintiffs comports[,] necessarily, with some
    Platonic ideal of perfect justice.
  


Source: p 124, The Legal Analyst, Ward Farnsworth

My guess is Definition 1.1 below. Yet is this use right? 


  Favourable to or respectful of individual rights and freedoms:


The definition concerns 'right and freedoms', while the context is individuals (as plaintiffs)
","from http://dictionary.reference.com/browse/liberal


  Synonyms
  
  
  progressive. 7. broad-minded, unprejudiced. 9. beneficent, charitable, openhanded, munificent, unstinting, lavish. See generous. 10. See ample.
  


http://dictionary.reference.com/browse/generous


  1.
  liberal in giving or sharing; unselfish: 


http://dictionary.reference.com/browse/charitable


  1.
  generous in donations or gifts ...
  2.
  kindly or lenient in judging people, acts, etc.


I'm going to have to go with definition 4 (with implications of 3 as well):


  3 (Especially of an interpretation of a law) broadly construed or understood; not strictly literal: they could have given the 1968 Act a more liberal interpretation
  
  4 Given, used, or occurring in generous amounts: liberal amounts of wine had been consumed


The judge is saying, ""Just because, with these rules, I'm giving the plaintiffs almost everything they're asking for by broadly construing rules in their favor, that doesn't mean I think it's a good idea. I don't get to make the law, I have to apply the law that's given to me via precedent.""

Now exactly what the word ""comports"" means, as a plural noun, is another question. I can't find a relevant definition. It seems to have a specific legal meaning of like ""demands"".
"
2592,2592,4122,How can I make a graph of a function?,"I'm trying to implement a function to LaTeX but i don't know how. I'm compiling using this  page: docs.latexlab.org
",Garmen1778,https://tex.stackexchange.com/users/12498,"Compile the following code with xelatex or a combo sequence latex-dvips-ps2pdf.



\documentclass[pstricks,border=12pt]{standalone}
\usepackage{pst-plot}

\begin{document}
\begin{pspicture}(-4.25,-1.25)(4.25,2.25)
    \def\f(#1){sin(2*#1)+0.5}
    \psaxes[labelFontSize=\scriptscriptstyle,ticksize=-2pt 2pt]{-&gt;}(0,0)(-4,-1)(4,2)[$x$,0][$y$,90]
    \psplot[linecolor=blue,algebraic]{-\psPi}{\psPi}{\f(x)}
    \rput[tl](*1 {\f(x)+0.5}){$y=\sin(2x)+\frac{1}{2}$}
\end{pspicture}
\end{document}


Explanation


Making diagrams (including function plotting) can be accomplished by using PSTricks (recommended because it is faster and easier to learn yet powerful) or TikZ  or others. The code above is written in PSTricks, you need to load \usepackage{pst-plot}.
To get a tight page, use 

\documentclass[pstricks,border=12pt]{standalone}

Define a canvas on which you draw.

\begin{pspicture}(-4.25,-1.25)(4.25,2.25)
 ... drawing codes go here ...
\end{pspicture}


(-4.25,-1.25) represents the bottom left point of your canvas and (4.25,2.25) is the top right point.
Define the function to plot.

\def\f(#1){sin(2*#1)+0.5}


In this example I chose y=sin(2x)+1/2.
Draw the coordinate axes.

\psaxes[labelFontSize=\scriptscriptstyle,ticksize=-2pt 2pt]{-&gt;}(0,0)(-4,-1)(4,2)[$x$,0][$y$,90]

Plot the graph.

\psplot[linecolor=blue,algebraic]{-\psPi}{\psPi}{\f(x)}

Put a label if necessary.

 \rput[tl](*1 {\f(x)+0.5}){$y=\sin(2x)+\frac{1}{2}$}


In PSTricks, we can specify a point in several ways. (*&lt;x-value&gt; {the value of expression in x for the given x}) is one of them. Thus (*1 {\f(x)+0.5}) mathematically means a point (x,y) where x=1 and y=f(1)+0.5.
Compile the input file with xelatex or the combo sequence latex-dvips-ps2pdf.
Done!


Miscellaneous

\psplot[linecolor=blue,algebraic,plotpoints=100]{Pi neg .5 sub}{Pi .5 add}{\f(x)}



The plotpoints can be used to increase the number of points used to plot the graph. But be wise, the greater its value is, the smoother the plot is but the bigger the file size becomes. For most extreme case, plotpoints=1000 should be more than enough. 
The first and second arguments of \psplot can accept RPN notation. In the example above, I used -π-.5 and π+.5 for both args, respectively. PSTricks gives you many good features, right?

",kiss my armpit,https://tex.stackexchange.com/users/19356,http://tex.stackexchange.com/questions/47594/how-can-i-make-a-graph-of-a-function,TECHNOLOGY,tex.stackexchange.com,1.0,0.5555555555555556,0.0,0.3333333333333333,1.0,0.6666666666666666,0.6666666666666666,0.4444444444444444,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.8888888888888888,0.8888888888888888,0.7777777777777778,1.0,1.0,0.8,1.0,0.3333333333333333,0.6666666666666666,0.8888888888888888,How to draw the graph of function?,"I'm trying to implement a function to latex, but I don't know how. I am compiling using the following page: docs.latexlab.org","Compile the following code with xelatex or a combo sequence latex-dvips-ps2pdf.



\documentclass[pstricks,border=12pt]{standalone}
\usepackage{pst-plot}

\begin{document}
\begin{pspicture}(-4.25,-1.25)(4.25,2.25)
    \def\f(#1){sin(2*#1)+0.5}
    \psaxes[labelFontSize=\scriptscriptstyle,ticksize=-2pt 2pt]{-&gt;}(0,0)(-4,-1)(4,2)[$x$,0][$y$,90]
    \psplot[linecolor=blue,algebraic]{-\psPi}{\psPi}{\f(x)}
    \rput[tl](*1 {\f(x)+0.5}){$y=\sin(2x)+\frac{1}{2}$}
\end{pspicture}
\end{document}


Explanation


Making diagrams (including function plotting) can be accomplished by using PSTricks (recommended because it is faster and easier to learn yet powerful) or TikZ  or others. The code above is written in PSTricks, you need to load \usepackage{pst-plot}.
To get a tight page, use 

\documentclass[pstricks,border=12pt]{standalone}

Define a canvas on which you draw.

\begin{pspicture}(-4.25,-1.25)(4.25,2.25)
 ... drawing codes go here ...
\end{pspicture}


(-4.25,-1.25) represents the bottom left point of your canvas and (4.25,2.25) is the top right point.
Define the function to plot.

\def\f(#1){sin(2*#1)+0.5}


In this example I chose y=sin(2x)+1/2.
Draw the coordinate axes.

\psaxes[labelFontSize=\scriptscriptstyle,ticksize=-2pt 2pt]{-&gt;}(0,0)(-4,-1)(4,2)[$x$,0][$y$,90]

Plot the graph.

\psplot[linecolor=blue,algebraic]{-\psPi}{\psPi}{\f(x)}

Put a label if necessary.

 \rput[tl](*1 {\f(x)+0.5}){$y=\sin(2x)+\frac{1}{2}$}


In PSTricks, we can specify a point in several ways. (*&lt;x-value&gt; {the value of expression in x for the given x}) is one of them. Thus (*1 {\f(x)+0.5}) mathematically means a point (x,y) where x=1 and y=f(1)+0.5.
Compile the input file with xelatex or the combo sequence latex-dvips-ps2pdf.
Done!


Miscellaneous

\psplot[linecolor=blue,algebraic,plotpoints=100]{Pi neg .5 sub}{Pi .5 add}{\f(x)}



The plotpoints can be used to increase the number of points used to plot the graph. But be wise, the greater its value is, the smoother the plot is but the bigger the file size becomes. For most extreme case, plotpoints=1000 should be more than enough. 
The first and second arguments of \psplot can accept RPN notation. In the example above, I used -π-.5 and π+.5 for both args, respectively. PSTricks gives you many good features, right?

"
5003,5003,7965,Forefront (Identity Manager/Sync Service) missing from Service Manager,"I am building a new testing environment, and in the process I have noticed that the Forefront services are missing from the Service Manager. Is there a way to add these services? This is the first time I have seen these missing. I am a local admin on the server. We are running Server 2008 R2 Enterprise with SP1
",Jason,https://sharepoint.stackexchange.com/users/4344,"I've seen this before.  Running a Install-SPService fixed it for me - http://sharepoint.nauplius.net/2011/06/missing-user-profile-synchronization.html.
",Trevor Seward,https://sharepoint.stackexchange.com/users/6024,http://sharepoint.stackexchange.com/questions/53508/forefront-identity-manager-sync-service-missing-from-service-manager,TECHNOLOGY,sharepoint.stackexchange.com,1.0,0.7777777777777778,0.0,1.0,1.0,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,1.0,Missing forefront in Service Manager (Identity Manager / synchronization service),"I'm building a new test environment, and in the process, I notice that the service manager lacks the forefront service. Is there a way to add these services? This is the first time I've seen these things disappear. I am the local administrator on the server. We are running server 2008 R2 enterprise with SP1",I've seen this before. Running install spsservice fixed it for me - http://sharepoint.nauplius.net/2011/06/missing-user-profile-synchronization.html.
3666,3666,5848,c stack smashing detected on file managing,"I'm having problem with my program. The variables are written in italian, I'm sorry!
I have to handle the penalties phase of a football game. If in the first five penalties the teams end tie, they will go for penalties to the end.

    if (retiPrimaSquadra != retiSecondaSquadra){
        buffer = fopen(""buffer.txt"", ""w"");
        fprintf(buffer, ""%d-%d"", retiPrimaSquadra, retiSecondaSquadra);
        fclose(buffer);
        return 0;
    }   else {
        printf(""Risultato secondo tempo supplementare: %d - %d\n\n"", retiPrimaSquadra, retiSecondaSquadra);
        printf(""RIGORI\n"");

        int rigoreA=0, rigoreB=0;
        char vRigoreA[5];
        char vRigoreB[5];
        int rigore=0;
        int i=0;

        vRigoreA[i]='x';

        //printf(""%c"", vRigoreA[i]);
        for(i=0; i&lt;5; i++){
        //tiro prima squadra
            rigore = (rand() % 101);
            if(rigore &lt;= 75){
                rigoreA++;
                retiPrimaSquadra++;
                vRigoreA[i]='x';
            }
            else{
                vRigoreA[i]='o';
            }
        //tiro seconda squadra
            rigore = (rand() % 101);
            if(rigore &lt;= 75){
                rigoreB++;
                retiSecondaSquadra++;
                vRigoreB[i]='x';
            }
            else{
                vRigoreB[i]='o';
            }
        //stampa xo
        printf(""%c %c\n"", vRigoreA[i], vRigoreB[i]);
        }
        //risultato 5 rigori
        printf(""%d - %d\n"", rigoreA, rigoreB);

        char enter = '\0';
        while(enter != '\n'){
            enter = getchar();
        }

        //OLTRANZA
        while(rigoreA==rigoreB){
            //tiro prima squadra
            rigore = (rand() % 101);
            if(rigore &lt;= 75){
                rigoreA++;
                retiPrimaSquadra++;
                vRigoreA[i]='x';
            }   else {
                vRigoreA[i]='o';
            }

            //tiro seconda squadra
            rigore = (rand() % 101);
            if(rigore &lt;= 75){
                rigoreB++;  
                retiSecondaSquadra++;
                vRigoreB[i]='x';
            }
            else{
                vRigoreB[i]='o';
            }
        //stampa xo
        printf(""%c %c\n"", vRigoreA[i], vRigoreB[i]);

        }

        printf(""check\n"");  
    }

    buffer = fopen(""buffer.txt"", ""w"");
    fprintf(buffer, ""%d-%d"", retiPrimaSquadra, retiSecondaSquadra);
    fclose(buffer);

}


The program runs with no errors if it doesn't enter in the last ""while"". Otherwise, after finishing the while cycle, when it goes to right the results in the buffer.txt file, it gives me a stack smashing detected problem. I really don't know how to handle it, cause it seems so stupid that if it doesn't enter the while it goes fine!
",Astinog,https://stackoverflow.com/users/1492438,"You are using i to access your vRigoreA array in the while (vRigoreA[i]='x';). However, i is set to 5 after your for-loop, so you are accessing stack memory not belonging to the array. At the end of the function, the debugger detects that out-of-bounds writes happened.
",MicroVirus,https://stackoverflow.com/users/2718186,http://stackoverflow.com/questions/24034820/c-stack-smashing-detected-on-file-managing,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.4444444444444444,0.0,1.0,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,0.8,0.6666666666666666,0.0,1.0,1.0,C stack crash detected in file management,"I'm having problem with my program. The variables are written in italian, I'm sorry!
I have to handle the penalties phase of a football game. If in the first five penalties the teams end tie, they will go for penalties to the end.

    if (retiPrimaSquadra != retiSecondaSquadra){
        buffer = fopen(""buffer.txt"", ""w"");
        fprintf(buffer, ""%d-%d"", retiPrimaSquadra, retiSecondaSquadra);
        fclose(buffer);
        return 0;
    }   else {
        printf(""Risultato secondo tempo supplementare: %d - %d\n\n"", retiPrimaSquadra, retiSecondaSquadra);
        printf(""RIGORI\n"");

        int rigoreA=0, rigoreB=0;
        char vRigoreA[5];
        char vRigoreB[5];
        int rigore=0;
        int i=0;

        vRigoreA[i]='x';

        //printf(""%c"", vRigoreA[i]);
        for(i=0; i&lt;5; i++){
        //tiro prima squadra
            rigore = (rand() % 101);
            if(rigore &lt;= 75){
                rigoreA++;
                retiPrimaSquadra++;
                vRigoreA[i]='x';
            }
            else{
                vRigoreA[i]='o';
            }
        //tiro seconda squadra
            rigore = (rand() % 101);
            if(rigore &lt;= 75){
                rigoreB++;
                retiSecondaSquadra++;
                vRigoreB[i]='x';
            }
            else{
                vRigoreB[i]='o';
            }
        //stampa xo
        printf(""%c %c\n"", vRigoreA[i], vRigoreB[i]);
        }
        //risultato 5 rigori
        printf(""%d - %d\n"", rigoreA, rigoreB);

        char enter = '\0';
        while(enter != '\n'){
            enter = getchar();
        }

        //OLTRANZA
        while(rigoreA==rigoreB){
            //tiro prima squadra
            rigore = (rand() % 101);
            if(rigore &lt;= 75){
                rigoreA++;
                retiPrimaSquadra++;
                vRigoreA[i]='x';
            }   else {
                vRigoreA[i]='o';
            }

            //tiro seconda squadra
            rigore = (rand() % 101);
            if(rigore &lt;= 75){
                rigoreB++;  
                retiSecondaSquadra++;
                vRigoreB[i]='x';
            }
            else{
                vRigoreB[i]='o';
            }
        //stampa xo
        printf(""%c %c\n"", vRigoreA[i], vRigoreB[i]);

        }

        printf(""check\n"");  
    }

    buffer = fopen(""buffer.txt"", ""w"");
    fprintf(buffer, ""%d-%d"", retiPrimaSquadra, retiSecondaSquadra);
    fclose(buffer);

}


The program runs with no errors if it doesn't enter in the last ""while"". Otherwise, after finishing the while cycle, when it goes to right the results in the buffer.txt file, it gives me a stack smashing detected problem. I really don't know how to handle it, cause it seems so stupid that if it doesn't enter the while it goes fine!
","You are using i to access your vRigoreA array in the while (vRigoreA[i]='x';). However, i is set to 5 after your for-loop, so you are accessing stack memory not belonging to the array. At the end of the function, the debugger detects that out-of-bounds writes happened.
"
4489,4489,7119,"Why isn't ""Column ordering"" available in my list settings?","I want to change the column order visible when viewing or editing a list item. I have accessed the ""Column ordering"" interface via the list settings page on other lists in the past, but it isn't visible in this list's settings.



Cheers!
",Pete,https://sharepoint.stackexchange.com/users/6300,"Change the order of the columns in the list's settings (or the content type)
",Colin,https://sharepoint.stackexchange.com/users/250,http://sharepoint.stackexchange.com/questions/29643/why-isnt-column-ordering-available-in-my-list-settings,TECHNOLOGY,sharepoint.stackexchange.com,1.0,0.8888888888888888,0.0,1.0,1.0,1.0,0.7777777777777778,0.4444444444444444,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.8888888888888888,0.8333333333333334,0.6666666666666666,0.8333333333333334,1.0,0.8,1.0,0.0,0.0,0.7777777777777778,Why is column sorting not available in my list settings?,"I want to change the order of columns that are visible when I view or edit list items. I have previously accessed the column sorting interface through the list settings page of other lists, but I can't see it in the list settings.",Change the order of columns in list settings (or content types)
1780,1780,2827,Decompiler Bytecode and Obfuscators,"Can we completely reverse-engineer the source code from java bytecode ? Why this feature is allowed in Java and How successful are java decompilers against obfuscators.?
",Suraj Menon,https://stackoverflow.com/users/1662935,"
  Can we completely reverse-engineer the source code from java bytecode ?


Not completely, because some aspects of source code, such as whitespace, local variable names, and comments, are not preserved in bytecode. Otherwise, yes -- while you can't get the exact same source code out, you can almost always get something that can at least be compiled back to the same bytecode.


  Why this feature is allowed in Java


It's not so much ""allowed"" as it is ""not prevented"". And it's not prevented because doing so is impossible -- the code must be runnable to be useful; if the code is runnable, then it is analyzable; if it is analyzable, then with sufficient analysis it can be converted back to source.


  How successful are java decompilers against obfuscators?


Not very. Most obfuscators I've seen (esp. ProGuard) are primarily effective in removing meaningful function and class names; obfuscating the logic itself is not typically attempted.
",duskwuff,https://stackoverflow.com/users/149341,http://stackoverflow.com/questions/13098606/decompiler-bytecode-and-obfuscators,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.3333333333333333,0.0,1.0,1.0,1.0,0.6666666666666666,0.4444444444444444,1.0,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,0.0,0.3333333333333333,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,0.8888888888888888,Decompiler bytecode and obfuscator,Can we completely reverse engineer the source code from Java bytecode? Why is this feature allowed in Java and how successful is java decompiler for obfuscator.?,"
  Can we completely reverse-engineer the source code from java bytecode ?


Not completely, because some aspects of source code, such as whitespace, local variable names, and comments, are not preserved in bytecode. Otherwise, yes -- while you can't get the exact same source code out, you can almost always get something that can at least be compiled back to the same bytecode.


  Why this feature is allowed in Java


It's not so much ""allowed"" as it is ""not prevented"". And it's not prevented because doing so is impossible -- the code must be runnable to be useful; if the code is runnable, then it is analyzable; if it is analyzable, then with sufficient analysis it can be converted back to source.


  How successful are java decompilers against obfuscators?


Not very. Most obfuscators I've seen (esp. ProGuard) are primarily effective in removing meaningful function and class names; obfuscating the logic itself is not typically attempted.
"
72,72,112,Trigger IP ban based on request of given file?,"I run a website where ""x.php"" was known to have vulnerabilities. The vulnerability has been fixed and I don't have ""x.php"" on my site anymore.

As such with major public vulnerabilities, it seems script kiddies around are running tools that hitting my site looking for ""x.php"" in the entire structure of the site - constantly, 24/7.

This is wasted bandwidth, traffic and load that I don't really need.

Is there a way to trigger a time-based (or permanent) ban to an IP address that tries to access ""x.php"" anywhere on my site?

Perhaps I need a custom 404 PHP page that captures the fact that the request was for ""x.php"" and then that triggers the ban? How can I do that?

Thanks!

EDIT:

I should add that part of hardening my site, I've started using ZBBlock:


  This php security script is designed
  to detect certain behaviors
  detrimental to websites, or known bad
  addresses attempting to access your
  site. It then will send the bad robot
  (usually) or hacker an authentic 403
  FORBIDDEN page with a description of
  what the problem was. If the attacker
  persists, then they will be served up
  a permanently reccurring 503 OVERLOAD
  message with a 24 hour timeout.


But ZBBlock doesn't do quite exactly what I want to do, it does help with other spam/script/hack blocking.
",Mike Atlas,https://webmasters.stackexchange.com/users/5448,"Recreate x.php and have it collect the IP address of anyone trying to reaching it. Then create (or modify) a .htaccess file that blocks them using Apache. The .htaccess file will look like this:

order deny,allow
deny from 123.123.123.123
deny from 353.345.345.345


Just keep appending to that file any IP address you want banned.

The x.php might look like this: (untested)

&lt;?php
    $fp = fopen('.htaccess', 'w');
    fwrite($fp, 'deny from  ' . $_SERVER['REMOTE_ADDR'] . ""\n"");
    fclose($fp);
?&gt;

",John Conde,https://webmasters.stackexchange.com/users/1253,http://webmasters.stackexchange.com/questions/9247/trigger-ip-ban-based-on-request-of-given-file,TECHNOLOGY,webmasters.stackexchange.com,1.0,0.5555555555555556,0.0,1.0,0.6666666666666666,1.0,0.6666666666666666,0.4444444444444444,0.3333333333333333,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,0.8888888888888888,Trigger IP inhibit based on request of given file?,"I run a website where ""x.php"" was known to have vulnerabilities. The vulnerability has been fixed and I don't have ""x.php"" on my site anymore.

As such with major public vulnerabilities, it seems script kiddies around are running tools that hitting my site looking for ""x.php"" in the entire structure of the site - constantly, 24/7.

This is wasted bandwidth, traffic and load that I don't really need.

Is there a way to trigger a time-based (or permanent) ban to an IP address that tries to access ""x.php"" anywhere on my site?

Perhaps I need a custom 404 PHP page that captures the fact that the request was for ""x.php"" and then that triggers the ban? How can I do that?

Thanks!

EDIT:

I should add that part of hardening my site, I've started using ZBBlock:


  This php security script is designed
  to detect certain behaviors
  detrimental to websites, or known bad
  addresses attempting to access your
  site. It then will send the bad robot
  (usually) or hacker an authentic 403
  FORBIDDEN page with a description of
  what the problem was. If the attacker
  persists, then they will be served up
  a permanently reccurring 503 OVERLOAD
  message with a 24 hour timeout.


But ZBBlock doesn't do quite exactly what I want to do, it does help with other spam/script/hack blocking.
","Recreate x.php and have it collect the IP address of anyone trying to reaching it. Then create (or modify) a .htaccess file that blocks them using Apache. The .htaccess file will look like this:

order deny,allow
deny from 123.123.123.123
deny from 353.345.345.345


Just keep appending to that file any IP address you want banned.

The x.php might look like this: (untested)

&lt;?php
    $fp = fopen('.htaccess', 'w');
    fwrite($fp, 'deny from  ' . $_SERVER['REMOTE_ADDR'] . ""\n"");
    fclose($fp);
?&gt;

"
2903,2903,4618,Mixed number fractions class,"I'm looking for bugs.  I tried to test all functionality in a variety of ways.

#by JB0x2D1

from decimal import Decimal
import math
import numbers
import operator
from fractions import Fraction

class Mixed(Fraction):
    """"""This class implements Fraction, which implements rational numbers.""""""
        # We're immutable, so use __new__ not __init__
    def __new__(cls, whole=0, numerator=None, denominator=None):
        """"""Constructs a Rational.

        Takes a string like '-1 2/3' or '1.5', another Rational instance, a
        numerator/denominator pair, a float, or a whole number/numerator/
        denominator set.  If one or more non-zero arguments is negative,
        all are treated as negative and the result is negative.

        General behavior:  whole number + (numerator / denominator)

        Examples
        --------

        &gt;&gt;&gt; Mixed(Mixed(-1,1,2), Mixed(0,1,2), Mixed(0,1,2))
        Mixed(-2, 1, 2)
        Note: The above call is similar to:
        &gt;&gt;&gt; Fraction(-3,2) + Fraction(Fraction(-1,2), Fraction(1,2))
        Fraction(-5, 2)
        &gt;&gt;&gt; Mixed('-1 2/3')
        Mixed(-1, 2, 3)
        &gt;&gt;&gt; Mixed(10,-8)
        Mixed(-1, 1, 4)
        &gt;&gt;&gt; Mixed(Fraction(1,7), 5)
        Mixed(0, 1, 35)
        &gt;&gt;&gt; Mixed(Mixed(1, 7), Fraction(2, 3))
        Mixed(0, 3, 14)
        &gt;&gt;&gt; Mixed(Mixed(0, 3, 2), Fraction(2, 3), 2)
        Mixed(1, 5, 6)
        &gt;&gt;&gt; Mixed('314')
        Mixed(314, 0, 1)
        &gt;&gt;&gt; Mixed('-35/4')
        Mixed(-8, 3, 4)
        &gt;&gt;&gt; Mixed('3.1415')
        Mixed(3, 283, 2000)
        &gt;&gt;&gt; Mixed('-47e-2')
        Mixed(0, -47, 100)
        &gt;&gt;&gt; Mixed(1.47)
        Mixed(1, 2116691824864133, 4503599627370496)
        &gt;&gt;&gt; Mixed(2.25)
        Mixed(2, 1, 4)
        &gt;&gt;&gt; Mixed(Decimal('1.47'))
        Mixed(1, 47, 100)

        """"""
        self = super(Fraction, cls).__new__(cls)

        if (numerator is None) and (denominator is None): #single argument
            if isinstance(whole, numbers.Rational) or \
               isinstance(whole, float) or \
               isinstance(whole, Decimal):
                if type(whole) == Mixed:
                    return whole
                f = Fraction(whole)
                whole = 0
            elif isinstance(whole, str):
                # Handle construction from strings.
                arg = whole
                fail = False
                try:
                    f = Fraction(whole)
                    whole = 0
                except ValueError:
                    n = whole.split()
                    if (len(n) == 2):
                        try:
                            whole = Fraction(n[0])
                            f = Fraction(n[1])
                        except ValueError:
                            fail = True
                    else:
                        fail = True
                if fail:
                    raise ValueError('Invalid literal for Mixed: %r' %
                                         arg)
            else:
                raise TypeError(""argument should be a string ""
                                ""or a Rational instance"")
        elif (isinstance(numerator, numbers.Rational) and #two arguments
            isinstance(whole, numbers.Rational) and (denominator is None)):
            #here whole is treated as numerator and numerator as denominator
            if numerator == 0:
                raise ZeroDivisionError('Mixed(%s, 0)' % whole)
            f = Fraction(whole, numerator)
            whole = 0
        elif (isinstance(whole, numbers.Rational) and #three arguments
              isinstance(numerator, numbers.Rational) and
              isinstance(denominator, numbers.Rational)):
            if denominator == 0:
                raise ZeroDivisionError('Mixed(%s, %s, 0)' % whole, numerator)
            whole = Fraction(whole)
            f = Fraction(numerator, denominator)
        else:
            raise TypeError(""all three arguments should be ""
                            ""Rational instances"")
        #handle negative values and convert improper to mixed number fraction
        if (whole &lt; 0) and (f &gt; 0):
            f = -f + whole
        elif (whole &gt; 0) and (f &lt; 0):
            f += -whole
        else:
            f += whole
        numerator = f.numerator
        denominator = f.denominator
        if numerator &lt; 0:
            whole = -(-numerator // denominator)
            numerator = -numerator % denominator
        else:
            whole = numerator // denominator
            numerator %= denominator
        self._whole = whole
        self._numerator = numerator
        self._denominator = denominator
        return self

    def __repr__(self):
        """"""repr(self)""""""
        return ('Mixed(%s, %s, %s)' % (self._whole, self._numerator,
                                       self._denominator))

    def __str__(self):
        """"""str(self)""""""
        if self._numerator == 0:
            return str(self._whole)
        elif self._whole != 0:
            return '%s %s/%s' % (self._whole, self._numerator,
                                 self._denominator)
        else:
            return '%s/%s' % (self._numerator, self._denominator)

    def to_fraction(self):
        n = self._numerator
        if self._whole != 0:
            if self._whole &lt; 0:
                n *= -1
            n += self._whole * self._denominator
        return Fraction(n, self._denominator)

    def limit_denominator(self, max_denominator=1000000):
        """"""Closest Fraction to self with denominator at most max_denominator.

        &gt;&gt;&gt; Mixed('3.141592653589793').limit_denominator(10)
        Mixed(3, 1, 7)
        &gt;&gt;&gt; Mixed('3.141592653589793').limit_denominator(100)
        Mixed(3, 14, 99)
        &gt;&gt;&gt; Mixed(4321, 8765).limit_denominator(10000)
        Mixed(0, 4321, 8765)
        """"""
        return Mixed(self.to_fraction().limit_denominator(max_denominator))

    @property
    def numerator(a):
        return a.to_fraction().numerator

    @property
    def denominator(a):
        return a._denominator

    @property
    def whole(a):
        """"""returns the whole number only (a % 1)

        &gt;&gt;&gt; Mixed(10,3).whole
        3
        """"""
        return a._whole

    @property
    def fnumerator(a):
        """""" returns the fractional portion's numerator.

        &gt;&gt;&gt; Mixed('1 3/4').fnumerator
        3
        """"""
        return a._numerator

    def _add(a, b):
        """"""a + b""""""
        return Mixed(a.numerator * b.denominator +
                     b.numerator * a.denominator,
                     a.denominator * b.denominator)
    __add__, __radd__ = Fraction._operator_fallbacks(_add, operator.add)

    def _sub(a, b):
        """"""a - b""""""
        return Mixed(a.numerator * b.denominator -
                        b.numerator * a.denominator,
                        a.denominator * b.denominator)

    __sub__, __rsub__ = Fraction._operator_fallbacks(_sub, operator.sub)

    def _mul(a, b):
        """"""a * b""""""
        return Mixed(a.numerator * b.numerator, a.denominator * b.denominator)

    __mul__, __rmul__ = Fraction._operator_fallbacks(_mul, operator.mul)


    def _div(a, b):
        """"""a / b""""""
        return Mixed(a.numerator * b.denominator,
                        a.denominator * b.numerator)

    __truediv__, __rtruediv__ = Fraction._operator_fallbacks(_div, operator.truediv)

    def __pow__(a, b):
        """"""a ** b

        If b is not an integer, the result will be a float or complex
        since roots are generally irrational. If b is an integer, the
        result will be rational.

        """"""
        if isinstance(b, numbers.Rational):
            if b.denominator == 1:
                return Mixed(Fraction(a) ** b)
            else:
                # A fractional power will generally produce an
                # irrational number.
                return float(a) ** float(b)
        else:
            return float(a) ** b

    def __rpow__(b, a):
        """"""a ** b""""""
        if b._denominator == 1 and b._numerator &gt;= 0:
            # If a is an int, keep it that way if possible.
            return a ** b.numerator

        if isinstance(a, numbers.Rational):
            return Mixed(a.numerator, a.denominator) ** b

        if b._denominator == 1:
            return a ** b.numerator

        return a ** float(b)

    def __pos__(a):
        """"""+a: Coerces a subclass instance to Fraction""""""
        return Mixed(a.numerator, a.denominator)

    def __neg__(a):
        """"""-a""""""
        return Mixed(-a.numerator, a.denominator)

    def __abs__(a):
        """"""abs(a)""""""
        return Mixed(abs(a.numerator), a.denominator)

    def __trunc__(a):
        """"""trunc(a)""""""
        if a.numerator &lt; 0:
            return -(-a.numerator // a.denominator)
        else:
            return a.numerator // a.denominator

    def __hash__(self):
        """"""hash(self)""""""
        return self.to_fraction().__hash__()

    def __eq__(a, b):
        """"""a == b""""""
        return Fraction(a) == b

    def _richcmp(self, other, op):
        """"""Helper for comparison operators, for internal use only.

        Implement comparison between a Rational instance `self`, and
        either another Rational instance or a float `other`.  If
        `other` is not a Rational instance or a float, return
        NotImplemented. `op` should be one of the six standard
        comparison operators.

        """"""
        return self.to_fraction()._richcmp(other, op)

    def __reduce__(self):
        return (self.__class__, (str(self),))

    def __copy__(self):
        if type(self) == Mixed:
            return self     # I'm immutable; therefore I am my own clone
        return self.__class__(self.numerator, self.denominator)

    def __deepcopy__(self, memo):
        if type(self) == Mixed:
            return self     # My components are also immutable
        return self.__class__(self.numerator, self.denominator)


Latest version download here.
",JB0x2D1,https://codereview.stackexchange.com/users/31982,"Don't ever reinvent the wheel. Fraction is decently cooperative class, you should never have to write basic operations from scratch. Use the inherited stuff. Here is the solution for basic arithmetic, shouldn't be hard to adapt for many other protocols. Also, it doesn't handle negative numbers because I'm lazy, I trust you can add support for that too.

from fractions import Fraction
class Mixed(Fraction):
    def __new__(cls, a, b, c):
        return super().__new__(cls, a*c + b, c)
    def __str__(self):
        return '{} {}'.format(*divmod(Fraction(self), 1))
    def inject(name, *, namespace = locals()):
        name = '__{}__'.format(name)
        def method(*args):
            result = getattr(Fraction, name)(*args)
            return Fraction.__new__(Mixed, result)
        namespace[name] = method
    for name in 'add sub mul truediv'.split():
        inject(name)
        inject('r' + name)
    for name in 'abs pos neg'.split():
        inject(name)
    del name, inject
print(Fraction(122,3) / Mixed(4,5,6) + 5)  # 13 12/29

",Veky,https://codereview.stackexchange.com/users/49039,http://codereview.stackexchange.com/questions/35274/mixed-number-fractions-class,TECHNOLOGY,codereview.stackexchange.com,0.6666666666666666,0.3333333333333333,0.0,0.0,1.0,0.5,0.6666666666666666,0.5,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.9,1.0,0.5,1.0,0.8333333333333334,Mixed number fraction class,"I'm looking for bugs.  I tried to test all functionality in a variety of ways.

#by JB0x2D1

from decimal import Decimal
import math
import numbers
import operator
from fractions import Fraction

class Mixed(Fraction):
    """"""This class implements Fraction, which implements rational numbers.""""""
        # We're immutable, so use __new__ not __init__
    def __new__(cls, whole=0, numerator=None, denominator=None):
        """"""Constructs a Rational.

        Takes a string like '-1 2/3' or '1.5', another Rational instance, a
        numerator/denominator pair, a float, or a whole number/numerator/
        denominator set.  If one or more non-zero arguments is negative,
        all are treated as negative and the result is negative.

        General behavior:  whole number + (numerator / denominator)

        Examples
        --------

        &gt;&gt;&gt; Mixed(Mixed(-1,1,2), Mixed(0,1,2), Mixed(0,1,2))
        Mixed(-2, 1, 2)
        Note: The above call is similar to:
        &gt;&gt;&gt; Fraction(-3,2) + Fraction(Fraction(-1,2), Fraction(1,2))
        Fraction(-5, 2)
        &gt;&gt;&gt; Mixed('-1 2/3')
        Mixed(-1, 2, 3)
        &gt;&gt;&gt; Mixed(10,-8)
        Mixed(-1, 1, 4)
        &gt;&gt;&gt; Mixed(Fraction(1,7), 5)
        Mixed(0, 1, 35)
        &gt;&gt;&gt; Mixed(Mixed(1, 7), Fraction(2, 3))
        Mixed(0, 3, 14)
        &gt;&gt;&gt; Mixed(Mixed(0, 3, 2), Fraction(2, 3), 2)
        Mixed(1, 5, 6)
        &gt;&gt;&gt; Mixed('314')
        Mixed(314, 0, 1)
        &gt;&gt;&gt; Mixed('-35/4')
        Mixed(-8, 3, 4)
        &gt;&gt;&gt; Mixed('3.1415')
        Mixed(3, 283, 2000)
        &gt;&gt;&gt; Mixed('-47e-2')
        Mixed(0, -47, 100)
        &gt;&gt;&gt; Mixed(1.47)
        Mixed(1, 2116691824864133, 4503599627370496)
        &gt;&gt;&gt; Mixed(2.25)
        Mixed(2, 1, 4)
        &gt;&gt;&gt; Mixed(Decimal('1.47'))
        Mixed(1, 47, 100)

        """"""
        self = super(Fraction, cls).__new__(cls)

        if (numerator is None) and (denominator is None): #single argument
            if isinstance(whole, numbers.Rational) or \
               isinstance(whole, float) or \
               isinstance(whole, Decimal):
                if type(whole) == Mixed:
                    return whole
                f = Fraction(whole)
                whole = 0
            elif isinstance(whole, str):
                # Handle construction from strings.
                arg = whole
                fail = False
                try:
                    f = Fraction(whole)
                    whole = 0
                except ValueError:
                    n = whole.split()
                    if (len(n) == 2):
                        try:
                            whole = Fraction(n[0])
                            f = Fraction(n[1])
                        except ValueError:
                            fail = True
                    else:
                        fail = True
                if fail:
                    raise ValueError('Invalid literal for Mixed: %r' %
                                         arg)
            else:
                raise TypeError(""argument should be a string ""
                                ""or a Rational instance"")
        elif (isinstance(numerator, numbers.Rational) and #two arguments
            isinstance(whole, numbers.Rational) and (denominator is None)):
            #here whole is treated as numerator and numerator as denominator
            if numerator == 0:
                raise ZeroDivisionError('Mixed(%s, 0)' % whole)
            f = Fraction(whole, numerator)
            whole = 0
        elif (isinstance(whole, numbers.Rational) and #three arguments
              isinstance(numerator, numbers.Rational) and
              isinstance(denominator, numbers.Rational)):
            if denominator == 0:
                raise ZeroDivisionError('Mixed(%s, %s, 0)' % whole, numerator)
            whole = Fraction(whole)
            f = Fraction(numerator, denominator)
        else:
            raise TypeError(""all three arguments should be ""
                            ""Rational instances"")
        #handle negative values and convert improper to mixed number fraction
        if (whole &lt; 0) and (f &gt; 0):
            f = -f + whole
        elif (whole &gt; 0) and (f &lt; 0):
            f += -whole
        else:
            f += whole
        numerator = f.numerator
        denominator = f.denominator
        if numerator &lt; 0:
            whole = -(-numerator // denominator)
            numerator = -numerator % denominator
        else:
            whole = numerator // denominator
            numerator %= denominator
        self._whole = whole
        self._numerator = numerator
        self._denominator = denominator
        return self

    def __repr__(self):
        """"""repr(self)""""""
        return ('Mixed(%s, %s, %s)' % (self._whole, self._numerator,
                                       self._denominator))

    def __str__(self):
        """"""str(self)""""""
        if self._numerator == 0:
            return str(self._whole)
        elif self._whole != 0:
            return '%s %s/%s' % (self._whole, self._numerator,
                                 self._denominator)
        else:
            return '%s/%s' % (self._numerator, self._denominator)

    def to_fraction(self):
        n = self._numerator
        if self._whole != 0:
            if self._whole &lt; 0:
                n *= -1
            n += self._whole * self._denominator
        return Fraction(n, self._denominator)

    def limit_denominator(self, max_denominator=1000000):
        """"""Closest Fraction to self with denominator at most max_denominator.

        &gt;&gt;&gt; Mixed('3.141592653589793').limit_denominator(10)
        Mixed(3, 1, 7)
        &gt;&gt;&gt; Mixed('3.141592653589793').limit_denominator(100)
        Mixed(3, 14, 99)
        &gt;&gt;&gt; Mixed(4321, 8765).limit_denominator(10000)
        Mixed(0, 4321, 8765)
        """"""
        return Mixed(self.to_fraction().limit_denominator(max_denominator))

    @property
    def numerator(a):
        return a.to_fraction().numerator

    @property
    def denominator(a):
        return a._denominator

    @property
    def whole(a):
        """"""returns the whole number only (a % 1)

        &gt;&gt;&gt; Mixed(10,3).whole
        3
        """"""
        return a._whole

    @property
    def fnumerator(a):
        """""" returns the fractional portion's numerator.

        &gt;&gt;&gt; Mixed('1 3/4').fnumerator
        3
        """"""
        return a._numerator

    def _add(a, b):
        """"""a + b""""""
        return Mixed(a.numerator * b.denominator +
                     b.numerator * a.denominator,
                     a.denominator * b.denominator)
    __add__, __radd__ = Fraction._operator_fallbacks(_add, operator.add)

    def _sub(a, b):
        """"""a - b""""""
        return Mixed(a.numerator * b.denominator -
                        b.numerator * a.denominator,
                        a.denominator * b.denominator)

    __sub__, __rsub__ = Fraction._operator_fallbacks(_sub, operator.sub)

    def _mul(a, b):
        """"""a * b""""""
        return Mixed(a.numerator * b.numerator, a.denominator * b.denominator)

    __mul__, __rmul__ = Fraction._operator_fallbacks(_mul, operator.mul)


    def _div(a, b):
        """"""a / b""""""
        return Mixed(a.numerator * b.denominator,
                        a.denominator * b.numerator)

    __truediv__, __rtruediv__ = Fraction._operator_fallbacks(_div, operator.truediv)

    def __pow__(a, b):
        """"""a ** b

        If b is not an integer, the result will be a float or complex
        since roots are generally irrational. If b is an integer, the
        result will be rational.

        """"""
        if isinstance(b, numbers.Rational):
            if b.denominator == 1:
                return Mixed(Fraction(a) ** b)
            else:
                # A fractional power will generally produce an
                # irrational number.
                return float(a) ** float(b)
        else:
            return float(a) ** b

    def __rpow__(b, a):
        """"""a ** b""""""
        if b._denominator == 1 and b._numerator &gt;= 0:
            # If a is an int, keep it that way if possible.
            return a ** b.numerator

        if isinstance(a, numbers.Rational):
            return Mixed(a.numerator, a.denominator) ** b

        if b._denominator == 1:
            return a ** b.numerator

        return a ** float(b)

    def __pos__(a):
        """"""+a: Coerces a subclass instance to Fraction""""""
        return Mixed(a.numerator, a.denominator)

    def __neg__(a):
        """"""-a""""""
        return Mixed(-a.numerator, a.denominator)

    def __abs__(a):
        """"""abs(a)""""""
        return Mixed(abs(a.numerator), a.denominator)

    def __trunc__(a):
        """"""trunc(a)""""""
        if a.numerator &lt; 0:
            return -(-a.numerator // a.denominator)
        else:
            return a.numerator // a.denominator

    def __hash__(self):
        """"""hash(self)""""""
        return self.to_fraction().__hash__()

    def __eq__(a, b):
        """"""a == b""""""
        return Fraction(a) == b

    def _richcmp(self, other, op):
        """"""Helper for comparison operators, for internal use only.

        Implement comparison between a Rational instance `self`, and
        either another Rational instance or a float `other`.  If
        `other` is not a Rational instance or a float, return
        NotImplemented. `op` should be one of the six standard
        comparison operators.

        """"""
        return self.to_fraction()._richcmp(other, op)

    def __reduce__(self):
        return (self.__class__, (str(self),))

    def __copy__(self):
        if type(self) == Mixed:
            return self     # I'm immutable; therefore I am my own clone
        return self.__class__(self.numerator, self.denominator)

    def __deepcopy__(self, memo):
        if type(self) == Mixed:
            return self     # My components are also immutable
        return self.__class__(self.numerator, self.denominator)


Latest version download here.
","Don't ever reinvent the wheel. Fraction is decently cooperative class, you should never have to write basic operations from scratch. Use the inherited stuff. Here is the solution for basic arithmetic, shouldn't be hard to adapt for many other protocols. Also, it doesn't handle negative numbers because I'm lazy, I trust you can add support for that too.

from fractions import Fraction
class Mixed(Fraction):
    def __new__(cls, a, b, c):
        return super().__new__(cls, a*c + b, c)
    def __str__(self):
        return '{} {}'.format(*divmod(Fraction(self), 1))
    def inject(name, *, namespace = locals()):
        name = '__{}__'.format(name)
        def method(*args):
            result = getattr(Fraction, name)(*args)
            return Fraction.__new__(Mixed, result)
        namespace[name] = method
    for name in 'add sub mul truediv'.split():
        inject(name)
        inject('r' + name)
    for name in 'abs pos neg'.split():
        inject(name)
    del name, inject
print(Fraction(122,3) / Mixed(4,5,6) + 5)  # 13 12/29

"
4161,4161,6632,How should one reconcile a wrong against another person?,"When someone commits a wrong against another person, what is he supposed to do to make things right?  Is seeking forgiveness from God sufficient, or do you first need to set things right with the other person?  If the latter, what are you obligated to do -- apologize, make amends (what kinds), something else?

Does the answer depend on the type of damage done?  For example, is gossip different from property damage, or injury?

Does the answer depend on who was wronged?  Is the obligation to a fellow Christian different than one to a non-Christian? 



I'm looking for a general Christian teaching on this subject.  If there's a wide range of opinions on this, I'd like to know what the teachings are, and the Scriptural support for them.

I am not Christian and thus am not asking what I should do in this case.  I know what is expected of me as a Jew if I have wronged somebody else, and I am curious about how that compares to what your religion teaches about what is expected of a Christian who wrongs another.  I'm not asking about the other side of the case, the obligation to forgive.
",Monica Cellio,https://christianity.stackexchange.com/users/4145,"This is one of those questions that should have a clear, easy answer, but when you ask ""what do Christians believe about this"" you will likely get a lot of different answers.  I'm going to put a preface explaining why those answers vary, and then go into a purely Scriptural view, which is the view you will likely hear from the pulpit of any Church you visit.



Why the answers may vary.

In Christianity, there is a concept of being ""free from the Law of Moses"" through the perfect substitutionary sacrifice of Christ.  The central theme of Christianity is that we can never be ""good enough"" to get to Heaven on our own, and that Jesus is the promised Christ - His sacrifice is what gets us to Heaven, not our own good works.  

One of the questions that varying groups differ (and they differ wildly) is what, exactly it means to be free from the Law of Moses.  There are other questions already on this site that explore that topic, but in a nutshell, there is debate over whether we are obligated to tithe, to refrain from certain things, to perform certain ceremonies, etc.

This applies to your question directly because some groups believe that we are under no obligation to obey the Old Testament commandments regarding this, and others will say we are.  Some will tell you that the Law of Love dictates that we will meet or exceed the requirements of Mosaic Law, and some would accuse those people of Legalism.

That said...



One common teaching

The teaching with which I am the most familiar with comes from the mouth of Jesus, as recorded in Matthew 5:20-24 (King James version)


  20 For I say unto you, That except your righteousness shall exceed the
  righteousness of the scribes and Pharisees, ye shall in no case enter
  into the kingdom of heaven.
  
  21 Ye have heard that it was said of them of old time, Thou shalt not
  kill; and whosoever shall kill shall be in danger of the judgment:
  
  22 But I say unto you, That whosoever is angry with his brother
  without a cause shall be in danger of the judgment: and whosoever
  shall say to his brother, Raca, shall be in danger of the council: but
  whosoever shall say, Thou fool, shall be in danger of hell fire.
  23 Therefore if thou bring thy gift to the altar, and there
  rememberest that thy brother hath ought against thee;
  
  24 Leave there thy gift before the altar, and go thy way; first be
  reconciled to thy brother, and then come and offer thy gift.


This is commonly taught as doing whatever it takes to make it right.  If you have sinned against someone, or even if that person thinks you have sinned against them, and you hadn't intended to, the priority is to reconcile and heal the relationship.

Per His words in verse 24. reconciliation with an offended person takes priority over worship.  (How can we come to God with a clean heart, if we are carrying the stain of sin?)


  Clarke's Commentary on the Bible expands on this:
  
  Leave there thy gift before the altar - This is as much as to say, ""Do
  not attempt to bring any offering to God while thou art in a spirit of
  enmity against any person; or hast any difference with thy neighbor,
  which thou hast not used thy diligence to get adjusted."" It is our
  duty and interest, both to bring our gift, and offer it too; but God
  will not accept of any act of religious worship from us, while any
  enmity subsists in our hearts towards any soul of man; or while any
  subsists in our neighbor's heart towards us, which we have not used
  the proper means to remove. A religion, the very essence of which is
  love, cannot suffer at its altars a heart that is revengeful and
  uncharitable, or which does not use its utmost endeavors to revive
  love in the heart of another. The original word, δωρον, which we
  translate gift, is used by the rabbins in Hebrew letters דורון doron,
  which signifies not only a gift, but a sacrifice offered to God. See
  several proofs in Schoettgen.


The answer to most of your sub-questions are simple, if we take His words at face value:


  Is seeking forgiveness from God sufficient, or do you first need to
  set things right with the other person?


We need to first make it right with the other person.  


  If the latter, what are you obligated to do -- apologize, make amends
  (what kinds), something else?


Whatever it takes to reconcile.  This may be as simple as an honest confession of your sin to the other person, and a sincere apology, it may involve paying something back, it may mean doing something you really don't want to do (so long as that thing isn't sinful).  You may have to apologize before the Church, or admit to peers/friends/families that you've done wrong.

There may be cases where the other offended party will not accept any offer of reconciliation, at which case, we can only do our best.  God knows our hearts and minds better than we can, and He knows both your mind and that of the person who holds something against you.


  Does the answer depend on who was wronged? Is the obligation to a
  fellow Christian different than one to a non-Christian?


No.  Absolutely not.  The obligation to a fellow Christian is no more or less than to a non-Christian.

I've taken the liberty of finding a few teachings on the subject:


http://blog.beliefnet.com/markdroberts/2010/09/what-to-do-when-you-sin-against-someone.html

discusses the importance of attempting to reconcile with the person you've wronged.

http://carm.org/christianity/devotions/confession

echoes the fact that going to God alone isn't enough, you must go to the person you've sinned against.

http://www.victorious.org/churchbook/chur29.htm

Discusses practical, Scriptural guidance for resolving disputed between believers.

http://jpsmind.wordpress.com/2007/01/30/do-we-need-to-confess-our-sins-to-those-we-have-sinned-against/

Speaks to how our relationship with each other reflects our relationship with God.

http://www.gotquestions.org/restitution-Bible.html

Compares Mosaic Law with the New Testament teaching on forgiveness and Repentance


",David Stratton,https://christianity.stackexchange.com/users/721,http://christianity.stackexchange.com/questions/14920/how-should-one-reconcile-a-wrong-against-another-person,CULTURE,christianity.stackexchange.com,1.0,0.5555555555555556,0.6666666666666666,0.0,0.3333333333333333,0.5,0.7777777777777778,0.7777777777777778,0.6666666666666666,0.0,1.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.3333333333333333,0.6666666666666666,0.0,1.0,1.0,0.8888888888888888,1.0,1.0,1.0,0.3333333333333333,0.3333333333333333,1.0,1.0,How should one reconcile one mistake with another?,"When someone commits a wrong against another person, what is he supposed to do to make things right?  Is seeking forgiveness from God sufficient, or do you first need to set things right with the other person?  If the latter, what are you obligated to do -- apologize, make amends (what kinds), something else?

Does the answer depend on the type of damage done?  For example, is gossip different from property damage, or injury?

Does the answer depend on who was wronged?  Is the obligation to a fellow Christian different than one to a non-Christian? 



I'm looking for a general Christian teaching on this subject.  If there's a wide range of opinions on this, I'd like to know what the teachings are, and the Scriptural support for them.

I am not Christian and thus am not asking what I should do in this case.  I know what is expected of me as a Jew if I have wronged somebody else, and I am curious about how that compares to what your religion teaches about what is expected of a Christian who wrongs another.  I'm not asking about the other side of the case, the obligation to forgive.
","This is one of those questions that should have a clear, easy answer, but when you ask ""what do Christians believe about this"" you will likely get a lot of different answers.  I'm going to put a preface explaining why those answers vary, and then go into a purely Scriptural view, which is the view you will likely hear from the pulpit of any Church you visit.



Why the answers may vary.

In Christianity, there is a concept of being ""free from the Law of Moses"" through the perfect substitutionary sacrifice of Christ.  The central theme of Christianity is that we can never be ""good enough"" to get to Heaven on our own, and that Jesus is the promised Christ - His sacrifice is what gets us to Heaven, not our own good works.  

One of the questions that varying groups differ (and they differ wildly) is what, exactly it means to be free from the Law of Moses.  There are other questions already on this site that explore that topic, but in a nutshell, there is debate over whether we are obligated to tithe, to refrain from certain things, to perform certain ceremonies, etc.

This applies to your question directly because some groups believe that we are under no obligation to obey the Old Testament commandments regarding this, and others will say we are.  Some will tell you that the Law of Love dictates that we will meet or exceed the requirements of Mosaic Law, and some would accuse those people of Legalism.

That said...



One common teaching

The teaching with which I am the most familiar with comes from the mouth of Jesus, as recorded in Matthew 5:20-24 (King James version)


  20 For I say unto you, That except your righteousness shall exceed the
  righteousness of the scribes and Pharisees, ye shall in no case enter
  into the kingdom of heaven.
  
  21 Ye have heard that it was said of them of old time, Thou shalt not
  kill; and whosoever shall kill shall be in danger of the judgment:
  
  22 But I say unto you, That whosoever is angry with his brother
  without a cause shall be in danger of the judgment: and whosoever
  shall say to his brother, Raca, shall be in danger of the council: but
  whosoever shall say, Thou fool, shall be in danger of hell fire.
  23 Therefore if thou bring thy gift to the altar, and there
  rememberest that thy brother hath ought against thee;
  
  24 Leave there thy gift before the altar, and go thy way; first be
  reconciled to thy brother, and then come and offer thy gift.


This is commonly taught as doing whatever it takes to make it right.  If you have sinned against someone, or even if that person thinks you have sinned against them, and you hadn't intended to, the priority is to reconcile and heal the relationship.

Per His words in verse 24. reconciliation with an offended person takes priority over worship.  (How can we come to God with a clean heart, if we are carrying the stain of sin?)


  Clarke's Commentary on the Bible expands on this:
  
  Leave there thy gift before the altar - This is as much as to say, ""Do
  not attempt to bring any offering to God while thou art in a spirit of
  enmity against any person; or hast any difference with thy neighbor,
  which thou hast not used thy diligence to get adjusted."" It is our
  duty and interest, both to bring our gift, and offer it too; but God
  will not accept of any act of religious worship from us, while any
  enmity subsists in our hearts towards any soul of man; or while any
  subsists in our neighbor's heart towards us, which we have not used
  the proper means to remove. A religion, the very essence of which is
  love, cannot suffer at its altars a heart that is revengeful and
  uncharitable, or which does not use its utmost endeavors to revive
  love in the heart of another. The original word, δωρον, which we
  translate gift, is used by the rabbins in Hebrew letters דורון doron,
  which signifies not only a gift, but a sacrifice offered to God. See
  several proofs in Schoettgen.


The answer to most of your sub-questions are simple, if we take His words at face value:


  Is seeking forgiveness from God sufficient, or do you first need to
  set things right with the other person?


We need to first make it right with the other person.  


  If the latter, what are you obligated to do -- apologize, make amends
  (what kinds), something else?


Whatever it takes to reconcile.  This may be as simple as an honest confession of your sin to the other person, and a sincere apology, it may involve paying something back, it may mean doing something you really don't want to do (so long as that thing isn't sinful).  You may have to apologize before the Church, or admit to peers/friends/families that you've done wrong.

There may be cases where the other offended party will not accept any offer of reconciliation, at which case, we can only do our best.  God knows our hearts and minds better than we can, and He knows both your mind and that of the person who holds something against you.


  Does the answer depend on who was wronged? Is the obligation to a
  fellow Christian different than one to a non-Christian?


No.  Absolutely not.  The obligation to a fellow Christian is no more or less than to a non-Christian.

I've taken the liberty of finding a few teachings on the subject:


http://blog.beliefnet.com/markdroberts/2010/09/what-to-do-when-you-sin-against-someone.html

discusses the importance of attempting to reconcile with the person you've wronged.

http://carm.org/christianity/devotions/confession

echoes the fact that going to God alone isn't enough, you must go to the person you've sinned against.

http://www.victorious.org/churchbook/chur29.htm

Discusses practical, Scriptural guidance for resolving disputed between believers.

http://jpsmind.wordpress.com/2007/01/30/do-we-need-to-confess-our-sins-to-those-we-have-sinned-against/

Speaks to how our relationship with each other reflects our relationship with God.

http://www.gotquestions.org/restitution-Bible.html

Compares Mosaic Law with the New Testament teaching on forgiveness and Repentance


"
483,483,753,Can I disable the default calendar app notifications?,"This strikes me as a bug since the behaviour is incredibly consistent, but perhaps someone here can help me.

I want to use the google developed calendar app as my main calendar app. My phone (a Galaxy S2) came with a samsung developed calendar app (both very conveniently named ""Calendar""). At this point, I simply want to disable the samsung calendar app from displaying any sort of notifications (since the google app also displays notifications and I want to use that app).

I have been able to do this by going to settings->Notifications in the samsung app and toggling to ""Off"".

However, as soon as I restart the device, the notifications are back on their original settings. Anyone else experience this? Anyone know how to make the settings stick?

EDIT: I notice the notification settings of the google developed app (sound, default reminder time, popup) are also not sticking after reboot. Is my device broken? It seems to only be for calendar. Gmail and other apps hold their settings fine.

EDIT 2: Ok, so disabling the samsung app allows my google app calendar settings to stick after reboot. So looks like that is what I will be doing. Anyone know how I can change the vcs file association to this app now?
",gnomed,https://android.stackexchange.com/users/13279,"I've same issue on my S2.

The problem is a conflict between Google Calendar &amp; Samsung stock calendar.

The second one overwrite settings of Google Calendar.

Only solution is disable it and use Google Calendar.
",Roks,https://android.stackexchange.com/users/35003,http://android.stackexchange.com/questions/33327/can-i-disable-the-default-calendar-app-notifications,TECHNOLOGY,android.stackexchange.com,0.8888888888888888,0.4444444444444444,0.0,1.0,0.6666666666666666,1.0,0.7777777777777778,0.4444444444444444,0.3333333333333333,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.7777777777777778,0.7777777777777778,0.6666666666666666,1.0,1.0,0.7333333333333333,1.0,0.0,0.6666666666666666,0.8888888888888888,Can I disable default calendar app notifications?,"This strikes me as a bug since the behaviour is incredibly consistent, but perhaps someone here can help me.

I want to use the google developed calendar app as my main calendar app. My phone (a Galaxy S2) came with a samsung developed calendar app (both very conveniently named ""Calendar""). At this point, I simply want to disable the samsung calendar app from displaying any sort of notifications (since the google app also displays notifications and I want to use that app).

I have been able to do this by going to settings->Notifications in the samsung app and toggling to ""Off"".

However, as soon as I restart the device, the notifications are back on their original settings. Anyone else experience this? Anyone know how to make the settings stick?

EDIT: I notice the notification settings of the google developed app (sound, default reminder time, popup) are also not sticking after reboot. Is my device broken? It seems to only be for calendar. Gmail and other apps hold their settings fine.

EDIT 2: Ok, so disabling the samsung app allows my google app calendar settings to stick after reboot. So looks like that is what I will be doing. Anyone know how I can change the vcs file association to this app now?
","I've same issue on my S2.

The problem is a conflict between Google Calendar &amp; Samsung stock calendar.

The second one overwrite settings of Google Calendar.

Only solution is disable it and use Google Calendar.
"
1478,1478,2324,Standards/recommendations for Drush make files included in contrib modules,"What are the standards/recommendations for Drush make files that are included in contrib modules? Specifically, should these make files be included by default (module_name.make) or not (module_name.make.example)?

If they should be included, what is the recommended/supported method of overriding/ignoring them? Is there any documentation to point module maintainers to when discussing this in their issue queues?

EDIT: Found this post by jhedstrom from June 2012 recommending naming make files with '.example' suffix. Is this still the recommendation, or have things changed since then?
https://drupal.org/comment/6160018#comment-6160018
",BWPanda,https://drupal.stackexchange.com/users/16537,"@jhedstrom recomendation is valid. Modules should not include a module_name.make file, to prevent drush make running them on recursion. Adding module_name.make.example is desired, and is helpful to build makefiles, specially when the module has several dependencies, including libraries.

OTOH profiles do include makefiles. It is a common practice for a different use case, where discovery and recursion is desired.
",jonhattan,https://drupal.stackexchange.com/users/8437,http://drupal.stackexchange.com/questions/103538/standards-recommendations-for-drush-make-files-included-in-contrib-modules,TECHNOLOGY,drupal.stackexchange.com,1.0,0.3333333333333333,0.0,1.0,1.0,1.0,0.3333333333333333,0.3333333333333333,1.0,0.0,0.5,1.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.5,1.0,Standard / recommendations for the flush make file included in the contrib module,"What are the standards/recommendations for Drush make files that are included in contrib modules? Specifically, should these make files be included by default (module_name.make) or not (module_name.make.example)?

If they should be included, what is the recommended/supported method of overriding/ignoring them? Is there any documentation to point module maintainers to when discussing this in their issue queues?

EDIT: Found this post by jhedstrom from June 2012 recommending naming make files with '.example' suffix. Is this still the recommendation, or have things changed since then?
https://drupal.org/comment/6160018#comment-6160018
","@jhedstrom recomendation is valid. Modules should not include a module_name.make file, to prevent drush make running them on recursion. Adding module_name.make.example is desired, and is helpful to build makefiles, specially when the module has several dependencies, including libraries.

OTOH profiles do include makefiles. It is a common practice for a different use case, where discovery and recursion is desired.
"
4508,4508,7144,Why did Benjen Stark take the Black?,"OK, I've waited until I finished ADWD in case there was any explanation there.

Why was Benjen Stark on the Wall? Was there an explanation I have missed?

I appreciate, as a younger brother, he would have had less opportunity than Brandon (or Eddard), and may have been looking for adventure or honour, but the Wall, by the time he would have joined, was hardly at the height of its renown.

Joining the Black wouldn't be, I would have thought, a particularly obvious option for Benjen, if he was simply looking for a title or a role in life to fit the name of Stark.
",johnc,https://scifi.stackexchange.com/users/34,"The recount of the tournament at Harrenhaal tells us that one of the Starks fell for Ashara Dayne and got her pregnant. It is widely believed that this was Eddard - but the only reason for this seems to be the Eddard/Ashara connection and the rumours of her being John Snow's mother. Such a thing would have been extremely out-of-character for Eddard and Brandon also seems unlikely as, at that point, he was both betrothed to Catelyn and in a tryst with the future Lady Dustin (though this does not rule him out altogether).

However, if we consider the only other character who knew the situation well - Barristan Selmy, who was in love with Ashara - he dismisses the notion of Ashara being John Snow's mother; saying her child was a stillborn girl - the grief over which drove Ashara to suicide. He also (as Meera did) avoids naming the father - referring to him simply as ""Stark"".

If it was not Eddard but Benjen who impregnated Ashara at Harrenhaal, this would provide a far greater reason for him to take the black - his daughter died at birth and the woman he loved killed herself with the grief of it.

Furthermore, if other theories (already noted in previous comments above) about John Snow's parentage are correct - and if Eddard knew of Benjen and Ashara's child - then this theory also explains why Eddard went to Starfall under the pretence of returning Arthur Dayne's sword (surely, given the circumstances, that could have waited a few weeks?) - he knew a Stark bastard was due to be born there and perhaps hoped to pass the infant Jon off as a twin or even replace Ashara's child with Jon.
",user15249,https://scifi.stackexchange.com/users/15249,http://scifi.stackexchange.com/questions/5895/why-did-benjen-stark-take-the-black,LIFE_ARTS,scifi.stackexchange.com,1.0,1.0,0.0,1.0,1.0,1.0,0.5,0.3333333333333333,1.0,0.0,0.5,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.8333333333333334,1.0,1.0,1.0,0.0,0.0,1.0,1.0,Why is Benyon stark taking the black one?,"OK, I've waited until I finished ADWD in case there was any explanation there.

Why was Benjen Stark on the Wall? Was there an explanation I have missed?

I appreciate, as a younger brother, he would have had less opportunity than Brandon (or Eddard), and may have been looking for adventure or honour, but the Wall, by the time he would have joined, was hardly at the height of its renown.

Joining the Black wouldn't be, I would have thought, a particularly obvious option for Benjen, if he was simply looking for a title or a role in life to fit the name of Stark.
","The recount of the tournament at Harrenhaal tells us that one of the Starks fell for Ashara Dayne and got her pregnant. It is widely believed that this was Eddard - but the only reason for this seems to be the Eddard/Ashara connection and the rumours of her being John Snow's mother. Such a thing would have been extremely out-of-character for Eddard and Brandon also seems unlikely as, at that point, he was both betrothed to Catelyn and in a tryst with the future Lady Dustin (though this does not rule him out altogether).

However, if we consider the only other character who knew the situation well - Barristan Selmy, who was in love with Ashara - he dismisses the notion of Ashara being John Snow's mother; saying her child was a stillborn girl - the grief over which drove Ashara to suicide. He also (as Meera did) avoids naming the father - referring to him simply as ""Stark"".

If it was not Eddard but Benjen who impregnated Ashara at Harrenhaal, this would provide a far greater reason for him to take the black - his daughter died at birth and the woman he loved killed herself with the grief of it.

Furthermore, if other theories (already noted in previous comments above) about John Snow's parentage are correct - and if Eddard knew of Benjen and Ashara's child - then this theory also explains why Eddard went to Starfall under the pretence of returning Arthur Dayne's sword (surely, given the circumstances, that could have waited a few weeks?) - he knew a Stark bastard was due to be born there and perhaps hoped to pass the infant Jon off as a twin or even replace Ashara's child with Jon.
"
4989,4989,7943,Is the Panamatic any good?,"Is the Lenspen Panamatic of any real use for creating panoramic shots or is it a waste of money?

More product details
",Shevek,https://photo.stackexchange.com/users/86,"I've never used one, but as far as I can tell it's just a bubble level combined with a device to click through increments of 15 degrees or so.

If my job was shooting panoramas all day long then it might make the process a little less laborious, but if you're taking time of the composition, lighting and camera settings for your panorama then lining the shots up shouldn't take too much effort. 

I normally line up landmarks against the focus points to ensure a consistent overlap. Spirit levels can be useful, but if you don't have one shoot the first and last image of the panorama as a test to check your tripod is level.
",Matt Grum,https://photo.stackexchange.com/users/1375,http://photo.stackexchange.com/questions/5158/is-the-panamatic-any-good,LIFE_ARTS,photo.stackexchange.com,0.8888888888888888,0.7777777777777778,0.3333333333333333,1.0,0.3333333333333333,0.5,0.4444444444444444,0.4444444444444444,0.0,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,1.0,0.5555555555555556,1.0,0.8888888888888888,0.9333333333333332,0.3333333333333333,0.0,1.0,0.8888888888888888,Is there anything good in Pan American?,"Can Lenspen really be used to make panoramic photos, or is it a waste of money?","I've never used one, but as far as I can tell it's just a bubble level combined with a device to click through increments of 15 degrees or so.

If my job was shooting panoramas all day long then it might make the process a little less laborious, but if you're taking time of the composition, lighting and camera settings for your panorama then lining the shots up shouldn't take too much effort. 

I normally line up landmarks against the focus points to ensure a consistent overlap. Spirit levels can be useful, but if you don't have one shoot the first and last image of the panorama as a test to check your tripod is level.
"
5632,5632,8929,Why is it that the product of first N prime numbers + 1 another prime?,"Recently I came across this proof for fact that primes are infinite.

It's a proof by contradiction. The proof assumes that primes are finite and there is a prime M which is larger than any prime out there. Then you basically take the product of all primes up to and including M and you add one to it, which the source where I read this proof claims is a prime obviously larger than M hence a contradiction to our assumption that primes are finite.

So why is it that product of first N primes + 1 another prime? 
",user2340452,https://math.stackexchange.com/users/102019,"Suppose there are only $n$ primes, $p_1,...,p_n$ and let $M=p_1...p_n+1$. If $M$ is composite, then there exists some prime $p_i$ which divides $M$. That is, there exists some $k$ such that $M=p_ik$. Note also that $p_i$ divides $M-1$. Therefore, there is some $\ell$ such that $M-1=p_i\ell$. Hence, we can write $M=p_i\ell+1=p_ik$. Alternately, $p_i(k-\ell)=1$. But this implies that $p_i$ divides $1$ and this is impossible. Therefore, the original assumption, that there are only $n$ primes, $p_1,...,p_n$, must be false.
",user140776,https://math.stackexchange.com/users/140776,http://math.stackexchange.com/questions/1380543/why-is-it-that-the-product-of-first-n-prime-numbers-1-another-prime,SCIENCE,math.stackexchange.com,0.8888888888888888,1.0,0.0,0.6666666666666666,1.0,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,1.0,Why is the product of the first n prime numbers and another prime number?,"Recently I came across this proof for fact that primes are infinite.

It's a proof by contradiction. The proof assumes that primes are finite and there is a prime M which is larger than any prime out there. Then you basically take the product of all primes up to and including M and you add one to it, which the source where I read this proof claims is a prime obviously larger than M hence a contradiction to our assumption that primes are finite.

So why is it that product of first N primes + 1 another prime? 
","Suppose there is only $n $primes, $p_1 , p_n $, and set $m = p_1 P_n+1$. If $M $is compound, then there are some $$PYI $, with a score of $M $. In other words, there are some $k $, making $m = piik $. Also note that $p} I $is divided by $M-1 $. Therefore, there are some $\ ell $, making $M-1 = p_i \ ell $. So, we can write $m = P Nie I \ ell + 1 = P Nie IK $. Or, $p I (k - \ ELL) = 1 $. But that means $p} I $divided by $1 $, which is impossible. Therefore, the initial assumption is that only $n $primes, $p_1 , p_n $, must be wrong."
5552,5552,8819,How are electromagnetic waves differentiated?,"I would like to know how the signals for remote controlled cars, radios, etc.. That use radio waves are told apart from each other. I know that the radio waves are modulated to encode data and the frequency or amplitude are changed, so then the waves are propagated through the air and received at another location via a receiver that is tuned to a certain frequency that the waves were emitted, but I'm sure in most places in the world by now there are numerous amounts of waves traversing at any point, why doesn't the receiver of this device happen to catch another wave of the same frequency instead of the one that was intended? or is there anything that stops me from having a device that emits a wide range of frequencies or amplitudes that would manipulate nearby electronics?
",AlanZ2223,https://physics.stackexchange.com/users/51988,"Radio wave receivers are designed to resonate at a particular frequency. If you look at the response of a resonant device as a function of frequency you get something like (this image is from the Wikipedia article):



This is a rather busy plot, but the point to take away is that the response of the resonant system is greatest when the frequency matches the resonant frequency. The more resonant the system is (the higher its Q factor) the more sharply peaked the response is.

So if you want your radio to pick up just 98.4MHz (the frequency of the radio station I'm listening to at the moment) you tune your receiver to resonate at 98.4MHz. It will still pick up other radio frequencies as well, but because of the resonance it's far more sensitive to the resonant frequency than to the other frequencies.
",John Rennie,https://physics.stackexchange.com/users/1325,http://physics.stackexchange.com/questions/129807/how-are-electromagnetic-waves-differentiated,SCIENCE,physics.stackexchange.com,1.0,0.4444444444444444,0.0,0.3333333333333333,1.0,1.0,0.4444444444444444,0.4444444444444444,1.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,1.0,0.0,0.7777777777777778,1.0,0.5555555555555556,1.0,1.0,0.8666666666666666,0.0,0.6666666666666666,1.0,1.0,How are electromagnetic waves distinguished?,"I want to know the signal of remote control car, radio, etc.. People using radio waves are separated from each other. I know that radio waves are modulated to encode data, and the frequency or amplitude will also change, so these waves are transmitted through the air, then received by one receiver at another location, and the receiver is tuned to a certain frequency, that is, the radio waves are transmitted, but I'm sure that up to now, there are countless waves propagating at any point in most parts of the world, why this Does the device's receiver not happen to catch another wave of the same frequency, rather than a predetermined frequency? Or is there something that prevents me from having a device that can emit a wide range of frequencies or amplitudes to manipulate nearby Electronics?","Radio wave receivers are designed to resonate at a particular frequency. If you look at the response of a resonant device as a function of frequency you get something like (this image is from the Wikipedia article):



This is a rather busy plot, but the point to take away is that the response of the resonant system is greatest when the frequency matches the resonant frequency. The more resonant the system is (the higher its Q factor) the more sharply peaked the response is.

So if you want your radio to pick up just 98.4MHz (the frequency of the radio station I'm listening to at the moment) you tune your receiver to resonate at 98.4MHz. It will still pick up other radio frequencies as well, but because of the resonance it's far more sensitive to the resonant frequency than to the other frequencies.
"
4768,4768,7570,"Can a smaller sensor's ""crop factor"" be used to calculate the exact increase in depth of field?","If APS-C and similar crop-sensor digital cameras have a focal length multiplying effect such that a 50mm lens has an apparent focal length closer to the field of view of an 80mm on a full frame camera, and yet at the same time the depth of field for the smaller sensor camera is more like the depth of field a 50mm lens would produce on a full frame camera (using the same aperture), then this would seem to suggest the concept of an ""aperture dividing effect.""

In other words, a 50mm f/1.8 lens on an APS-C camera would act more like a 80mm f/2.8 (approx. 1.8 * 1.6x) lens in 35mm equivalent — for depth of field, not considering exposure.

Can someone with a better understanding of the physics involved clarify this for me.  I've never seen this concept explicitly mentioned anywhere, so I am a bit suspect of it.
",Sean,https://photo.stackexchange.com/users/1480,"There is no ""focal length multiplier effect"", period.
The focal length of the lens does NOT change magically because you use a smaller or larger sensor, it stays exactly the same.

All you get is an image that's cropped from the one you would have gotten had you used the same lens to record an image on a larger size sensor.
The DOF will thus be the same it would have been had you used that larger sensor as well.
",jwenting,https://photo.stackexchange.com/users/4000,http://photo.stackexchange.com/questions/10079/can-a-smaller-sensors-crop-factor-be-used-to-calculate-the-exact-increase-in,LIFE_ARTS,photo.stackexchange.com,0.7777777777777778,0.7777777777777778,0.0,0.5,1.0,1.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,0.8888888888888888,1.0,0.8,0.0,0.0,1.0,1.0,"Can the ""crop coefficient"" of a smaller sensor be used to calculate the precise increase in depth of field?","If APS-C and similar crop sensor digital cameras have a focal length multiplier effect, which makes the 50mm lens have a focal length closer to the 80mm field of view on the full frame camera, and the depth of field of the smaller sensor camera is more similar to the depth of field camera generated by the 50mm lens on the full frame camera (using the same aperture), then this seems to imply ""aperture segmentation effect"" Concept","There is no ""focal length multiplier effect"", period.
The focal length of the lens does NOT change magically because you use a smaller or larger sensor, it stays exactly the same.

All you get is an image that's cropped from the one you would have gotten had you used the same lens to record an image on a larger size sensor.
The DOF will thus be the same it would have been had you used that larger sensor as well.
"
5246,5246,8342,How to read NTFS drives in Linux (RHEL 6)?,"My system is on dual boot. I have installed both RHEL 6 and win7 in it. I use RHEL mostly and I want to use my windows' NTFS drive in RHEL. How can I do it? Tell me the procedure.


",Chankey Pathak,https://unix.stackexchange.com/users/2063,"A very similar question seems to have been answered over at Super User.

http://superuser.com/questions/251663/unable-to-mount-ntfs-drive-with-rhel-6

Hope that helps.

Edit: 

If you wanted to mount sda3 your command would look like this: 

mount -t ntfs-3g /dev/sda3 /mnt/windows


For more information on ntfs-3g check out the site here.
",Chris Knadler,https://unix.stackexchange.com/users/8487,http://unix.stackexchange.com/questions/16893/how-to-read-ntfs-drives-in-linux-rhel-6,TECHNOLOGY,unix.stackexchange.com,1.0,0.5555555555555556,0.0,0.6666666666666666,1.0,1.0,0.6666666666666666,0.7777777777777778,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.7777777777777778,0.7777777777777778,0.3333333333333333,0.7777777777777778,0.7777777777777778,0.6666666666666667,0.3333333333333333,0.0,0.6666666666666666,0.7777777777777778,How do I read NTFS drives in Linux (RHEL 6)?,"My system is dual booted. I have installed rhel6 and win7. I mainly use RHEL, and I want to use my windows NTFS drive in RHEL. What shall I do? Tell me the procedure.","A very similar question seems to have been answered over at Super User.

http://superuser.com/questions/251663/unable-to-mount-ntfs-drive-with-rhel-6

Hope that helps.

Edit: 

If you wanted to mount sda3 your command would look like this: 

mount -t ntfs-3g /dev/sda3 /mnt/windows


For more information on ntfs-3g check out the site here.
"
1757,1757,2784,US Tax exemption for Independent student contractor working from India,"I am an undergraduate computer science student, resident and citizen of India, I'll be working as an Independent student contractor for a US based software company from my home country (India), during this program I will never go to US and all my payments are a student stipend.

I am in no way a company employee and won't enjoy any benefits of a regular employee, moreover my income is project based there is no fixed based salary.

The company asks me to fill W-8BEN form for tax withholding, but I am not sure if I should pay tax to Indian Govt or to the US state. My questions are mainly:


Who should I pay tax to India/US state ?
Am I eligible for tax exemption from US because of US India tax treaty ?
ref:  http://www.irs.gov/pub/irs-trty/india.pdf  Article 15 (Independent Personal Services)
Do I need to fill any formal tax forms ? If yes which one W-8BEN or 8233(asking for tax exemption) ?
What reason should I specify for tax exemption , being an Independent contractor  not living in US, or being a student ?


I'll be really thankful if someone can please help me regarding this.
Thanks in advance !
",bitgeeky,https://money.stackexchange.com/users/25719,"
  Who should I pay tax to India/US state ?


India.


  Am I eligible for tax exemption from US because of US India tax treaty
  ?


No, because there's nothing to exempt.


  Do I need to fill any formal tax forms ? If yes which one W-8BEN or
  8233(asking for tax exemption) ?


You need to fill W8-BEN showing that you're not a US person for tax purposes.


  What reason should I specify for tax exemption , being an Independent
  contractor not living in US, or being a student ?


Moot since you're not liable for any taxes in the US based on the information you've provided.
",littleadv,https://money.stackexchange.com/users/2998,http://money.stackexchange.com/questions/44658/us-tax-exemption-for-independent-student-contractor-working-from-india,LIFE_ARTS,money.stackexchange.com,1.0,0.3333333333333333,0.0,0.6666666666666666,1.0,1.0,0.5555555555555556,0.4444444444444444,0.6666666666666666,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,0.0,0.5555555555555556,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.9333333333333332,0.0,0.0,1.0,0.8888888888888888,US tax exemption for independent student contractors working in India,"I am an undergraduate computer science student, resident and citizen of India, I'll be working as an Independent student contractor for a US based software company from my home country (India), during this program I will never go to US and all my payments are a student stipend.

I am in no way a company employee and won't enjoy any benefits of a regular employee, moreover my income is project based there is no fixed based salary.

The company asks me to fill W-8BEN form for tax withholding, but I am not sure if I should pay tax to Indian Govt or to the US state. My questions are mainly:


Who should I pay tax to India/US state ?
Am I eligible for tax exemption from US because of US India tax treaty ?
ref:  http://www.irs.gov/pub/irs-trty/india.pdf  Article 15 (Independent Personal Services)
Do I need to fill any formal tax forms ? If yes which one W-8BEN or 8233(asking for tax exemption) ?
What reason should I specify for tax exemption , being an Independent contractor  not living in US, or being a student ?


I'll be really thankful if someone can please help me regarding this.
Thanks in advance !
","
  Who should I pay tax to India/US state ?


India.


  Am I eligible for tax exemption from US because of US India tax treaty
  ?


No, because there's nothing to exempt.


  Do I need to fill any formal tax forms ? If yes which one W-8BEN or
  8233(asking for tax exemption) ?


You need to fill W8-BEN showing that you're not a US person for tax purposes.


  What reason should I specify for tax exemption , being an Independent
  contractor not living in US, or being a student ?


Moot since you're not liable for any taxes in the US based on the information you've provided.
"
2792,2792,4451,Where did Kagami Taiga live when he lived in the US?,"We see a flashback to when Kagami lived in the US in episode 1 of season 2 (26Q). 



Judging from all the palm trees, I'd hazard a guess that he was probably in California. California also seems like the most likely option on a demographic basis (i.e. where are Japanese temporary immigrants most likely to end up?).

Is it ever explicitly stated where he lived? And if it is California, is it ever stated whether he's in SoCal or NorCal (or somewhere else)?
",senshin,https://anime.stackexchange.com/users/1908,"The only indication offhand gets kinda spoilery but 

Character Spoiler: 


   Unrevealed yet in the anime as of episode 1 of Kuroko no Basket S2, Alexandra Garcia, was a college champion in the NCAA from UCLA. In her retirement, she frequented betting courts on the streets (which could technically be anywhere) and eventually runs into Taiga &amp; Himuro. 


Event Spoiler:


   Alexandra trains Taiga &amp; Himuro as kids. Later on Taiga decides to receive training once more from his old master by returning to Los Angeles, so it's pretty suggested that everything took place in SoCal. Here's a pic of an announced airline destination: Chapter 111, page 19 from Batoto.net


I tried to minimize unnecessary spoiling information. Overall, a bit circumstantial, but still enough for me to presume that they're in Southern California. 
",Daz C,https://anime.stackexchange.com/users/2364,http://anime.stackexchange.com/questions/5417/where-did-kagami-taiga-live-when-he-lived-in-the-us,CULTURE,anime.stackexchange.com,1.0,0.4444444444444444,0.0,0.6666666666666666,1.0,1.0,0.6666666666666666,0.3333333333333333,1.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.6666666666666666,0.0,0.7777777777777778,0.8888888888888888,0.7777777777777778,1.0,1.0,0.8666666666666666,0.0,0.0,1.0,0.6666666666666666,Where did Kagame taga live when he was in America?,"We see a flashback to when Kagami lived in the US in episode 1 of season 2 (26Q). 



Judging from all the palm trees, I'd hazard a guess that he was probably in California. California also seems like the most likely option on a demographic basis (i.e. where are Japanese temporary immigrants most likely to end up?).

Is it ever explicitly stated where he lived? And if it is California, is it ever stated whether he's in SoCal or NorCal (or somewhere else)?
","The only indication offhand gets kinda spoilery but 

Character Spoiler: 


   Unrevealed yet in the anime as of episode 1 of Kuroko no Basket S2, Alexandra Garcia, was a college champion in the NCAA from UCLA. In her retirement, she frequented betting courts on the streets (which could technically be anywhere) and eventually runs into Taiga &amp; Himuro. 


Event Spoiler:


   Alexandra trains Taiga &amp; Himuro as kids. Later on Taiga decides to receive training once more from his old master by returning to Los Angeles, so it's pretty suggested that everything took place in SoCal. Here's a pic of an announced airline destination: Chapter 111, page 19 from Batoto.net


I tried to minimize unnecessary spoiling information. Overall, a bit circumstantial, but still enough for me to presume that they're in Southern California. 
"
1443,1443,2272,Identifying sequential patterns,"I am working with sequence data which are long lists of malware win-api calls. I am trying to cast the problem of identifying 'malware behavior' into one of finding sequential patterns. I treat each api call as a single item Itemset. The number of different possible items (api calls) is quite large. 

Now, when I apply the SPADE algorithm (see also, Zaki, SPADE: An Efficient Algorithm for Mining Frequent Sequences, Machine Learning, 42, 31–60, 2001) I run into memory problems.
Is there a better alternative way to find sequential patterns among large high vocabulary sequences?
",chet,https://stats.stackexchange.com/users/4534,"You may try other sequential pattern mining algorithm.

For example, the open-source SPMF java data mining library offers SPADE, but also PrefixSpan, SPAM, CM-SPAM, CM-SPADE, GSP, etc  (by the way, I'm the project founder).  To my knowledge CM-SPADE usually is faster than SPADE.  In terms of memory perhaps that SPAM uses less memory..  You could try it.
",Phil,https://stats.stackexchange.com/users/42902,http://stats.stackexchange.com/questions/14651/identifying-sequential-patterns,SCIENCE,stats.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.0,0.0,1.0,Identify sequence patterns,"I'm working on sequence data, which is a long list of malware win API calls. I try to turn the problem of identifying ""malware behavior"" into the problem of finding sequential patterns. I treat each API call as a single set of items. The number of different possible items (API calls) is quite large.","You may try other sequential pattern mining algorithm.

For example, the open-source SPMF java data mining library offers SPADE, but also PrefixSpan, SPAM, CM-SPAM, CM-SPADE, GSP, etc  (by the way, I'm the project founder).  To my knowledge CM-SPADE usually is faster than SPADE.  In terms of memory perhaps that SPAM uses less memory..  You could try it.
"
4812,4812,7646,Is there a stable Linux distro using btrfs?,"I'm a big fan of ZFS on FreeBSD (I've been using it on my home server since before it got stable; bleeding edge, baby!) and I'd like to try out btrfs to see how that's evolving.

Since it's still largely in development, none of the usual mainstream distros have btrfs as an option. I haven't used Linux in a bunch of years, so I don't really know what my best options are for giving btrfs a try.

Requirements:


easy to install
btrfs supported without requiring me to rebuild the kernel


Thanks!
",chrish,https://superuser.com/users/36842,"openSUSE 11.3 has btrfs support, and is pretty awesome.


  Btrfs has been developed to become the next generation default Linux file system. openSUSE is the first distribution that lets you choose Btrfs in the installer.
  
  The installer will warn you that Btrfs is still experimental, so be cautious of using it on production system. You also have to remember to setup a separate /boot partition as the boot loader will not boot from a Btrfs partition yet.


openSUSE fanboi here
",Sathya,https://superuser.com/users/4377,http://superuser.com/questions/190680,TECHNOLOGY,superuser.com,0.3333333333333333,1.0,0.0,1.0,1.0,1.0,0.6666666666666666,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.8333333333333334,0.8333333333333334,0.6666666666666666,0.8333333333333334,1.0,1.0,0.0,0.0,1.0,1.0,Is there a stable Linux distribution using Btrfs?,"I'm a big fan of ZFS on FreeBSD (I've been using it on my home server since before it got stable; bleeding edge, baby!) and I'd like to try out btrfs to see how that's evolving.

Since it's still largely in development, none of the usual mainstream distros have btrfs as an option. I haven't used Linux in a bunch of years, so I don't really know what my best options are for giving btrfs a try.

Requirements:


easy to install
btrfs supported without requiring me to rebuild the kernel


Thanks!
","openSUSE 11.3 has btrfs support, and is pretty awesome.


  Btrfs has been developed to become the next generation default Linux file system. openSUSE is the first distribution that lets you choose Btrfs in the installer.
  
  The installer will warn you that Btrfs is still experimental, so be cautious of using it on production system. You also have to remember to setup a separate /boot partition as the boot loader will not boot from a Btrfs partition yet.


openSUSE fanboi here
"
5581,5581,8861,Why doesn't my MacBook recognize the original HD any longer?,"I replaced the stock hd with a samsung ssd (840) about 18 months ago. It died last week. I tried putting the original HD back in and the computer won't recognize it. Even when I hold down the option key when booting nothing happens. When I remove the disk and connect it via USB it boots up fine as an external hard drive. Any reason why that would be?
",Alex,https://apple.stackexchange.com/users/87312,"If the original drives does work in an external case but not internally than patrix has the right idea.

We know the old drive is good as it works in an external case
We know the SSD does not work at all because it doesn't work internally or in the Mac.

In both of those cases drives are not working internally, one known bad and one known good. 

Unfortunately that points to a problem with the MacBook itself. It could be a loose connector (at the drive end or the motherboard end) And by connector I mean data and power, check both, end to end. Look for breaks, bends, crimps (that are not part of cable routing). Look for dirty or obstructed contacts. Blow some canned air into the contacts. Ifixit.com has come really great take apart instructions for just about every recent model of Mac/iPad/iPhone. Follow along with there instructions and pictures and look for differences in what theirs looks like and what yours looks like.

Logic dictates that the problem is inside your MacBook. the problem now is finding out where and then how to fix it.
",Steve Chambers,https://apple.stackexchange.com/users/33273,http://apple.stackexchange.com/questions/141510/why-doesnt-my-macbook-recognize-the-original-hd-any-longer,TECHNOLOGY,apple.stackexchange.com,1.0,0.5555555555555556,0.0,1.0,0.6666666666666666,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,0.0,1.0,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8666666666666666,0.6666666666666666,0.0,0.6666666666666666,0.8888888888888888,Why can't my MacBook recognize the original HD anymore?,"About 18 months ago, I replaced the hard disk with Samsung's SSD (840). It died last week. I tried to put the original HD back, but the computer couldn't recognize it. Even if you hold down the option key at startup, nothing happens. When I remove the disk and connect it via USB, it can be started as an external hard disk. Why is that?","If the original drives does work in an external case but not internally than patrix has the right idea.

We know the old drive is good as it works in an external case
We know the SSD does not work at all because it doesn't work internally or in the Mac.

In both of those cases drives are not working internally, one known bad and one known good. 

Unfortunately that points to a problem with the MacBook itself. It could be a loose connector (at the drive end or the motherboard end) And by connector I mean data and power, check both, end to end. Look for breaks, bends, crimps (that are not part of cable routing). Look for dirty or obstructed contacts. Blow some canned air into the contacts. Ifixit.com has come really great take apart instructions for just about every recent model of Mac/iPad/iPhone. Follow along with there instructions and pictures and look for differences in what theirs looks like and what yours looks like.

Logic dictates that the problem is inside your MacBook. the problem now is finding out where and then how to fix it.
"
4981,4981,7932,"/var/lib for holding served data, why?","Acording to the FHS, the directories /lib and /usr/lib are both for libraries (libraries used in /sbin and user libraries, respectively).

But what about the /var/lib folder? Following the same logic this folder should have something like ""variable libraries"" (that sounds strange) but it actually holds data generated and maintained by running programs, or as defined by the wikipedia article: 


  State information. Persistent data modified by programs as they run, e.g., databases, packaging system metadata, etc.


From a fresh view, it makes more sense to put database data and served files under /srv instead of /var/lib
",Bruno Polaco,https://serverfault.com/users/141694,"This is explained in the commit to the new 3.0 version:

http://bzr.linuxfoundation.org/loggerhead/lsb/devel/fhs-spec/revision/26

Specifically, /srv/ is for served, file-system structured data, /var/lib/ is for locally-consumed data. Apache will serve out of /srv as it's filesystem hierarchical. MySQL serves out of /var/lib since only mysqld accesses it and it is not filesystem hierarchical.
",sysadmin1138,https://serverfault.com/users/3038,http://serverfault.com/questions/439903,TECHNOLOGY,serverfault.com,0.7777777777777778,0.4444444444444444,0.3333333333333333,0.0,1.0,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,0.7777777777777778,"/Var / lib for storing service data, why?","Acording to the FHS, the directories /lib and /usr/lib are both for libraries (libraries used in /sbin and user libraries, respectively).

But what about the /var/lib folder? Following the same logic this folder should have something like ""variable libraries"" (that sounds strange) but it actually holds data generated and maintained by running programs, or as defined by the wikipedia article: 


  State information. Persistent data modified by programs as they run, e.g., databases, packaging system metadata, etc.


From a fresh view, it makes more sense to put database data and served files under /srv instead of /var/lib
","This is explained in the commit to the new 3.0 version:

http://bzr.linuxfoundation.org/loggerhead/lsb/devel/fhs-spec/revision/26

Specifically, /srv/ is for served, file-system structured data, /var/lib/ is for locally-consumed data. Apache will serve out of /srv as it's filesystem hierarchical. MySQL serves out of /var/lib since only mysqld accesses it and it is not filesystem hierarchical.
"
2681,2681,4275,Use case of try-except-else statement,"What is the point of using an else clause if there is a return instruction in the except clause?

def foo():
    try:
        # Some code
    except:
        # Some code
        return
    else:
        # Some code


I'm asking this question because the Django documentation does it at some point, in the vote() function. Considering that the return instruction in the except clause will anyway stop the execution of the function, why did they use an else clause to isolate the code that should only be executed if no exception was raised? They could have just omitted the else clause entirely.
",user3084451,https://stackoverflow.com/users/3084451,"If there is no exception in the try: suite, then the else: suite is executed. In other words, only if there is an actual exception is the except: suite reached and the return statement used.

In my view, the return statement is what is redundant here; a pass would have sufficed. I'd use an else: suite to a try when there is additional code that should only be executed if no exception is raised, but could raise exceptions itself that should not be caught.

You are right that a return in the except clause makes using an else: for that section of code somewhat redundant. The whole suite could be de-dented and the else: line removed:

def foo():
    try:
        # Some code
    except:
        # Some code
        return

    # Some code

",Martijn Pieters,https://stackoverflow.com/users/100297,http://stackoverflow.com/questions/20586165/use-case-of-try-except-else-statement,STACKOVERFLOW,stackoverflow.com,1.0,0.3333333333333333,0.0,1.0,1.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,1.0,Use case of try except else statement,"What is the point of using an else clause if there is a return instruction in the except clause?

def foo():
    try:
        # Some code
    except:
        # Some code
        return
    else:
        # Some code


I'm asking this question because the Django documentation does it at some point, in the vote() function. Considering that the return instruction in the except clause will anyway stop the execution of the function, why did they use an else clause to isolate the code that should only be executed if no exception was raised? They could have just omitted the else clause entirely.
","If there is no exception in the try: suite, then the else: suite is executed. In other words, only if there is an actual exception is the except: suite reached and the return statement used.

In my view, the return statement is what is redundant here; a pass would have sufficed. I'd use an else: suite to a try when there is additional code that should only be executed if no exception is raised, but could raise exceptions itself that should not be caught.

You are right that a return in the except clause makes using an else: for that section of code somewhat redundant. The whole suite could be de-dented and the else: line removed:

def foo():
    try:
        # Some code
    except:
        # Some code
        return

    # Some code

"
2893,2893,4602,Using a time to set XY chart axis scaling as in Excel 2003,"In Excel 2003, when you created a XY chart using time as an axis, you could set the scaling of the axis by typing in the date. In Excel 2007, you have to use the decimal version of the time (eg. How many days since some arbitrary earlier date).

A developer posted on a blog that this issue would be fixed in a future release, but all versions of Excel 2007 I have tried have not resolved this issue. The relevant quote:


  Those of you familiar with this technique of converting time to a decimal may recall that Excel 2003 allowed you to enter a date and time like “1/1/07 11:00 AM” directly in the  axis option min/max fields and Excel would calculate the appropriate decimal representation.  This currently does not work in Excel 2007 but will be fixed in a subsequent release. 


I was wondering if there was a way to avoid having to make such a calculation?
",CookieOfFortune,https://superuser.com/users/8249,"I have just copied the data from that blog post into Excel 2010, and typing 11:00 and 17:00 as the minimum and maximum for the x-axis, does gives an axis running between those times as one would expect.
",Neal,https://superuser.com/users/14664,http://superuser.com/questions/148886,TECHNOLOGY,superuser.com,0.8888888888888888,0.4444444444444444,0.0,1.0,1.0,1.0,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.8888888888888888,0.6666666666666666,0.4444444444444444,0.8888888888888888,0.6666666666666666,0.4666666666666667,0.0,0.0,0.3333333333333333,0.8888888888888888,Use Excel 2003 to set the scaling time of XY chart axis,"In Excel 2003, when you created a XY chart using time as an axis, you could set the scaling of the axis by typing in the date. In Excel 2007, you have to use the decimal version of the time (eg. How many days since some arbitrary earlier date).

A developer posted on a blog that this issue would be fixed in a future release, but all versions of Excel 2007 I have tried have not resolved this issue. The relevant quote:


  Those of you familiar with this technique of converting time to a decimal may recall that Excel 2003 allowed you to enter a date and time like “1/1/07 11:00 AM” directly in the  axis option min/max fields and Excel would calculate the appropriate decimal representation.  This currently does not work in Excel 2007 but will be fixed in a subsequent release. 


I was wondering if there was a way to avoid having to make such a calculation?
","I have just copied the data from that blog post into Excel 2010, and typing 11:00 and 17:00 as the minimum and maximum for the x-axis, does gives an axis running between those times as one would expect.
"
971,971,1537,Network database access - How do I connect to a remote database?,"I am able to connect to a specific MS Access Database when it is on the same Windows computer as Mathematica via the command

&lt;&lt; DatabaseLink`;
conn = OpenSQLConnection[JDBC[""odbc"", ""Databasename""]];


However, I cannot figure out how to connect to this database over a local area network -- disregarding trivial network problems (the computers can ping eachother), is this even possible?
",R.S.,https://mathematica.stackexchange.com/users/6704,"Empirically, it is not possible to directly connect Linux (and therefore also not MMA under Linux) to a MS Access data source in an acceptable amount of time. 
An alternative solution is to migrate the .accdb -> MySQL DB, which then can be queried platform independently. How to connect to this DB is described in the MMA documentation (works out of the box). The migration step is, according to MySQL whitepapers, easily possible - I will update this post if this is the case. MS Access can still be used as a convenient frontend to the MySQL DB.
",R.S.,https://mathematica.stackexchange.com/users/6704,http://mathematica.stackexchange.com/questions/24215/network-database-access-how-do-i-connect-to-a-remote-database,TECHNOLOGY,mathematica.stackexchange.com,1.0,0.7777777777777778,0.0,0.6666666666666666,0.3333333333333333,1.0,0.4444444444444444,0.4444444444444444,0.3333333333333333,0.0,1.0,0.6666666666666666,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.0,0.3333333333333333,0.8888888888888888,Network database access - how do I connect to a remote database?,"I am able to connect to a specific MS Access Database when it is on the same Windows computer as Mathematica via the command

&lt;&lt; DatabaseLink`;
conn = OpenSQLConnection[JDBC[""odbc"", ""Databasename""]];


However, I cannot figure out how to connect to this database over a local area network -- disregarding trivial network problems (the computers can ping eachother), is this even possible?
","Empirically, it is not possible to directly connect Linux (and therefore also not MMA under Linux) to a MS Access data source in an acceptable amount of time. 
An alternative solution is to migrate the .accdb -> MySQL DB, which then can be queried platform independently. How to connect to this DB is described in the MMA documentation (works out of the box). The migration step is, according to MySQL whitepapers, easily possible - I will update this post if this is the case. MS Access can still be used as a convenient frontend to the MySQL DB.
"
2109,2109,3357,AppleScript: how to get the current directory of the topmost Terminal,"I want to get the current directory of the topmost Terminal tab/window (via AppleScript or something else, it doesn't really matter). How can I do that?
",Albert,https://stackoverflow.com/users/133374,"Another solution.

get_foregroundterminal_curdir_fast.scpt:

tell application ""Terminal""
    do shell script ""lsof -a -p `lsof -a -c bash -u $USER -d 0 -n | tail -n +2 | awk '{if($NF==\"""" &amp; (tty of front tab of front window) &amp; ""\""){print $2}}'` -d cwd -n | tail -n +2 | awk '{print $NF}'""
end tell


I use lsof itself to get PID of the bash shell of the corresponding Terminal window. This is MUCH faster than using fuser (milliseconds vs. seconds).
",Rockallite,https://stackoverflow.com/users/2293304,http://stackoverflow.com/questions/5290299/applescript-how-to-get-the-current-directory-of-the-topmost-terminal,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.8888888888888888,0.0,1.0,0.3333333333333333,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.0,0.0,1.0,Applescript: how to get the current directory of the top terminal,"I want to get the current directory of the topmost terminal tab / window (it doesn't matter, by Applescript or otherwise). What shall I do?","Another solution.

get_foregroundterminal_curdir_fast.scpt:

tell application ""Terminal""
    do shell script ""lsof -a -p `lsof -a -c bash -u $USER -d 0 -n | tail -n +2 | awk '{if($NF==\"""" &amp; (tty of front tab of front window) &amp; ""\""){print $2}}'` -d cwd -n | tail -n +2 | awk '{print $NF}'""
end tell


I use lsof itself to get PID of the bash shell of the corresponding Terminal window. This is MUCH faster than using fuser (milliseconds vs. seconds).
"
2666,2666,4246,Server compromised - How do I find out what is sending mail,"A friend of mine has a few small businesses and hosts Wordpress-based sites for them on a dedicated host. The Wordpress installs were neglected for awhile and the host ended up getting compromised. There's now 100's of spam messages going out every second. What can I look at to determine what's generating the mail?

The only way I can get the spam to stop is to shutdown Postfix. We've had it off for a few days to prevent spamming, but this also means he can't send mail from his businesses addresses.

If I shutdown both apache and postfix, netstat shows no remote connections except my SSH login. If I then start postfix (but leave apache stopped), 100's of remote connections to port 25 immediately open. This leads me to believe that some process on the host is doing this, rather than something coming in through Wordpress/some rogue script that we missed in the clean-up. There were also IRC bots on here, but we've removed those, and netstat no longer shows any open connections to IRC.

When I look at ps axjf - all of the smtp processes roll up to /usr/libexec/postfix/master, which has a parent id of 1. This doesn't really give me an idea of where the mail is being generated.

Neither ps nor top show any suspicious processes (as far as I can tell).

What else can I look at to see what's creating/sending the mail? I can post the output of ps whatever_flags_you_want both with and without postfix running, if it will help.

Thanks.
",pata,https://unix.stackexchange.com/users/103244,"Thanks for the responses everyone. We did install and run rkhunter, it didn't find anything.

It looks like we actually did take care of this in the initial clean-up, but postfix was trying to resend messages that had been bounced after the host was blacklisted.

There were 100's of thousands of messages stuck in /var/spool/postfix/deferred. I think when I started postfix, it was moving those back to ./active and trying to resend. I just deleted everything in ./deferred and ./active, then started postfix. It doesn't appear that any new messages are being created or sent. I'm thinking this was just me not understanding how postfix works.

I've been running

watch -d -n 1 'ls -lhart /var/spool/postfix/active'

and 

watch 'netstat --program --numeric-hosts --numeric-ports --extend | grep -E "":25|postfix|smtp""'

For about 30 minutes and see no outgoing activity.
",pata,https://unix.stackexchange.com/users/103244,http://unix.stackexchange.com/questions/185023/server-compromised-how-do-i-find-out-what-is-sending-mail,TECHNOLOGY,unix.stackexchange.com,1.0,0.7777777777777778,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.8888888888888888,0.6666666666666666,1.0,1.0,1.0,0.5,1.0,0.5,0.5,1.0,Server compromised - how to find out what to send,"A friend of mine has a few small businesses and hosts Wordpress-based sites for them on a dedicated host. The Wordpress installs were neglected for awhile and the host ended up getting compromised. There's now 100's of spam messages going out every second. What can I look at to determine what's generating the mail?

The only way I can get the spam to stop is to shutdown Postfix. We've had it off for a few days to prevent spamming, but this also means he can't send mail from his businesses addresses.

If I shutdown both apache and postfix, netstat shows no remote connections except my SSH login. If I then start postfix (but leave apache stopped), 100's of remote connections to port 25 immediately open. This leads me to believe that some process on the host is doing this, rather than something coming in through Wordpress/some rogue script that we missed in the clean-up. There were also IRC bots on here, but we've removed those, and netstat no longer shows any open connections to IRC.

When I look at ps axjf - all of the smtp processes roll up to /usr/libexec/postfix/master, which has a parent id of 1. This doesn't really give me an idea of where the mail is being generated.

Neither ps nor top show any suspicious processes (as far as I can tell).

What else can I look at to see what's creating/sending the mail? I can post the output of ps whatever_flags_you_want both with and without postfix running, if it will help.

Thanks.
","Thanks for the responses everyone. We did install and run rkhunter, it didn't find anything.

It looks like we actually did take care of this in the initial clean-up, but postfix was trying to resend messages that had been bounced after the host was blacklisted.

There were 100's of thousands of messages stuck in /var/spool/postfix/deferred. I think when I started postfix, it was moving those back to ./active and trying to resend. I just deleted everything in ./deferred and ./active, then started postfix. It doesn't appear that any new messages are being created or sent. I'm thinking this was just me not understanding how postfix works.

I've been running

watch -d -n 1 'ls -lhart /var/spool/postfix/active'

and 

watch 'netstat --program --numeric-hosts --numeric-ports --extend | grep -E "":25|postfix|smtp""'

For about 30 minutes and see no outgoing activity.
"
2107,2107,3353,How to forcibly disconnect a application listening on a port,"I have an app that doesn't properly stop listening on a port.

How do I force it to stop so I can open the application again/use that port again?
",bobber205,https://serverfault.com/users/24088,"Yup - get TCPView from SysInternals, find the application and the connection, and close it. Failing that, restarting the application, unless the specific app has a way of doing this. Most apps won't.
",mfinni,https://serverfault.com/users/29373,http://serverfault.com/questions/115194,TECHNOLOGY,serverfault.com,1.0,0.7777777777777778,0.0,1.0,0.3333333333333333,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.8888888888888888,0.8888888888888888,0.5555555555555556,0.8888888888888888,1.0,0.8,1.0,0.0,0.0,0.8888888888888888,How to forcibly disconnect an application listening to a port,"I have an app that doesn't properly stop listening on a port.

How do I force it to stop so I can open the application again/use that port again?
","Yup - get TCPView from SysInternals, find the application and the connection, and close it. Failing that, restarting the application, unless the specific app has a way of doing this. Most apps won't.
"
2634,2634,4187,Sodium Bisulfate vs Sodium Bisulfite,"I'm wanting to do a follow up to this Q&amp;A in the cooking stack regarding browning avocados. I specifically want to expand my experiment to to include the options in Wayfaring Stranger's Answer. Unfortunately, I managed to get the wrong stuff, and shipping rules make exchanging it problematic.

I am the proud owner of $500~\mathrm{g}$ of sodium bisulfate ($\ce{NaHSO4}$), instead of sodium bisulfite ($\ce{NaHSO3}$).

Dammit Jim! I'm a cook not a chemist!

What I have learned is that that both compounds are used as food additives towards the same end, and that my stuff has a slightly higher LD50. That's it.

Can anyone advise as to substituting my compound for the other? I'm not interested in tasty guacamole at this point, I'm really only looking at browning. If I'm trying to more or less duplicate the more successful experiments of the University of Florida, should I start with the same ratios? Or more or less of the additive? I can get sodium metabisulfite (also an anti-oxidant food additive) locally, if that would be a better option.

EDIT: So far, answers have all been consistent in that I have a half-kilo of white powder that is useless to me. I will make a trip to the wine-making shop and acquire some sodium metabisulfite. That still leaves me with the question of how much? The University of Florida got the results I'd like to duplicate with $30~\mathrm{mg}$ of sodium bisulfite per $100~\mathrm{g}$ of avocado. Should I start with the same ratio of sodium metabisulfite?
",Jolenealaska,https://chemistry.stackexchange.com/users/8265,"Generally, sodium hydrogen sulfite and sodium hydrogen sulfate are not interchangeable.

Sodium hydrogen sulfite or “sodium bisulfite” (NaHSO3) is used in food processing as sanitising agent for food containers and fermentation equipment, preservative to reduce or prevent microbial spoilage, selective inhibitor of undesirable microorganisms
in the fermentation industries, and as an antioxidant and inhibitor of enzyme-catalysed
oxidative discoloration and non-enzymic browning. The food additive code (the E number, which is commonly found on food labels) of sodium hydrogen sulfite is E 222.

Sodium hydrogen sulfate or “sodium bisulfate” (NaHSO4) is used as acidity regulator. The food additive code of sodium hydrogen sulfate is E 514.
",Loong,https://chemistry.stackexchange.com/users/7951,http://chemistry.stackexchange.com/questions/17321/sodium-bisulfate-vs-sodium-bisulfite,SCIENCE,chemistry.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,0.3333333333333333,1.0,1.0,0.4444444444444444,0.4444444444444444,1.0,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.0,0.0,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,1.0,0.8888888888888888,0.8,0.0,0.0,1.0,0.8888888888888888,Sodium bisulfite vs sodium bisulfite,"I'm wanting to do a follow up to this Q&amp;A in the cooking stack regarding browning avocados. I specifically want to expand my experiment to to include the options in Wayfaring Stranger's Answer. Unfortunately, I managed to get the wrong stuff, and shipping rules make exchanging it problematic.

I am the proud owner of $500~\mathrm{g}$ of sodium bisulfate ($\ce{NaHSO4}$), instead of sodium bisulfite ($\ce{NaHSO3}$).

Dammit Jim! I'm a cook not a chemist!

What I have learned is that that both compounds are used as food additives towards the same end, and that my stuff has a slightly higher LD50. That's it.

Can anyone advise as to substituting my compound for the other? I'm not interested in tasty guacamole at this point, I'm really only looking at browning. If I'm trying to more or less duplicate the more successful experiments of the University of Florida, should I start with the same ratios? Or more or less of the additive? I can get sodium metabisulfite (also an anti-oxidant food additive) locally, if that would be a better option.

EDIT: So far, answers have all been consistent in that I have a half-kilo of white powder that is useless to me. I will make a trip to the wine-making shop and acquire some sodium metabisulfite. That still leaves me with the question of how much? The University of Florida got the results I'd like to duplicate with $30~\mathrm{mg}$ of sodium bisulfite per $100~\mathrm{g}$ of avocado. Should I start with the same ratio of sodium metabisulfite?
","Generally, sodium hydrogen sulfite and sodium hydrogen sulfate are not interchangeable.

Sodium hydrogen sulfite or “sodium bisulfite” (NaHSO3) is used in food processing as sanitising agent for food containers and fermentation equipment, preservative to reduce or prevent microbial spoilage, selective inhibitor of undesirable microorganisms
in the fermentation industries, and as an antioxidant and inhibitor of enzyme-catalysed
oxidative discoloration and non-enzymic browning. The food additive code (the E number, which is commonly found on food labels) of sodium hydrogen sulfite is E 222.

Sodium hydrogen sulfate or “sodium bisulfate” (NaHSO4) is used as acidity regulator. The food additive code of sodium hydrogen sulfate is E 514.
"
2899,2899,4611,Detect user device and assign different jquery (desktop / mobile(ipad)) in js/ jquery?,"&lt;script src=""jsv3/jquery.js""&gt;&lt;/script&gt;
&lt;!--&lt;script src=""jsv3/jquery.mobile-1.2.0.min.js""&gt;&lt;/script&gt;--&gt;


Currently I have insert script for desktop version only because I found that declare two jquery will occur error. Are there any way to check the device type and select different jquery plugin for corresponding device? Thanks 
",Leo Chan,https://stackoverflow.com/users/1280996,"if (navigator.userAgent==""&lt;type&gt;""){ //check your device type

  var fileref=document.createElement('script')
  fileref.setAttribute(""type"",""text/javascript"")
  fileref.setAttribute(""src"", filename)
 }


HTH
",Sovan,https://stackoverflow.com/users/1896937,http://stackoverflow.com/questions/13876411/detect-user-device-and-assign-different-jquery-desktop-mobileipad-in-js-j,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.7777777777777778,0.0,1.0,1.0,1.0,0.5555555555555556,0.5555555555555556,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.5555555555555556,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,0.0,0.7777777777777778,Detect user devices in JS / jQuery and assign different jQuery (desktop / mobile device (iPad))?,"&lt;script src=""jsv3/jquery.js""&gt;&lt;/script&gt;
&lt;!--&lt;script src=""jsv3/jquery.mobile-1.2.0.min.js""&gt;&lt;/script&gt;--&gt;


Currently I have insert script for desktop version only because I found that declare two jquery will occur error. Are there any way to check the device type and select different jquery plugin for corresponding device? Thanks 
","if (navigator.userAgent==""&lt;type&gt;""){ //check your device type

  var fileref=document.createElement('script')
  fileref.setAttribute(""type"",""text/javascript"")
  fileref.setAttribute(""src"", filename)
 }


HTH
"
14,14,18,"multiple keys via HKDF - whats better, one or two applications of HKDF-extract","Assume for the sake of the question that I have two variable-length bit strings, each with 128 bit cryptographic randomness, and I want to extract two 128 bit keys via HKDF-SHA256.

Which alternative is better (if any), and why?


Use a single HKDF-extract on the concatenation of the two strings, and two HKDF-expands with different info strings to get two 128 bit keys.
Use two HKDF-extract operations, one for each bit string, and use a single HKDF-expand on each to get two 128 bit keys.


Or in other words, is it better to HKDF-extract on a longer IKM string and use multiple HKDF-expands, or is it better to use HKDF on independent but shorter IKMs.

My intuition tells me that, if my randomness strings are really as good as I claim, then two independent HKDF extracts are better, but using a single one on the concatenation is, in practice, just as safe, and safer if my input randomness is not actually as good as assumed, so two HKDFs might be more robust in practice.
",Marc Lehmann,https://crypto.stackexchange.com/users/7672,"Realistically, it probably doesn't matter, if all of your premises are accurate.

If it were me, I'd probably concatenate the inputs, then apply a HKDF to the concatenation to derive two keys -- but honestly, it's unlikely to matter.  This is very unlikely to be the weakest link in your system.  Pick something that's easy to implement and easy to understand, and move on: focus your energy on some other aspect of your system.
",D.W.,https://crypto.stackexchange.com/users/351,http://crypto.stackexchange.com/questions/9318/multiple-keys-via-hkdf-whats-better-one-or-two-applications-of-hkdf-extract,TECHNOLOGY,crypto.stackexchange.com,1.0,1.0,0.0,1.0,1.0,0.0,0.6666666666666666,1.0,0.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.3333333333333333,1.0,1.0,0.9,0.0,0.0,0.0,1.0,"Multiple keys through hkdf - what's better, one or two applications extracted by hkdf","Assume for the sake of the question that I have two variable-length bit strings, each with 128 bit cryptographic randomness, and I want to extract two 128 bit keys via HKDF-SHA256.

Which alternative is better (if any), and why?


Use a single HKDF-extract on the concatenation of the two strings, and two HKDF-expands with different info strings to get two 128 bit keys.
Use two HKDF-extract operations, one for each bit string, and use a single HKDF-expand on each to get two 128 bit keys.


Or in other words, is it better to HKDF-extract on a longer IKM string and use multiple HKDF-expands, or is it better to use HKDF on independent but shorter IKMs.

My intuition tells me that, if my randomness strings are really as good as I claim, then two independent HKDF extracts are better, but using a single one on the concatenation is, in practice, just as safe, and safer if my input randomness is not actually as good as assumed, so two HKDFs might be more robust in practice.
","Realistically, it probably doesn't matter, if all of your premises are accurate.

If it were me, I'd probably concatenate the inputs, then apply a HKDF to the concatenation to derive two keys -- but honestly, it's unlikely to matter.  This is very unlikely to be the weakest link in your system.  Pick something that's easy to implement and easy to understand, and move on: focus your energy on some other aspect of your system.
"
2198,2198,3505,How to create properly tree-hierarchy,"I'm using web2py to create an application

I've got 2 different roles: client and referents. Every client can have multiple referents. 
Both client and referent can insert row in a table, called object.

The user table, where client and referent are registered, has a column called ""client_id"".
Every referent in the column_id has the id of the client to whom he reference to.

The problem is: which value should a client have in client_id?
A possible answer could be NULL or the id of the client itself.

Which one is better? Or there's something better?
",asdf,https://dba.stackexchange.com/users/28806,"Main reason why I'd choose NULL is a bit simpler queries - you don't need to care about self-relationship when you are querying ,for instance, number of referred users by the given. You can also save some space in case you create an index on client_id (it usually makes sense) because some RDMS, for example Oracle, don't include NULLs into index, others, like SQL server, allow filtered indexes (WHERE client_id IS NOT NULL). 
",a1ex07,https://dba.stackexchange.com/users/2232,http://dba.stackexchange.com/questions/50704,TECHNOLOGY,dba.stackexchange.com,0.6666666666666666,0.3333333333333333,0.0,0.3333333333333333,1.0,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.7777777777777778,0.4444444444444444,0.7777777777777778,0.7777777777777778,0.7333333333333333,0.0,0.0,1.0,1.0,How to create tree hierarchy correctly,"I'm using web2py to create an application

I've got 2 different roles: client and referents. Every client can have multiple referents. 
Both client and referent can insert row in a table, called object.

The user table, where client and referent are registered, has a column called ""client_id"".
Every referent in the column_id has the id of the client to whom he reference to.

The problem is: which value should a client have in client_id?
A possible answer could be NULL or the id of the client itself.

Which one is better? Or there's something better?
","Main reason why I'd choose NULL is a bit simpler queries - you don't need to care about self-relationship when you are querying ,for instance, number of referred users by the given. You can also save some space in case you create an index on client_id (it usually makes sense) because some RDMS, for example Oracle, don't include NULLs into index, others, like SQL server, allow filtered indexes (WHERE client_id IS NOT NULL). 
"
4125,4125,6584,What's the point in limiting the number of security groups per tenant In OpenStack?,"By default, a tenant (1) can only create 10 security groups (2). Is there any reason to keep this number so low?

(1) http://docs.openstack.org/grizzly/openstack-compute/admin/content//users-and-projects.html:


  Legacy terminology: earlier versions of OpenStack used the term
  ""project"" instead of ""tenant"".


(2) http://docs.openstack.org/user-guide-admin/content/cli_set_quotas.html:

$ nova quota-defaults
+-----------------------------+-------+
| Quota                       | Limit |
+-----------------------------+-------+
| instances                   | 10    |
| cores                       | 20    |
| ram                         | 51200 |
| floating_ips                | 10    |
| fixed_ips                   | -1    |
| metadata_items              | 128   |
| injected_files              | 5     |
| injected_file_content_bytes | 10240 |
| injected_file_path_bytes    | 255   |
| key_pairs                   | 100   |
| security_groups             | 10    |
| security_group_rules        | 20    |
+-----------------------------+-------+

",Franck Dernoncourt,https://serverfault.com/users/126950,"The most obvious effect is to keep firewall rules to a manageable level, which does not have a significant impact on performance. At a certain point, you may end up with too many firewall rules and not enough CPU to process them quickly enough. The default limits may seem low, but they're sufficient for most people, who will never create more than a few security groups with perhaps half a dozen rules each.
",Michael Hampton,https://serverfault.com/users/126632,http://serverfault.com/questions/571442,TECHNOLOGY,serverfault.com,1.0,0.7777777777777778,0.0,0.6666666666666666,0.6666666666666666,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,0.8888888888888888,What's the point of limiting the number of security groups per tenant in openstack?,"By default, a tenant (1) can only create 10 security groups (2). Is there any reason to keep this number so low?

(1) http://docs.openstack.org/grizzly/openstack-compute/admin/content//users-and-projects.html:


  Legacy terminology: earlier versions of OpenStack used the term
  ""project"" instead of ""tenant"".


(2) http://docs.openstack.org/user-guide-admin/content/cli_set_quotas.html:

$ nova quota-defaults
+-----------------------------+-------+
| Quota                       | Limit |
+-----------------------------+-------+
| instances                   | 10    |
| cores                       | 20    |
| ram                         | 51200 |
| floating_ips                | 10    |
| fixed_ips                   | -1    |
| metadata_items              | 128   |
| injected_files              | 5     |
| injected_file_content_bytes | 10240 |
| injected_file_path_bytes    | 255   |
| key_pairs                   | 100   |
| security_groups             | 10    |
| security_group_rules        | 20    |
+-----------------------------+-------+

","The most obvious effect is to keep firewall rules to a manageable level, which does not have a significant impact on performance. At a certain point, you may end up with too many firewall rules and not enough CPU to process them quickly enough. The default limits may seem low, but they're sufficient for most people, who will never create more than a few security groups with perhaps half a dozen rules each.
"
3137,3137,4998,"My visa period start on arrival, would they let me get into the plane?","I have a question, I applied for the Schengen visa through Germany, on the form they ask me when I'd arriving (to Germany) and when I'd returning. they take this exact date as the visa period.

I wondering if they would let me get into the plane, even though my flight it a day before the arrival.

Let get the real deal; let say this:

My visa is valid from 02/12/2014 to 02/02/2015. But, my flight is scheduled to be departing on 01/12/2014, but entering Germany 02/12/2014. the flight duration is almost 9hours and there is 7hours difference between Germany and the departing flight country.
",user20722,https://travel.stackexchange.com/users/20722,"The purpose of the airline checking your  ticket, visa and passport is to ensure that they can legally transport you to your destination, and believe from that evidence that you will be permitted into the country of destination.

For this to occur, you need to usually show some or all of:


a return ticket, or exit ticket out of the destination country
a valid passport, sometimes with pages/months free on the passport
a visa for the country, valid for when you enter the country


So, for this question, the focus is on the visa. Their simple process will be - when he arrives, will he have a valid visa? Yes. Great, approved.

Similarly, if your visa was valid on the day you left and NOT when you arrived (ie you were arriving at the end of your visa for some weird reason) they'd hopefully not let you board, as when you arrive, your visa wouldn't be valid.

Conclusion: Fly, and enjoy Germany!
",Mark Mayo,https://travel.stackexchange.com/users/101,http://travel.stackexchange.com/questions/37336/my-visa-period-start-on-arrival-would-they-let-me-get-into-the-plane,CULTURE,travel.stackexchange.com,1.0,0.7777777777777778,0.0,1.0,1.0,1.0,0.5555555555555556,0.5555555555555556,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,0.8888888888888888,My visa period starts from the time of arrival. Will they let me on the plane?,"I have a question, I applied for the Schengen visa through Germany, on the form they ask me when I'd arriving (to Germany) and when I'd returning. they take this exact date as the visa period.

I wondering if they would let me get into the plane, even though my flight it a day before the arrival.

Let get the real deal; let say this:

My visa is valid from 02/12/2014 to 02/02/2015. But, my flight is scheduled to be departing on 01/12/2014, but entering Germany 02/12/2014. the flight duration is almost 9hours and there is 7hours difference between Germany and the departing flight country.
","The purpose of the airline checking your  ticket, visa and passport is to ensure that they can legally transport you to your destination, and believe from that evidence that you will be permitted into the country of destination.

For this to occur, you need to usually show some or all of:


a return ticket, or exit ticket out of the destination country
a valid passport, sometimes with pages/months free on the passport
a visa for the country, valid for when you enter the country


So, for this question, the focus is on the visa. Their simple process will be - when he arrives, will he have a valid visa? Yes. Great, approved.

Similarly, if your visa was valid on the day you left and NOT when you arrived (ie you were arriving at the end of your visa for some weird reason) they'd hopefully not let you board, as when you arrive, your visa wouldn't be valid.

Conclusion: Fly, and enjoy Germany!
"
2399,2399,3829,viewForAnnotation detail disclosure changing current location as well as pins,"In my viewForAnnotation method I am adding a detail disclosure button to the right of the pin, however it changes the showsUserLocation to be a red pin, with a disclosure button to the right of the ""Current Location"" text.

How can I stop the current location symbol from being a pin? Without the method it is fine.

- (MKAnnotationView *)mapView:(MKMapView *)mapView viewForAnnotation:(id &lt;MKAnnotation&gt;)annotation {

    static NSString *identifier = @""MyLocation"";

        MKPinAnnotationView *annotationView =
        (MKPinAnnotationView *)[mapView dequeueReusableAnnotationViewWithIdentifier:identifier];

        if (annotationView == nil) {
            annotationView = [[MKPinAnnotationView alloc]
                              initWithAnnotation:annotation
                              reuseIdentifier:identifier];
        } else {
            annotationView.annotation = annotation;
        }

        annotationView.enabled = YES;
        annotationView.canShowCallout = YES;

        // Create a UIButton object to add on the
        UIButton *rightButton = [UIButton buttonWithType:UIButtonTypeDetailDisclosure];
        [rightButton setTitle:annotation.title forState:UIControlStateHighlighted];
        [annotationView setRightCalloutAccessoryView:rightButton];

    return annotationView;
}

",Josh Boothe,https://stackoverflow.com/users/1862869,"add in the beginning of the method

 if (annotation == mapView.userLocation) {
    return nil;
}

",nerowolfe,https://stackoverflow.com/users/2354060,http://stackoverflow.com/questions/16854361/viewforannotation-detail-disclosure-changing-current-location-as-well-as-pins,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.5555555555555556,0.0,1.0,1.0,1.0,0.4444444444444444,0.4444444444444444,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9,1.0,0.3333333333333333,0.0,0.8888888888888888,View notification details disclosure for changing current location and pins,"In my viewForAnnotation method I am adding a detail disclosure button to the right of the pin, however it changes the showsUserLocation to be a red pin, with a disclosure button to the right of the ""Current Location"" text.

How can I stop the current location symbol from being a pin? Without the method it is fine.

- (MKAnnotationView *)mapView:(MKMapView *)mapView viewForAnnotation:(id &lt;MKAnnotation&gt;)annotation {

    static NSString *identifier = @""MyLocation"";

        MKPinAnnotationView *annotationView =
        (MKPinAnnotationView *)[mapView dequeueReusableAnnotationViewWithIdentifier:identifier];

        if (annotationView == nil) {
            annotationView = [[MKPinAnnotationView alloc]
                              initWithAnnotation:annotation
                              reuseIdentifier:identifier];
        } else {
            annotationView.annotation = annotation;
        }

        annotationView.enabled = YES;
        annotationView.canShowCallout = YES;

        // Create a UIButton object to add on the
        UIButton *rightButton = [UIButton buttonWithType:UIButtonTypeDetailDisclosure];
        [rightButton setTitle:annotation.title forState:UIControlStateHighlighted];
        [annotationView setRightCalloutAccessoryView:rightButton];

    return annotationView;
}

","add in the beginning of the method

 if (annotation == mapView.userLocation) {
    return nil;
}

"
4149,4149,6617,Saying Baruch Shepatrani for a girl,"Do you say Boruch Shepatrani for a girl at her Bas Mitzva? If not, why not?
",Gershon Gold,https://judaism.stackexchange.com/users/200,"Rav Ovadya Yosef, in Yabia Omer 6 OC 29, writes that one should say the blessing (ברוך שפטרני מעונשה של זו) at the Bat Mitzva celebration without God's name, just as one should recite it without God's name at a boy's Bar Mitzva celebration.
",Double AA,https://judaism.stackexchange.com/users/759,http://judaism.stackexchange.com/questions/15897/saying-baruch-shepatrani-for-a-girl,CULTURE,judaism.stackexchange.com,0.7777777777777778,0.4444444444444444,0.0,0.3333333333333333,1.0,1.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.6666666666666666,1.0,1.0,"For a girl, Baruch shepattani","You say that polluk shepattani is for a girl at her rite of passage? If not, why not?","In yabia Omar 6 OC 29, RAF owadia Joseph wrote that in bat rite of passage without God's name, people should say blessings, just as in boy rite of passage without God's name, people should recite without God's name."
3696,3696,5890,How to make extra crispy and crunchy breading like KFC?,"I'm wondering how I would go about making extra crispy chicken breading like they do at many places like KFC and the like. Is there a certain ingredient that makes the breading like that?

Any assistance would be very much appreciated, and feel free to share any of your own recipes for crispy chicken breading if you have them. I'll be sure to put them to good use!

Thanks!
",James Mowery,https://cooking.stackexchange.com/users/2109,"I normally use all purpose flour cornmeal onion powder garlic powder paprika and meat tenderizer.Just wet the chicken with water or with marinade,toss in a ziploc with flour and seasonings.Then fry for 20 or 25 min in the fry daddy and presto!!!!
",jason,https://cooking.stackexchange.com/users/17174,http://cooking.stackexchange.com/questions/5764/how-to-make-extra-crispy-and-crunchy-breading-like-kfc,LIFE_ARTS,cooking.stackexchange.com,1.0,0.8888888888888888,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,1.0,0.8888888888888888,0.4444444444444444,1.0,0.8888888888888888,0.6666666666666667,0.6666666666666666,0.3333333333333333,0.0,0.7777777777777778,How to make crisp bread like KFC?,"I'm wondering how I would go about making extra crispy chicken breading like they do at many places like KFC and the like. Is there a certain ingredient that makes the breading like that?

Any assistance would be very much appreciated, and feel free to share any of your own recipes for crispy chicken breading if you have them. I'll be sure to put them to good use!

Thanks!
","I normally use all purpose flour cornmeal onion powder garlic powder paprika and meat tenderizer.Just wet the chicken with water or with marinade,toss in a ziploc with flour and seasonings.Then fry for 20 or 25 min in the fry daddy and presto!!!!
"
4182,4182,6672,"Why does SFDC create a Lead via the LMA, but Checkout creates an Account when a payment is processed","I understand a Checkout transaction is ""sold"" - does SFDC just expect the ISV to convert the lead created via the LMA?

It would be great to hear what other ISVs are doing here.
",Rich Rosen,https://salesforce.stackexchange.com/users/2650,"This behavior follows the methodology design of salesforce.com. A lead is an unqualified sale opportunity, and an account is a closed sale. The idea is that sales associates would follow up on LMA-created leads to try and close the deal, while those that subscribe would be listed as accounts (so you can track the opportunities, customer portal access to cases, and so on).
",sfdcfox,https://salesforce.stackexchange.com/users/2984,http://salesforce.stackexchange.com/questions/10958/why-does-sfdc-create-a-lead-via-the-lma-but-checkout-creates-an-account-when-a,TECHNOLOGY,salesforce.stackexchange.com,0.8888888888888888,0.7777777777777778,0.0,0.5,1.0,1.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.8888888888888888,0.7777777777777778,0.6666666666666666,0.8888888888888888,0.8888888888888888,0.9,0.0,0.0,1.0,1.0,Why does SFDC create a lead through LMA while checkout creates an account when processing payments,"I know that checkout transactions are ""sold"" - does SFDC just want ISV to convert leads created through LMA?","This behavior follows the methodology design of salesforce.com. Lead is an unqualified opportunity, and customer is a closed sale. Our idea is that sales associates will track leads created by LMA to try and complete transactions, while subscribed leads will be listed as accounts (so you can track opportunities, customer portal access to cases, etc.)."
2055,2055,3276,Should we allow or avoid non-standard pronouns?,"This question brings up an important question:

Do we want to allow or avoid the use of non-standard English such as the words zie and zir as non gender specific pronouns on this site?
",Flimzy,https://meta.christianity.stackexchange.com/users/20,"I think that the pronouns were used in good faith but were a bit confusing. However, the edit was also a bit confusing.

On the other hand (and I feel this is important):


Confusing terms should be clarified. A note or a link is sufficient here to preserve the original form while making it clear to everybody. Instead of changing the pronouns, since TRiG objects, we should simply add a footnote.
Users should feel welcome to the site, and I think that needing to open a question like this in meta is not what should happen for such a minor matter. TRiG does have some reasons to be upset at the kind of treatment he's receiving--whether he's right or wrong, having three people ""shooting him down"" in the comments, as well, is not the way to solve this. 
I don't think that trying to moderate every... single... minor... point... in meta is actually useful or good for the site in general. It feels pedantic and a bit off-topic.

",Sklivvz,https://meta.christianity.stackexchange.com/users/279,http://meta.christianity.stackexchange.com/questions/514/should-we-allow-or-avoid-non-standard-pronouns,CULTURE,meta.christianity.stackexchange.com,1.0,0.7777777777777778,1.0,0.6666666666666666,0.0,0.0,0.7777777777777778,0.7777777777777778,0.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,1.0,0.6666666666666666,1.0,0.7777777777777778,0.5333333333333333,0.0,0.0,0.6666666666666666,1.0,Should we allow or avoid the use of non-standard pronouns?,"This question brings up an important question:

Do we want to allow or avoid the use of non-standard English such as the words zie and zir as non gender specific pronouns on this site?
","I think that the pronouns were used in good faith but were a bit confusing. However, the edit was also a bit confusing.

On the other hand (and I feel this is important):


Confusing terms should be clarified. A note or a link is sufficient here to preserve the original form while making it clear to everybody. Instead of changing the pronouns, since TRiG objects, we should simply add a footnote.
Users should feel welcome to the site, and I think that needing to open a question like this in meta is not what should happen for such a minor matter. TRiG does have some reasons to be upset at the kind of treatment he's receiving--whether he's right or wrong, having three people ""shooting him down"" in the comments, as well, is not the way to solve this. 
I don't think that trying to moderate every... single... minor... point... in meta is actually useful or good for the site in general. It feels pedantic and a bit off-topic.

"
4778,4778,7587,Adapt fatFS library to PIC32,"I'm developing an application with PIC32MX, that record 3 WAV sounds and store theme into SD. Unfortunately the speed that I have reach is 155 kB/s and is insufficient for my application. Then I have to move fatFS, that use multi sector write speed wich seems to solve my problem. I download the latest library for fatFS here (bottom of the page). I read on the internet that this code is generic and only some part of code needs to be adapted, based on microcontroller in use.
I have spent many time trying to understand what are this portions of code, but I still dont'find theme.
Anyone can help me?

EDIT: Finally I understand how to modify the fatFS for adapt it to my system.
But I have a little poblem. After I properly modified the ""platform dependent"" section with correct SPI and chip select pin, I tryied to compile. I obtained an error about windows.h and tchar.h, included in file integer.h. But in integer.h I see the ifdef, and I want compile the ""embedded"" section, not the windows section. If I try to delete the ifdef, I obtained this error: "" ';' expected but 'fs_type' found "". This come from typedef struct of ff.h.
On internet there are project with the identical structure, why this doesn't compile?
",Electroman2000,https://electronics.stackexchange.com/users/69146,"Microchip Harmony and MLA both contain good fast file access libraries, supporting multiple backing stores including SD, MMC, CF-II, USB MSD, etc.  I suggest you give them a go since they are already tailored to the PIC32 chips.
",Majenko,https://electronics.stackexchange.com/users/4245,http://electronics.stackexchange.com/questions/158130/adapt-fatfs-library-to-pic32,SCIENCE,electronics.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.4444444444444444,0.8888888888888888,0.6666666666666666,0.8888888888888888,0.8888888888888888,0.6666666666666667,0.6666666666666666,0.0,0.3333333333333333,0.8888888888888888,Adapt FatFs library to PIC32,"I'm developing an application with PIC32MX, that record 3 WAV sounds and store theme into SD. Unfortunately the speed that I have reach is 155 kB/s and is insufficient for my application. Then I have to move fatFS, that use multi sector write speed wich seems to solve my problem. I download the latest library for fatFS here (bottom of the page). I read on the internet that this code is generic and only some part of code needs to be adapted, based on microcontroller in use.
I have spent many time trying to understand what are this portions of code, but I still dont'find theme.
Anyone can help me?

EDIT: Finally I understand how to modify the fatFS for adapt it to my system.
But I have a little poblem. After I properly modified the ""platform dependent"" section with correct SPI and chip select pin, I tryied to compile. I obtained an error about windows.h and tchar.h, included in file integer.h. But in integer.h I see the ifdef, and I want compile the ""embedded"" section, not the windows section. If I try to delete the ifdef, I obtained this error: "" ';' expected but 'fs_type' found "". This come from typedef struct of ff.h.
On internet there are project with the identical structure, why this doesn't compile?
","Microchip harmony and MLA both contain good fast file access libraries and support multiple backup storage, including SD, MMC, CF-II, USB MSD, etc. I suggest you try it because they have been customized for PIC32 chips."
4346,4346,6921,Hanging boot and cannot boot to disk,"I'm having a very puzzling problem with my PC. Recently I have not been able to boot very consistently. The boot will hang during the Windows 7 splash screen and will not go further. The same thing happens when trying to run Startup Repair. At this point in time, I cannot boot, period. 

I've tried booting in safe mode. Safe mode boot hangs after loading disk.sys and will not go further. I've tried using LKGC, which also had no affect.

Normally in this situation, I would do some hardware testing (memtest, chkdsk, windows recovery), but for some reason I cannot boot to any disks whatsoever. The DVD drive I'm trying to boot with is only a few weeks old (my old one died recently), and I've used these disks to boot with before, so I know they are good. 

At this point, I'm a bit stymied as to what I should do next. I'm downloading Ubuntu now to try and backup some stuff, but again, I doubt the boot will be successful. If anyone has any advice on what to try now, I would really appreciate the help.
",Elliot,https://superuser.com/users/135283,"Try removing and reseating your memory modules one at a time with just your primary drive connected.  It is also worth removing any expansion cards you might have too.  If this gets you to the login screen, have a look through event viewer for any erroneous entries - you can then start shutting down, adding back hardware and starting up, one item at time until you find the offending piece of kit - assuming its hardware based.
",sgtbeano,https://superuser.com/users/135252,http://superuser.com/questions/426761,TECHNOLOGY,superuser.com,0.6666666666666666,0.3333333333333333,0.0,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,1.0,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,0.0,0.8888888888888888,"Pending boot, unable to boot to disk","I'm having a very puzzling problem with my PC. Recently I have not been able to boot very consistently. The boot will hang during the Windows 7 splash screen and will not go further. The same thing happens when trying to run Startup Repair. At this point in time, I cannot boot, period. 

I've tried booting in safe mode. Safe mode boot hangs after loading disk.sys and will not go further. I've tried using LKGC, which also had no affect.

Normally in this situation, I would do some hardware testing (memtest, chkdsk, windows recovery), but for some reason I cannot boot to any disks whatsoever. The DVD drive I'm trying to boot with is only a few weeks old (my old one died recently), and I've used these disks to boot with before, so I know they are good. 

At this point, I'm a bit stymied as to what I should do next. I'm downloading Ubuntu now to try and backup some stuff, but again, I doubt the boot will be successful. If anyone has any advice on what to try now, I would really appreciate the help.
","Try removing and reinstalling one memory module at a time with only the primary drive connected. It's also worth removing any expansion cards you may have. If this brings you to the login screen, check for any error entries in the event viewer - then you can start shutting down, adding hardware, and starting one project at a time until you find the problematic Toolkit - assuming it is hardware based."
1925,1925,3071,"How to prevent the ""Too awesome to use"" syndrome","When you give the player a rare but powerful item which can only be used once but is never really required to proceed, most players will not use it at all, because they are waiting for the perfect moment. But even when this moment comes, they will still be reluctant to use it, because there might be an even better moment later. So they keep hoarding it for a moment which will never come. 

In the end, they will carry the item around until it is outclassed by other, more readily available resources, or even until the very end of the game. That means that such one-shot items don't provide any gameplay-value at all. They are simply too awesome to use.

What can you do to encourage the player to make use of their one-shot items and not hoard them?
",Philipp,https://gamedev.stackexchange.com/users/21890,"If the item is too awesome to be used, then the difficulty of the game is too low.

Alternatively, the player might be insecure about using the item because he doesn't precisely know the benefit of doing so.
",A.B.,https://gamedev.stackexchange.com/users/30716,http://gamedev.stackexchange.com/questions/55558/how-to-prevent-the-too-awesome-to-use-syndrome,TECHNOLOGY,gamedev.stackexchange.com,1.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.6666666666666666,0.3333333333333333,1.0,1.0,0.4,0.0,0.0,1.0,0.6666666666666666,"How to prevent ""too good to use"" syndrome","When you give the player a rare but powerful item which can only be used once but is never really required to proceed, most players will not use it at all, because they are waiting for the perfect moment. But even when this moment comes, they will still be reluctant to use it, because there might be an even better moment later. So they keep hoarding it for a moment which will never come. 

In the end, they will carry the item around until it is outclassed by other, more readily available resources, or even until the very end of the game. That means that such one-shot items don't provide any gameplay-value at all. They are simply too awesome to use.

What can you do to encourage the player to make use of their one-shot items and not hoard them?
","If the item is too awesome to be used, then the difficulty of the game is too low.

Alternatively, the player might be insecure about using the item because he doesn't precisely know the benefit of doing so.
"
5506,5506,8737,IE9 RC crashes on my Windows 7 laptop?,"I was using IE9 beta till now and installed IE9 RC today. However it starts crashing on 50% of the sites I visit. This also includes www.youtube.com. 

I did not uninstall IE9 beta before installing IE9 RC. Could this be the reason?

EDIT: I have uninstalled IE9 RC and installed it again after restart but that has not fixed this issue. 
",Amitabh,https://superuser.com/users/33132,"I would uninstall all versions of IE9, reboot and try installing RC again.
",Moab,https://superuser.com/users/40928,http://superuser.com/questions/245001,TECHNOLOGY,superuser.com,1.0,0.6666666666666666,0.0,1.0,1.0,1.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.3333333333333333,0.0,0.7777777777777778,0.7777777777777778,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,0.0,0.8888888888888888,IE9 RC crashes on my windows 7 laptop?,"I was using IE9 beta till now and installed IE9 RC today. However it starts crashing on 50% of the sites I visit. This also includes www.youtube.com. 

I did not uninstall IE9 beta before installing IE9 RC. Could this be the reason?

EDIT: I have uninstalled IE9 RC and installed it again after restart but that has not fixed this issue. 
","I will uninstall all versions of IE9, restart and try installing RC again."
34,34,52,C# Test Assembly,"I am new to C# and am having a particularly difficult time figuring out how test assemblies work. This is my Solution directory (with a single project MyProject inside of it):

MySolution/MySolutionFile.sln     -- My Solution File
MySolution/packages               -- My Packages Directory
MySolution/MyProject/Properties   -- My Project Properties

MySolution/MyProject/src                    -- My Source Code
                    /src/MyClass1.cs
                    /src/MyClass2.cs

MySolution/MyProject/test                   -- My NUnit Tests
                    /test/MyClass1Test.cs
                    /test/MyClass2Test.cs

MySolution/MyProject/TheMainClass.cs


Now I can run all the tests in the test folder from visual studio. However I want to run the tests from a CI system like TeamCity, in which case I need an assembly path. How do I generate just the test folder into an assembly to be run.

Do I need to add to the main class a method that runs each test in the MySolution/test folder?
",Anil Vaitla,https://stackoverflow.com/users/815977,"I think you need to read about projects and solutions: http://msdn.microsoft.com/en-us/library/ee817674.aspx

And after that it all becomes more clear: Have one solution, inside of that solution create a project for your application and a project for your unit-tests. In test-project add reference to the testing framework of your choice and a reference to your application-project. 

This way your application does not know about your tests and compiled into one assembly. At the same time your tests depend on your application, but compiled into another assembly, which can be used by your test-runner GUI/CI or whatever else you use.

And to answer your next question, for test-project you need to choose project type of ""Library"" (console application will work as well if you like)
",trailmax,https://stackoverflow.com/users/809357,http://stackoverflow.com/questions/12379599/c-sharp-test-assembly,STACKOVERFLOW,stackoverflow.com,1.0,0.3333333333333333,0.0,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.6666666666666666,1.0,0.8,1.0,0.0,1.0,1.0,C test components,"I am new to C# and am having a particularly difficult time figuring out how test assemblies work. This is my Solution directory (with a single project MyProject inside of it):

MySolution/MySolutionFile.sln     -- My Solution File
MySolution/packages               -- My Packages Directory
MySolution/MyProject/Properties   -- My Project Properties

MySolution/MyProject/src                    -- My Source Code
                    /src/MyClass1.cs
                    /src/MyClass2.cs

MySolution/MyProject/test                   -- My NUnit Tests
                    /test/MyClass1Test.cs
                    /test/MyClass2Test.cs

MySolution/MyProject/TheMainClass.cs


Now I can run all the tests in the test folder from visual studio. However I want to run the tests from a CI system like TeamCity, in which case I need an assembly path. How do I generate just the test folder into an assembly to be run.

Do I need to add to the main class a method that runs each test in the MySolution/test folder?
","I think you need to read about projects and solutions: http://msdn.microsoft.com/en-us/library/ee817674.aspx

And after that it all becomes more clear: Have one solution, inside of that solution create a project for your application and a project for your unit-tests. In test-project add reference to the testing framework of your choice and a reference to your application-project. 

This way your application does not know about your tests and compiled into one assembly. At the same time your tests depend on your application, but compiled into another assembly, which can be used by your test-runner GUI/CI or whatever else you use.

And to answer your next question, for test-project you need to choose project type of ""Library"" (console application will work as well if you like)
"
1178,1178,1851,Is there a stable Linux distro using btrfs?,"I'm a big fan of ZFS on FreeBSD (I've been using it on my home server since before it got stable; bleeding edge, baby!) and I'd like to try out btrfs to see how that's evolving.

Since it's still largely in development, none of the usual mainstream distros have btrfs as an option. I haven't used Linux in a bunch of years, so I don't really know what my best options are for giving btrfs a try.

Requirements:


easy to install
btrfs supported without requiring me to rebuild the kernel


Thanks!
",chrish,https://superuser.com/users/36842,"Debian supports it.

I've had it installed on a server of mine and running for about six months now.  No issues, really.
",LawrenceC,https://superuser.com/users/51705,http://superuser.com/questions/190680,TECHNOLOGY,superuser.com,1.0,0.3333333333333333,0.0,0.0,1.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,1.0,0.8,0.0,1.0,0.0,1.0,Is there a stable Linux distribution using Btrfs?,"I'm a big fan of ZFS on FreeBSD (I've been using it on my home server since before it got stable; bleeding edge, baby!) and I'd like to try out btrfs to see how that's evolving.

Since it's still largely in development, none of the usual mainstream distros have btrfs as an option. I haven't used Linux in a bunch of years, so I don't really know what my best options are for giving btrfs a try.

Requirements:


easy to install
btrfs supported without requiring me to rebuild the kernel


Thanks!
","Debian supports it.

I've had it installed on a server of mine and running for about six months now.  No issues, really.
"
3905,3905,6222,Trigger IP ban based on request of given file?,"I run a website where ""x.php"" was known to have vulnerabilities. The vulnerability has been fixed and I don't have ""x.php"" on my site anymore.

As such with major public vulnerabilities, it seems script kiddies around are running tools that hitting my site looking for ""x.php"" in the entire structure of the site - constantly, 24/7.

This is wasted bandwidth, traffic and load that I don't really need.

Is there a way to trigger a time-based (or permanent) ban to an IP address that tries to access ""x.php"" anywhere on my site?

Perhaps I need a custom 404 PHP page that captures the fact that the request was for ""x.php"" and then that triggers the ban? How can I do that?

Thanks!

EDIT:

I should add that part of hardening my site, I've started using ZBBlock:


  This php security script is designed
  to detect certain behaviors
  detrimental to websites, or known bad
  addresses attempting to access your
  site. It then will send the bad robot
  (usually) or hacker an authentic 403
  FORBIDDEN page with a description of
  what the problem was. If the attacker
  persists, then they will be served up
  a permanently reccurring 503 OVERLOAD
  message with a 24 hour timeout.


But ZBBlock doesn't do quite exactly what I want to do, it does help with other spam/script/hack blocking.
",Mike Atlas,https://webmasters.stackexchange.com/users/5448,"The PHP code that John Conde posted does not work. It replaces the entire .htaccess file as an undesirable result. The PHP below would be a good replacement for his PHP and I have tested it.

&lt;?php      
    $ipdeny = 'deny from  ' . $_SERVER['REMOTE_ADDR'];
    file_put_contents('.htaccess', $ipdeny . PHP_EOL, FILE_APPEND);
?&gt;

",Jonathan Rowley,https://webmasters.stackexchange.com/users/37257,http://webmasters.stackexchange.com/questions/9247/trigger-ip-ban-based-on-request-of-given-file,TECHNOLOGY,webmasters.stackexchange.com,1.0,0.6666666666666666,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.5555555555555556,0.6666666666666666,0.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.7333333333333333,1.0,0.3333333333333333,0.3333333333333333,1.0,Trigger IP inhibit based on request of given file?,"I run a website where ""x.php"" was known to have vulnerabilities. The vulnerability has been fixed and I don't have ""x.php"" on my site anymore.

As such with major public vulnerabilities, it seems script kiddies around are running tools that hitting my site looking for ""x.php"" in the entire structure of the site - constantly, 24/7.

This is wasted bandwidth, traffic and load that I don't really need.

Is there a way to trigger a time-based (or permanent) ban to an IP address that tries to access ""x.php"" anywhere on my site?

Perhaps I need a custom 404 PHP page that captures the fact that the request was for ""x.php"" and then that triggers the ban? How can I do that?

Thanks!

EDIT:

I should add that part of hardening my site, I've started using ZBBlock:


  This php security script is designed
  to detect certain behaviors
  detrimental to websites, or known bad
  addresses attempting to access your
  site. It then will send the bad robot
  (usually) or hacker an authentic 403
  FORBIDDEN page with a description of
  what the problem was. If the attacker
  persists, then they will be served up
  a permanently reccurring 503 OVERLOAD
  message with a 24 hour timeout.


But ZBBlock doesn't do quite exactly what I want to do, it does help with other spam/script/hack blocking.
","The PHP code that John Conde posted does not work. It replaces the entire .htaccess file as an undesirable result. The PHP below would be a good replacement for his PHP and I have tested it.

&lt;?php      
    $ipdeny = 'deny from  ' . $_SERVER['REMOTE_ADDR'];
    file_put_contents('.htaccess', $ipdeny . PHP_EOL, FILE_APPEND);
?&gt;

"
576,576,900,How are electromagnetic waves differentiated?,"I would like to know how the signals for remote controlled cars, radios, etc.. That use radio waves are told apart from each other. I know that the radio waves are modulated to encode data and the frequency or amplitude are changed, so then the waves are propagated through the air and received at another location via a receiver that is tuned to a certain frequency that the waves were emitted, but I'm sure in most places in the world by now there are numerous amounts of waves traversing at any point, why doesn't the receiver of this device happen to catch another wave of the same frequency instead of the one that was intended? or is there anything that stops me from having a device that emits a wide range of frequencies or amplitudes that would manipulate nearby electronics?
",AlanZ2223,https://physics.stackexchange.com/users/51988,"
  why doesn't the receiver of this device happen to catch another wave of the same frequency instead of the one that was intended?


It does catch other waves at the same frequency. This is called noise. Communications are engineered so that the signal is significantly stronger than the potential noise such that it can still be reliably demodulated.

More generally, all wireless communications use the same medium (the electromagnetic field), and the problem of allowing multiple users access to this shared medium is multiplexing. While frequency division multiplexing is most common, it is not the only way: for example ultra-wideband communications may use time-division multiplexing, and spread-spectrum may use code-division multiplexing.

These methods can also be used in combination. For example, we may tune a receiver to a particular frequency (frequency-division multiplexing), and simultaneously use a directional antenna to reduce sensitivity in directions where there is only noise (space-division multiplexing). A system's ability to distinguish the desired signal from noise is called selectivity, and the more known about the desired signal (frequency, timing, phase, polarization, etc), the more selective a receiver can be.


  is there anything that stops me from having a device that emits a wide range of frequencies or amplitudes that would manipulate nearby electronics?


Regulatory bodies, such as the FCC, in conjunction with international bodies such as the ITU, establish licenses and laws which grant specific users or classes of users exclusive access to allocated spectrum. Violators are fined, or made by force if necessary to stop transmitting.

A device that transmits over some range of frequencies with the intent of disabling other radio devices would be called a jammer. There's no technical reason you couldn't build one, but ultimately the government's monopoly on violence will discourage you. A military, having no reason to fear these consequences, makes jammers all the time.
",Phil Frost,https://physics.stackexchange.com/users/24140,http://physics.stackexchange.com/questions/129807/how-are-electromagnetic-waves-differentiated,SCIENCE,physics.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,0.3333333333333333,1.0,1.0,0.6666666666666666,0.4444444444444444,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.3333333333333333,1.0,0.0,0.6666666666666666,1.0,0.7777777777777778,1.0,1.0,0.9333333333333332,0.0,0.3333333333333333,1.0,0.7777777777777778,How are electromagnetic waves distinguished?,"I want to know the signal of remote control car, radio, etc.. People using radio waves are separated from each other. I know that radio waves are modulated to encode data, and the frequency or amplitude will also change, so these waves are transmitted through the air, then received by one receiver at another location, and the receiver is tuned to a certain frequency, that is, the radio waves are transmitted, but I'm sure that up to now, there are countless waves propagating at any point in most parts of the world, why this Does the device's receiver not happen to catch another wave of the same frequency, rather than a predetermined frequency? Or is there something that prevents me from having a device that can emit a wide range of frequencies or amplitudes to manipulate nearby Electronics?","
  why doesn't the receiver of this device happen to catch another wave of the same frequency instead of the one that was intended?


It does catch other waves at the same frequency. This is called noise. Communications are engineered so that the signal is significantly stronger than the potential noise such that it can still be reliably demodulated.

More generally, all wireless communications use the same medium (the electromagnetic field), and the problem of allowing multiple users access to this shared medium is multiplexing. While frequency division multiplexing is most common, it is not the only way: for example ultra-wideband communications may use time-division multiplexing, and spread-spectrum may use code-division multiplexing.

These methods can also be used in combination. For example, we may tune a receiver to a particular frequency (frequency-division multiplexing), and simultaneously use a directional antenna to reduce sensitivity in directions where there is only noise (space-division multiplexing). A system's ability to distinguish the desired signal from noise is called selectivity, and the more known about the desired signal (frequency, timing, phase, polarization, etc), the more selective a receiver can be.


  is there anything that stops me from having a device that emits a wide range of frequencies or amplitudes that would manipulate nearby electronics?


Regulatory bodies, such as the FCC, in conjunction with international bodies such as the ITU, establish licenses and laws which grant specific users or classes of users exclusive access to allocated spectrum. Violators are fined, or made by force if necessary to stop transmitting.

A device that transmits over some range of frequencies with the intent of disabling other radio devices would be called a jammer. There's no technical reason you couldn't build one, but ultimately the government's monopoly on violence will discourage you. A military, having no reason to fear these consequences, makes jammers all the time.
"
2852,2852,4540,Inverse fourier transform of exponentially decaying function in the frequency domain,"I want to take the inverse Fourier transform of the following function:

$$ \hat{f}(\omega) = \begin{cases}e^{-r  \sqrt{\omega}} &amp; \text{for } \omega &gt; 0 \\ 0 &amp; \text{otherwise}\end{cases},$$ 

such that

$$ f(t) = \int_{-\infty}^\infty \hat{f}(w)e^{i\omega t} d\omega= \int_0^\infty e^{-r \sqrt{\omega}} e^{i\omega t} d\omega,$$ 

where $r$ is a constant.

I am having trouble in integrating this. That $ \sqrt{\omega}$ is ruining my day. Any suggestions?

Kind regards
",sigma,https://math.stackexchange.com/users/82973,"Substitute $\omega = u^2$ and consider the resulting expression as

$$-2 \frac{\partial}{\partial r} \int_0^{\infty} du \, e^{-r u} \, e^{i t u^2}$$

The integral will end up being some sort of error function of complex argument; the derivative may invoke a more elementary expression, but likely not.
",Ron Gordon,https://math.stackexchange.com/users/53268,http://math.stackexchange.com/questions/423629/inverse-fourier-transform-of-exponentially-decaying-function-in-the-frequency-do,SCIENCE,math.stackexchange.com,0.6666666666666666,0.5555555555555556,0.0,1.0,1.0,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,1.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,1.0,Inverse Fourier transform of exponential decay function in frequency domain,"I want to take the inverse Fourier transform of the following function:

$$ \hat{f}(\omega) = \begin{cases}e^{-r  \sqrt{\omega}} &amp; \text{for } \omega &gt; 0 \\ 0 &amp; \text{otherwise}\end{cases},$$ 

such that

$$ f(t) = \int_{-\infty}^\infty \hat{f}(w)e^{i\omega t} d\omega= \int_0^\infty e^{-r \sqrt{\omega}} e^{i\omega t} d\omega,$$ 

where $r$ is a constant.

I am having trouble in integrating this. That $ \sqrt{\omega}$ is ruining my day. Any suggestions?

Kind regards
","Substitute $\omega = u^2$ and consider the resulting expression as

$$-2 \frac{\partial}{\partial r} \int_0^{\infty} du \, e^{-r u} \, e^{i t u^2}$$

The integral will end up being some sort of error function of complex argument; the derivative may invoke a more elementary expression, but likely not.
"
3695,3695,5888,Captcha-like font,"I'm looking for a font that reminds of a captcha without being too difficult to read. It has to be available from google web fonts though.

Does anyone have any good tips?

Edit: It doesn't have to have a real captcha functionality. I'm making a game where a font like this would fit very well.

So basically, a font that reminds the user of a captcha, without being exhaustive to read over long periods. And available on google-fonts.
",justanotherhobbyist,https://graphicdesign.stackexchange.com/users/4114,"Captcha Like font + Only from Google Web fonts = no such thing.

A font like that has incredibly limited usefulness, and even though Google fonts has some odd choices in its collection, I don't see why they'd have any interest in adding a novelty font such as that to the collection. 
",DA01,https://graphicdesign.stackexchange.com/users/306,http://graphicdesign.stackexchange.com/questions/6693/captcha-like-font,LIFE_ARTS,graphicdesign.stackexchange.com,0.7777777777777778,0.4444444444444444,0.0,1.0,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,0.6666666666666666,0.8888888888888888,Verification code like fonts,"I'm looking for a font that reminds of a captcha without being too difficult to read. It has to be available from google web fonts though.

Does anyone have any good tips?

Edit: It doesn't have to have a real captcha functionality. I'm making a game where a font like this would fit very well.

So basically, a font that reminds the user of a captcha, without being exhaustive to read over long periods. And available on google-fonts.
","Captcha Like font + Only from Google Web fonts = no such thing.

A font like that has incredibly limited usefulness, and even though Google fonts has some odd choices in its collection, I don't see why they'd have any interest in adding a novelty font such as that to the collection. 
"
1308,1308,2061,sharing state between different controllers in angular,"I have two controls : Left Side Navigation and the right pane that changes the content on clicking of any item on left navigation. 

Here is the html (angular view):

&lt;nav class=""navigation""&gt;
        &lt;ul class=""list-unstyled"" ng-controller=""NavigationController as navigation""&gt;
            &lt;li ng-repeat=""nav in navigation.tabs"" class=""has-submenu""&gt;
                &lt;a href=""#"" ng-click=""navigation.changeContent(nav.name)""&gt;{{nav.name}}&lt;/a&gt;
                &lt;ul class=""list-unstyled"" ng-show=""nav.subNav""&gt;
                    &lt;li ng-repeat=""subnav in nav.subNav""&gt;&lt;a href=""#"" ng-click=""navigation.changeContent(subnav.name)""&gt;{{subnav.name}}&lt;/a&gt;&lt;/li&gt;
                &lt;/ul&gt;
            &lt;/li&gt;
        &lt;/ul&gt;
    &lt;/nav&gt;

&lt;section class=""content"" ng-controller=""ContentSwitcher as content""&gt;
{{content.tab}}
&lt;div class=""warper container-fluid"" &gt;
&lt;div class=""container-scroll""&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/section&gt;


And here is the controller

(function () {
    var app = angular.module('provisioning', []);

    app.service('contentService',function(){
       var tab = 'Dashboard';
        return {
            getTab : function(){ return tab; },
            setTab : function(value){ tab = value}
        }
    });
    app.controller('NavigationController',['contentService','$log', function(cs,log){
        this.tabs = [
            {
                name: 'Dashboard'
            },
            {
                name: 'Manage',
                subNav: [
                    {
                        name: 'Account'
                    },
                    {
                        name: 'Facility'
                    },
                    {
                        name: 'Doctors'
                    },
                    {
                        name: 'Patients'
                    },
                    {
                        name: 'Nurses'
                    },
                    {
                        name: 'Device Inventory'
                    }

                ]
            },
            {
                name: 'Health Tracker'
            },
            {
                name: 'Reports'
            },
            {
                name: 'Settings'
            },
            {
                name: 'Logout'
            }
        ];
        var template = this;
        this.changeContent = function(tab){
            cs.setTab(tab);
        }
    }]);
    app.controller('ContentSwitcher', ['contentService',function(cs){
        this.tab = cs.getTab();
    }]);
})();


Also, is it best way to achieve what I intend to do in angularjs? I created a service and shared the variable in the two different controllers. However it doesn't work. The content on right never gets updated on clicking any of the item on left menu.
",beNerd,https://stackoverflow.com/users/1490278,"My answer to a previous question may help. It uses a type of observer pattern.

AngularJs update directive after a call to service method

Your service would change to allow all interested controller or directives to either generate or listen for certain events and access the associated data.
",Yeager,https://stackoverflow.com/users/3936969,http://stackoverflow.com/questions/29139107/sharing-state-between-different-controllers-in-angular,STACKOVERFLOW,stackoverflow.com,0.8333333333333334,0.3333333333333333,0.0,1.0,0.6666666666666666,1.0,0.6666666666666666,0.4444444444444444,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,0.0,0.3333333333333333,1.0,0.6666666666666666,1.0,1.0,0.9,0.3333333333333333,0.0,1.0,0.8888888888888888,State sharing between different controllers in angle,"I have two controls : Left Side Navigation and the right pane that changes the content on clicking of any item on left navigation. 

Here is the html (angular view):

&lt;nav class=""navigation""&gt;
        &lt;ul class=""list-unstyled"" ng-controller=""NavigationController as navigation""&gt;
            &lt;li ng-repeat=""nav in navigation.tabs"" class=""has-submenu""&gt;
                &lt;a href=""#"" ng-click=""navigation.changeContent(nav.name)""&gt;{{nav.name}}&lt;/a&gt;
                &lt;ul class=""list-unstyled"" ng-show=""nav.subNav""&gt;
                    &lt;li ng-repeat=""subnav in nav.subNav""&gt;&lt;a href=""#"" ng-click=""navigation.changeContent(subnav.name)""&gt;{{subnav.name}}&lt;/a&gt;&lt;/li&gt;
                &lt;/ul&gt;
            &lt;/li&gt;
        &lt;/ul&gt;
    &lt;/nav&gt;

&lt;section class=""content"" ng-controller=""ContentSwitcher as content""&gt;
{{content.tab}}
&lt;div class=""warper container-fluid"" &gt;
&lt;div class=""container-scroll""&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/section&gt;


And here is the controller

(function () {
    var app = angular.module('provisioning', []);

    app.service('contentService',function(){
       var tab = 'Dashboard';
        return {
            getTab : function(){ return tab; },
            setTab : function(value){ tab = value}
        }
    });
    app.controller('NavigationController',['contentService','$log', function(cs,log){
        this.tabs = [
            {
                name: 'Dashboard'
            },
            {
                name: 'Manage',
                subNav: [
                    {
                        name: 'Account'
                    },
                    {
                        name: 'Facility'
                    },
                    {
                        name: 'Doctors'
                    },
                    {
                        name: 'Patients'
                    },
                    {
                        name: 'Nurses'
                    },
                    {
                        name: 'Device Inventory'
                    }

                ]
            },
            {
                name: 'Health Tracker'
            },
            {
                name: 'Reports'
            },
            {
                name: 'Settings'
            },
            {
                name: 'Logout'
            }
        ];
        var template = this;
        this.changeContent = function(tab){
            cs.setTab(tab);
        }
    }]);
    app.controller('ContentSwitcher', ['contentService',function(cs){
        this.tab = cs.getTab();
    }]);
})();


Also, is it best way to achieve what I intend to do in angularjs? I created a service and shared the variable in the two different controllers. However it doesn't work. The content on right never gets updated on clicking any of the item on left menu.
","My answer to a previous question may help. It uses a type of observer pattern.

AngularJs update directive after a call to service method

Your service would change to allow all interested controller or directives to either generate or listen for certain events and access the associated data.
"
3653,3653,5828,"""going to"" vs ""will""","I know several questions were asked about the difference between ""going to"" and ""will"".
Based on several answers (see, for instance, here, here and here), I understood that ""will"" is more spontaneous and ""going to"" is used with more planned actions.

So, it seems that everything is pretty fine. However, in this question, Kosmonaut has an answer in which he states:
""Let's say that tomorrow you will walk your dog from 7 - 8 AM"".

On the one hand, you probably planned to walk your dog long before and thus I should use ""Let's say that tomorrow you're going to walk your dog from 7 - 8 am"". 

On the other hand, since I'm saying ""let's say..."", I'm deciding right now (thus, unplanned) that you will walk your dog. So, even though in this hypothetical situation you made a plan, I'm in a more spontaneous mood deciding right now that that's what you will do tomorrow, and, thus, I should use ""will"".

Which one (if any) of the above explanations is right?
",Manoel Galdino,https://english.stackexchange.com/users/21109,"Any answer given on EL&amp;U, given the constraints of time and space, will leave out some of the truth. That perhaps explains the limited nature of the earlier answers to this question to which the OP refers. In any case, non-native speakers usually want simple answers and these will suffice up to intermediate level. 

This particular example introduces additional complications, because the speaker is not talking about the speaker’s own future acts, but about someone else’s. That makes the spontaneous/planned distinction inappropriate. In this case, going to seems the most natural expression, and it is indeed ‘often used as a general verb form for the future, especially in spoken English’ (‘An A-Z of English Grammar and Usage’). 

English has no set of verbal inflections to express the future.  It uses instead auxiliary verbs or, in some cases, the present tense or the present progressive construction. Although going to can be used in many cases, it can’t be used in all, and it certainly isn't invariably interchangeable with will. Native speakers will know intuitively when to say, for example, ‘Next year we’re going to have a holiday in Greece’ (not will) and when to say ‘Right, I’ll see you outside in half an hour’ (not going to). There is a clear difference in usage, reflecting the speaker’s intention in each case. Non-native speakers can only expect to distinguish such differences after considerable exposure to the language. The kind of quick fix found in the spontaneous/planned distinction will serve up to a point, but not beyond.
",Barrie England,https://english.stackexchange.com/users/12952,http://english.stackexchange.com/questions/87900/going-to-vs-will,CULTURE,english.stackexchange.com,1.0,0.3333333333333333,0.6666666666666666,1.0,0.3333333333333333,1.0,0.6666666666666666,0.8888888888888888,0.0,0.0,1.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.6666666666666666,0.0,1.0,1.0,0.8888888888888888,1.0,1.0,1.0,0.0,0.0,0.6666666666666666,1.0,"Go to ""vs"" will","I know several questions were asked about the difference between ""going to"" and ""will"".
Based on several answers (see, for instance, here, here and here), I understood that ""will"" is more spontaneous and ""going to"" is used with more planned actions.

So, it seems that everything is pretty fine. However, in this question, Kosmonaut has an answer in which he states:
""Let's say that tomorrow you will walk your dog from 7 - 8 AM"".

On the one hand, you probably planned to walk your dog long before and thus I should use ""Let's say that tomorrow you're going to walk your dog from 7 - 8 am"". 

On the other hand, since I'm saying ""let's say..."", I'm deciding right now (thus, unplanned) that you will walk your dog. So, even though in this hypothetical situation you made a plan, I'm in a more spontaneous mood deciding right now that that's what you will do tomorrow, and, thus, I should use ""will"".

Which one (if any) of the above explanations is right?
","Any answer given on EL&amp;U, given the constraints of time and space, will leave out some of the truth. That perhaps explains the limited nature of the earlier answers to this question to which the OP refers. In any case, non-native speakers usually want simple answers and these will suffice up to intermediate level. 

This particular example introduces additional complications, because the speaker is not talking about the speaker’s own future acts, but about someone else’s. That makes the spontaneous/planned distinction inappropriate. In this case, going to seems the most natural expression, and it is indeed ‘often used as a general verb form for the future, especially in spoken English’ (‘An A-Z of English Grammar and Usage’). 

English has no set of verbal inflections to express the future.  It uses instead auxiliary verbs or, in some cases, the present tense or the present progressive construction. Although going to can be used in many cases, it can’t be used in all, and it certainly isn't invariably interchangeable with will. Native speakers will know intuitively when to say, for example, ‘Next year we’re going to have a holiday in Greece’ (not will) and when to say ‘Right, I’ll see you outside in half an hour’ (not going to). There is a clear difference in usage, reflecting the speaker’s intention in each case. Non-native speakers can only expect to distinguish such differences after considerable exposure to the language. The kind of quick fix found in the spontaneous/planned distinction will serve up to a point, but not beyond.
"
487,487,759,Bash - use loop to make backup script more efficient,"I've a backup script (bash). Part of it is shown below. This script does a 14 day rotation of the backup. If I want to change this to say 30 days, I'd have to write out 30 such if-then blocks. I'm sure this could be replaced by a nifty for-loop. What would it be?

# step 1: delete the oldest snapshot, if it exists:
if [ -d $BACKUP_DIR/daily.14 ] ; then                   \
$RM -rf $BACKUP_DIR/daily.14 ;                          \
fi ;

# step 2: shift the middle snapshot(s) back by one, if they exist
if [ -d $BACKUP_DIR/daily.13 ] ; then                   \
$MV $BACKUP_DIR/daily.13 $BACKUP_DIR/daily.14 ; \
fi;

if [ -d $BACKUP_DIR/daily.12 ] ; then                   \
$MV $BACKUP_DIR/daily.12 $BACKUP_DIR/daily.13 ; \
fi;

if [ -d $BACKUP_DIR/daily.11 ] ; then                   \
$MV $BACKUP_DIR/daily.11 $BACKUP_DIR/daily.12 ; \
fi;

if [ -d $BACKUP_DIR/daily.10 ] ; then                   \
$MV $BACKUP_DIR/daily.10 $BACKUP_DIR/daily.11 ; \
fi;

if [ -d $BACKUP_DIR/daily.9 ] ; then                    \
$MV $BACKUP_DIR/daily.9 $BACKUP_DIR/daily.10 ;  \
fi;

if [ -d $BACKUP_DIR/daily.8 ] ; then                    \
$MV $BACKUP_DIR/daily.8 $BACKUP_DIR/daily.9 ;   \
fi;

if [ -d $BACKUP_DIR/daily.7 ] ; then                    \
$MV $BACKUP_DIR/daily.7 $BACKUP_DIR/daily.8 ;   \
fi;

if [ -d $BACKUP_DIR/daily.6 ] ; then                    \
$MV $BACKUP_DIR/daily.6 $BACKUP_DIR/daily.7 ;   \
fi;

if [ -d $BACKUP_DIR/daily.5 ] ; then                    \
$MV $BACKUP_DIR/daily.5 $BACKUP_DIR/daily.6 ;   \
fi;

if [ -d $BACKUP_DIR/daily.4 ] ; then                    \
$MV $BACKUP_DIR/daily.4 $BACKUP_DIR/daily.5 ;   \
fi;

if [ -d $BACKUP_DIR/daily.3 ] ; then                    \
$MV $BACKUP_DIR/daily.3 $BACKUP_DIR/daily.4 ;   \
fi;

if [ -d $BACKUP_DIR/daily.2 ] ; then                    \
$MV $BACKUP_DIR/daily.2 $BACKUP_DIR/daily.3 ;   \
fi;

if [ -d $BACKUP_DIR/daily.1 ] ; then                    \
$MV $BACKUP_DIR/daily.1 $BACKUP_DIR/daily.2 ;   \
fi;


# step 3: make a hard-link-only (except for dirs) copy of the latest snapshot, if that exists
if [ -d $BACKUP_DIR/daily.0 ] ; then                    \
$CP -al $BACKUP_DIR/daily.0 $BACKUP_DIR/daily.1 ;       \
fi;

",Sparctus,https://superuser.com/users/107329,"#!/bin/bash
MAX=29

for i in `seq 1 $MAX` 
do 
    echo "" check file exists directory.$i""
    echo ""mv directory.$i to directory"" `expr $i - 1`
done


This might be a good starting point 
",Goblin,https://superuser.com/users/151389,http://superuser.com/questions/459658,TECHNOLOGY,superuser.com,0.8888888888888888,0.5555555555555556,0.0,0.5,1.0,1.0,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.7777777777777778,0.5555555555555556,0.8888888888888888,1.0,0.8,1.0,0.0,0.0,0.6666666666666666,Bash - use cycle to improve the efficiency of backup scripts,"I've a backup script (bash). Part of it is shown below. This script does a 14 day rotation of the backup. If I want to change this to say 30 days, I'd have to write out 30 such if-then blocks. I'm sure this could be replaced by a nifty for-loop. What would it be?

# step 1: delete the oldest snapshot, if it exists:
if [ -d $BACKUP_DIR/daily.14 ] ; then                   \
$RM -rf $BACKUP_DIR/daily.14 ;                          \
fi ;

# step 2: shift the middle snapshot(s) back by one, if they exist
if [ -d $BACKUP_DIR/daily.13 ] ; then                   \
$MV $BACKUP_DIR/daily.13 $BACKUP_DIR/daily.14 ; \
fi;

if [ -d $BACKUP_DIR/daily.12 ] ; then                   \
$MV $BACKUP_DIR/daily.12 $BACKUP_DIR/daily.13 ; \
fi;

if [ -d $BACKUP_DIR/daily.11 ] ; then                   \
$MV $BACKUP_DIR/daily.11 $BACKUP_DIR/daily.12 ; \
fi;

if [ -d $BACKUP_DIR/daily.10 ] ; then                   \
$MV $BACKUP_DIR/daily.10 $BACKUP_DIR/daily.11 ; \
fi;

if [ -d $BACKUP_DIR/daily.9 ] ; then                    \
$MV $BACKUP_DIR/daily.9 $BACKUP_DIR/daily.10 ;  \
fi;

if [ -d $BACKUP_DIR/daily.8 ] ; then                    \
$MV $BACKUP_DIR/daily.8 $BACKUP_DIR/daily.9 ;   \
fi;

if [ -d $BACKUP_DIR/daily.7 ] ; then                    \
$MV $BACKUP_DIR/daily.7 $BACKUP_DIR/daily.8 ;   \
fi;

if [ -d $BACKUP_DIR/daily.6 ] ; then                    \
$MV $BACKUP_DIR/daily.6 $BACKUP_DIR/daily.7 ;   \
fi;

if [ -d $BACKUP_DIR/daily.5 ] ; then                    \
$MV $BACKUP_DIR/daily.5 $BACKUP_DIR/daily.6 ;   \
fi;

if [ -d $BACKUP_DIR/daily.4 ] ; then                    \
$MV $BACKUP_DIR/daily.4 $BACKUP_DIR/daily.5 ;   \
fi;

if [ -d $BACKUP_DIR/daily.3 ] ; then                    \
$MV $BACKUP_DIR/daily.3 $BACKUP_DIR/daily.4 ;   \
fi;

if [ -d $BACKUP_DIR/daily.2 ] ; then                    \
$MV $BACKUP_DIR/daily.2 $BACKUP_DIR/daily.3 ;   \
fi;

if [ -d $BACKUP_DIR/daily.1 ] ; then                    \
$MV $BACKUP_DIR/daily.1 $BACKUP_DIR/daily.2 ;   \
fi;


# step 3: make a hard-link-only (except for dirs) copy of the latest snapshot, if that exists
if [ -d $BACKUP_DIR/daily.0 ] ; then                    \
$CP -al $BACKUP_DIR/daily.0 $BACKUP_DIR/daily.1 ;       \
fi;

","#!/bin/bash
MAX=29

for i in `seq 1 $MAX` 
do 
    echo "" check file exists directory.$i""
    echo ""mv directory.$i to directory"" `expr $i - 1`
done


This might be a good starting point 
"
3244,3244,5173,How to make extra crispy and crunchy breading like KFC?,"I'm wondering how I would go about making extra crispy chicken breading like they do at many places like KFC and the like. Is there a certain ingredient that makes the breading like that?

Any assistance would be very much appreciated, and feel free to share any of your own recipes for crispy chicken breading if you have them. I'll be sure to put them to good use!

Thanks!
",James Mowery,https://cooking.stackexchange.com/users/2109,"its have been an ancient question on how to get chicken crispy like kfc. here is kfc recipe mix for breading.
10 kg cake flour
650 grm milk and egg.
1 kg salt
1 kg seasoning
also note that kfc breading consist of dry ingrediants milk and egg powder that why their chicken is crispy we all know that the milk is browning and egg binding. and yep they uses pressure fryer. if you need to archieve almost similar result with your recipe you need a pressure fryer or just forget about it.

i am working with fried chicken in fact i made my breading from scratch using their measurement in making my recipe. my chicken is much more crisper and dryer than kfc. i reduced milk and egg by 150 grm added 2.5 kg brown bread flour sift my breading twice before i started breading chicken. the result was amazing i am supply breading to small restaurants competing against the giants Freddy Hirsch etc the difference is my breading is one product you open the breading and bread chicken thats all.

the only way to get away without using fressure fryer is steaming the chicken. double bread it and fry in the open chip fryer. i gave that method to chicken xpress for their hot wings and its working. yeah we can cook too in South Africa.
",Nkululeko,https://cooking.stackexchange.com/users/15236,http://cooking.stackexchange.com/questions/5764/how-to-make-extra-crispy-and-crunchy-breading-like-kfc,LIFE_ARTS,cooking.stackexchange.com,1.0,1.0,0.0,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.7777777777777778,0.6666666666666666,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8,1.0,0.3333333333333333,0.0,0.6666666666666666,How to make crisp bread like KFC?,"I'm wondering how I would go about making extra crispy chicken breading like they do at many places like KFC and the like. Is there a certain ingredient that makes the breading like that?

Any assistance would be very much appreciated, and feel free to share any of your own recipes for crispy chicken breading if you have them. I'll be sure to put them to good use!

Thanks!
","its have been an ancient question on how to get chicken crispy like kfc. here is kfc recipe mix for breading.
10 kg cake flour
650 grm milk and egg.
1 kg salt
1 kg seasoning
also note that kfc breading consist of dry ingrediants milk and egg powder that why their chicken is crispy we all know that the milk is browning and egg binding. and yep they uses pressure fryer. if you need to archieve almost similar result with your recipe you need a pressure fryer or just forget about it.

i am working with fried chicken in fact i made my breading from scratch using their measurement in making my recipe. my chicken is much more crisper and dryer than kfc. i reduced milk and egg by 150 grm added 2.5 kg brown bread flour sift my breading twice before i started breading chicken. the result was amazing i am supply breading to small restaurants competing against the giants Freddy Hirsch etc the difference is my breading is one product you open the breading and bread chicken thats all.

the only way to get away without using fressure fryer is steaming the chicken. double bread it and fry in the open chip fryer. i gave that method to chicken xpress for their hot wings and its working. yeah we can cook too in South Africa.
"
5149,5149,8184,Inverse fourier transform of exponentially decaying function in the frequency domain,"I want to take the inverse Fourier transform of the following function:

$$ \hat{f}(\omega) = \begin{cases}e^{-r  \sqrt{\omega}} &amp; \text{for } \omega &gt; 0 \\ 0 &amp; \text{otherwise}\end{cases},$$ 

such that

$$ f(t) = \int_{-\infty}^\infty \hat{f}(w)e^{i\omega t} d\omega= \int_0^\infty e^{-r \sqrt{\omega}} e^{i\omega t} d\omega,$$ 

where $r$ is a constant.

I am having trouble in integrating this. That $ \sqrt{\omega}$ is ruining my day. Any suggestions?

Kind regards
",sigma,https://math.stackexchange.com/users/82973,"This would amount to compute the Fourier transform of a streched exponential, which has no simple-closed form formula, it's known as the Kohlrausch–Williams–Watts function. See also here.
",leonbloy,https://math.stackexchange.com/users/312,http://math.stackexchange.com/questions/423629/inverse-fourier-transform-of-exponentially-decaying-function-in-the-frequency-do,SCIENCE,math.stackexchange.com,0.5555555555555556,0.4444444444444444,0.0,1.0,0.6666666666666666,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.5555555555555556,0.7777777777777778,0.5,1.0,1.0,0.9,0.5,0.0,1.0,0.8888888888888888,Inverse Fourier transform of exponential decay function in frequency domain,"I want to take the inverse Fourier transform of the following function:

$$ \hat{f}(\omega) = \begin{cases}e^{-r  \sqrt{\omega}} &amp; \text{for } \omega &gt; 0 \\ 0 &amp; \text{otherwise}\end{cases},$$ 

such that

$$ f(t) = \int_{-\infty}^\infty \hat{f}(w)e^{i\omega t} d\omega= \int_0^\infty e^{-r \sqrt{\omega}} e^{i\omega t} d\omega,$$ 

where $r$ is a constant.

I am having trouble in integrating this. That $ \sqrt{\omega}$ is ruining my day. Any suggestions?

Kind regards
",This is equivalent to calculating a Fourier transform with tension index. It has no simple closed formula. It is called Kohlrausch Williams watts function. See also here.
5116,5116,8135,Can't deploy Sharepoint 2013 app,"I'm trying to deploy my first sharepoint 2013 via Visual Studio. I generated an isolated app domain.

When deploying the app i get an error in Visual Studio.

ErrorDetail: The remote hosting service is not configured.
ErrorType: Configuration
ErrorTypeName: Configuration
ExceptionMessage: Microsoft.Office.SecureStoreService.Server.SecureStoreServiceTargetApplicationNotFoundException: Target application not found (application id: __RemoteAppManagementInfo__).


I don't know how to fix that. I already set up a new App Service Apllication, generated a key in secure store, restarted it, add Managed Account to Admin-List of secure store.
",Steffen Schindler,https://sharepoint.stackexchange.com/users/3529,"The message could come from the fact that you are doing a ""High-Trust"" SharePoint App, which requires also configuring Certificates. I would suggest you really folow to the letter these 2 posts, and also try to create a simple SharePoint Hosted, to make sure it works.


http://msdn.microsoft.com/en-us/library/fp179923.aspx
http://msdn.microsoft.com/en-us/library/fp179901.aspx


Some tips: 
 - make sure DNS is properly setup with a Wildcard domain or your local hosts file 
 - do not use sub-domains (Mirjam has an excellent article here http://sharepointchick.com/archive/2012/07/29/setting-up-your-app-domain-for-sharepoint-2013.aspx)
",Marius Constantinescu - MVP,https://sharepoint.stackexchange.com/users/5306,http://sharepoint.stackexchange.com/questions/59222/cant-deploy-sharepoint-2013-app,TECHNOLOGY,sharepoint.stackexchange.com,0.7777777777777778,0.6666666666666666,0.0,0.0,1.0,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.0,0.6666666666666666,1.0,0.6666666666666666,0.8888888888888888,1.0,0.8666666666666666,0.6666666666666666,0.3333333333333333,1.0,0.8888888888888888,Unable to deploy SharePoint 2013 application,"I'm trying to deploy my first sharepoint 2013 via Visual Studio. I generated an isolated app domain.

When deploying the app i get an error in Visual Studio.

ErrorDetail: The remote hosting service is not configured.
ErrorType: Configuration
ErrorTypeName: Configuration
ExceptionMessage: Microsoft.Office.SecureStoreService.Server.SecureStoreServiceTargetApplicationNotFoundException: Target application not found (application id: __RemoteAppManagementInfo__).


I don't know how to fix that. I already set up a new App Service Apllication, generated a key in secure store, restarted it, add Managed Account to Admin-List of secure store.
","The message could come from the fact that you are doing a ""High-Trust"" SharePoint App, which requires also configuring Certificates. I would suggest you really folow to the letter these 2 posts, and also try to create a simple SharePoint Hosted, to make sure it works.


http://msdn.microsoft.com/en-us/library/fp179923.aspx
http://msdn.microsoft.com/en-us/library/fp179901.aspx


Some tips: 
 - make sure DNS is properly setup with a Wildcard domain or your local hosts file 
 - do not use sub-domains (Mirjam has an excellent article here http://sharepointchick.com/archive/2012/07/29/setting-up-your-app-domain-for-sharepoint-2013.aspx)
"
4554,4554,7214,Culinary uses for juniper extract?,"I bought some juniper extract for making bath stuff, and it doesn't seem to be very effective for this purpose. I have used juniper berries before, so I thought I might be able to use the extract for cooking or baking. I have not been able to find any recipes online. 

Is juniper extract ok to eat? What types of applications would it be good for, I assume whole berries is much better choice for marinades. Would it have the same uses as orange or peppermint extract?
",Manako,https://cooking.stackexchange.com/users/1675,"You could make gin! Add the juniper to vodka and you have instant gin. BTW, I don't drink alcohol.
",No'am Newman,https://cooking.stackexchange.com/users/3469,http://cooking.stackexchange.com/questions/12950/culinary-uses-for-juniper-extract,LIFE_ARTS,cooking.stackexchange.com,1.0,0.6666666666666666,0.0,0.3333333333333333,1.0,0.3333333333333333,0.5555555555555556,0.5555555555555556,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.7777777777777778,0.7777777777777778,0.4444444444444444,1.0,1.0,0.6,0.0,0.6666666666666666,0.0,0.8888888888888888,What is the cooking use of juniper extract?,"I bought some juniper extract for making bath stuff, and it doesn't seem to be very effective for this purpose. I have used juniper berries before, so I thought I might be able to use the extract for cooking or baking. I have not been able to find any recipes online. 

Is juniper extract ok to eat? What types of applications would it be good for, I assume whole berries is much better choice for marinades. Would it have the same uses as orange or peppermint extract?
","You can make gin! Add gin to vodka and you'll have instant gin. By the way, I don't drink."
5454,5454,8656,difference between metadata and tooling API,"What is the difference between metadata API and tooling API?  When I read the documentation, they both appear the same to me from the metadata perspective. I would like to know how I can use it for retrieving metadata.  How is the tooling API specifically different from metadata API for retrieving metadata?
",Kevin Bellati,https://salesforce.stackexchange.com/users/13059,"While there is overlap, the Tooling API is specifically designed to help developers build IDE apps for salesforce, while the metadata API is more general purpose configuration migration. For example, you can get a symbol table for a class, such as it's members and functions, without writing your own parser. The metadata API is suitable for simple migrations, but the Tooling API gives developers a platform for debugging, code coverage, auto complete, and more.

Consider the migration toolkit versus the Force.com IDE, and you'll see the difference. One lets you move configuration changes, the other lets you develop new code entirely (minus, if course, the fact that auto complete isn't present in current IDE builds). The Developer Console also shows the power of the Tooling API.

Technically, the Tooling API could completely replace the metadata API, since the metadata API, came first and is less powerful, but it will be supported for some time to come yet.

New projects should probably use the Tooling API as much as practical, but the metadata API is widely supported, in comparison, so it will be a while yet until it is completely replaced.
",sfdcfox,https://salesforce.stackexchange.com/users/2984,http://salesforce.stackexchange.com/questions/57840/difference-between-metadata-and-tooling-api,TECHNOLOGY,salesforce.stackexchange.com,1.0,0.6666666666666666,0.0,0.3333333333333333,1.0,1.0,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.0,0.3333333333333333,0.0,1.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.3333333333333333,0.3333333333333333,0.0,0.8888888888888888,The difference between metadata and tool API,"What's the difference between metadata API and tool API? When I read documents, they are all the same to me from a metadata perspective. I want to know how to use it to retrieve metadata. How is the tool API different from the metadata API used to retrieve metadata?","While there is overlap, the Tooling API is specifically designed to help developers build IDE apps for salesforce, while the metadata API is more general purpose configuration migration. For example, you can get a symbol table for a class, such as it's members and functions, without writing your own parser. The metadata API is suitable for simple migrations, but the Tooling API gives developers a platform for debugging, code coverage, auto complete, and more.

Consider the migration toolkit versus the Force.com IDE, and you'll see the difference. One lets you move configuration changes, the other lets you develop new code entirely (minus, if course, the fact that auto complete isn't present in current IDE builds). The Developer Console also shows the power of the Tooling API.

Technically, the Tooling API could completely replace the metadata API, since the metadata API, came first and is less powerful, but it will be supported for some time to come yet.

New projects should probably use the Tooling API as much as practical, but the metadata API is widely supported, in comparison, so it will be a while yet until it is completely replaced.
"
3126,3126,4979,"Is there a word for ""rule by criminals""?","Is there a word for ""rule by criminals""? Not kleptocracy, which is rule by thieves, but more broadly by criminals.
",EdL,https://english.stackexchange.com/users/68265,"You may be interested in kakistocracy, definition from Wiktionary:


  Government under the control of a nation's worst or least-qualified citizens.

",daturkel,https://english.stackexchange.com/users/68977,http://english.stackexchange.com/questions/156373/is-there-a-word-for-rule-by-criminals,CULTURE,english.stackexchange.com,1.0,1.0,0.0,1.0,1.0,0.6666666666666666,0.7777777777777778,0.8888888888888888,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,0.3333333333333333,1.0,"Is there the word ""criminal rule""?","Is there the word ""criminal rule""? It's not thief rule, it's broader criminal rule.","You may be interested in kakistocracy, definition from Wiktionary:


  Government under the control of a nation's worst or least-qualified citizens.

"
3486,3486,5564,Which Windows 7 to install?,"I have 2GB of RAM on my laptop, which is the max.  

Should I install 32 bit version or 64 bit version?
",AngryHacker,https://superuser.com/users/2805,"I don't think there's a black and white answer here, there are pros and cons for both:

32 bit: Pros


Better device driver support
More 32bit applications


64 bit: 


Larger available memory space if you have more than 3Gb RAM
All compatible device drivers are signed


In your case with only 2Gb ram I'd probably just go 32bit as there isn't significant benefit going to 64bit.
",Mark,https://superuser.com/users/4118,http://superuser.com/questions/17917,TECHNOLOGY,superuser.com,1.0,0.3333333333333333,0.0,1.0,1.0,1.0,0.6666666666666666,0.5555555555555556,0.0,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,0.3333333333333333,0.8888888888888888,Which Windows 7 do you want to install?,"I have 2GB of RAM on my laptop, which is the max.  

Should I install 32 bit version or 64 bit version?
","I don't think there's a black and white answer here, there are pros and cons for both:

32 bit: Pros


Better device driver support
More 32bit applications


64 bit: 


Larger available memory space if you have more than 3Gb RAM
All compatible device drivers are signed


In your case with only 2Gb ram I'd probably just go 32bit as there isn't significant benefit going to 64bit.
"
3106,3106,4946,Sodium Bisulfate vs Sodium Bisulfite,"I'm wanting to do a follow up to this Q&amp;A in the cooking stack regarding browning avocados. I specifically want to expand my experiment to to include the options in Wayfaring Stranger's Answer. Unfortunately, I managed to get the wrong stuff, and shipping rules make exchanging it problematic.

I am the proud owner of $500~\mathrm{g}$ of sodium bisulfate ($\ce{NaHSO4}$), instead of sodium bisulfite ($\ce{NaHSO3}$).

Dammit Jim! I'm a cook not a chemist!

What I have learned is that that both compounds are used as food additives towards the same end, and that my stuff has a slightly higher LD50. That's it.

Can anyone advise as to substituting my compound for the other? I'm not interested in tasty guacamole at this point, I'm really only looking at browning. If I'm trying to more or less duplicate the more successful experiments of the University of Florida, should I start with the same ratios? Or more or less of the additive? I can get sodium metabisulfite (also an anti-oxidant food additive) locally, if that would be a better option.

EDIT: So far, answers have all been consistent in that I have a half-kilo of white powder that is useless to me. I will make a trip to the wine-making shop and acquire some sodium metabisulfite. That still leaves me with the question of how much? The University of Florida got the results I'd like to duplicate with $30~\mathrm{mg}$ of sodium bisulfite per $100~\mathrm{g}$ of avocado. Should I start with the same ratio of sodium metabisulfite?
",Jolenealaska,https://chemistry.stackexchange.com/users/8265,"
Sodium bisulphate (NaHSO4): an acid
Sodium bisulphiTe (NaHSO3): an antioxidant
Sodium metabisulphiTe (Na2S2O5): another antioxidant


In short, bisulphate and bisulphite are not interchangeable, but bisulphite and metabisulphite are.

Sodium metabisulphite is prepared from sodium bisulphite via dehydration, as in this equation:
$$\ce{2 NaHSO3 -&gt; Na2S2O5 + H2O }$$
It's reversible in aqueous solution. The assumption that 30 mg of metabisulphite contain the same amount of sulphite as 30 mg of bisulphite is OK, the error is small, about 10 %.  The correct amount would be 27 mg of metabisulphite.

You'd ask yourself if pasteurization (75 deg. C, 30 seconds) would work to deactivate the polyphenoloxidase without affecting flavour too much.

I'd also suggest searching Pubmed (it's a decent alternative to commercial citation databases) for such keywords as ""polyphenol oxidase"" (that's the enzyme that causes browning), ""inhibition"" and ""sulfite"".

If you want hands-on answers I'd suggest going to the library and get (via interlibrary loan) a copy of this paper: Plant Foods Hum Nutr. 1995, 47, 245-56, ""The control of polyphenol oxidase activity in fruits and vegetables. A study of the interactions between the chemical compounds used and heat treatment.""


  From the abstract: ... Interactions between the use of ascorbic acid,
  citric acid, EDTA, sodium metabisulphite and heat treatment (70
  degrees C for 2 min) in the control of PPO activity were studied in
  avocado ..., banana ..., apple ..., pear ..., peach ..., potato ...,
  eggplant ..., mushroom ... and
  hearts-of-palm ... . The results demonstrated that
  PPO of avocado and eggplant was most resistant to inhibition by the
  methods used. ... The results indicated that,
  with the exception of PPO from avocado, the most adequate alternative
  method to substitute for the use of SO2 in the control of PPO was a
  combination of ascorbic acid, citric acid and heat treatment.


This shows that how to get on top of browning while still having a presentable product is a tough problem and an active area of research.  Also, avocado seems a specially hard case.
",Abel Friedman,https://chemistry.stackexchange.com/users/7920,http://chemistry.stackexchange.com/questions/17321/sodium-bisulfate-vs-sodium-bisulfite,SCIENCE,chemistry.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,1.0,1.0,1.0,0.6666666666666666,0.7777777777777778,0.3333333333333333,0.0,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.0,0.7777777777777778,1.0,0.8888888888888888,1.0,1.0,0.9333333333333332,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.8888888888888888,Sodium bisulfite vs sodium bisulfite,"I'm wanting to do a follow up to this Q&amp;A in the cooking stack regarding browning avocados. I specifically want to expand my experiment to to include the options in Wayfaring Stranger's Answer. Unfortunately, I managed to get the wrong stuff, and shipping rules make exchanging it problematic.

I am the proud owner of $500~\mathrm{g}$ of sodium bisulfate ($\ce{NaHSO4}$), instead of sodium bisulfite ($\ce{NaHSO3}$).

Dammit Jim! I'm a cook not a chemist!

What I have learned is that that both compounds are used as food additives towards the same end, and that my stuff has a slightly higher LD50. That's it.

Can anyone advise as to substituting my compound for the other? I'm not interested in tasty guacamole at this point, I'm really only looking at browning. If I'm trying to more or less duplicate the more successful experiments of the University of Florida, should I start with the same ratios? Or more or less of the additive? I can get sodium metabisulfite (also an anti-oxidant food additive) locally, if that would be a better option.

EDIT: So far, answers have all been consistent in that I have a half-kilo of white powder that is useless to me. I will make a trip to the wine-making shop and acquire some sodium metabisulfite. That still leaves me with the question of how much? The University of Florida got the results I'd like to duplicate with $30~\mathrm{mg}$ of sodium bisulfite per $100~\mathrm{g}$ of avocado. Should I start with the same ratio of sodium metabisulfite?
","
Sodium bisulphate (NaHSO4): an acid
Sodium bisulphiTe (NaHSO3): an antioxidant
Sodium metabisulphiTe (Na2S2O5): another antioxidant


In short, bisulphate and bisulphite are not interchangeable, but bisulphite and metabisulphite are.

Sodium metabisulphite is prepared from sodium bisulphite via dehydration, as in this equation:
$$\ce{2 NaHSO3 -&gt; Na2S2O5 + H2O }$$
It's reversible in aqueous solution. The assumption that 30 mg of metabisulphite contain the same amount of sulphite as 30 mg of bisulphite is OK, the error is small, about 10 %.  The correct amount would be 27 mg of metabisulphite.

You'd ask yourself if pasteurization (75 deg. C, 30 seconds) would work to deactivate the polyphenoloxidase without affecting flavour too much.

I'd also suggest searching Pubmed (it's a decent alternative to commercial citation databases) for such keywords as ""polyphenol oxidase"" (that's the enzyme that causes browning), ""inhibition"" and ""sulfite"".

If you want hands-on answers I'd suggest going to the library and get (via interlibrary loan) a copy of this paper: Plant Foods Hum Nutr. 1995, 47, 245-56, ""The control of polyphenol oxidase activity in fruits and vegetables. A study of the interactions between the chemical compounds used and heat treatment.""


  From the abstract: ... Interactions between the use of ascorbic acid,
  citric acid, EDTA, sodium metabisulphite and heat treatment (70
  degrees C for 2 min) in the control of PPO activity were studied in
  avocado ..., banana ..., apple ..., pear ..., peach ..., potato ...,
  eggplant ..., mushroom ... and
  hearts-of-palm ... . The results demonstrated that
  PPO of avocado and eggplant was most resistant to inhibition by the
  methods used. ... The results indicated that,
  with the exception of PPO from avocado, the most adequate alternative
  method to substitute for the use of SO2 in the control of PPO was a
  combination of ascorbic acid, citric acid and heat treatment.


This shows that how to get on top of browning while still having a presentable product is a tough problem and an active area of research.  Also, avocado seems a specially hard case.
"
2463,2463,3928,How complex are sprite tasks usually allowed to be?,"What is the general consensus on how detailed a Sprite command can be? I know Sprite tasks aren't spent until the Technomancer changes the command, but does having conditional modifiers like ""if"" or ""if/else"" statements or specific details to objectives count as multiple Tasks? Can stuff like that count as a single Task until you give it other conditions, or would any change in activity count as a spent Task? Also, does a single task limit the sprite to use of a single Complex Form or Power, or can they use as many as they need to continue performing a task?
",Cobalt,https://rpg.stackexchange.com/users/4492,"Sprites are sentients, not drones.  The task you give them can be as complex as you desire, though excessive conditional statements might not only frustrate your GM, but also result in your sprites performing emergent behavior that you did not intend them to preform (but 'coded' them to) and thus frustrate you as well.  Any task that is complicated in the wrong ways (though if/then/else should be fine in this sense) also runs the risk of confusing your sprite, which is generally not good for the health of your electronics.

N.B.
Sprites are nicer than spirits, in general, and much more forgiving of behavior on the part of technomancers that would constitute ""abuse"" for summoners.  Nonetheless, it is possible to piss off your sprites (or sprites in general) and angry sprites, while more likely to harrass you than kill you outright, are still not something you want to deal with.  Sprites mildly resent having tasks, and making a massive if/then/else tree so you can keep them indentured for longer than normal is the kind of thing the book seems to indicate will result in them being mad at you.  



Sources:

Sprites are semi-sentient


  Technomancers also have the ability to create semi-autonomous entities out of the fabric of the Matrix, digital creatures that answer to the technomancer’s beck and call.


Tasks are continuous


  A task is a continuous service the technomancer asks, cajoles, or demands from the sprite.


Spirits struggle against magicians who abuse the system to oppress them


  [rules on page 187] This modifier should only be applied when roleplaying calls for it, such as when a magician has been abusive towards her bound spirits or has repeatedly
  put them at risk or forced them to undertake draining tasks like
  Spell Binding. 


Those rules are also applicable to sprites


  Registered sprites may be a drain on the technomancer’s mental
  resources, if the gamemaster chooses, in the same way that bound spirits
  might affect a magician (Bound Spirits, p. 187).


But Sprites are for forgiving and less violent than spirits, generally (compare the following passage to what Free Spirits do when they break free from a binding)


  Free sprites that have been registered against their will are
  not usually vindictive or determined to inflict harm on the operator,
  but will go to any means to counterbalance an “unsatisfied
  equation.” What this may mean in particular cases depends on the
  nature and profile of the free sprite and is left to the gamemaster.
  The sprite can be re-registered through a new registering session,
  as long as the free sprite source code is not altered. This can
  be done an unlimited number of times, but if the operator glitches
  on the re-registering test, the free sprite will get 1 Combat Turn
  to do anything it wants before it is brought back under control.
  If the technomancer character scores a critical glitch on the reregistering,
  he forfeits all remaining owed tasks and the sprite can
  do anything it wants.


All quotes except the last one (from Unwired) are from the Core Rulebook.
",the dark wanderer,https://rpg.stackexchange.com/users/14848,http://rpg.stackexchange.com/questions/27463/how-complex-are-sprite-tasks-usually-allowed-to-be,CULTURE,rpg.stackexchange.com,1.0,0.6666666666666666,0.0,1.0,0.6666666666666666,1.0,0.6666666666666666,0.3333333333333333,1.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.3333333333333333,0.0,1.0,1.0,How complex are sprite tasks usually allowed?,"What is the consensus on the level of detail of Sprite command? I know that sprite tasks will not be used until technomancer changes the command, but do conditional modifiers such as ""if"" or ""if / else"" statements or specific details of targets count as multiple tasks? Before you give it other conditions, can such a thing be counted as a separate task? Or is any change in the activity counted as an expensive task? Also, does a task restrict elves from using a complex form or power, or can they use as much as possible because they need to continue to perform a task?","Sprites are sentients, not drones.  The task you give them can be as complex as you desire, though excessive conditional statements might not only frustrate your GM, but also result in your sprites performing emergent behavior that you did not intend them to preform (but 'coded' them to) and thus frustrate you as well.  Any task that is complicated in the wrong ways (though if/then/else should be fine in this sense) also runs the risk of confusing your sprite, which is generally not good for the health of your electronics.

N.B.
Sprites are nicer than spirits, in general, and much more forgiving of behavior on the part of technomancers that would constitute ""abuse"" for summoners.  Nonetheless, it is possible to piss off your sprites (or sprites in general) and angry sprites, while more likely to harrass you than kill you outright, are still not something you want to deal with.  Sprites mildly resent having tasks, and making a massive if/then/else tree so you can keep them indentured for longer than normal is the kind of thing the book seems to indicate will result in them being mad at you.  



Sources:

Sprites are semi-sentient


  Technomancers also have the ability to create semi-autonomous entities out of the fabric of the Matrix, digital creatures that answer to the technomancer’s beck and call.


Tasks are continuous


  A task is a continuous service the technomancer asks, cajoles, or demands from the sprite.


Spirits struggle against magicians who abuse the system to oppress them


  [rules on page 187] This modifier should only be applied when roleplaying calls for it, such as when a magician has been abusive towards her bound spirits or has repeatedly
  put them at risk or forced them to undertake draining tasks like
  Spell Binding. 


Those rules are also applicable to sprites


  Registered sprites may be a drain on the technomancer’s mental
  resources, if the gamemaster chooses, in the same way that bound spirits
  might affect a magician (Bound Spirits, p. 187).


But Sprites are for forgiving and less violent than spirits, generally (compare the following passage to what Free Spirits do when they break free from a binding)


  Free sprites that have been registered against their will are
  not usually vindictive or determined to inflict harm on the operator,
  but will go to any means to counterbalance an “unsatisfied
  equation.” What this may mean in particular cases depends on the
  nature and profile of the free sprite and is left to the gamemaster.
  The sprite can be re-registered through a new registering session,
  as long as the free sprite source code is not altered. This can
  be done an unlimited number of times, but if the operator glitches
  on the re-registering test, the free sprite will get 1 Combat Turn
  to do anything it wants before it is brought back under control.
  If the technomancer character scores a critical glitch on the reregistering,
  he forfeits all remaining owed tasks and the sprite can
  do anything it wants.


All quotes except the last one (from Unwired) are from the Core Rulebook.
"
2982,2982,4749,Mechanic Troubles And A Small Watery Oil Leak,"My car is a 2005 BMW 525i E60 with about 180,000km on the clock. It has been well looked after and serviced. I don't get dealer services, but go to a mechanic who has always been good and uses the same oils and genuine parts that BMW use. He used to be a BMW tech for about 25 years before going out on his own and is considerably cheaper.

Before we proceed, I apologise for the long story and hope you can bear with me. Make yourself a tea or coffee before you read this. I greatly appreciate any help anyone has to offer.

The story begins about 2 weeks ago when I took my car to the mechanic for a service. I was experiencing issues where the car was sluggy and I had an oil leak, simple enough I thought.

The mechanic called me and said they discovered a couple of inches of the fuel line beneath the car had been crushed (the hose is metal bent at weird angles and whatnot) and brake lines had also been squashed basically flat. The lines were squashed by a loose chunk of concrete coming off of a driveway. They called BMW and they were quoted $1300 AUD and a 3 week wait as the lines had to come from Germany.

They phoned around and were able to find second hand lines for about $400. They fitted the new lines and discovered the source of the leak was actually the oil filter, at first they thought the mount was cracked, but the car just needed a new oil filter. They also discovered a faulty part (a thermostat they had only replaced not even a year ago) still under warranty that they replaced. An engine mount near the alternator was also replaced, I recall they mentioned having to remove the alternator and whatnot to get to it.

After spending $2200 AUD on the repairs (a little more than I was expecting), I picked the car up and for a day it was perfect. It had a new-found sense of performance, was smoother than ever. Then the second day rolled around and my fiance calls me to tell me the car was blowing white smoke.

She picked me up and the car would pour out copious amounts of white smoke when taking off from lights, going up hills, etc. It wasn't a small amount either, it was literally clouds. It didn't have a sweet smell, more of a fume smell. The car was also idling rough and driving pretty rough as well, wasn't overly lacking power though.

I know what you are thinking and yes, it was my first thought too: the head gasket is blown and coolant and oil were mixing together. I had a sinking feeling in my stomach.

After the car had cooled down, I checked the oil and coolant. The oil was pretty much empty, it was below the minimum mark and the coolant was also a quarter down. Looking at the mechanic invoice it said they used about 6 litres of synthetic oil, where did it go I wondered. I checked the coolant and it was clean, I checked the oil and it was clean. I've seen what a blown head gasket looks like this wasn't looking the case. The oil had vanished, and some of the coolant as well, but it didn't appear as though the two were mixing.

Every time the car was started from a stationery position, it would blow lots of white smoke as it did when the car was being driven. Moisture getting into the engine somewhere seemed to be the most likely cause.

Because it was a late Friday evening and the mechanic workshop wasn't open until Monday, I decided to carefully fill the oil and coolant back up, I had some demineralised water and I also had some synthetic motor oil on hand. I filled the oil to just a little below the minimum mark and the coolant back to the full mark. I would call the mechanic on Monday and do some observational testing over the weekend.

As soon as I topped up both fluids, I started the car and no white smoke. I let it run for about 15 minutes. I turned it off, checked fluids and they were still full. The oil still appeared to be clean. I drove the car around the block and the white smoke was still gone. This was a good sign, but also a sign perhaps they forgot to top up the oil they charged me for, had it done damage I wondered?

The next morning I started the car and a puff of white smoke emerged and then cleared. Driving it however seemed to pose no problem, the white smoke would only appear after the car had been turned off and sitting for quite a while and first started. I checked the fluids and the oil was fine, the coolant had gone down a really tiny bit. Because I always park my car on a drip tray I noticed there was a water like oil substance on the tray, it wasn't a large amount, but enough to make me take notice. The oil had not gone down which made it all the more weird, where was the oil like colour and substance coming from?

Sunday rolled around the subsequently the same thing. No oil loss, coolant had gone down a bit more, white smoke on initial start after sitting and then cleared. I was hopeful when I took it to the mechanic on Monday it would be resolved.

I took it to the mechanic finally, I told them how the oil was empty and I topped it up, I also explained the coolant loss and they got me to start the car. Because the cloud of white smoke only happens on start, they couldn't see it. They said they could see a tiny bit of exhaust smoke and then subsequently tried telling me because of the age of the car (it's a 2005) that it was most likely the valve stem seals.

They then sold me a bottle of what looked like water which they poured into the oil for softening up the valve stem seals and said to keep an eye on it. They said if I notice any troubles, to bring it back. I stupidly went along with it even after explaining the oil loss and coolant loss. They offered no possible explanation as to why the oil was empty, I assumed it wasn't topped up. 

All of these issues are new ones I didn't have before I took the car to them, why would the valve stem seals all of a sudden cause me an issue after coincidentally getting it looked over and work done?

A couple of days had passed and the white smoke issue had temporarily disappeared and I thought, oh, maybe they were right. Then I noticed the smoke had returned again on start, I checked the fluids again and the oil was clean and fine. There were no signs of oil in the coolant or coolant in the oil. I however had noticed the coolant had dropped to about the half way mark now and the watery like oil was still leaking onto the drip tray.

I called them up and they said to bring it back down, I was determined to get them to actually look at the car this time. It was raining and I parked in the car park. The mechanic dude came out and I explained the situation. He offered no possible explanation for the coolant loss. It was also coincidentally raining and has been for the past few days. He said the water from the rain would have washed whatever was leaking from underneath and to bring it back when it's not raining.

What is going on here? What are my rights? I feel so helpless and trapped at the moment. I feel as though they're trying to avoid looking at the car properly maybe because they know they're responsible and scared maybe they blew the head gasket which is an expensive job.

What should I say to them next time I see them to make sure it gets fixed and looked at without incurring cost upon myself? I know it's hard, but what are some potential issues that could be responsible for my symptoms? Coolant loss, not going into the oil and oil not going down.
",Dwayne Charrington,https://mechanics.stackexchange.com/users/51,"after topping off your oil park in a wind free environment o/night having laid down
newspaper under car which may narrow down source of leak.Just to be sure lock garage to ensure the car is not being tampered with.Some folks find such things as fuel/oil
tampering funny
",mike,https://mechanics.stackexchange.com/users/4815,http://mechanics.stackexchange.com/questions/9015/mechanic-troubles-and-a-small-watery-oil-leak,CULTURE,mechanics.stackexchange.com,1.0,0.3333333333333333,0.0,0.0,1.0,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.0,1.0,0.6666666666666666,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,1.0,0.7777777777777778,0.3333333333333333,0.7777777777777778,1.0,0.6666666666666667,0.3333333333333333,0.0,0.0,0.6666666666666666,Mechanical failure and a small amount of water-based oil leakage,"My car is a 2005 BMW 525i E60 with about 180,000km on the clock. It has been well looked after and serviced. I don't get dealer services, but go to a mechanic who has always been good and uses the same oils and genuine parts that BMW use. He used to be a BMW tech for about 25 years before going out on his own and is considerably cheaper.

Before we proceed, I apologise for the long story and hope you can bear with me. Make yourself a tea or coffee before you read this. I greatly appreciate any help anyone has to offer.

The story begins about 2 weeks ago when I took my car to the mechanic for a service. I was experiencing issues where the car was sluggy and I had an oil leak, simple enough I thought.

The mechanic called me and said they discovered a couple of inches of the fuel line beneath the car had been crushed (the hose is metal bent at weird angles and whatnot) and brake lines had also been squashed basically flat. The lines were squashed by a loose chunk of concrete coming off of a driveway. They called BMW and they were quoted $1300 AUD and a 3 week wait as the lines had to come from Germany.

They phoned around and were able to find second hand lines for about $400. They fitted the new lines and discovered the source of the leak was actually the oil filter, at first they thought the mount was cracked, but the car just needed a new oil filter. They also discovered a faulty part (a thermostat they had only replaced not even a year ago) still under warranty that they replaced. An engine mount near the alternator was also replaced, I recall they mentioned having to remove the alternator and whatnot to get to it.

After spending $2200 AUD on the repairs (a little more than I was expecting), I picked the car up and for a day it was perfect. It had a new-found sense of performance, was smoother than ever. Then the second day rolled around and my fiance calls me to tell me the car was blowing white smoke.

She picked me up and the car would pour out copious amounts of white smoke when taking off from lights, going up hills, etc. It wasn't a small amount either, it was literally clouds. It didn't have a sweet smell, more of a fume smell. The car was also idling rough and driving pretty rough as well, wasn't overly lacking power though.

I know what you are thinking and yes, it was my first thought too: the head gasket is blown and coolant and oil were mixing together. I had a sinking feeling in my stomach.

After the car had cooled down, I checked the oil and coolant. The oil was pretty much empty, it was below the minimum mark and the coolant was also a quarter down. Looking at the mechanic invoice it said they used about 6 litres of synthetic oil, where did it go I wondered. I checked the coolant and it was clean, I checked the oil and it was clean. I've seen what a blown head gasket looks like this wasn't looking the case. The oil had vanished, and some of the coolant as well, but it didn't appear as though the two were mixing.

Every time the car was started from a stationery position, it would blow lots of white smoke as it did when the car was being driven. Moisture getting into the engine somewhere seemed to be the most likely cause.

Because it was a late Friday evening and the mechanic workshop wasn't open until Monday, I decided to carefully fill the oil and coolant back up, I had some demineralised water and I also had some synthetic motor oil on hand. I filled the oil to just a little below the minimum mark and the coolant back to the full mark. I would call the mechanic on Monday and do some observational testing over the weekend.

As soon as I topped up both fluids, I started the car and no white smoke. I let it run for about 15 minutes. I turned it off, checked fluids and they were still full. The oil still appeared to be clean. I drove the car around the block and the white smoke was still gone. This was a good sign, but also a sign perhaps they forgot to top up the oil they charged me for, had it done damage I wondered?

The next morning I started the car and a puff of white smoke emerged and then cleared. Driving it however seemed to pose no problem, the white smoke would only appear after the car had been turned off and sitting for quite a while and first started. I checked the fluids and the oil was fine, the coolant had gone down a really tiny bit. Because I always park my car on a drip tray I noticed there was a water like oil substance on the tray, it wasn't a large amount, but enough to make me take notice. The oil had not gone down which made it all the more weird, where was the oil like colour and substance coming from?

Sunday rolled around the subsequently the same thing. No oil loss, coolant had gone down a bit more, white smoke on initial start after sitting and then cleared. I was hopeful when I took it to the mechanic on Monday it would be resolved.

I took it to the mechanic finally, I told them how the oil was empty and I topped it up, I also explained the coolant loss and they got me to start the car. Because the cloud of white smoke only happens on start, they couldn't see it. They said they could see a tiny bit of exhaust smoke and then subsequently tried telling me because of the age of the car (it's a 2005) that it was most likely the valve stem seals.

They then sold me a bottle of what looked like water which they poured into the oil for softening up the valve stem seals and said to keep an eye on it. They said if I notice any troubles, to bring it back. I stupidly went along with it even after explaining the oil loss and coolant loss. They offered no possible explanation as to why the oil was empty, I assumed it wasn't topped up. 

All of these issues are new ones I didn't have before I took the car to them, why would the valve stem seals all of a sudden cause me an issue after coincidentally getting it looked over and work done?

A couple of days had passed and the white smoke issue had temporarily disappeared and I thought, oh, maybe they were right. Then I noticed the smoke had returned again on start, I checked the fluids again and the oil was clean and fine. There were no signs of oil in the coolant or coolant in the oil. I however had noticed the coolant had dropped to about the half way mark now and the watery like oil was still leaking onto the drip tray.

I called them up and they said to bring it back down, I was determined to get them to actually look at the car this time. It was raining and I parked in the car park. The mechanic dude came out and I explained the situation. He offered no possible explanation for the coolant loss. It was also coincidentally raining and has been for the past few days. He said the water from the rain would have washed whatever was leaking from underneath and to bring it back when it's not raining.

What is going on here? What are my rights? I feel so helpless and trapped at the moment. I feel as though they're trying to avoid looking at the car properly maybe because they know they're responsible and scared maybe they blew the head gasket which is an expensive job.

What should I say to them next time I see them to make sure it gets fixed and looked at without incurring cost upon myself? I know it's hard, but what are some potential issues that could be responsible for my symptoms? Coolant loss, not going into the oil and oil not going down.
","after topping off your oil park in a wind free environment o/night having laid down
newspaper under car which may narrow down source of leak.Just to be sure lock garage to ensure the car is not being tampered with.Some folks find such things as fuel/oil
tampering funny
"
4513,4513,7154,Why was the winner of the AES competition not a Feistel cipher?,"The winner of the AES competition has a structure that does not qualify as a Feistel cipher, as explained in answers to this recent question.

However, most many of the AES candidates, and all 3 out of 4 some other finalists (Twofish, MARS) are Feistel ciphers, if we define that as a cipher transforming a block of data using a number of rounds which each can be expressed as:


split all the bits of the block $B_j$ into two disjoint portions $L_j$ and $R_j$ (typically of equal size);
compute some (typically round-dependent) function of $R_j$ and key with output $F_j$ of same width as $L_j$;
compute  $L_j'=L_j\oplus F_j$ where $\oplus$ is binary addition with removal of some carry bits (e.g. exclusive-OR, where all carry bits are removed);
recombine bits of $L_j'$ and the unmodified $R_j$ into a new block $B_{j+1}$.


Note: Serpent and RC6 can not be put in this framework (thanks to @Reid and @J.D. for pointing that). Neither can Rijndael/AES.

At the time of the AES competition, Feistel ciphers already enjoyed a well understood theory. In particular DES was among them, and essentially unbroken in practice except for its small key and block size. It would seem that proposing anything else than a Feistel cipher would be an uphill battle.

Yet, Rijndael won the AES competion, and does not fall under the above definition. Did a desirable characteristic of Rijndael made it preferred to the other candidates despite the apparent drawback of using a relatively untested structure? And if that characteristic could not be matched by a Feistel cipher, why?
",fgrieu,https://crypto.stackexchange.com/users/555,"DES actually demonstrated that a Feistel structure was not a guarantee against attacks. In ""academic"" terms, DES is broken by both differential and linear cryptanalysis, because they require, respectively, $2^{47}$ chosen plaintexts and $2^{43}$ known plaintexts, whereas the DES key is (effectively) 56 bits. Of course, for practical attacks, we would brute force the key: computing the function $2^k$ times is vastly easier than obtaining $2^k$ known plaintext/ciphertext pairs (or, even worse, chosen plaintext/ciphertext pairs). But in the usual ""academic"" evaluation of security, both linear and differential cryptanalysis count as breaks.

Luby and Rackoff have demonstrated in 1988 that given ""perfect"" round functions, a four-round Feistel structure is secure. However, this proof has two practical issues:


It is relative to the output size of the round function, i.e. 32 bits for a 64-bit block cipher. For 128-bit security, blocks have to be 256-bit wide for the proof to actually apply; but the AES call for candidates requested 256-bit security with 128-bit blocks, not the other way round.
DES has amply demonstrated that concrete round functions cannot be assumed to be perfect.


So while the security provided by a Feistel structure was already quite well understood at that time (around 1997, when AES candidates were being designed), it was also quite known to be ""suboptimal"" in the following sense: to get the most out of the existing security proofs, you had to go to impractical block sizes or number of rounds. Indeed, many researchers were dissatisfied with the Feistel structure, and eager to explore new structures. The AES competition was at the right time to become a test bed for such novel designs, and the accumulated research has shown substitution-permutation networks (as used by Rijndael) to be valid competitors to Feistel structures.
",Thomas Pornin,https://crypto.stackexchange.com/users/28,http://crypto.stackexchange.com/questions/10631/why-was-the-winner-of-the-aes-competition-not-a-feistel-cipher,TECHNOLOGY,crypto.stackexchange.com,0.3333333333333333,1.0,0.0,0.0,1.0,1.0,0.6666666666666666,0.3333333333333333,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.0,0.0,1.0,1.0,Why isn't the winner of the AES competition the fester code?,"The winner of the AES competition has a structure that does not qualify as a Feistel cipher, as explained in answers to this recent question.

However, most many of the AES candidates, and all 3 out of 4 some other finalists (Twofish, MARS) are Feistel ciphers, if we define that as a cipher transforming a block of data using a number of rounds which each can be expressed as:


split all the bits of the block $B_j$ into two disjoint portions $L_j$ and $R_j$ (typically of equal size);
compute some (typically round-dependent) function of $R_j$ and key with output $F_j$ of same width as $L_j$;
compute  $L_j'=L_j\oplus F_j$ where $\oplus$ is binary addition with removal of some carry bits (e.g. exclusive-OR, where all carry bits are removed);
recombine bits of $L_j'$ and the unmodified $R_j$ into a new block $B_{j+1}$.


Note: Serpent and RC6 can not be put in this framework (thanks to @Reid and @J.D. for pointing that). Neither can Rijndael/AES.

At the time of the AES competition, Feistel ciphers already enjoyed a well understood theory. In particular DES was among them, and essentially unbroken in practice except for its small key and block size. It would seem that proposing anything else than a Feistel cipher would be an uphill battle.

Yet, Rijndael won the AES competion, and does not fall under the above definition. Did a desirable characteristic of Rijndael made it preferred to the other candidates despite the apparent drawback of using a relatively untested structure? And if that characteristic could not be matched by a Feistel cipher, why?
","DES actually demonstrated that a Feistel structure was not a guarantee against attacks. In ""academic"" terms, DES is broken by both differential and linear cryptanalysis, because they require, respectively, $2^{47}$ chosen plaintexts and $2^{43}$ known plaintexts, whereas the DES key is (effectively) 56 bits. Of course, for practical attacks, we would brute force the key: computing the function $2^k$ times is vastly easier than obtaining $2^k$ known plaintext/ciphertext pairs (or, even worse, chosen plaintext/ciphertext pairs). But in the usual ""academic"" evaluation of security, both linear and differential cryptanalysis count as breaks.

Luby and Rackoff have demonstrated in 1988 that given ""perfect"" round functions, a four-round Feistel structure is secure. However, this proof has two practical issues:


It is relative to the output size of the round function, i.e. 32 bits for a 64-bit block cipher. For 128-bit security, blocks have to be 256-bit wide for the proof to actually apply; but the AES call for candidates requested 256-bit security with 128-bit blocks, not the other way round.
DES has amply demonstrated that concrete round functions cannot be assumed to be perfect.


So while the security provided by a Feistel structure was already quite well understood at that time (around 1997, when AES candidates were being designed), it was also quite known to be ""suboptimal"" in the following sense: to get the most out of the existing security proofs, you had to go to impractical block sizes or number of rounds. Indeed, many researchers were dissatisfied with the Feistel structure, and eager to explore new structures. The AES competition was at the right time to become a test bed for such novel designs, and the accumulated research has shown substitution-permutation networks (as used by Rijndael) to be valid competitors to Feistel structures.
"
3246,3246,5175,What are the rules of thumb for margins in web design?,"My web designer tells me that in a web page, the empty margins or padding should always be multiples of a standard. For example 6 px, 12px, 18px. This should produce nicely balanced lay-outs. I would like to learn a little bit more about it:

Should one really not violate this at all?

Should the standard be the same horizontally and vertically?
",Tintels,https://ux.stackexchange.com/users/4703,"You should have consistency yes - but if the page is not user focused what good are multiple standard margins/padding anyways. I try and use multiples of 5 personally as it is faster to equate. 
",culvi,https://ux.stackexchange.com/users/4731,http://ux.stackexchange.com/questions/6135/what-are-the-rules-of-thumb-for-margins-in-web-design,TECHNOLOGY,ux.stackexchange.com,0.7777777777777778,0.7777777777777778,0.0,1.0,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,0.3333333333333333,0.7777777777777778,What is the rule of thumb for margins in web design?,"My web designer told me that in a web page, blank margins or padding should always be a standard multiple. For example, 6 pixels, 12 pixels, 18 pixels. This will produce a good balanced layout. I would like to know more about:","You should have consistency yes - but if the page is not user focused what good are multiple standard margins/padding anyways. I try and use multiples of 5 personally as it is faster to equate. 
"
3108,3108,4952,100% Rye Pizza Base Recipes?,"I'm looking for a 100% rye pizza base recipe. The recipes I can find all combine the rye with other flours (typically wheat based). I know it is possible to create 100% rye based pizza bases as I know of one pizza place in town that sells them. 

I understand that they had to do something special to keep the pizza base from falling apart. I don't mind experimenting a bit to find a recipe that works, but I could use some ideas on where to start - what sort of ingredients might bind the rye so that it doesn't crumble as a thin pizza base and maintains a low glycemic index for my diabetic wife.

The only dietary requirements would be that the various ingredients maintain a low glycemic index or a specific ingredient with a high glycemic index can be counteracted by some other ingredient. And only using rye flour.
",Stephen Perelson,https://cooking.stackexchange.com/users/1892,"Have you considered using 100% rye bread as your beginning and going from there, rather than pizza crust?  Peter Reinhart's Bread Baker's Apprentice has a 100% rye sourdough bread that might suit your needs, although it will be a time consuming process.  A preview is online in Google Books.  The recipe is similar to a Neopolitan pizza dough - just basic ingredients with no fat.  Because of this, I'd roll out the pizza very thin, New York style, for a crackling crisp crust.  If you don't want to buy the book, many local libraries carry it in the US, at least.
",justkt,https://cooking.stackexchange.com/users/1816,http://cooking.stackexchange.com/questions/4979/100-rye-pizza-base-recipes,LIFE_ARTS,cooking.stackexchange.com,0.8888888888888888,0.8888888888888888,0.0,1.0,0.6666666666666666,0.6666666666666666,0.7777777777777778,0.7777777777777778,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,1.0,0.8888888888888888,0.8,0.0,0.3333333333333333,0.3333333333333333,0.7777777777777778,100% rye pizza formula?,"I'm looking for a 100% rye pizza base recipe. The recipes I can find all combine the rye with other flours (typically wheat based). I know it is possible to create 100% rye based pizza bases as I know of one pizza place in town that sells them. 

I understand that they had to do something special to keep the pizza base from falling apart. I don't mind experimenting a bit to find a recipe that works, but I could use some ideas on where to start - what sort of ingredients might bind the rye so that it doesn't crumble as a thin pizza base and maintains a low glycemic index for my diabetic wife.

The only dietary requirements would be that the various ingredients maintain a low glycemic index or a specific ingredient with a high glycemic index can be counteracted by some other ingredient. And only using rye flour.
","Have you considered using 100% rye bread as your beginning and going from there, rather than pizza crust?  Peter Reinhart's Bread Baker's Apprentice has a 100% rye sourdough bread that might suit your needs, although it will be a time consuming process.  A preview is online in Google Books.  The recipe is similar to a Neopolitan pizza dough - just basic ingredients with no fat.  Because of this, I'd roll out the pizza very thin, New York style, for a crackling crisp crust.  If you don't want to buy the book, many local libraries carry it in the US, at least.
"
2183,2183,3476,"Silent, extremely portable instrument to learn music","I am currently off work for more or less a month, so I decided it could be a great time to learn an instrument and how to compose some simple tunes.

I am 29, never played anything meaningful in my life, know very little to nothing about music theory but I can comfortably read notes on a score.



Asking a search engine for suggestions brought me to the music section of stackexchange and particulary to this question. After some thought I am planning to buy the Kaossilator 2 becase I feel/think:


it is not too expensive for me (less than 200$) (otherwise I would have fancied a Teenage engineering OP1;
it can be completely silent (commuting home->work->home takes quite a long time, I would like to be able to practice in crowded places (without annoying anyone);
it is extremely portable (for the above commuting);
it can be played even without being plugged to a pc (otherwise I would have chosen this korg nano keyboard);
it can study some music theory with it;
in some six months I will be able to show some decent performance with it (so to say, I hope it has a bit of depth and is not just a toy).


Since (as I said), I know nothing of music and musical instruments, I would like to have someone savvy to 'validate' my points; alternative suggestions/idead would be appreciated, too!

I am sorry I haven't 'linkified' but, as it is my first question, stackexchange only allows me to have two hyperlinks.
",Pal Lito,https://music.stackexchange.com/users/3098,"Electric instruments still make some noise, so if you must be absolutely silent, then I think you'll have to pick up something electronic. Otherwise, an electric ukulele is pretty compact and a lot of fun to play. 

One possibility you didn't mention is applications for smartphones like iPhones. If you already have an Android or iOS device, there are a number of cheap applications that you can use for learning as well as creating music. I would recommend looking in the ""Music"" category for your app store and picking some things you like. 
",Stephan A. Terre,https://music.stackexchange.com/users/2652,http://music.stackexchange.com/questions/7615/silent-extremely-portable-instrument-to-learn-music,LIFE_ARTS,music.stackexchange.com,0.7777777777777778,0.5555555555555556,0.0,0.6666666666666666,0.6666666666666666,0.0,0.6666666666666666,0.7777777777777778,0.0,0.0,1.0,1.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.7777777777777778,0.4444444444444444,1.0,0.7777777777777778,0.8666666666666666,0.0,0.0,0.0,1.0,"Silent, very portable instruments to learn music","I am currently off work for more or less a month, so I decided it could be a great time to learn an instrument and how to compose some simple tunes.

I am 29, never played anything meaningful in my life, know very little to nothing about music theory but I can comfortably read notes on a score.



Asking a search engine for suggestions brought me to the music section of stackexchange and particulary to this question. After some thought I am planning to buy the Kaossilator 2 becase I feel/think:


it is not too expensive for me (less than 200$) (otherwise I would have fancied a Teenage engineering OP1;
it can be completely silent (commuting home->work->home takes quite a long time, I would like to be able to practice in crowded places (without annoying anyone);
it is extremely portable (for the above commuting);
it can be played even without being plugged to a pc (otherwise I would have chosen this korg nano keyboard);
it can study some music theory with it;
in some six months I will be able to show some decent performance with it (so to say, I hope it has a bit of depth and is not just a toy).


Since (as I said), I know nothing of music and musical instruments, I would like to have someone savvy to 'validate' my points; alternative suggestions/idead would be appreciated, too!

I am sorry I haven't 'linkified' but, as it is my first question, stackexchange only allows me to have two hyperlinks.
","Electric instruments still make some noise, so if you must be absolutely silent, then I think you'll have to pick up something electronic. Otherwise, an electric ukulele is pretty compact and a lot of fun to play. 

One possibility you didn't mention is applications for smartphones like iPhones. If you already have an Android or iOS device, there are a number of cheap applications that you can use for learning as well as creating music. I would recommend looking in the ""Music"" category for your app store and picking some things you like. 
"
4415,4415,7014,Does the original jutsu user feel anything when a shadow clone is dispersed forcefully?,"According to the wiki,


  While the technique can be extremely beneficial, attempting to use multiple clones for training purposes can be mentally harmful to the user, as not only is all the experience collected by the user, but so is all the mental stress from training each clone


Now, when a clone is destroyed, there must be some mental stress involved. So does Naruto (or anyone else) feel anything when their shadow clones are dispersed? 

Nothing has been shown to indicate this (at least in the anime). I was wondering why this would not be applicable.
",Chetter Hummin,https://anime.stackexchange.com/users/321,"You basically answered your own question. It is indeed stated that Naruto receives the experience, mental stress and chakra of the clone. When a clone is destroyed, it, of course, had mental stress (as it just got attacked and killed).

Most of the times you do not see this, either because Naruto is used to this and has an immense capacity to endure this, or because the technique would become meaningless if he could not use it due to all the stress. (I suspect the latter)

Although, during the training where he uses his clones to decrease the training duration, it became clear that is was very hard on him due to the mental stress he received of his clones.
",Veger,https://anime.stackexchange.com/users/51,http://anime.stackexchange.com/questions/2193/does-the-original-jutsu-user-feel-anything-when-a-shadow-clone-is-dispersed-forc,CULTURE,anime.stackexchange.com,0.6666666666666666,0.7777777777777778,0.6666666666666666,1.0,0.6666666666666666,1.0,0.6666666666666666,0.4444444444444444,0.3333333333333333,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8,0.0,0.0,1.0,1.0,"When shadow clones are forced to disperse, how does the original jutsu user feel?","According to the wiki,


  While the technique can be extremely beneficial, attempting to use multiple clones for training purposes can be mentally harmful to the user, as not only is all the experience collected by the user, but so is all the mental stress from training each clone


Now, when a clone is destroyed, there must be some mental stress involved. So does Naruto (or anyone else) feel anything when their shadow clones are dispersed? 

Nothing has been shown to indicate this (at least in the anime). I was wondering why this would not be applicable.
","You basically answered your own question. It is indeed stated that Naruto receives the experience, mental stress and chakra of the clone. When a clone is destroyed, it, of course, had mental stress (as it just got attacked and killed).

Most of the times you do not see this, either because Naruto is used to this and has an immense capacity to endure this, or because the technique would become meaningless if he could not use it due to all the stress. (I suspect the latter)

Although, during the training where he uses his clones to decrease the training duration, it became clear that is was very hard on him due to the mental stress he received of his clones.
"
1845,1845,2927,Migration Assistant fails on Ethernet Mavericks-to-Mavericks migration,"I have the following setup and am attempting the use Migration Assistant over Ethernet:


Source machine: Early 2009 24-inch iMac running OS X 10.9 
Destination
machine: Latest MacBook Pro Retina running OS X 10.9
Connection: direct Ethernet cable between machines


When I use Migration assistant following Apple's documentation I pass through the confirmation code step on both machines, and then get as far as the ""Checking Source Machine"" screen on the destination, and am stuck there for about 10 minutes, at which point the destination machine jumps back to the language selection setup page, and the source machine says ""This machine is attempting to reconnect to your other Mac"".

At this point I'm at a dead end: Attempting to proceed through the setup again on the destination gets me nowhere, and the only option on the source machine is ""Cancel Transfer"", which quits Migration Assistant there and ends the whole process.

On the source machine I've turned off LittleSnitch, which I normally have running, turned off Apple's firewall, and enabled file sharing.

What am I missing? Are there other settings somewhere that I need to check? I've also tried using FireWire to connect my machines, but have a different set of issues there.
",orome,https://apple.stackexchange.com/users/4395,"Here are the points which don't block Migration Assistant on the source Mac side:

Firewall on

File Sharing off

FileVault on


Here are 2 key points which blocks the reachability of Migration Assistant on the source Mac side:

IPv6

IPv6 off


This isn't the default configuration. But within enterprise large networks it
is a usefull practice to avoid IPv6 problems when your infrastructure and
your other computers don't manage it yet.

If IPv6 is off on the source Mac, just turn it on before firing the installation process from the target Mac.

Firewall setting

If your firewall setting on the source Mac is set so that it won't automatically accept connection from signed software (as in this screen capture)


then ""Migration Assistant"" will fail (the connection will fail, and the source Mac won't display the code to confirm it is the right source).

You just have to turn this switch on before firing the installation process from the target Mac.
Of course, this setting won't be correctly transfered by the Migration Assistant since it would block it.

Beware if you want to make different tests!

Once the source Mac has been seen on the network (or direct connection) any configuration change on the source side won't be seen on the target side.

To see any configuration change of the source side the installation process of the target side must be restarted at the boot step from 
disk.

The back button isn't sufficient.

The Migration Assistant on the source Mac can detect this failure factor and could warn us that it will fail with a clear warning window
rather than to play with the rotating gearing.
",daniel Azuelos,https://apple.stackexchange.com/users/22003,http://apple.stackexchange.com/questions/111615/migration-assistant-fails-on-ethernet-mavericks-to-mavericks-migration,TECHNOLOGY,apple.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,0.0,1.0,1.0,0.5555555555555556,0.4444444444444444,0.6666666666666666,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.0,0.7777777777777778,0.7777777777777778,0.6666666666666666,0.8888888888888888,1.0,0.9,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.7777777777777778,The migration assistant failed in the Ethernet calf to calf migration,"I have the following setup and am attempting the use Migration Assistant over Ethernet:


Source machine: Early 2009 24-inch iMac running OS X 10.9 
Destination
machine: Latest MacBook Pro Retina running OS X 10.9
Connection: direct Ethernet cable between machines


When I use Migration assistant following Apple's documentation I pass through the confirmation code step on both machines, and then get as far as the ""Checking Source Machine"" screen on the destination, and am stuck there for about 10 minutes, at which point the destination machine jumps back to the language selection setup page, and the source machine says ""This machine is attempting to reconnect to your other Mac"".

At this point I'm at a dead end: Attempting to proceed through the setup again on the destination gets me nowhere, and the only option on the source machine is ""Cancel Transfer"", which quits Migration Assistant there and ends the whole process.

On the source machine I've turned off LittleSnitch, which I normally have running, turned off Apple's firewall, and enabled file sharing.

What am I missing? Are there other settings somewhere that I need to check? I've also tried using FireWire to connect my machines, but have a different set of issues there.
","Here are the points which don't block Migration Assistant on the source Mac side:

Firewall on

File Sharing off

FileVault on


Here are 2 key points which blocks the reachability of Migration Assistant on the source Mac side:

IPv6

IPv6 off


This isn't the default configuration. But within enterprise large networks it
is a usefull practice to avoid IPv6 problems when your infrastructure and
your other computers don't manage it yet.

If IPv6 is off on the source Mac, just turn it on before firing the installation process from the target Mac.

Firewall setting

If your firewall setting on the source Mac is set so that it won't automatically accept connection from signed software (as in this screen capture)


then ""Migration Assistant"" will fail (the connection will fail, and the source Mac won't display the code to confirm it is the right source).

You just have to turn this switch on before firing the installation process from the target Mac.
Of course, this setting won't be correctly transfered by the Migration Assistant since it would block it.

Beware if you want to make different tests!

Once the source Mac has been seen on the network (or direct connection) any configuration change on the source side won't be seen on the target side.

To see any configuration change of the source side the installation process of the target side must be restarted at the boot step from 
disk.

The back button isn't sufficient.

The Migration Assistant on the source Mac can detect this failure factor and could warn us that it will fail with a clear warning window
rather than to play with the rotating gearing.
"
2093,2093,3334,Seven Mitzvos D'Rabanan,"I heard there are 620 letters in the Aseres Hadibros which corresponds to the 613 Mitzvos of the Torah and 7 Mitzvos D'Rabanan. What are the Seven Mitzvos D'Rabanan - שבע מצוות דרבנן? Is there a easy way to remember them? Is there any disagreement as to what the seven are?
",C. Ben Yosef,https://judaism.stackexchange.com/users/1197,"The Chinuch (p394 in this edition) gives the list below and explains each in detail!

The 7 Mitzvos are:

1) Berachos - Reciting Berachos

2) Netilas Yadayim - washing your hands

3) Eruvin - allowing one to carry within an Eruv and walk further on Shabbos through an Eruv Techumin 

4) Reciting Hallel on festivals

5) Ner Shabbos - Shabbos candles

6) Megilla - on Purim

7) Chanuka - lighting the Menora.

There are many mnemonics for remembering them.
One from Sefer Keser Torah is:

אש""ר לרע""ך

א - אור (חנוכה)
ש - שבת (נר)
ר - רנה (הלל)
ל - לקריאה (מגילה)
ר - רחיצה (נטילת ידיים)
ע - ערובין
כ - כברכותיך


More can be found at wikipedia 
",Zvi,https://judaism.stackexchange.com/users/5140,http://judaism.stackexchange.com/questions/53631/seven-mitzvos-drabanan,CULTURE,judaism.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,0.5,1.0,0.5,0.6666666666666666,0.5555555555555556,1.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.6666666666666666,0.0,1.0,1.0,0.4444444444444444,1.0,1.0,0.7333333333333333,0.3333333333333333,0.0,0.3333333333333333,1.0,The rite of passage of rabanan VII,"I heard that there are 620 letters in the sermon of ASAR, corresponding to 613 rites in tora and 7 rites in rabanan. What is the rite of passage for the Seventh National Congress of labanan? Is there an easy way to remember them? What are the seven different opinions?","The Chinuch (p394 in this edition) gives the list below and explains each in detail!

The 7 Mitzvos are:

1) Berachos - Reciting Berachos

2) Netilas Yadayim - washing your hands

3) Eruvin - allowing one to carry within an Eruv and walk further on Shabbos through an Eruv Techumin 

4) Reciting Hallel on festivals

5) Ner Shabbos - Shabbos candles

6) Megilla - on Purim

7) Chanuka - lighting the Menora.

There are many mnemonics for remembering them.
One from Sefer Keser Torah is:

אש""ר לרע""ך

א - אור (חנוכה)
ש - שבת (נר)
ר - רנה (הלל)
ל - לקריאה (מגילה)
ר - רחיצה (נטילת ידיים)
ע - ערובין
כ - כברכותיך


More can be found at wikipedia 
"
5104,5104,8120,How to get <img> src from CDATA in RSS?,"I am fetching data from RSS feed with Magpie.
$rss[description]  contains CDATA with html elements:  

&lt;![CDATA[  
&lt;div&gt;  
 &lt;a href='url'&gt;  
  &lt;img src='img_url' alt='aaa' title='bbb' border='0' width='116' height='116'&gt;  
 &lt;/a&gt;  
&lt;/div&gt;]]&gt;  
Some other text  


How can I fetch ""img_url"" from this?  Is preg_match() the only way? Maybe I can use simpleXML?
",lvil,https://stackoverflow.com/users/533861,"yes,you should use regex,CDATA means that the data should be treat as normal string without parse,so you should think it as a string..
",Nowhy,https://stackoverflow.com/users/1136992,http://stackoverflow.com/questions/8838742/how-to-get-img-src-from-cdata-in-rss,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.6666666666666666,0.0,0.5,1.0,1.0,0.6666666666666666,0.5555555555555556,0.3333333333333333,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.0,0.7777777777777778,0.8888888888888888,0.5555555555555556,1.0,0.8888888888888888,0.8,0.6666666666666666,0.0,0.6666666666666666,0.7777777777777778,How to get SRC from CDATA in RSS?,"I am fetching data from RSS feed with Magpie.
$rss[description]  contains CDATA with html elements:  

&lt;![CDATA[  
&lt;div&gt;  
 &lt;a href='url'&gt;  
  &lt;img src='img_url' alt='aaa' title='bbb' border='0' width='116' height='116'&gt;  
 &lt;/a&gt;  
&lt;/div&gt;]]&gt;  
Some other text  


How can I fetch ""img_url"" from this?  Is preg_match() the only way? Maybe I can use simpleXML?
","Yes, you should use regex, CDATA means that the data should be treated as a normal string without parsing, so you should treat it as a string.."
2545,2545,4052,Mutually generics,"Given posets $P,Q\in M$, I would like to know under what circumstances there are mutually generic filters $G\subseteq P$ and $H\subseteq Q$ (generic over $M$). Also, what are the characterizations of mutual genericity? And finally, what can we say about the relation between $M[G]$ and $M[H]$ in that case?

I have a slight difficulty finding references to the notion and properties of mutual genericity (whatever they are).
",kvagk,https://mathoverflow.net/users/4826,"Another fact to add to Joel's list, one which I found surprising when I first came across it, is that adding a single Cohen real adds a perfect set of reals such that any finitely many are mutually generic over each other. To see this simply consider the trace of a Cohen real on the members of an almost disjoint family and use the theorem Joel quotes about products.
",Juris Steprans,https://mathoverflow.net/users/13878,http://mathoverflow.net/questions/70211,SCIENCE,mathoverflow.net,1.0,0.3333333333333333,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.6666666666666666,0.3333333333333333,1.0,0.6666666666666666,0.4,0.0,0.0,0.0,1.0,Interdependent,"Considering posts $p, Q \ in M $, I'd like to know when there are general filters $g \ substeq p $, and $h \ substeq q $(generic over $M $). What are the characteristics of mutual generics? Finally, what can we say about the relationship between M [g] $and m [H] $in this case?","Another fact to add to Joel's list, one which I found surprising when I first came across it, is that adding a single Cohen real adds a perfect set of reals such that any finitely many are mutually generic over each other. To see this simply consider the trace of a Cohen real on the members of an almost disjoint family and use the theorem Joel quotes about products.
"
2029,2029,3235,Visual Studio profiler not finding symbols when I run it in Azure,"I am trying to profile my Windows Azure application using the Visual Studio Profiler in Windows Azure. I followed the instructions at http://msdn.microsoft.com/en-us/library/windowsazure/hh369930.aspx#BK_ProfilingCloudService, but I run into this problem where when I download the profiling report from an instance it can't find the symbol information and I get nothing but hex values for the function names. The profiler outputs the following errors:


Warning VSP2701: F:\approot\MyApp.MyLib.dll could not be found when looking for symbol information.
Warning VSP2701: D:\windows\system32\MSASN1.dll could not be found when looking for symbol information.
Warning VSP2701: D:\windows\system32\slc.dll could not be found when looking for symbol information.
Warning VSP2701: D:\windows\assembly\NativeImages_v4.0.30319_64\Microsoft.Build.Fra#\d172e68980f5b5930d83fc1bccfc07e3\Microsoft.Build.Framework.ni.dll could not be found when looking for symbol information.
Warning VSP2701: D:\windows\Microsoft.Net\assembly\GAC_MSIL\Microsoft.Build.Framework\v4.0_4.0.0.0__b03f5f7f11d50a3a\Microsoft.Build.Framework.dll could not be found when looking for symbol information.
Warning VSP2701: D:\windows\assembly\NativeImages_v4.0.30319_64\System.Runtime.Cach#\5cf803aa1b791b9c6cf2d5167fe7d63b\System.Runtime.Caching.ni.dll could not be found when looking for symbol information.
Warning VSP2701: D:\windows\assembly\NativeImages_v4.0.30319_64\System.Web.Applicat#\fdc3ab5c1ff60542a20b6950f64eeb29\System.Web.ApplicationServices.ni.dll could not be found when looking for symbol information.
Warning VSP2701: D:\windows\Microsoft.Net\assembly\GAC_MSIL\System.Web.ApplicationServices\v4.0_4.0.0.0__31bf3856ad364e35\System.Web.ApplicationServices.dll could not be found when looking for symbol information.
Warning VSP2701: D:\windows\assembly\NativeImages_v4.0.30319_64\System.DirectorySer#\770f4419204ad7db44842c6dbb86a336\System.DirectoryServices.Protocols.ni.dll could not be found when looking for symbol information.
Warning VSP2701: D:\windows\Microsoft.Net\assembly\GAC_MSIL\System.DirectoryServices.Protocols\v4.0_4.0.0.0__b03f5f7f11d50a3a\System.DirectoryServices.Protocols.dll could not be found when looking for symbol information.
Warning VSP2701: D:\windows\assembly\NativeImages_v4.0.30319_64\System.DirectorySer#\7f7a77e6e63a5169626f3c0c8c7d72a8\System.DirectoryServices.ni.dll could not be found when looking for symbol information.
Warning VSP2701: D:\windows\Microsoft.Net\assembly\GAC_MSIL\System.DirectoryServices\v4.0_4.0.0.0__b03f5f7f11d50a3a\System.DirectoryServices.dll could not be found when looking for symbol information.
Warning VSP2701: D:\windows\assembly\NativeImages_v4.0.30319_64\System.Drawing\741fda6371303be2c86d23b8dcf88cc3\System.Drawing.ni.dll could not be found when looking for symbol information.
Warning VSP2701: D:\windows\assembly\NativeImages_v4.0.30319_64\System.Data.SqlXml\2d6a784738e5d67e70feb68f0c53a3d8\System.Data.SqlXml.ni.dll could not be found when looking for symbol information.
Warning VSP2701: D:\windows\Microsoft.Net\assembly\GAC_MSIL\System.Data.SqlXml\v4.0_4.0.0.0__b77a5c561934e089\System.Data.SqlXml.dll could not be found when looking for symbol information.
Warning VSP2701: D:\windows\assembly\NativeImages_v4.0.30319_64\System.Security\b7ad9cb6010b93a853dd647d9e1f3857\System.Security.ni.dll could not be found when looking for symbol information.
Warning VSP2701: D:\windows\Microsoft.Net\assembly\GAC_MSIL\System.Security\v4.0_4.0.0.0__b03f5f7f11d50a3a\System.Security.dll could not be found when looking for symbol information.


And so on. Looking at the paths, this is clearly the path that is being looked for on the actual Azure instance (I've been in via RDP enough times to recognize what D:\windows and F:\approot means). But I'm viewing this performance report on my own machine. So how can I tell the profiler to look for symbols using MY machine's settings, and not the Azure instance's settings?

For the record, I AM following the instructions in the linked pages, and I have googled this extensively and found nothing. Not to say there's nothing out there, but I'm following the instructions in the profiling blogs and such and still getting the errors. I asked this question on the MSDN forums and a Microsoft rep basically told me that if I followed the instructions it would definitely work.
",Mike,https://stackoverflow.com/users/227675,"Sorry I didn't see this earlier. Basically the issue is that when your app is profiled, many of the binaries are ngened. Because of this, the system cannot interpret the function addresses without the correct pdb hence you see Hex. You will need to generate the ngen pdb on the same machine where the ngenbinary exist (see http://blogs.msdn.com/b/visualstudioalm/archive/2012/12/10/creating-ngen-pdbs-for-profiling-reports.aspx ). That should take care of most of the binaries listed as *.ni.dll . As for your own application, setting the Symbol location in Visual Studio should be sufficient to locate the symbols for your own application. Hope this helps
",Andre Hamilton,https://stackoverflow.com/users/2279049,http://stackoverflow.com/questions/14360543/visual-studio-profiler-not-finding-symbols-when-i-run-it-in-azure,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.4444444444444444,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.3333333333333333,1.0,1.0,No symbols found while running visual studio Profiler in azure,"I am trying to profile my Windows Azure application using the Visual Studio Profiler in Windows Azure. I followed the instructions at http://msdn.microsoft.com/en-us/library/windowsazure/hh369930.aspx#BK_ProfilingCloudService, but I run into this problem where when I download the profiling report from an instance it can't find the symbol information and I get nothing but hex values for the function names. The profiler outputs the following errors:


Warning VSP2701: F:\approot\MyApp.MyLib.dll could not be found when looking for symbol information.
Warning VSP2701: D:\windows\system32\MSASN1.dll could not be found when looking for symbol information.
Warning VSP2701: D:\windows\system32\slc.dll could not be found when looking for symbol information.
Warning VSP2701: D:\windows\assembly\NativeImages_v4.0.30319_64\Microsoft.Build.Fra#\d172e68980f5b5930d83fc1bccfc07e3\Microsoft.Build.Framework.ni.dll could not be found when looking for symbol information.
Warning VSP2701: D:\windows\Microsoft.Net\assembly\GAC_MSIL\Microsoft.Build.Framework\v4.0_4.0.0.0__b03f5f7f11d50a3a\Microsoft.Build.Framework.dll could not be found when looking for symbol information.
Warning VSP2701: D:\windows\assembly\NativeImages_v4.0.30319_64\System.Runtime.Cach#\5cf803aa1b791b9c6cf2d5167fe7d63b\System.Runtime.Caching.ni.dll could not be found when looking for symbol information.
Warning VSP2701: D:\windows\assembly\NativeImages_v4.0.30319_64\System.Web.Applicat#\fdc3ab5c1ff60542a20b6950f64eeb29\System.Web.ApplicationServices.ni.dll could not be found when looking for symbol information.
Warning VSP2701: D:\windows\Microsoft.Net\assembly\GAC_MSIL\System.Web.ApplicationServices\v4.0_4.0.0.0__31bf3856ad364e35\System.Web.ApplicationServices.dll could not be found when looking for symbol information.
Warning VSP2701: D:\windows\assembly\NativeImages_v4.0.30319_64\System.DirectorySer#\770f4419204ad7db44842c6dbb86a336\System.DirectoryServices.Protocols.ni.dll could not be found when looking for symbol information.
Warning VSP2701: D:\windows\Microsoft.Net\assembly\GAC_MSIL\System.DirectoryServices.Protocols\v4.0_4.0.0.0__b03f5f7f11d50a3a\System.DirectoryServices.Protocols.dll could not be found when looking for symbol information.
Warning VSP2701: D:\windows\assembly\NativeImages_v4.0.30319_64\System.DirectorySer#\7f7a77e6e63a5169626f3c0c8c7d72a8\System.DirectoryServices.ni.dll could not be found when looking for symbol information.
Warning VSP2701: D:\windows\Microsoft.Net\assembly\GAC_MSIL\System.DirectoryServices\v4.0_4.0.0.0__b03f5f7f11d50a3a\System.DirectoryServices.dll could not be found when looking for symbol information.
Warning VSP2701: D:\windows\assembly\NativeImages_v4.0.30319_64\System.Drawing\741fda6371303be2c86d23b8dcf88cc3\System.Drawing.ni.dll could not be found when looking for symbol information.
Warning VSP2701: D:\windows\assembly\NativeImages_v4.0.30319_64\System.Data.SqlXml\2d6a784738e5d67e70feb68f0c53a3d8\System.Data.SqlXml.ni.dll could not be found when looking for symbol information.
Warning VSP2701: D:\windows\Microsoft.Net\assembly\GAC_MSIL\System.Data.SqlXml\v4.0_4.0.0.0__b77a5c561934e089\System.Data.SqlXml.dll could not be found when looking for symbol information.
Warning VSP2701: D:\windows\assembly\NativeImages_v4.0.30319_64\System.Security\b7ad9cb6010b93a853dd647d9e1f3857\System.Security.ni.dll could not be found when looking for symbol information.
Warning VSP2701: D:\windows\Microsoft.Net\assembly\GAC_MSIL\System.Security\v4.0_4.0.0.0__b03f5f7f11d50a3a\System.Security.dll could not be found when looking for symbol information.


And so on. Looking at the paths, this is clearly the path that is being looked for on the actual Azure instance (I've been in via RDP enough times to recognize what D:\windows and F:\approot means). But I'm viewing this performance report on my own machine. So how can I tell the profiler to look for symbols using MY machine's settings, and not the Azure instance's settings?

For the record, I AM following the instructions in the linked pages, and I have googled this extensively and found nothing. Not to say there's nothing out there, but I'm following the instructions in the profiling blogs and such and still getting the errors. I asked this question on the MSDN forums and a Microsoft rep basically told me that if I followed the instructions it would definitely work.
","Sorry I didn't see this earlier. Basically the issue is that when your app is profiled, many of the binaries are ngened. Because of this, the system cannot interpret the function addresses without the correct pdb hence you see Hex. You will need to generate the ngen pdb on the same machine where the ngenbinary exist (see http://blogs.msdn.com/b/visualstudioalm/archive/2012/12/10/creating-ngen-pdbs-for-profiling-reports.aspx ). That should take care of most of the binaries listed as *.ni.dll . As for your own application, setting the Symbol location in Visual Studio should be sufficient to locate the symbols for your own application. Hope this helps
"
4649,4649,7372,"Can a smaller sensor's ""crop factor"" be used to calculate the exact increase in depth of field?","If APS-C and similar crop-sensor digital cameras have a focal length multiplying effect such that a 50mm lens has an apparent focal length closer to the field of view of an 80mm on a full frame camera, and yet at the same time the depth of field for the smaller sensor camera is more like the depth of field a 50mm lens would produce on a full frame camera (using the same aperture), then this would seem to suggest the concept of an ""aperture dividing effect.""

In other words, a 50mm f/1.8 lens on an APS-C camera would act more like a 80mm f/2.8 (approx. 1.8 * 1.6x) lens in 35mm equivalent — for depth of field, not considering exposure.

Can someone with a better understanding of the physics involved clarify this for me.  I've never seen this concept explicitly mentioned anywhere, so I am a bit suspect of it.
",Sean,https://photo.stackexchange.com/users/1480,"Yes, a sensor's crop factor can be used when calculating the change in depth of field (DoF) of a lens compared to that lens' use on a full frame (FF) camera. But it will not always lead to an increase in the DoF. If shot from the same distance and displayed to the same size, the DoF for the crop body camera will be reduced (because the virtual image projected on the sensor, including the circles of confusion, will be enlarged to a greater degree). If, on the other hand, you adjust your shooting distance to frame the subject similarly the DoF will increase.

There are so many variables to deal with in this question and most of the answers assume several without specifying those assumptions. This leads to gross misunderstandings about the relationship of focal length, aperture, sensor size, shooting distance, display size, viewing distance, and even the visual acuity of the viewer to Depth of Field (DoF). All of these factors combined will determine the Depth of Field of an image. This is because DoF is a perception of what range of distances from the focal plane are in focus. Only one distance from the focal plane is actually in focus such that a point light source will theoretically produce a point of light on the focal plane. Point light sources at all other distances produce a blur circle that varies in size based on their proportional distance to the focal plane as compared to the focus distance. DoF is defined as the range between the near and far distance from the focal plane that the blur circle is still perceived as a point by the viewer of an image.

We ask questions such as, ""How does depth of field change when using the same lens on a camera with a different sized sensor?"" The correct answer is, ""It depends."" It depends on whether you shoot from the same distance (and thus change the framing of the subject) or shoot from a difference distance to approximate the same framing of the subject. It depends on whether the display size of the image is the same or the display size of the image is changed by the same proportion as the different sensor sizes. It depends on what changes and what stays the same in regard to all of the factors cited above.

If the same focal length is used at the same subject distance with the same aperture using the same sensor size with the same pixel density and printed at the same resolution on the same size paper and viewed by persons with the same visual acuity then the DoF of the two images will be the same. If any one of these variables change without a corresponding change to the others, the DoF will also be changed.

For the rest of this answer we will assume the image viewing distance and the visual acuity of the viewer are constant. We will also assume that apertures are large enough that diffraction does not come into play. And we will assume any printing is done on the same printer at the same number of dpi but not necessarily the same ppi and not necessarily on the same size paper.

For the sake of simplicity, let's consider a couple of theoretical cameras. One has a 36mm X 24mm sensor with a resolution of 3600 X 2400 pixels. This would be an 8.6MP full frame (FF) sensor. Our other camera has a 24mm X 16mm sensor with a resolution of 2400 X 1600 pixels. This would be a 3.8MP 1.5x crop body (CB). Both cameras have the same pixel size and pixel pitch. Both cameras have the same design and sensitivity at the pixel level. In other words the center 24mm X 16mm of the larger FF sensor is identical to the smaller CB sensor.

If you attach the same 50mm lens to both cameras and take a photo of the same subject from the same distance at f/2 (assuming all other settings are the same) and crop the FF sensor image to 2400 X 1600 pixels and print both images on 6"" X 4"" paper, the two images will be virtually identical, and the DoF will be the same in both photos.

If you attach the same 50mm lens to both cameras and take a photo of the same subject from the same distance at f/2 (assuming all other settings are the same) and print all of both images on 6"" X 4"" paper there will be some noticeable differences. The image from the FF camera will have a wider field of view (FoV), the subject will be smaller and the DoF will be greater than the image from the CB camera. This is because the FF image was printed at 600 ppi and the CB image was printed at 400 ppi. By enlarging each pixel from the CB camera by 50%, we also enlarged the size of each blur circle by the same amount. This means that the largest blur circle projected on the CB sensor that will be perceived as a point is 33% smaller (the reciprocal of 3/2 is 2/3) than on the FF sensor. If we had printed the FF image on 9"" X 6"" paper and the CB image on 6"" X 4"" paper the DoF would have been the same (both printed at 400 ppi), as would the subject sizes in both prints. If we then trimmed the center of the 9"" X 6"" print to a 6"" X 4"" print we would again have near identical prints.

If we attach the same 50mm lens to both cameras and take a photo at f/2 of the same subject from different distances so that the subject size is the same and print both images on 6"" X 4"" paper there will be some noticeable differences. The perspective will have changed because the CB image was taken at a greater distance from the subject. The subject will appear compressed in the CB image compared to the FF image. If background details are visible the background will also appear closer to the subject than in the image from the FF sensor. Because the 50mm lens was focused at a 50% greater distance, the DoF also increased by 50%. If the subject was at 10' using the FF camera and 15' using the CB camera here are the resulting DoF calculations:


50mm @ f/2 from 10' on FF: 9.33' to 10.8'. DoF of 1.45' (17.4""). The DoF ranges from 8"" in front of to 9.6"" behind the 10' point of focus (PoF).
50mm @ f/2 from 15' on CB: 14.0' to 16.2'. DoF of 2.18' (26.16""). The DoF ranges from 12"" in front of to 14.4"" behind the 15' PoF.


These calculations are based on a circle of confusion (CoC) of .03mm for the FF camera and .02mm for the CB camera. This is because we are printing at 600 ppi for the FF and 400 ppi for the CB (and the pixels are the same size for both- 0.01mm or 10µm).

In reality, we all know the pixels on most FF sensors are larger than the pixels on most newer CB sensors. They range from 6.92µm on the 18MP FF Canon 1D X to 7.21µm on the 16MP D4 to 4.7µm on the 36MP FF Nikon D800. The crop bodies go from 4.16µm for the 18MP Canon 7D to 3.89µm for the 24MP Nikon D7100 (the D7200 will be around 3.0µm) to 5.08µm for the 14MP Sony SLT Alpha 33. In all cases the pixel size is considerably smaller than the generally accepted CoC of .03mm (30µm) for FF cameras and .02mm (20µm) for 1.5x CB cameras. For 1.6x CB Canon cameras 0.019 (19µm) is generally used. The largest size pixels Canon has used in the last decade or so was 8.2µm for the 12.8MP FF 5D and the 8.2MP APS-H 1D mkII. What all this means is that at the pixel peeping level, focus blur will be visible even for objects within the accepted DoF because the accepted blur circle is anywhere from 4 to 7 times larger than the pixels on current DSLRs.  To calculate DoF at the pixel level you would need to use a CoC the size of your camera's pixels which would be much narrower than most DoF calculators use.
",Michael Clark,https://photo.stackexchange.com/users/15871,http://photo.stackexchange.com/questions/10079/can-a-smaller-sensors-crop-factor-be-used-to-calculate-the-exact-increase-in,LIFE_ARTS,photo.stackexchange.com,0.8333333333333334,0.6666666666666666,0.0,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.8333333333333334,1.0,0.8333333333333334,1.0,1.0,0.9,0.0,0.0,0.5,0.8333333333333334,"Can the ""crop coefficient"" of a smaller sensor be used to calculate the precise increase in depth of field?","If APS-C and similar crop sensor digital cameras have a focal length multiplier effect, which makes the 50mm lens have a focal length closer to the 80mm field of view on the full frame camera, and the depth of field of the smaller sensor camera is more similar to the depth of field camera generated by the 50mm lens on the full frame camera (using the same aperture), then this seems to imply ""aperture segmentation effect"" Concept","Yes, a sensor's crop factor can be used when calculating the change in depth of field (DoF) of a lens compared to that lens' use on a full frame (FF) camera. But it will not always lead to an increase in the DoF. If shot from the same distance and displayed to the same size, the DoF for the crop body camera will be reduced (because the virtual image projected on the sensor, including the circles of confusion, will be enlarged to a greater degree). If, on the other hand, you adjust your shooting distance to frame the subject similarly the DoF will increase.

There are so many variables to deal with in this question and most of the answers assume several without specifying those assumptions. This leads to gross misunderstandings about the relationship of focal length, aperture, sensor size, shooting distance, display size, viewing distance, and even the visual acuity of the viewer to Depth of Field (DoF). All of these factors combined will determine the Depth of Field of an image. This is because DoF is a perception of what range of distances from the focal plane are in focus. Only one distance from the focal plane is actually in focus such that a point light source will theoretically produce a point of light on the focal plane. Point light sources at all other distances produce a blur circle that varies in size based on their proportional distance to the focal plane as compared to the focus distance. DoF is defined as the range between the near and far distance from the focal plane that the blur circle is still perceived as a point by the viewer of an image.

We ask questions such as, ""How does depth of field change when using the same lens on a camera with a different sized sensor?"" The correct answer is, ""It depends."" It depends on whether you shoot from the same distance (and thus change the framing of the subject) or shoot from a difference distance to approximate the same framing of the subject. It depends on whether the display size of the image is the same or the display size of the image is changed by the same proportion as the different sensor sizes. It depends on what changes and what stays the same in regard to all of the factors cited above.

If the same focal length is used at the same subject distance with the same aperture using the same sensor size with the same pixel density and printed at the same resolution on the same size paper and viewed by persons with the same visual acuity then the DoF of the two images will be the same. If any one of these variables change without a corresponding change to the others, the DoF will also be changed.

For the rest of this answer we will assume the image viewing distance and the visual acuity of the viewer are constant. We will also assume that apertures are large enough that diffraction does not come into play. And we will assume any printing is done on the same printer at the same number of dpi but not necessarily the same ppi and not necessarily on the same size paper.

For the sake of simplicity, let's consider a couple of theoretical cameras. One has a 36mm X 24mm sensor with a resolution of 3600 X 2400 pixels. This would be an 8.6MP full frame (FF) sensor. Our other camera has a 24mm X 16mm sensor with a resolution of 2400 X 1600 pixels. This would be a 3.8MP 1.5x crop body (CB). Both cameras have the same pixel size and pixel pitch. Both cameras have the same design and sensitivity at the pixel level. In other words the center 24mm X 16mm of the larger FF sensor is identical to the smaller CB sensor.

If you attach the same 50mm lens to both cameras and take a photo of the same subject from the same distance at f/2 (assuming all other settings are the same) and crop the FF sensor image to 2400 X 1600 pixels and print both images on 6"" X 4"" paper, the two images will be virtually identical, and the DoF will be the same in both photos.

If you attach the same 50mm lens to both cameras and take a photo of the same subject from the same distance at f/2 (assuming all other settings are the same) and print all of both images on 6"" X 4"" paper there will be some noticeable differences. The image from the FF camera will have a wider field of view (FoV), the subject will be smaller and the DoF will be greater than the image from the CB camera. This is because the FF image was printed at 600 ppi and the CB image was printed at 400 ppi. By enlarging each pixel from the CB camera by 50%, we also enlarged the size of each blur circle by the same amount. This means that the largest blur circle projected on the CB sensor that will be perceived as a point is 33% smaller (the reciprocal of 3/2 is 2/3) than on the FF sensor. If we had printed the FF image on 9"" X 6"" paper and the CB image on 6"" X 4"" paper the DoF would have been the same (both printed at 400 ppi), as would the subject sizes in both prints. If we then trimmed the center of the 9"" X 6"" print to a 6"" X 4"" print we would again have near identical prints.

If we attach the same 50mm lens to both cameras and take a photo at f/2 of the same subject from different distances so that the subject size is the same and print both images on 6"" X 4"" paper there will be some noticeable differences. The perspective will have changed because the CB image was taken at a greater distance from the subject. The subject will appear compressed in the CB image compared to the FF image. If background details are visible the background will also appear closer to the subject than in the image from the FF sensor. Because the 50mm lens was focused at a 50% greater distance, the DoF also increased by 50%. If the subject was at 10' using the FF camera and 15' using the CB camera here are the resulting DoF calculations:


50mm @ f/2 from 10' on FF: 9.33' to 10.8'. DoF of 1.45' (17.4""). The DoF ranges from 8"" in front of to 9.6"" behind the 10' point of focus (PoF).
50mm @ f/2 from 15' on CB: 14.0' to 16.2'. DoF of 2.18' (26.16""). The DoF ranges from 12"" in front of to 14.4"" behind the 15' PoF.


These calculations are based on a circle of confusion (CoC) of .03mm for the FF camera and .02mm for the CB camera. This is because we are printing at 600 ppi for the FF and 400 ppi for the CB (and the pixels are the same size for both- 0.01mm or 10µm).

In reality, we all know the pixels on most FF sensors are larger than the pixels on most newer CB sensors. They range from 6.92µm on the 18MP FF Canon 1D X to 7.21µm on the 16MP D4 to 4.7µm on the 36MP FF Nikon D800. The crop bodies go from 4.16µm for the 18MP Canon 7D to 3.89µm for the 24MP Nikon D7100 (the D7200 will be around 3.0µm) to 5.08µm for the 14MP Sony SLT Alpha 33. In all cases the pixel size is considerably smaller than the generally accepted CoC of .03mm (30µm) for FF cameras and .02mm (20µm) for 1.5x CB cameras. For 1.6x CB Canon cameras 0.019 (19µm) is generally used. The largest size pixels Canon has used in the last decade or so was 8.2µm for the 12.8MP FF 5D and the 8.2MP APS-H 1D mkII. What all this means is that at the pixel peeping level, focus blur will be visible even for objects within the accepted DoF because the accepted blur circle is anywhere from 4 to 7 times larger than the pixels on current DSLRs.  To calculate DoF at the pixel level you would need to use a CoC the size of your camera's pixels which would be much narrower than most DoF calculators use.
"
4582,4582,7263,PostGIS to GeoJSON with GDAL: how to get lat/longs?,"I'm trying to convert line features from PostGIS to GeoJSON files, as follows:

from psycopg2 import *
from subprocess import call

conn = connect(dbname='gis')
cur=conn.cursor()

cur.execute(""SELECT distinct osm_id,route_name from planet_osm_line where route_name like '%Rail Trail' and network='rcn';"")

for record in cur:
  print ""%s"" % record[1]
  call ([""ogr2ogr"", ""-f"", ""GeoJSON"", record[1] + "".json"",  'PG:dbname=\'gis\'', ""-sql"", 'SELECT route_name,osm_id,tags::hstore-&gt;\'state\' as state,way from planet_osm_line where osm_id=%d' % record[0]])


That is, ultimately ogr2ogr gets called like this:

ogr2ogr -f GeoJSON blah.json ""PG:dbname='gis'"" -sql 'SELECT route_name,osm_id,tags::hstore-&gt;\'state\' as state,way from planet_osm_line where osm_id=-12345'


The GeoJSON files that get created have coordinates that look like this [ 16153119.78, -4561568.23 ]:

{ ""type"": ""Feature"", ""properties"": { ""route_name"": ""Waverley Rail Trail"", ""osm_id"": -64660, ""state"": null }, ""geometry"": { ""type"": ""LineString"", ""coordinates"": [ [ 16153119.78, -4561568.23 ], [ 16153117.1, -4561567.48 ], [ 16153114.81, -4561565.86 ], [ 16153113.24, -4561563.55 ], [ 16153112.64, -4561561.63 ], [ 16153112.64, -4561558.82 ], [ 16153113.6, -4561556.2 ], [ 16153115.39, -4561554.05 ], [ 16153117.82, -4561552.66 ], [ 16153119.98, -4561552.2 ], [ 16153122.76, -4561552.48 ], [ 16153125.28, -4561553.69 ], [ 16153127.35, -4561555.88 ], [ 16153128.43, -4561558.46 ], [ 16153128.62, -4561560.38 ], [ 16153128.08, -4561563.13 ], [ 16153126.64, -4561565.51 ], [ 16153124.47, -4561567.26 ], [ 16153121.82, -4561568.17 ], [ 16153119.78, -4561568.23 ] ] } }


Please forgive my ignorance, but what am I doing wrong here? I assume what is being written is some kind of projected value rather than the raw lat/long - so how do I get those? 

I've tried using t_srs=ESPG:3857 but that didn't fix it.
",Steve Bennett,https://gis.stackexchange.com/users/8442,"OpenLayers uses the EPSG:3857 coordinate system, in meters, and not the WGS84 system, in degrees, look at OpenStreetMap Wiki: EPSG:3857

But why use subprocess and ogr2ogr? 

1) you can use directly the PostGIS ST_AsGeoJSON function:

import psycopg2
conn = psycopg2.connect(""dbname='osm' host='localhost' user='me'"")
cur = conn.cursor()
# srid of the layer
sql = """"""SELECT Find_SRID('public', 'planet_osm_line', 'way');""""""
cur.execute(sql)
print cur.fetchone()[0]
900913 # The srid is 900913 (now ESPG:3857)


What is the srid of your layer ?
Use of ST_AsGeoJSON:

cur = conn.cursor()
sql = """"""SELECT ST_AsGeoJSON(way) from planet_osm_line WHERE osm_id=34587377;""""""
cur.execute(sql)
print cur.fetchone()[0]
{""type"":""LineString"",""coordinates"":[[286345.320000000006985,6623598.759999999776483],[286086.950000000011642,6623556.240000000223517],[286256.710000000020955,6622864.799999999813735],[286244.340000000025611,6622861.809999999590218],[286248.78000000002794,6622841.459999999962747],[286195.179999999993015,6622784.349999999627471],[286193.900000000023283,6622756.799999999813735],[286201.429999999993015,6622760.429999999701977],[286214.479999999981374,6622746.240000000223517],[286280.869999999995343,6622702.580000000074506],[286315.070000000006985,6622679.21999999973923],[286298.820000000006985,6622638.849999999627471],[286381.39000000001397,6622609.290000000037253],[286408.419999999983702,6622599.429999999701977],[286499.520000000018626,6622396],[286540.380000000004657,6622248.320000000298023],[286491.299999999988358,6622026.139999999664724],[286333.520000000018626,6621847.75],[285781.320000000006985,6621559.429999999701977],[285733.900000000023283,6621542.389999999664724],[285704.659999999974389,6621539.450000000186265],[285580.510000000009313,6621479.200000000186265],[285461.570000000006985,6621473.490000000223517],[285387.659999999974389,6621462.879999999888241],[285204.580000000016298,6621478.320000000298023],[285177.35999999998603,6621476.370000000111759],[285151.14000000001397,6621468.360000000335276],[285092.150000000023283,6621434.330000000074506],[285063.840000000025611,6621405.099999999627471],[285042.570000000006985,6621364.759999999776483],[284963.869999999995343,6621333.660000000149012],[284913.429999999993015,6621318.639999999664724],[284824.5,6621241.110000000335276],[284719,6621002.940000000409782],[284415.020000000018626,6620781.519999999552965],[283894.53000000002794,6620613.259999999776483],[283610.39000000001397,6620628.200000000186265],[283526.669999999983702,6620603.169999999925494]]}


2) or the osgeo.ogrmodule:

from osgeo import ogr
connString = """"""PG: host='localhost' dbname='osm' user'=me'""""""
conn = ogr.Open(connString)
for layer in conn:
     print layer.GetName()
planet_osm_point
planet_osm_roads
planet_osm_line
planet_osm_polygon
# first layer = planet_osm_point
conn = ogr.Open(connString)
layer= conn[0]
print layer.GetName()
planet_osm_point
print layer.GetSpatialRef().ExportToWkt() 
'PROJCS[""Popular Visualisation CRS / Mercator (deprecated)"",GEOGCS[""Popular Visualisation CRS"",DATUM[""Popular_Visualisation_Datum"",SPHEROID[""Popular Visualisation Sphere"",6378137,0,AUTHORITY[""EPSG"",""7059""]],TOWGS84[0,0,0,0,0,0,0],AUTHORITY[""EPSG"",""6055""]],PRIMEM[""Greenwich"",0,AUTHORITY[""EPSG"",""8901""]],UNIT[""degree"",0.01745329251994328,AUTHORITY[""EPSG"",""9122""]],AUTHORITY[""EPSG"",""4055""]],UNIT[""metre"",1,AUTHORITY[""EPSG"",""9001""]],PROJECTION[""Mercator_1SP""],PARAMETER[""central_meridian"",0],PARAMETER[""scale_factor"",1],PARAMETER[""false_easting"",0],PARAMETER[""false_northing"",0],AUTHORITY[""EPSG"",""3785""],AXIS[""X"",EAST],AXIS[""Y"",NORTH]]'
for feature in layer:
   geom = feature.GetGeometryRef()
   print geom.ExportToJson()
{ ""type"": ""Point"", ""coordinates"": [ 283528.026815425022505, 6604019.682090770453215 ] }
{ ""type"": ""Point"", ""coordinates"": [ 283528.026815425022505, 6604019.664439089596272 ] }
 ....

",gene,https://gis.stackexchange.com/users/2581,http://gis.stackexchange.com/questions/92960/postgis-to-geojson-with-gdal-how-to-get-lat-longs,TECHNOLOGY,gis.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.3333333333333333,1.0,Using GDAL to add PostGIS to geojson: how to get lat / long?,"I'm trying to convert line features from PostGIS to GeoJSON files, as follows:

from psycopg2 import *
from subprocess import call

conn = connect(dbname='gis')
cur=conn.cursor()

cur.execute(""SELECT distinct osm_id,route_name from planet_osm_line where route_name like '%Rail Trail' and network='rcn';"")

for record in cur:
  print ""%s"" % record[1]
  call ([""ogr2ogr"", ""-f"", ""GeoJSON"", record[1] + "".json"",  'PG:dbname=\'gis\'', ""-sql"", 'SELECT route_name,osm_id,tags::hstore-&gt;\'state\' as state,way from planet_osm_line where osm_id=%d' % record[0]])


That is, ultimately ogr2ogr gets called like this:

ogr2ogr -f GeoJSON blah.json ""PG:dbname='gis'"" -sql 'SELECT route_name,osm_id,tags::hstore-&gt;\'state\' as state,way from planet_osm_line where osm_id=-12345'


The GeoJSON files that get created have coordinates that look like this [ 16153119.78, -4561568.23 ]:

{ ""type"": ""Feature"", ""properties"": { ""route_name"": ""Waverley Rail Trail"", ""osm_id"": -64660, ""state"": null }, ""geometry"": { ""type"": ""LineString"", ""coordinates"": [ [ 16153119.78, -4561568.23 ], [ 16153117.1, -4561567.48 ], [ 16153114.81, -4561565.86 ], [ 16153113.24, -4561563.55 ], [ 16153112.64, -4561561.63 ], [ 16153112.64, -4561558.82 ], [ 16153113.6, -4561556.2 ], [ 16153115.39, -4561554.05 ], [ 16153117.82, -4561552.66 ], [ 16153119.98, -4561552.2 ], [ 16153122.76, -4561552.48 ], [ 16153125.28, -4561553.69 ], [ 16153127.35, -4561555.88 ], [ 16153128.43, -4561558.46 ], [ 16153128.62, -4561560.38 ], [ 16153128.08, -4561563.13 ], [ 16153126.64, -4561565.51 ], [ 16153124.47, -4561567.26 ], [ 16153121.82, -4561568.17 ], [ 16153119.78, -4561568.23 ] ] } }


Please forgive my ignorance, but what am I doing wrong here? I assume what is being written is some kind of projected value rather than the raw lat/long - so how do I get those? 

I've tried using t_srs=ESPG:3857 but that didn't fix it.
","OpenLayers uses the EPSG:3857 coordinate system, in meters, and not the WGS84 system, in degrees, look at OpenStreetMap Wiki: EPSG:3857

But why use subprocess and ogr2ogr? 

1) you can use directly the PostGIS ST_AsGeoJSON function:

import psycopg2
conn = psycopg2.connect(""dbname='osm' host='localhost' user='me'"")
cur = conn.cursor()
# srid of the layer
sql = """"""SELECT Find_SRID('public', 'planet_osm_line', 'way');""""""
cur.execute(sql)
print cur.fetchone()[0]
900913 # The srid is 900913 (now ESPG:3857)


What is the srid of your layer ?
Use of ST_AsGeoJSON:

cur = conn.cursor()
sql = """"""SELECT ST_AsGeoJSON(way) from planet_osm_line WHERE osm_id=34587377;""""""
cur.execute(sql)
print cur.fetchone()[0]
{""type"":""LineString"",""coordinates"":[[286345.320000000006985,6623598.759999999776483],[286086.950000000011642,6623556.240000000223517],[286256.710000000020955,6622864.799999999813735],[286244.340000000025611,6622861.809999999590218],[286248.78000000002794,6622841.459999999962747],[286195.179999999993015,6622784.349999999627471],[286193.900000000023283,6622756.799999999813735],[286201.429999999993015,6622760.429999999701977],[286214.479999999981374,6622746.240000000223517],[286280.869999999995343,6622702.580000000074506],[286315.070000000006985,6622679.21999999973923],[286298.820000000006985,6622638.849999999627471],[286381.39000000001397,6622609.290000000037253],[286408.419999999983702,6622599.429999999701977],[286499.520000000018626,6622396],[286540.380000000004657,6622248.320000000298023],[286491.299999999988358,6622026.139999999664724],[286333.520000000018626,6621847.75],[285781.320000000006985,6621559.429999999701977],[285733.900000000023283,6621542.389999999664724],[285704.659999999974389,6621539.450000000186265],[285580.510000000009313,6621479.200000000186265],[285461.570000000006985,6621473.490000000223517],[285387.659999999974389,6621462.879999999888241],[285204.580000000016298,6621478.320000000298023],[285177.35999999998603,6621476.370000000111759],[285151.14000000001397,6621468.360000000335276],[285092.150000000023283,6621434.330000000074506],[285063.840000000025611,6621405.099999999627471],[285042.570000000006985,6621364.759999999776483],[284963.869999999995343,6621333.660000000149012],[284913.429999999993015,6621318.639999999664724],[284824.5,6621241.110000000335276],[284719,6621002.940000000409782],[284415.020000000018626,6620781.519999999552965],[283894.53000000002794,6620613.259999999776483],[283610.39000000001397,6620628.200000000186265],[283526.669999999983702,6620603.169999999925494]]}


2) or the osgeo.ogrmodule:

from osgeo import ogr
connString = """"""PG: host='localhost' dbname='osm' user'=me'""""""
conn = ogr.Open(connString)
for layer in conn:
     print layer.GetName()
planet_osm_point
planet_osm_roads
planet_osm_line
planet_osm_polygon
# first layer = planet_osm_point
conn = ogr.Open(connString)
layer= conn[0]
print layer.GetName()
planet_osm_point
print layer.GetSpatialRef().ExportToWkt() 
'PROJCS[""Popular Visualisation CRS / Mercator (deprecated)"",GEOGCS[""Popular Visualisation CRS"",DATUM[""Popular_Visualisation_Datum"",SPHEROID[""Popular Visualisation Sphere"",6378137,0,AUTHORITY[""EPSG"",""7059""]],TOWGS84[0,0,0,0,0,0,0],AUTHORITY[""EPSG"",""6055""]],PRIMEM[""Greenwich"",0,AUTHORITY[""EPSG"",""8901""]],UNIT[""degree"",0.01745329251994328,AUTHORITY[""EPSG"",""9122""]],AUTHORITY[""EPSG"",""4055""]],UNIT[""metre"",1,AUTHORITY[""EPSG"",""9001""]],PROJECTION[""Mercator_1SP""],PARAMETER[""central_meridian"",0],PARAMETER[""scale_factor"",1],PARAMETER[""false_easting"",0],PARAMETER[""false_northing"",0],AUTHORITY[""EPSG"",""3785""],AXIS[""X"",EAST],AXIS[""Y"",NORTH]]'
for feature in layer:
   geom = feature.GetGeometryRef()
   print geom.ExportToJson()
{ ""type"": ""Point"", ""coordinates"": [ 283528.026815425022505, 6604019.682090770453215 ] }
{ ""type"": ""Point"", ""coordinates"": [ 283528.026815425022505, 6604019.664439089596272 ] }
 ....

"
3351,3351,5347,How to install jekyll?,"According to the jekyll site, this is how you make a new website with jekyll: 

~ $ gem install jekyll
~ $ jekyll new myblog
~ $ cd myblog
~/myblog $ jekyll serve


gem install jekyll didn't work, nor did sudo gem install jekyll: 

└─&gt;gem install jekyll
ERROR:  While executing gem ... (Errno::EACCES)
    Permission denied - /var/lib/gems/1.9.1/gems/fast-stemmer-1.0.2/LICENSE
┌─[Sat Jun 08][jon@jon-MacMini:~/Web]
└─&gt;sudo !!
sudo gem install jekyll
Building native extensions.  This could take a while...
ERROR:  Error installing jekyll:
    ERROR: Failed to build gem native extension.

        /usr/bin/ruby1.9.1 extconf.rb
/usr/lib/ruby/1.9.1/rubygems/custom_require.rb:36:in `require': cannot load such file -- mkmf (LoadError)
    from /usr/lib/ruby/1.9.1/rubygems/custom_require.rb:36:in `require'
    from extconf.rb:1:in `&lt;main&gt;'


Gem files will remain installed in /var/lib/gems/1.9.1/gems/fast-stemmer-1.0.2 for inspection.
Results logged to /var/lib/gems/1.9.1/gems/fast-stemmer-1.0.2/ext/gem_make.out


I also tried following the answer here, but that doesn't help. sudo apt-get install jekyll works. Even then, though, running jekyll new myblog returns this error: 

└─&gt;jekyll new myblog
/usr/lib/ruby/1.9.1/rubygems/custom_require.rb:36:in `require': iconv will be deprecated in the future, use String#encode instead.
WARNING: Could not read configuration. Using defaults (and options).
    No such file or directory - new/_config.yml
Building site: new -&gt; myblog
/usr/lib/ruby/vendor_ruby/jekyll/site.rb:126:in `chdir': No such file or directory - /home/jon/Web/new/ (Errno::ENOENT)
    from /usr/lib/ruby/vendor_ruby/jekyll/site.rb:126:in `read_directories'
    from /usr/lib/ruby/vendor_ruby/jekyll/site.rb:98:in `read'
    from /usr/lib/ruby/vendor_ruby/jekyll/site.rb:38:in `process'
    from /usr/bin/jekyll:250:in `&lt;main&gt;'


Anyone know what's causing this? 
",Jon,https://askubuntu.com/users/6699,"On my 13.04 and 14.04 systems, things worked for me after installing the ruby-dev package, then running the gem install:


sudo apt-get install ruby1.9.1-dev 
gem install jekyll # if this fails then sudo gem install jekyll


After that, jekyll was installed correctly.

Note that for the gem install instruction, it is better not to use sudo.*  

It's better to use something like RVM, so that sudo isn't required. On some systems  it may be necessary to use sudo, if for instance permissions were set by previous sudo commands or root-level configuration.  

See this stackoverflow question -- how to install gems without sudo for more information and for help on getting permissions set to user instead of root.

* Credit to @iguarav for this best practices advice as well as the link to rvm.io. 
",belacqua,https://askubuntu.com/users/8844,http://askubuntu.com/questions/305884/how-to-install-jekyll,TECHNOLOGY,askubuntu.com,0.7777777777777778,0.5555555555555556,0.0,1.0,1.0,1.0,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,0.8888888888888888,0.8666666666666666,1.0,0.0,1.0,0.8888888888888888,How do I install Jekyll?,"According to the jekyll site, this is how you make a new website with jekyll: 

~ $ gem install jekyll
~ $ jekyll new myblog
~ $ cd myblog
~/myblog $ jekyll serve


gem install jekyll didn't work, nor did sudo gem install jekyll: 

└─&gt;gem install jekyll
ERROR:  While executing gem ... (Errno::EACCES)
    Permission denied - /var/lib/gems/1.9.1/gems/fast-stemmer-1.0.2/LICENSE
┌─[Sat Jun 08][jon@jon-MacMini:~/Web]
└─&gt;sudo !!
sudo gem install jekyll
Building native extensions.  This could take a while...
ERROR:  Error installing jekyll:
    ERROR: Failed to build gem native extension.

        /usr/bin/ruby1.9.1 extconf.rb
/usr/lib/ruby/1.9.1/rubygems/custom_require.rb:36:in `require': cannot load such file -- mkmf (LoadError)
    from /usr/lib/ruby/1.9.1/rubygems/custom_require.rb:36:in `require'
    from extconf.rb:1:in `&lt;main&gt;'


Gem files will remain installed in /var/lib/gems/1.9.1/gems/fast-stemmer-1.0.2 for inspection.
Results logged to /var/lib/gems/1.9.1/gems/fast-stemmer-1.0.2/ext/gem_make.out


I also tried following the answer here, but that doesn't help. sudo apt-get install jekyll works. Even then, though, running jekyll new myblog returns this error: 

└─&gt;jekyll new myblog
/usr/lib/ruby/1.9.1/rubygems/custom_require.rb:36:in `require': iconv will be deprecated in the future, use String#encode instead.
WARNING: Could not read configuration. Using defaults (and options).
    No such file or directory - new/_config.yml
Building site: new -&gt; myblog
/usr/lib/ruby/vendor_ruby/jekyll/site.rb:126:in `chdir': No such file or directory - /home/jon/Web/new/ (Errno::ENOENT)
    from /usr/lib/ruby/vendor_ruby/jekyll/site.rb:126:in `read_directories'
    from /usr/lib/ruby/vendor_ruby/jekyll/site.rb:98:in `read'
    from /usr/lib/ruby/vendor_ruby/jekyll/site.rb:38:in `process'
    from /usr/bin/jekyll:250:in `&lt;main&gt;'


Anyone know what's causing this? 
","On my 13.04 and 14.04 systems, things worked for me after installing the ruby-dev package, then running the gem install:


sudo apt-get install ruby1.9.1-dev 
gem install jekyll # if this fails then sudo gem install jekyll


After that, jekyll was installed correctly.

Note that for the gem install instruction, it is better not to use sudo.*  

It's better to use something like RVM, so that sudo isn't required. On some systems  it may be necessary to use sudo, if for instance permissions were set by previous sudo commands or root-level configuration.  

See this stackoverflow question -- how to install gems without sudo for more information and for help on getting permissions set to user instead of root.

* Credit to @iguarav for this best practices advice as well as the link to rvm.io. 
"
2951,2951,4695,native-activity sample project won't compile if I change file exteension to .cpp,"I've compiled the native activity sample and it runs fine. When I switch from main.c to main.cpp I get a compiler error 

$ /cygdrive/c/android-ndk-r7/ndk-build
make: *** No rule to make target `jni/main.c', needed by `obj/local/armeabi/objs/native-activity/main.o'.  Stop.


I changed the make file to main.cpp.

I'm new to Android and Linux. I'm using Cygwin. 
",Tavison,https://stackoverflow.com/users/664328,"I had to delete the object files. Dumb mistake.
",Tavison,https://stackoverflow.com/users/664328,http://stackoverflow.com/questions/9481668/native-activity-sample-project-wont-compile-if-i-change-file-exteension-to-cpp,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.5555555555555556,0.0,1.0,1.0,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,1.0,0.0,0.8888888888888888,0.8888888888888888,0.4444444444444444,1.0,1.0,0.8,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.8888888888888888,"If you change the extension file to. CPP, the native activity sample project is not compiled","I've compiled the native activity sample and it runs fine. When I switch from main.c to main.cpp I get a compiler error 

$ /cygdrive/c/android-ndk-r7/ndk-build
make: *** No rule to make target `jni/main.c', needed by `obj/local/armeabi/objs/native-activity/main.o'.  Stop.


I changed the make file to main.cpp.

I'm new to Android and Linux. I'm using Cygwin. 
","I had to delete the object files. Dumb mistake.
"
285,285,460,native-activity sample project won't compile if I change file exteension to .cpp,"I've compiled the native activity sample and it runs fine. When I switch from main.c to main.cpp I get a compiler error 

$ /cygdrive/c/android-ndk-r7/ndk-build
make: *** No rule to make target `jni/main.c', needed by `obj/local/armeabi/objs/native-activity/main.o'.  Stop.


I changed the make file to main.cpp.

I'm new to Android and Linux. I'm using Cygwin. 
",Tavison,https://stackoverflow.com/users/664328,"Check your Android.mk file looking for main.c and change it to main.cpp

LOCAL_SRC_FILES := main.c


must be:

LOCAL_SRC_FILES := main.cpp

",Tio Pepe,https://stackoverflow.com/users/855378,http://stackoverflow.com/questions/9481668/native-activity-sample-project-wont-compile-if-i-change-file-exteension-to-cpp,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.3333333333333333,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,1.0,"If you change the extension file to. CPP, the native activity sample project is not compiled","I've compiled the native activity sample and it runs fine. When I switch from main.c to main.cpp I get a compiler error 

$ /cygdrive/c/android-ndk-r7/ndk-build
make: *** No rule to make target `jni/main.c', needed by `obj/local/armeabi/objs/native-activity/main.o'.  Stop.


I changed the make file to main.cpp.

I'm new to Android and Linux. I'm using Cygwin. 
","Check your Android.mk file looking for main.c and change it to main.cpp

LOCAL_SRC_FILES := main.c


must be:

LOCAL_SRC_FILES := main.cpp

"
128,128,203,How do you import a Compositing Node Set-up?,"I have a Compositing node set-up for a lomography effect that I want to export or append to other blend files. Is there a way to do this? 

I tried grouping the nodes, but the group wasn't appearing anywhere when I tried to append them in. (Node setup attached for whatever it's worth.)
",kopi_bon,https://blender.stackexchange.com/users/15487,"You can do this by making these nodes into a custom Node Group and then appending it to the file. To do this select all the nodes, and press Ctrl+G. (I would recommend not including the Render Layer and Composite nodes, as they will be present in the new file)

Now you can go to your new file and select File > Append and then navigate to the proper .blend file and then into the NodeGroup folder. Select the desired node group, and click Append.

Now you can go into your node editor and use Shift+A > Group to select your node group. You can edit it using Tab.
",VRM,https://blender.stackexchange.com/users/6204,http://blender.stackexchange.com/questions/33576/how-do-you-import-a-compositing-node-set-up,TECHNOLOGY,blender.stackexchange.com,1.0,0.3333333333333333,0.0,0.0,1.0,1.0,0.5,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9,1.0,0.0,0.0,1.0,How to import a composite node set?,"I have a Compositing node set-up for a lomography effect that I want to export or append to other blend files. Is there a way to do this? 

I tried grouping the nodes, but the group wasn't appearing anywhere when I tried to append them in. (Node setup attached for whatever it's worth.)
","You can do this by making these nodes into a custom Node Group and then appending it to the file. To do this select all the nodes, and press Ctrl+G. (I would recommend not including the Render Layer and Composite nodes, as they will be present in the new file)

Now you can go to your new file and select File > Append and then navigate to the proper .blend file and then into the NodeGroup folder. Select the desired node group, and click Append.

Now you can go into your node editor and use Shift+A > Group to select your node group. You can edit it using Tab.
"
3130,3130,4988,"Usage of ""might"" and ""would"" to indicate doubt","Do the sentences 


  She might be only 28, but Jodie
  Whittaker....


and


  My parents would have walked along the
  Barrow


wrongly suggest doubt, or are they normal usage? Are there names for these constructions?
Taken from Irish Times .



I googled ""would have spent their time"". 
Many cases were counterfactuals (""... otherwise they would have spent their time...”)
But plenty simply describe past events, as the in the usage sited above.
I couldn't detect a regional bias.
As an Irish-English speaker this usage is unremarkable for example I might say


  This is the exact spot where Caesar
  would have crossed the Rubicon


I think the intention is to evoke the event rather than just record it.
",cindi,https://english.stackexchange.com/users/122,"Brian Hooper: I had a look via Google for more information on this point, but, try as I might, I couldn't find anything. I remember reading an article on the difference between ""Launching the lifeboat may have saved lives"" and ""Launching the lifeboat might have saved lives"" but I can't remember where so that doesn't help much as a reference.

Nohat: I would say may/might + perfective (have) has a different meaning than the “concession” meaning here. “Launching the lifeboat may have saved lives” implies the lifeboat was launched, whereas “… might have saved lives” implies it wasn’t launched.

==============

I'm not completely sure of how things operate here at Stack Exchange. I'm not trying to step on anyone's toes, nor am I trying to be mean or snide. I don't know if this is the ""proper"" manner of addressing this. It seems to me that Comments is meant for just that, a short comment. 

This, to my mind, requires much more discussion, [and I hope it doesn't end here. Is there not a venue for advanced discussion?], hence more needed space so I've opted for a  Your Answer. And I believe my comments are directed to answering the question.

With respect, there's no way we can make the assumption that there is a ""rule"" that will describe for all situations/scenarios that launching or not launching a lifeboat [or similar situation] may or may not or might or might not have saved lives or told or implied to us whether or not a lifeboat was launched.

There are scenarios where both 'may' and 'might' are used with their normal epistemic [level of certainty] meanings to speculate on past time events just as they are used to speculate on future or present condition events.

Let me create a scenario. This is a time before ship to shore radios, radar, etc. were available.

A ferry is about to leave port. A person on the dock remarks, ""That boat might sink"". That is based on their personal feeling according to whatever facts, feelings, superstitions that person holds that has influenced their choice of 'might'.

A worker who has been involved in maintaining the ferry says, ""I warned my superiors. That ferry may sink"". 

The owner says, ""That ferry will never sink"" [Where have we heard that before?]

A foreman says in a suicide note, ""I have to address this, ... to set the record straight. We did our best but the owners wanted to save money. That ferry probably will go down on this trip.""

Other people, for whatever personal reasons they have, even a premonition, could choose, ""The ferry will almost certainly sink"" / ""The ferry may well/might well sink"".

The wide variation, which ranges from zero percent chance [owner] to say, a old time ""terrorist"" who has made some effort to sink the boat, conjecturing ""That ferry will go down"", does not mean that anyone of them is right before the boat leaves port.

That's what modals allow us to do, speculate on events, conjecture, and it doesn't matter if the event is past, present or future.

There is a terrible storm, the ferry is overdue. Those same people, probably now joined by countless others, all weigh in with their OPINIONS because, they have nothing else to go on. Remember, this is a time before radios, radar, etc.

1)The ferry went down.

2) The ferry must have sunk.

3) The ferry probably/likely sank.

4) The ferry may have gone down.

5) The ferry might have gone down.

6) The ferry didn't sink.

Again, at this point, with the available information, all are opinions, even 1) and 6), though one of them will, maybe, probably never, eventually be confirmed as fact.

But look at the modal perfect examples for that's the point I'm trying to get across. Sometimes, 'might' just means what it most often normally means, ""there's a tiny to small chance that X will occur/is occurring/has occurred"".

The ferry, I'm sad to report, [this is my scenario] went down. The people of that time only know this because no trace was ever found of the boat, the people or the things on the boat. No lifeboats were ever launched.

There is now rampant speculation among the population on whether a or some lifeboats would have saved lives.    

1) Lifeboats would have saved lives.

2) Lifeboats almost certainly would have saved lives.

[Note that 'must have saved lives', epistemically equal to 'almost certainly would have saved lives' isn't possible here]

3) Lifeboats probably/likely would have saved lives.

[Note that 'should have saved lives', is strange here even though 'should' is epistemically equal to 'probably/likely'.]

4) Lifeboats may have saved lives.

5) Lifeboats might have saved lives.

6) Lifeboats wouldn't have saved lives.

But all these are still simply personal opinions, not statements of fact.

Look at the 'may have' and 'might have' parts. There's no implication in the 'might have saved lives' opinion that lifeboats were launched. There's a fact that dismisses any such implication. No lifeboats were launched.

Certainly, there are situations where 'might' and 'may are used to effect a meaning other that their basic epistemic/level of certainty meanings. I noted this with respect to 'might' in my previous post.

We know that there are meanings for 'may' and for 'might' that are sometimes used to make a concession and sometimes, to angrily suggest [sometimes using understatement] that something should have been done. 

For this scenario, ""You might have [at the very least] sent out one search boat!"" 

What nohat stated was true, but it's not true for all situations, not even for most; I'd say that its true for a small portion of 'might have + PP' situations. 

I'm sorry that this is so long, but if you'll bear with me. I've read often this idea presented by nohat. It is similar in nature to the thought used to prohibit ""If S was"" as a counterfactual use. 

Somebody, sometime, noticed that ""If S was"" can hold the meaning of ""allowing that that is true, ... "", so they errantly made a determination that that excluded the counterfactual 'was' use in ""If I was you, ... "". 

Language is exceedingly complex and these kinds of expansive notions aren't helpful to come to an understanding of language. They have no affect on native speakers, save for the fact that the myths continue to be spread, but they have a gigantic affect on ESL/EFLs, both in terms of comprehension and production.

Another of these expansive notions is the idea that 'would' is subjunctive. It is not! There are only a few examples of the subjunctive left in English and 'would' is not one of them.

'would' can be, and is often used in subjunctive uses to express subjunctive/contrary to fact ideas, but so are a lot of other modals.

'would' also hold the meaning of 100% true, ""that would be Bill""; ""He would, ten years later, be elected president"". 

The original question, which I'm now pointedly getting to, [how does one illustrate a degree of embarrassment?]

My parents would have walked along the Barrow

likely, in my opinion, shows this same meaning of 'would', ie. 100% true. I may be wrong for this particular instance but that doesn't negate the fact that that is how 'would' is often used. 


  Cindi noted: I think the intention is
  to evoke the event rather than just
  record it.


Cindi and I disagree. She has an opinion on how 'would' is being used here that differs from my opinion. She may well be right. The speaker could be using 'would have' in the same sense as 'must have', which would express some degree of doubt.

The mistaken notion that 'would' is always subjunctive/shows doubt cause these kinds of misunderstanding. I suspect that the person who asked the original question is a native speaker - I could be wrong here too but nevertheless, the answers, I feel, illustrate just how strong this notion is set even in the conscious ideas of native speakers. 

It's interesting to note, please do, that this notion doesn't exist in our personal natural grammars because we all use this idea of 'would' as 100% true in so many instances, without it twigging whatever conscious prescriptions we hold.
",Dan,https://english.stackexchange.com/users/2015,http://english.stackexchange.com/questions/3541/usage-of-might-and-would-to-indicate-doubt,CULTURE,english.stackexchange.com,0.7777777777777778,0.7777777777777778,0.0,0.3333333333333333,1.0,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.0,0.0,0.6666666666666666,0.0,0.3333333333333333,0.0,0.6666666666666666,0.0,0.0,0.0,0.6666666666666666,0.0,0.7777777777777778,0.7777777777777778,1.0,0.8888888888888888,0.8888888888888888,0.8,0.0,0.0,0.6666666666666666,0.6666666666666666,"Use ""may"" and ""will"" to express doubt","Do the sentences 


  She might be only 28, but Jodie
  Whittaker....


and


  My parents would have walked along the
  Barrow


wrongly suggest doubt, or are they normal usage? Are there names for these constructions?
Taken from Irish Times .



I googled ""would have spent their time"". 
Many cases were counterfactuals (""... otherwise they would have spent their time...”)
But plenty simply describe past events, as the in the usage sited above.
I couldn't detect a regional bias.
As an Irish-English speaker this usage is unremarkable for example I might say


  This is the exact spot where Caesar
  would have crossed the Rubicon


I think the intention is to evoke the event rather than just record it.
","Brian Hooper: I had a look via Google for more information on this point, but, try as I might, I couldn't find anything. I remember reading an article on the difference between ""Launching the lifeboat may have saved lives"" and ""Launching the lifeboat might have saved lives"" but I can't remember where so that doesn't help much as a reference.

Nohat: I would say may/might + perfective (have) has a different meaning than the “concession” meaning here. “Launching the lifeboat may have saved lives” implies the lifeboat was launched, whereas “… might have saved lives” implies it wasn’t launched.

==============

I'm not completely sure of how things operate here at Stack Exchange. I'm not trying to step on anyone's toes, nor am I trying to be mean or snide. I don't know if this is the ""proper"" manner of addressing this. It seems to me that Comments is meant for just that, a short comment. 

This, to my mind, requires much more discussion, [and I hope it doesn't end here. Is there not a venue for advanced discussion?], hence more needed space so I've opted for a  Your Answer. And I believe my comments are directed to answering the question.

With respect, there's no way we can make the assumption that there is a ""rule"" that will describe for all situations/scenarios that launching or not launching a lifeboat [or similar situation] may or may not or might or might not have saved lives or told or implied to us whether or not a lifeboat was launched.

There are scenarios where both 'may' and 'might' are used with their normal epistemic [level of certainty] meanings to speculate on past time events just as they are used to speculate on future or present condition events.

Let me create a scenario. This is a time before ship to shore radios, radar, etc. were available.

A ferry is about to leave port. A person on the dock remarks, ""That boat might sink"". That is based on their personal feeling according to whatever facts, feelings, superstitions that person holds that has influenced their choice of 'might'.

A worker who has been involved in maintaining the ferry says, ""I warned my superiors. That ferry may sink"". 

The owner says, ""That ferry will never sink"" [Where have we heard that before?]

A foreman says in a suicide note, ""I have to address this, ... to set the record straight. We did our best but the owners wanted to save money. That ferry probably will go down on this trip.""

Other people, for whatever personal reasons they have, even a premonition, could choose, ""The ferry will almost certainly sink"" / ""The ferry may well/might well sink"".

The wide variation, which ranges from zero percent chance [owner] to say, a old time ""terrorist"" who has made some effort to sink the boat, conjecturing ""That ferry will go down"", does not mean that anyone of them is right before the boat leaves port.

That's what modals allow us to do, speculate on events, conjecture, and it doesn't matter if the event is past, present or future.

There is a terrible storm, the ferry is overdue. Those same people, probably now joined by countless others, all weigh in with their OPINIONS because, they have nothing else to go on. Remember, this is a time before radios, radar, etc.

1)The ferry went down.

2) The ferry must have sunk.

3) The ferry probably/likely sank.

4) The ferry may have gone down.

5) The ferry might have gone down.

6) The ferry didn't sink.

Again, at this point, with the available information, all are opinions, even 1) and 6), though one of them will, maybe, probably never, eventually be confirmed as fact.

But look at the modal perfect examples for that's the point I'm trying to get across. Sometimes, 'might' just means what it most often normally means, ""there's a tiny to small chance that X will occur/is occurring/has occurred"".

The ferry, I'm sad to report, [this is my scenario] went down. The people of that time only know this because no trace was ever found of the boat, the people or the things on the boat. No lifeboats were ever launched.

There is now rampant speculation among the population on whether a or some lifeboats would have saved lives.    

1) Lifeboats would have saved lives.

2) Lifeboats almost certainly would have saved lives.

[Note that 'must have saved lives', epistemically equal to 'almost certainly would have saved lives' isn't possible here]

3) Lifeboats probably/likely would have saved lives.

[Note that 'should have saved lives', is strange here even though 'should' is epistemically equal to 'probably/likely'.]

4) Lifeboats may have saved lives.

5) Lifeboats might have saved lives.

6) Lifeboats wouldn't have saved lives.

But all these are still simply personal opinions, not statements of fact.

Look at the 'may have' and 'might have' parts. There's no implication in the 'might have saved lives' opinion that lifeboats were launched. There's a fact that dismisses any such implication. No lifeboats were launched.

Certainly, there are situations where 'might' and 'may are used to effect a meaning other that their basic epistemic/level of certainty meanings. I noted this with respect to 'might' in my previous post.

We know that there are meanings for 'may' and for 'might' that are sometimes used to make a concession and sometimes, to angrily suggest [sometimes using understatement] that something should have been done. 

For this scenario, ""You might have [at the very least] sent out one search boat!"" 

What nohat stated was true, but it's not true for all situations, not even for most; I'd say that its true for a small portion of 'might have + PP' situations. 

I'm sorry that this is so long, but if you'll bear with me. I've read often this idea presented by nohat. It is similar in nature to the thought used to prohibit ""If S was"" as a counterfactual use. 

Somebody, sometime, noticed that ""If S was"" can hold the meaning of ""allowing that that is true, ... "", so they errantly made a determination that that excluded the counterfactual 'was' use in ""If I was you, ... "". 

Language is exceedingly complex and these kinds of expansive notions aren't helpful to come to an understanding of language. They have no affect on native speakers, save for the fact that the myths continue to be spread, but they have a gigantic affect on ESL/EFLs, both in terms of comprehension and production.

Another of these expansive notions is the idea that 'would' is subjunctive. It is not! There are only a few examples of the subjunctive left in English and 'would' is not one of them.

'would' can be, and is often used in subjunctive uses to express subjunctive/contrary to fact ideas, but so are a lot of other modals.

'would' also hold the meaning of 100% true, ""that would be Bill""; ""He would, ten years later, be elected president"". 

The original question, which I'm now pointedly getting to, [how does one illustrate a degree of embarrassment?]

My parents would have walked along the Barrow

likely, in my opinion, shows this same meaning of 'would', ie. 100% true. I may be wrong for this particular instance but that doesn't negate the fact that that is how 'would' is often used. 


  Cindi noted: I think the intention is
  to evoke the event rather than just
  record it.


Cindi and I disagree. She has an opinion on how 'would' is being used here that differs from my opinion. She may well be right. The speaker could be using 'would have' in the same sense as 'must have', which would express some degree of doubt.

The mistaken notion that 'would' is always subjunctive/shows doubt cause these kinds of misunderstanding. I suspect that the person who asked the original question is a native speaker - I could be wrong here too but nevertheless, the answers, I feel, illustrate just how strong this notion is set even in the conscious ideas of native speakers. 

It's interesting to note, please do, that this notion doesn't exist in our personal natural grammars because we all use this idea of 'would' as 100% true in so many instances, without it twigging whatever conscious prescriptions we hold.
"
198,198,319,Why do I have to explicitly add perl before the script for getops to run properly?,"When i run my script like so: 

C:\>perl script.pl -f file

It works fine. But, if I just do:

C:\>script.pl -f file

then I don't get any errors but getopts doesn't assign anything to $opt_f

This works just fine on perl 5.8 Windows XP, but it doesn't work on perl 5.12 on Windows 7.
There aren't any other versions of perl installed (its a new OS build).

Code:

use Getopt::Std;
our ($opt_f);
getopts('f:');
print ""input file is: $opt_f \n"";
print ""$0\n


Run with:

C:\&gt; perl get.pl -f sadf
input file is: sadf
get.pl


Run without:

C:\&gt;get.pl -f sadf
input file is:


Nothing!

EDIT:  fixed and this question was a repeat...
http://stackoverflow.com/questions/1695188/how-do-i-make-perl-scripts-recognize-parameters-in-the-win32-cmd-console

The OP of that post figured it out.
I had to do the same but also recreate the assoc in the gui (in addition to in the reg and on the command line with ftype.)  
",Alex,https://stackoverflow.com/users/8676,"First, look at:

C:\> assoc .pl
.pl=Perl

Take the string on the RHS, and invoke:

C:\> ftype Perl
Perl=""C:\opt\Perl\bin\perl.exe"" ""%1"" %*

Make sure %* is there.

If not, run a cmd.exe shell as administrator, and invoke

C:\> ftype Perl=perl.exe %1 %*

See also ftype /?.
",Sinan Ünür,https://stackoverflow.com/users/100754,http://stackoverflow.com/questions/4065054/why-do-i-have-to-explicitly-add-perl-before-the-script-for-getops-to-run-properl,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.6666666666666666,0.0,0.5,1.0,1.0,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.0,0.7777777777777778,0.7777777777777778,0.5555555555555556,0.8888888888888888,1.0,0.8666666666666666,1.0,0.3333333333333333,0.0,0.8888888888888888,Why add Perl explicitly before the getops script runs properly?,"When i run my script like so: 

C:\>perl script.pl -f file

It works fine. But, if I just do:

C:\>script.pl -f file

then I don't get any errors but getopts doesn't assign anything to $opt_f

This works just fine on perl 5.8 Windows XP, but it doesn't work on perl 5.12 on Windows 7.
There aren't any other versions of perl installed (its a new OS build).

Code:

use Getopt::Std;
our ($opt_f);
getopts('f:');
print ""input file is: $opt_f \n"";
print ""$0\n


Run with:

C:\&gt; perl get.pl -f sadf
input file is: sadf
get.pl


Run without:

C:\&gt;get.pl -f sadf
input file is:


Nothing!

EDIT:  fixed and this question was a repeat...
http://stackoverflow.com/questions/1695188/how-do-i-make-perl-scripts-recognize-parameters-in-the-win32-cmd-console

The OP of that post figured it out.
I had to do the same but also recreate the assoc in the gui (in addition to in the reg and on the command line with ftype.)  
","First, look at:

C:\> assoc .pl
.pl=Perl

Take the string on the RHS, and invoke:

C:\> ftype Perl
Perl=""C:\opt\Perl\bin\perl.exe"" ""%1"" %*

Make sure %* is there.

If not, run a cmd.exe shell as administrator, and invoke

C:\> ftype Perl=perl.exe %1 %*

See also ftype /?.
"
3870,3870,6161,Can excited electrons fall back to their ground state without the emission of photons?,"In gas discharge lamps, for example, a current composed of ionized atoms excites the electrons of the atoms of the gas, and when they fall back to their ground state photons are emitted. Why is the reverse process (energy transfer of an excited electron to a free electron) never mentioned? Is it not possible or is the characteristic time involved too low for the electron to ""wait"" for an electron to pass? 

I have read about losing excitation energy as heat in chemistry oriented articles, but they don't go too deep. Here is an example.
",Ant,https://physics.stackexchange.com/users/36680,"Two thoughts for you in addition to dmckee's answer.

1) Andrew Murray's research group in Manchester has done some experiments on superelastic collisions of electrons with excited atoms, see for example here. In these collisions free electrons hit excited atoms and gain energy from the excitation energy of the atom. This is a difficult experiment - you need a nice laser system to make a large enough population of excited atoms to make it possible. 

2) You mention losing energy as 'heat'. Energy loss to heat is particularly relevant to systems where the excited atoms (or molecules) are in liquid or solid. Effectively the excitation energy is converted by collisions with neighbouring atoms (or molecules) into vibrational / rotational motion, which goes into heat. This is relevant to Kasha's rule in classical photochemistry. Kasha's rule applies to molecules in liquids (or solids).

So in the case of the discharge lamp you are thinking of the excited atoms are in a gas phase environment and the likelihood of losing excitation energy to heat will depend on the rate of collisions and, hence, the gas pressure.
",tom,https://physics.stackexchange.com/users/62952,http://physics.stackexchange.com/questions/145077/can-excited-electrons-fall-back-to-their-ground-state-without-the-emission-of-ph,SCIENCE,physics.stackexchange.com,0.6666666666666666,0.7777777777777778,0.0,1.0,1.0,1.0,0.6666666666666666,0.5555555555555556,0.6666666666666666,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.7777777777777778,0.6666666666666666,0.7777777777777778,1.0,0.7,0.0,0.0,1.0,0.8888888888888888,Can excited electrons return to the ground state without photon emission?,"For example, in a gas discharge lamp, an electric current composed of ionized atoms excites the electrons of the gas atoms, and when they fall back to the ground state, they emit photons. Why is there no mention of the reverse process (energy transfer from the excited electron to the free electron)? Is this impossible, or is the characteristic time required for the electron to ""wait"" for the electron to pass too low?","Two thoughts for you in addition to dmckee's answer.

1) Andrew Murray's research group in Manchester has done some experiments on superelastic collisions of electrons with excited atoms, see for example here. In these collisions free electrons hit excited atoms and gain energy from the excitation energy of the atom. This is a difficult experiment - you need a nice laser system to make a large enough population of excited atoms to make it possible. 

2) You mention losing energy as 'heat'. Energy loss to heat is particularly relevant to systems where the excited atoms (or molecules) are in liquid or solid. Effectively the excitation energy is converted by collisions with neighbouring atoms (or molecules) into vibrational / rotational motion, which goes into heat. This is relevant to Kasha's rule in classical photochemistry. Kasha's rule applies to molecules in liquids (or solids).

So in the case of the discharge lamp you are thinking of the excited atoms are in a gas phase environment and the likelihood of losing excitation energy to heat will depend on the rate of collisions and, hence, the gas pressure.
"
2649,2649,4208,viewForAnnotation detail disclosure changing current location as well as pins,"In my viewForAnnotation method I am adding a detail disclosure button to the right of the pin, however it changes the showsUserLocation to be a red pin, with a disclosure button to the right of the ""Current Location"" text.

How can I stop the current location symbol from being a pin? Without the method it is fine.

- (MKAnnotationView *)mapView:(MKMapView *)mapView viewForAnnotation:(id &lt;MKAnnotation&gt;)annotation {

    static NSString *identifier = @""MyLocation"";

        MKPinAnnotationView *annotationView =
        (MKPinAnnotationView *)[mapView dequeueReusableAnnotationViewWithIdentifier:identifier];

        if (annotationView == nil) {
            annotationView = [[MKPinAnnotationView alloc]
                              initWithAnnotation:annotation
                              reuseIdentifier:identifier];
        } else {
            annotationView.annotation = annotation;
        }

        annotationView.enabled = YES;
        annotationView.canShowCallout = YES;

        // Create a UIButton object to add on the
        UIButton *rightButton = [UIButton buttonWithType:UIButtonTypeDetailDisclosure];
        [rightButton setTitle:annotation.title forState:UIControlStateHighlighted];
        [annotationView setRightCalloutAccessoryView:rightButton];

    return annotationView;
}

",Josh Boothe,https://stackoverflow.com/users/1862869,"This is covered in the docs, too: 


  If the object in the annotation parameter is an instance of the MKUserLocation class, you can provide a custom view to denote the user’s location. To display the user’s location using the default system view, return nil.


http://developer.apple.com/library/ios/#documentation/MapKit/Reference/MKMapViewDelegate_Protocol/MKMapViewDelegate/MKMapViewDelegate.html#//apple_ref/occ/intf/MKMapViewDelegate
",incanus,https://stackoverflow.com/users/977220,http://stackoverflow.com/questions/16854361/viewforannotation-detail-disclosure-changing-current-location-as-well-as-pins,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.6666666666666666,0.0,1.0,1.0,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.0,0.6666666666666666,0.8888888888888888,View notification details disclosure for changing current location and pins,"In my viewForAnnotation method I am adding a detail disclosure button to the right of the pin, however it changes the showsUserLocation to be a red pin, with a disclosure button to the right of the ""Current Location"" text.

How can I stop the current location symbol from being a pin? Without the method it is fine.

- (MKAnnotationView *)mapView:(MKMapView *)mapView viewForAnnotation:(id &lt;MKAnnotation&gt;)annotation {

    static NSString *identifier = @""MyLocation"";

        MKPinAnnotationView *annotationView =
        (MKPinAnnotationView *)[mapView dequeueReusableAnnotationViewWithIdentifier:identifier];

        if (annotationView == nil) {
            annotationView = [[MKPinAnnotationView alloc]
                              initWithAnnotation:annotation
                              reuseIdentifier:identifier];
        } else {
            annotationView.annotation = annotation;
        }

        annotationView.enabled = YES;
        annotationView.canShowCallout = YES;

        // Create a UIButton object to add on the
        UIButton *rightButton = [UIButton buttonWithType:UIButtonTypeDetailDisclosure];
        [rightButton setTitle:annotation.title forState:UIControlStateHighlighted];
        [annotationView setRightCalloutAccessoryView:rightButton];

    return annotationView;
}

","This is covered in the docs, too: 


  If the object in the annotation parameter is an instance of the MKUserLocation class, you can provide a custom view to denote the user’s location. To display the user’s location using the default system view, return nil.


http://developer.apple.com/library/ios/#documentation/MapKit/Reference/MKMapViewDelegate_Protocol/MKMapViewDelegate/MKMapViewDelegate.html#//apple_ref/occ/intf/MKMapViewDelegate
"
1689,1689,2672,"How to prevent the ""Too awesome to use"" syndrome","When you give the player a rare but powerful item which can only be used once but is never really required to proceed, most players will not use it at all, because they are waiting for the perfect moment. But even when this moment comes, they will still be reluctant to use it, because there might be an even better moment later. So they keep hoarding it for a moment which will never come. 

In the end, they will carry the item around until it is outclassed by other, more readily available resources, or even until the very end of the game. That means that such one-shot items don't provide any gameplay-value at all. They are simply too awesome to use.

What can you do to encourage the player to make use of their one-shot items and not hoard them?
",Philipp,https://gamedev.stackexchange.com/users/21890,"Tell the player in advance when they are going to get a refill. Maybe the first or second time they will assume there is a boss battle between now and then, but after that they should get the hint.

Alternatively, make using the weapon so fun that they don't WANT to save it.
",DeadMG,https://gamedev.stackexchange.com/users/4662,http://gamedev.stackexchange.com/questions/55558/how-to-prevent-the-too-awesome-to-use-syndrome,TECHNOLOGY,gamedev.stackexchange.com,1.0,0.7777777777777778,0.0,0.3333333333333333,0.6666666666666666,0.0,0.5555555555555556,0.5555555555555556,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,1.0,0.8888888888888888,0.5555555555555556,1.0,1.0,0.7333333333333333,0.0,0.3333333333333333,0.3333333333333333,0.8888888888888888,"How to prevent ""too good to use"" syndrome","When you give the player a rare but powerful item which can only be used once but is never really required to proceed, most players will not use it at all, because they are waiting for the perfect moment. But even when this moment comes, they will still be reluctant to use it, because there might be an even better moment later. So they keep hoarding it for a moment which will never come. 

In the end, they will carry the item around until it is outclassed by other, more readily available resources, or even until the very end of the game. That means that such one-shot items don't provide any gameplay-value at all. They are simply too awesome to use.

What can you do to encourage the player to make use of their one-shot items and not hoard them?
","Tell the player in advance when they are going to get a refill. Maybe the first or second time they will assume there is a boss battle between now and then, but after that they should get the hint.

Alternatively, make using the weapon so fun that they don't WANT to save it.
"
4626,4626,7338,How to read NTFS drives in Linux (RHEL 6)?,"My system is on dual boot. I have installed both RHEL 6 and win7 in it. I use RHEL mostly and I want to use my windows' NTFS drive in RHEL. How can I do it? Tell me the procedure.


",Chankey Pathak,https://unix.stackexchange.com/users/2063,"Install the fuse ntfs-3g package (if not available download it, remember your OS type 64-bit or 32-bit)

You must be logged in as root for the below command to work :

# yum install ntfs-3g


if yum is not configured install it by using rpm command.

Entering the below commands would help you determine the name of an NTFS partition :

# fdisk -l /dev/sda
# fdisk -l /dev/sdb


It is essential to load the fuse driver. The below command should help you do that :

 # modprobe fuse


Now using the below command you must build a mount point:

 # mkdir /mnt/ntfs


The following command would help you with mounting the ntfs partition :

 # mount -t ntfs-3g /dev/sda1 /mnt/ntfs


This is a temporary mounting only, if you reboot your pc the mount point will be lost. To mount it permanently, you need to edit the /etc/fstab configuration file.

# vim /etc/fstab


in the file

ex: # device name   mount point     fs-type      options                 
/dev/sda6          /mnt/ntfs        ntfs-3g      auto          0 0     


clear explanation for each column: 


device name - your partition name ex: /dev/sda6 
mount point - where u mount u r partition  ex: /mnt/ntfs
fs-type - your file system type ex: ntfs-3g (if u give ntfs, may be it is not work)
option - Ex:auto (if not work give it is defaults)


last two columns same as  0 0

Hope it will work.
",user29706,https://unix.stackexchange.com/users/29706,http://unix.stackexchange.com/questions/16893/how-to-read-ntfs-drives-in-linux-rhel-6,TECHNOLOGY,unix.stackexchange.com,1.0,0.6666666666666666,0.0,0.0,1.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,1.0,0.9,0.0,1.0,0.0,0.6666666666666666,How do I read NTFS drives in Linux (RHEL 6)?,"My system is dual booted. I have installed rhel6 and win7. I mainly use RHEL, and I want to use my windows NTFS drive in RHEL. What shall I do? Tell me the procedure.","Install the fuse ntfs-3g package (if not available download it, remember your OS type 64-bit or 32-bit)

You must be logged in as root for the below command to work :

# yum install ntfs-3g


if yum is not configured install it by using rpm command.

Entering the below commands would help you determine the name of an NTFS partition :

# fdisk -l /dev/sda
# fdisk -l /dev/sdb


It is essential to load the fuse driver. The below command should help you do that :

 # modprobe fuse


Now using the below command you must build a mount point:

 # mkdir /mnt/ntfs


The following command would help you with mounting the ntfs partition :

 # mount -t ntfs-3g /dev/sda1 /mnt/ntfs


This is a temporary mounting only, if you reboot your pc the mount point will be lost. To mount it permanently, you need to edit the /etc/fstab configuration file.

# vim /etc/fstab


in the file

ex: # device name   mount point     fs-type      options                 
/dev/sda6          /mnt/ntfs        ntfs-3g      auto          0 0     


clear explanation for each column: 


device name - your partition name ex: /dev/sda6 
mount point - where u mount u r partition  ex: /mnt/ntfs
fs-type - your file system type ex: ntfs-3g (if u give ntfs, may be it is not work)
option - Ex:auto (if not work give it is defaults)


last two columns same as  0 0

Hope it will work.
"
363,363,573,Magento & fputcsv strange empty row at beginning of file,"I'm writing some info to a .csv file in Magento:

public function batch_update_attributeAction(){
    $attribute_id = $_GET['attribute_id'];
    $table_name = $_GET['table_name'];
    $input = $_GET['input'];
    $input = explode(';', $input);
    $connection = Mage::getModel('core/resource')-&gt;getConnection('core_read');
    #$connection_write = Mage::getModel('core/resource')-&gt;getConnection('core_write');
    $csv_array = array();
    array_push($csv_array, array('entity_id', 'name', 'previous_value', 'updated_value'));
    foreach ($input as $part){
        $parts = explode("","", $part);
        $entity_id = $parts[0];
        $value = $parts[1];
        $sql = 'SELECT `value` FROM ' . $table_name . ' WHERE `entity_id` = ? AND `attribute_id` = ?';
        $current_value = $connection-&gt;fetchOne($sql, array($entity_id, $attribute_id));
        $sql = 'SELECT `value` FROM `catalog_product_entity_varchar` WHERE `entity_id` = ? AND `attribute_id` = ?';
        $name = $connection-&gt;fetchOne($sql, array($entity_id, 56));
        array_push($csv_array, array($entity_id, $name, $current_value, $value));
        #echo ""UPDATE `$table_name` SET `value` = $value WHERE `entity_id` = $entity_id AND `attribute_id` = $attribute_id&lt;br/&gt;"";
    }
    $user = Mage::getSingleton('admin/session')-&gt;getUser()-&gt;getFirstname();
    $date = Mage::getModel('core/date')-&gt;timestamp(time());
    $date = date('Y-m-d', $date);
    header('Content-Type: application/csv');
    header('Content-Disposition: attachement; filename=""$date $table_name update $user.csv"";');
    $f = fopen('php://output', 'w');
    foreach ($csv_array as $line) {
        fputcsv($f, $line, "","");
    }
}


Other than the empty starting row, everything is perfect.

Interestingly enough, if I run this outside of the Magento code pool, i.e from a root script, it functions perfectly. Any input would be appreciated.
",Moose,https://magento.stackexchange.com/users/4021,"Than somewhere in magento a line break happens, either a echo ""\n"", but I would bet, it is something like:

// here is a line break at the beginning of the file
&lt;?php


or

?&gt;
// here is an empty line in the file

",Fabian Blechschmidt,https://magento.stackexchange.com/users/217,http://magento.stackexchange.com/questions/22131/magento-fputcsv-strange-empty-row-at-beginning-of-file,TECHNOLOGY,magento.stackexchange.com,0.7777777777777778,0.4444444444444444,0.0,0.5,1.0,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,1.0,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,1.0,1.0,0.9,0.0,0.3333333333333333,1.0,0.5555555555555556,Strange blank line at the beginning of Magento & fputcsv file,"I'm writing some info to a .csv file in Magento:

public function batch_update_attributeAction(){
    $attribute_id = $_GET['attribute_id'];
    $table_name = $_GET['table_name'];
    $input = $_GET['input'];
    $input = explode(';', $input);
    $connection = Mage::getModel('core/resource')-&gt;getConnection('core_read');
    #$connection_write = Mage::getModel('core/resource')-&gt;getConnection('core_write');
    $csv_array = array();
    array_push($csv_array, array('entity_id', 'name', 'previous_value', 'updated_value'));
    foreach ($input as $part){
        $parts = explode("","", $part);
        $entity_id = $parts[0];
        $value = $parts[1];
        $sql = 'SELECT `value` FROM ' . $table_name . ' WHERE `entity_id` = ? AND `attribute_id` = ?';
        $current_value = $connection-&gt;fetchOne($sql, array($entity_id, $attribute_id));
        $sql = 'SELECT `value` FROM `catalog_product_entity_varchar` WHERE `entity_id` = ? AND `attribute_id` = ?';
        $name = $connection-&gt;fetchOne($sql, array($entity_id, 56));
        array_push($csv_array, array($entity_id, $name, $current_value, $value));
        #echo ""UPDATE `$table_name` SET `value` = $value WHERE `entity_id` = $entity_id AND `attribute_id` = $attribute_id&lt;br/&gt;"";
    }
    $user = Mage::getSingleton('admin/session')-&gt;getUser()-&gt;getFirstname();
    $date = Mage::getModel('core/date')-&gt;timestamp(time());
    $date = date('Y-m-d', $date);
    header('Content-Type: application/csv');
    header('Content-Disposition: attachement; filename=""$date $table_name update $user.csv"";');
    $f = fopen('php://output', 'w');
    foreach ($csv_array as $line) {
        fputcsv($f, $line, "","");
    }
}


Other than the empty starting row, everything is perfect.

Interestingly enough, if I run this outside of the Magento code pool, i.e from a root script, it functions perfectly. Any input would be appreciated.
","Than somewhere in magento a line break happens, either a echo ""\n"", but I would bet, it is something like:

// here is a line break at the beginning of the file
&lt;?php


or

?&gt;
// here is an empty line in the file

"
2659,2659,4232,MacBook Pro Retina and fonts rendering,"I am using MPB retina. I have more than two years of a constant osx experience but what I can't stand is an OSX font rendering. That's simply uncomfortable for my eyes. Big amount of my work I do using external monitor (Nec 24') and fonts look even more blurry (terrible) on it.
Is there any official or unofficial way to change font rendering in OSX?
Any kind of custom kexts or patching would be appreciated. I can't find myself anything wrt this.
",temper,https://superuser.com/users/278127,"You can use a lighter text rendering style by running

defaults write -g AppleFontSmoothing -int 1


and quitting and reopening applications to apply the changes.


",user495470,https://superuser.com/users/69039,http://superuser.com/questions/682396,TECHNOLOGY,superuser.com,0.8888888888888888,0.4444444444444444,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.6666666666666666,0.3333333333333333,0.0,1.0,MacBook Pro retina and font rendering,"I use the MPB retina. I have more than two years of OSX experience, but what I can't stand is OSX font rendering. It's just uncomfortable for my eyes. A lot of work I do is to use an external display (NEC 24 '), which makes the font look more blurry (bad).","You can use a lighter text rendering style by running

defaults write -g AppleFontSmoothing -int 1


and quitting and reopening applications to apply the changes.


"
5793,5793,9179,Examples of two different descriptions of a set that are not obviously equivalent?,"I am teaching a course in enumerative combinatorics this semester and one of my students asked for deeper clarification regarding the difference between a ""combinatorial"" and a ""bijective"" proof.  Specifically, they pointed out that when one is proving the validity of a combinatorial identity by counting a set in two different ways, this is a different activity than giving an explicit bijection between two different sets.  However, in combinatorics we often use the phrases ""combinatorial proof"" and ""bijective proof"" as synonyms, and I have often heard people use the phrase ""bijective proof"" regarding a ""count in two different ways"" proof of an identity.

It seems to me that often a combinatorial proof arises from describing one set in two different ways; implicit in a proof of the equality of the two descriptions of this set is the identity bijection from the set to itself.  In this sense, one might regard all ""combinatorial"" proofs as ""bijective,"" but I feel that I am on quite shaky ground with this.  These thoughts have led me to the following questions:

Question 1: What are some examples of combinatorial situations where the same set can be described in two different ways but it is not at all clear that the two descriptions yield the same object?

Question 2: What are some examples of situations where two bijective proofs have been given for a theorem or identity where the bijections turned out to be the same, but proving their equivalence was non-trivial?

I would also appreciate opinions regarding the distinction, if any, between combinatorial arguments where one proves identities by describing a set in two different ways and combinatorial arguments where one sets up bijections between genuinely different sets of objects.

EDIT

Thanks for the answers and comments so far.  Here are two examples that will hopefully clarify what I am asking.  One example of a bijective proof between two different sets are showing that Dyck paths and nonnesting partitions are both Catalan-enumerated objects (even preserving the Narayana statistic with a good bijection).  On the other hand, the identity $\sum_{k=0}^nk{n\choose k}=n2^{n-1}$ is usually proved by describing $k$-subsets of $n$ with a distinguished element in two different ways: in the first way, pick the set then specify the element; in the second way, pick the element then specify the rest of the set.  These are both referred to as bijective or combinatorial proofs, yet somehow they each have a different feel to them.  In the second case, it is pretty easy to see that the two descriptions of these objects yield the same set of objects, but surely there must be more situations where the same set is described in two different ways and the equivalence of their descriptions is difficult to ascertain.  Similarly, there must be times where there are several bijections between different sets, like the first example, where the bijections are the same but not obviously so.  What I am wondering about are examples of these two situations.

A non-combinatorial example of an answer to Q1 is the compact-group vs reflection group definition of the Weyl group of a semi-simple Lie Algebra, where it isn't immediately clear that the same group is obtained.  However, I am looking for more combinatorial examples.
",Ben Braun,https://mathoverflow.net/users/10602,"At the risk of plugging one of my own papers, may I recommend

Producing New Bijections from Old by David Feldman and James Propp (published in Advances in Mathematics, volume 113 (1995), pages 1-44)

which you can find here http://jamespropp.org/cancel.ps.gz .

Establishing a definition of bijective proof turns out difficult since it hinges on the distinction between proving the existence of a bijection and using a bijection to establish an equality.  One would like to trade in this syntactic problem (distinguishing a class of proofs) for a semantic problem - a mathematical universe where one can distinguish between mere numerical equality and the existence of a bijection.

Topos theory offers one approach.  There one can have two sheaves with a bijection between every stalk of one and every stalk of the other, but no global isomorphism of the sheaves.  Alternatively, one can have two sets of the same cardinality that carry different actions by the same finite group $G$.  

This may all see to be getting away from the real world, but what Jim and I show in the paper is that it all does have bankable implications for relative questions about the existence of bijections.  For example, if you have sets $A$ and $B$ and you find a bijection between $A^2$ and $B^2$, our paper gives you an concrete effective way to get a bijection between $A$ and $B$.  We also give a group-theoretical criterion that predicts the existence
of this effective reduction before you actually have it in your hands.

On the other hand, we show that a bijection between $2^A$ and $2^B$ does not effectively give rise to a bijection between $A$ and $B$.  Such a bijection might be too symmetrical, and we actually write down a concrete example to show you how things can go wrong.

Pedagogically speaking, I have often encountered two diametrically opposite and equally difficult lessons.  I have encountered many students who don't understand why you don't need the axiom of choice to pick out one element from one non-empty set (with more than one element)...in classical mathematics, say ZF.  And I have encountered just as many students who don't understand why you do need the axiom of choice to pick out one element from a two element set...in effective, or intuitionistic mathematics, or in a topos.  
",David Feldman,https://mathoverflow.net/users/10909,http://mathoverflow.net/questions/52899,SCIENCE,mathoverflow.net,1.0,0.3333333333333333,0.0,0.0,1.0,0.0,0.6666666666666666,0.7777777777777778,1.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.7777777777777778,1.0,1.0,0.9333333333333332,0.0,0.0,0.0,1.0,Two examples of different descriptions of a set are obviously not equivalent?,"I am teaching a course in enumerative combinatorics this semester and one of my students asked for deeper clarification regarding the difference between a ""combinatorial"" and a ""bijective"" proof.  Specifically, they pointed out that when one is proving the validity of a combinatorial identity by counting a set in two different ways, this is a different activity than giving an explicit bijection between two different sets.  However, in combinatorics we often use the phrases ""combinatorial proof"" and ""bijective proof"" as synonyms, and I have often heard people use the phrase ""bijective proof"" regarding a ""count in two different ways"" proof of an identity.

It seems to me that often a combinatorial proof arises from describing one set in two different ways; implicit in a proof of the equality of the two descriptions of this set is the identity bijection from the set to itself.  In this sense, one might regard all ""combinatorial"" proofs as ""bijective,"" but I feel that I am on quite shaky ground with this.  These thoughts have led me to the following questions:

Question 1: What are some examples of combinatorial situations where the same set can be described in two different ways but it is not at all clear that the two descriptions yield the same object?

Question 2: What are some examples of situations where two bijective proofs have been given for a theorem or identity where the bijections turned out to be the same, but proving their equivalence was non-trivial?

I would also appreciate opinions regarding the distinction, if any, between combinatorial arguments where one proves identities by describing a set in two different ways and combinatorial arguments where one sets up bijections between genuinely different sets of objects.

EDIT

Thanks for the answers and comments so far.  Here are two examples that will hopefully clarify what I am asking.  One example of a bijective proof between two different sets are showing that Dyck paths and nonnesting partitions are both Catalan-enumerated objects (even preserving the Narayana statistic with a good bijection).  On the other hand, the identity $\sum_{k=0}^nk{n\choose k}=n2^{n-1}$ is usually proved by describing $k$-subsets of $n$ with a distinguished element in two different ways: in the first way, pick the set then specify the element; in the second way, pick the element then specify the rest of the set.  These are both referred to as bijective or combinatorial proofs, yet somehow they each have a different feel to them.  In the second case, it is pretty easy to see that the two descriptions of these objects yield the same set of objects, but surely there must be more situations where the same set is described in two different ways and the equivalence of their descriptions is difficult to ascertain.  Similarly, there must be times where there are several bijections between different sets, like the first example, where the bijections are the same but not obviously so.  What I am wondering about are examples of these two situations.

A non-combinatorial example of an answer to Q1 is the compact-group vs reflection group definition of the Weyl group of a semi-simple Lie Algebra, where it isn't immediately clear that the same group is obtained.  However, I am looking for more combinatorial examples.
","At the risk of plugging one of my own papers, may I recommend

Producing New Bijections from Old by David Feldman and James Propp (published in Advances in Mathematics, volume 113 (1995), pages 1-44)

which you can find here http://jamespropp.org/cancel.ps.gz .

Establishing a definition of bijective proof turns out difficult since it hinges on the distinction between proving the existence of a bijection and using a bijection to establish an equality.  One would like to trade in this syntactic problem (distinguishing a class of proofs) for a semantic problem - a mathematical universe where one can distinguish between mere numerical equality and the existence of a bijection.

Topos theory offers one approach.  There one can have two sheaves with a bijection between every stalk of one and every stalk of the other, but no global isomorphism of the sheaves.  Alternatively, one can have two sets of the same cardinality that carry different actions by the same finite group $G$.  

This may all see to be getting away from the real world, but what Jim and I show in the paper is that it all does have bankable implications for relative questions about the existence of bijections.  For example, if you have sets $A$ and $B$ and you find a bijection between $A^2$ and $B^2$, our paper gives you an concrete effective way to get a bijection between $A$ and $B$.  We also give a group-theoretical criterion that predicts the existence
of this effective reduction before you actually have it in your hands.

On the other hand, we show that a bijection between $2^A$ and $2^B$ does not effectively give rise to a bijection between $A$ and $B$.  Such a bijection might be too symmetrical, and we actually write down a concrete example to show you how things can go wrong.

Pedagogically speaking, I have often encountered two diametrically opposite and equally difficult lessons.  I have encountered many students who don't understand why you don't need the axiom of choice to pick out one element from one non-empty set (with more than one element)...in classical mathematics, say ZF.  And I have encountered just as many students who don't understand why you do need the axiom of choice to pick out one element from a two element set...in effective, or intuitionistic mathematics, or in a topos.  
"
789,789,1254,Does becoming martyr have an evolutionary advantage?,"This is related to 
How does &quot;be altruist to those who are similar to you&quot; evolve?

Altruism that is


Not reciprocal
Not familiar


has little explanation. One possible explanation is that the trait itself may correlate well with genetics. One great answer there is that often the cost of altruism is small anyway. It can explain why people vote. Here the expense is small anyway.

Still there seems to be some factors that are even bigger.

Let's take a look at people that die for their ideology. Christian martyrs, Muslim suicide bombers, or Communist guerilla fighters. They seem to get so little and well, die.

And that's pretty common. It seems pretty easy for a leader or pedagogue to rouse men to be soldiers. Of course, becoming a soldier is a pretty shitty job, yet most men don't mind.

These people make a huge sacrifice for the sake of their country, ideology, or people that are not even genetically related to them.

Why?
",J. Chang,https://biology.stackexchange.com/users/554,"Your question is quite broad and asks for explanations for various behaviours which can lead to self-sacrifice. 

Religious reasons: The genetic influence here may be a predisposition to let others influence you. This is what gives rise to culture in the first place, in other words: the predisposition to at some point maybe sacrifice yourself because you are taught to do so can only die out if the basic behaviour which gives rise to culture dies out. Cultures which lead their members to die may decimate their own numbers, but they will not wipe out culture itself because in the bigger scale, those with culture do better than those without. (Plus, those who sacrifice themselves may have children as well, so any genetic influence on their behaviour can be carried on.) This also goes far into the field of memetic evolution, which is disputed but may be interesting to read about.

Political reasons: As in, dying for one's nation or country rather than because of teachings. This probably has a defensive behaviour towards one's own group as the genetic influence. Also, reputation plays a big role: see shigeta's excellent answer.

You also mention willingness to subordinate oneself which is a very common pattern not only in humans. Richard Dawkins touches on this in The Selfish Gene, but there are probably papers more focussed on this particular topic out there as well.

I think it is far-fetched to assume a genetic inheritance of in general ""willingness to die for something"" (which would be required for genetic evolution to work on it). Each thing that some people may be willing to die for can have completely different reasons. I think in these terms the willingness to die is usually an exaggeration of a behaviour which evolved for different reasons.
",Armatus,https://biology.stackexchange.com/users/806,http://biology.stackexchange.com/questions/2366/does-becoming-martyr-have-an-evolutionary-advantage,SCIENCE,biology.stackexchange.com,1.0,0.6666666666666666,0.6666666666666666,0.5,0.3333333333333333,0.5,0.6666666666666666,0.4444444444444444,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.0,1.0,0.8888888888888888,Is there an evolutionary advantage to being a martyr?,"This is related to 
How does &quot;be altruist to those who are similar to you&quot; evolve?

Altruism that is


Not reciprocal
Not familiar


has little explanation. One possible explanation is that the trait itself may correlate well with genetics. One great answer there is that often the cost of altruism is small anyway. It can explain why people vote. Here the expense is small anyway.

Still there seems to be some factors that are even bigger.

Let's take a look at people that die for their ideology. Christian martyrs, Muslim suicide bombers, or Communist guerilla fighters. They seem to get so little and well, die.

And that's pretty common. It seems pretty easy for a leader or pedagogue to rouse men to be soldiers. Of course, becoming a soldier is a pretty shitty job, yet most men don't mind.

These people make a huge sacrifice for the sake of their country, ideology, or people that are not even genetically related to them.

Why?
","Your question is quite broad and asks for explanations for various behaviours which can lead to self-sacrifice. 

Religious reasons: The genetic influence here may be a predisposition to let others influence you. This is what gives rise to culture in the first place, in other words: the predisposition to at some point maybe sacrifice yourself because you are taught to do so can only die out if the basic behaviour which gives rise to culture dies out. Cultures which lead their members to die may decimate their own numbers, but they will not wipe out culture itself because in the bigger scale, those with culture do better than those without. (Plus, those who sacrifice themselves may have children as well, so any genetic influence on their behaviour can be carried on.) This also goes far into the field of memetic evolution, which is disputed but may be interesting to read about.

Political reasons: As in, dying for one's nation or country rather than because of teachings. This probably has a defensive behaviour towards one's own group as the genetic influence. Also, reputation plays a big role: see shigeta's excellent answer.

You also mention willingness to subordinate oneself which is a very common pattern not only in humans. Richard Dawkins touches on this in The Selfish Gene, but there are probably papers more focussed on this particular topic out there as well.

I think it is far-fetched to assume a genetic inheritance of in general ""willingness to die for something"" (which would be required for genetic evolution to work on it). Each thing that some people may be willing to die for can have completely different reasons. I think in these terms the willingness to die is usually an exaggeration of a behaviour which evolved for different reasons.
"
203,203,326,Understand Atmega168P Datasheet,"I am in the process of reading through the above mentioned doc from here.

In page-21, second paragraph in section 8.5 I/O Memory, line 6 is given as below:


  When using the I/O specific commands IN and OUT, the I/O addresses 0x00 - 0x3F must be used.


However, in page-224, row 1 of table, first column, Assembly Code Example has the last line as follows:

out TWCR, r16


But as per page-21 statment, above instruction is wrong as TWCR has memory address 0xBC as given in page-396 row 6. 

Is there something wrong here, or am I understanding it wrong?

Please help.

Edit: definitions file
",Babu James,https://electronics.stackexchange.com/users/49700,"You're understanding it wrong.  Yes, TWCR has a memory address of 0xBC, but that isn't its IO address.

There are two ways of accessing the port - through IO, and through memory.  In C, when you assign a value to that address it changes the address to be the IO address instead and uses an in or an out instruction rather than load or store instructions.

-- edit --

Looking at the definitions file you have posted, there is this little bit:

; ***** I/O REGISTER DEFINITIONS *****************************************
; NOTE:
; Definitions marked ""MEMORY MAPPED""are extended I/O ports
; and cannot be used with IN/OUT instructions
....
.equ    TWCR    = 0xbc  ; MEMORY MAPPED


I suspect actually that the data sheet is incorrect.  It wouldn't be surprising if that whole section about the TWI were copied verbatim from another data sheet whose TWI interface is IO mapped not memory mapped, such as the ATMega32.  It's not uncommon.
",Majenko,https://electronics.stackexchange.com/users/4245,http://electronics.stackexchange.com/questions/122444/understand-atmega168p-datasheet,SCIENCE,electronics.stackexchange.com,0.7777777777777778,0.4444444444444444,0.0,1.0,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,1.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.3333333333333333,0.0,1.0,0.8888888888888888,Understand atmega168p data sheet,"I am in the process of reading through the above mentioned doc from here.

In page-21, second paragraph in section 8.5 I/O Memory, line 6 is given as below:


  When using the I/O specific commands IN and OUT, the I/O addresses 0x00 - 0x3F must be used.


However, in page-224, row 1 of table, first column, Assembly Code Example has the last line as follows:

out TWCR, r16


But as per page-21 statment, above instruction is wrong as TWCR has memory address 0xBC as given in page-396 row 6. 

Is there something wrong here, or am I understanding it wrong?

Please help.

Edit: definitions file
","You're understanding it wrong.  Yes, TWCR has a memory address of 0xBC, but that isn't its IO address.

There are two ways of accessing the port - through IO, and through memory.  In C, when you assign a value to that address it changes the address to be the IO address instead and uses an in or an out instruction rather than load or store instructions.

-- edit --

Looking at the definitions file you have posted, there is this little bit:

; ***** I/O REGISTER DEFINITIONS *****************************************
; NOTE:
; Definitions marked ""MEMORY MAPPED""are extended I/O ports
; and cannot be used with IN/OUT instructions
....
.equ    TWCR    = 0xbc  ; MEMORY MAPPED


I suspect actually that the data sheet is incorrect.  It wouldn't be surprising if that whole section about the TWI were copied verbatim from another data sheet whose TWI interface is IO mapped not memory mapped, such as the ATMega32.  It's not uncommon.
"
3064,3064,4880,Can summoned creatures take items back with them?,"If you summon a creature and give it any item then dismiss it, does the item go with it?
",Axel_690,https://rpg.stackexchange.com/users/6004,"It would require a DM ruling.

There are no specific mention of rules that specifically address that concern. But one should consider the following:

Paladin's Special Mount


  Each time the mount is called, it appears in full health, regardless of any damage it may have taken previously. The mount also appears wearing or carrying any gear it had when it was last dismissed. Calling a mount is a conjuration (calling) effect. Should the paladin’s mount die, it immediately disappears, leaving behind any equipment it was carrying.


The main reason a Paladin's Mount is a conjuration (calling), rather than conjuration (summoning), is due to dispel circumstances. It wouldn't be fun for the paladin if someone simply dispelled his mount from underneath him (although some may find that hilarious).

Also consider the aspect of conjuration (teleportation). For example, the teleportation spell states:


  You can bring along objects as long as their weight doesn’t exceed your maximum load. 


Since extraplanar travel isn't allowed with teleportation explicitly, lets look at Lesser Planar Ally:


  A task taking up to 1 minute per caster level requires a payment of 100 gp per HD of the creature called.
  
  At the end of its task, or when the duration bargained for expires, the creature returns to its home plane (after reporting back to you, if appropriate and possible). 


Depending on the amount of hit dice, that could be a considerable amount of gold - and weight.

Opinion

I would say Conjuration (Summoning), No; Conjuration (Calling), Yes. And that would make perfect sense. Your DM would be the final arbiter. But imagine the implications if he allowed someone to be grabbed and sucked into whatever plane the creature was summoned from...

Then again, it could be one heck of an adventure hook:


",Ruut,https://rpg.stackexchange.com/users/11343,http://rpg.stackexchange.com/questions/63767/can-summoned-creatures-take-items-back-with-them,CULTURE,rpg.stackexchange.com,0.7777777777777778,0.7777777777777778,0.0,1.0,1.0,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7777777777777778,1.0,1.0,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,1.0,Can the summoned creature take the item back?,"If you summon a creature and give it anything and then disband it, is this thing with it?","It would require a DM ruling.

There are no specific mention of rules that specifically address that concern. But one should consider the following:

Paladin's Special Mount


  Each time the mount is called, it appears in full health, regardless of any damage it may have taken previously. The mount also appears wearing or carrying any gear it had when it was last dismissed. Calling a mount is a conjuration (calling) effect. Should the paladin’s mount die, it immediately disappears, leaving behind any equipment it was carrying.


The main reason a Paladin's Mount is a conjuration (calling), rather than conjuration (summoning), is due to dispel circumstances. It wouldn't be fun for the paladin if someone simply dispelled his mount from underneath him (although some may find that hilarious).

Also consider the aspect of conjuration (teleportation). For example, the teleportation spell states:


  You can bring along objects as long as their weight doesn’t exceed your maximum load. 


Since extraplanar travel isn't allowed with teleportation explicitly, lets look at Lesser Planar Ally:


  A task taking up to 1 minute per caster level requires a payment of 100 gp per HD of the creature called.
  
  At the end of its task, or when the duration bargained for expires, the creature returns to its home plane (after reporting back to you, if appropriate and possible). 


Depending on the amount of hit dice, that could be a considerable amount of gold - and weight.

Opinion

I would say Conjuration (Summoning), No; Conjuration (Calling), Yes. And that would make perfect sense. Your DM would be the final arbiter. But imagine the implications if he allowed someone to be grabbed and sucked into whatever plane the creature was summoned from...

Then again, it could be one heck of an adventure hook:


"
4212,4212,6714,adobe illustrator - linework and paintbucket on different layers,"I would like to have my brush strokes on one layer and coloring done by live paint bucket on another layer. When I select the strokes and make a live paint group to color with everything, strokes and colors inside strokes become one object. Is there any way to seperate my brush linework and colors on different layers?
",Anoop Alex,https://graphicdesign.stackexchange.com/users/33295,"Duplicate the line art layer and color that.

Live Paint objects have to be on the current layer.
",Scott,https://graphicdesign.stackexchange.com/users/3270,http://graphicdesign.stackexchange.com/questions/51402/adobe-illustrator-linework-and-paintbucket-on-different-layers,LIFE_ARTS,graphicdesign.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,0.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.6666666666666666,0.8888888888888888,0.6666666666666666,0.8888888888888888,0.6666666666666666,0.7,0.6666666666666666,0.3333333333333333,0.0,0.8888888888888888,Adobe illustrator - lines and buckets on different layers,"I want my brush strokes on one layer and coloring by live paint buckets on the other. When I select a stroke and create a real-time paint group to shade everything, the stroke and the color within the stroke become one object. Is there any way to separate my brush lines from colors on different layers?","Duplicate the line art layer and color that.

Live Paint objects have to be on the current layer.
"
273,273,439,How is a transition between drywall and wood typically handled?,"I just finished sheet rocking my living room and am stuck at a stand-still.  My ceiling is 12' feet high at the tallest point and slopes down to 8'.  That said, at the 12' wall, the sheetrock only goes up 8' and is then met by a lap and gap type wood, which then continues up to the ceiling. The wood then slopes (on the wall). At the 8' point of the ceiling, the sheetrock butts up to the ceiling.  

My question is...How would I install a crown moulding or transition piece at the point where the sheetrock meets the wood?  The previous owners had a painted 1x4 where the paneling (now sheetrock) met the wood. However, I am wanting something a bit nicer than just a 1x4 transition.

Either I am the only person out there with a room like this or I am searching incorrectly on Google.  Does anyone have any ideas or pictures on this? I can definitely provide pictures if needed. I am tempted to pull the wood all the way to ceiling and continue the sheetrock all the way up. Any advice would be much appreciated!
",Cory,https://diy.stackexchange.com/users/39028,"Here's a few options I can think of.

Lap joint

If the wood is a bit thicker than the drywall, you could use a router to remove some of the material on the back side of the lowest plank (may require installing an additional plank, or extending the drywall). Then allow the lowest plank to lap over the drywall. Make sure you leave enough of a gap between the two materials, to allow for expansion and contraction.



Transition

Another option would be to use a transition strip, like the ones commonly used in flooring. You'd use T-molding if the materials are even with each other, or a reducer if they're not.



Molding

A simple 1x4 like the previous owners had, or a more decorative piece of molding could be used.

 
",Tester101,https://diy.stackexchange.com/users/33,http://diy.stackexchange.com/questions/68609/how-is-a-transition-between-drywall-and-wood-typically-handled,LIFE_ARTS,diy.stackexchange.com,1.0,0.3333333333333333,0.0,0.0,1.0,0.0,0.6666666666666666,0.4444444444444444,0.3333333333333333,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.7777777777777778,How is the transition between drywall and wood usually handled?,"I just finished sheet rocking my living room and am stuck at a stand-still.  My ceiling is 12' feet high at the tallest point and slopes down to 8'.  That said, at the 12' wall, the sheetrock only goes up 8' and is then met by a lap and gap type wood, which then continues up to the ceiling. The wood then slopes (on the wall). At the 8' point of the ceiling, the sheetrock butts up to the ceiling.  

My question is...How would I install a crown moulding or transition piece at the point where the sheetrock meets the wood?  The previous owners had a painted 1x4 where the paneling (now sheetrock) met the wood. However, I am wanting something a bit nicer than just a 1x4 transition.

Either I am the only person out there with a room like this or I am searching incorrectly on Google.  Does anyone have any ideas or pictures on this? I can definitely provide pictures if needed. I am tempted to pull the wood all the way to ceiling and continue the sheetrock all the way up. Any advice would be much appreciated!
","Here's a few options I can think of.

Lap joint

If the wood is a bit thicker than the drywall, you could use a router to remove some of the material on the back side of the lowest plank (may require installing an additional plank, or extending the drywall). Then allow the lowest plank to lap over the drywall. Make sure you leave enough of a gap between the two materials, to allow for expansion and contraction.



Transition

Another option would be to use a transition strip, like the ones commonly used in flooring. You'd use T-molding if the materials are even with each other, or a reducer if they're not.



Molding

A simple 1x4 like the previous owners had, or a more decorative piece of molding could be used.

 
"
2663,2663,4240,drive 3 phase induction motor with only DC (not pwm) thru each phase,"I've been researching making a driver for a 3 phase induction motor powered by DC source using PWM to approximate sine waves in each phase.

However, the switching speeds of the PWM signal for the rotational speed I want is difficult to obtain with hobby microcontroller boards like the arduino.

Can I just switch the DC directly thru each phase at the correct time only twice per cycle ?  Essentially I would be approximating a sine wave with only 2 different voltages thru the coils, ie: +V and -V (using H bridge circuitry here)

Will this create enough of a rotating magnetic field that sufficient current is induced in the rotor cage ?

What will be the losses in power / efficiency for this, or any other drawbacks for this system ?

The bonus is greatly simplified drive electronics.
",bobjandal,https://electronics.stackexchange.com/users/16361,"You may be considering a simple 3phase AC inverter design or a powerful high torque variable frequency drive (VFD) electronics.   Your choice depends on detailed specs including torque vs speed and budget. In both cases, a square wave would not be desireable as the eddy current losses would be excessive so multi-level low impedance drive is needed to appropximate the sine wave.


",Tony Stewart. EE since '75,https://electronics.stackexchange.com/users/17574,http://electronics.stackexchange.com/questions/49698/drive-3-phase-induction-motor-with-only-dc-not-pwm-thru-each-phase,TECHNOLOGY,electronics.stackexchange.com,1.0,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,1.0,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.5555555555555556,0.8888888888888888,0.5555555555555556,1.0,1.0,0.8,0.6666666666666666,0.0,0.3333333333333333,0.8888888888888888,Drive DC (non PWM) three-phase induction motor through each phase,"I've been researching making a driver for a 3 phase induction motor powered by DC source using PWM to approximate sine waves in each phase.

However, the switching speeds of the PWM signal for the rotational speed I want is difficult to obtain with hobby microcontroller boards like the arduino.

Can I just switch the DC directly thru each phase at the correct time only twice per cycle ?  Essentially I would be approximating a sine wave with only 2 different voltages thru the coils, ie: +V and -V (using H bridge circuitry here)

Will this create enough of a rotating magnetic field that sufficient current is induced in the rotor cage ?

What will be the losses in power / efficiency for this, or any other drawbacks for this system ?

The bonus is greatly simplified drive electronics.
","You may be considering a simple 3phase AC inverter design or a powerful high torque variable frequency drive (VFD) electronics.   Your choice depends on detailed specs including torque vs speed and budget. In both cases, a square wave would not be desireable as the eddy current losses would be excessive so multi-level low impedance drive is needed to appropximate the sine wave.


"
2968,2968,4722,ASA: How to connect server with a external IP address already assigned?,"

Any ideas how this can be done on a ASA? There was a sonicwall in place but it just died and we do not have a replacement besides this ASA. The 24.172.x.132 is a spam filter and I can't change the IP address. It needs to be able to access one server in the LAN.
",evolvd,https://serverfault.com/users/32265,"I am not sure if this will work for you - but I have a cloud spam filter that can talk to my internal exchange server so it seems like a similar situation.

I have an incoming access rule that permits the source 24.172.x.132 to talk to the destination x.x.x.x (outside ip of your server) for the service smtp.

Then I have a static NAT rule on the outside interface for the source 192.x.x.x (inside ip of your server) for service smtp with the address x.x.x.x (outside ip of your server)

example:

access rule:

outside: 
source;24.172.x.132
destination;server-outside-ip 
service;smtp 
action; permit

NAT Rule:

type;static
no destination
source;server-inside-ip
service;smtp
interface;outside

",Jeff,https://serverfault.com/users/47017,http://serverfault.com/questions/342557,TECHNOLOGY,serverfault.com,0.8888888888888888,0.6666666666666666,0.0,1.0,1.0,1.0,0.5555555555555556,0.3333333333333333,0.3333333333333333,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.8888888888888888,0.7777777777777778,0.6666666666666666,0.8888888888888888,0.6666666666666666,0.5,0.3333333333333333,0.3333333333333333,0.3333333333333333,1.0,ASA: how do I connect a server to an assigned external IP address?,"Do you know how to do this on ASA? There's a sonival in place, but it's just dead, and we don't have a replacement for this ASA. 24.172.x.132 is a spam filter and I can't change my IP address. It needs to be able to access a server in the LAN.","I am not sure if this will work for you - but I have a cloud spam filter that can talk to my internal exchange server so it seems like a similar situation.

I have an incoming access rule that permits the source 24.172.x.132 to talk to the destination x.x.x.x (outside ip of your server) for the service smtp.

Then I have a static NAT rule on the outside interface for the source 192.x.x.x (inside ip of your server) for service smtp with the address x.x.x.x (outside ip of your server)

example:

access rule:

outside: 
source;24.172.x.132
destination;server-outside-ip 
service;smtp 
action; permit

NAT Rule:

type;static
no destination
source;server-inside-ip
service;smtp
interface;outside

"
2237,2237,3567,How to undo card archive on Trello?,"I accidentally hit c with a card selected and archived the card. I tried to undo the archive but couldn't find the option. I tried moving the card back to the list but that didn't seem to work.
",wting,https://webapps.stackexchange.com/users/16677,"Click &lt; Show Sidebar then Menu then Archive to see your archived items. Once there you can add them back to your board.

 




",TK-421,https://webapps.stackexchange.com/users/76083,http://webapps.stackexchange.com/questions/24271/how-to-undo-card-archive-on-trello,TECHNOLOGY,webapps.stackexchange.com,0.8888888888888888,0.8888888888888888,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,1.0,How do I undo the card archive on trello?,"I accidentally typed C with a selected card and saved it. I tried to undo the archive, but I couldn't find the option. I tried to move the card back to the list, but it didn't seem to work.","Click &lt; Show Sidebar then Menu then Archive to see your archived items. Once there you can add them back to your board.

 




"
4754,4754,7540,ASA: How to connect server with a external IP address already assigned?,"

Any ideas how this can be done on a ASA? There was a sonicwall in place but it just died and we do not have a replacement besides this ASA. The 24.172.x.132 is a spam filter and I can't change the IP address. It needs to be able to access one server in the LAN.
",evolvd,https://serverfault.com/users/32265,"A traditional DMZ would have a firewall between the DMZ and the internet, and one between the DMZ and the inside network.  You can do this all on an ASA, but it depends on the model and licensing.

Internet
--------- Firewall
DMZ (with your spam filter)
--------- Firewall
Inside network


You could make that first firewall a software one, running on the spam-filter server.

So you could have the server on the Internet network as far as the ASA is concerned.  If you have spare ports on your ASA you could just assign one to the outside network (so you have two) and connect your spam server to that.  Then create a firewall rule allowing traffic from the spam-filter server into your inside network as required.  If you don't have a spare port, you will need a switch before the ASA.

You could get more fancy using a DMZ vlan on the ASA itself, and use the ASA to firewall the spam-filter, and the inside network.  This is probably the closest to what your Sonicwall was doing.
",dunxd,https://serverfault.com/users/31143,http://serverfault.com/questions/342557,TECHNOLOGY,serverfault.com,1.0,0.5555555555555556,0.0,0.3333333333333333,1.0,0.3333333333333333,0.4444444444444444,0.8888888888888888,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,1.0,ASA: how do I connect a server to an assigned external IP address?,"Do you know how to do this on ASA? There's a sonival in place, but it's just dead, and we don't have a replacement for this ASA. 24.172.x.132 is a spam filter and I can't change my IP address. It needs to be able to access a server in the LAN.","A traditional DMZ would have a firewall between the DMZ and the internet, and one between the DMZ and the inside network.  You can do this all on an ASA, but it depends on the model and licensing.

Internet
--------- Firewall
DMZ (with your spam filter)
--------- Firewall
Inside network


You could make that first firewall a software one, running on the spam-filter server.

So you could have the server on the Internet network as far as the ASA is concerned.  If you have spare ports on your ASA you could just assign one to the outside network (so you have two) and connect your spam server to that.  Then create a firewall rule allowing traffic from the spam-filter server into your inside network as required.  If you don't have a spare port, you will need a switch before the ASA.

You could get more fancy using a DMZ vlan on the ASA itself, and use the ASA to firewall the spam-filter, and the inside network.  This is probably the closest to what your Sonicwall was doing.
"
5305,5305,8424,drive 3 phase induction motor with only DC (not pwm) thru each phase,"I've been researching making a driver for a 3 phase induction motor powered by DC source using PWM to approximate sine waves in each phase.

However, the switching speeds of the PWM signal for the rotational speed I want is difficult to obtain with hobby microcontroller boards like the arduino.

Can I just switch the DC directly thru each phase at the correct time only twice per cycle ?  Essentially I would be approximating a sine wave with only 2 different voltages thru the coils, ie: +V and -V (using H bridge circuitry here)

Will this create enough of a rotating magnetic field that sufficient current is induced in the rotor cage ?

What will be the losses in power / efficiency for this, or any other drawbacks for this system ?

The bonus is greatly simplified drive electronics.
",bobjandal,https://electronics.stackexchange.com/users/16361,"Yes, using square waves instead of sine waves can be done.  As you suspected, it will be less efficient.  Think of it in frequency space.  The fundamental component of the square wave will do all the work.  The remaining harmonics will heat the motor without adding useful torque, will add mechanical stresses, and can cause more audible noise.

You say you can't get a PWM frequency fast enough to produce a reasonable sine wave, but that is hard to believe.  Surely the AVR can do 25 kHz or so PWM?  I have done this a few times with Microchip PICs, some of which even have a special PWM module intended for this application.
",Olin Lathrop,https://electronics.stackexchange.com/users/4512,http://electronics.stackexchange.com/questions/49698/drive-3-phase-induction-motor-with-only-dc-not-pwm-thru-each-phase,TECHNOLOGY,electronics.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.3333333333333333,1.0,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.0,0.3333333333333333,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.6666666666666666,0.0,0.6666666666666666,1.0,Drive DC (non PWM) three-phase induction motor through each phase,"I've been researching making a driver for a 3 phase induction motor powered by DC source using PWM to approximate sine waves in each phase.

However, the switching speeds of the PWM signal for the rotational speed I want is difficult to obtain with hobby microcontroller boards like the arduino.

Can I just switch the DC directly thru each phase at the correct time only twice per cycle ?  Essentially I would be approximating a sine wave with only 2 different voltages thru the coils, ie: +V and -V (using H bridge circuitry here)

Will this create enough of a rotating magnetic field that sufficient current is induced in the rotor cage ?

What will be the losses in power / efficiency for this, or any other drawbacks for this system ?

The bonus is greatly simplified drive electronics.
","Yes, square waves can be used instead of sine waves. As you suspect, this will reduce efficiency. Think about frequency space. The basic components of the square wave will do all the work. The remaining harmonics will heat the motor without increasing the useful torque, will increase the mechanical stress and may cause more audible noise."
3810,3810,6055,Nexus 7 is stuck in reboot loop after full discharge,"I have a few day old Nexus 7 tablet, unrooted, bootloader still locked, and otherwise in factory condition. This morning, it ran its charge out. When I plugged in it, this happens:


Google Logo appears.
Nexus Logo appears.
Lock screen which shows charging: 0%.
White screen, device powers off.
Repeat.


What is happening? Thanks!
",Eric,https://android.stackexchange.com/users/25632,"Some devices (I don't know about the Nexus 7, but I think it will be about the same) only charge when they have still a little charge left on their battery, because - believe it or not - charging happens electronically. So it can be that your device has absolutely no juice left to run. An example of such a device is the BlackBerry PlayBook (not Android) where this trick works when your tablet doesn't want to boot.

But there is a simple solution for that, which can take some time. Try to keep your device awake for as long as possible, even if that means you have to restart it a couple of times. Of course you do this while your charger is connected. After you have restarted it a couple of times, it should normally boot up. I expect it will take about 7 or 8 boots for the battery to be charged at minimum level again. After that, make sure you keep the device connected long enough so the battery is fully charged (have a look in your user manual how long it is recommended, most tablets need about 8 hours).

Another option is that your device just needs a little more juice to start. In that case you should leave it plugged in for some time (I recommend at least an hour) before booting.

tl;dr: Two options you could try: 1) Just keep restarting it, after a while it will start as normal. Recharge the battery for a long time (probably around 8 hours). 2) Leave it plugged in for a long time before restarting
",ndsmyter,https://android.stackexchange.com/users/25403,http://android.stackexchange.com/questions/36220/nexus-7-is-stuck-in-reboot-loop-after-full-discharge,TECHNOLOGY,android.stackexchange.com,1.0,0.7777777777777778,0.0,0.3333333333333333,1.0,1.0,0.8888888888888888,0.6666666666666666,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,1.0,0.0,1.0,1.0,0.7777777777777778,1.0,1.0,0.8666666666666666,1.0,0.3333333333333333,1.0,0.8888888888888888,Nexus7 stuck in restart cycle after full release,"I had a few days ago on the nexus 7 tablet, it didn't start, the boot loader was still locked, otherwise in factory conditions. This morning, it ran out of electricity. When I turn on the power, the following occurs:","Some devices (I don't know about the Nexus 7, but I think it will be about the same) only charge when they have still a little charge left on their battery, because - believe it or not - charging happens electronically. So it can be that your device has absolutely no juice left to run. An example of such a device is the BlackBerry PlayBook (not Android) where this trick works when your tablet doesn't want to boot.

But there is a simple solution for that, which can take some time. Try to keep your device awake for as long as possible, even if that means you have to restart it a couple of times. Of course you do this while your charger is connected. After you have restarted it a couple of times, it should normally boot up. I expect it will take about 7 or 8 boots for the battery to be charged at minimum level again. After that, make sure you keep the device connected long enough so the battery is fully charged (have a look in your user manual how long it is recommended, most tablets need about 8 hours).

Another option is that your device just needs a little more juice to start. In that case you should leave it plugged in for some time (I recommend at least an hour) before booting.

tl;dr: Two options you could try: 1) Just keep restarting it, after a while it will start as normal. Recharge the battery for a long time (probably around 8 hours). 2) Leave it plugged in for a long time before restarting
"
5025,5025,8001,What table tools/packages do you use?,"Making tables in LaTeX can be painful. All you need is a semi complex table with cells that have to span multiple rows/columns. What tools do you use to get around this complexity? Tabular? Tabularx? Are there others?
",levesque,https://tex.stackexchange.com/users/10,"External Tools



I find that a lot of the pain involved in creating LaTeX tables comes simply from laying them out- it's tough to make a table markup syntax that isn't tedious to type and modify.  Because of this, I use other programs to help me deal with some of the work involved in creating tables:


If my LaTeX editor has a table wizard, I use it to create the table.
If my data is in a spreadsheet, I use a plugin to export it to LaTeX.  For Excel, I use excel2latex and for OpenOffice I use calc2latex.
If my data is in R, I use the xtable package.


I find these tools take care of 80-95% of the work required to create a table- I then go through and refine some of the stylistic choices.  The only problem with this approach is that the tools aren't of much use if a table requires a substantial update or re-write or needs to be generated automatically from an arbitrary dataset.

LaTeX Packages



Personally, I use the Memoir class for the majority of my documents.  Memoir integrates the functionality of a ton of table packages such as booktabs and tabularx and integrates them in a sane way so your document doesn't end up with a list of \usepackage{}s that is a mile long.  See Chapter 11: Rows and Columns of the Memoir manual for a description of the support provided by the class for tabular material.

In addition to Memoir, I often augment it's capabilities with the following two packages:


The longtable package for laying out tables that flow across more than one page.  Longtable's handling of table headers and footers is extremely nice for putting things like ""Continued on the next page..."" exactly where they are supposed to be.
The siunitx package- this package is all about typesetting units and numbers.  The sinuitx package adds the S column descriptor which can be used to perform all kinds of advanced formatting for table columns that contain numbers such as:


Alignment of separators such as commas and decimal points.
Automatic rounding, truncation or conversion to scientific notation.


",Sharpie,https://tex.stackexchange.com/users/17,http://tex.stackexchange.com/questions/214/what-table-tools-packages-do-you-use,TECHNOLOGY,tex.stackexchange.com,1.0,0.5555555555555556,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.7777777777777778,1.0,0.7777777777777778,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,1.0,What table tools / bags do you use?,Making tables out of latex can be painful. You only need a semi complex table in which cells must span multiple rows / columns. What tools do you use to circumvent this complexity? Form? Form? Anything else?,"External Tools



I find that a lot of the pain involved in creating LaTeX tables comes simply from laying them out- it's tough to make a table markup syntax that isn't tedious to type and modify.  Because of this, I use other programs to help me deal with some of the work involved in creating tables:


If my LaTeX editor has a table wizard, I use it to create the table.
If my data is in a spreadsheet, I use a plugin to export it to LaTeX.  For Excel, I use excel2latex and for OpenOffice I use calc2latex.
If my data is in R, I use the xtable package.


I find these tools take care of 80-95% of the work required to create a table- I then go through and refine some of the stylistic choices.  The only problem with this approach is that the tools aren't of much use if a table requires a substantial update or re-write or needs to be generated automatically from an arbitrary dataset.

LaTeX Packages



Personally, I use the Memoir class for the majority of my documents.  Memoir integrates the functionality of a ton of table packages such as booktabs and tabularx and integrates them in a sane way so your document doesn't end up with a list of \usepackage{}s that is a mile long.  See Chapter 11: Rows and Columns of the Memoir manual for a description of the support provided by the class for tabular material.

In addition to Memoir, I often augment it's capabilities with the following two packages:


The longtable package for laying out tables that flow across more than one page.  Longtable's handling of table headers and footers is extremely nice for putting things like ""Continued on the next page..."" exactly where they are supposed to be.
The siunitx package- this package is all about typesetting units and numbers.  The sinuitx package adds the S column descriptor which can be used to perform all kinds of advanced formatting for table columns that contain numbers such as:


Alignment of separators such as commas and decimal points.
Automatic rounding, truncation or conversion to scientific notation.


"
3082,3082,4906,God the Father's possession of a body of flesh and bones,"There is a belief out there that God the Father has always possessed a body of flesh and bones. Some of the proponents of this belief don't find it contradictory to John 4:24 (""God is a Spirit"") as the verse may be referring only to one part of God without limiting God to being only that one part - just like, for example, in 1 Pet 3:20 (""eight souls were saved by water"") Peter called some humans ""souls"", but he didn't mean by that that they didn't posses bodies.

The example of Jesus after His resurrection, Who, while possessing a body of flesh and bones, still retains all the qualities that are usually ascribed only to God, for example, His omnipresence, could go along with this belief. 

I wonder if Biblical hermeneutics, namely the hermeneutics of the Old Testament, allows for this belief. If not, please, point out those places that speak against the validity of this belief.
",brilliant,https://christianity.stackexchange.com/users/234,"The OT is very clear that any static image or representation of the Divine is a very bad thing. The first two commandments are prohibitions of idolatry and the primary charge of the Prophets is against the same. To ascribe flesh and image to God would be heretical to the Jewish writers and authors of the books. As such, using a ""primary sense to the primary recipient"" hermeneutic would completely fail. Idolatry was so antithetical to the Jewish understanding would have made giving God any flesh or image heretical to unthinkable. 

That said (and I say this as a non-Mormon), the primary problem and setting in which Joseph Smith either wrote or was called in (depending on your belief), was not one in which idolatry was an issue. As such, it is difficult to apply a Jewish understanding to a Mormon prophet. Would a Jew think this silly? Sure. But then again, the idea that God would ever take on flesh even temporarily as the Messiah is equally repugnant, so as an argument there is not much to gain. 
",Affable Geek,https://christianity.stackexchange.com/users/1039,http://christianity.stackexchange.com/questions/13648/god-the-fathers-possession-of-a-body-of-flesh-and-bones,CULTURE,christianity.stackexchange.com,0.7777777777777778,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.4444444444444444,0.4444444444444444,0.6666666666666666,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,1.0,0.0,0.6666666666666666,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,1.0,0.3333333333333333,0.0,0.6666666666666666,1.0,God the Father's possession of a body of flesh and bones,"There is a belief out there that God the Father has always possessed a body of flesh and bones. Some of the proponents of this belief don't find it contradictory to John 4:24 (""God is a Spirit"") as the verse may be referring only to one part of God without limiting God to being only that one part - just like, for example, in 1 Pet 3:20 (""eight souls were saved by water"") Peter called some humans ""souls"", but he didn't mean by that that they didn't posses bodies.

The example of Jesus after His resurrection, Who, while possessing a body of flesh and bones, still retains all the qualities that are usually ascribed only to God, for example, His omnipresence, could go along with this belief. 

I wonder if Biblical hermeneutics, namely the hermeneutics of the Old Testament, allows for this belief. If not, please, point out those places that speak against the validity of this belief.
","The OT is very clear that any static image or representation of the Divine is a very bad thing. The first two commandments are prohibitions of idolatry and the primary charge of the Prophets is against the same. To ascribe flesh and image to God would be heretical to the Jewish writers and authors of the books. As such, using a ""primary sense to the primary recipient"" hermeneutic would completely fail. Idolatry was so antithetical to the Jewish understanding would have made giving God any flesh or image heretical to unthinkable. 

That said (and I say this as a non-Mormon), the primary problem and setting in which Joseph Smith either wrote or was called in (depending on your belief), was not one in which idolatry was an issue. As such, it is difficult to apply a Jewish understanding to a Mormon prophet. Would a Jew think this silly? Sure. But then again, the idea that God would ever take on flesh even temporarily as the Messiah is equally repugnant, so as an argument there is not much to gain. 
"
4059,4059,6477,"What does ""deal"" and ""take "" person mean?","E.g. when somebody say something like:

Person 1: ""Jeana can deal but not take.""

Person 2: ""Yes, she always was the deal but not take person.﻿""

Could somebody explain to me what ""deal"" and ""take"" person mean?
",Derfder,https://ell.stackexchange.com/users/1795,"In this example, it looks like deal and take are being used in the same way that dish out and take are used in the following example (from wiktionary's dish out entry):


  She can dish out criticism but she can't take it.


Just what it is that's being dealt or taken depends on context, but common examples include criticism, orders, and unsolicited advice.
",James Waldby - jwpat7,https://ell.stackexchange.com/users/146,http://ell.stackexchange.com/questions/14755/what-does-deal-and-take-person-mean,CULTURE,ell.stackexchange.com,0.7777777777777778,0.7777777777777778,0.0,1.0,1.0,1.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.6666666666666666,1.0,0.5555555555555556,1.0,1.0,0.8666666666666666,0.0,0.0,0.6666666666666666,0.8888888888888888,"What do you mean by ""deal"" and ""accept""?","E.g. when somebody say something like:

Person 1: ""Jeana can deal but not take.""

Person 2: ""Yes, she always was the deal but not take person.﻿""

Could somebody explain to me what ""deal"" and ""take"" person mean?
","In this example, it looks like deal and take are being used in the same way that dish out and take are used in the following example (from wiktionary's dish out entry):


  She can dish out criticism but she can't take it.


Just what it is that's being dealt or taken depends on context, but common examples include criticism, orders, and unsolicited advice.
"
831,831,1325,Are Mintakans related to Vulcans?,"In TNG ""Who Watches the Watchers"" we learn about the Mintakans, who are described as ""proto-Vulcan humanoids"".  Does this mean that the Mintakans come from a common ancestor to the Vulcans, or does it mean that the two species have evolved coincidentally to share many of the same features? (Or not so coincidentally if you take into account that genetic-seeding by the super ancient humanoids.)

We have been shown many species that look completely like humans, and even entire planets that mirror Earth (TOS ""Miri"") and maybe some of those species could be considered ""proto-human humanoids"".

I don't think it has been defined how long Vulcans have had space travel, or if it's even possible the Vulcans evolved from some other species that had space travel earlier, and the Mintakans are some off-shoot of that species.  This could possibly be justified from what Spock says in TOS ""Return to Tomorrow"" where he seems to suggest in response to Sargon and the astrobiology doctor that there are unexplained issues with Vulcans evolving on the planet Vulcan, that they might have been colonized by Sargon's people instead.

Interesting reading:
http://en.memory-alpha.org/wiki/Vulcan_history
",Sean Fahey,https://scifi.stackexchange.com/users/19629,"Probably not. The Vulcans have historically been very aware (if not forthcoming) about members of their gene pool and where they may be found. In this case, the term Proto-Vulcan humanoid implies the species has many of the same mental, physical and social traits originally seen exhibited by early pre-spaceflight Vulcans. 


This may include psychic ability such as telepathy, logical and disciplined minds, and a superior (to human) physiology. They may also share similar blood chemistry and the ability to be affected by similar diseases.
Since Rombulas (and Remans) WERE once Vulcans they have a direct descent line from the planet Vulcan in the distant past.
The Mintakins were not likely initially Vulcan and may have been descended from Sargon's species before they lost their original bodies. There were also said to have been Proto-Vulcan humanoids.
Other such proto-Vulcan humanoids include the Rigilans and the Halanan.

",Thaddeus Howze,https://scifi.stackexchange.com/users/2765,http://scifi.stackexchange.com/questions/44952/are-mintakans-related-to-vulcans,LIFE_ARTS,scifi.stackexchange.com,1.0,0.3333333333333333,0.0,0.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,1.0,Do the mintagans have anything to do with the Vulcan?,"In TNG ""Who Watches the Watchers"" we learn about the Mintakans, who are described as ""proto-Vulcan humanoids"".  Does this mean that the Mintakans come from a common ancestor to the Vulcans, or does it mean that the two species have evolved coincidentally to share many of the same features? (Or not so coincidentally if you take into account that genetic-seeding by the super ancient humanoids.)

We have been shown many species that look completely like humans, and even entire planets that mirror Earth (TOS ""Miri"") and maybe some of those species could be considered ""proto-human humanoids"".

I don't think it has been defined how long Vulcans have had space travel, or if it's even possible the Vulcans evolved from some other species that had space travel earlier, and the Mintakans are some off-shoot of that species.  This could possibly be justified from what Spock says in TOS ""Return to Tomorrow"" where he seems to suggest in response to Sargon and the astrobiology doctor that there are unexplained issues with Vulcans evolving on the planet Vulcan, that they might have been colonized by Sargon's people instead.

Interesting reading:
http://en.memory-alpha.org/wiki/Vulcan_history
","Probably not. The Vulcans have historically been very aware (if not forthcoming) about members of their gene pool and where they may be found. In this case, the term Proto-Vulcan humanoid implies the species has many of the same mental, physical and social traits originally seen exhibited by early pre-spaceflight Vulcans. 


This may include psychic ability such as telepathy, logical and disciplined minds, and a superior (to human) physiology. They may also share similar blood chemistry and the ability to be affected by similar diseases.
Since Rombulas (and Remans) WERE once Vulcans they have a direct descent line from the planet Vulcan in the distant past.
The Mintakins were not likely initially Vulcan and may have been descended from Sargon's species before they lost their original bodies. There were also said to have been Proto-Vulcan humanoids.
Other such proto-Vulcan humanoids include the Rigilans and the Halanan.

"
3052,3052,4862,"Without using dowels, how do I join 2x4s edge to edge to be 1.5"" x 7""?","I am trying to join a 2x4 supporting a workbench tabletop to another to make a backsplash of sorts. Any ideas how to do this without dowels? (No, I can't use 2x8)


",Jens Turner,https://diy.stackexchange.com/users/15656,"As you say you want to use screws and it's non-structural, I'd go with:

Get some 4"" wood screws, drill half way down through the upper piece with a drill slightly bigger than the screw heads, you shouldn't need to do pilot holes all the way through as 2"" really shouldn't split unless you use huge screws.

I'd go with 4 or 5 screws along the length.

Screw down through the top piece until you get a little bit of the tip poking out (say 1mm)

Align the top piece on the bottom piece, give it a knock to set the exposed tips into the lower piece, and screw down.

If you don't want exposed holes do it the other way up, if the lower piece is not already set in place.
",Digital Lightcraft,https://diy.stackexchange.com/users/15522,http://diy.stackexchange.com/questions/32868/without-using-dowels-how-do-i-join-2x4s-edge-to-edge-to-be-1-5-x-7,LIFE_ARTS,diy.stackexchange.com,1.0,1.0,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,0.8888888888888888,"How do I connect 2x4s edge to edge as 1.5 ""x 7"" without the use of dowels?","I'm trying to add a 2x4 support to one workbench desktop to another, to make one backward. Is there any way to do it without pins? (no, I can't use 2x8)","As you say you want to use screws and it's non-structural, I'd go with:

Get some 4"" wood screws, drill half way down through the upper piece with a drill slightly bigger than the screw heads, you shouldn't need to do pilot holes all the way through as 2"" really shouldn't split unless you use huge screws.

I'd go with 4 or 5 screws along the length.

Screw down through the top piece until you get a little bit of the tip poking out (say 1mm)

Align the top piece on the bottom piece, give it a knock to set the exposed tips into the lower piece, and screw down.

If you don't want exposed holes do it the other way up, if the lower piece is not already set in place.
"
2870,2870,4567,"Criteria is plural, of course, but","I know that criteria is plural, but I am trying to explain a situation in which possibly the set of criterion should be considered singular.

In this situation, the set of criterion, called Criteria B, is necessary for a specific determination to be made. The sentence in questions says, ""If Criteria B is negative, evaluators do not need to complete a comprehensive Criteria C.""

or should it be:

""If Criteria B are negative, evaluators do not need to complete comprehensive Criteria C"" 

I do not see this particular scenario addressed in other discussions of criteria/criterion. 
",Sarah M.,https://english.stackexchange.com/users/112342,"According to this article at grammarist, criteria is gaining traction as a singular noun, and appears in that role in notable publications.


  Although criterion lives, criteria is gaining ground as a singular
  noun, as used below:
  
  Careful though… this criteria is a double edged sword. [Schriever Air
  Force Base]
  
  The only criteria is that it must be partially or completely open to
  the public. [Houston Business Journal]
  
  Dark matter is another criteria that is examined. [Universe Today]


Based on this, I'd not deem If Criteria B is negative... to be incorrect. 

Purists would prefer If Criteria B are negative..., though, in my opinion. The Oxford dictionary still considers the singular usage a 'common mistake'. 


  Strictly speaking, the singular form (following the original Greek) is
  criterion and the plural form is criteria. It is a common mistake to
  use criteria as if it were a singular, as in a further criteria needs
  to be considered.


Which one you should use depends largely on the audience. I'd say go with the singular, which is more widely used and isn't outright wrong; unless you have reason to believe your audience is likely to frown upon the controversial usage of the singular. It's like deciding whether you'll end a sentence with a preposition or not.
",Tushar Raj,https://english.stackexchange.com/users/77339,http://english.stackexchange.com/questions/238406/criteria-is-plural-of-course-but,CULTURE,english.stackexchange.com,1.0,0.3333333333333333,0.0,1.0,1.0,1.0,0.4444444444444444,0.5555555555555556,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.3333333333333333,0.0,0.6666666666666666,0.0,0.7777777777777778,0.7777777777777778,0.8333333333333334,0.7777777777777778,1.0,0.7333333333333333,0.0,0.0,1.0,0.7777777777777778,"Of course, standards are diverse, but","I know that criteria is plural, but I am trying to explain a situation in which possibly the set of criterion should be considered singular.

In this situation, the set of criterion, called Criteria B, is necessary for a specific determination to be made. The sentence in questions says, ""If Criteria B is negative, evaluators do not need to complete a comprehensive Criteria C.""

or should it be:

""If Criteria B are negative, evaluators do not need to complete comprehensive Criteria C"" 

I do not see this particular scenario addressed in other discussions of criteria/criterion. 
","According to this article at grammarist, criteria is gaining traction as a singular noun, and appears in that role in notable publications.


  Although criterion lives, criteria is gaining ground as a singular
  noun, as used below:
  
  Careful though… this criteria is a double edged sword. [Schriever Air
  Force Base]
  
  The only criteria is that it must be partially or completely open to
  the public. [Houston Business Journal]
  
  Dark matter is another criteria that is examined. [Universe Today]


Based on this, I'd not deem If Criteria B is negative... to be incorrect. 

Purists would prefer If Criteria B are negative..., though, in my opinion. The Oxford dictionary still considers the singular usage a 'common mistake'. 


  Strictly speaking, the singular form (following the original Greek) is
  criterion and the plural form is criteria. It is a common mistake to
  use criteria as if it were a singular, as in a further criteria needs
  to be considered.


Which one you should use depends largely on the audience. I'd say go with the singular, which is more widely used and isn't outright wrong; unless you have reason to believe your audience is likely to frown upon the controversial usage of the singular. It's like deciding whether you'll end a sentence with a preposition or not.
"
2507,2507,3997,Is it safe to eat freshwater fish raw?,"According to this question freshwater fish should not be used in Ceviche--why not?
",Jay,https://cooking.stackexchange.com/users/2299,"In addition to hobodaves fine answer, freshwater fish usually contains a lot more mercury and other very unhelathy substances caused by human pollution. Some doctors recommend you to only eat freshwater fish twice a month.
",Lars Andren,https://cooking.stackexchange.com/users/1200,http://cooking.stackexchange.com/questions/7268/is-it-safe-to-eat-freshwater-fish-raw,LIFE_ARTS,cooking.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,0.3333333333333333,1.0,1.0,0.7777777777777778,0.7777777777777778,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,1.0,0.3333333333333333,1.0,1.0,0.6,0.0,0.0,1.0,0.7777777777777778,Is it safe to eat fresh water fish raw?,"According to this question, freshwater fish should not be used in the womb - why not?","In addition to hobodaves fine answer, freshwater fish usually contains a lot more mercury and other very unhelathy substances caused by human pollution. Some doctors recommend you to only eat freshwater fish twice a month.
"
1662,1662,2628,where to put .sty and .cls file for project,"I want to use my own .sty and .cls file in a project. I know of the following two possibilities of placing them:


in my local tex tree (or the general tex tree, which is worse)
in the same directory as the .tex file


Both of these I find unsatisfactory for the following reasons:

The local tex tree is unsatisfactory since the .sty file is specific for the project, so I want it to be close to the project, so I easily remember where it is etc. Also, I am using dropbox to synchronize the project files between different computers automatically, so the .sty file should be in the dropbox folder.

The 'same directory' is unsatisfactory since the project is in a directory with many subdirectories. The .tex files in all these subdirectories should be able to access the same .sty file.

What I would like to do is: create a subdirectory 'style files' in the project directory, where I put style and class files (there are several for the project), then tell tex somehow where to find them.

How can I do this?

I am using a recent TexLive on  Mac OS X.6

I know there have been questions about placement of .sty files, but I did not find an answer to this question.
",Daniel,https://tex.stackexchange.com/users/9171,"there is a third possibility and for projects the best one: put all in a texmf directory which is located inside your documents directory. Then do a export TEXMFHOME=texmf before running pdflatex or something else and the texmf tree will be searched first. 

Inside this local texmf you must have the same TeX Directory Structure as usual: http://tug.org/tds For a local texmf tree you do not need to run texhash because files are searched recursively in that tree
",Herbert,https://tex.stackexchange.com/users/2478,http://tex.stackexchange.com/questions/34203/where-to-put-sty-and-cls-file-for-project,TECHNOLOGY,tex.stackexchange.com,0.7777777777777778,0.5555555555555556,0.0,1.0,0.6666666666666666,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,0.8333333333333334,0.9,1.0,0.0,0.0,0.6666666666666666,Where to store. Sty and. CLS files for the project,"I want to use my own .sty and .cls file in a project. I know of the following two possibilities of placing them:


in my local tex tree (or the general tex tree, which is worse)
in the same directory as the .tex file


Both of these I find unsatisfactory for the following reasons:

The local tex tree is unsatisfactory since the .sty file is specific for the project, so I want it to be close to the project, so I easily remember where it is etc. Also, I am using dropbox to synchronize the project files between different computers automatically, so the .sty file should be in the dropbox folder.

The 'same directory' is unsatisfactory since the project is in a directory with many subdirectories. The .tex files in all these subdirectories should be able to access the same .sty file.

What I would like to do is: create a subdirectory 'style files' in the project directory, where I put style and class files (there are several for the project), then tell tex somehow where to find them.

How can I do this?

I am using a recent TexLive on  Mac OS X.6

I know there have been questions about placement of .sty files, but I did not find an answer to this question.
","there is a third possibility and for projects the best one: put all in a texmf directory which is located inside your documents directory. Then do a export TEXMFHOME=texmf before running pdflatex or something else and the texmf tree will be searched first. 

Inside this local texmf you must have the same TeX Directory Structure as usual: http://tug.org/tds For a local texmf tree you do not need to run texhash because files are searched recursively in that tree
"
6032,6032,9574,How to remember a trusted machine using two factor authentication (like Google's system),"We are developing a web application that will use two factor authentication. We are likely to try and emulate something similar to that used by google, where to login you enter a username and password, and then receive a token in an SMS message to be entered as well.

We would like to allow users to remember a client machine if they would like to so that they can login for 30 days without requiring the second authentication method. What information will we have access to (through headers of the web page requests etc.) which we can use to uniquely identify this trusted client machine? 

Obviously a user can have more than one trusted client machine, and I completely expect that if they use two different browsers on the same trusted machine machine, each browser will have to be trusted independently.

Setting a cookie on the machine with some GUID which means this is trusted simply would not be good enough, as someone else could just copy the cookie, and create it on their own browser circumventing the two factor authentication.
",Marryat,https://security.stackexchange.com/users/21071,"Don't think this can be done safely for an arbitrary client using only a standard web browser. As you say, cookies are not a safe choice to authorise a computer. Besides, cookies are set per browser, not per computer. You could try browser fingerprinting techniques, but again this is specific to the browser, not the computer. And keep in mind that HTTP requests, including User Agent strings, can be set arbitrarily by a malicious client.
",Gruber,https://security.stackexchange.com/users/20225,http://security.stackexchange.com/questions/31327/how-to-remember-a-trusted-machine-using-two-factor-authentication-like-googles,TECHNOLOGY,security.stackexchange.com,1.0,0.8888888888888888,0.0,0.6666666666666666,1.0,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.6666666666666666,0.0,1.0,0.0,0.0,0.0,0.0,0.3333333333333333,1.0,0.3333333333333333,0.0,0.0,1.0,0.8888888888888888,0.5555555555555556,1.0,1.0,0.7333333333333333,0.6666666666666666,0.3333333333333333,1.0,1.0,How to use two factor authentication to remember trusted machines (such as Google's system),"We are developing a web application that will use two factor authentication. We are likely to try and emulate something similar to that used by google, where to login you enter a username and password, and then receive a token in an SMS message to be entered as well.

We would like to allow users to remember a client machine if they would like to so that they can login for 30 days without requiring the second authentication method. What information will we have access to (through headers of the web page requests etc.) which we can use to uniquely identify this trusted client machine? 

Obviously a user can have more than one trusted client machine, and I completely expect that if they use two different browsers on the same trusted machine machine, each browser will have to be trusted independently.

Setting a cookie on the machine with some GUID which means this is trusted simply would not be good enough, as someone else could just copy the cookie, and create it on their own browser circumventing the two factor authentication.
","Don't think it's safe to use only one standard web browser for an arbitrary client. As you said, cookies are not a safe option for authorized computers. In addition, cookies are set by browser, not by computer. You can try browser fingerprint technology, but it's also browser specific, not computer specific. Keep in mind that malicious clients can set up HTTP requests at will, including user agent strings."
175,175,273,"What is a *slightly* less extreme equivalent to being ""fluent"" in a language?","tl;dr: What is a less extreme (but still noticeable) alternative to the word ""fluent"", when saying e.g. ""I am fluent in C++/Python/whatever?""



I think I can call myself ""fluent"" in C#, because I know the language and runtime very well, and I'm very familiar with the .NET framework's APIs and classes, etc.

I would like to claim the same thing for Python and C++.
But while I can program in Python (I did so for an entire summer, making a website with Django), for example, I would not call myself fluent because my code isn't always ""Pythonic"" (e.g. using map/filter vs. list comprehensions), and I'm not too intimate with some aspects of the language and standard library yet (e.g. the introspection API, etc.).

Is there a word or phrase I can use on e.g. a resume to describe what I know?

I can think of ""very familiar with"", but is there a better word/phrase I can use?
",Mehrdad,https://programmers.stackexchange.com/users/11833,"If you are referring to a natural spoken language, one step down from fluent would be ""conversant"", such as ""Fluent in French, conversant in Spanish.""

For programming languages, I usually write something like: ""Very experienced in C and C++, familiar with Python and C#"". But I agree with Irwin that ""proficient"" seems to be one step below ""fluent"", so maybe it goes: fluent --> proficient --> familiar.
",stackoverflowuser2010,https://programmers.stackexchange.com/users/8402,http://programmers.stackexchange.com/questions/106004/what-is-a-slightly-less-extreme-equivalent-to-being-fluent-in-a-language,TECHNOLOGY,programmers.stackexchange.com,1.0,0.8888888888888888,0.0,1.0,1.0,0.3333333333333333,0.5555555555555556,0.6666666666666666,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,0.8888888888888888,0.7777777777777778,1.0,1.0,0.9333333333333332,0.0,0.0,0.3333333333333333,1.0,"What is a *slightly* less extreme equivalent to being ""fluent"" in a language?","tl;dr: What is a less extreme (but still noticeable) alternative to the word ""fluent"", when saying e.g. ""I am fluent in C++/Python/whatever?""



I think I can call myself ""fluent"" in C#, because I know the language and runtime very well, and I'm very familiar with the .NET framework's APIs and classes, etc.

I would like to claim the same thing for Python and C++.
But while I can program in Python (I did so for an entire summer, making a website with Django), for example, I would not call myself fluent because my code isn't always ""Pythonic"" (e.g. using map/filter vs. list comprehensions), and I'm not too intimate with some aspects of the language and standard library yet (e.g. the introspection API, etc.).

Is there a word or phrase I can use on e.g. a resume to describe what I know?

I can think of ""very familiar with"", but is there a better word/phrase I can use?
","If you are referring to a natural spoken language, one step down from fluent would be ""conversant"", such as ""Fluent in French, conversant in Spanish.""

For programming languages, I usually write something like: ""Very experienced in C and C++, familiar with Python and C#"". But I agree with Irwin that ""proficient"" seems to be one step below ""fluent"", so maybe it goes: fluent --> proficient --> familiar.
"
1464,1464,2307,How to quick select all rows in iOS5 UITableView,"With iOS-5 UITableView allowsmultipleselection, is there any quick way with good performance to select (and highlighted) all rows? I'm talking about more than thousands rows data of fetchedResultsController. 

I've tried with selectRowAtIndexPath:animated loop, and seems it's not a good idea for huge dataset.

Also I've discovered if deselect all rows performance will be better with tableview reloadData than deselectRowAtIndexPath:animated: inside a loop. Is this the safe way to clear selections?

Thanks
",deden,https://stackoverflow.com/users/346758,"As I know, you haven't any other posibility to select rows, only selectRowAtIndexPath:.

And I think, you shouldn't have so many rows in table view, try to optimize it. Do you really need so many rows?
",Roman Truba,https://stackoverflow.com/users/1271424,http://stackoverflow.com/questions/9731199/how-to-quick-select-all-rows-in-ios5-uitableview,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.6666666666666666,0.0,1.0,1.0,1.0,0.5555555555555556,0.3333333333333333,0.6666666666666666,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.6666666666666666,0.7777777777777778,0.4666666666666667,0.0,0.0,0.3333333333333333,0.6666666666666666,How to quickly select all rows in ios5 uitableview,"With iOS-5 UITableView allowsmultipleselection, is there any quick way with good performance to select (and highlighted) all rows? I'm talking about more than thousands rows data of fetchedResultsController. 

I've tried with selectRowAtIndexPath:animated loop, and seems it's not a good idea for huge dataset.

Also I've discovered if deselect all rows performance will be better with tableview reloadData than deselectRowAtIndexPath:animated: inside a loop. Is this the safe way to clear selections?

Thanks
","As I know, you haven't any other posibility to select rows, only selectRowAtIndexPath:.

And I think, you shouldn't have so many rows in table view, try to optimize it. Do you really need so many rows?
"
2069,2069,3298,IE9 RC crashes on my Windows 7 laptop?,"I was using IE9 beta till now and installed IE9 RC today. However it starts crashing on 50% of the sites I visit. This also includes www.youtube.com. 

I did not uninstall IE9 beta before installing IE9 RC. Could this be the reason?

EDIT: I have uninstalled IE9 RC and installed it again after restart but that has not fixed this issue. 
",Amitabh,https://superuser.com/users/33132,"Does this occur on pages with flash or any other plugins?
Have you tried checking memory in your computer?  

I can't really have any other idea. Other apps misbehave too? (To be honest I don't really have an idea why would you want to use IE9RC if the other apps work like a charm. Like.. it only have GPU accel.. like Chrome and Firefox's latest beta. Nothing new, nothing special.)
",Shiki,https://superuser.com/users/16001,http://superuser.com/questions/245001,TECHNOLOGY,superuser.com,0.8888888888888888,0.3333333333333333,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,1.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.3333333333333333,0.0,0.4444444444444444,0.8888888888888888,0.5555555555555556,1.0,1.0,0.6666666666666667,0.6666666666666666,0.0,0.0,1.0,IE9 RC crashes on my windows 7 laptop?,"I was using IE9 beta till now and installed IE9 RC today. However it starts crashing on 50% of the sites I visit. This also includes www.youtube.com. 

I did not uninstall IE9 beta before installing IE9 RC. Could this be the reason?

EDIT: I have uninstalled IE9 RC and installed it again after restart but that has not fixed this issue. 
","Does this occur on pages with flash or any other plugins?
Have you tried checking memory in your computer?  

I can't really have any other idea. Other apps misbehave too? (To be honest I don't really have an idea why would you want to use IE9RC if the other apps work like a charm. Like.. it only have GPU accel.. like Chrome and Firefox's latest beta. Nothing new, nothing special.)
"
5125,5125,8151,Difference between busses,"I think I am confusing the difference between some of the of busses, such as IDE, SATA, USB, and PCI.  What is the relationship between all four, how are they connected to each other? From what I read it seems like PCI connects them together as well as to the CPU, but it's not clear.  Any help would be greatly appreciated. I am cross referencing this post with another I made about the Linux commands to browse them.  http://unix.stackexchange.com/questions/27414/ide-and-pci-bus-commands
",rubixibuc,https://electronics.stackexchange.com/users/7163,"This smells like a homework assignment.  In any case, it should be easy to look up some introduction to each of these busses and then compare them.  However, briefly:

IDE is a parallel bus used primarily inside computers to communicate with disk drives.  It is carried on ribbon cables 2-3 inches wide.

SATA is the replacement for IDE.  It is high speed serial, so uses a lot fewer wires.

PCI is the bus you physically plug I/O cards into in a PC.  These are the cards with the tall thin metal faces that provide connections out the back via the ""I/O slots"".  For example, you can get add on ethernet ""cards"" if you want your PC to have more than the one network connetion the comes on the motherboard.

USB is for external devices.  Surely you've heard of this unless you've been living under a rock for the last 20 years.



As for compare and contrast, this is your homework assignment, not mine.
",Olin Lathrop,https://electronics.stackexchange.com/users/4512,http://electronics.stackexchange.com/questions/24077/difference-between-busses,SCIENCE,electronics.stackexchange.com,0.7777777777777778,0.4444444444444444,0.0,1.0,1.0,1.0,0.6666666666666666,0.4444444444444444,0.3333333333333333,0.0,0.0,0.0,0.6666666666666666,0.0,0.3333333333333333,0.0,0.0,0.0,1.0,0.0,0.4444444444444444,1.0,0.5555555555555556,1.0,1.0,0.8666666666666666,0.0,0.0,0.6666666666666666,0.8888888888888888,The difference between buses,"I think I've confused some bus differences, such as IDE, SATA, USB and PCI. What is the relationship between the four and how are they related to each other? From what I read, PCI connects them together and connects them to the CPU, but it's not clear. Any help will be appreciated. I'm cross referencing this article and another about Linux commands to browse through them. http://unix.stackexchange.com/questions/27414/ide-and-pci-bus-commands","This smells like a homework assignment.  In any case, it should be easy to look up some introduction to each of these busses and then compare them.  However, briefly:

IDE is a parallel bus used primarily inside computers to communicate with disk drives.  It is carried on ribbon cables 2-3 inches wide.

SATA is the replacement for IDE.  It is high speed serial, so uses a lot fewer wires.

PCI is the bus you physically plug I/O cards into in a PC.  These are the cards with the tall thin metal faces that provide connections out the back via the ""I/O slots"".  For example, you can get add on ethernet ""cards"" if you want your PC to have more than the one network connetion the comes on the motherboard.

USB is for external devices.  Surely you've heard of this unless you've been living under a rock for the last 20 years.



As for compare and contrast, this is your homework assignment, not mine.
"
1449,1449,2283,Why are the ringwraiths fearful of coming in contact with water?,"At least twice in LoTR:FotR, ringwraiths cower away from bodies of water. The second time (the ford of Bruinen) can be explained away by their fear of some Elvish magical trap through the enchantment of the water; but what about the first time, at the ferry? One of the Nazgul could have easily made the jump onto the barge and quickly dispatched those pesky Hobitsses.
",einpoklum,https://scifi.stackexchange.com/users/16835,"It is very plausible that it is a holdover of the power of Ulmo. See this forum thread for more...

http://forum.barrowdowns.com/archive/index.php?t-201.html
",StarSpawnedOne,https://scifi.stackexchange.com/users/21941,http://scifi.stackexchange.com/questions/48656/why-are-the-ringwraiths-fearful-of-coming-into-contact-with-water,LIFE_ARTS,scifi.stackexchange.com,1.0,1.0,0.0,1.0,1.0,1.0,0.6666666666666666,0.5555555555555556,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.5555555555555556,1.0,0.8888888888888888,0.7333333333333333,0.0,0.0,1.0,1.0,Why is the ring ghost afraid of contact with water?,"At least two times in Lotte: Ford, the soul flinches out of the water. The second time (Ford of brunin) can be explained by their fear of some magical traps of elves through the magic of water; but the first time, on the ferry? One of the nazgules jumped on the barge easily, and soon drove away the nasty hobbits.","It is very plausible that it is a holdover of the power of Ulmo. See this forum thread for more...

http://forum.barrowdowns.com/archive/index.php?t-201.html
"
4506,4506,7142,regex to match xml tags not containing other tags,"Let's say I want to look for XML like this:

&lt;Address&gt;
    &lt;Street&gt;Windsor&lt;/Street&gt;
&lt;/Address&gt;


and I do not want to match XML like this:

&lt;Address&gt;
    &lt;Number&gt;15&lt;/Number&gt;
    &lt;Street&gt;Windsor&lt;/Street&gt;
&lt;/Address&gt;


That is, I am looking for addresses where the Address node does not contain a Number tag.

I tried patterns like 

&lt;Address&gt;(?!Number)&lt;/Address&gt;


or 

&lt;Address&gt;.*?(?!Number).*?&lt;/Address&gt;


But I can't quite figure it out :-(

Any ideas?
",user1547254,https://stackoverflow.com/users/1547254,"&lt;Address&gt;(?:(?!&lt;Address&gt;)(?!&lt;Number&gt;).)*&lt;/Address&gt;


Warning: that assumes that you either have no newlines in your text, or that . can cross newline boundaries, the so-call /s or DOTALL mode, which (?s) will enable in some regex languages.
",tchrist,https://stackoverflow.com/users/471272,http://stackoverflow.com/questions/12152393/regex-to-match-xml-tags-not-containing-other-tags,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.5555555555555556,0.0,1.0,1.0,1.0,0.5555555555555556,0.5555555555555556,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.9,1.0,0.3333333333333333,0.0,0.8888888888888888,Regular expressions that match XML tags that do not contain other tags,"Let's say I want to look for XML like this:

&lt;Address&gt;
    &lt;Street&gt;Windsor&lt;/Street&gt;
&lt;/Address&gt;


and I do not want to match XML like this:

&lt;Address&gt;
    &lt;Number&gt;15&lt;/Number&gt;
    &lt;Street&gt;Windsor&lt;/Street&gt;
&lt;/Address&gt;


That is, I am looking for addresses where the Address node does not contain a Number tag.

I tried patterns like 

&lt;Address&gt;(?!Number)&lt;/Address&gt;


or 

&lt;Address&gt;.*?(?!Number).*?&lt;/Address&gt;


But I can't quite figure it out :-(

Any ideas?
","&lt;Address&gt;(?:(?!&lt;Address&gt;)(?!&lt;Number&gt;).)*&lt;/Address&gt;


Warning: that assumes that you either have no newlines in your text, or that . can cross newline boundaries, the so-call /s or DOTALL mode, which (?s) will enable in some regex languages.
"
4416,4416,7015,What technique/sensor can I use to recognized tagged objects thrown onto a surface?,"I am trying to implement a concept for somebody else. 

Basically, I want to create a smart surface. I want to create a surface I can throw one or more tagged objects on that should all be recognized. 

I am unsure how to this and what sensors I should use. I have been thinking about using one of the NFC ICs from NXP. However, designing a circuit board and buying this IC is too expensive for our idea. I'm also unsure of whether the surface area will cause problems, because it'll be quite large (think of a small coffee table). 

I've also been thinking about other ways to recognize objects, but I have not come up with anything yet. I am probably not using the correct term. 

Does anyone know of a type or sensor or technique to implement this? 

Note: I am a computer engineer, not an electrical engineer. I know the basics, but really not much more than that, so I prefer a solution that is available as a simple IC or a complete circuit board with the really complicated things done for me by the experts :) 
",Pascal Muller,https://electronics.stackexchange.com/users/16149,"Look for RFID tags, and RFID sensors.

This RFID reader from SparkFun has a built-in antenna and a range of 200 mm and works with inexpensive 125 KHz RFID tags. Also, SparkFun has this USB RFID adapter to connect to a reader such as above, and provide USB data read off the tags directly to your computer or other device.

If you need to span a large area such as a coffee table, your options are: RFID reader with external antenna port, or a number of integrated antenna RFID readers arranged around the periphery of the surface

The mechanism used in some department stores, for instance, has their items tagged with RFID tags, and RFID antenna loops 3-5 feet tall and about a foot wide, on either side of the exit doors. The range is a few feet, which should serve the purpose. In your case, such an antenna would be a suitable loop of wire around the periphery of the surface.

Note that this mechanism will not allow your system to distinguish between tagged objects actually dropped on the surface as opposed to held above it. If the ""dropped on"" parameter is crucial, then multiple smaller-range RFID readers would serve you better - or a metal contact surface that works as your antenna, designed for a very small read range.
",Anindo Ghosh,https://electronics.stackexchange.com/users/14004,http://electronics.stackexchange.com/questions/49015/what-technique-sensor-can-i-use-to-recognized-tagged-objects-thrown-onto-a-surfa,SCIENCE,electronics.stackexchange.com,0.8888888888888888,0.6666666666666666,0.0,1.0,0.6666666666666666,1.0,0.5555555555555556,0.5555555555555556,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,1.0,What technology / sensor can I use to identify the marked object thrown on the surface?,"I am trying to implement a concept for somebody else. 

Basically, I want to create a smart surface. I want to create a surface I can throw one or more tagged objects on that should all be recognized. 

I am unsure how to this and what sensors I should use. I have been thinking about using one of the NFC ICs from NXP. However, designing a circuit board and buying this IC is too expensive for our idea. I'm also unsure of whether the surface area will cause problems, because it'll be quite large (think of a small coffee table). 

I've also been thinking about other ways to recognize objects, but I have not come up with anything yet. I am probably not using the correct term. 

Does anyone know of a type or sensor or technique to implement this? 

Note: I am a computer engineer, not an electrical engineer. I know the basics, but really not much more than that, so I prefer a solution that is available as a simple IC or a complete circuit board with the really complicated things done for me by the experts :) 
","Look for RFID tags, and RFID sensors.

This RFID reader from SparkFun has a built-in antenna and a range of 200 mm and works with inexpensive 125 KHz RFID tags. Also, SparkFun has this USB RFID adapter to connect to a reader such as above, and provide USB data read off the tags directly to your computer or other device.

If you need to span a large area such as a coffee table, your options are: RFID reader with external antenna port, or a number of integrated antenna RFID readers arranged around the periphery of the surface

The mechanism used in some department stores, for instance, has their items tagged with RFID tags, and RFID antenna loops 3-5 feet tall and about a foot wide, on either side of the exit doors. The range is a few feet, which should serve the purpose. In your case, such an antenna would be a suitable loop of wire around the periphery of the surface.

Note that this mechanism will not allow your system to distinguish between tagged objects actually dropped on the surface as opposed to held above it. If the ""dropped on"" parameter is crucial, then multiple smaller-range RFID readers would serve you better - or a metal contact surface that works as your antenna, designed for a very small read range.
"
2604,2604,4143,How can I write HTML and send as an email?,"I want to send HTML email from my Outlook or Yahoo, Gmail, Hotmail. I wasn't able to find any such option where I could write HTML which will then be rendered at the receiver's end. How can I do that?
",Umair Jabbar,https://webapps.stackexchange.com/users/2676,"If you want to send HTML emails, you need to use a tool that let you write the content of the email yourself instead of relying on WYSIWYG editors.
The most part of mail clients doesn't allow this feature, mainly for security reasons.

With web email clients, such as Gmail, Yahoo or Hotmail, you can try to use the WebKit Inspector (in Safari and Chrome) or Firebug to edit the content of the email directly in the DOM, bypassing the interface restrictions. However, your code is likely to be sanitized by the application and it won't work as expected.

The best solution is to send the emails using a programming language (e.g. mail() in PHP or Pony in Ruby), or a mail service designed to handle HTML content such as MadMimi, Mailchimp, Campaign Monitor...
",Simone Carletti,https://webapps.stackexchange.com/users/1632,http://webapps.stackexchange.com/questions/7932/how-can-i-write-html-and-send-as-an-email,TECHNOLOGY,webapps.stackexchange.com,1.0,1.0,0.0,0.0,1.0,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.6666666666666666,0.6666666666666666,0.3333333333333333,1.0,How do I write HTML and send it as an email?,"I want to send HTML messages from my outlook or Yahoo, Gmail, hotmail. I can't find any of these options, I can write HTML and then render it at the end of the receiver. What shall I do?","If you want to send HTML emails, you need to use a tool that let you write the content of the email yourself instead of relying on WYSIWYG editors.
The most part of mail clients doesn't allow this feature, mainly for security reasons.

With web email clients, such as Gmail, Yahoo or Hotmail, you can try to use the WebKit Inspector (in Safari and Chrome) or Firebug to edit the content of the email directly in the DOM, bypassing the interface restrictions. However, your code is likely to be sanitized by the application and it won't work as expected.

The best solution is to send the emails using a programming language (e.g. mail() in PHP or Pony in Ruby), or a mail service designed to handle HTML content such as MadMimi, Mailchimp, Campaign Monitor...
"
3093,3093,4924,Is it appropriate to follow up on a faculty application?,"I am currently applying to faculty positions, primarily teaching positions at 4 year colleges and universities. I am told many of these jobs have more than 100-200 applicants. Some of the jobs ads themselves say they get hundreds of applicants, and go on to say something to the effect 'you probably aren't going to hear anything from us', which says to me - 'don't bother us'. I have 3 questions, which overlap:


If I don't hear back from them at all, is it appropriate to contact the department?
If I hear back that they got my application and materials, is it appropriate to contact the department?
People that I know from the business world encourage me to be more aggressive by calling the departments to check in, and even asking if I can come visit the department. I am concerned that this sort of attitude can have a backlash effect. Is this sort of aggressive approach accepted in academia?

",DJBunk,https://academia.stackexchange.com/users/4269,"It is certainly appropriate to ask whether they got your application. It is also appropriate to enquire about how the process is progressing. I would avoid being too pushy about it, as this will not influence anyone, at least not in a positive sense. And sometimes these application processes take an extremely long time.

It may be appropriate to visit the department to give a presentation, as this is one thing academics do anyway, even when they are not applying for positions. Give a good presentation and this might help your application – though it could be the case that the people judging the application are completely disjoint from the people in the audience.
",Dave Clarke,https://academia.stackexchange.com/users/643,http://academia.stackexchange.com/questions/7955/is-it-appropriate-to-follow-up-on-a-faculty-application,LIFE_ARTS,academia.stackexchange.com,1.0,0.5555555555555556,0.0,0.0,0.6666666666666666,0.0,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,0.3333333333333333,0.8888888888888888,Is it appropriate to follow up the teacher application?,"I am currently applying to faculty positions, primarily teaching positions at 4 year colleges and universities. I am told many of these jobs have more than 100-200 applicants. Some of the jobs ads themselves say they get hundreds of applicants, and go on to say something to the effect 'you probably aren't going to hear anything from us', which says to me - 'don't bother us'. I have 3 questions, which overlap:


If I don't hear back from them at all, is it appropriate to contact the department?
If I hear back that they got my application and materials, is it appropriate to contact the department?
People that I know from the business world encourage me to be more aggressive by calling the departments to check in, and even asking if I can come visit the department. I am concerned that this sort of attitude can have a backlash effect. Is this sort of aggressive approach accepted in academia?

","It is certainly appropriate to ask whether they got your application. It is also appropriate to enquire about how the process is progressing. I would avoid being too pushy about it, as this will not influence anyone, at least not in a positive sense. And sometimes these application processes take an extremely long time.

It may be appropriate to visit the department to give a presentation, as this is one thing academics do anyway, even when they are not applying for positions. Give a good presentation and this might help your application – though it could be the case that the people judging the application are completely disjoint from the people in the audience.
"
240,240,385,Why do I have to explicitly add perl before the script for getops to run properly?,"When i run my script like so: 

C:\>perl script.pl -f file

It works fine. But, if I just do:

C:\>script.pl -f file

then I don't get any errors but getopts doesn't assign anything to $opt_f

This works just fine on perl 5.8 Windows XP, but it doesn't work on perl 5.12 on Windows 7.
There aren't any other versions of perl installed (its a new OS build).

Code:

use Getopt::Std;
our ($opt_f);
getopts('f:');
print ""input file is: $opt_f \n"";
print ""$0\n


Run with:

C:\&gt; perl get.pl -f sadf
input file is: sadf
get.pl


Run without:

C:\&gt;get.pl -f sadf
input file is:


Nothing!

EDIT:  fixed and this question was a repeat...
http://stackoverflow.com/questions/1695188/how-do-i-make-perl-scripts-recognize-parameters-in-the-win32-cmd-console

The OP of that post figured it out.
I had to do the same but also recreate the assoc in the gui (in addition to in the reg and on the command line with ftype.)  
",Alex,https://stackoverflow.com/users/8676,"When you invoke your code as perl script.pl -f file, you are explicitly running the perl executable and passing it a filename and options to parse.  But when you invoke it as script.pl -f file, you are asking your login shell to run the file, which it will parse as a shell script in the absence of any other information -- this is not what you want, as your file is not a bash script, but a perl script!

Normally such information (what program to use to parse the script) is given in what is called a shebang line. If you add this to the top of your script, it should run properly:

#!/usr/bin/perl


(or perhaps #!/bin/env perl, if you want the env program to find perl in your $PATH for you).
",Ether,https://stackoverflow.com/users/40468,http://stackoverflow.com/questions/4065054/why-do-i-have-to-explicitly-add-perl-before-the-script-for-getops-to-run-properl,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.6666666666666666,0.0,1.0,0.6666666666666666,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.3333333333333333,0.0,0.6666666666666666,0.8888888888888888,Why add Perl explicitly before the getops script runs properly?,"When i run my script like so: 

C:\>perl script.pl -f file

It works fine. But, if I just do:

C:\>script.pl -f file

then I don't get any errors but getopts doesn't assign anything to $opt_f

This works just fine on perl 5.8 Windows XP, but it doesn't work on perl 5.12 on Windows 7.
There aren't any other versions of perl installed (its a new OS build).

Code:

use Getopt::Std;
our ($opt_f);
getopts('f:');
print ""input file is: $opt_f \n"";
print ""$0\n


Run with:

C:\&gt; perl get.pl -f sadf
input file is: sadf
get.pl


Run without:

C:\&gt;get.pl -f sadf
input file is:


Nothing!

EDIT:  fixed and this question was a repeat...
http://stackoverflow.com/questions/1695188/how-do-i-make-perl-scripts-recognize-parameters-in-the-win32-cmd-console

The OP of that post figured it out.
I had to do the same but also recreate the assoc in the gui (in addition to in the reg and on the command line with ftype.)  
","When you call the code in the form of a Perl script. Pl-f file, you explicitly run the Perl executable and pass it the filename and options to parse. But when you call it as a script.pl-f file, you ask the login shell to run the file, which will parse into a shell script without any other information - this is not what you want, because your file is not a bash script, but a Perl script!"
391,391,613,Apartment in Munich,"I'm a married man looking for an apartment to live with my wife from February 2014 until April 2014.  How can I find an apartment for this time period?
",user10034,https://travel.stackexchange.com/users/10034,"If you don't speak German, Airbnb is your best bet. For the period you mention, they feature some 150 entire apartments that are suitable for 2 persons.
",Maître Peseur,https://travel.stackexchange.com/users/11860,http://travel.stackexchange.com/questions/23451/apartment-in-munich,CULTURE,travel.stackexchange.com,1.0,0.3333333333333333,0.0,0.5,1.0,0.5,0.5555555555555556,0.5555555555555556,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,1.0,0.0,0.0,0.5555555555555556,1.0,0.5555555555555556,1.0,1.0,0.9333333333333332,0.3333333333333333,0.6666666666666666,0.0,0.8888888888888888,Munich apartment,"I am a married man. From February 2014 to April 2014, I want to find an apartment to live with my wife. How can I find an apartment in this period of time?","If you don't speak German, airbnb is your best choice. During the period you mentioned, they have about 150 complete apartments for two people."
2046,2046,3260,Is there added value in having your own presentation layout and using it consistently?,"From the perspective of a Ph.D. student, how much of an added value is it to have your own presentation slides layout, that is used consistently throughout your Ph.D. conference presentations and other talks (and possibly throughout your academic career afterwards)?

Here is one such example from the Computer Science community.

This as as opposed to using existing Beamer templates with LaTeX, or built-in PowerPoint templates, or simply preparing each presentation on its own (without a specific layout).

A couple of axes I can think along:


Creating a signature layout that distinguishes one in their community
Ease of preparation of presentations (especially over time), maybe overcoming constraints with existing templates.


Note that I am not concerned with the question of content, but just design and layout.
",lyes,https://academia.stackexchange.com/users/15902,"Yes. If you're like me you'll never like everything about a standard layout, and you want your tools to disappear as quickly as possible when creating content.
Noticing something in your slides that you want to change (bullet type, or title colour, or whatever) is the easiest way to get distracted from doing so.

Having a standard layout for your own work means you have to spend the least amount of time worrying about the formatting.
",Will Robertson,https://academia.stackexchange.com/users/7754,http://academia.stackexchange.com/questions/25822/is-there-added-value-in-having-your-own-presentation-layout-and-using-it-consist,LIFE_ARTS,academia.stackexchange.com,0.8888888888888888,0.8888888888888888,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,0.6666666666666666,1.0,Is there added value in having your own presentation layout and using it consistently?,"From the perspective of a Ph.D. student, how much of an added value is it to have your own presentation slides layout, that is used consistently throughout your Ph.D. conference presentations and other talks (and possibly throughout your academic career afterwards)?

Here is one such example from the Computer Science community.

This as as opposed to using existing Beamer templates with LaTeX, or built-in PowerPoint templates, or simply preparing each presentation on its own (without a specific layout).

A couple of axes I can think along:


Creating a signature layout that distinguishes one in their community
Ease of preparation of presentations (especially over time), maybe overcoming constraints with existing templates.


Note that I am not concerned with the question of content, but just design and layout.
","Yes. If you're like me you'll never like everything about a standard layout, and you want your tools to disappear as quickly as possible when creating content.
Noticing something in your slides that you want to change (bullet type, or title colour, or whatever) is the easiest way to get distracted from doing so.

Having a standard layout for your own work means you have to spend the least amount of time worrying about the formatting.
"
797,797,1264,How can an Imperator Titan house a city on its shoulders when it's only 100 meters tall?,"I've often been confused at the size of Warhammer 40k titans. I've been reading one of the Horus Heresy books and it describes an Imperator class titan as having a small city on its shoulders with command stations, barracks, etc. At 100 meters tall, this is only 7 meters taller than the Statue of Liberty. I've been up the Statue of Liberty, and it definitely couldn't host a small city. I get that they're wider but still it seems that it's a bit of a stretch of imagination to suppose that it could host such a large structure.
",Neil Hanvey,https://scifi.stackexchange.com/users/36763,"This is partially a style issue. This is a partially medium translation issue. How the Imperator Titans look in the games and how they look in the minds of artists are completely different. There are no cities on the tops of these Imperator Titans. There is often a command center where the battle can be seen and managed since they supposed to tower over the battlefield stylistically and figuratively.




This is the Imperator Class Titan figure. Most of the time there is nothing around it, so you don't know how big it is in proportion to anything else. Different sculptures emphasize different things. Some are more ornate than others and have better detail. These are some of the early designs.





The titan is often shown not alongside anything that gives it scale. The structure on the top of the shoulders of the central body has three (possibly four) guns mounted on the very top for ranged mortar fire. Some of the early paintings depicted them like this. Again, nothing really to scale it against so it can look so large…
Some artists when they cast the Imperator Titan, in the right light, with billowing smoke wafting up from the craters below, it can seem monstrously large. Just the way the God Emperor's avatar, the Imperium's most terrifying war machine should look.





But if you are from one of those Forge worlds and stylish lighting isn't going to cut it, you can compare the size of the Imperator and realize it isn't a small city of there, nor a castle, instead it is just four very large cannons mounted there. There is also a heavily shielded command center with room enough for a good deal of staff. Maybe a latte bar. A matter of style over substance. 





Here how the figures compare to the field of battle at scale. The second image shows the Imperator against the other titans at scale. Look at the teeny-tiny space marine at his feet. Remember that guy is supposed to be this guy... 





Now can you see why Imperators are supposed to be terrifying and people might be prone to exaggerate what they remember seeing? Shellshock, hysteria. This is the impression the Imperium wants to leave you with.


See Also: What makes titans so valuable in the Warhammer 40K universe?
",Thaddeus Howze,https://scifi.stackexchange.com/users/2765,http://scifi.stackexchange.com/questions/73913/how-can-an-imperator-titan-house-a-city-on-its-shoulders-when-its-only-100-mete,LIFE_ARTS,scifi.stackexchange.com,0.6666666666666666,1.0,0.0,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.8333333333333334,1.0,1.0,1.0,1.0,1.0,0.0,0.0,1.0,1.0,"When a city is only 100 meters high, how can an emperor Titan carry it on his shoulder?","I'm often confused about the size of the 40, 000 Titan hammer. I have been reading a Horus heresy book, which describes an empire level Titan with a small city carrying a command post, barracks, etc., 100 meters high, only 7 meters higher than the statue of liberty. I've been to the statue of liberty. It can't hold a small city. I know they are wider, but it seems a little unexpected that it can accommodate such a large structure.","This is partially a style issue. This is a partially medium translation issue. How the Imperator Titans look in the games and how they look in the minds of artists are completely different. There are no cities on the tops of these Imperator Titans. There is often a command center where the battle can be seen and managed since they supposed to tower over the battlefield stylistically and figuratively.




This is the Imperator Class Titan figure. Most of the time there is nothing around it, so you don't know how big it is in proportion to anything else. Different sculptures emphasize different things. Some are more ornate than others and have better detail. These are some of the early designs.





The titan is often shown not alongside anything that gives it scale. The structure on the top of the shoulders of the central body has three (possibly four) guns mounted on the very top for ranged mortar fire. Some of the early paintings depicted them like this. Again, nothing really to scale it against so it can look so large…
Some artists when they cast the Imperator Titan, in the right light, with billowing smoke wafting up from the craters below, it can seem monstrously large. Just the way the God Emperor's avatar, the Imperium's most terrifying war machine should look.





But if you are from one of those Forge worlds and stylish lighting isn't going to cut it, you can compare the size of the Imperator and realize it isn't a small city of there, nor a castle, instead it is just four very large cannons mounted there. There is also a heavily shielded command center with room enough for a good deal of staff. Maybe a latte bar. A matter of style over substance. 





Here how the figures compare to the field of battle at scale. The second image shows the Imperator against the other titans at scale. Look at the teeny-tiny space marine at his feet. Remember that guy is supposed to be this guy... 





Now can you see why Imperators are supposed to be terrifying and people might be prone to exaggerate what they remember seeing? Shellshock, hysteria. This is the impression the Imperium wants to leave you with.


See Also: What makes titans so valuable in the Warhammer 40K universe?
"
1991,1991,3179,Downloading specific yeast genes in an automated manner?,"I have 6 genes of Candida albicans yeast namely orf19.723, orf19.5908, orf19.610, orf19.2119, orf19.4998 and orf19.4056. And I have found the corresponding ortholog genes from Broad Institute website of other 16 species of yeast. So I have all gene names. Now how would I specifically download these genes and from where can I do this, preferably in an automated manner?

Also is there any standard naming convention? Because the ORF names given have other names too like BCR1, EFG1 and NDT80.

The list of gene names I have :

The orthologs of C. Albicans with S. cerevisiae
orf19.2119  YHR124W 
orf19.4998  YBR033W YKL034W 
orf19.5908  YBR083W 
orf19.610   YMR016C YKL043W 
orf19.723   NONE
orf19.4056  YMR136W 

The orthologs of C. Albicans with S. paradoxus
orf19.2119  spar33-g1.1 
orf19.4998  spar197-g23.1   spar324-g3.1    
orf19.5908  spar200-g4.1    
orf19.610   spar184-g1.1    spar324-g10.1   
orf19.723   NONE
orf19.4056  spar165-g2.1

The orthologs of C. Albicans with S. mikatae
orf19.2119  NONE
orf19.4998  smik146-g12.1   smik109-g17.1   
orf19.5908  smik83-g2.1 
orf19.610   smik571-g2.1    smik109-g10.1   
orf19.723   NONE
orf19.4056  smik1535-g1.1   

The orthologs of C. Albicans with S. bayanus
orf19.2119  sbayc514-g9.1   
orf19.4998  sbayc611-g22.1  sbayc652-g20.1  
orf19.5908  sbayc678-g131.1 
orf19.610   sbayc638-g23.1  sbayc652-g27.1  
orf19.723   NONE
orf19.4056  sbayc657-g41.1

The orthologs of C. Albicans with S. castellii
orf19.2119  Scas697.24  
orf19.4998  Scas625.4   
orf19.5908  Scas718.27  Scas635.12  
orf19.610   Scas106.1   Scas709.52  Scas625.8   
orf19.723   NONE
orf19.4056  Scas680.22d 

The orthologs of C. Albicans with C. glabrata
orf19.2119  CAGL0L13090g    
orf19.4998  CAGL0L01947g    
orf19.5908  CAGL0M01716g    CAGL0F04081g    
orf19.610   CAGL0M07634g    CAGL0L01771g    
orf19.723   NONE
orf19.4056  CAGL0I00902g    CAGL0L06776g    

The orthologs of C. Albicans with S. kluyveri
orf19.2119  SAKL0E11330g    
orf19.4998  SAKL0A09812g    
orf19.5908  SAKL0B06578g    
orf19.610   SAKL0D13442g    
orf19.723   SAKL0A03476g    
orf19.4056  SAKL0E04862g    

The orthologs of C. Albicans with K. lactis
orf19.2119  KLLA0F24420g    
orf19.4998  KLLA0F25674g    
orf19.5908  KLLA0E12507g    
orf19.610   KLLA0F04840g    
orf19.723   NONE
orf19.4056  KLLA0F17116g    

The orthologs of C. Albicans with A. gossypii
orf19.2119  AGR347W 
orf19.4998  AFR275W 
orf19.5908  AER177W 
orf19.610   ABR055C 
orf19.723   NONE
orf19.4056  ADR249W 

The orthologs of C. Albicans with K. waltii
orf19.2119  Kwal33.14699    
orf19.4998  Kwal26.8099 
orf19.5908  Kwal27.12423    
orf19.610   Kwal26.8176 
orf19.723   NONE
orf19.4056  Kwal47.17849    

The orthologs of C. Albicans with C. tropicalis
orf19.2119  CTRG01097.3 
orf19.4998  CTRG03636.3 
orf19.5908  CTRG02294.3 
orf19.610   NONE
orf19.723   CTRG00608.3 
orf19.4056  CTRG04523.3 

The orthologs of C. Albicans with L. elongosporus
orf19.2119  LELG01178   
orf19.4998  NONE
orf19.5908  LELG02666   
orf19.610   LELG05390   
orf19.723   LELG03123   
orf19.4056  LELG01761   

The orthologs of C. Albicans with C. parapsilosis
orf19.2119  CPAG04608   
orf19.4998  NONE
orf19.5908  CPAG01691   
orf19.610   CPAG00178   
orf19.723   CPAG00564   
orf19.4056  CPAG05034   

The orthologs of C. Albicans with D. hansenii
orf19.2119  DEHA2A07282g    
orf19.4998  NONE
orf19.5908  DEHA2G13794g    
orf19.610   DEHA2E10978g    
orf19.723   DEHA2E05984g    
orf19.4056  DEHA2E07172g    DEHA2F25916g    

The orthologs of C. Albicans with C. guilliermondii
orf19.2119  PGUG02096.1 
orf19.4998  NONE
orf19.5908  PGUG04378.1 
orf19.610   PGUG03651.1 
orf19.723   PGUG05571.1 
orf19.4056  PGUG05533.1 

The orthologs of C. Albicans with C. lusitaniae
orf19.2119  CLUG00404   
orf19.4998  NONE
orf19.5908  CLUG04694   
orf19.610   CLUG02047   
orf19.723   CLUG00627   
orf19.4056  CLUG05535

",dexterdev,https://biology.stackexchange.com/users/5669,"OK, the first step must be to map all these IDs to the same database. Try using http://uniprot.org if you want protein sequences else, look for each of them and find the corresponding Refseq ID. Since you have IDs from multiple databases, you might need to google them individually. If you know the ID type of each identifier you have, you can use a tool like DAVID's gene name converter to automate it. 

Once you have a list of IDs from the same database, save them in a file (one ID per line). Then, for UniProt accessions, you can get the FASTA protein sequence by running:

while read name; do wget -O - http://uniprot.org/$name.fasta; done &lt; names.txt


For RefSeq IDs, you can use the batch retrieval tool of Entrez. 
",terdon,https://biology.stackexchange.com/users/1306,http://biology.stackexchange.com/questions/26148/downloading-specific-yeast-genes-in-an-automated-manner,SCIENCE,biology.stackexchange.com,0.8888888888888888,0.4444444444444444,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.4444444444444444,0.6666666666666666,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,0.0,0.8888888888888888,Download specific yeast genes automatically?,"I have 6 genes of Candida albicans yeast namely orf19.723, orf19.5908, orf19.610, orf19.2119, orf19.4998 and orf19.4056. And I have found the corresponding ortholog genes from Broad Institute website of other 16 species of yeast. So I have all gene names. Now how would I specifically download these genes and from where can I do this, preferably in an automated manner?

Also is there any standard naming convention? Because the ORF names given have other names too like BCR1, EFG1 and NDT80.

The list of gene names I have :

The orthologs of C. Albicans with S. cerevisiae
orf19.2119  YHR124W 
orf19.4998  YBR033W YKL034W 
orf19.5908  YBR083W 
orf19.610   YMR016C YKL043W 
orf19.723   NONE
orf19.4056  YMR136W 

The orthologs of C. Albicans with S. paradoxus
orf19.2119  spar33-g1.1 
orf19.4998  spar197-g23.1   spar324-g3.1    
orf19.5908  spar200-g4.1    
orf19.610   spar184-g1.1    spar324-g10.1   
orf19.723   NONE
orf19.4056  spar165-g2.1

The orthologs of C. Albicans with S. mikatae
orf19.2119  NONE
orf19.4998  smik146-g12.1   smik109-g17.1   
orf19.5908  smik83-g2.1 
orf19.610   smik571-g2.1    smik109-g10.1   
orf19.723   NONE
orf19.4056  smik1535-g1.1   

The orthologs of C. Albicans with S. bayanus
orf19.2119  sbayc514-g9.1   
orf19.4998  sbayc611-g22.1  sbayc652-g20.1  
orf19.5908  sbayc678-g131.1 
orf19.610   sbayc638-g23.1  sbayc652-g27.1  
orf19.723   NONE
orf19.4056  sbayc657-g41.1

The orthologs of C. Albicans with S. castellii
orf19.2119  Scas697.24  
orf19.4998  Scas625.4   
orf19.5908  Scas718.27  Scas635.12  
orf19.610   Scas106.1   Scas709.52  Scas625.8   
orf19.723   NONE
orf19.4056  Scas680.22d 

The orthologs of C. Albicans with C. glabrata
orf19.2119  CAGL0L13090g    
orf19.4998  CAGL0L01947g    
orf19.5908  CAGL0M01716g    CAGL0F04081g    
orf19.610   CAGL0M07634g    CAGL0L01771g    
orf19.723   NONE
orf19.4056  CAGL0I00902g    CAGL0L06776g    

The orthologs of C. Albicans with S. kluyveri
orf19.2119  SAKL0E11330g    
orf19.4998  SAKL0A09812g    
orf19.5908  SAKL0B06578g    
orf19.610   SAKL0D13442g    
orf19.723   SAKL0A03476g    
orf19.4056  SAKL0E04862g    

The orthologs of C. Albicans with K. lactis
orf19.2119  KLLA0F24420g    
orf19.4998  KLLA0F25674g    
orf19.5908  KLLA0E12507g    
orf19.610   KLLA0F04840g    
orf19.723   NONE
orf19.4056  KLLA0F17116g    

The orthologs of C. Albicans with A. gossypii
orf19.2119  AGR347W 
orf19.4998  AFR275W 
orf19.5908  AER177W 
orf19.610   ABR055C 
orf19.723   NONE
orf19.4056  ADR249W 

The orthologs of C. Albicans with K. waltii
orf19.2119  Kwal33.14699    
orf19.4998  Kwal26.8099 
orf19.5908  Kwal27.12423    
orf19.610   Kwal26.8176 
orf19.723   NONE
orf19.4056  Kwal47.17849    

The orthologs of C. Albicans with C. tropicalis
orf19.2119  CTRG01097.3 
orf19.4998  CTRG03636.3 
orf19.5908  CTRG02294.3 
orf19.610   NONE
orf19.723   CTRG00608.3 
orf19.4056  CTRG04523.3 

The orthologs of C. Albicans with L. elongosporus
orf19.2119  LELG01178   
orf19.4998  NONE
orf19.5908  LELG02666   
orf19.610   LELG05390   
orf19.723   LELG03123   
orf19.4056  LELG01761   

The orthologs of C. Albicans with C. parapsilosis
orf19.2119  CPAG04608   
orf19.4998  NONE
orf19.5908  CPAG01691   
orf19.610   CPAG00178   
orf19.723   CPAG00564   
orf19.4056  CPAG05034   

The orthologs of C. Albicans with D. hansenii
orf19.2119  DEHA2A07282g    
orf19.4998  NONE
orf19.5908  DEHA2G13794g    
orf19.610   DEHA2E10978g    
orf19.723   DEHA2E05984g    
orf19.4056  DEHA2E07172g    DEHA2F25916g    

The orthologs of C. Albicans with C. guilliermondii
orf19.2119  PGUG02096.1 
orf19.4998  NONE
orf19.5908  PGUG04378.1 
orf19.610   PGUG03651.1 
orf19.723   PGUG05571.1 
orf19.4056  PGUG05533.1 

The orthologs of C. Albicans with C. lusitaniae
orf19.2119  CLUG00404   
orf19.4998  NONE
orf19.5908  CLUG04694   
orf19.610   CLUG02047   
orf19.723   CLUG00627   
orf19.4056  CLUG05535

","OK, the first step must be to map all these IDs to the same database. Try using http://uniprot.org if you want protein sequences else, look for each of them and find the corresponding Refseq ID. Since you have IDs from multiple databases, you might need to google them individually. If you know the ID type of each identifier you have, you can use a tool like DAVID's gene name converter to automate it. 

Once you have a list of IDs from the same database, save them in a file (one ID per line). Then, for UniProt accessions, you can get the FASTA protein sequence by running:

while read name; do wget -O - http://uniprot.org/$name.fasta; done &lt; names.txt


For RefSeq IDs, you can use the batch retrieval tool of Entrez. 
"
1866,1866,2964,why is 'child of' modifier scaling my bone?,"I'm a Blender noob and I'm having so many issues with parenting bones. I'm trying to use the 'child of' modifier to parent a 'lightsaber bone' to a 'hand bone'. But when i apply the modifier, the lightsaber bone and its mesh is shrunk down to half it's size for some reason. And completely misplaced. 
Has anyone come across this problem before? Thanks so much in advance for any ideas. 
",NickG77,https://blender.stackexchange.com/users/1884,"A child of constraint is the same as parenting an object, when you move the parent the child also moves, scale the parent and the child also scales.

By using the constraint instead of direct parenting you can control some of this behaviour. By turning off the scale options you can stop the lightsaber scaling with your armature.



This does highlight one point though, you have an armature that is scaled, you most likely scaled the armature while in object mode to get it to fit your model. Having an armature that is scaled can cause odd behaviour like this at times so you may want to apply the scale to your armature by pressing CtrlA and choosing scale while in object mode.


",sambler,https://blender.stackexchange.com/users/935,http://blender.stackexchange.com/questions/5635/why-is-child-of-modifier-scaling-my-bone,TECHNOLOGY,blender.stackexchange.com,0.3333333333333333,0.8888888888888888,0.0,0.6666666666666666,1.0,1.0,0.6666666666666666,0.4444444444444444,0.6666666666666666,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,0.0,0.8888888888888888,0.7777777777777778,0.6666666666666666,1.0,0.8888888888888888,0.7,0.3333333333333333,0.0,1.0,0.8888888888888888,"Why is the ""child of"" modifier scaling my bones?","I'm a mixed fan and I have a lot of problems with raising bones. I tried to use the child of modifier to set lightsaber bone to the parent of hand bone. But when I applied the modifier, the lightsaber bone and its mesh were somehow reduced to half its size. It's completely misplaced.","A child of constraint is the same as parenting an object, when you move the parent the child also moves, scale the parent and the child also scales.

By using the constraint instead of direct parenting you can control some of this behaviour. By turning off the scale options you can stop the lightsaber scaling with your armature.



This does highlight one point though, you have an armature that is scaled, you most likely scaled the armature while in object mode to get it to fit your model. Having an armature that is scaled can cause odd behaviour like this at times so you may want to apply the scale to your armature by pressing CtrlA and choosing scale while in object mode.


"
49,49,75,Thunderbird 2.0: Inbox size is 4GB on disk: how do I reduce it?,"Mozilla Thunderbird 2.0: I have set Thunderbird never to delete a message that is on disk...Thus, after four short years, I have a 4GB Inbox file. Thunderbird needs about 10 minutes to read it, and even then I can't compact it. Anyone have some suggestions?
",Eric,https://superuser.com/users/15673,"There is definitely a 4GB limit on Windows due to Windows limitations which means you will have problem with individual Thunderbird mail folders that are larger than 4GB.

And I thought the 4GB limit existed on Mac and Linux as well (so I am curious as to how emgee can have a Thunderbird folder that's 7GB! emgee: perhaps you are referring to a Unified Folder being 7GB but your individual folders are &lt; 4GB?)

Nick's suggestion (i.e. move to new, multiple Thunderbird folders each of which is &lt;4GB. please clarify emgee) should work. More info with a complete procedure (change ""Sent"" to ""Inbox""):
http://getsatisfaction.com/mozilla_messaging/topics/version_3_1_2_still_has_the_missing_sent_message_bug#reply_3235232
",Roland Tanglao,https://superuser.com/users/9764,http://superuser.com/questions/198503,TECHNOLOGY,superuser.com,0.7777777777777778,0.7777777777777778,0.3333333333333333,0.6666666666666666,1.0,0.3333333333333333,0.6666666666666666,0.4444444444444444,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,1.0,1.0,0.7777777777777778,1.0,1.0,0.8666666666666666,0.6666666666666666,0.3333333333333333,0.6666666666666666,1.0,Thunderbird 2.0: the inbox size is 4GB disk: how to reduce it?,"Mozilla Thunderbird 2.0: I have set Thunderbird to never delete messages on disk So, in just four years, I have a 4GB inbox file. Thunderbird takes 10 minutes to read, and even then I can't compress it. Is there any suggestion?","There is definitely a 4GB limit on Windows due to Windows limitations which means you will have problem with individual Thunderbird mail folders that are larger than 4GB.

And I thought the 4GB limit existed on Mac and Linux as well (so I am curious as to how emgee can have a Thunderbird folder that's 7GB! emgee: perhaps you are referring to a Unified Folder being 7GB but your individual folders are &lt; 4GB?)

Nick's suggestion (i.e. move to new, multiple Thunderbird folders each of which is &lt;4GB. please clarify emgee) should work. More info with a complete procedure (change ""Sent"" to ""Inbox""):
http://getsatisfaction.com/mozilla_messaging/topics/version_3_1_2_still_has_the_missing_sent_message_bug#reply_3235232
"
364,364,574,FragmentTabHost in VS2013 - xamarin C#,"the code i used to create FragmentTabHost :( i am designing for android 2.2 to upper)
i have googled a lot but no use so
i have placed all of my code here.
I get error in :

   mTabHost.AddTab(spec);


please help how to solve ??

Activity 2.cs

using System;
using System.Collections.Generic;
using System.Linq;
using System.Text;


using Android.App;
using Android.Content;
using Android.OS;
using Android.Runtime;
using Android.Views;
using Android.Widget;
using Android.Content.PM;
using Android.Support.V4.App;


namespace ANRestaurant.Forms
{
[Activity(Label = ""ANRestaurant"", MainLauncher = true, Icon = ""@drawable/icon"", ScreenOrientation = ScreenOrientation.Portrait)]


public class Activity2 : FragmentActivity
{
    FragmentTabHost mTabHost;
    protected override void OnCreate(Bundle bundle)
    {
        base.OnCreate(bundle);


        SetContentView(Resource.Layout.activity_main);
        try
        {
            mTabHost = FindViewById&lt;FragmentTabHost&gt;(Resource.Id.tabhostN  );
            Intent intent;
            intent = new Intent(this, typeof(Fragment1));
            intent.AddFlags(ActivityFlags.NewTask);
            //mTabHost.Setup(this, SupportFragmentManager, Resource.Id.tabFrameLayout);


            TabHost.TabSpec spec;
            spec = mTabHost.NewTabSpec(""artists"");
            spec.SetIndicator(""Artists"", Resources.GetDrawable(Resource.Drawable.tab_icon1)  );
            spec.SetContent(intent);
            mTabHost.AddTab(spec);   ======&gt;Here is the error
            //mTabHost.AddTab(
            //        mTabHost.NewTabSpec(""tab2"").SetIndicator(""Tab 2"", null),
            //       intent, null);
            //mTabHost.addTab(
            //        mTabHost.newTabSpec(""tab2"").setIndicator(""Tab 2"", null),
            //        FragmentTab.class, null);
            //mTabHost.addTab(
            //        mTabHost.newTabSpec(""tab3"").setIndicator(""Tab 3"", null),
            //        FragmentTab.class, null);
        }
        catch (Exception ex)
        {


        }
    }
}
}


activity_main.axml

&lt;?xml version=""1.0"" encoding=""utf-8""?&gt;
&lt;android.support.v4.app.FragmentTabHost xmlns:android=""http://schemas.android.com/apk/res/android""
    android:id=""@+id/tabhostN""
    android:layout_width=""match_parent""
    android:layout_height=""match_parent""&gt;
    &lt;LinearLayout
        android:layout_width=""match_parent""
        android:layout_height=""match_parent""
        android:orientation=""vertical""&gt;
        &lt;TabWidget
            android:id=""@+id/tabs""
            android:layout_width=""match_parent""
            android:layout_height=""wrap_content""
            android:layout_weight=""0""
            android:orientation=""horizontal"" /&gt;
        &lt;FrameLayout
            android:id=""@+id/tabFrameLayout""
            android:layout_width=""match_parent""
            android:layout_height=""0dp""
            android:layout_weight=""1"" /&gt;
    &lt;/LinearLayout&gt;
&lt;/android.support.v4.app.FragmentTabHost&gt;

Fragment1.cs

using System;
using System.Collections.Generic;
using System.Linq;
using System.Text;


using Android.App;
using Android.Content;
using Android.OS;
using Android.Runtime;
using Android.Util;
using Android.Views;
using Android.Widget;


namespace ANRestaurant.Forms
{
public class Fragment1 : Fragment
{



    public override void OnCreate(Bundle savedInstanceState)
    {
        base.OnCreate(savedInstanceState);


        // Create your fragment here
    }
    public override View OnCreateView(LayoutInflater inflater, ViewGroup container, Bundle savedInstanceState)
    {
        View view = inflater.Inflate(Resource.Layout.fragment1, container, false);
       return view;
         //return base.OnCreateView(inflater, container, savedInstanceState);
    }
}
}


ٍError Is :
Java.Lang.NullPointerException: Exception of type  Java.Lang.NullPointerException  was thrown.
at Android.Runtime.JNIEnv.CallVoidMethod (IntPtr jobject, IntPtr jmethod, Android.Runtime.JValue[] parms) 
",Ali Naiemabadi,https://stackoverflow.com/users/4019504,"I got the same error and found here.
The problem is here in your fragment:

using Android.App;


Change it to:

using Android.Support.V4.App;


It's ok now...

It waste me the whole day.

OK, in output window it shows cast type error. like this：

Android.App.Fragment can't cast to Android.Support.V4.App.Fragment.

",Thyiad,https://stackoverflow.com/users/4873641,http://stackoverflow.com/questions/25726932/fragmenttabhost-in-vs2013-xamarin-c-sharp,STACKOVERFLOW,stackoverflow.com,0.6666666666666666,0.3333333333333333,0.0,0.3333333333333333,1.0,0.6666666666666666,0.6666666666666666,0.4444444444444444,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.6666666666666666,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,0.8888888888888888,0.8,0.6666666666666666,0.6666666666666666,1.0,0.5555555555555556,Fragment host in vs2013 - xamarin C#,"the code i used to create FragmentTabHost :( i am designing for android 2.2 to upper)
i have googled a lot but no use so
i have placed all of my code here.
I get error in :

   mTabHost.AddTab(spec);


please help how to solve ??

Activity 2.cs

using System;
using System.Collections.Generic;
using System.Linq;
using System.Text;


using Android.App;
using Android.Content;
using Android.OS;
using Android.Runtime;
using Android.Views;
using Android.Widget;
using Android.Content.PM;
using Android.Support.V4.App;


namespace ANRestaurant.Forms
{
[Activity(Label = ""ANRestaurant"", MainLauncher = true, Icon = ""@drawable/icon"", ScreenOrientation = ScreenOrientation.Portrait)]


public class Activity2 : FragmentActivity
{
    FragmentTabHost mTabHost;
    protected override void OnCreate(Bundle bundle)
    {
        base.OnCreate(bundle);


        SetContentView(Resource.Layout.activity_main);
        try
        {
            mTabHost = FindViewById&lt;FragmentTabHost&gt;(Resource.Id.tabhostN  );
            Intent intent;
            intent = new Intent(this, typeof(Fragment1));
            intent.AddFlags(ActivityFlags.NewTask);
            //mTabHost.Setup(this, SupportFragmentManager, Resource.Id.tabFrameLayout);


            TabHost.TabSpec spec;
            spec = mTabHost.NewTabSpec(""artists"");
            spec.SetIndicator(""Artists"", Resources.GetDrawable(Resource.Drawable.tab_icon1)  );
            spec.SetContent(intent);
            mTabHost.AddTab(spec);   ======&gt;Here is the error
            //mTabHost.AddTab(
            //        mTabHost.NewTabSpec(""tab2"").SetIndicator(""Tab 2"", null),
            //       intent, null);
            //mTabHost.addTab(
            //        mTabHost.newTabSpec(""tab2"").setIndicator(""Tab 2"", null),
            //        FragmentTab.class, null);
            //mTabHost.addTab(
            //        mTabHost.newTabSpec(""tab3"").setIndicator(""Tab 3"", null),
            //        FragmentTab.class, null);
        }
        catch (Exception ex)
        {


        }
    }
}
}


activity_main.axml

&lt;?xml version=""1.0"" encoding=""utf-8""?&gt;
&lt;android.support.v4.app.FragmentTabHost xmlns:android=""http://schemas.android.com/apk/res/android""
    android:id=""@+id/tabhostN""
    android:layout_width=""match_parent""
    android:layout_height=""match_parent""&gt;
    &lt;LinearLayout
        android:layout_width=""match_parent""
        android:layout_height=""match_parent""
        android:orientation=""vertical""&gt;
        &lt;TabWidget
            android:id=""@+id/tabs""
            android:layout_width=""match_parent""
            android:layout_height=""wrap_content""
            android:layout_weight=""0""
            android:orientation=""horizontal"" /&gt;
        &lt;FrameLayout
            android:id=""@+id/tabFrameLayout""
            android:layout_width=""match_parent""
            android:layout_height=""0dp""
            android:layout_weight=""1"" /&gt;
    &lt;/LinearLayout&gt;
&lt;/android.support.v4.app.FragmentTabHost&gt;

Fragment1.cs

using System;
using System.Collections.Generic;
using System.Linq;
using System.Text;


using Android.App;
using Android.Content;
using Android.OS;
using Android.Runtime;
using Android.Util;
using Android.Views;
using Android.Widget;


namespace ANRestaurant.Forms
{
public class Fragment1 : Fragment
{



    public override void OnCreate(Bundle savedInstanceState)
    {
        base.OnCreate(savedInstanceState);


        // Create your fragment here
    }
    public override View OnCreateView(LayoutInflater inflater, ViewGroup container, Bundle savedInstanceState)
    {
        View view = inflater.Inflate(Resource.Layout.fragment1, container, false);
       return view;
         //return base.OnCreateView(inflater, container, savedInstanceState);
    }
}
}


ٍError Is :
Java.Lang.NullPointerException: Exception of type  Java.Lang.NullPointerException  was thrown.
at Android.Runtime.JNIEnv.CallVoidMethod (IntPtr jobject, IntPtr jmethod, Android.Runtime.JValue[] parms) 
","I got the same error and found here.
The problem is here in your fragment:

using Android.App;


Change it to:

using Android.Support.V4.App;


It's ok now...

It waste me the whole day.

OK, in output window it shows cast type error. like this：

Android.App.Fragment can't cast to Android.Support.V4.App.Fragment.

"
2571,2571,4092,Effective game mechanics for handling conflicts with spirits,"A very effective set piece can be conflict with the spirit world.  A nice example of the kind of thing I am thinking of is from the 1982 Conan film, where the wizard opens a gateway to the spirit world to get demons to revive Conan, and where Valeria fights incorporeal demons to save Conan (YouTube, from 6:45 into the clip to the end &amp; onto next clip).

RQ3 had nice mechanics for dealing with these situations, with shamans who can take characters to the other side through their fetch, spirit combat to handle attacks by hostile spirits, using magic points as an orthogonal measure of strength to hit points.  

AD&amp;D was pretty lousy for this kind of thing back in the day: its distinction between combat involving the incorporeal attribute or in the ethereal and astral realms didn't really work for setting up situations.  But newer D&amp;Ds seem to have better resources, though I've not seen this in action.

What good game mechanics are there for handling conflicts with spirits?

Postscript

The kind of thing game mechanics need, I think, to sustain interest in spirits and spirit combat are:


Spirits are immaterial and that means you have to do different sorts of things to influence them.  E.g., if the best way to deal with an ancient ghost is to chop it up with an axe, that'll spil that atmosphere a bit;
Likewise, spirits are potentially powerful adversaries.  Not very high-powered spells that can get rid of most spirits with a 65% chance of success detract from interest;
Characters can be experts in spirits, and it is good if the nature of those experts draws on resonant real-world and fictional atmospheric devices such as shamans, ancestor worship, fetches, and the like.  It's also good if characters regularly need the services of these figures. 

",Alticamelus,https://rpg.stackexchange.com/users/973,"White Wolf's nWoD (particularly Werewolf: The Forsaken and Mage: The Awakening, afaik) has real extensive support for stories involving the spirit world(s) and spirits, well built rules that could easily be tweaked further to allow for homegrown settings independent of nWoD as well.

(The old versions of these games would work great too, though the new one's general system - Storytelling - is more streamlined, so I'd go for that one instead of the old Storyteller system.)

Edit: Here's a link to a summary of nWoD's spirits. Without having read the abovementioned books (and the core), parts of it will naturally be hard to understand, yet even by skimming it you may get a general picture of how Storytelling views and handles spirits by default.
",OpaCitiZen,https://rpg.stackexchange.com/users/507,http://rpg.stackexchange.com/questions/8106/effective-game-mechanics-for-handling-conflicts-with-spirits,CULTURE,rpg.stackexchange.com,1.0,0.7777777777777778,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.4444444444444444,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.3333333333333333,0.3333333333333333,0.0,0.8888888888888888,0.8888888888888888,0.5555555555555556,0.8888888888888888,0.8888888888888888,0.7333333333333333,0.0,0.0,0.6666666666666666,1.0,An effective game mechanism to deal with spiritual conflicts,"A very effective set piece can be conflict with the spirit world.  A nice example of the kind of thing I am thinking of is from the 1982 Conan film, where the wizard opens a gateway to the spirit world to get demons to revive Conan, and where Valeria fights incorporeal demons to save Conan (YouTube, from 6:45 into the clip to the end &amp; onto next clip).

RQ3 had nice mechanics for dealing with these situations, with shamans who can take characters to the other side through their fetch, spirit combat to handle attacks by hostile spirits, using magic points as an orthogonal measure of strength to hit points.  

AD&amp;D was pretty lousy for this kind of thing back in the day: its distinction between combat involving the incorporeal attribute or in the ethereal and astral realms didn't really work for setting up situations.  But newer D&amp;Ds seem to have better resources, though I've not seen this in action.

What good game mechanics are there for handling conflicts with spirits?

Postscript

The kind of thing game mechanics need, I think, to sustain interest in spirits and spirit combat are:


Spirits are immaterial and that means you have to do different sorts of things to influence them.  E.g., if the best way to deal with an ancient ghost is to chop it up with an axe, that'll spil that atmosphere a bit;
Likewise, spirits are potentially powerful adversaries.  Not very high-powered spells that can get rid of most spirits with a 65% chance of success detract from interest;
Characters can be experts in spirits, and it is good if the nature of those experts draws on resonant real-world and fictional atmospheric devices such as shamans, ancestor worship, fetches, and the like.  It's also good if characters regularly need the services of these figures. 

","White Wolf's nWoD (particularly Werewolf: The Forsaken and Mage: The Awakening, afaik) has real extensive support for stories involving the spirit world(s) and spirits, well built rules that could easily be tweaked further to allow for homegrown settings independent of nWoD as well.

(The old versions of these games would work great too, though the new one's general system - Storytelling - is more streamlined, so I'd go for that one instead of the old Storyteller system.)

Edit: Here's a link to a summary of nWoD's spirits. Without having read the abovementioned books (and the core), parts of it will naturally be hard to understand, yet even by skimming it you may get a general picture of how Storytelling views and handles spirits by default.
"
5275,5275,8382,Forefront (Identity Manager/Sync Service) missing from Service Manager,"I am building a new testing environment, and in the process I have noticed that the Forefront services are missing from the Service Manager. Is there a way to add these services? This is the first time I have seen these missing. I am a local admin on the server. We are running Server 2008 R2 Enterprise with SP1
",Jason,https://sharepoint.stackexchange.com/users/4344,"Jason,

May be this is of help to you:
On a SharePoint 2010 box Forefront services is missing from the services console

Extract from blog:


  For User Profile service application we require following service in
  the services.msc.
  
  
  Forefront Identity Manager Service.
  Forefront Identity synchronization Manage Service.
  
  
  The above service gets provisioned when we services are provisioned. I
  my case I found both the Forefront services was missing.
  
  Later after further research found that following registry keys were
  missing from the SharePoint box, due to this Forefront services was
  missing from the services.msc.
  
  Missing registry Key:
  
  HKLM\System\Controlset1\FIMService
  
  HKLM\System\Controlset2\FIMService
  
  HKLM\System\CurrentControlset\FIMService
  
  HKLM\System\Controlset1\FIMSynchronizationService
  
  HKLM\System\Controlset2\FIMSynchronizationService
  
  HKLM\System\CurrentControlset\FIMSynchronizationService
  
  Exported the above registry Keys from working SharePoint 2010 box and
  imported in to the Problematic SharePoint 2010 box were we have issue
  starting User Profile service application.
  
  Note:- Before making any registry changes ensure we take a backup of
  the registry.
  
  After importing the registry key reboot the machine and then you would
  find the both the Forefront services
  
  
  Forefront Identity Manager Service.
  Forefront Identity synchronization Manage Service.
  

",Arsalan Adam Khatri,https://sharepoint.stackexchange.com/users/4100,http://sharepoint.stackexchange.com/questions/53508/forefront-identity-manager-sync-service-missing-from-service-manager,TECHNOLOGY,sharepoint.stackexchange.com,1.0,0.6666666666666666,0.0,0.5,1.0,1.0,0.5,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,0.8333333333333334,0.8,0.0,1.0,0.0,0.8333333333333334,Missing forefront in Service Manager (Identity Manager / synchronization service),"I'm building a new test environment, and in the process, I notice that the service manager lacks the forefront service. Is there a way to add these services? This is the first time I've seen these things disappear. I am the local administrator on the server. We are running server 2008 R2 enterprise with SP1","Jason,

May be this is of help to you:
On a SharePoint 2010 box Forefront services is missing from the services console

Extract from blog:


  For User Profile service application we require following service in
  the services.msc.
  
  
  Forefront Identity Manager Service.
  Forefront Identity synchronization Manage Service.
  
  
  The above service gets provisioned when we services are provisioned. I
  my case I found both the Forefront services was missing.
  
  Later after further research found that following registry keys were
  missing from the SharePoint box, due to this Forefront services was
  missing from the services.msc.
  
  Missing registry Key:
  
  HKLM\System\Controlset1\FIMService
  
  HKLM\System\Controlset2\FIMService
  
  HKLM\System\CurrentControlset\FIMService
  
  HKLM\System\Controlset1\FIMSynchronizationService
  
  HKLM\System\Controlset2\FIMSynchronizationService
  
  HKLM\System\CurrentControlset\FIMSynchronizationService
  
  Exported the above registry Keys from working SharePoint 2010 box and
  imported in to the Problematic SharePoint 2010 box were we have issue
  starting User Profile service application.
  
  Note:- Before making any registry changes ensure we take a backup of
  the registry.
  
  After importing the registry key reboot the machine and then you would
  find the both the Forefront services
  
  
  Forefront Identity Manager Service.
  Forefront Identity synchronization Manage Service.
  

"
5548,5548,8812,Count values in multiple columns based on ranges in first column,"I have a  7 different columns with various attributes &amp; 500 rows with corresponding values for these attributes [Numbers,texts,YES/No etc]..Example only 2 column with values shown.

1st column have range &amp; rest 6 have values need to be counted based on the ranges.

Column 1 is called level ,  I have levels from 1 to 7....this will repeat for next groups.

Level 1 is main level &amp; remaining levels [2 to 7] are sub levels. Need to find missing value counts for this group and subsequent groups.

PS: this is for a Bill OF material [BOM]

example

   Level Number Description
-   1   6586    ABC
    2   6579    XYZ
    3   6689    
    3   7854    123
    4   6011    GHF
G1  4   OOPO    YUI
    4   5589    OIK
    5   2132    
    6   4178    BUY
-   7   7145    CRI
*   1   8245    WES
    2   6666    RED
    3   1025    TRY
G2  3   9898    UIO
    4   4567    POL
    5   1234    WIP
    6   987     III
*   7   7787    RTE
+   1   6652    WED
    2   5425    
    3   9899    TRY
G3  3   6452    OOP
    4   3452    POE
    5   7890    
    6           LLK
+   7   8889    RET


Result expected [Aim is to find count of missing/wrong values]

Main ITEM      Number Description
    G1           1       3     [1 text in number column,2 blank/1 number in Dsecr column]
    G2           0       0     [ 0 error , as both columns filled proeprly]
    G3           1       2     [1 blank in Number column,2 blanks in Descr. column]


   Name &amp; description corresponding to level 1 are always constant.


To make things bit more clear...

If i use MATCH function with lookupvalue ABC it will give position 3 &amp; MATCH function for WES will give posiiton 9. Based on this range ,Row 3 to row 8,[Row 9 will start of anotther range] need count of blanks or texts for NUMBER,Count of blanks for DESCRIPTION and some other attributes which i have not included here.

ABC is a group with 2 to 7 sub levels

    1      6586     ABC
    2      6579     XYZ
    3      6689       
    3      7854     123
    4      6011     GHF
    4      OOPO     YUI
    4      5589     OIK
    5      2132     
    6      4178     BUY
    7      7145     CRI 


WES is a group with next 2 to 7 sub levels

1      8245     WES
2      6666     RED
3      1025     TRY 
3      9898     UIO
4      4567     POL
5      1234     WIP
6      0987     III
7      7787     RTE


WED is next group

    1      6652     WED
    2      5425     
    3      9899    TRY
    3      6452     OOP
    4      3452     POE
    5      7890     
    6               LLK
    7      8889     RET

",user3286682,https://stackoverflow.com/users/3286682,"In cell D2 type =if(A2="""","""",if(A2=1,C2,C1))  This will associate main level name with all subgroups.

In cell E2 type =if(A2="""","""",if(B2="""",E1+1,E1))  This will running count blanks in the numeric column for the main level

In cell F2 type =if(A2="""","""",if(AND(B2&gt;-1,B2&lt;10000),F1+1,F1))  This should running count non-numeric in the numeric column.

In cell G2 type =if(A2="""","""",if(C2="""",G1+1,G1))  This should running count blanks in the description column

I don't have excel on this machine so this is untested.

Update for group sequence:
In cell H2 type =if(A2="""",H1+1,H1)  This should generate a higher number sequence when the group changes.

In cell I2 type =""G""&amp;H2  This gets the H columns sequence and prefixes G by concatenation

If you paste all these functions down to the end of your data block, you should then be able to do a pivot table to ""compress"" everything into what you need as described in your specifications.  You can put the ""I"" and ""D"" columns in the row area of the pivot.  Double click each of these and for subtotals, select none.  The ""E"", ""F"" and ""G"" columns in the value area, double click each and pick ""max"".  Move the values to ""columns"" if the are vertically arranged.
",bf2020,https://stackoverflow.com/users/3038209,http://stackoverflow.com/questions/21643832/count-values-in-multiple-columns-based-on-ranges-in-first-column,STACKOVERFLOW,stackoverflow.com,0.6666666666666666,0.3333333333333333,0.0,0.0,1.0,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.7777777777777778,Calculate values in multiple columns based on ranges in the first column,"I have a  7 different columns with various attributes &amp; 500 rows with corresponding values for these attributes [Numbers,texts,YES/No etc]..Example only 2 column with values shown.

1st column have range &amp; rest 6 have values need to be counted based on the ranges.

Column 1 is called level ,  I have levels from 1 to 7....this will repeat for next groups.

Level 1 is main level &amp; remaining levels [2 to 7] are sub levels. Need to find missing value counts for this group and subsequent groups.

PS: this is for a Bill OF material [BOM]

example

   Level Number Description
-   1   6586    ABC
    2   6579    XYZ
    3   6689    
    3   7854    123
    4   6011    GHF
G1  4   OOPO    YUI
    4   5589    OIK
    5   2132    
    6   4178    BUY
-   7   7145    CRI
*   1   8245    WES
    2   6666    RED
    3   1025    TRY
G2  3   9898    UIO
    4   4567    POL
    5   1234    WIP
    6   987     III
*   7   7787    RTE
+   1   6652    WED
    2   5425    
    3   9899    TRY
G3  3   6452    OOP
    4   3452    POE
    5   7890    
    6           LLK
+   7   8889    RET


Result expected [Aim is to find count of missing/wrong values]

Main ITEM      Number Description
    G1           1       3     [1 text in number column,2 blank/1 number in Dsecr column]
    G2           0       0     [ 0 error , as both columns filled proeprly]
    G3           1       2     [1 blank in Number column,2 blanks in Descr. column]


   Name &amp; description corresponding to level 1 are always constant.


To make things bit more clear...

If i use MATCH function with lookupvalue ABC it will give position 3 &amp; MATCH function for WES will give posiiton 9. Based on this range ,Row 3 to row 8,[Row 9 will start of anotther range] need count of blanks or texts for NUMBER,Count of blanks for DESCRIPTION and some other attributes which i have not included here.

ABC is a group with 2 to 7 sub levels

    1      6586     ABC
    2      6579     XYZ
    3      6689       
    3      7854     123
    4      6011     GHF
    4      OOPO     YUI
    4      5589     OIK
    5      2132     
    6      4178     BUY
    7      7145     CRI 


WES is a group with next 2 to 7 sub levels

1      8245     WES
2      6666     RED
3      1025     TRY 
3      9898     UIO
4      4567     POL
5      1234     WIP
6      0987     III
7      7787     RTE


WED is next group

    1      6652     WED
    2      5425     
    3      9899    TRY
    3      6452     OOP
    4      3452     POE
    5      7890     
    6               LLK
    7      8889     RET

","In cell D2 type =if(A2="""","""",if(A2=1,C2,C1))  This will associate main level name with all subgroups.

In cell E2 type =if(A2="""","""",if(B2="""",E1+1,E1))  This will running count blanks in the numeric column for the main level

In cell F2 type =if(A2="""","""",if(AND(B2&gt;-1,B2&lt;10000),F1+1,F1))  This should running count non-numeric in the numeric column.

In cell G2 type =if(A2="""","""",if(C2="""",G1+1,G1))  This should running count blanks in the description column

I don't have excel on this machine so this is untested.

Update for group sequence:
In cell H2 type =if(A2="""",H1+1,H1)  This should generate a higher number sequence when the group changes.

In cell I2 type =""G""&amp;H2  This gets the H columns sequence and prefixes G by concatenation

If you paste all these functions down to the end of your data block, you should then be able to do a pivot table to ""compress"" everything into what you need as described in your specifications.  You can put the ""I"" and ""D"" columns in the row area of the pivot.  Double click each of these and for subtotals, select none.  The ""E"", ""F"" and ""G"" columns in the value area, double click each and pick ""max"".  Move the values to ""columns"" if the are vertically arranged.
"
4072,4072,6499,sharing state between different controllers in angular,"I have two controls : Left Side Navigation and the right pane that changes the content on clicking of any item on left navigation. 

Here is the html (angular view):

&lt;nav class=""navigation""&gt;
        &lt;ul class=""list-unstyled"" ng-controller=""NavigationController as navigation""&gt;
            &lt;li ng-repeat=""nav in navigation.tabs"" class=""has-submenu""&gt;
                &lt;a href=""#"" ng-click=""navigation.changeContent(nav.name)""&gt;{{nav.name}}&lt;/a&gt;
                &lt;ul class=""list-unstyled"" ng-show=""nav.subNav""&gt;
                    &lt;li ng-repeat=""subnav in nav.subNav""&gt;&lt;a href=""#"" ng-click=""navigation.changeContent(subnav.name)""&gt;{{subnav.name}}&lt;/a&gt;&lt;/li&gt;
                &lt;/ul&gt;
            &lt;/li&gt;
        &lt;/ul&gt;
    &lt;/nav&gt;

&lt;section class=""content"" ng-controller=""ContentSwitcher as content""&gt;
{{content.tab}}
&lt;div class=""warper container-fluid"" &gt;
&lt;div class=""container-scroll""&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/section&gt;


And here is the controller

(function () {
    var app = angular.module('provisioning', []);

    app.service('contentService',function(){
       var tab = 'Dashboard';
        return {
            getTab : function(){ return tab; },
            setTab : function(value){ tab = value}
        }
    });
    app.controller('NavigationController',['contentService','$log', function(cs,log){
        this.tabs = [
            {
                name: 'Dashboard'
            },
            {
                name: 'Manage',
                subNav: [
                    {
                        name: 'Account'
                    },
                    {
                        name: 'Facility'
                    },
                    {
                        name: 'Doctors'
                    },
                    {
                        name: 'Patients'
                    },
                    {
                        name: 'Nurses'
                    },
                    {
                        name: 'Device Inventory'
                    }

                ]
            },
            {
                name: 'Health Tracker'
            },
            {
                name: 'Reports'
            },
            {
                name: 'Settings'
            },
            {
                name: 'Logout'
            }
        ];
        var template = this;
        this.changeContent = function(tab){
            cs.setTab(tab);
        }
    }]);
    app.controller('ContentSwitcher', ['contentService',function(cs){
        this.tab = cs.getTab();
    }]);
})();


Also, is it best way to achieve what I intend to do in angularjs? I created a service and shared the variable in the two different controllers. However it doesn't work. The content on right never gets updated on clicking any of the item on left menu.
",beNerd,https://stackoverflow.com/users/1490278,"You need to tell your controller that the value of the tab has changed and then update it with the new value from the service. The second controller (ContentSwitcher) can not know, that the value changed and you simply assigned the string value of getTab once to this.tab.

One way to archive this automatically is changing the type of the variable inside your serivce from string to an object (e.g. tab = {name:'Dashboard'}) and then call $scope.$apply after you made changes to it.

In your first controller you still assign this.tab = service.getTab() (which will be an object) and in your view {{tab.name}}.
",Rouby,https://stackoverflow.com/users/1165330,http://stackoverflow.com/questions/29139107/sharing-state-between-different-controllers-in-angular,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.3333333333333333,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.3333333333333333,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,1.0,State sharing between different controllers in angle,"I have two controls : Left Side Navigation and the right pane that changes the content on clicking of any item on left navigation. 

Here is the html (angular view):

&lt;nav class=""navigation""&gt;
        &lt;ul class=""list-unstyled"" ng-controller=""NavigationController as navigation""&gt;
            &lt;li ng-repeat=""nav in navigation.tabs"" class=""has-submenu""&gt;
                &lt;a href=""#"" ng-click=""navigation.changeContent(nav.name)""&gt;{{nav.name}}&lt;/a&gt;
                &lt;ul class=""list-unstyled"" ng-show=""nav.subNav""&gt;
                    &lt;li ng-repeat=""subnav in nav.subNav""&gt;&lt;a href=""#"" ng-click=""navigation.changeContent(subnav.name)""&gt;{{subnav.name}}&lt;/a&gt;&lt;/li&gt;
                &lt;/ul&gt;
            &lt;/li&gt;
        &lt;/ul&gt;
    &lt;/nav&gt;

&lt;section class=""content"" ng-controller=""ContentSwitcher as content""&gt;
{{content.tab}}
&lt;div class=""warper container-fluid"" &gt;
&lt;div class=""container-scroll""&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/section&gt;


And here is the controller

(function () {
    var app = angular.module('provisioning', []);

    app.service('contentService',function(){
       var tab = 'Dashboard';
        return {
            getTab : function(){ return tab; },
            setTab : function(value){ tab = value}
        }
    });
    app.controller('NavigationController',['contentService','$log', function(cs,log){
        this.tabs = [
            {
                name: 'Dashboard'
            },
            {
                name: 'Manage',
                subNav: [
                    {
                        name: 'Account'
                    },
                    {
                        name: 'Facility'
                    },
                    {
                        name: 'Doctors'
                    },
                    {
                        name: 'Patients'
                    },
                    {
                        name: 'Nurses'
                    },
                    {
                        name: 'Device Inventory'
                    }

                ]
            },
            {
                name: 'Health Tracker'
            },
            {
                name: 'Reports'
            },
            {
                name: 'Settings'
            },
            {
                name: 'Logout'
            }
        ];
        var template = this;
        this.changeContent = function(tab){
            cs.setTab(tab);
        }
    }]);
    app.controller('ContentSwitcher', ['contentService',function(cs){
        this.tab = cs.getTab();
    }]);
})();


Also, is it best way to achieve what I intend to do in angularjs? I created a service and shared the variable in the two different controllers. However it doesn't work. The content on right never gets updated on clicking any of the item on left menu.
","You need to tell your controller that the value of the tab has changed and then update it with the new value from the service. The second controller (ContentSwitcher) can not know, that the value changed and you simply assigned the string value of getTab once to this.tab.

One way to archive this automatically is changing the type of the variable inside your serivce from string to an object (e.g. tab = {name:'Dashboard'}) and then call $scope.$apply after you made changes to it.

In your first controller you still assign this.tab = service.getTab() (which will be an object) and in your view {{tab.name}}.
"
4201,4201,6700,Parsing a Text to only see specific data,"I have the following text lines:

.add 7971 [Player: Sunfire (Account: 11309) X: 5839.623047 Y: 600.437439 Z: 650.839722 Map: 571 Selected player: Llubia (GUID: 19369)]  
.add 43956 [Player: Sunfire (Account: 11309) X: 5277.887695 Y: 2862.181641 Z: 446.735931 Map: 571 Selected none:  (GUID: 0)]  
.add 43956 [Player: Sunfire (Account: 11309) X: 5281.407715 Y: 2864.844482 Z: 446.735931 Map: 571 Selected player: Staticbaby (GUID: 19826)]  
.add 43956 [Player: Sunfire (Account: 11309) X: 5231.464844 Y: 1437.029175 Z: 648.498535 Map: 571 Selected player: Sunfire (GUID: 15295)]  
.add 44077 [Player: Sunfire (Account: 11309) X: 5231.464844 Y: 1437.029175 Z: 648.498535 Map: 571 Selected player: Sunfire (GUID: 15295)]  
.add 49285 [Player: Sunfire (Account: 11309) X: 16225.323242 Y: 16252.759766 Z: 12.790466 Map: 1 Selected none:  (GUID: 0)]  
.add 44115 175 [Player: Elmasguapo (Account: 11309) X: 1659.845093 Y: -4198.589844 Z: 56.382870 Map: 1 Selected none:  (GUID: 0)]  
.add 34078 [Player: Sunfire (Account: 11309) X: 16227.969727 Y: 16280.081055 Z: 13.175169 Map: 1 Selected none:  (GUID: 0)]  
.add  |cffffffff|Hitem:41427:0:0:0:0:0:0:0:80|h[Fuego de Artificio de Dalaran]|h|r 50 [Player: Sunfire (Account: 11309) X: 16221.392578 Y: 16260.944336 Z: 13.255954 Map: 1 Selected none:  (GUID: 0)]  
.add  |cffffffff|Hitem:45932:0:0:0:0:0:0:0:80|h[Gelatina Negra]|h|r [Player: Sunfire (Account: 11309) X: 5874.347168 Y: 679.056763 Z: 167.483719 Map: 571 Selected player: Assasins (GUID: 19438)]  
.add  |cffffffff|Hitem:45932:0:0:0:0:0:0:0:80|h[Gelatina Negra]|h|r [Player: Sunfire (Account: 11309) X: 5873.767090 Y: 679.386841 Z: 167.435257 Map: 571 Selected player: Assasins (GUID: 19438)]  
.add  |cffffffff|Hitem:45932:0:0:0:0:0:0:0:80|h[Gelatina Negra]|h|r [Player: Sunfire (Account: 11309) X: 16226.880859 Y: 16247.247070 Z: 12.286857 Map: 1 Selected player: Irmtarget (GUID: 18521)]  
.add  |cffffffff|Hitem:45932:0:0:0:0:0:0:0:80|h[Gelatina Negra]|h|r [Player: Sunfire (Account: 11309) X: 16229.297852 Y: 16251.202148 Z: 13.081388 Map: 1 Selected player: Irmtarget (GUID: 18521)]  
.add 41600 2 [Player: Sunfire (Account: 11309) X: 16223.138672 Y: 16250.496094 Z: 12.431313 Map: 1 Selected player: Eifreen (GUID: 20341)]  
.add 41600 1 [Player: Sunfire (Account: 11309) X: 16223.138672 Y: 16250.496094 Z: 12.431313 Map: 1 Selected player: Eifreen (GUID: 20341)]  
.add 40516 [Player: Sunfire (Account: 11309) X: 16223.138672 Y: 16250.496094 Z: 12.431313 Map: 1 Selected player: Eifreen (GUID: 20341)]  
.add 44661 [Player: Sunfire (Account: 11309) X: 16223.138672 Y: 16250.496094 Z: 12.431313 Map: 1 Selected player: Eifreen (GUID: 20341)]  
.add 40518 [Player: Sunfire (Account: 11309) X: 16223.138672 Y: 16250.496094 Z: 12.431313 Map: 1 Selected player: Eifreen (GUID: 20341)]  
.add 44005 [Player: Sunfire (Account: 11309) X: 16223.138672 Y: 16250.496094 Z: 12.431313 Map: 1 Selected player: Eifreen (GUID: 20341)]  
.add 45867 [Player: Sunfire (Account: 11309) X: 16223.138672 Y: 16250.496094 Z: 12.431313 Map: 1 Selected player: Eifreen (GUID: 20341)]  
.add 45316 [Player: Sunfire (Account: 11309) X: 16223.138672 Y: 16250.496094 Z: 12.431313 Map: 1 Selected player: Eifreen (GUID: 20341)]  


And I want to parse it so it outputs something like this:

Line 1 For example - 7971 Llubia
Line 3 For example - 43956 Staticbaby
Line 9 For Example - 45932 Assassins

And so on.. This is done in the terminal with commands like cut, grep, cat, etc..

UPDATE: Here is the whole file: http://paste2.org/p/1744102 to parse in that way.

UPDATE2: Please forgive me if I do not accept an answer just yet. Am waiting for the bounty option to appear since for me, stuff like this deserve a bounty. So I will add a bounty and give it to the correct answer or answers.
",Luis Alvarado,https://askubuntu.com/users/7035,"awk '
  # ignore lines with ""none:"" or ""player:"" in $(NF-2)
  $(NF-2) ~ /^(none|player):$/ { 
    next   # read next line
  }

  { 
    # remove dots from $2 in every line
    gsub(/\./,"""",$2) 
  }

  /\|Hitem:/ {
    # if it has ""|Hitem:"" in $2, remove everything
    # before and after the colons
    sub(/.+\|Hitem:/,"""",$2)
    sub(/:.+/,"""",$2)
    print $2,$(NF-2)
    next   # read next line
  }

  {
    print $2,$(NF-2)
  }
' your_file.txt


Line 380 has Selected player:  (GUID: 6873)]. You have to decide what to do with such lines (ignore them? print the GUID instead?).
",elmicha,https://askubuntu.com/users/16134,http://askubuntu.com/questions/73311/parsing-a-text-to-only-see-specific-data,TECHNOLOGY,askubuntu.com,0.7777777777777778,0.3333333333333333,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,0.0,0.8888888888888888,Analyze text to view only specific data,"I have the following text lines:

.add 7971 [Player: Sunfire (Account: 11309) X: 5839.623047 Y: 600.437439 Z: 650.839722 Map: 571 Selected player: Llubia (GUID: 19369)]  
.add 43956 [Player: Sunfire (Account: 11309) X: 5277.887695 Y: 2862.181641 Z: 446.735931 Map: 571 Selected none:  (GUID: 0)]  
.add 43956 [Player: Sunfire (Account: 11309) X: 5281.407715 Y: 2864.844482 Z: 446.735931 Map: 571 Selected player: Staticbaby (GUID: 19826)]  
.add 43956 [Player: Sunfire (Account: 11309) X: 5231.464844 Y: 1437.029175 Z: 648.498535 Map: 571 Selected player: Sunfire (GUID: 15295)]  
.add 44077 [Player: Sunfire (Account: 11309) X: 5231.464844 Y: 1437.029175 Z: 648.498535 Map: 571 Selected player: Sunfire (GUID: 15295)]  
.add 49285 [Player: Sunfire (Account: 11309) X: 16225.323242 Y: 16252.759766 Z: 12.790466 Map: 1 Selected none:  (GUID: 0)]  
.add 44115 175 [Player: Elmasguapo (Account: 11309) X: 1659.845093 Y: -4198.589844 Z: 56.382870 Map: 1 Selected none:  (GUID: 0)]  
.add 34078 [Player: Sunfire (Account: 11309) X: 16227.969727 Y: 16280.081055 Z: 13.175169 Map: 1 Selected none:  (GUID: 0)]  
.add  |cffffffff|Hitem:41427:0:0:0:0:0:0:0:80|h[Fuego de Artificio de Dalaran]|h|r 50 [Player: Sunfire (Account: 11309) X: 16221.392578 Y: 16260.944336 Z: 13.255954 Map: 1 Selected none:  (GUID: 0)]  
.add  |cffffffff|Hitem:45932:0:0:0:0:0:0:0:80|h[Gelatina Negra]|h|r [Player: Sunfire (Account: 11309) X: 5874.347168 Y: 679.056763 Z: 167.483719 Map: 571 Selected player: Assasins (GUID: 19438)]  
.add  |cffffffff|Hitem:45932:0:0:0:0:0:0:0:80|h[Gelatina Negra]|h|r [Player: Sunfire (Account: 11309) X: 5873.767090 Y: 679.386841 Z: 167.435257 Map: 571 Selected player: Assasins (GUID: 19438)]  
.add  |cffffffff|Hitem:45932:0:0:0:0:0:0:0:80|h[Gelatina Negra]|h|r [Player: Sunfire (Account: 11309) X: 16226.880859 Y: 16247.247070 Z: 12.286857 Map: 1 Selected player: Irmtarget (GUID: 18521)]  
.add  |cffffffff|Hitem:45932:0:0:0:0:0:0:0:80|h[Gelatina Negra]|h|r [Player: Sunfire (Account: 11309) X: 16229.297852 Y: 16251.202148 Z: 13.081388 Map: 1 Selected player: Irmtarget (GUID: 18521)]  
.add 41600 2 [Player: Sunfire (Account: 11309) X: 16223.138672 Y: 16250.496094 Z: 12.431313 Map: 1 Selected player: Eifreen (GUID: 20341)]  
.add 41600 1 [Player: Sunfire (Account: 11309) X: 16223.138672 Y: 16250.496094 Z: 12.431313 Map: 1 Selected player: Eifreen (GUID: 20341)]  
.add 40516 [Player: Sunfire (Account: 11309) X: 16223.138672 Y: 16250.496094 Z: 12.431313 Map: 1 Selected player: Eifreen (GUID: 20341)]  
.add 44661 [Player: Sunfire (Account: 11309) X: 16223.138672 Y: 16250.496094 Z: 12.431313 Map: 1 Selected player: Eifreen (GUID: 20341)]  
.add 40518 [Player: Sunfire (Account: 11309) X: 16223.138672 Y: 16250.496094 Z: 12.431313 Map: 1 Selected player: Eifreen (GUID: 20341)]  
.add 44005 [Player: Sunfire (Account: 11309) X: 16223.138672 Y: 16250.496094 Z: 12.431313 Map: 1 Selected player: Eifreen (GUID: 20341)]  
.add 45867 [Player: Sunfire (Account: 11309) X: 16223.138672 Y: 16250.496094 Z: 12.431313 Map: 1 Selected player: Eifreen (GUID: 20341)]  
.add 45316 [Player: Sunfire (Account: 11309) X: 16223.138672 Y: 16250.496094 Z: 12.431313 Map: 1 Selected player: Eifreen (GUID: 20341)]  


And I want to parse it so it outputs something like this:

Line 1 For example - 7971 Llubia
Line 3 For example - 43956 Staticbaby
Line 9 For Example - 45932 Assassins

And so on.. This is done in the terminal with commands like cut, grep, cat, etc..

UPDATE: Here is the whole file: http://paste2.org/p/1744102 to parse in that way.

UPDATE2: Please forgive me if I do not accept an answer just yet. Am waiting for the bounty option to appear since for me, stuff like this deserve a bounty. So I will add a bounty and give it to the correct answer or answers.
","awk '
  # ignore lines with ""none:"" or ""player:"" in $(NF-2)
  $(NF-2) ~ /^(none|player):$/ { 
    next   # read next line
  }

  { 
    # remove dots from $2 in every line
    gsub(/\./,"""",$2) 
  }

  /\|Hitem:/ {
    # if it has ""|Hitem:"" in $2, remove everything
    # before and after the colons
    sub(/.+\|Hitem:/,"""",$2)
    sub(/:.+/,"""",$2)
    print $2,$(NF-2)
    next   # read next line
  }

  {
    print $2,$(NF-2)
  }
' your_file.txt


Line 380 has Selected player:  (GUID: 6873)]. You have to decide what to do with such lines (ignore them? print the GUID instead?).
"
1676,1676,2650,printf is causing a segfault with getlogin(),"I'm new to C, so I apologize if the answer is obvious, I've searched elsewhere.

the libraries I'm including are:

#include &lt;unistd.h&gt;
#include &lt;stdio.h&gt;
#include &lt;string.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;sys/wait.h&gt; 
#include &lt;fcntl.h&gt;
#include &lt;sys/stat.h&gt;


the code that is failing is:

    char *USER = getlogin();
    char CWD[128];

    if (USER == NULL)
        printf(""cry\n"");

    getcwd(CWD, sizeof(CWD));
    printf(""this prints\n"");
    printf(USER);
    printf(""this does not\n"");
    printf(""%s@myshell:%s&gt; "", USER, CWD);


cry does not print, so that should mean that getlogin is successful.  the segfault is caused on printf(USER);

further testing shows that the folling block prints entirely

    printf(""this prints\n"");
    printf(USER);
    printf(""this prints\n"");


but the folling block will print this prints end then segfault without showing USER

    printf(""this prints\n"");
    printf(USER);


EDIT:

Sorry for wasting your time.  I accidentally deleted an fgets that was supposed to follow it and that was causing the segfault.  I've been on this bug for a couple hours now, I love it when the problem is so small.

Thanks
",d0m1n1c,https://stackoverflow.com/users/2758011,"You should check getcwd return value. According to man page of getcwd:


  If the length of the absolute pathname of the current working
  directory, including the terminating null byte, exceeds size bytes,
  NULL is returned, and errno is set to ERANGE; an application should
  check for this error, and allocate a larger buffer if necessary.

",nikpel7,https://stackoverflow.com/users/1200465,http://stackoverflow.com/questions/21490433/printf-is-causing-a-segfault-with-getlogin,STACKOVERFLOW,stackoverflow.com,1.0,0.3333333333333333,0.0,0.5,0.5,1.0,0.4444444444444444,0.4444444444444444,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,0.8888888888888888,Printf uses getlogin() to cause segfault,"I'm new to C, so I apologize if the answer is obvious, I've searched elsewhere.

the libraries I'm including are:

#include &lt;unistd.h&gt;
#include &lt;stdio.h&gt;
#include &lt;string.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;sys/wait.h&gt; 
#include &lt;fcntl.h&gt;
#include &lt;sys/stat.h&gt;


the code that is failing is:

    char *USER = getlogin();
    char CWD[128];

    if (USER == NULL)
        printf(""cry\n"");

    getcwd(CWD, sizeof(CWD));
    printf(""this prints\n"");
    printf(USER);
    printf(""this does not\n"");
    printf(""%s@myshell:%s&gt; "", USER, CWD);


cry does not print, so that should mean that getlogin is successful.  the segfault is caused on printf(USER);

further testing shows that the folling block prints entirely

    printf(""this prints\n"");
    printf(USER);
    printf(""this prints\n"");


but the folling block will print this prints end then segfault without showing USER

    printf(""this prints\n"");
    printf(USER);


EDIT:

Sorry for wasting your time.  I accidentally deleted an fgets that was supposed to follow it and that was causing the segfault.  I've been on this bug for a couple hours now, I love it when the problem is so small.

Thanks
","You should check getcwd return value. According to man page of getcwd:


  If the length of the absolute pathname of the current working
  directory, including the terminating null byte, exceeds size bytes,
  NULL is returned, and errno is set to ERANGE; an application should
  check for this error, and allocate a larger buffer if necessary.

"
5250,5250,8348,uniformly continuous functions and measures,"Consider  a sequence of measures for which $\int f \, \mathrm{d}\mu_{n} \to \int f \,  \mathrm{d}\mu$ for all uniformly continuous functions $f$. Is it true that $\mu_n \to \mu$ strongly?
",user24367,https://math.stackexchange.com/users/17523,"Consider $\mu_n$ an approximation to the identity; e.g. $$\mu_n = \frac n 2 \chi_{[-1/n, 1/n]} \lambda$$ for $\lambda$ the Lebesgue measure. Then $\int f\ d\mu_n \to \int f\ d\delta = f(0)$ for all continuous $f$; but $\mu_n({0})=0\to0\ne1=\delta({0})$.
",Anthony Carapetis,https://math.stackexchange.com/users/28513,http://math.stackexchange.com/questions/500032/uniformly-continuous-functions-and-measures,SCIENCE,math.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,0.6666666666666666,1.0,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.5555555555555556,1.0,0.5555555555555556,1.0,1.0,0.7333333333333333,0.3333333333333333,0.3333333333333333,0.3333333333333333,1.0,Uniform continuous function and measure,"Consider a sequence of measures with $\ INTF \, \ mathrm {D} \ mu {n} \ to \ INTF \, \ mathrm {D} \ Mu $for all uniformly continuous functions $f $. Is it true that $\ mu_n \ to \ Mu $is very strong?","Consider $$muin $$an approximate identity; for example, $$Munn = \ frac N 2 \ CI {[- 1 / N, 1 / N]} \ lambda $$lambda $leberg measure. For all consecutive $f $, then $\ INTF \ D \ mu_n \ to \ INTF \ D \ delta = f (0) $; but $\ mu_n ({0}) = 0 \ to0 \ ne1 = \ Delta ({0}) $."
1310,1310,2064,Parsing a Text to only see specific data,"I have the following text lines:

.add 7971 [Player: Sunfire (Account: 11309) X: 5839.623047 Y: 600.437439 Z: 650.839722 Map: 571 Selected player: Llubia (GUID: 19369)]  
.add 43956 [Player: Sunfire (Account: 11309) X: 5277.887695 Y: 2862.181641 Z: 446.735931 Map: 571 Selected none:  (GUID: 0)]  
.add 43956 [Player: Sunfire (Account: 11309) X: 5281.407715 Y: 2864.844482 Z: 446.735931 Map: 571 Selected player: Staticbaby (GUID: 19826)]  
.add 43956 [Player: Sunfire (Account: 11309) X: 5231.464844 Y: 1437.029175 Z: 648.498535 Map: 571 Selected player: Sunfire (GUID: 15295)]  
.add 44077 [Player: Sunfire (Account: 11309) X: 5231.464844 Y: 1437.029175 Z: 648.498535 Map: 571 Selected player: Sunfire (GUID: 15295)]  
.add 49285 [Player: Sunfire (Account: 11309) X: 16225.323242 Y: 16252.759766 Z: 12.790466 Map: 1 Selected none:  (GUID: 0)]  
.add 44115 175 [Player: Elmasguapo (Account: 11309) X: 1659.845093 Y: -4198.589844 Z: 56.382870 Map: 1 Selected none:  (GUID: 0)]  
.add 34078 [Player: Sunfire (Account: 11309) X: 16227.969727 Y: 16280.081055 Z: 13.175169 Map: 1 Selected none:  (GUID: 0)]  
.add  |cffffffff|Hitem:41427:0:0:0:0:0:0:0:80|h[Fuego de Artificio de Dalaran]|h|r 50 [Player: Sunfire (Account: 11309) X: 16221.392578 Y: 16260.944336 Z: 13.255954 Map: 1 Selected none:  (GUID: 0)]  
.add  |cffffffff|Hitem:45932:0:0:0:0:0:0:0:80|h[Gelatina Negra]|h|r [Player: Sunfire (Account: 11309) X: 5874.347168 Y: 679.056763 Z: 167.483719 Map: 571 Selected player: Assasins (GUID: 19438)]  
.add  |cffffffff|Hitem:45932:0:0:0:0:0:0:0:80|h[Gelatina Negra]|h|r [Player: Sunfire (Account: 11309) X: 5873.767090 Y: 679.386841 Z: 167.435257 Map: 571 Selected player: Assasins (GUID: 19438)]  
.add  |cffffffff|Hitem:45932:0:0:0:0:0:0:0:80|h[Gelatina Negra]|h|r [Player: Sunfire (Account: 11309) X: 16226.880859 Y: 16247.247070 Z: 12.286857 Map: 1 Selected player: Irmtarget (GUID: 18521)]  
.add  |cffffffff|Hitem:45932:0:0:0:0:0:0:0:80|h[Gelatina Negra]|h|r [Player: Sunfire (Account: 11309) X: 16229.297852 Y: 16251.202148 Z: 13.081388 Map: 1 Selected player: Irmtarget (GUID: 18521)]  
.add 41600 2 [Player: Sunfire (Account: 11309) X: 16223.138672 Y: 16250.496094 Z: 12.431313 Map: 1 Selected player: Eifreen (GUID: 20341)]  
.add 41600 1 [Player: Sunfire (Account: 11309) X: 16223.138672 Y: 16250.496094 Z: 12.431313 Map: 1 Selected player: Eifreen (GUID: 20341)]  
.add 40516 [Player: Sunfire (Account: 11309) X: 16223.138672 Y: 16250.496094 Z: 12.431313 Map: 1 Selected player: Eifreen (GUID: 20341)]  
.add 44661 [Player: Sunfire (Account: 11309) X: 16223.138672 Y: 16250.496094 Z: 12.431313 Map: 1 Selected player: Eifreen (GUID: 20341)]  
.add 40518 [Player: Sunfire (Account: 11309) X: 16223.138672 Y: 16250.496094 Z: 12.431313 Map: 1 Selected player: Eifreen (GUID: 20341)]  
.add 44005 [Player: Sunfire (Account: 11309) X: 16223.138672 Y: 16250.496094 Z: 12.431313 Map: 1 Selected player: Eifreen (GUID: 20341)]  
.add 45867 [Player: Sunfire (Account: 11309) X: 16223.138672 Y: 16250.496094 Z: 12.431313 Map: 1 Selected player: Eifreen (GUID: 20341)]  
.add 45316 [Player: Sunfire (Account: 11309) X: 16223.138672 Y: 16250.496094 Z: 12.431313 Map: 1 Selected player: Eifreen (GUID: 20341)]  


And I want to parse it so it outputs something like this:

Line 1 For example - 7971 Llubia
Line 3 For example - 43956 Staticbaby
Line 9 For Example - 45932 Assassins

And so on.. This is done in the terminal with commands like cut, grep, cat, etc..

UPDATE: Here is the whole file: http://paste2.org/p/1744102 to parse in that way.

UPDATE2: Please forgive me if I do not accept an answer just yet. Am waiting for the bounty option to appear since for me, stuff like this deserve a bounty. So I will add a bounty and give it to the correct answer or answers.
",Luis Alvarado,https://askubuntu.com/users/7035,"It's not really feasible to use command line tools to parse irregular ouput.  Would be better to use python, etc..  

If you had complete regularity, e.g., you could use something as simple as:

awk '{print $2 "" "" $17}' INPUT


This misses the 'Hitem' lines from your example. 

This is an ugly hack, but it takes the 'Hitem' lines into account:

 sed 's/^.*Hitem:\([0-9]*\):0/\1/' INPUT | awk -F: '{print $1 "" "" $0}' | sed 's/\.add //' | sed 's/^\([0-9]* \).*Selected player: \([A-Za-z]* \).*$/\1 \2/' | egrep -v 'Selected none'


Which gave me:  

7971  Llubia 
43956  Staticbaby 
43956  Sunfire 
44077  Sunfire 
45932  Assasins 
45932  Assasins 
45932  Irmtarget 
45932  Irmtarget 
41600  Eifreen 
41600  Eifreen 
40516  Eifreen 
44661  Eifreen 
40518  Eifreen 
44005  Eifreen 
45867  Eifreen 
45316  Eifreen 


This fails on the additional info you've added, however, which is why I've added the comments/caveat about regularity here.
",belacqua,https://askubuntu.com/users/8844,http://askubuntu.com/questions/73311/parsing-a-text-to-only-see-specific-data,TECHNOLOGY,askubuntu.com,0.7777777777777778,0.4444444444444444,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,0.8,0.6666666666666666,0.0,0.3333333333333333,0.8888888888888888,Analyze text to view only specific data,"I have the following text lines:

.add 7971 [Player: Sunfire (Account: 11309) X: 5839.623047 Y: 600.437439 Z: 650.839722 Map: 571 Selected player: Llubia (GUID: 19369)]  
.add 43956 [Player: Sunfire (Account: 11309) X: 5277.887695 Y: 2862.181641 Z: 446.735931 Map: 571 Selected none:  (GUID: 0)]  
.add 43956 [Player: Sunfire (Account: 11309) X: 5281.407715 Y: 2864.844482 Z: 446.735931 Map: 571 Selected player: Staticbaby (GUID: 19826)]  
.add 43956 [Player: Sunfire (Account: 11309) X: 5231.464844 Y: 1437.029175 Z: 648.498535 Map: 571 Selected player: Sunfire (GUID: 15295)]  
.add 44077 [Player: Sunfire (Account: 11309) X: 5231.464844 Y: 1437.029175 Z: 648.498535 Map: 571 Selected player: Sunfire (GUID: 15295)]  
.add 49285 [Player: Sunfire (Account: 11309) X: 16225.323242 Y: 16252.759766 Z: 12.790466 Map: 1 Selected none:  (GUID: 0)]  
.add 44115 175 [Player: Elmasguapo (Account: 11309) X: 1659.845093 Y: -4198.589844 Z: 56.382870 Map: 1 Selected none:  (GUID: 0)]  
.add 34078 [Player: Sunfire (Account: 11309) X: 16227.969727 Y: 16280.081055 Z: 13.175169 Map: 1 Selected none:  (GUID: 0)]  
.add  |cffffffff|Hitem:41427:0:0:0:0:0:0:0:80|h[Fuego de Artificio de Dalaran]|h|r 50 [Player: Sunfire (Account: 11309) X: 16221.392578 Y: 16260.944336 Z: 13.255954 Map: 1 Selected none:  (GUID: 0)]  
.add  |cffffffff|Hitem:45932:0:0:0:0:0:0:0:80|h[Gelatina Negra]|h|r [Player: Sunfire (Account: 11309) X: 5874.347168 Y: 679.056763 Z: 167.483719 Map: 571 Selected player: Assasins (GUID: 19438)]  
.add  |cffffffff|Hitem:45932:0:0:0:0:0:0:0:80|h[Gelatina Negra]|h|r [Player: Sunfire (Account: 11309) X: 5873.767090 Y: 679.386841 Z: 167.435257 Map: 571 Selected player: Assasins (GUID: 19438)]  
.add  |cffffffff|Hitem:45932:0:0:0:0:0:0:0:80|h[Gelatina Negra]|h|r [Player: Sunfire (Account: 11309) X: 16226.880859 Y: 16247.247070 Z: 12.286857 Map: 1 Selected player: Irmtarget (GUID: 18521)]  
.add  |cffffffff|Hitem:45932:0:0:0:0:0:0:0:80|h[Gelatina Negra]|h|r [Player: Sunfire (Account: 11309) X: 16229.297852 Y: 16251.202148 Z: 13.081388 Map: 1 Selected player: Irmtarget (GUID: 18521)]  
.add 41600 2 [Player: Sunfire (Account: 11309) X: 16223.138672 Y: 16250.496094 Z: 12.431313 Map: 1 Selected player: Eifreen (GUID: 20341)]  
.add 41600 1 [Player: Sunfire (Account: 11309) X: 16223.138672 Y: 16250.496094 Z: 12.431313 Map: 1 Selected player: Eifreen (GUID: 20341)]  
.add 40516 [Player: Sunfire (Account: 11309) X: 16223.138672 Y: 16250.496094 Z: 12.431313 Map: 1 Selected player: Eifreen (GUID: 20341)]  
.add 44661 [Player: Sunfire (Account: 11309) X: 16223.138672 Y: 16250.496094 Z: 12.431313 Map: 1 Selected player: Eifreen (GUID: 20341)]  
.add 40518 [Player: Sunfire (Account: 11309) X: 16223.138672 Y: 16250.496094 Z: 12.431313 Map: 1 Selected player: Eifreen (GUID: 20341)]  
.add 44005 [Player: Sunfire (Account: 11309) X: 16223.138672 Y: 16250.496094 Z: 12.431313 Map: 1 Selected player: Eifreen (GUID: 20341)]  
.add 45867 [Player: Sunfire (Account: 11309) X: 16223.138672 Y: 16250.496094 Z: 12.431313 Map: 1 Selected player: Eifreen (GUID: 20341)]  
.add 45316 [Player: Sunfire (Account: 11309) X: 16223.138672 Y: 16250.496094 Z: 12.431313 Map: 1 Selected player: Eifreen (GUID: 20341)]  


And I want to parse it so it outputs something like this:

Line 1 For example - 7971 Llubia
Line 3 For example - 43956 Staticbaby
Line 9 For Example - 45932 Assassins

And so on.. This is done in the terminal with commands like cut, grep, cat, etc..

UPDATE: Here is the whole file: http://paste2.org/p/1744102 to parse in that way.

UPDATE2: Please forgive me if I do not accept an answer just yet. Am waiting for the bounty option to appear since for me, stuff like this deserve a bounty. So I will add a bounty and give it to the correct answer or answers.
","It's not really feasible to use command line tools to parse irregular ouput.  Would be better to use python, etc..  

If you had complete regularity, e.g., you could use something as simple as:

awk '{print $2 "" "" $17}' INPUT


This misses the 'Hitem' lines from your example. 

This is an ugly hack, but it takes the 'Hitem' lines into account:

 sed 's/^.*Hitem:\([0-9]*\):0/\1/' INPUT | awk -F: '{print $1 "" "" $0}' | sed 's/\.add //' | sed 's/^\([0-9]* \).*Selected player: \([A-Za-z]* \).*$/\1 \2/' | egrep -v 'Selected none'


Which gave me:  

7971  Llubia 
43956  Staticbaby 
43956  Sunfire 
44077  Sunfire 
45932  Assasins 
45932  Assasins 
45932  Irmtarget 
45932  Irmtarget 
41600  Eifreen 
41600  Eifreen 
40516  Eifreen 
44661  Eifreen 
40518  Eifreen 
44005  Eifreen 
45867  Eifreen 
45316  Eifreen 


This fails on the additional info you've added, however, which is why I've added the comments/caveat about regularity here.
"
1498,1498,2360,Hard Disk Speed for Virt Laptop,"If I want to run a few dev VMs on a laptop, how fast do my drives realistically need to be?  I do not expect lightning fast performance, but the last time I tried this on a Lenovo Thinkpad T400, suspending to disk takes forever, and the host OS (Windows 7 x64 Professional) grinds to a halt with VMWare Workstation 6.5.  I understand this is going to happen, and this is not the right platform in general, but how much better would I have it with a 7200 RPM drive?  Are there faster drives available?  I really want to have the flexibility of VMs on the go, and it takes 3+ or 4+ minutes the last time I tried.  The current one is really crappy.  I am shopping for a new computer anyway, and I was hoping someone could tell me this is a worthwhile consideration for now and the future or just a pipedream.
",songei2f,https://serverfault.com/users/40097,"You don't mention the memory on your system, the speed of the processor, what load you normally run, what you're doing in the VM's...Some of it might be in the links, but for the sake of the question it wouldn't have been all that hard to just post what your system has so people answering don't have to chase links.

Nor do you really say what's acceptable for speed (or perceived speed). That's the biggest issue that specs can't give...what do you consider acceptable?

Best answer I can offer is that 7200 RPM drives would help a little. SSD drives should really speed it up. Bump memory up as much as your system will accept and you'll see another nice boost.
",Bart Silverstrim,https://serverfault.com/users/13647,http://serverfault.com/questions/240323,TECHNOLOGY,serverfault.com,0.7777777777777778,0.4444444444444444,0.0,0.5,1.0,0.5,0.6666666666666666,0.5555555555555556,0.6666666666666666,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.6666666666666667,0.6666666666666666,0.0,1.0,1.0,Hard disk speed of virt laptop,"If I want to run several dev VMS on a laptop, how fast does my drive actually need to be? I don't expect lightning fast performance, but the last time I tried this feature on Lenovo's ThinkPad T400, it took forever to hang to disk, while the host operating system (windows 7x64 professional) gradually stopped on VMware Workstation 6.5. I know it's going to happen, it's not the right platform, but how good am I to have a 7200 RPM drive? Do you have a faster drive? I really want to use VMS flexibly on VO, and try for 3 to 4 minutes for the last time. The one now is really bad. Anyway, I'm buying a new computer, and I hope someone can tell me that it's a present and future worth considering, or just a fantasy.","You don't mention the memory on your system, the speed of the processor, what load you normally run, what you're doing in the VM's...Some of it might be in the links, but for the sake of the question it wouldn't have been all that hard to just post what your system has so people answering don't have to chase links.

Nor do you really say what's acceptable for speed (or perceived speed). That's the biggest issue that specs can't give...what do you consider acceptable?

Best answer I can offer is that 7200 RPM drives would help a little. SSD drives should really speed it up. Bump memory up as much as your system will accept and you'll see another nice boost.
"
26,26,36,How can I write HTML and send as an email?,"I want to send HTML email from my Outlook or Yahoo, Gmail, Hotmail. I wasn't able to find any such option where I could write HTML which will then be rendered at the receiver's end. How can I do that?
",Umair Jabbar,https://webapps.stackexchange.com/users/2676,"HTML in email clients is a very very thorny problem because most of them do not just embed a browser, but implement random subsets of the HTML and CSS. And there is a LOT of email clients.

If you really do need to do this, you may look at professional solutions from Mailing List Marketing companies. It is a known problem in that space and there are services, tutorials (example) and checklists for that. Here is a service from MailChimp. Most of the providers offer something similar.
",Alexandre Rafalovitch,https://webapps.stackexchange.com/users/2820,http://webapps.stackexchange.com/questions/7932/how-can-i-write-html-and-send-as-an-email,TECHNOLOGY,webapps.stackexchange.com,1.0,0.8888888888888888,0.0,0.6666666666666666,1.0,0.6666666666666666,0.7777777777777778,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.8888888888888888,0.5555555555555556,1.0,1.0,0.7333333333333333,0.0,0.0,1.0,1.0,How do I write HTML and send it as an email?,"I want to send HTML messages from my outlook or Yahoo, Gmail, hotmail. I can't find any of these options, I can write HTML and then render it at the end of the receiver. What shall I do?","HTML in email clients is a very very thorny problem because most of them do not just embed a browser, but implement random subsets of the HTML and CSS. And there is a LOT of email clients.

If you really do need to do this, you may look at professional solutions from Mailing List Marketing companies. It is a known problem in that space and there are services, tutorials (example) and checklists for that. Here is a service from MailChimp. Most of the providers offer something similar.
"
1191,1191,1873,AppleScript: how to get the current directory of the topmost Terminal,"I want to get the current directory of the topmost Terminal tab/window (via AppleScript or something else, it doesn't really matter). How can I do that?
",Albert,https://stackoverflow.com/users/133374,"Ok, I have one solution.

get_foregroundterminal_proclist.scpt:

tell application ""Terminal""
    do shell script ""fuser "" &amp; (tty of front tab of front window)
end tell


get_foregroundterminal_curdir.sh:

#!/bin/bash

function pwdx {
    lsof -a -p $1 -d cwd -n | tail -1 | awk '{print $NF}'
}

for pid in $(osascript ""$(dirname ""$0"")/get_foregroundterminal_proclist.scpt""); do
    pwdx $pid
    break # break on first
done

",Albert,https://stackoverflow.com/users/133374,http://stackoverflow.com/questions/5290299/applescript-how-to-get-the-current-directory-of-the-topmost-terminal,STACKOVERFLOW,stackoverflow.com,1.0,0.6666666666666666,0.0,1.0,1.0,1.0,0.5555555555555556,0.5555555555555556,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.0,0.0,0.8888888888888888,Applescript: how to get the current directory of the top terminal,"I want to get the current directory of the topmost terminal tab / window (it doesn't matter, by Applescript or otherwise). What shall I do?","Ok, I have one solution.

get_foregroundterminal_proclist.scpt:

tell application ""Terminal""
    do shell script ""fuser "" &amp; (tty of front tab of front window)
end tell


get_foregroundterminal_curdir.sh:

#!/bin/bash

function pwdx {
    lsof -a -p $1 -d cwd -n | tail -1 | awk '{print $NF}'
}

for pid in $(osascript ""$(dirname ""$0"")/get_foregroundterminal_proclist.scpt""); do
    pwdx $pid
    break # break on first
done

"
3848,3848,6117,Scipy Fast 1-D interpolation without any loop,"I have two 2D array, x(ni, nj) and y(ni,nj), that I need to interpolate over one axis. I want to interpolate along last axis for every ni.

I wrote

import numpy as np
from scipy.interpolate import interp1d

z = np.asarray([200,300,400,500,600])
out = []
for i in range(ni):
    f = interp1d(x[i,:], y[i,:], kind='linear')
    out.append(f(z))
out = np.asarray(out)


However, I think this method is inefficient and slow due to loop if array size is too large. What is the fastest way to interpolate multi-dimensional array like this? Is there any way to perform linear and cubic interpolation without loop? Thanks.
",Tetsuro,https://stackoverflow.com/users/1979961,"One optimization is to allocate the result array once like so:

import numpy as np
from scipy.interpolate import interp1d

z = np.asarray([200,300,400,500,600])
out = np.zeros( [ni, len(z)], dtype=np.float32 ) 
for i in range(ni):
    f = interp1d(x[i,:], y[i,:], kind='linear')
    out[i,:]=f(z)


This will save you some memory copying that occurs in your implementation, which occurs in the calls to out.append(...).
",Dave,https://stackoverflow.com/users/1497199,http://stackoverflow.com/questions/14559687/scipy-fast-1-d-interpolation-without-any-loop,STACKOVERFLOW,stackoverflow.com,0.6666666666666666,0.5555555555555556,0.0,0.0,1.0,1.0,0.5555555555555556,0.3333333333333333,0.3333333333333333,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.6666666666666666,1.0,0.5555555555555556,1.0,1.0,0.8,0.6666666666666666,0.3333333333333333,0.0,0.7777777777777778,SciPy fast one-dimensional interpolation without any loop,"I have two 2D array, x(ni, nj) and y(ni,nj), that I need to interpolate over one axis. I want to interpolate along last axis for every ni.

I wrote

import numpy as np
from scipy.interpolate import interp1d

z = np.asarray([200,300,400,500,600])
out = []
for i in range(ni):
    f = interp1d(x[i,:], y[i,:], kind='linear')
    out.append(f(z))
out = np.asarray(out)


However, I think this method is inefficient and slow due to loop if array size is too large. What is the fastest way to interpolate multi-dimensional array like this? Is there any way to perform linear and cubic interpolation without loop? Thanks.
","One optimization is to allocate the result array once like so:

import numpy as np
from scipy.interpolate import interp1d

z = np.asarray([200,300,400,500,600])
out = np.zeros( [ni, len(z)], dtype=np.float32 ) 
for i in range(ni):
    f = interp1d(x[i,:], y[i,:], kind='linear')
    out[i,:]=f(z)


This will save you some memory copying that occurs in your implementation, which occurs in the calls to out.append(...).
"
5839,5839,9252,Python Condensing Code,"My code is pretty long and I need help condensing it to make it more convenient. The code I have is suppose to do the set of instructions I commanded it to do on a fluke robot. I am using python. The robot is suppose to do the following code using it sensors. I need help condensing it.

EDIT:

My code: 

from Myro import *
from Graphics import *
init('/dev/tty.IPRE6-366079-DevB')

def markYellow(pic):
    for pix in getPixels(pic):
        r = getRed(pix)
        g = getGreen(pix)
        b = getBlue(pix)
        if r &gt; 200 and b &lt; 90 and g &gt; 150:
            setRed(pix,255)
            setGreen(pix,255)
            setBlue(pix,255)
        else:
            setRed(pix,0)
            setGreen(pix,0)
            setBlue(pix,0)

def pctMarked(pic):
    totalPixels = 0
    whitePixels = 0
    for pix in getPixels(pic):
        if getRed(pix) == 255:
            whitePixels = whitePixels + 1
        totalPixels = totalPixels + 1
    result = whitePixels / float(totalPixels)
    return result


def findAvgX(pic):
    pixelCount  = 0
    totalXCount = 0
    for pix in getPixels(pic):
        if getRed(pix) == 255:
            x = getX(pix)
            totalXCount = totalXCount + x
            pixelCount = pixelCount + 1
    avgX = totalXCount / float( pixelCount)
    return avgX


def turn():
    findAvgX(pic)
    if wallLocation &lt;= 85:
        turnLeft(1,0.25)
    elif ballLocation &gt;= 170:
        turnRight(1,0.25)


def celebrate():
    move(0.25,1)
    beep(1,800)
    beep(1,1600)
    beep(1,800)
    stop()

def main():
    p = takePicture()
    markYellow(p)
    pctMarked(p)
    while pctMarked(pic) &lt; 0.2: 
        rotate(1,1)
        p = takePicture()
        markYellow(p)
        pctMarked(p)
    turn()
    while getObstacle('center')&gt; 1000: # I'm not sure about the number. We can test it tomorrow
        forward(1,1)
    celebrate()

",Q.matin,https://stackoverflow.com/users/1670186,"# helper functions
def getRGB(pix):
    return getRed(pix), getGreen(pix), getBlue(pix)

def setRGB(pix, r, g, b):
    setRed(pix,r)
    setGreen(pix,g)
    setBlue(pix,b)

def markYellow(pic):
    for pix in getPixels(pic):
        r, g, b = getRGB(pix)
        if r &gt; 200 and b &lt; 90 and g &gt; 150:
            setRGB(pix, 255, 255, 255) 
        else:
            setRGB(pix, 0, 0, 0)

def pctMarked(pic):
    # is there a more direct way to get the totalPixels?
    # totalPixels = len(pic) # perhaps?
    totalPixels = sum(1 for pix in getPixels(pic))
    whitePixels = sum(getRGB(pix) == (255, 255, 255) for pix in getPixels(pic))
    return whitePixels / float(totalPixels)

",John La Rooy,https://stackoverflow.com/users/174728,http://stackoverflow.com/questions/13169971/python-condensing-code,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.4444444444444444,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.8888888888888888,0.8888888888888888,0.5,0.8888888888888888,1.0,0.9,1.0,0.0,0.0,0.8333333333333334,Python compressed code,"My code is pretty long and I need help condensing it to make it more convenient. The code I have is suppose to do the set of instructions I commanded it to do on a fluke robot. I am using python. The robot is suppose to do the following code using it sensors. I need help condensing it.

EDIT:

My code: 

from Myro import *
from Graphics import *
init('/dev/tty.IPRE6-366079-DevB')

def markYellow(pic):
    for pix in getPixels(pic):
        r = getRed(pix)
        g = getGreen(pix)
        b = getBlue(pix)
        if r &gt; 200 and b &lt; 90 and g &gt; 150:
            setRed(pix,255)
            setGreen(pix,255)
            setBlue(pix,255)
        else:
            setRed(pix,0)
            setGreen(pix,0)
            setBlue(pix,0)

def pctMarked(pic):
    totalPixels = 0
    whitePixels = 0
    for pix in getPixels(pic):
        if getRed(pix) == 255:
            whitePixels = whitePixels + 1
        totalPixels = totalPixels + 1
    result = whitePixels / float(totalPixels)
    return result


def findAvgX(pic):
    pixelCount  = 0
    totalXCount = 0
    for pix in getPixels(pic):
        if getRed(pix) == 255:
            x = getX(pix)
            totalXCount = totalXCount + x
            pixelCount = pixelCount + 1
    avgX = totalXCount / float( pixelCount)
    return avgX


def turn():
    findAvgX(pic)
    if wallLocation &lt;= 85:
        turnLeft(1,0.25)
    elif ballLocation &gt;= 170:
        turnRight(1,0.25)


def celebrate():
    move(0.25,1)
    beep(1,800)
    beep(1,1600)
    beep(1,800)
    stop()

def main():
    p = takePicture()
    markYellow(p)
    pctMarked(p)
    while pctMarked(pic) &lt; 0.2: 
        rotate(1,1)
        p = takePicture()
        markYellow(p)
        pctMarked(p)
    turn()
    while getObstacle('center')&gt; 1000: # I'm not sure about the number. We can test it tomorrow
        forward(1,1)
    celebrate()

","# helper functions
def getRGB(pix):
    return getRed(pix), getGreen(pix), getBlue(pix)

def setRGB(pix, r, g, b):
    setRed(pix,r)
    setGreen(pix,g)
    setBlue(pix,b)

def markYellow(pic):
    for pix in getPixels(pic):
        r, g, b = getRGB(pix)
        if r &gt; 200 and b &lt; 90 and g &gt; 150:
            setRGB(pix, 255, 255, 255) 
        else:
            setRGB(pix, 0, 0, 0)

def pctMarked(pic):
    # is there a more direct way to get the totalPixels?
    # totalPixels = len(pic) # perhaps?
    totalPixels = sum(1 for pix in getPixels(pic))
    whitePixels = sum(getRGB(pix) == (255, 255, 255) for pix in getPixels(pic))
    return whitePixels / float(totalPixels)

"
5183,5183,8235,Why isn't my if/elseif/else working correctly here?,"I am using a simple if/elseif/else bit of code to generate a header image for my page, I can't seem to understand why it isn't working properly. It determines the category of the page being displayed and displays a header accordingly. Here's the code in my header.php: 

&lt;?php if (is_category('dino run') || has_category('dino run')) { ?&gt;
    &lt;a href=""dino-run/""&gt;&lt;li&gt;&lt;div class=""logo splash2""&gt;Dino Run&lt;/div&gt;&lt;/li&gt;&lt;/a&gt;           
&lt;?php } elseif (is_category('potatoman') || has_category('potatoman')) { ?&gt;
    &lt;a href=""http://www.pixeljam.com/potatoman/""&gt;&lt;div class=""logo splash4""&gt;Potatoman Seeks the Troof&lt;/div&gt;&lt;/a&gt;
&lt;?php } elseif (is_category('glorkian' || 'glork') || has_category('glorkian' || 'glork')) { ?&gt;
    &lt;a href=""glorkian""&gt;&lt;div class=""logo splash3""&gt;Glorkian Warrior&lt;/div&gt;&lt;/a&gt;
&lt;?php } else { ?&gt;
        &lt;a href=""#""&gt;&lt;div class=""logo splash1""&gt;The Pixeljam Octology&lt;/div&gt;&lt;/a&gt;
&lt;?php } ?&gt;


The problem I'm having is I click on a post that has a category ""Dino Run"" and it displays fine... but when I click on a post that doesn't have any of the above 3 defined categories it doesn't fall through to the else statement, it actually displays the third header ""Glorkian Warrior"".

Any ideas what I did wrong here?
",ChaBuku Bakke,https://wordpress.stackexchange.com/users/44564,"I would use: 

in_category('cat-slug') ) { 


if you want to display the image on all posts in the category.

Here's a working example i wrote and tested.

This returns true on both the category archive page and all posts in the category

if(is_home())

echo '&lt;div class=""home-header""&gt;&lt;img src=""http://yourdomain.com/path/to/image.png"" alt=""category header image"" /&gt;&lt;/div&gt;';

elseif(in_category('category-1') )

echo '&lt;div class=""category-one-header""&gt;&lt;img src=""http://yourdomain.com/path/to/image.png"" alt=""category header image"" /&gt;&lt;/div&gt;';

elseif(in_category('category-2') )

echo '&lt;div class=""category-two-header""&gt;&lt;img src=""http://yourdomain.com/path/to/image.png"" alt=""category header image"" /&gt;&lt;/div&gt;';

elseif(in_category('category-3') )

echo '&lt;div class=""category-three-header""&gt;&lt;img src=""http://yourdomain.com/path/to/image.png"" alt=""category header image"" /&gt;&lt;/div&gt;';

elseif(in_category('category-4') )

echo '&lt;div class=""category-four-header""&gt;&lt;img src=""http://yourdomain.com/path/to/image.png"" alt=""category header image"" /&gt;&lt;/div&gt;';

}


Related info

Another option would be to use the code from the Twenty Eleven themes header.php file which enables you to use the built in Add Featured Image meta box to display unique headers on different posts and pages without adding any code.

Or you could easily add conditionals and else if statements to that code which is a more efficient solution.
",Brad Dalton,https://wordpress.stackexchange.com/users/9884,http://wordpress.stackexchange.com/questions/129127/why-isnt-my-if-elseif-else-working-correctly-here,TECHNOLOGY,wordpress.stackexchange.com,0.6666666666666666,0.4444444444444444,0.0,0.0,1.0,0.0,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.9,1.0,0.0,0.0,0.8888888888888888,Why can't my if / else if / else work here?,"I am using a simple if/elseif/else bit of code to generate a header image for my page, I can't seem to understand why it isn't working properly. It determines the category of the page being displayed and displays a header accordingly. Here's the code in my header.php: 

&lt;?php if (is_category('dino run') || has_category('dino run')) { ?&gt;
    &lt;a href=""dino-run/""&gt;&lt;li&gt;&lt;div class=""logo splash2""&gt;Dino Run&lt;/div&gt;&lt;/li&gt;&lt;/a&gt;           
&lt;?php } elseif (is_category('potatoman') || has_category('potatoman')) { ?&gt;
    &lt;a href=""http://www.pixeljam.com/potatoman/""&gt;&lt;div class=""logo splash4""&gt;Potatoman Seeks the Troof&lt;/div&gt;&lt;/a&gt;
&lt;?php } elseif (is_category('glorkian' || 'glork') || has_category('glorkian' || 'glork')) { ?&gt;
    &lt;a href=""glorkian""&gt;&lt;div class=""logo splash3""&gt;Glorkian Warrior&lt;/div&gt;&lt;/a&gt;
&lt;?php } else { ?&gt;
        &lt;a href=""#""&gt;&lt;div class=""logo splash1""&gt;The Pixeljam Octology&lt;/div&gt;&lt;/a&gt;
&lt;?php } ?&gt;


The problem I'm having is I click on a post that has a category ""Dino Run"" and it displays fine... but when I click on a post that doesn't have any of the above 3 defined categories it doesn't fall through to the else statement, it actually displays the third header ""Glorkian Warrior"".

Any ideas what I did wrong here?
","I would use: 

in_category('cat-slug') ) { 


if you want to display the image on all posts in the category.

Here's a working example i wrote and tested.

This returns true on both the category archive page and all posts in the category

if(is_home())

echo '&lt;div class=""home-header""&gt;&lt;img src=""http://yourdomain.com/path/to/image.png"" alt=""category header image"" /&gt;&lt;/div&gt;';

elseif(in_category('category-1') )

echo '&lt;div class=""category-one-header""&gt;&lt;img src=""http://yourdomain.com/path/to/image.png"" alt=""category header image"" /&gt;&lt;/div&gt;';

elseif(in_category('category-2') )

echo '&lt;div class=""category-two-header""&gt;&lt;img src=""http://yourdomain.com/path/to/image.png"" alt=""category header image"" /&gt;&lt;/div&gt;';

elseif(in_category('category-3') )

echo '&lt;div class=""category-three-header""&gt;&lt;img src=""http://yourdomain.com/path/to/image.png"" alt=""category header image"" /&gt;&lt;/div&gt;';

elseif(in_category('category-4') )

echo '&lt;div class=""category-four-header""&gt;&lt;img src=""http://yourdomain.com/path/to/image.png"" alt=""category header image"" /&gt;&lt;/div&gt;';

}


Related info

Another option would be to use the code from the Twenty Eleven themes header.php file which enables you to use the built in Add Featured Image meta box to display unique headers on different posts and pages without adding any code.

Or you could easily add conditionals and else if statements to that code which is a more efficient solution.
"
1737,1737,2747,How long does it take for a calf to be full grown in Harvest Moon A New Beginning?,"How long does it take for a calf to be full grown in Harvest Moon A New Beginning?
And for that fact, what about the other animals? (chicks, sheeps, you get the deal)
",MaryAnn,https://gaming.stackexchange.com/users/66145,"According to this source, cows have a pregnancy period of 21 days, followed by another 20 days until adolescence. While the source is somewhat incomplete, I would hazard a guess that sheep and alpaca have the same pre-adolescent period since they share the same pregnancy period of 21 days.

Chickens, on the other hand, have an incubation period of 7 days (since you put eggs in the hatcher, rather then get them pregnant), followed by 8 days until adolescence.

Note that this source is incomplete for higher quality breeds such as Jersey cows and Silkie chickens, but from my experience with previous games in the series (such as Tale of Two Towns), they should share the same pregnancy/incubation/adolescence period as the base livestock.
",Yuuki,https://gaming.stackexchange.com/users/27975,http://gaming.stackexchange.com/questions/149850/how-long-does-it-take-for-a-calf-to-be-full-grown-in-harvest-moon-a-new-beginnin,CULTURE,gaming.stackexchange.com,1.0,0.8888888888888888,0.0,1.0,1.0,1.0,0.6666666666666666,0.4444444444444444,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.3333333333333333,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.3333333333333333,0.6666666666666666,1.0,How long does it take for a calf to grow into a new beginning on the harvest moon?,"How long does it take for a calf to be full grown in Harvest Moon A New Beginning?
And for that fact, what about the other animals? (chicks, sheeps, you get the deal)
","According to this source, cows have a pregnancy period of 21 days, followed by another 20 days until adolescence. While the source is somewhat incomplete, I would hazard a guess that sheep and alpaca have the same pre-adolescent period since they share the same pregnancy period of 21 days.

Chickens, on the other hand, have an incubation period of 7 days (since you put eggs in the hatcher, rather then get them pregnant), followed by 8 days until adolescence.

Note that this source is incomplete for higher quality breeds such as Jersey cows and Silkie chickens, but from my experience with previous games in the series (such as Tale of Two Towns), they should share the same pregnancy/incubation/adolescence period as the base livestock.
"
2504,2504,3994,Is it safe to eat freshwater fish raw?,"According to this question freshwater fish should not be used in Ceviche--why not?
",Jay,https://cooking.stackexchange.com/users/2299,"Salmon is a fresh water fish that is regularly used for sushi, however it needs to go through extra preparation. Typically it needs to be frozen at -31F for seven days to kill whatever parasites are in there.
",cspirou,https://cooking.stackexchange.com/users/19277,http://cooking.stackexchange.com/questions/7268/is-it-safe-to-eat-freshwater-fish-raw,LIFE_ARTS,cooking.stackexchange.com,1.0,1.0,0.3333333333333333,1.0,0.6666666666666666,0.6666666666666666,0.8888888888888888,0.8888888888888888,0.3333333333333333,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,1.0,Is it safe to eat fresh water fish raw?,"According to this question, freshwater fish should not be used in the womb - why not?","Salmon is a fresh water fish that is regularly used for sushi, however it needs to go through extra preparation. Typically it needs to be frozen at -31F for seven days to kill whatever parasites are in there.
"
1482,1482,2331,Access admin for sub directory website,"I have a website at http://www.avantalarm.com/ and I've created a development site at http://www.avantalarm.com/dev/ and everything seems to be working fine, however when I go to http://www.avantalarm.com/dev/admin to reach the development admin page, it redirects me to the main admin page for my main site.  I don't know a ton about .htaccess and I'm not sure if that's the problem, but I'd love to be able to reach my dev site's admin page.  Any help would be appreciated.  If I can offer up any code let me know.
",jonullberg,https://magento.stackexchange.com/users/755,"You can access you admin on the dev website. https://www.avantalarm.com/dev/index.php/admin
I don't know what can cause this. Maybe it's a custom extension. I saw that you are using BalkeTechnologies_StoreMaintenance that has a custom router. Could  be that.
Anyway you now can acccess the admin on the dev website.
[Edit]
Also the base url should be changed in core_config_data.
",Marius,https://magento.stackexchange.com/users/146,http://magento.stackexchange.com/questions/4093/access-admin-for-sub-directory-website,TECHNOLOGY,magento.stackexchange.com,0.6666666666666666,0.4444444444444444,0.0,1.0,0.6666666666666666,0.5,0.6666666666666666,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.8888888888888888,1.0,0.7777777777777778,1.0,1.0,0.9333333333333332,0.6666666666666666,0.0,0.3333333333333333,0.8888888888888888,Administrators accessing subdirectory sites,"I have a website at http://www.avantalarm.com/. I created a development site at http://www.avantalarm.com/dev/. Everything looks good, but when I go to http://www.avantalarm.com/dev/admin to visit the development management page, it will redirect me to the main management page of the main site. I don't know about. Htaccess, and I'm not sure if that's the problem, but I'd love to be able to access the administration page of my developer site. Any help will be appreciated. If I can provide any code, please let me know.","You can access you admin on the dev website. https://www.avantalarm.com/dev/index.php/admin
I don't know what can cause this. Maybe it's a custom extension. I saw that you are using BalkeTechnologies_StoreMaintenance that has a custom router. Could  be that.
Anyway you now can acccess the admin on the dev website.
[Edit]
Also the base url should be changed in core_config_data.
"
1503,1503,2366,UNIX semaphores,"I wrote an example program about UNIX semaphores, where a process and its child lock/unlock the same semaphore. I would appreciate your feedback about what I could improve in my C style. Generally I feel that the program flow is hard to read because of all those error checks, but I didn't find a better way to write it. It's also breaking the rule of ""one vertical screen maximum per function"" but I don't see a logical way to split it into functions.

#include &lt;semaphore.h&gt;
#include &lt;stdio.h&gt;
#include &lt;errno.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;unistd.h&gt;
#include &lt;sys/types.h&gt;
#include &lt;sys/stat.h&gt;
#include &lt;fcntl.h&gt;
#include &lt;sys/mman.h&gt;

int main(void)
{ 
  /* place semaphore in shared memory */
  sem_t *sema = mmap(NULL, sizeof(sema), 
          PROT_READ |PROT_WRITE,MAP_SHARED|MAP_ANONYMOUS, -1, 0);
  if (!sema) {
    perror(""Out of memory"");
    exit(EXIT_FAILURE);
  }

  /* create, initialize semaphore */
  if (sem_init(sema, 1, 0) &lt; 0) {
    perror(""semaphore initilization"");
    exit(EXIT_FAILURE);
  }

  int i, nloop=10;
  int ret = fork();
  if (ret &lt; 0) {
    perror(""fork failed"");
    exit(EXIT_FAILURE);
  }

  if (ret == 0) { 
    /* child process*/
    for (i = 0; i &lt; nloop; i++) {
      printf(""child unlocks semaphore: %d\n"", i);
      sem_post(sema);
      sleep(1);
    }
    if (munmap(sema, sizeof(sema)) &lt; 0) {
      perror(""munmap failed"");
      exit(EXIT_FAILURE);
    }
    exit(EXIT_SUCCESS);
  }

  if (ret &gt; 0) {
    /* back to parent process */
    for (i = 0; i &lt; nloop; i++) {
      printf(""parent starts waiting: %d\n"", i);
      sem_wait(sema);
      printf(""parent finished waiting: %d\n"", i);
    }
    if (sem_destroy(sema) &lt; 0) {
      perror(""sem_destroy failed"");
      exit(EXIT_FAILURE);
    }
    if (munmap(sema, sizeof(sema)) &lt; 0) {
      perror(""munmap failed"");
      exit(EXIT_FAILURE);
    }
    exit(EXIT_SUCCESS);
  }
}

",Étienne,https://codereview.stackexchange.com/users/25742,"One thing to note:

sem_t *sema = mmap(NULL, sizeof(sema), 
         PROT_READ |PROT_WRITE,MAP_SHARED|MAP_ANONYMOUS, -1, 0);
if (!sema) {


Failure in mmap will return MAP_FAILED, not NULL (usually I think MAP_FAILED expands to -1 cast to a pointer, meaning your failure check won't work).

As for style: This is just an opinion, but I think your style could benefit from the concept of a ""cleanup block"".

For example, instead of this kind of style [paraphrasing your code, not doing literal quotes]:

sema = mmap(/* ... */);

if (sema == MAP_FAILED)
{
   exit(EXIT_FAILURE);
}

foo = malloc(sizeof(*foo));
if (!foo)
{
   exit(EXIT_FAILURE);
}


You could do something like:

   int status = EXIT_FAILURE;
   sem_t *sema = NULL;
   struct foo *foo = NULL;

   sema = mmap(/* ... */);

   if (sema == MAP_FAILED)
   {
      goto cleanup;
   }

   foo = malloc(sizeof(*foo));
   if (!foo)
   {
      goto cleanup;
   }

   // TODO: do stuff with sema and foo

   // mark success
   status = EXIT_SUCCESS;

cleanup:
   if (sema &amp;&amp; sema != MAP_FAILED)
      munmap(sema, /* ... */);
   if (foo)
      free(foo);

   return status;


The benefit to this kind of style is that you can add any type of allocation you want (in between the other stuff, before it, after it, whatever), and you just need to add a quick line or two in the cleanup block, and suddenly, all success and failure paths get the resources freed.  If any of the intermediate steps fail and you wind up in the cleanup block, you can be assured that you're not leaking anything, and it won't feel repetitive to make that happen.

There are other variants of this, for example if you or someone you're working with has some religious objection to goto (even though it's the cleanest way to do error handling in plain C), on the slightly more repetitive side you could repeatedly check status to see that you're still succeeding:

int status = EXIT_SUCCESS;
sem_t *sema = NULL;
struct foo *foo = NULL;

if (status == EXIT_SUCCESS)
{
   sema = mmap(/* ... */);

   if (sema == MAP_FAILED)
   {
      status = EXIT_FAILURE;
   }
}

if (status == EXIT_SUCCESS)
{
   foo = malloc(sizeof(*foo));
   if (!foo)
   {
      status = EXIT_FAILURE;
   }
}

if (status == EXIT_SUCCESS)
{
   // TODO: do stuff with sema and foo
}

if (sema &amp;&amp; sema != MAP_FAILED)
   munmap(sema, /* ... */);
if (foo)
   free(foo);

return status;

",asveikau,https://codereview.stackexchange.com/users/4029,http://codereview.stackexchange.com/questions/27000/unix-semaphores,TECHNOLOGY,codereview.stackexchange.com,0.7777777777777778,0.3333333333333333,0.3333333333333333,0.5,0.0,0.0,0.6666666666666666,0.4444444444444444,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.8888888888888888,1.0,0.6666666666666666,0.8888888888888888,1.0,0.8,0.0,0.3333333333333333,1.0,1.0,UNIX semaphore,"I wrote an example program about UNIX semaphores, where a process and its child lock/unlock the same semaphore. I would appreciate your feedback about what I could improve in my C style. Generally I feel that the program flow is hard to read because of all those error checks, but I didn't find a better way to write it. It's also breaking the rule of ""one vertical screen maximum per function"" but I don't see a logical way to split it into functions.

#include &lt;semaphore.h&gt;
#include &lt;stdio.h&gt;
#include &lt;errno.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;unistd.h&gt;
#include &lt;sys/types.h&gt;
#include &lt;sys/stat.h&gt;
#include &lt;fcntl.h&gt;
#include &lt;sys/mman.h&gt;

int main(void)
{ 
  /* place semaphore in shared memory */
  sem_t *sema = mmap(NULL, sizeof(sema), 
          PROT_READ |PROT_WRITE,MAP_SHARED|MAP_ANONYMOUS, -1, 0);
  if (!sema) {
    perror(""Out of memory"");
    exit(EXIT_FAILURE);
  }

  /* create, initialize semaphore */
  if (sem_init(sema, 1, 0) &lt; 0) {
    perror(""semaphore initilization"");
    exit(EXIT_FAILURE);
  }

  int i, nloop=10;
  int ret = fork();
  if (ret &lt; 0) {
    perror(""fork failed"");
    exit(EXIT_FAILURE);
  }

  if (ret == 0) { 
    /* child process*/
    for (i = 0; i &lt; nloop; i++) {
      printf(""child unlocks semaphore: %d\n"", i);
      sem_post(sema);
      sleep(1);
    }
    if (munmap(sema, sizeof(sema)) &lt; 0) {
      perror(""munmap failed"");
      exit(EXIT_FAILURE);
    }
    exit(EXIT_SUCCESS);
  }

  if (ret &gt; 0) {
    /* back to parent process */
    for (i = 0; i &lt; nloop; i++) {
      printf(""parent starts waiting: %d\n"", i);
      sem_wait(sema);
      printf(""parent finished waiting: %d\n"", i);
    }
    if (sem_destroy(sema) &lt; 0) {
      perror(""sem_destroy failed"");
      exit(EXIT_FAILURE);
    }
    if (munmap(sema, sizeof(sema)) &lt; 0) {
      perror(""munmap failed"");
      exit(EXIT_FAILURE);
    }
    exit(EXIT_SUCCESS);
  }
}

","One thing to note:

sem_t *sema = mmap(NULL, sizeof(sema), 
         PROT_READ |PROT_WRITE,MAP_SHARED|MAP_ANONYMOUS, -1, 0);
if (!sema) {


Failure in mmap will return MAP_FAILED, not NULL (usually I think MAP_FAILED expands to -1 cast to a pointer, meaning your failure check won't work).

As for style: This is just an opinion, but I think your style could benefit from the concept of a ""cleanup block"".

For example, instead of this kind of style [paraphrasing your code, not doing literal quotes]:

sema = mmap(/* ... */);

if (sema == MAP_FAILED)
{
   exit(EXIT_FAILURE);
}

foo = malloc(sizeof(*foo));
if (!foo)
{
   exit(EXIT_FAILURE);
}


You could do something like:

   int status = EXIT_FAILURE;
   sem_t *sema = NULL;
   struct foo *foo = NULL;

   sema = mmap(/* ... */);

   if (sema == MAP_FAILED)
   {
      goto cleanup;
   }

   foo = malloc(sizeof(*foo));
   if (!foo)
   {
      goto cleanup;
   }

   // TODO: do stuff with sema and foo

   // mark success
   status = EXIT_SUCCESS;

cleanup:
   if (sema &amp;&amp; sema != MAP_FAILED)
      munmap(sema, /* ... */);
   if (foo)
      free(foo);

   return status;


The benefit to this kind of style is that you can add any type of allocation you want (in between the other stuff, before it, after it, whatever), and you just need to add a quick line or two in the cleanup block, and suddenly, all success and failure paths get the resources freed.  If any of the intermediate steps fail and you wind up in the cleanup block, you can be assured that you're not leaking anything, and it won't feel repetitive to make that happen.

There are other variants of this, for example if you or someone you're working with has some religious objection to goto (even though it's the cleanest way to do error handling in plain C), on the slightly more repetitive side you could repeatedly check status to see that you're still succeeding:

int status = EXIT_SUCCESS;
sem_t *sema = NULL;
struct foo *foo = NULL;

if (status == EXIT_SUCCESS)
{
   sema = mmap(/* ... */);

   if (sema == MAP_FAILED)
   {
      status = EXIT_FAILURE;
   }
}

if (status == EXIT_SUCCESS)
{
   foo = malloc(sizeof(*foo));
   if (!foo)
   {
      status = EXIT_FAILURE;
   }
}

if (status == EXIT_SUCCESS)
{
   // TODO: do stuff with sema and foo
}

if (sema &amp;&amp; sema != MAP_FAILED)
   munmap(sema, /* ... */);
if (foo)
   free(foo);

return status;

"
4998,4998,7957,How to undo card archive on Trello?,"I accidentally hit c with a card selected and archived the card. I tried to undo the archive but couldn't find the option. I tried moving the card back to the list but that didn't seem to work.
",wting,https://webapps.stackexchange.com/users/16677,"You can also visit your profile and see the audit trail of what you've done to each card, which includes a link to the archived card. Then you can ""move"" the card back to the board.
",greeni,https://webapps.stackexchange.com/users/62417,http://webapps.stackexchange.com/questions/24271/how-to-undo-card-archive-on-trello,TECHNOLOGY,webapps.stackexchange.com,1.0,1.0,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.4444444444444444,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.8888888888888888,0.7777777777777778,0.6666666666666666,0.8888888888888888,1.0,0.8,0.6666666666666666,0.3333333333333333,0.0,0.8888888888888888,How do I undo the card archive on trello?,"I accidentally typed C with a selected card and saved it. I tried to undo the archive, but I couldn't find the option. I tried to move the card back to the list, but it didn't seem to work.","You can also visit your profile to see your audit trail for each card, including a link to the archive card. Then you can ""move"" the card back to the blackboard."
1400,1400,2207,What platform can I use to establish a users support forum?,"I was asked to develop a users support community forum for a small and young hi-tech company. This kind of forums is very popular with companies these days and is a great alternative to the official product support lines. An example of what we look for is the Analog Devices' Engineer Zone forums.

I am totally noob to this area so any advice will be appreciated - how to start developing such a site, what platforms are available (preferably open-source/free) and what are the advantages and disadvantages of these platforms.

Is a stackexchange style forum appropriate for such site?

* If you think there is a better SE site to post this question, please let me know.
",ysap,https://webmasters.stackexchange.com/users/9535,"We have been using OSQA (a free software StackExchange clone) which is quite useful for public-access queries. (Note however that OSQA is not very actively developed, so AskBot might be a better choice these days.)

However, we haven't seen a lot of buy-in from our clients and partners, which may be related to our non-consumer industry, so they may not be used to using the public web professionally (in some cases, not even LinkedIn). So we're in the process of putting together a login-only bbPress forum, since our sysadmin suggested they might feel a bit more secure there (emotionally and technologically). We are planning to treat posts something like tickets, for example by encouraging users to mark them as solved, etc.

So the short answer is, the Q&amp;A interface has incredible utility and I hope it becomes the norm, but if you find it doesn't gain traction with your userbase, a forum (possibly private) might be a better answer.
",d3vid,https://webmasters.stackexchange.com/users/27825,http://webmasters.stackexchange.com/questions/18090/what-platform-can-i-use-to-establish-a-users-support-forum,TECHNOLOGY,webmasters.stackexchange.com,1.0,0.5555555555555556,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,1.0,0.8888888888888888,0.8,0.3333333333333333,0.0,0.6666666666666666,0.8888888888888888,What platform can I use to set up user support forum?,"I was asked to develop a users support community forum for a small and young hi-tech company. This kind of forums is very popular with companies these days and is a great alternative to the official product support lines. An example of what we look for is the Analog Devices' Engineer Zone forums.

I am totally noob to this area so any advice will be appreciated - how to start developing such a site, what platforms are available (preferably open-source/free) and what are the advantages and disadvantages of these platforms.

Is a stackexchange style forum appropriate for such site?

* If you think there is a better SE site to post this question, please let me know.
","We have been using OSQA (a free software StackExchange clone) which is quite useful for public-access queries. (Note however that OSQA is not very actively developed, so AskBot might be a better choice these days.)

However, we haven't seen a lot of buy-in from our clients and partners, which may be related to our non-consumer industry, so they may not be used to using the public web professionally (in some cases, not even LinkedIn). So we're in the process of putting together a login-only bbPress forum, since our sysadmin suggested they might feel a bit more secure there (emotionally and technologically). We are planning to treat posts something like tickets, for example by encouraging users to mark them as solved, etc.

So the short answer is, the Q&amp;A interface has incredible utility and I hope it becomes the norm, but if you find it doesn't gain traction with your userbase, a forum (possibly private) might be a better answer.
"
84,84,139,I want to build a portable railgun and I'm a complete rookie,"I'd like to enter the world of electronic hobbies by making a railgun, and so far I know that I understand the basics of the device and that I need high amounts of direct current.

However, I am puzzled, as to where to begin calculating. I'd like to set myself X amount of joules/kjoules of electric energy and work from that, but I know stuff like rail length and how the rails push eachother apart would affect performance, so I'd like to know;


How Farads relate to Joules (I know the J/V^2 formula but that wasn't clear enough)?
Should I opt for a single powerful capacitor or a bunch of smaller ones, especially since I want to unload the charge as fast as possible?
What kind of conductive metal should I use that would be both conductive enough for acceleration and durable enough to resist the recoil and other forces involved?
How should I cool it or deal with the heat? 
Would there be much heat to begin with in a portable railgun?
Would ABS coating be a proper body for the gun, protecting the user from the lethal amperages that will be involved?
How exactly does rail length help the case, as I would use a bipod for a long rifle if that will increase my efficiency?
Would it be a better idea to have conductive bullets, insulated bullets with discarding and conductive sabots, or a stable aperture that will simply stop at the end of the barrel by whatever means I can come up with while letting the unbound insulated bullet out? 
Should I keep my circuit simple as to just use switches, a battery, capacitor, and some LEDs, or are there more efficient circuit components?
I'd like to have a control mechanism that lights the Red LED when it is charging, green when it is charged, how can I do that? In my simple sketchup of the circuit I have V-switches (don't know the technical name) aligned in a way that the lights should light correctly during the course of my planned three stage trigger, but better ideas are obviously welcome.
Will a capacitor lose its current when neither of the ends are connected to a complete circuit but both of them have wires attached to them? I am guessing not but better safe than sorry.
Is there a way to make sure the capacitor has depleted its entire charge? 
What would be a good idea to improve safety and efficiency?


Thanks in advance!
",lychnus,https://electronics.stackexchange.com/users/23933,"A 10g projectile moving at 100m/s has a kinetic energy given by 1/2 m (v^2), ie 50J.

Assume 10% efficiency, so you need to supply 500J from the capacitor bank. Assume we're using your 16milifard suggested number. Rearrange F = J/V^2 to V = sqrt(J/F). That yields a comparatively modest 176V. Of course, that's the energy in fully charging them, and you can't use all of it due to the voltage drop.

Assume a 50cm rail and a stationary projectile to start (in practice they're launched in mechanically). By s = (v1 + v2) t/2 that gives us 1/100s time of acceleration. That yields an instantaneous power of 50kW and current of ~280A. Delivering that kind of current requires extremely low resistance wiring and busbars and will be quite hard to achieve in a portable design. I suspect that a practical design will use a higher voltage to offset this problem and offset the voltage drop as the capacitors discharge. Perhaps only the top 10-20% of charge can be used effectively.

Putting switches in the power path is to be avoided as the current will tend to weld them shut.

Heat issues: one shot will dump a few hundred J of heat into the rails and air around them. Air cooling will do for low rates of fire.

Safety: is a relative term. You're never going to get this thing CE approved. Shrouding the whole thing in ABS (or PVC piping) to keep fingers away from high voltage, temperature, and moving parts is a good start. I'd apply an insulating varnish or conformal coating to all exposed metal on the internals (except rail active surfaces) as well, as an attempt at double-insulation and to keep out moisture.

Charge indicator: this is really the least of your problems. Start with a voltmeter.

Cap discharge: they will stay charged to lethal voltages! ""Bleeder resistors"" are usually used to drain them off. Note that discharging a 500J pack through a 1W resistor will have to take at least 500 seconds. Voltmeter comes in handy here for watching the discharge.

Sabot: I don't think this is normally done, and it complicates the whole thing hugely.

Construction: you have a bit of a mechanical engineering problem in ensuring that the rails are securely fixed but at the same time electrically isolated from each other and the chassis. You can get insulators to fit around screws and bolts, but the clearance required to do this at kV levels may be a problem.

Getting the rails parallel enough and contacting the projectile without too much friction or arcing is also going to be a problem.
",pjc50,https://electronics.stackexchange.com/users/2228,http://electronics.stackexchange.com/questions/69366/i-want-to-build-a-portable-railgun-and-im-a-complete-rookie,TECHNOLOGY,electronics.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,0.3333333333333333,1.0,0.6666666666666666,0.6666666666666666,0.5555555555555556,1.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.0,0.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,1.0,0.6666666666666666,0.8888888888888888,I want to be a portable railgun. I'm a rookie,"I'd like to enter the world of electronic hobbies by making a railgun, and so far I know that I understand the basics of the device and that I need high amounts of direct current.

However, I am puzzled, as to where to begin calculating. I'd like to set myself X amount of joules/kjoules of electric energy and work from that, but I know stuff like rail length and how the rails push eachother apart would affect performance, so I'd like to know;


How Farads relate to Joules (I know the J/V^2 formula but that wasn't clear enough)?
Should I opt for a single powerful capacitor or a bunch of smaller ones, especially since I want to unload the charge as fast as possible?
What kind of conductive metal should I use that would be both conductive enough for acceleration and durable enough to resist the recoil and other forces involved?
How should I cool it or deal with the heat? 
Would there be much heat to begin with in a portable railgun?
Would ABS coating be a proper body for the gun, protecting the user from the lethal amperages that will be involved?
How exactly does rail length help the case, as I would use a bipod for a long rifle if that will increase my efficiency?
Would it be a better idea to have conductive bullets, insulated bullets with discarding and conductive sabots, or a stable aperture that will simply stop at the end of the barrel by whatever means I can come up with while letting the unbound insulated bullet out? 
Should I keep my circuit simple as to just use switches, a battery, capacitor, and some LEDs, or are there more efficient circuit components?
I'd like to have a control mechanism that lights the Red LED when it is charging, green when it is charged, how can I do that? In my simple sketchup of the circuit I have V-switches (don't know the technical name) aligned in a way that the lights should light correctly during the course of my planned three stage trigger, but better ideas are obviously welcome.
Will a capacitor lose its current when neither of the ends are connected to a complete circuit but both of them have wires attached to them? I am guessing not but better safe than sorry.
Is there a way to make sure the capacitor has depleted its entire charge? 
What would be a good idea to improve safety and efficiency?


Thanks in advance!
","A 10g projectile moving at 100m/s has a kinetic energy given by 1/2 m (v^2), ie 50J.

Assume 10% efficiency, so you need to supply 500J from the capacitor bank. Assume we're using your 16milifard suggested number. Rearrange F = J/V^2 to V = sqrt(J/F). That yields a comparatively modest 176V. Of course, that's the energy in fully charging them, and you can't use all of it due to the voltage drop.

Assume a 50cm rail and a stationary projectile to start (in practice they're launched in mechanically). By s = (v1 + v2) t/2 that gives us 1/100s time of acceleration. That yields an instantaneous power of 50kW and current of ~280A. Delivering that kind of current requires extremely low resistance wiring and busbars and will be quite hard to achieve in a portable design. I suspect that a practical design will use a higher voltage to offset this problem and offset the voltage drop as the capacitors discharge. Perhaps only the top 10-20% of charge can be used effectively.

Putting switches in the power path is to be avoided as the current will tend to weld them shut.

Heat issues: one shot will dump a few hundred J of heat into the rails and air around them. Air cooling will do for low rates of fire.

Safety: is a relative term. You're never going to get this thing CE approved. Shrouding the whole thing in ABS (or PVC piping) to keep fingers away from high voltage, temperature, and moving parts is a good start. I'd apply an insulating varnish or conformal coating to all exposed metal on the internals (except rail active surfaces) as well, as an attempt at double-insulation and to keep out moisture.

Charge indicator: this is really the least of your problems. Start with a voltmeter.

Cap discharge: they will stay charged to lethal voltages! ""Bleeder resistors"" are usually used to drain them off. Note that discharging a 500J pack through a 1W resistor will have to take at least 500 seconds. Voltmeter comes in handy here for watching the discharge.

Sabot: I don't think this is normally done, and it complicates the whole thing hugely.

Construction: you have a bit of a mechanical engineering problem in ensuring that the rails are securely fixed but at the same time electrically isolated from each other and the chassis. You can get insulators to fit around screws and bolts, but the clearance required to do this at kV levels may be a problem.

Getting the rails parallel enough and contacting the projectile without too much friction or arcing is also going to be a problem.
"
651,651,1034,Why some Book reference requests are closed and some are not?,"I'm just wondering some Questions (actually book request) are closed ( Good book for beginning android development ) and some questions are not closed (  Best book / resources for learning iOS programming? )?

Is there any specific reason? Or just it was overlooked by the community?

Update

The second question is closed now
",Walid Hossain,https://meta.stackexchange.com/users/171962,"Just overlooked.  They used to be acceptable back when the site first started, so there are an awful lot of them.  We just haven't had time to go through and clean them all up yet.  The one you linked to is now closed.
",Bill the Lizard,https://meta.stackexchange.com/users/1288,http://meta.stackexchange.com/questions/114330,TECHNOLOGY,meta.stackexchange.com,0.5555555555555556,0.5555555555555556,0.0,0.3333333333333333,1.0,0.3333333333333333,0.6666666666666666,0.4444444444444444,0.6666666666666666,0.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.4444444444444444,0.8888888888888888,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,0.8888888888888888,Why are some book reference requests closed and others not?,I just want to know that some problems (actually Book requests) are over (good books to start Android Development) and some problems are not over (the best books / resources to learn IOS programming?) ?,"Just overlooked.  They used to be acceptable back when the site first started, so there are an awful lot of them.  We just haven't had time to go through and clean them all up yet.  The one you linked to is now closed.
"
1110,1110,1745,"Where are the fishing spots surrounded by rocks etc, and do they actually increase the chances of catching fish?","While talking to the fisher guy in the fishing hut he told me the best place to fish was in small places surrounded be rocks or wall. 

Is this true? If so, where are theses places in the game? Is there anything else that helps to catch more fish? 

For example, I have noticed that fishing next to a fisherman seems to have a higher chance of catching something. is this correct, and what else helps with fishing?
",Qwertie,https://gaming.stackexchange.com/users/57500,"Trent's answer gives a solid overview of chain fishing in general. To complement that, here are some of the best areas for chain fishing.

Note that each spot is surrounded on 3 sides with rocks or cliff.

This spot is just below Ambrette Town (courtesy of this guide). Exit the Museum onto the Sand, then double back along the cliffs:



Then there's Shalour City, Route 8 and Route 21 (guide)

Shalour:


Route 8:


Route 21:


These are just some of the areas where it is possible, there are many others. Look around, try and find more!
",Robotnik,https://gaming.stackexchange.com/users/28182,http://gaming.stackexchange.com/questions/153619/where-are-the-fishing-spots-surrounded-by-rocks-etc-and-do-they-actually-increa,CULTURE,gaming.stackexchange.com,0.8888888888888888,0.7777777777777778,0.0,0.6666666666666666,1.0,0.6666666666666666,0.6666666666666666,0.4444444444444444,1.0,0.0,0.0,0.3333333333333333,0.0,0.3333333333333333,0.0,0.3333333333333333,0.0,0.3333333333333333,0.3333333333333333,0.0,0.7777777777777778,0.7777777777777778,0.3333333333333333,1.0,0.8888888888888888,0.6,0.0,0.0,0.0,0.8888888888888888,"Where are the fishing spots around the rocks, and do they really increase the chances of fishing?","While talking to the fisher guy in the fishing hut he told me the best place to fish was in small places surrounded be rocks or wall. 

Is this true? If so, where are theses places in the game? Is there anything else that helps to catch more fish? 

For example, I have noticed that fishing next to a fisherman seems to have a higher chance of catching something. is this correct, and what else helps with fishing?
","Trent's answer gives a solid overview of chain fishing in general. To complement that, here are some of the best areas for chain fishing.

Note that each spot is surrounded on 3 sides with rocks or cliff.

This spot is just below Ambrette Town (courtesy of this guide). Exit the Museum onto the Sand, then double back along the cliffs:



Then there's Shalour City, Route 8 and Route 21 (guide)

Shalour:


Route 8:


Route 21:


These are just some of the areas where it is possible, there are many others. Look around, try and find more!
"
1759,1759,2787,Sodium Bisulfate vs Sodium Bisulfite,"I'm wanting to do a follow up to this Q&amp;A in the cooking stack regarding browning avocados. I specifically want to expand my experiment to to include the options in Wayfaring Stranger's Answer. Unfortunately, I managed to get the wrong stuff, and shipping rules make exchanging it problematic.

I am the proud owner of $500~\mathrm{g}$ of sodium bisulfate ($\ce{NaHSO4}$), instead of sodium bisulfite ($\ce{NaHSO3}$).

Dammit Jim! I'm a cook not a chemist!

What I have learned is that that both compounds are used as food additives towards the same end, and that my stuff has a slightly higher LD50. That's it.

Can anyone advise as to substituting my compound for the other? I'm not interested in tasty guacamole at this point, I'm really only looking at browning. If I'm trying to more or less duplicate the more successful experiments of the University of Florida, should I start with the same ratios? Or more or less of the additive? I can get sodium metabisulfite (also an anti-oxidant food additive) locally, if that would be a better option.

EDIT: So far, answers have all been consistent in that I have a half-kilo of white powder that is useless to me. I will make a trip to the wine-making shop and acquire some sodium metabisulfite. That still leaves me with the question of how much? The University of Florida got the results I'd like to duplicate with $30~\mathrm{mg}$ of sodium bisulfite per $100~\mathrm{g}$ of avocado. Should I start with the same ratio of sodium metabisulfite?
",Jolenealaska,https://chemistry.stackexchange.com/users/8265,"Sodium bisulfate will also control browning. It works by lowering the pH to inhibit the polyphenol oxidase enzyme. It lowers pH without a sour taste so it does not change the flavor of the food. 
",user16167,https://chemistry.stackexchange.com/users/16167,http://chemistry.stackexchange.com/questions/17321/sodium-bisulfate-vs-sodium-bisulfite,SCIENCE,chemistry.stackexchange.com,1.0,0.3333333333333333,0.0,0.3333333333333333,1.0,1.0,0.4444444444444444,0.4444444444444444,1.0,0.0,0.0,1.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.8888888888888888,0.7777777777777778,0.4444444444444444,0.8888888888888888,0.8888888888888888,0.6,0.0,0.3333333333333333,0.6666666666666666,0.8888888888888888,Sodium bisulfite vs sodium bisulfite,"I'm wanting to do a follow up to this Q&amp;A in the cooking stack regarding browning avocados. I specifically want to expand my experiment to to include the options in Wayfaring Stranger's Answer. Unfortunately, I managed to get the wrong stuff, and shipping rules make exchanging it problematic.

I am the proud owner of $500~\mathrm{g}$ of sodium bisulfate ($\ce{NaHSO4}$), instead of sodium bisulfite ($\ce{NaHSO3}$).

Dammit Jim! I'm a cook not a chemist!

What I have learned is that that both compounds are used as food additives towards the same end, and that my stuff has a slightly higher LD50. That's it.

Can anyone advise as to substituting my compound for the other? I'm not interested in tasty guacamole at this point, I'm really only looking at browning. If I'm trying to more or less duplicate the more successful experiments of the University of Florida, should I start with the same ratios? Or more or less of the additive? I can get sodium metabisulfite (also an anti-oxidant food additive) locally, if that would be a better option.

EDIT: So far, answers have all been consistent in that I have a half-kilo of white powder that is useless to me. I will make a trip to the wine-making shop and acquire some sodium metabisulfite. That still leaves me with the question of how much? The University of Florida got the results I'd like to duplicate with $30~\mathrm{mg}$ of sodium bisulfite per $100~\mathrm{g}$ of avocado. Should I start with the same ratio of sodium metabisulfite?
","Sodium bisulfate will also control browning. It works by lowering the pH to inhibit the polyphenol oxidase enzyme. It lowers pH without a sour taste so it does not change the flavor of the food. 
"
4517,4517,7159,Sodium Bisulfate vs Sodium Bisulfite,"I'm wanting to do a follow up to this Q&amp;A in the cooking stack regarding browning avocados. I specifically want to expand my experiment to to include the options in Wayfaring Stranger's Answer. Unfortunately, I managed to get the wrong stuff, and shipping rules make exchanging it problematic.

I am the proud owner of $500~\mathrm{g}$ of sodium bisulfate ($\ce{NaHSO4}$), instead of sodium bisulfite ($\ce{NaHSO3}$).

Dammit Jim! I'm a cook not a chemist!

What I have learned is that that both compounds are used as food additives towards the same end, and that my stuff has a slightly higher LD50. That's it.

Can anyone advise as to substituting my compound for the other? I'm not interested in tasty guacamole at this point, I'm really only looking at browning. If I'm trying to more or less duplicate the more successful experiments of the University of Florida, should I start with the same ratios? Or more or less of the additive? I can get sodium metabisulfite (also an anti-oxidant food additive) locally, if that would be a better option.

EDIT: So far, answers have all been consistent in that I have a half-kilo of white powder that is useless to me. I will make a trip to the wine-making shop and acquire some sodium metabisulfite. That still leaves me with the question of how much? The University of Florida got the results I'd like to duplicate with $30~\mathrm{mg}$ of sodium bisulfite per $100~\mathrm{g}$ of avocado. Should I start with the same ratio of sodium metabisulfite?
",Jolenealaska,https://chemistry.stackexchange.com/users/8265,"Sulfate will not provide the antioxidant effect you seek.  Metabisulfite has antioxidant effect.
",Brinn Belyea,https://chemistry.stackexchange.com/users/5601,http://chemistry.stackexchange.com/questions/17321/sodium-bisulfate-vs-sodium-bisulfite,SCIENCE,chemistry.stackexchange.com,1.0,0.3333333333333333,0.0,0.6666666666666666,0.3333333333333333,1.0,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.3333333333333333,0.0,0.3333333333333333,0.0,0.5555555555555556,0.7777777777777778,0.5555555555555556,1.0,0.8888888888888888,0.6666666666666667,0.0,0.0,0.6666666666666666,0.8888888888888888,Sodium bisulfite vs sodium bisulfite,"I'm wanting to do a follow up to this Q&amp;A in the cooking stack regarding browning avocados. I specifically want to expand my experiment to to include the options in Wayfaring Stranger's Answer. Unfortunately, I managed to get the wrong stuff, and shipping rules make exchanging it problematic.

I am the proud owner of $500~\mathrm{g}$ of sodium bisulfate ($\ce{NaHSO4}$), instead of sodium bisulfite ($\ce{NaHSO3}$).

Dammit Jim! I'm a cook not a chemist!

What I have learned is that that both compounds are used as food additives towards the same end, and that my stuff has a slightly higher LD50. That's it.

Can anyone advise as to substituting my compound for the other? I'm not interested in tasty guacamole at this point, I'm really only looking at browning. If I'm trying to more or less duplicate the more successful experiments of the University of Florida, should I start with the same ratios? Or more or less of the additive? I can get sodium metabisulfite (also an anti-oxidant food additive) locally, if that would be a better option.

EDIT: So far, answers have all been consistent in that I have a half-kilo of white powder that is useless to me. I will make a trip to the wine-making shop and acquire some sodium metabisulfite. That still leaves me with the question of how much? The University of Florida got the results I'd like to duplicate with $30~\mathrm{mg}$ of sodium bisulfite per $100~\mathrm{g}$ of avocado. Should I start with the same ratio of sodium metabisulfite?
",Sulfates do not provide the antioxidant effect you seek. Sodium pyrosulfite has antioxidant effect.
1064,1064,1675,Are Mintakans related to Vulcans?,"In TNG ""Who Watches the Watchers"" we learn about the Mintakans, who are described as ""proto-Vulcan humanoids"".  Does this mean that the Mintakans come from a common ancestor to the Vulcans, or does it mean that the two species have evolved coincidentally to share many of the same features? (Or not so coincidentally if you take into account that genetic-seeding by the super ancient humanoids.)

We have been shown many species that look completely like humans, and even entire planets that mirror Earth (TOS ""Miri"") and maybe some of those species could be considered ""proto-human humanoids"".

I don't think it has been defined how long Vulcans have had space travel, or if it's even possible the Vulcans evolved from some other species that had space travel earlier, and the Mintakans are some off-shoot of that species.  This could possibly be justified from what Spock says in TOS ""Return to Tomorrow"" where he seems to suggest in response to Sargon and the astrobiology doctor that there are unexplained issues with Vulcans evolving on the planet Vulcan, that they might have been colonized by Sargon's people instead.

Interesting reading:
http://en.memory-alpha.org/wiki/Vulcan_history
",Sean Fahey,https://scifi.stackexchange.com/users/19629,"Nobody knows.

In ""Return to Tomorrow"" Spock speculated that Vulcans might be descended from Sargon's people more than 600,000 years ago. In any case there might be descendants of other colonies of Sargon's people on other planets, who would look a lot like Sargon's people - whose biological bodies were never seen  but believed by Sargon to resemble Earth Humans or Vulcans.

""Balance of terror"" implies that Vulcan conquered and colonized other planets once, and Romulans seemed to be descendants of those warlike and unreformed ancient Vulcans. It is logical to assume that society on Vulcan and Romulus reverted to barbarism as civilization collapsed during the fall of the Vulcan Empire and it took countless thousands of years for Vulcan and Romulus to rebuild civilization and become space traveling societies again.

STTNG ""Gambit"" mentions ruins of Romulan off-shoot cultures on various planets one being two thousand years old. Thus we may deduce that probably the Romulans regain spaceflight abilities several thousand years ago and later lost them and regained them again just a few centuries ago.

Of course many fans believe in a far different chronology based on Diane Duane's novels, with Vulcan and Romulus both keeping interstellar travel abilities for over two thousand years until the time of STTNG. But that contradicts the chronological implications of the various episodes.

In ""The Paradise Syndrome""  Spock mentions that some Vulcan offshoot cultures use musical notation alphabets. That implies that there were at least two known ones which did so and at least one known one which did not.

The people of Rigel V might be descended from Vulcans and/or Sargon's people, since in ""Journey to Babel"" it was said that their physiology was similar to, but not identical with, Vulcan physiology.

And that is about all the information available to decide whether the Mintakans are descended from Vulcans and/or Sargon's b people or evolved independently to be similar to Vulcans.

Except of course that it hardly needs saying that a planet orbiting a star such as Mintaka would not have time to evolve intelligent life and the Mintakans and/or their planet must have been imported from elsewhere, perhaps by the Preservers.
",M A Golding,https://scifi.stackexchange.com/users/13823,http://scifi.stackexchange.com/questions/44952/are-mintakans-related-to-vulcans,LIFE_ARTS,scifi.stackexchange.com,0.8888888888888888,1.0,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.8888888888888888,0.5555555555555556,0.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,1.0,0.8888888888888888,0.8888888888888888,0.8888888888888888,1.0,0.8666666666666666,0.0,0.0,0.6666666666666666,1.0,Do the mintagans have anything to do with the Vulcan?,"In TNG ""Who Watches the Watchers"" we learn about the Mintakans, who are described as ""proto-Vulcan humanoids"".  Does this mean that the Mintakans come from a common ancestor to the Vulcans, or does it mean that the two species have evolved coincidentally to share many of the same features? (Or not so coincidentally if you take into account that genetic-seeding by the super ancient humanoids.)

We have been shown many species that look completely like humans, and even entire planets that mirror Earth (TOS ""Miri"") and maybe some of those species could be considered ""proto-human humanoids"".

I don't think it has been defined how long Vulcans have had space travel, or if it's even possible the Vulcans evolved from some other species that had space travel earlier, and the Mintakans are some off-shoot of that species.  This could possibly be justified from what Spock says in TOS ""Return to Tomorrow"" where he seems to suggest in response to Sargon and the astrobiology doctor that there are unexplained issues with Vulcans evolving on the planet Vulcan, that they might have been colonized by Sargon's people instead.

Interesting reading:
http://en.memory-alpha.org/wiki/Vulcan_history
","Nobody knows.

In ""Return to Tomorrow"" Spock speculated that Vulcans might be descended from Sargon's people more than 600,000 years ago. In any case there might be descendants of other colonies of Sargon's people on other planets, who would look a lot like Sargon's people - whose biological bodies were never seen  but believed by Sargon to resemble Earth Humans or Vulcans.

""Balance of terror"" implies that Vulcan conquered and colonized other planets once, and Romulans seemed to be descendants of those warlike and unreformed ancient Vulcans. It is logical to assume that society on Vulcan and Romulus reverted to barbarism as civilization collapsed during the fall of the Vulcan Empire and it took countless thousands of years for Vulcan and Romulus to rebuild civilization and become space traveling societies again.

STTNG ""Gambit"" mentions ruins of Romulan off-shoot cultures on various planets one being two thousand years old. Thus we may deduce that probably the Romulans regain spaceflight abilities several thousand years ago and later lost them and regained them again just a few centuries ago.

Of course many fans believe in a far different chronology based on Diane Duane's novels, with Vulcan and Romulus both keeping interstellar travel abilities for over two thousand years until the time of STTNG. But that contradicts the chronological implications of the various episodes.

In ""The Paradise Syndrome""  Spock mentions that some Vulcan offshoot cultures use musical notation alphabets. That implies that there were at least two known ones which did so and at least one known one which did not.

The people of Rigel V might be descended from Vulcans and/or Sargon's people, since in ""Journey to Babel"" it was said that their physiology was similar to, but not identical with, Vulcan physiology.

And that is about all the information available to decide whether the Mintakans are descended from Vulcans and/or Sargon's b people or evolved independently to be similar to Vulcans.

Except of course that it hardly needs saying that a planet orbiting a star such as Mintaka would not have time to evolve intelligent life and the Mintakans and/or their planet must have been imported from elsewhere, perhaps by the Preservers.
"
301,301,486,Online broker available in Europe - to buy index funds or ETF with small investments,"So i am trying to start investing periodically some small amounts.
I am particularly interested in index funds or ETF.

I would like to be able buy, track, sell them, and etc online.
There are a lot of online brokers like : TD Ameritrade, etrade and etc. , but i cant seem to find the one that would allow to register fro Europe citizen, like from Denmark. (all the top ones require USA citizenship or etc).

Is there any like that at all ? If not - what other options there are to make such investments ?
",XFaktor,https://money.stackexchange.com/users/17734,"A few ideas to get you started


Go to your newsagent and buy the latest issue of some DIY investing magazine. You should get some commercial on the major players
DumbCoder suggested tdwaterhouse. They have an offshore service (never tried them but the fees look high)
Saxobank has a strong presence in the nordics 
Check this page. They seems to be comparing brokers in the different European countries. Not sure what to think about that their results. If I check for the UK I notice that a lot of the big guys are missing
Use Google

",Jeff,https://money.stackexchange.com/users/13085,http://money.stackexchange.com/questions/33724/online-broker-available-in-europe-to-buy-index-funds-or-etf-with-small-investm,LIFE_ARTS,money.stackexchange.com,1.0,0.6666666666666666,0.0,0.5,1.0,0.5,0.6666666666666666,0.4444444444444444,0.3333333333333333,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,0.0,0.0,0.5555555555555556,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8,0.3333333333333333,0.6666666666666666,0.0,0.6666666666666666,Online brokers in Europe - buying index funds or ETFs with small investments,"So i am trying to start investing periodically some small amounts.
I am particularly interested in index funds or ETF.

I would like to be able buy, track, sell them, and etc online.
There are a lot of online brokers like : TD Ameritrade, etrade and etc. , but i cant seem to find the one that would allow to register fro Europe citizen, like from Denmark. (all the top ones require USA citizenship or etc).

Is there any like that at all ? If not - what other options there are to make such investments ?
","A few ideas to get you started


Go to your newsagent and buy the latest issue of some DIY investing magazine. You should get some commercial on the major players
DumbCoder suggested tdwaterhouse. They have an offshore service (never tried them but the fees look high)
Saxobank has a strong presence in the nordics 
Check this page. They seems to be comparing brokers in the different European countries. Not sure what to think about that their results. If I check for the UK I notice that a lot of the big guys are missing
Use Google

"
243,243,389,Translate C code to assembly code?,"I have to translate this C code to assembly code:

 #include &lt;stdio.h&gt;

 int main(){

 int a, b,c;
 scanf(""%d"",&amp;a);
 scanf(""%d"",&amp;b);
 if (a == b){
   b++;
 } 
 if (a &gt; b){
  c = a;
  a = b;
  b = c;    
 }
 printf(""%d\n"",b-a);
 return 0;
 }  


My code is below, and incomplete.

    rdint %eax        # reading a
    rdint %ebx        # reading b
    irmovl $1, %edi

    subl %eax,%ebx
    addl %ebx, %edi
    je Equal


    irmov1 %eax, %efx  #flagged as invalid line
    irmov1 %ebx, %egx
    irmov1 %ecx, %ehx
    irmovl $0, %eax
    irmovl $0, %ebx
    irmovl $0, %ecx

    addl %eax, %efx    #flagged as invalid line
    addl %ebx, %egx
    addl %ecx, %ehx



    halt


Basically I think it is mostly done, but I have commented next to two lines flagged as invalid when I try to run it, but I'm not sure why they are invalid.  I'm also not sure how to do an if statment for  a > b.  I could use any suggestions from people who know about y86 assembly language.
",user1261445,https://stackoverflow.com/users/1261445,"From what I can find online (1, 2), the only supported registers are: eax, ecx, edx, ebx, esi, edi, esp,  and ebp.

You are requesting non-existent registers (efx and further).

Also irmov is for moving an immediate operand (read: constant numerical value) into a register operand, whereas your irmov1 %eax, %efx has two register operands.

Finally, in computer software there's a huge difference between the character representing digit ""one"" and the character representing letter ""L"". Mind your 1's and l's. I mean irmov1 vs irmovl.
",Alexey Frunze,https://stackoverflow.com/users/968261,http://stackoverflow.com/questions/11422895/translate-c-code-to-assembly-code,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.3333333333333333,0.0,1.0,0.6666666666666666,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,0.3333333333333333,1.0,Translate C code into assembly code?,"I have to translate this C code to assembly code:

 #include &lt;stdio.h&gt;

 int main(){

 int a, b,c;
 scanf(""%d"",&amp;a);
 scanf(""%d"",&amp;b);
 if (a == b){
   b++;
 } 
 if (a &gt; b){
  c = a;
  a = b;
  b = c;    
 }
 printf(""%d\n"",b-a);
 return 0;
 }  


My code is below, and incomplete.

    rdint %eax        # reading a
    rdint %ebx        # reading b
    irmovl $1, %edi

    subl %eax,%ebx
    addl %ebx, %edi
    je Equal


    irmov1 %eax, %efx  #flagged as invalid line
    irmov1 %ebx, %egx
    irmov1 %ecx, %ehx
    irmovl $0, %eax
    irmovl $0, %ebx
    irmovl $0, %ecx

    addl %eax, %efx    #flagged as invalid line
    addl %ebx, %egx
    addl %ecx, %ehx



    halt


Basically I think it is mostly done, but I have commented next to two lines flagged as invalid when I try to run it, but I'm not sure why they are invalid.  I'm also not sure how to do an if statment for  a > b.  I could use any suggestions from people who know about y86 assembly language.
","From what I can find online (1, 2), the only supported registers are: eax, ecx, edx, ebx, esi, edi, esp,  and ebp.

You are requesting non-existent registers (efx and further).

Also irmov is for moving an immediate operand (read: constant numerical value) into a register operand, whereas your irmov1 %eax, %efx has two register operands.

Finally, in computer software there's a huge difference between the character representing digit ""one"" and the character representing letter ""L"". Mind your 1's and l's. I mean irmov1 vs irmovl.
"
5481,5481,8701,Creating fake (test) data,"Is there a module or part of devel module that will auto populate (with fake data) a Content Type a create a dozen or so nodes?
",rgchi,https://drupal.stackexchange.com/users/5966,"If you installed the Devel module, there should be a submodule on the admin/modules page called Devel generate:



Enable it, and you should have some new menu entries in admin/config/development for generating fake conent, menus, terms, users, and vocabularies.
",mpdonadio,https://drupal.stackexchange.com/users/835,http://drupal.stackexchange.com/questions/50952/creating-fake-test-data,TECHNOLOGY,drupal.stackexchange.com,0.6666666666666666,0.3333333333333333,0.0,1.0,1.0,0.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.0,1.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.6666666666666666,0.0,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,0.8,0.0,1.0,0.0,0.7777777777777778,Create fake (test) data,Is there a module or part of the devel module that will automatically populate (with fake data) a content type A to create a dozen nodes?,"If you installed the Devel module, there should be a submodule on the admin/modules page called Devel generate:



Enable it, and you should have some new menu entries in admin/config/development for generating fake conent, menus, terms, users, and vocabularies.
"
5556,5556,8825,Disabled buttons while long running task,"My application has a toolbar and a lot of buttons on it. Some buttons start a long running processes(tasks). At this moment every task executes asynchronously to allow user to do something else while task is executing. Thereby I have a problem: user can click the same button many times to start others same tasks. I have decided to disable button before start task and enable it after finish. Other problem, I should to protect other buttons from pressing (some of these would be disabled after done current tasks). In general, I have to disable all buttons (toolbar) to be sure that user cannot do something dangerous with buttons at transient. My questions are: 

Could someone recommend way to distract users from flickering (disable/enable buttons) or how to involve them in process, how to made them filling that task is not so long?

Maybe I should to execute tasks synchronously and disable all UI for time of execution? 

By the way:
Delay can vary from 1 to 10 sec. About progress bar: it is a difficult to calculate current progress, and it causes some performance degradation (task can be done faster without any additional UI iterations from other threads).  
",igor,https://ux.stackexchange.com/users/79,"If you want to avoid the flickering, you could follow Joel's advice: ""Don't hide or disable menu items"" and when a user presses a toolbar button for something already executing or that would interfere with another executing task, you can then either show a message on why you can't complete the users request or ""cache submitted tasks"" (and have a window of tasks to be executed) or just do as the user requests and execute it again (be aware of synchronisations problems here).
",Marjan Venema,https://ux.stackexchange.com/users/762,http://ux.stackexchange.com/questions/10336/disabled-buttons-while-long-running-task,TECHNOLOGY,ux.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,1.0,1.0,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.0,0.0,0.8888888888888888,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.7777777777777778,0.8,1.0,0.0,0.3333333333333333,1.0,Disable button when running task for a long time,"My app has a toolbar and many buttons. Some buttons start long-running processes (tasks). At this point, each task is executed asynchronously to allow the user to perform other operations while the task is executing. So I ran into a problem: users can click the same button multiple times to start the same task for other users. I decided to disable the button before I started the task and enable it when I finished. Another problem is that I should protect other buttons from being pressed (some of them will be disabled after completing the current task). Generally speaking, I have to disable all buttons (toolbars) to make sure that users can't do dangerous things to buttons in an instant. My question is:","If you want to avoid flickering, you can follow Joel's advice: ""don't hide or disable menu items"". When the user presses the toolbar button, some tasks that have already been executed or will interfere with another task that is being executed. Then, you can display a message explaining the reason why the user's request can't be completed or ""caching submitted tasks"" (with a task window to be executed Or according to the user's request and execute again (please pay attention to the synchronization problem here)."
241,241,386,Why isn't my if/elseif/else working correctly here?,"I am using a simple if/elseif/else bit of code to generate a header image for my page, I can't seem to understand why it isn't working properly. It determines the category of the page being displayed and displays a header accordingly. Here's the code in my header.php: 

&lt;?php if (is_category('dino run') || has_category('dino run')) { ?&gt;
    &lt;a href=""dino-run/""&gt;&lt;li&gt;&lt;div class=""logo splash2""&gt;Dino Run&lt;/div&gt;&lt;/li&gt;&lt;/a&gt;           
&lt;?php } elseif (is_category('potatoman') || has_category('potatoman')) { ?&gt;
    &lt;a href=""http://www.pixeljam.com/potatoman/""&gt;&lt;div class=""logo splash4""&gt;Potatoman Seeks the Troof&lt;/div&gt;&lt;/a&gt;
&lt;?php } elseif (is_category('glorkian' || 'glork') || has_category('glorkian' || 'glork')) { ?&gt;
    &lt;a href=""glorkian""&gt;&lt;div class=""logo splash3""&gt;Glorkian Warrior&lt;/div&gt;&lt;/a&gt;
&lt;?php } else { ?&gt;
        &lt;a href=""#""&gt;&lt;div class=""logo splash1""&gt;The Pixeljam Octology&lt;/div&gt;&lt;/a&gt;
&lt;?php } ?&gt;


The problem I'm having is I click on a post that has a category ""Dino Run"" and it displays fine... but when I click on a post that doesn't have any of the above 3 defined categories it doesn't fall through to the else statement, it actually displays the third header ""Glorkian Warrior"".

Any ideas what I did wrong here?
",ChaBuku Bakke,https://wordpress.stackexchange.com/users/44564,"is_category will not process the logic inside the argument list. This:

is_category('glorkian' || 'glork')


The condition is true on all category pages. What I think is happening is that PHP does parse that argument string, but is always going to be true. Try this:

var_dump('glorkian' || 'glork');


Meaning that what you are doing, essentially, is this:

is_category(true);


That is not a valid argument but the function seems to revert to default functionality-- is this a category archive or not? Obviously, the answer is ""yes"" on any category archive. 

Valid arguments are:


  (mixed) (optional) Category ID, Category Title, Category Slug or Array
  of IDs, names, and slugs. 
  
  http://codex.wordpress.org/Function_Reference/is_category#Parameters


So I believe that what you need is :

is_category(
  array(
    'glorkian',
    'glork'
  )
);


It is the same with has_category.
",s_ha_dum,https://wordpress.stackexchange.com/users/21376,http://wordpress.stackexchange.com/questions/129127/why-isnt-my-if-elseif-else-working-correctly-here,TECHNOLOGY,wordpress.stackexchange.com,1.0,0.3333333333333333,0.0,1.0,1.0,1.0,0.5,0.5,0.5,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.5,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8,0.5,0.0,1.0,0.8333333333333334,Why can't my if / else if / else work here?,"I am using a simple if/elseif/else bit of code to generate a header image for my page, I can't seem to understand why it isn't working properly. It determines the category of the page being displayed and displays a header accordingly. Here's the code in my header.php: 

&lt;?php if (is_category('dino run') || has_category('dino run')) { ?&gt;
    &lt;a href=""dino-run/""&gt;&lt;li&gt;&lt;div class=""logo splash2""&gt;Dino Run&lt;/div&gt;&lt;/li&gt;&lt;/a&gt;           
&lt;?php } elseif (is_category('potatoman') || has_category('potatoman')) { ?&gt;
    &lt;a href=""http://www.pixeljam.com/potatoman/""&gt;&lt;div class=""logo splash4""&gt;Potatoman Seeks the Troof&lt;/div&gt;&lt;/a&gt;
&lt;?php } elseif (is_category('glorkian' || 'glork') || has_category('glorkian' || 'glork')) { ?&gt;
    &lt;a href=""glorkian""&gt;&lt;div class=""logo splash3""&gt;Glorkian Warrior&lt;/div&gt;&lt;/a&gt;
&lt;?php } else { ?&gt;
        &lt;a href=""#""&gt;&lt;div class=""logo splash1""&gt;The Pixeljam Octology&lt;/div&gt;&lt;/a&gt;
&lt;?php } ?&gt;


The problem I'm having is I click on a post that has a category ""Dino Run"" and it displays fine... but when I click on a post that doesn't have any of the above 3 defined categories it doesn't fall through to the else statement, it actually displays the third header ""Glorkian Warrior"".

Any ideas what I did wrong here?
","is_category will not process the logic inside the argument list. This:

is_category('glorkian' || 'glork')


The condition is true on all category pages. What I think is happening is that PHP does parse that argument string, but is always going to be true. Try this:

var_dump('glorkian' || 'glork');


Meaning that what you are doing, essentially, is this:

is_category(true);


That is not a valid argument but the function seems to revert to default functionality-- is this a category archive or not? Obviously, the answer is ""yes"" on any category archive. 

Valid arguments are:


  (mixed) (optional) Category ID, Category Title, Category Slug or Array
  of IDs, names, and slugs. 
  
  http://codex.wordpress.org/Function_Reference/is_category#Parameters


So I believe that what you need is :

is_category(
  array(
    'glorkian',
    'glork'
  )
);


It is the same with has_category.
"
5321,5321,8452,drive 3 phase induction motor with only DC (not pwm) thru each phase,"I've been researching making a driver for a 3 phase induction motor powered by DC source using PWM to approximate sine waves in each phase.

However, the switching speeds of the PWM signal for the rotational speed I want is difficult to obtain with hobby microcontroller boards like the arduino.

Can I just switch the DC directly thru each phase at the correct time only twice per cycle ?  Essentially I would be approximating a sine wave with only 2 different voltages thru the coils, ie: +V and -V (using H bridge circuitry here)

Will this create enough of a rotating magnetic field that sufficient current is induced in the rotor cage ?

What will be the losses in power / efficiency for this, or any other drawbacks for this system ?

The bonus is greatly simplified drive electronics.
",bobjandal,https://electronics.stackexchange.com/users/16361,"If you're switching the DC through 3 half-bridges, this will work just fine. Torque will be uneven at low speeds and waveforms rather nasty, but it'll work.

Beware that turning current OFF fast to an inductive load (i.e. motor) is a good way to generate very high voltages so pay attention to protective diodes. NOT 1N4001s (FAR too slow) but high speed switching, high current diodes from each motor terminal to both supply rails, and overvoltage protection on the rails...

[edit...]
The problem with PWM is not the PWM frequency, but the number of times you have to change it per revolution... 

As you are controlling it with software, there is nothing to stop you using PWM at low speed, and switching to direct (square wave) drive at high speed.
",Brian Drummond,https://electronics.stackexchange.com/users/16324,http://electronics.stackexchange.com/questions/49698/drive-3-phase-induction-motor-with-only-dc-not-pwm-thru-each-phase,TECHNOLOGY,electronics.stackexchange.com,1.0,0.5555555555555556,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.6666666666666666,0.0,1.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,1.0,0.8333333333333334,1.0,1.0,0.9333333333333332,0.3333333333333333,0.0,0.3333333333333333,1.0,Drive DC (non PWM) three-phase induction motor through each phase,"I've been researching making a driver for a 3 phase induction motor powered by DC source using PWM to approximate sine waves in each phase.

However, the switching speeds of the PWM signal for the rotational speed I want is difficult to obtain with hobby microcontroller boards like the arduino.

Can I just switch the DC directly thru each phase at the correct time only twice per cycle ?  Essentially I would be approximating a sine wave with only 2 different voltages thru the coils, ie: +V and -V (using H bridge circuitry here)

Will this create enough of a rotating magnetic field that sufficient current is induced in the rotor cage ?

What will be the losses in power / efficiency for this, or any other drawbacks for this system ?

The bonus is greatly simplified drive electronics.
","If you're switching the DC through 3 half-bridges, this will work just fine. Torque will be uneven at low speeds and waveforms rather nasty, but it'll work.

Beware that turning current OFF fast to an inductive load (i.e. motor) is a good way to generate very high voltages so pay attention to protective diodes. NOT 1N4001s (FAR too slow) but high speed switching, high current diodes from each motor terminal to both supply rails, and overvoltage protection on the rails...

[edit...]
The problem with PWM is not the PWM frequency, but the number of times you have to change it per revolution... 

As you are controlling it with software, there is nothing to stop you using PWM at low speed, and switching to direct (square wave) drive at high speed.
"
4709,4709,7465,Does the <h1> tag get more SEO value if there is no usable keyword in the URL?,"I'm looking at a site for which the domain name and URL do not impart any meaningful data to a search engine.  It does have:


&lt;h1&gt; (eBook name)
&lt;h2&gt; (author - cannot be changed) 
&lt;p&gt; (description)


Do the &lt;h1&gt; and &lt;p&gt; elements provide SEO value?  Those are the only elements in that page that really provide any relevant information to search engines.   I see other sites that use keywords in their URL.

In theory, can the &lt;h1&gt; element be compared to a domain name in terms of SEO value?
",Marek Andreansky,https://webmasters.stackexchange.com/users/35439,"Keywords are not needed in the domain name for a page to rank for that keyword.   Even keywords in the URL path don't help much (see Are keywords in URLs good SEO or needlessly redundant?)

The page title (&lt;title&gt;) is the place where words give the most ranking weight.  Other usages on the page can also help.   

It is important to note that overusing a keyword can actually hurt rankings.   Using a keyword once in the title, once in the h1, and once in the page body is enough.   Using the keyword more than that is unlikely to help rankings.   Using the keyword more than that in ways that make the text awkward to read can cause keyword stuffing penalties.
",Stephen Ostermiller,https://webmasters.stackexchange.com/users/14543,http://webmasters.stackexchange.com/questions/58569/does-the-h1-tag-get-more-seo-value-if-there-is-no-usable-keyword-in-the-url,TECHNOLOGY,webmasters.stackexchange.com,1.0,0.8888888888888888,0.0,0.6666666666666666,1.0,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.6666666666666666,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.0,1.0,1.0,"If no keywords are available in the URL, will the < H1 > tag get more SEO values?","I'm looking at a site for which the domain name and URL do not impart any meaningful data to a search engine.  It does have:


&lt;h1&gt; (eBook name)
&lt;h2&gt; (author - cannot be changed) 
&lt;p&gt; (description)


Do the &lt;h1&gt; and &lt;p&gt; elements provide SEO value?  Those are the only elements in that page that really provide any relevant information to search engines.   I see other sites that use keywords in their URL.

In theory, can the &lt;h1&gt; element be compared to a domain name in terms of SEO value?
","Keywords are not needed in the domain name for a page to rank for that keyword.   Even keywords in the URL path don't help much (see Are keywords in URLs good SEO or needlessly redundant?)

The page title (&lt;title&gt;) is the place where words give the most ranking weight.  Other usages on the page can also help.   

It is important to note that overusing a keyword can actually hurt rankings.   Using a keyword once in the title, once in the h1, and once in the page body is enough.   Using the keyword more than that is unlikely to help rankings.   Using the keyword more than that in ways that make the text awkward to read can cause keyword stuffing penalties.
"
5008,5008,7974,Can I run 64-bit VM guests on a 32-bit host?,"Can I run 64-bit VM guests on a 32-bit host?

If I have a physical PC with 32 bit can I launch a VM that is 64 bit?
What virtual machine software (Virtual PC or VirtualBox or other) would allow this?

I read out there that VMware may support this but I am looking for something Open source or free.

Host would preferably be a Windows host but could be Linux. Guest needs to be Windows.

Thanks
",Maestro1024,https://serverfault.com/users/12050,"This is trickier than I thought before I was in the market for a box that can handle 64-bit guests.

Myth #1: All 64-bit hosts can run 64-bit guests. False. 64-bit guest requires specific hardware support: VT-x or AMD-V.

Myth #2: All 64-bit processors support 64-bit guests. False. See myth #1.

Myth #3: All current Intel 64-bit processors have VT-x. False. Many brand new 64-bit processors (T6400, T6500 etc.) do NOT support VT-x, in the name of market segmentation.

Myth #4: All machines with VT-x capable processor can support 64-bit guest. False. VT-x support is disabled by default on Intel processors and needs to be enabled by BIOS. Many BIOS, e.g., those in most Acer laptops, do NOT have the option to turn on VT-x.

Basically host OS is irrelevant w.r.t 64-bit guest. If you're looking for a cheap machine to run 64-bit guests, stick to current AMD Athlon 64 (with AM2 or AM3 sockets) or Opteron (2+ generations) processors, as AMD-V support is on by default.
",obecalp,https://serverfault.com/users/3713,http://serverfault.com/questions/64127,TECHNOLOGY,serverfault.com,0.8888888888888888,0.8888888888888888,0.0,1.0,1.0,0.3333333333333333,0.4444444444444444,0.3333333333333333,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0,1.0,1.0,0.9,0.0,0.0,0.6666666666666666,1.0,Can I run a 64 bit virtual machine guest on a 32-bit host?,"Can I run 64-bit VM guests on a 32-bit host?

If I have a physical PC with 32 bit can I launch a VM that is 64 bit?
What virtual machine software (Virtual PC or VirtualBox or other) would allow this?

I read out there that VMware may support this but I am looking for something Open source or free.

Host would preferably be a Windows host but could be Linux. Guest needs to be Windows.

Thanks
","This is trickier than I thought before I was in the market for a box that can handle 64-bit guests.

Myth #1: All 64-bit hosts can run 64-bit guests. False. 64-bit guest requires specific hardware support: VT-x or AMD-V.

Myth #2: All 64-bit processors support 64-bit guests. False. See myth #1.

Myth #3: All current Intel 64-bit processors have VT-x. False. Many brand new 64-bit processors (T6400, T6500 etc.) do NOT support VT-x, in the name of market segmentation.

Myth #4: All machines with VT-x capable processor can support 64-bit guest. False. VT-x support is disabled by default on Intel processors and needs to be enabled by BIOS. Many BIOS, e.g., those in most Acer laptops, do NOT have the option to turn on VT-x.

Basically host OS is irrelevant w.r.t 64-bit guest. If you're looking for a cheap machine to run 64-bit guests, stick to current AMD Athlon 64 (with AM2 or AM3 sockets) or Opteron (2+ generations) processors, as AMD-V support is on by default.
"
5658,5658,8972,How to fix a Macbook Pro trackpad where the mouse pointer is randomly moving?,"The trackpad on my Macbook Pro just started acting oddly. It's randomly clicking (which might cause me to switch programs), right-clicking and even once my screen even showed the swiping animation as if I was trying to switch to a different desktop.    

Part of me fears that this is some sort of joke hacking attempt (I know of a USB device you plug into someones computer and it randomly moves their mouse and types on their keyboard), but there is nothing plugged into my machine and I just turned off the Wi-Fi and watched as this web page tried to close, the mouse right clicked twice, highlighted a word and clicked ""Paste and Match Style"" in the Chrome right-click menu.
Also as I've been typing (with my Wi-Fi turned off) the mouse has randomly been clicking inside this question and changing where I am typing.  

I just plugged in a USB mouse which seems to work fine but the trackpad is now nearly useless. I can't even move the mouse cursor more than a few centimeters with it.

Is this a common issue?
EDIT
I think it is dying actually. I can now click but not move at all with the trackpad, while a regular mouse works fine.
EDIT 2
And now it seems to be working again. I turned on the option for ""Ignore Trackpad when Mouse is plugged in"" under Universal Access. I cleaned the trackpad with rubbing alcohol, I whined and complained for a few minutes to my dog, turned off the ""Ignore Trackpad"" setting, unplugged the USB mouse, and the Trackpad appears to be working mostly normally.
If I run my finger across it at the top or bottom portion of the mouse, it works, but there is a line horizontally across it (almost exactly where a physical trackpad button would end on the old trackpads) that is ""dead"".  The mouse stops moving, or moves sluggishly when hitting that spot and that ""spot"" goes across the whole trackpad.
",James P. Wright,https://apple.stackexchange.com/users/4049,"This was driving me crazy, too. It just started happening yesterday, but was dangerous as the cursor kept selecting everything--making selection rectangles especially on the desktop, opening programs I didn't want to open on the dock, and generally jumping around like a drunk rabbit. 

Searched forums, read about others saying this happened to them after updating their Mac software, etc., etc. Got so frustrated I literally slapped the trackpad with my open palm. And what do you know--that fixed it. Now my trackpad is working perfectly again. Must have been something pinching or pressing against the underside of the trackpad. 

Don't know if you're all going to believe me 'cause it sounds ridiculous, and if you do believe me I don't know if you're willing to do it. But I swear on my soul it's true and I'm posting this solution for all to see because I want to help. 
",lilbluemuffin,https://apple.stackexchange.com/users/48551,http://apple.stackexchange.com/questions/62146/how-to-fix-a-macbook-pro-trackpad-where-the-mouse-pointer-is-randomly-moving,TECHNOLOGY,apple.stackexchange.com,0.8888888888888888,0.7777777777777778,0.0,1.0,1.0,1.0,0.5555555555555556,0.5555555555555556,0.3333333333333333,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,1.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,1.0,0.6,0.6666666666666666,0.3333333333333333,0.0,1.0,How to repair the MacBook Pro touchpad with randomly moving mouse pointer?,"The trackpad on my Macbook Pro just started acting oddly. It's randomly clicking (which might cause me to switch programs), right-clicking and even once my screen even showed the swiping animation as if I was trying to switch to a different desktop.    

Part of me fears that this is some sort of joke hacking attempt (I know of a USB device you plug into someones computer and it randomly moves their mouse and types on their keyboard), but there is nothing plugged into my machine and I just turned off the Wi-Fi and watched as this web page tried to close, the mouse right clicked twice, highlighted a word and clicked ""Paste and Match Style"" in the Chrome right-click menu.
Also as I've been typing (with my Wi-Fi turned off) the mouse has randomly been clicking inside this question and changing where I am typing.  

I just plugged in a USB mouse which seems to work fine but the trackpad is now nearly useless. I can't even move the mouse cursor more than a few centimeters with it.

Is this a common issue?
EDIT
I think it is dying actually. I can now click but not move at all with the trackpad, while a regular mouse works fine.
EDIT 2
And now it seems to be working again. I turned on the option for ""Ignore Trackpad when Mouse is plugged in"" under Universal Access. I cleaned the trackpad with rubbing alcohol, I whined and complained for a few minutes to my dog, turned off the ""Ignore Trackpad"" setting, unplugged the USB mouse, and the Trackpad appears to be working mostly normally.
If I run my finger across it at the top or bottom portion of the mouse, it works, but there is a line horizontally across it (almost exactly where a physical trackpad button would end on the old trackpads) that is ""dead"".  The mouse stops moving, or moves sluggishly when hitting that spot and that ""spot"" goes across the whole trackpad.
","This was driving me crazy, too. It just started happening yesterday, but was dangerous as the cursor kept selecting everything--making selection rectangles especially on the desktop, opening programs I didn't want to open on the dock, and generally jumping around like a drunk rabbit. 

Searched forums, read about others saying this happened to them after updating their Mac software, etc., etc. Got so frustrated I literally slapped the trackpad with my open palm. And what do you know--that fixed it. Now my trackpad is working perfectly again. Must have been something pinching or pressing against the underside of the trackpad. 

Don't know if you're all going to believe me 'cause it sounds ridiculous, and if you do believe me I don't know if you're willing to do it. But I swear on my soul it's true and I'm posting this solution for all to see because I want to help. 
"
1608,1608,2526,Hyper-V virtual machine can't be migrated to a specific host in the cluster,"I have a three-node Hyper-V cluster running on Windows Server 2008 R2 which is working quite flawlessly: there are no errors, live migration works, all hosts can and will happily run all virtual machines, and so on.

But one specific virtual machinee is trying to make me go mad: it works on two nodes of the cluster, but not on the third one.

Whenever I try to move the VM to that node, be it in a live migration or with the VM powered off, it always fails. In the event log of the host these events are logged:

Source: Hyper-V-VMMS
Event ID: 16300
Cannot load a virtual machine configuration: General access denied error (0x80070005) (Virtual machine ID &lt;GUID&gt;)

Source: Hyper-V-VMMS
Evend ID: 20100
The Virtual Machine Management Service failed to register the configuration for the virtual machine '&lt;GUID&gt;' at 'C:\ClusterStorage\&lt;PATH&gt;\&lt;VM&gt;': General access denied error (0x80070005)

Source: Hyper-V-High-Availability
Event ID: 21102
'Virtual Machine Configuration &lt;VM&gt;' failed to register the virtual machine with the virtual machine management service.


All other VMs can be moved to/from the offending host, and the offending VM can be moved between the other two hosts. Also, this is not a storage problem, because there are other VMs in the same cluster volume, and the host has no troubles running them.

What's going on here?
",Massimo,https://serverfault.com/users/6352,"No answer found, it wasn't an actul ACL problem (file ACLs of the offending VM were identical to all other ones), probably something got stuck in the VM configuration.

Deleting the VM, re-creating it and re-attaching its VHDs completely fixed the problem.
",Massimo,https://serverfault.com/users/6352,http://serverfault.com/questions/440613,TECHNOLOGY,serverfault.com,1.0,0.4444444444444444,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.8,0.6666666666666666,0.3333333333333333,1.0,1.0,Failed to migrate Hyper-V virtual machine to a specific host in the cluster,"I have a three-node Hyper-V cluster running on Windows Server 2008 R2 which is working quite flawlessly: there are no errors, live migration works, all hosts can and will happily run all virtual machines, and so on.

But one specific virtual machinee is trying to make me go mad: it works on two nodes of the cluster, but not on the third one.

Whenever I try to move the VM to that node, be it in a live migration or with the VM powered off, it always fails. In the event log of the host these events are logged:

Source: Hyper-V-VMMS
Event ID: 16300
Cannot load a virtual machine configuration: General access denied error (0x80070005) (Virtual machine ID &lt;GUID&gt;)

Source: Hyper-V-VMMS
Evend ID: 20100
The Virtual Machine Management Service failed to register the configuration for the virtual machine '&lt;GUID&gt;' at 'C:\ClusterStorage\&lt;PATH&gt;\&lt;VM&gt;': General access denied error (0x80070005)

Source: Hyper-V-High-Availability
Event ID: 21102
'Virtual Machine Configuration &lt;VM&gt;' failed to register the virtual machine with the virtual machine management service.


All other VMs can be moved to/from the offending host, and the offending VM can be moved between the other two hosts. Also, this is not a storage problem, because there are other VMs in the same cluster volume, and the host has no troubles running them.

What's going on here?
","No answer found, it wasn't an actul ACL problem (file ACLs of the offending VM were identical to all other ones), probably something got stuck in the VM configuration.

Deleting the VM, re-creating it and re-attaching its VHDs completely fixed the problem.
"
5600,5600,8886,Stocks and Bankruptcy,"Trying to understand what happens when a company goes in and out of bankruptcy. I'll use American Airlines as an example because it's what I've been following for some years.

In November 2011, AA announced its bankruptcy; its stock, which was sliding, dropped to 0.38. It stayed flat during 2012, and now that a merger deal has been approved, it climbed up to almost 12.

During 2012 I thought of buying some AA stock because it was so damn cheap. If I had, I could be selling it today for a nice 32x profit. But at the time I was adviced not to - I was told because the company was bankrupt, its stock was just for speculators, pump and dump schemes, and so on, and it would become worthless when the company merged (it would be delisted and a new one added).

So when I read that the merger was approved, I expected it to drop to near zero. Instead, it climbed sharply.

Can anyone explain what's going on? If I had bought in 2012, what would have been the risk to offset this fantastic 32x reward? What will actually happen to AA stock once it exits bankruptcy? It sounds too good to be true, so it probably is, but I can't see why. What am I missing? Why didn't everyone buy AA during 2012?
",ggambett,https://money.stackexchange.com/users/11263,"When they entered Bankruptcy they changed their stock symbol from AAMR to AAMRQ. The Q tells investors that the company i in Bankruptcy. This i what the SEC says about the Q:


  ""Q"" Added To Stock Ticker Symbol
  
  When a company is involved in bankruptcy proceedings, the letter ""Q""
  is added to the end of the company's stock ticker symbol. In most
  cases, when a company emerges from bankruptcy, the reorganization plan
  will cancel the existing equity stock and the old shares will be
  worthless. Given that risk, before purchasing stock in a bankrupt
  company, investors should read the company's proposed plan of
  reorganization. For more information about the impact of bankruptcy
  proceedings on securities, please read our online publication,
  Corporate Bankruptcy.


The risks are they never recover, or that the old shares have nothing to do with new company. Many investors don't understand this. Recently some uninformed investors(?) tried to get a jump on the Twitter IPO by purchasing share of what they thought was Twitter but was instead the bankrupt company Tweeter Home Entertainment.


  Shares of Tweeter Home Entertainment, a Boston-based consumer
  electronics chain that filed for bankruptcy in 2007, soared Friday in
  a case of mistaken identity on Wall Street.
  
  Apparently, some investors confused Tweeter, which trades under the
  symbol TWTRQ, with Twitter and piled into the penny stock.
  
  Tweeter, which trades over the counter, opened at 2 cents a share and
  jumped as much as 15 cents — or 1,800 percent — before regulators
  halted trading.
  
  Almost 15 million shares had changed hands at that point, while the
  average daily volume is closer to 150,000.


Sometimes it does happen that the new company does give some value to the old investors, but more often then not the old investors are completely wiped out.
",mhoran_psprep,https://money.stackexchange.com/users/5414,http://money.stackexchange.com/questions/26285/stocks-and-bankruptcy,LIFE_ARTS,money.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,0.3333333333333333,0.6666666666666666,1.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.0,1.0,1.0,Stock and bankruptcy,"Trying to understand what happens when a company goes in and out of bankruptcy. I'll use American Airlines as an example because it's what I've been following for some years.

In November 2011, AA announced its bankruptcy; its stock, which was sliding, dropped to 0.38. It stayed flat during 2012, and now that a merger deal has been approved, it climbed up to almost 12.

During 2012 I thought of buying some AA stock because it was so damn cheap. If I had, I could be selling it today for a nice 32x profit. But at the time I was adviced not to - I was told because the company was bankrupt, its stock was just for speculators, pump and dump schemes, and so on, and it would become worthless when the company merged (it would be delisted and a new one added).

So when I read that the merger was approved, I expected it to drop to near zero. Instead, it climbed sharply.

Can anyone explain what's going on? If I had bought in 2012, what would have been the risk to offset this fantastic 32x reward? What will actually happen to AA stock once it exits bankruptcy? It sounds too good to be true, so it probably is, but I can't see why. What am I missing? Why didn't everyone buy AA during 2012?
","When they entered Bankruptcy they changed their stock symbol from AAMR to AAMRQ. The Q tells investors that the company i in Bankruptcy. This i what the SEC says about the Q:


  ""Q"" Added To Stock Ticker Symbol
  
  When a company is involved in bankruptcy proceedings, the letter ""Q""
  is added to the end of the company's stock ticker symbol. In most
  cases, when a company emerges from bankruptcy, the reorganization plan
  will cancel the existing equity stock and the old shares will be
  worthless. Given that risk, before purchasing stock in a bankrupt
  company, investors should read the company's proposed plan of
  reorganization. For more information about the impact of bankruptcy
  proceedings on securities, please read our online publication,
  Corporate Bankruptcy.


The risks are they never recover, or that the old shares have nothing to do with new company. Many investors don't understand this. Recently some uninformed investors(?) tried to get a jump on the Twitter IPO by purchasing share of what they thought was Twitter but was instead the bankrupt company Tweeter Home Entertainment.


  Shares of Tweeter Home Entertainment, a Boston-based consumer
  electronics chain that filed for bankruptcy in 2007, soared Friday in
  a case of mistaken identity on Wall Street.
  
  Apparently, some investors confused Tweeter, which trades under the
  symbol TWTRQ, with Twitter and piled into the penny stock.
  
  Tweeter, which trades over the counter, opened at 2 cents a share and
  jumped as much as 15 cents — or 1,800 percent — before regulators
  halted trading.
  
  Almost 15 million shares had changed hands at that point, while the
  average daily volume is closer to 150,000.


Sometimes it does happen that the new company does give some value to the old investors, but more often then not the old investors are completely wiped out.
"
2668,2668,4248,Why was the winner of the AES competition not a Feistel cipher?,"The winner of the AES competition has a structure that does not qualify as a Feistel cipher, as explained in answers to this recent question.

However, most many of the AES candidates, and all 3 out of 4 some other finalists (Twofish, MARS) are Feistel ciphers, if we define that as a cipher transforming a block of data using a number of rounds which each can be expressed as:


split all the bits of the block $B_j$ into two disjoint portions $L_j$ and $R_j$ (typically of equal size);
compute some (typically round-dependent) function of $R_j$ and key with output $F_j$ of same width as $L_j$;
compute  $L_j'=L_j\oplus F_j$ where $\oplus$ is binary addition with removal of some carry bits (e.g. exclusive-OR, where all carry bits are removed);
recombine bits of $L_j'$ and the unmodified $R_j$ into a new block $B_{j+1}$.


Note: Serpent and RC6 can not be put in this framework (thanks to @Reid and @J.D. for pointing that). Neither can Rijndael/AES.

At the time of the AES competition, Feistel ciphers already enjoyed a well understood theory. In particular DES was among them, and essentially unbroken in practice except for its small key and block size. It would seem that proposing anything else than a Feistel cipher would be an uphill battle.

Yet, Rijndael won the AES competion, and does not fall under the above definition. Did a desirable characteristic of Rijndael made it preferred to the other candidates despite the apparent drawback of using a relatively untested structure? And if that characteristic could not be matched by a Feistel cipher, why?
",fgrieu,https://crypto.stackexchange.com/users/555,"As a page at ibm.com indicates, there could have been a bit of a ""contra"" attitude against Feistel ciphers thanks to DES having seen the first breaks in it's security etc. 


  Down with the Feistel structure!
  
  In most ciphers, the round transformation has the well-known Feistel structure. In this structure typically part of the bits of the intermediate State are simply transposed unchanged to another position. (An example of this linear kind of structure are those tables we discussed back in the DES discussion that substitute bits by a fixed tabular means.) The round transformation of Rijndael does not have this venerable Feistel structure. Instead, the round transformation is composed of three distinct invertible uniform transformations, called layers. (""Uniform"" here means that every bit of the State is treated in a similar way.)
  
  The linear mixing layer guarantees high diffusion over multiple rounds. The non-linear layer uses parallel application of S-boxes that have the desired (hence optimum) worst-case nonlinearity properties. The S-boxes are non-linear. That's the key conceptual difference between DES and Rijndael…


So, I guess one of the reasons they chose a non-Feistel cipher could well have been that they wanted to guarantee higher security through higher diffusion etc. while hoping that — in case Feistel ciphers should collapse sooner than expected — the next crypto they were about to recommend wouldn't automatically join in and break down too.

Serpent for example was designed so that all operations can be executed in parallel, using 32 1-bit slices. While this maximizes parallelism, it also allowed immediate use of the extensive cryptanalysis work performed on DES. A good reason not to give Serpent that final go and prefer ""something else"" (most probably because Serpent's origins were too close to a theoretically broken Feistel — DES).

This would also go in canon with what @thomas-pornin mentioned in the first lines of his great answer.
",e-sushi,https://crypto.stackexchange.com/users/12164,http://crypto.stackexchange.com/questions/10631/why-was-the-winner-of-the-aes-competition-not-a-feistel-cipher,TECHNOLOGY,crypto.stackexchange.com,1.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.6666666666666666,0.0,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.9,0.0,0.0,1.0,1.0,Why isn't the winner of the AES competition the fester code?,"The winner of the AES competition has a structure that does not qualify as a Feistel cipher, as explained in answers to this recent question.

However, most many of the AES candidates, and all 3 out of 4 some other finalists (Twofish, MARS) are Feistel ciphers, if we define that as a cipher transforming a block of data using a number of rounds which each can be expressed as:


split all the bits of the block $B_j$ into two disjoint portions $L_j$ and $R_j$ (typically of equal size);
compute some (typically round-dependent) function of $R_j$ and key with output $F_j$ of same width as $L_j$;
compute  $L_j'=L_j\oplus F_j$ where $\oplus$ is binary addition with removal of some carry bits (e.g. exclusive-OR, where all carry bits are removed);
recombine bits of $L_j'$ and the unmodified $R_j$ into a new block $B_{j+1}$.


Note: Serpent and RC6 can not be put in this framework (thanks to @Reid and @J.D. for pointing that). Neither can Rijndael/AES.

At the time of the AES competition, Feistel ciphers already enjoyed a well understood theory. In particular DES was among them, and essentially unbroken in practice except for its small key and block size. It would seem that proposing anything else than a Feistel cipher would be an uphill battle.

Yet, Rijndael won the AES competion, and does not fall under the above definition. Did a desirable characteristic of Rijndael made it preferred to the other candidates despite the apparent drawback of using a relatively untested structure? And if that characteristic could not be matched by a Feistel cipher, why?
","As a page at ibm.com indicates, there could have been a bit of a ""contra"" attitude against Feistel ciphers thanks to DES having seen the first breaks in it's security etc. 


  Down with the Feistel structure!
  
  In most ciphers, the round transformation has the well-known Feistel structure. In this structure typically part of the bits of the intermediate State are simply transposed unchanged to another position. (An example of this linear kind of structure are those tables we discussed back in the DES discussion that substitute bits by a fixed tabular means.) The round transformation of Rijndael does not have this venerable Feistel structure. Instead, the round transformation is composed of three distinct invertible uniform transformations, called layers. (""Uniform"" here means that every bit of the State is treated in a similar way.)
  
  The linear mixing layer guarantees high diffusion over multiple rounds. The non-linear layer uses parallel application of S-boxes that have the desired (hence optimum) worst-case nonlinearity properties. The S-boxes are non-linear. That's the key conceptual difference between DES and Rijndael…


So, I guess one of the reasons they chose a non-Feistel cipher could well have been that they wanted to guarantee higher security through higher diffusion etc. while hoping that — in case Feistel ciphers should collapse sooner than expected — the next crypto they were about to recommend wouldn't automatically join in and break down too.

Serpent for example was designed so that all operations can be executed in parallel, using 32 1-bit slices. While this maximizes parallelism, it also allowed immediate use of the extensive cryptanalysis work performed on DES. A good reason not to give Serpent that final go and prefer ""something else"" (most probably because Serpent's origins were too close to a theoretically broken Feistel — DES).

This would also go in canon with what @thomas-pornin mentioned in the first lines of his great answer.
"
5763,5763,9133,Dynamic Programming: find the minimal route with ten nodes from a set of 100 nodes,"You are given 100 stations and distance between each adjacent stations. Now you have to select 10 stations(means 10 hops) among those 100 stations in such a way that maximum of distance between any 2 hops will be minimised. By default 1 and 100 stations are selected , so you need to choose only 8 more stations.
",John Smith,https://stackoverflow.com/users/1263492,"You are going to need to give us a question.  It looks like you are being asked a question for an interview and then want us to give it to you to reiterate to an employer.  It is pretty easy though, i have a similar program on my home pc implementing a few different path finding techniques.
",Fallenreaper,https://stackoverflow.com/users/1404049,http://stackoverflow.com/questions/10953545,STACKOVERFLOW,stackoverflow.com,0.6666666666666666,0.6666666666666666,0.0,0.5,0.0,1.0,0.5,0.3333333333333333,0.0,0.5,0.5,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.5,0.0,0.6666666666666666,0.3333333333333333,0.5,0.8333333333333334,0.5,0.4,0.0,0.0,0.0,0.8333333333333334,Dynamic planning: finding the minimum path of 10 nodes from a group of 100 nodes,"Give you 100 sites and the distance between each adjacent site. Now, you have to choose 10 of the 100 stations (which means 10 hops) to minimize the distance between any two hops. By default, 1 and 100 stations are selected, so you only need to select an additional 8 stations.","You need to give us a question. You seem to have been asked an interview question, and then want us to give it to you and let you reiterate it to the employer. However, it's very simple. I have a similar program on my home computer, which implements some different path finding technologies."
4382,4382,6969,Highcharts - Cannot set x-axes categories in column charts with negative values,"Hi I have a column chart with negative values which is showing wrong x-axes categories value. I'm sending a pre-build JSON array from the server , but no matter what i can't get the x-axes categories to show the right values.

Here is the code :

     var chart_data = JSON.parse(data).avg_range;


                        console.log(chart_data.x_axes);

                        var safety_chart_average = {
                            chart: {
                                type: 'column',
                                renderTo: pattern + '-safety-mini-chart-section',
                                spacingRight: 20,
                                spacingLeft: 20,
                            },
                            rangeSelector: {
                                enabled: false
                            },
                            navigator: {
                                enabled: false
                            },
                            scrollbar: {
                                enabled: false
                            },
                            credits: {
                                enabled: false
                            },
                            title: {
                                text: ""Avg Changes"",
                                marginBottom: -10
                            },
                            xAxis: {
                                categories: chart_data.x_axes
                            },
                            series: chart_data.prices


 };


This is what i'm getting



The x-axes is showing wrong values, as you can see from the picture above. 

But console.log(chart_data.x_axes) gives 
[""Day 1"", ""Day 2"", ""Day 3""] which should be the correct x-axes label.

Please let me know how can i fix this x-axes label error. 
",Maxx,https://stackoverflow.com/users/2536469,"You are sending in options to a StockChart. If you look in the API for xAxis on StockChart you see that it has no categories.

If you are not using any Highstock functionality I would switch to a regular Highcharts-chart, using new Highcharts.Chart instead.

If you must use Highstock you will have to look into other alternatives, as the xAxis uses time intervals. This StackOverflow answer may give you some hope, depending of how you are using Highstock in your implementation.
",Halvor Strand,https://stackoverflow.com/users/2732991,http://stackoverflow.com/questions/24596073/highcharts-cannot-set-x-axes-categories-in-column-charts-with-negative-values,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.6666666666666666,0.0,1.0,1.0,1.0,0.5555555555555556,0.5555555555555556,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8,0.3333333333333333,0.6666666666666666,0.3333333333333333,0.8888888888888888,Highcharts - cannot set the x-axis category in a column chart with negative values,"Hi I have a column chart with negative values which is showing wrong x-axes categories value. I'm sending a pre-build JSON array from the server , but no matter what i can't get the x-axes categories to show the right values.

Here is the code :

     var chart_data = JSON.parse(data).avg_range;


                        console.log(chart_data.x_axes);

                        var safety_chart_average = {
                            chart: {
                                type: 'column',
                                renderTo: pattern + '-safety-mini-chart-section',
                                spacingRight: 20,
                                spacingLeft: 20,
                            },
                            rangeSelector: {
                                enabled: false
                            },
                            navigator: {
                                enabled: false
                            },
                            scrollbar: {
                                enabled: false
                            },
                            credits: {
                                enabled: false
                            },
                            title: {
                                text: ""Avg Changes"",
                                marginBottom: -10
                            },
                            xAxis: {
                                categories: chart_data.x_axes
                            },
                            series: chart_data.prices


 };


This is what i'm getting



The x-axes is showing wrong values, as you can see from the picture above. 

But console.log(chart_data.x_axes) gives 
[""Day 1"", ""Day 2"", ""Day 3""] which should be the correct x-axes label.

Please let me know how can i fix this x-axes label error. 
","You are sending in options to a StockChart. If you look in the API for xAxis on StockChart you see that it has no categories.

If you are not using any Highstock functionality I would switch to a regular Highcharts-chart, using new Highcharts.Chart instead.

If you must use Highstock you will have to look into other alternatives, as the xAxis uses time intervals. This StackOverflow answer may give you some hope, depending of how you are using Highstock in your implementation.
"
5026,5026,8002,Windows Software to Mount Volume/Partition Image File,"Last night I had a BSOD a couple of minutes after moving a file. After a reboot, I found that the file was gone (it was deleted from the source partition and not present on the destination).

I took an image of the source volume (ie from the Boot Sector to the last cluster of the partition). Then I wrote a program to extract the unused clusters from a disk and save them as files.

Some of the free clusters on the original volume have now been overwritten so I need to use the image to do my final extraction. That means I need some software that can mount a volume/partition image, but all of the image mounting software I can find can only mount disk images (ie from the MBR—the master partition table—on).

Does anyone know of (hopefully free) Windows software that can do this?

I’ve already tried (without success): VirtualCloneDrive, DaemonTools, VirtualFloppyDrive (and probably a couple of others I can’t think of). They all either nag that the file is no good, or try to mount it, resulting in a disk that Windows complains has an unknown/corrupt filesystem.

Thanks.
",Synetech,https://superuser.com/users/3279,"You'd use Virtual CloneDrive (freeware) to mount .ISO, .CCD, .DVD, .IMG, .UDF and .BIN files.



via HowToGeek
",Ye Lin Aung,https://superuser.com/users/29679,http://superuser.com/questions/172184,TECHNOLOGY,superuser.com,0.8888888888888888,0.5555555555555556,0.0,0.6666666666666666,1.0,1.0,0.6666666666666666,0.5555555555555556,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8666666666666666,0.6666666666666666,0.0,0.0,0.8888888888888888,Install windows software for volume / partition image files,"Last night I had a BSOD a couple of minutes after moving a file. After a reboot, I found that the file was gone (it was deleted from the source partition and not present on the destination).

I took an image of the source volume (ie from the Boot Sector to the last cluster of the partition). Then I wrote a program to extract the unused clusters from a disk and save them as files.

Some of the free clusters on the original volume have now been overwritten so I need to use the image to do my final extraction. That means I need some software that can mount a volume/partition image, but all of the image mounting software I can find can only mount disk images (ie from the MBR—the master partition table—on).

Does anyone know of (hopefully free) Windows software that can do this?

I’ve already tried (without success): VirtualCloneDrive, DaemonTools, VirtualFloppyDrive (and probably a couple of others I can’t think of). They all either nag that the file is no good, or try to mount it, resulting in a disk that Windows complains has an unknown/corrupt filesystem.

Thanks.
","You can use the virtual CloneDrive (free software) to load. ISO,. CCD,. DVD,. Img,. UDF, and. Bin files."
3991,3991,6370,Does the original jutsu user feel anything when a shadow clone is dispersed forcefully?,"According to the wiki,


  While the technique can be extremely beneficial, attempting to use multiple clones for training purposes can be mentally harmful to the user, as not only is all the experience collected by the user, but so is all the mental stress from training each clone


Now, when a clone is destroyed, there must be some mental stress involved. So does Naruto (or anyone else) feel anything when their shadow clones are dispersed? 

Nothing has been shown to indicate this (at least in the anime). I was wondering why this would not be applicable.
",Chetter Hummin,https://anime.stackexchange.com/users/321,"Well, actually the mental stress involved when a clone is forcefully destroyed being transferred to the original has been showed on a number of occasions in the anime, including once before the timeskip.

During the Invasion of Konoha arc:


   When Naruto fights Gaara, Gaara goes into the Ichibi Shukaku mode, and Naruto attacks Gaara/Shukaku using 1000 clones with the Naruto Niisen Rendan (Naruto Two Thousand Combo). He then attempts the Naruto Yonsen Rendan (Naruto Four Thousand Combo), but Shukaku fights back and destroys nearly all the clones. As Naruto is forced back, he exclaims, ""That hurt a lot"".


Later after the timeskip, when Kakashi tells Naruto that the pain experienced by the clone is transferred to the user, Naruto says in a dejected/annoyed tone, ""I knew that already.""
",Masked Man,https://anime.stackexchange.com/users/99,http://anime.stackexchange.com/questions/2193/does-the-original-jutsu-user-feel-anything-when-a-shadow-clone-is-dispersed-forc,CULTURE,anime.stackexchange.com,0.8888888888888888,1.0,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.8,0.0,0.0,0.6666666666666666,0.8888888888888888,"When shadow clones are forced to disperse, how does the original jutsu user feel?","According to the wiki,


  While the technique can be extremely beneficial, attempting to use multiple clones for training purposes can be mentally harmful to the user, as not only is all the experience collected by the user, but so is all the mental stress from training each clone


Now, when a clone is destroyed, there must be some mental stress involved. So does Naruto (or anyone else) feel anything when their shadow clones are dispersed? 

Nothing has been shown to indicate this (at least in the anime). I was wondering why this would not be applicable.
","Well, actually the mental stress involved when a clone is forcefully destroyed being transferred to the original has been showed on a number of occasions in the anime, including once before the timeskip.

During the Invasion of Konoha arc:


   When Naruto fights Gaara, Gaara goes into the Ichibi Shukaku mode, and Naruto attacks Gaara/Shukaku using 1000 clones with the Naruto Niisen Rendan (Naruto Two Thousand Combo). He then attempts the Naruto Yonsen Rendan (Naruto Four Thousand Combo), but Shukaku fights back and destroys nearly all the clones. As Naruto is forced back, he exclaims, ""That hurt a lot"".


Later after the timeskip, when Kakashi tells Naruto that the pain experienced by the clone is transferred to the user, Naruto says in a dejected/annoyed tone, ""I knew that already.""
"
6039,6039,9584,Using a time to set XY chart axis scaling as in Excel 2003,"In Excel 2003, when you created a XY chart using time as an axis, you could set the scaling of the axis by typing in the date. In Excel 2007, you have to use the decimal version of the time (eg. How many days since some arbitrary earlier date).

A developer posted on a blog that this issue would be fixed in a future release, but all versions of Excel 2007 I have tried have not resolved this issue. The relevant quote:


  Those of you familiar with this technique of converting time to a decimal may recall that Excel 2003 allowed you to enter a date and time like “1/1/07 11:00 AM” directly in the  axis option min/max fields and Excel would calculate the appropriate decimal representation.  This currently does not work in Excel 2007 but will be fixed in a subsequent release. 


I was wondering if there was a way to avoid having to make such a calculation?
",CookieOfFortune,https://superuser.com/users/8249,"Excel 2007 has a problem with time as an axis in charts. Using ‘the decimal version of time’ is probably the best workaround.  

The Microsoft blog you refer to closes with:  


  “In summary, whenever you need to create a time series chart where the units are smaller than a day, avoid using line, column, bar, or area chart types. Instead use an XY (Scatter) chart to accurately reflect the span of time.”  


but even so the example used there requires decimal versions.  

As mentioned by @Neal, this has been fixed for Excel 2010, as indicated by Microsoft would be the case. 

Your question also mentions “days since some arbitrary earlier date”. This is a date matter for which no workaround is required when considering whole days. Formatting the source data in date format should be sufficient.
",pnuts,https://superuser.com/users/145438,http://superuser.com/questions/148886,TECHNOLOGY,superuser.com,0.6666666666666666,0.5555555555555556,0.0,0.0,1.0,1.0,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.7777777777777778,0.6666666666666666,0.3333333333333333,0.7777777777777778,1.0,0.6,0.6666666666666666,0.0,1.0,1.0,Use Excel 2003 to set the scaling time of XY chart axis,"In Excel 2003, when you created a XY chart using time as an axis, you could set the scaling of the axis by typing in the date. In Excel 2007, you have to use the decimal version of the time (eg. How many days since some arbitrary earlier date).

A developer posted on a blog that this issue would be fixed in a future release, but all versions of Excel 2007 I have tried have not resolved this issue. The relevant quote:


  Those of you familiar with this technique of converting time to a decimal may recall that Excel 2003 allowed you to enter a date and time like “1/1/07 11:00 AM” directly in the  axis option min/max fields and Excel would calculate the appropriate decimal representation.  This currently does not work in Excel 2007 but will be fixed in a subsequent release. 


I was wondering if there was a way to avoid having to make such a calculation?
","Excel 2007 has a problem with time as an axis in charts. Using ‘the decimal version of time’ is probably the best workaround.  

The Microsoft blog you refer to closes with:  


  “In summary, whenever you need to create a time series chart where the units are smaller than a day, avoid using line, column, bar, or area chart types. Instead use an XY (Scatter) chart to accurately reflect the span of time.”  


but even so the example used there requires decimal versions.  

As mentioned by @Neal, this has been fixed for Excel 2010, as indicated by Microsoft would be the case. 

Your question also mentions “days since some arbitrary earlier date”. This is a date matter for which no workaround is required when considering whole days. Formatting the source data in date format should be sufficient.
"
5675,5675,8997,"""going to"" vs ""will""","I know several questions were asked about the difference between ""going to"" and ""will"".
Based on several answers (see, for instance, here, here and here), I understood that ""will"" is more spontaneous and ""going to"" is used with more planned actions.

So, it seems that everything is pretty fine. However, in this question, Kosmonaut has an answer in which he states:
""Let's say that tomorrow you will walk your dog from 7 - 8 AM"".

On the one hand, you probably planned to walk your dog long before and thus I should use ""Let's say that tomorrow you're going to walk your dog from 7 - 8 am"". 

On the other hand, since I'm saying ""let's say..."", I'm deciding right now (thus, unplanned) that you will walk your dog. So, even though in this hypothetical situation you made a plan, I'm in a more spontaneous mood deciding right now that that's what you will do tomorrow, and, thus, I should use ""will"".

Which one (if any) of the above explanations is right?
",Manoel Galdino,https://english.stackexchange.com/users/21109,"Doing some research, I discovered that the spontaneous vs planned rule for ""going to"" and ""will"" is taught to ESL students, but not used otherwise.  I did discover a few good rules of thumb that are decent guidelines and make sense to me (a native English speaker):


""Going to"" is a kind of present tense, so use ""going to"" in situations where the 
present is connected to the future.
Example:
      I feel a drop - I bet it's going to rain.
      I am going to walk to school because my bike has a flat tire.
Use ""will"" in writing and ""going to"" when speaking.
Use ""will"" when talking about the not-immediate future and ""going to"" for the immediate future.
Use ""will"" and ""going to"" interchangeably for making predictions.


If you are looking for a good explanation about when to use either form, I suggest you read this article, which explains how to teach the differences between ""going to"" and ""will"".
",Kathryn,https://english.stackexchange.com/users/28838,http://english.stackexchange.com/questions/87900/going-to-vs-will,CULTURE,english.stackexchange.com,0.8888888888888888,0.4444444444444444,0.0,1.0,1.0,1.0,0.6666666666666666,0.7777777777777778,0.3333333333333333,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,0.3333333333333333,0.0,1.0,1.0,"Go to ""vs"" will","I know several questions were asked about the difference between ""going to"" and ""will"".
Based on several answers (see, for instance, here, here and here), I understood that ""will"" is more spontaneous and ""going to"" is used with more planned actions.

So, it seems that everything is pretty fine. However, in this question, Kosmonaut has an answer in which he states:
""Let's say that tomorrow you will walk your dog from 7 - 8 AM"".

On the one hand, you probably planned to walk your dog long before and thus I should use ""Let's say that tomorrow you're going to walk your dog from 7 - 8 am"". 

On the other hand, since I'm saying ""let's say..."", I'm deciding right now (thus, unplanned) that you will walk your dog. So, even though in this hypothetical situation you made a plan, I'm in a more spontaneous mood deciding right now that that's what you will do tomorrow, and, thus, I should use ""will"".

Which one (if any) of the above explanations is right?
","Doing some research, I discovered that the spontaneous vs planned rule for ""going to"" and ""will"" is taught to ESL students, but not used otherwise.  I did discover a few good rules of thumb that are decent guidelines and make sense to me (a native English speaker):


""Going to"" is a kind of present tense, so use ""going to"" in situations where the 
present is connected to the future.
Example:
      I feel a drop - I bet it's going to rain.
      I am going to walk to school because my bike has a flat tire.
Use ""will"" in writing and ""going to"" when speaking.
Use ""will"" when talking about the not-immediate future and ""going to"" for the immediate future.
Use ""will"" and ""going to"" interchangeably for making predictions.


If you are looking for a good explanation about when to use either form, I suggest you read this article, which explains how to teach the differences between ""going to"" and ""will"".
"
1957,1957,3118,How to interpret a Current Value into a PWM signal percentage?,"I have a maltab model, output of which (from an RL circuit) is a value for current. I want to interpret this value of current into a PWM signal with frequency of 1000Hz and duty cycle of 50%. I have only worked with defined pwm signals with constant frequency &amp; duty cycle. 
so basically the system should be like this:

RL CKT - Current(0.5A) --> PWM signal generator_output = 0.5A @ 1000Hz &amp; 50% Duty Cycle

Thanks for any form of guidance!
",sheetansh,https://electronics.stackexchange.com/users/16171,"Based on your question and subsequent comments, what you are asking for is a pulse with a repetition rate of 1000 Hz and a duty cycle of 50% whose amplitude is a linear function of the current from your RC circuit.  First of all, if the shape is a pulse and the duty cycle is 50%, then the waveform is a square wave.  Second, if you want the amplitude to vary with your current, then that is amplitude and not pulse width modulation, also known as PAM.  Third, it should be easy to create such a waveform within MATLAB by defining a function with the characteristics you want.
",Barry,https://electronics.stackexchange.com/users/10016,http://electronics.stackexchange.com/questions/82109/how-to-interpret-a-current-value-into-a-pwm-signal-percentage,SCIENCE,electronics.stackexchange.com,1.0,0.5555555555555556,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,0.8888888888888888,How to interpret the current value as a percentage of PWM signal?,I have a maltab model whose output (from the RL circuit) is a current value. I want to interpret this current value as a PWM signal with a frequency of 1000Hz and a duty cycle of 50%. I have only studied specific PWM signals with constant frequency and duty cycle.,"Based on your question and subsequent comments, what you are asking for is a pulse with a repetition rate of 1000 Hz and a duty cycle of 50% whose amplitude is a linear function of the current from your RC circuit.  First of all, if the shape is a pulse and the duty cycle is 50%, then the waveform is a square wave.  Second, if you want the amplitude to vary with your current, then that is amplitude and not pulse width modulation, also known as PAM.  Third, it should be easy to create such a waveform within MATLAB by defining a function with the characteristics you want.
"
5453,5453,8654,where to put .sty and .cls file for project,"I want to use my own .sty and .cls file in a project. I know of the following two possibilities of placing them:


in my local tex tree (or the general tex tree, which is worse)
in the same directory as the .tex file


Both of these I find unsatisfactory for the following reasons:

The local tex tree is unsatisfactory since the .sty file is specific for the project, so I want it to be close to the project, so I easily remember where it is etc. Also, I am using dropbox to synchronize the project files between different computers automatically, so the .sty file should be in the dropbox folder.

The 'same directory' is unsatisfactory since the project is in a directory with many subdirectories. The .tex files in all these subdirectories should be able to access the same .sty file.

What I would like to do is: create a subdirectory 'style files' in the project directory, where I put style and class files (there are several for the project), then tell tex somehow where to find them.

How can I do this?

I am using a recent TexLive on  Mac OS X.6

I know there have been questions about placement of .sty files, but I did not find an answer to this question.
",Daniel,https://tex.stackexchange.com/users/9171,"At the top level of the TeX Live distribution there is a texmf.cnf file that you can edit, if you don't want to set environment variables; the usual value for TEXMFHOME is, with an vanilla TeX Live

TEXMFHOME = ~/texmf


which stands for a texmf folder in your home. With the MacTeX installed TeX Live it is

TEXMFHOME = ~/Library/texmf


This kpathsea variable can be set to whatever you prefer:

TEXMFHOME = {~/Library/texmf,/Volumes/Dropbox/texmf}


would make TeX programs search also the texmf folder (which should be organized as a TeX tree) in the disk called Dropbox. You should know the precise path to give. Assuming this, you can put your classes and packages inside 

/Volumes/Dropbox/texmf/tex/latex/myproject


(choose a better name) and all users that modify accordingly the texmf.cnf file on their machines will be able to access the tree.

Launching TeX programs as, say,

TEXMFHOME=:/Volumes/Dropbox/texmf// pdflatex filename


would be equivalent (notice the initial colon that means ""append"" the new tree after the value stated in texmf.cnf and the trailing // to mean ""search recursively). Such a setting of TEXMFHOME can be of course stated in the overall environment. The texmf.cnf way is safer, as it doesn't depend on shell setup; the extra tree will be ignored if not found on the system.
",egreg,https://tex.stackexchange.com/users/4427,http://tex.stackexchange.com/questions/34203/where-to-put-sty-and-cls-file-for-project,TECHNOLOGY,tex.stackexchange.com,1.0,0.5,0.0,0.0,1.0,1.0,0.5,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.8333333333333334,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.5,1.0,Where to store. Sty and. CLS files for the project,"I want to use my own .sty and .cls file in a project. I know of the following two possibilities of placing them:


in my local tex tree (or the general tex tree, which is worse)
in the same directory as the .tex file


Both of these I find unsatisfactory for the following reasons:

The local tex tree is unsatisfactory since the .sty file is specific for the project, so I want it to be close to the project, so I easily remember where it is etc. Also, I am using dropbox to synchronize the project files between different computers automatically, so the .sty file should be in the dropbox folder.

The 'same directory' is unsatisfactory since the project is in a directory with many subdirectories. The .tex files in all these subdirectories should be able to access the same .sty file.

What I would like to do is: create a subdirectory 'style files' in the project directory, where I put style and class files (there are several for the project), then tell tex somehow where to find them.

How can I do this?

I am using a recent TexLive on  Mac OS X.6

I know there have been questions about placement of .sty files, but I did not find an answer to this question.
","At the top level of the TeX Live distribution there is a texmf.cnf file that you can edit, if you don't want to set environment variables; the usual value for TEXMFHOME is, with an vanilla TeX Live

TEXMFHOME = ~/texmf


which stands for a texmf folder in your home. With the MacTeX installed TeX Live it is

TEXMFHOME = ~/Library/texmf


This kpathsea variable can be set to whatever you prefer:

TEXMFHOME = {~/Library/texmf,/Volumes/Dropbox/texmf}


would make TeX programs search also the texmf folder (which should be organized as a TeX tree) in the disk called Dropbox. You should know the precise path to give. Assuming this, you can put your classes and packages inside 

/Volumes/Dropbox/texmf/tex/latex/myproject


(choose a better name) and all users that modify accordingly the texmf.cnf file on their machines will be able to access the tree.

Launching TeX programs as, say,

TEXMFHOME=:/Volumes/Dropbox/texmf// pdflatex filename


would be equivalent (notice the initial colon that means ""append"" the new tree after the value stated in texmf.cnf and the trailing // to mean ""search recursively). Such a setting of TEXMFHOME can be of course stated in the overall environment. The texmf.cnf way is safer, as it doesn't depend on shell setup; the extra tree will be ignored if not found on the system.
"
2533,2533,4036,Can I disable the default calendar app notifications?,"This strikes me as a bug since the behaviour is incredibly consistent, but perhaps someone here can help me.

I want to use the google developed calendar app as my main calendar app. My phone (a Galaxy S2) came with a samsung developed calendar app (both very conveniently named ""Calendar""). At this point, I simply want to disable the samsung calendar app from displaying any sort of notifications (since the google app also displays notifications and I want to use that app).

I have been able to do this by going to settings->Notifications in the samsung app and toggling to ""Off"".

However, as soon as I restart the device, the notifications are back on their original settings. Anyone else experience this? Anyone know how to make the settings stick?

EDIT: I notice the notification settings of the google developed app (sound, default reminder time, popup) are also not sticking after reboot. Is my device broken? It seems to only be for calendar. Gmail and other apps hold their settings fine.

EDIT 2: Ok, so disabling the samsung app allows my google app calendar settings to stick after reboot. So looks like that is what I will be doing. Anyone know how I can change the vcs file association to this app now?
",gnomed,https://android.stackexchange.com/users/13279,"I don't know how to make the setting stick, but if you are using ICS you can easily disable the Samsung calendar app - so it will act as if it is uninstalled.

You can disable it by clicking the Disable button on the App settings page - just above the disable notifications checkbox.

Once this is done, reboot your device and it will act as if that app is no longer installed!
",Liam W,https://android.stackexchange.com/users/11209,http://android.stackexchange.com/questions/33327/can-i-disable-the-default-calendar-app-notifications,TECHNOLOGY,android.stackexchange.com,1.0,0.3333333333333333,0.0,0.5,1.0,1.0,0.4444444444444444,0.4444444444444444,1.0,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.6666666666666666,0.0,0.8888888888888888,0.8888888888888888,0.5555555555555556,1.0,1.0,0.8,0.6666666666666666,0.6666666666666666,0.0,0.8888888888888888,Can I disable default calendar app notifications?,"This strikes me as a bug since the behaviour is incredibly consistent, but perhaps someone here can help me.

I want to use the google developed calendar app as my main calendar app. My phone (a Galaxy S2) came with a samsung developed calendar app (both very conveniently named ""Calendar""). At this point, I simply want to disable the samsung calendar app from displaying any sort of notifications (since the google app also displays notifications and I want to use that app).

I have been able to do this by going to settings->Notifications in the samsung app and toggling to ""Off"".

However, as soon as I restart the device, the notifications are back on their original settings. Anyone else experience this? Anyone know how to make the settings stick?

EDIT: I notice the notification settings of the google developed app (sound, default reminder time, popup) are also not sticking after reboot. Is my device broken? It seems to only be for calendar. Gmail and other apps hold their settings fine.

EDIT 2: Ok, so disabling the samsung app allows my google app calendar settings to stick after reboot. So looks like that is what I will be doing. Anyone know how I can change the vcs file association to this app now?
","I don't know how to make the setting stick, but if you are using ICS you can easily disable the Samsung calendar app - so it will act as if it is uninstalled.

You can disable it by clicking the Disable button on the App settings page - just above the disable notifications checkbox.

Once this is done, reboot your device and it will act as if that app is no longer installed!
"
3018,3018,4812,Laravel eloquent how to order collection by accessor in appends array,"I have following Eloquent model:

class Song extends Eloquent {

protected $table = 'mg_songs';
protected $hidden = array('events');
protected $appends = array('lastDate');

public function events()
{
    return $this-&gt;belongsToMany('Event', 'song_event');
}

public function getLastDateAttribute()
{
    if (!$this-&gt;events) return null;

    return $this-&gt;events[0]-&gt;date-&gt;formatLocalized('%d.%m.%Y (%a, %Hч)');
}}


Is it possible to sort by ""lastdate"" field same as db field:

$songs-&gt;orderBy('title', 'asc'); - works
$songs-&gt;orderBy('lastDate', 'desc'); - doesn't works


May be exist simple answer?

EDITED:

My db structure (only needed fields), with many-to-many:

events table
event_id
date

songs table
song_id
title

song_event pivot table
id
song_id
event_id

SQL-request:

SELECT s.title, (SELECT MAX(e.date) FROM events e JOIN song_event se ON (e.id = se.event_id) WHERE se.song_id = s.id) AS s_date FROM mg_songs s ORDER BY s_date desc

",gurkov,https://stackoverflow.com/users/4066716,"You can sort the resulting collection by accessor, obviously the query can't be ordered, for it's not in the db.

$songs = Song::all(); // get the result
$songs-&gt;sortByDesc('lastDate'); // sort using collection method

// or ascending:
$songs-&gt;sortBy('lastDate');


You could achieve the same using joins, if you prefer to do this in the db call (it's better in terms of performance).



Another thing: you use if( ! $this-&gt;events) which will cause trouble soon.

Check this out:

// hasOne / belongsTo / morphTo etc - single relations
$model-&gt;relation; // returns related model OR null -&gt; evaluates to false

// BUT for hasMany / belongsToMany etc - multiple results
$model-&gt;relation; // always returns a collection, even if empty, evaluates to true


So change this if to:

public function getLastDateAttribute()
{
    if ( ! count($this-&gt;events)) return null;

    return $this-&gt;events[0]-&gt;date-&gt;formatLocalized('%d.%m.%Y (%a, %Hч)');
}}

",Jarek Tkaczyk,https://stackoverflow.com/users/784588,http://stackoverflow.com/questions/25975542/laravel-eloquent-how-to-order-collection-by-accessor-in-appends-array,STACKOVERFLOW,stackoverflow.com,0.6666666666666666,0.3333333333333333,0.0,0.0,1.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0,1.0,1.0,0.0,0.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.8,1.0,1.0,0.0,1.0,Laravel eloquently explains how to sort collections by accessor in the appends array,"I have following Eloquent model:

class Song extends Eloquent {

protected $table = 'mg_songs';
protected $hidden = array('events');
protected $appends = array('lastDate');

public function events()
{
    return $this-&gt;belongsToMany('Event', 'song_event');
}

public function getLastDateAttribute()
{
    if (!$this-&gt;events) return null;

    return $this-&gt;events[0]-&gt;date-&gt;formatLocalized('%d.%m.%Y (%a, %Hч)');
}}


Is it possible to sort by ""lastdate"" field same as db field:

$songs-&gt;orderBy('title', 'asc'); - works
$songs-&gt;orderBy('lastDate', 'desc'); - doesn't works


May be exist simple answer?

EDITED:

My db structure (only needed fields), with many-to-many:

events table
event_id
date

songs table
song_id
title

song_event pivot table
id
song_id
event_id

SQL-request:

SELECT s.title, (SELECT MAX(e.date) FROM events e JOIN song_event se ON (e.id = se.event_id) WHERE se.song_id = s.id) AS s_date FROM mg_songs s ORDER BY s_date desc

","You can sort the resulting collection by accessor, obviously the query can't be ordered, for it's not in the db.

$songs = Song::all(); // get the result
$songs-&gt;sortByDesc('lastDate'); // sort using collection method

// or ascending:
$songs-&gt;sortBy('lastDate');


You could achieve the same using joins, if you prefer to do this in the db call (it's better in terms of performance).



Another thing: you use if( ! $this-&gt;events) which will cause trouble soon.

Check this out:

// hasOne / belongsTo / morphTo etc - single relations
$model-&gt;relation; // returns related model OR null -&gt; evaluates to false

// BUT for hasMany / belongsToMany etc - multiple results
$model-&gt;relation; // always returns a collection, even if empty, evaluates to true


So change this if to:

public function getLastDateAttribute()
{
    if ( ! count($this-&gt;events)) return null;

    return $this-&gt;events[0]-&gt;date-&gt;formatLocalized('%d.%m.%Y (%a, %Hч)');
}}

"
5040,5040,8022,Powerpoint vba to change text gradient?,"Is there anything in Powerpoint vba (2007 or 2010) that lets you set or change the gradient colors on a text object (the text itself)? All I can find are presetTextEffect settings. Thanks.
",user2076996,https://stackoverflow.com/users/2076996,"Is this what you need?...



If so, here is the code which I made it with. You will need to improve it accordingly. There are plenty of formatting possibilities when applying gradient formation. Therefore I will suggest to experiment and checking VBA help for additional information.

Sub Test()
    Dim TXTbox As Shape
    Set TXTbox = ActivePresentation.Slides(1).Shapes(1)

        With TXTbox.TextFrame2.TextRange.Font.Fill
            .ForeColor.RGB = RGB(0, 128, 128)
            .OneColorGradient msoGradientHorizontal, 1, 1
        End With

End Sub

",Kazimierz Jawor,https://stackoverflow.com/users/2143262,http://stackoverflow.com/questions/16945623/powerpoint-vba-to-change-text-gradient,STACKOVERFLOW,stackoverflow.com,1.0,0.8888888888888888,0.0,1.0,1.0,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.3333333333333333,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,0.8888888888888888,0.8888888888888888,0.8,1.0,0.0,0.3333333333333333,0.7777777777777778,Does PowerPoint VBA change the text gradient?,Is there anything in PowerPoint VBA (2007 or 2010) that allows you to set or change the gradient of a text object (the text itself)? I can only find the default text effect settings. Thank you.,"Is this what you need?...



If so, here is the code which I made it with. You will need to improve it accordingly. There are plenty of formatting possibilities when applying gradient formation. Therefore I will suggest to experiment and checking VBA help for additional information.

Sub Test()
    Dim TXTbox As Shape
    Set TXTbox = ActivePresentation.Slides(1).Shapes(1)

        With TXTbox.TextFrame2.TextRange.Font.Fill
            .ForeColor.RGB = RGB(0, 128, 128)
            .OneColorGradient msoGradientHorizontal, 1, 1
        End With

End Sub

"
2737,2737,4363,How complex are sprite tasks usually allowed to be?,"What is the general consensus on how detailed a Sprite command can be? I know Sprite tasks aren't spent until the Technomancer changes the command, but does having conditional modifiers like ""if"" or ""if/else"" statements or specific details to objectives count as multiple Tasks? Can stuff like that count as a single Task until you give it other conditions, or would any change in activity count as a spent Task? Also, does a single task limit the sprite to use of a single Complex Form or Power, or can they use as many as they need to continue performing a task?
",Cobalt,https://rpg.stackexchange.com/users/4492,"I need to look in the book (so expect an edit later) but the way I view sprite tasks is sort of a ""Do While"" loop.  It'll execute its task until preset conditions are met.  Rather than give it multiple sets of commands, to me it would only make sense to have subsidiary sprites to deal with interfering tasks. 

Nested conditionals take a huge toll on the GM, especially if they are not technically minded towards following 4 step pseudocode much less priorities and algorithms.

Edit: Page 241 of the 20th Anniversary Edition book says...


  Continuous use of a specific power, whether on a single target
  or a group, counts as only one task. If the parameters of a task are
  changed, another task is used. Engaging opponents in a single node
  in cybercombat only counts as one task, regardless of the number of
  foes involved.

",CatLord,https://rpg.stackexchange.com/users/3273,http://rpg.stackexchange.com/questions/27463/how-complex-are-sprite-tasks-usually-allowed-to-be,CULTURE,rpg.stackexchange.com,1.0,0.5555555555555556,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.4444444444444444,1.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.3333333333333333,1.0,0.8888888888888888,How complex are sprite tasks usually allowed?,"What is the consensus on the level of detail of Sprite command? I know that sprite tasks will not be used until technomancer changes the command, but do conditional modifiers such as ""if"" or ""if / else"" statements or specific details of targets count as multiple tasks? Before you give it other conditions, can such a thing be counted as a separate task? Or is any change in the activity counted as an expensive task? Also, does a task restrict elves from using a complex form or power, or can they use as much as possible because they need to continue to perform a task?","I need to look in the book (so expect an edit later) but the way I view sprite tasks is sort of a ""Do While"" loop.  It'll execute its task until preset conditions are met.  Rather than give it multiple sets of commands, to me it would only make sense to have subsidiary sprites to deal with interfering tasks. 

Nested conditionals take a huge toll on the GM, especially if they are not technically minded towards following 4 step pseudocode much less priorities and algorithms.

Edit: Page 241 of the 20th Anniversary Edition book says...


  Continuous use of a specific power, whether on a single target
  or a group, counts as only one task. If the parameters of a task are
  changed, another task is used. Engaging opponents in a single node
  in cybercombat only counts as one task, regardless of the number of
  foes involved.

"
3761,3761,5988,"Netbook screen display is garbled (has black/white & horizontal line patterns, screen freezes, and/or wrong display position)","Upon powering my netbook on, its screen turns into a garbled display (has black/white patterns, horizontal line patterns, screen freezes and/or wrong display position). This distortion happens even at BIOS startup, continuing to Windows startup. Occasionally, the issue starts around 3 minutes after the Windows desktop appears.

Pictures of the monitor (click on image to enlarge):



  

More pictures at: http://imgur.com/a/ArME1

Details:   


This happens even in safe mode (the last picture above is of the
netbook screen in safe mode).  
I  connected the netbook to an external monitor (through VGA) and the display in the external monitor shows up just fine. I have been able to use the netbook without any issues with an external monitor.    
Aside from the monitor, the netbook still works (I can shut it down with keyboard shortcuts) and the files that it has shared through LAN can be accessed fine. The torrent client's web interface on the netbook can also still be accessed on another computer.  
The issue sometimes happens even at BIOS startup.  
The variations of the distortion will sometimes change randomly.   
Occasionally, the non-distorted screen display will simply freeze.
The netbook didn't fall in the ground or get hit by an object.  
The netbook is mostly used as a torrent seeder and downloader. Its lid is opened and closed around 2 times a day only, but the netbook is powered on almost 24/7 (its lid is closed most of the time). It is mostly accessed through another computer through LAN and is not often used directly.  
The netbook was bought around 2 years ago.  


What are the possible causes of this? Any possible fixes or methods of repair I can look into? The netbook is now out of warranty.

Netbook details:  


Model: Samsung NP-N150
OS:  Windows 7 Starter  
Graphics Chip: Intel GMA3150  
Monitor: Screen Size 10.1"", LED Backlit
Other specs here: http://www.samsung.com/us/computer/laptops/NP-N150-JA01US-specs

",galacticninja,https://superuser.com/users/10259,"Putting a live linux distribution on a USB stick would let you test hardware vs software easily.  Seeing what happens if you sit at the BIOS screen like Bobby suggested isn't a bad idea; but a pure textmode display will put significantly less load on the GPU than GUI desktop will.

Since the problem doesn't occur immediately on powerup, the only cause that seems likely to me is overheating.  Have you verified that the fan still spins.  Taking the bottom off and blowing out any accumulated dust should help here.

CoreTemp will let you monitor the CPU temperature; if it's really high the odds are your GPU is also overheating since the GPU and CPU are integrated but I'm not aware of anything to read the GPU temperature directly.
",Dan Neely,https://superuser.com/users/15990,http://superuser.com/questions/421513,TECHNOLOGY,superuser.com,1.0,0.4444444444444444,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.4444444444444444,0.6666666666666666,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,0.6666666666666666,0.8888888888888888,0.6666666666666666,0.8888888888888888,0.8888888888888888,0.9,1.0,0.0,0.6666666666666666,0.8888888888888888,"The screen of netbook is disordered (with black and white and horizontal line patterns, screen freezing and / or wrong display position)","Upon powering my netbook on, its screen turns into a garbled display (has black/white patterns, horizontal line patterns, screen freezes and/or wrong display position). This distortion happens even at BIOS startup, continuing to Windows startup. Occasionally, the issue starts around 3 minutes after the Windows desktop appears.

Pictures of the monitor (click on image to enlarge):



  

More pictures at: http://imgur.com/a/ArME1

Details:   


This happens even in safe mode (the last picture above is of the
netbook screen in safe mode).  
I  connected the netbook to an external monitor (through VGA) and the display in the external monitor shows up just fine. I have been able to use the netbook without any issues with an external monitor.    
Aside from the monitor, the netbook still works (I can shut it down with keyboard shortcuts) and the files that it has shared through LAN can be accessed fine. The torrent client's web interface on the netbook can also still be accessed on another computer.  
The issue sometimes happens even at BIOS startup.  
The variations of the distortion will sometimes change randomly.   
Occasionally, the non-distorted screen display will simply freeze.
The netbook didn't fall in the ground or get hit by an object.  
The netbook is mostly used as a torrent seeder and downloader. Its lid is opened and closed around 2 times a day only, but the netbook is powered on almost 24/7 (its lid is closed most of the time). It is mostly accessed through another computer through LAN and is not often used directly.  
The netbook was bought around 2 years ago.  


What are the possible causes of this? Any possible fixes or methods of repair I can look into? The netbook is now out of warranty.

Netbook details:  


Model: Samsung NP-N150
OS:  Windows 7 Starter  
Graphics Chip: Intel GMA3150  
Monitor: Screen Size 10.1"", LED Backlit
Other specs here: http://www.samsung.com/us/computer/laptops/NP-N150-JA01US-specs

","Putting a live linux distribution on a USB stick would let you test hardware vs software easily.  Seeing what happens if you sit at the BIOS screen like Bobby suggested isn't a bad idea; but a pure textmode display will put significantly less load on the GPU than GUI desktop will.

Since the problem doesn't occur immediately on powerup, the only cause that seems likely to me is overheating.  Have you verified that the fan still spins.  Taking the bottom off and blowing out any accumulated dust should help here.

CoreTemp will let you monitor the CPU temperature; if it's really high the odds are your GPU is also overheating since the GPU and CPU are integrated but I'm not aware of anything to read the GPU temperature directly.
"
4612,4612,7313,What are the variable costs for an information company?,"For a company like GoodGuide, who make their money not by selling a hard product (with investment costs etc) but by selling product placement and business intelligence, what are their variable costs?

I understand what variable costs are for a pizza shop, where the costs vary based on the number of pizzas made and sold. More product = higher costs.

But in general, how do you talk about variable costs for a company that provides information?
",CodyBugstein,https://money.stackexchange.com/users/9863,"One of the things that make internet companies so profitable is that there is no additional costs to ""sell another widget"".  With something like EBay, there is no additional cost to add another auction/sale.  While this is true for a single auction, it eventually becomes untrue.  If you add one million auctions, the company may pay additional bandwidth, storage fees, system engineering fees, and even development fees to make the site able to handle that much volume.

Sorry that I am unfamiliar with GoodGuide but I am sure you can extrapolate.  
",Pete B.,https://money.stackexchange.com/users/10613,http://money.stackexchange.com/questions/30705/what-are-the-variable-costs-for-an-information-company,LIFE_ARTS,money.stackexchange.com,0.8888888888888888,0.7777777777777778,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.4444444444444444,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.3333333333333333,0.6666666666666666,0.0,0.8888888888888888,0.8888888888888888,0.4444444444444444,0.8888888888888888,0.8888888888888888,0.6666666666666667,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.8888888888888888,What is the variable cost of an information company?,"For a company like GoodGuide, who make their money not by selling a hard product (with investment costs etc) but by selling product placement and business intelligence, what are their variable costs?

I understand what variable costs are for a pizza shop, where the costs vary based on the number of pizzas made and sold. More product = higher costs.

But in general, how do you talk about variable costs for a company that provides information?
","One reason Internet companies are so profitable is that there is no extra cost to ""sell another widget."". For sites like eBay, there's no extra cost to add another auction / sale. Although this is true for an auction, it turns out to be untrue in the end. If one million auctions are added, the company may pay for additional bandwidth, storage, system engineering, and even development fees to enable the site to handle so many transactions."
4525,4525,7170,Why is the 't' in Hash Table(Hashtable) in Java not capitalized,"Everything in Java seems to follow capitalization rules except for Hashtable. 

Hashtable&lt;String, String&gt; ht = new Hashtable&lt;String, String&gt;();


as opposed to 

ArrayList&lt;String&gt; a = new ArrayList&lt;String&gt;();


or 

HashMap&lt;String,Integer&gt; a = new HashMap&lt;String,Integer&gt;(); 


Why is this ? Is Hash Table read as just one word (Hashtable) ?
",Slartibartfast,https://stackoverflow.com/users/1081340,"Although this question has no technical value, I have to admit, I've asked myself this a couple of times :)

My version is that unlike List (ArrayList), Set (HashSet) , Map (Tree/HashMap) table is not a data structure.

Of course (its possibly known) that the Hashtable class was created before the collection framework (in java 1.0). So maybe at that point they didn't really thought about the same naming conventions.
In general we better use collection framework from java 2+ :)
",Mark Bramnik,https://stackoverflow.com/users/605153,http://stackoverflow.com/questions/12506706/why-is-the-t-in-hash-tablehashtable-in-java-not-capitalized,STACKOVERFLOW,stackoverflow.com,1.0,0.7777777777777778,0.0,1.0,1.0,1.0,0.5555555555555556,0.5555555555555556,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.8,0.0,0.0,1.0,1.0,Why is t in hash table not capitalized in Java,"Everything in Java seems to follow capitalization rules except for Hashtable. 

Hashtable&lt;String, String&gt; ht = new Hashtable&lt;String, String&gt;();


as opposed to 

ArrayList&lt;String&gt; a = new ArrayList&lt;String&gt;();


or 

HashMap&lt;String,Integer&gt; a = new HashMap&lt;String,Integer&gt;(); 


Why is this ? Is Hash Table read as just one word (Hashtable) ?
","Although this question has no technical value, I have to admit, I've asked myself this a couple of times :)

My version is that unlike List (ArrayList), Set (HashSet) , Map (Tree/HashMap) table is not a data structure.

Of course (its possibly known) that the Hashtable class was created before the collection framework (in java 1.0). So maybe at that point they didn't really thought about the same naming conventions.
In general we better use collection framework from java 2+ :)
"
445,445,694,How to change port number in vino?,"How to change port number in vino ubuntu 11.10?

Cannot find option to change from port 5900 on vino vnc 'remote desktop' window, nor can I find it via gconf-editor as was available in previous ubuntu version.

Please help
",Matt Perry,https://askubuntu.com/users/29396,"There is a brainstorm idea that was closed because it was thought of as a bug report: http://brainstorm.ubuntu.com/idea/25109/

Here is another question regarding this and the second answer mentions how to do it but I recommend using iptables: Enable remote VNC from the commandline?

UPDATE - As mentioned by the answer from Oli that would be the way to do it until the vino-preferences readds the option again.
",Luis Alvarado,https://askubuntu.com/users/7035,http://askubuntu.com/questions/69965/how-to-change-port-number-in-vino,TECHNOLOGY,askubuntu.com,1.0,0.8333333333333334,0.0,0.0,1.0,1.0,0.5,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,0.6666666666666666,0.6666666666666666,0.8333333333333334,1.0,0.6,0.0,0.0,1.0,1.0,How to change the port number in vino?,"How to change port number in vino ubuntu 11.10?

Cannot find option to change from port 5900 on vino vnc 'remote desktop' window, nor can I find it via gconf-editor as was available in previous ubuntu version.

Please help
","There is a brainstorm idea that was closed because it was thought of as a bug report: http://brainstorm.ubuntu.com/idea/25109/

Here is another question regarding this and the second answer mentions how to do it but I recommend using iptables: Enable remote VNC from the commandline?

UPDATE - As mentioned by the answer from Oli that would be the way to do it until the vino-preferences readds the option again.
"
1536,1536,2413,basic date comparsion for expiration checking,"i want to create a traffic lights system that will tell me how many days are left to go until a document reaches its expiration date.
I want it to be marked by colors in my html.


green: if the document has 31 days or more to go until it expires.
amber: 30 days or less until it expires.
red: for 7 days or less.


I also want to display a text, telling me how many days until expiration.
The expiration date comes from my database in the field called insurance_date

Heres my code i am new to php so struggling to put my code together, if someone could show me how to restructure my code in order to achieve what im trying to do id be greatful, thanks.

my code:

 &lt;?php 

   include 'config.php';
   $data = mysql_query(""SELECT * FROM supplier_stats"") 
   or die(mysql_error()); 

   while($info = mysql_fetch_array( $data )) 
   { 
     echo ""&lt;p&gt;Insurance Expires ! - &lt;font color=\""red\""&gt;"".$info['insurance_date'] . ""&lt;/font&gt;&lt;/p&gt;""; 

   } 

   $date_diff = 60*60*24*7; // 7 days
   // time()+$date_diff will be a timestamp 7 days in the future
   if ($info['insurance_date'] &lt; time()+$date_diff) {
    echo ""less than 7 days left!"";
   }

",user3488706,https://stackoverflow.com/users/3488706,"In your while loop, you iterate over all entries in the supplier_stats table.
For every iteration, you output ""&lt;p&gt;Insurance Expires ! ....
You probably do not want to do that.
Edit your query to only select the entries that will expire within your range.

Example:

SELECT * FROM supplier_stats WHERE insurance_date &gt;= yourDateToCompareTo


Depending on how you did set up your Database, insurance_date may be of 'MySQL Type DATE or String or even Integer. Depending on that, you have to make the Comparsion to check if the date is close to your expiration range.

After your loop (closed by }) you still use the $info in your if ($info['insurance_date'] which will only use the LAST entry in your table.

This is however a very, very basic Question and i'd advise you to read up on some very basic beginners tutorials which can be found easily using an internet search engine.
",Andresch Serj,https://stackoverflow.com/users/532495,http://stackoverflow.com/questions/23060541/basic-date-comparsion-for-expiration-checking,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.3333333333333333,0.0,1.0,0.6666666666666666,1.0,0.6666666666666666,0.4444444444444444,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,0.7777777777777778,Basic date comparison of overdue inspection,"i want to create a traffic lights system that will tell me how many days are left to go until a document reaches its expiration date.
I want it to be marked by colors in my html.


green: if the document has 31 days or more to go until it expires.
amber: 30 days or less until it expires.
red: for 7 days or less.


I also want to display a text, telling me how many days until expiration.
The expiration date comes from my database in the field called insurance_date

Heres my code i am new to php so struggling to put my code together, if someone could show me how to restructure my code in order to achieve what im trying to do id be greatful, thanks.

my code:

 &lt;?php 

   include 'config.php';
   $data = mysql_query(""SELECT * FROM supplier_stats"") 
   or die(mysql_error()); 

   while($info = mysql_fetch_array( $data )) 
   { 
     echo ""&lt;p&gt;Insurance Expires ! - &lt;font color=\""red\""&gt;"".$info['insurance_date'] . ""&lt;/font&gt;&lt;/p&gt;""; 

   } 

   $date_diff = 60*60*24*7; // 7 days
   // time()+$date_diff will be a timestamp 7 days in the future
   if ($info['insurance_date'] &lt; time()+$date_diff) {
    echo ""less than 7 days left!"";
   }

","In your while loop, you iterate over all entries in the supplier_stats table.
For every iteration, you output ""&lt;p&gt;Insurance Expires ! ....
You probably do not want to do that.
Edit your query to only select the entries that will expire within your range.

Example:

SELECT * FROM supplier_stats WHERE insurance_date &gt;= yourDateToCompareTo


Depending on how you did set up your Database, insurance_date may be of 'MySQL Type DATE or String or even Integer. Depending on that, you have to make the Comparsion to check if the date is close to your expiration range.

After your loop (closed by }) you still use the $info in your if ($info['insurance_date'] which will only use the LAST entry in your table.

This is however a very, very basic Question and i'd advise you to read up on some very basic beginners tutorials which can be found easily using an internet search engine.
"
1979,1979,3153,"Prove $[A,B^n] = nB^{n-1}[A,B]$","I am trying to show that $[A,B^n] = nB^{n-1}[A,B]$ where A and B are two Hermitian operators that commute with their commutator. However, I am running into a little problem and would like a hint of how to proceed.

If A and B commute then $[A,B] = ABA^{-1}B^{-1} = e$ where e is the identity element of the group.

$$\therefore AB=BA$$

$$n=1; [A,B^1] = (1)B^0[A,B] = e$$
This statement is certainly true. however moving on to $n = 2$ I find...

$$[A,B^2] = AB^2A^{-1}B^{-2} = ABBA^{-1}B^{-1}B^{-1} = BBAA^{-1}B^{-1}B^{-1}$$

Where in the last step I have used the fact that A and B commute to rearange the terms. However, it is plain to see that this last term simply reduces to the identity as well and for the n = 2 case we have:

$$[A,B^2] = e \ne 2B[A,B] = 2Be = 2B$$

Clearly I have assumed something I shouldn't have. The fact that there is a multiplicative factor of n implies I should be adding things, but I thought if I kept it as general as possible, the answer should just fall out naturally. I don't want an answer please, only guidance.
",user28823,https://physics.stackexchange.com/users/28823,"It seems that the question (v1) is caused by the fact that there are two different notions of the commutator: 


One for group theory: 
$$\tag{1} [A,B] ~:=~ ABA^{-1}B^{-1}$$ 
(or sometimes $[A,B] := A^{-1}B^{-1}AB$, depending on convention), which is relatively seldom used in physics.
One for rings/associative algebras: 
$$\tag{2} [A,B]:=AB-BA,$$ 
which is the definition usually used in physics. (This latter definition (2) generalizes to a supercommutator in superalgebras.)


The identity 

$$\tag{*}  [A,B^n] ~=~ nB^{n-1}[A,B]$$ 

holds in the latter sense (2), if $[[A,B],B]=0$. (It is not necessary to demand $[A,[A,B]]=0$.) More generally, for a sufficiently well-behaved function $f$, we have

$$\tag{**} [A,f(B)] ~=~ f^{\prime}(B)[A,B], $$

if $[[A,B],B]=0$. 

The group commutator (1) is dimensionless, which (among other things) makes the identity (*) unnatural to demand for group commutators.
",Qmechanic,https://physics.stackexchange.com/users/2451,http://physics.stackexchange.com/questions/78222/prove-a-bn-nbn-1a-b,SCIENCE,physics.stackexchange.com,0.6666666666666666,0.3333333333333333,0.0,1.0,1.0,1.0,0.5,0.5,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,1.0,"Prove $[a, B ^ n] = NB ^ {n-1} [a, b]$","I am trying to show that $[A,B^n] = nB^{n-1}[A,B]$ where A and B are two Hermitian operators that commute with their commutator. However, I am running into a little problem and would like a hint of how to proceed.

If A and B commute then $[A,B] = ABA^{-1}B^{-1} = e$ where e is the identity element of the group.

$$\therefore AB=BA$$

$$n=1; [A,B^1] = (1)B^0[A,B] = e$$
This statement is certainly true. however moving on to $n = 2$ I find...

$$[A,B^2] = AB^2A^{-1}B^{-2} = ABBA^{-1}B^{-1}B^{-1} = BBAA^{-1}B^{-1}B^{-1}$$

Where in the last step I have used the fact that A and B commute to rearange the terms. However, it is plain to see that this last term simply reduces to the identity as well and for the n = 2 case we have:

$$[A,B^2] = e \ne 2B[A,B] = 2Be = 2B$$

Clearly I have assumed something I shouldn't have. The fact that there is a multiplicative factor of n implies I should be adding things, but I thought if I kept it as general as possible, the answer should just fall out naturally. I don't want an answer please, only guidance.
","It seems that the question (v1) is caused by the fact that there are two different notions of the commutator: 


One for group theory: 
$$\tag{1} [A,B] ~:=~ ABA^{-1}B^{-1}$$ 
(or sometimes $[A,B] := A^{-1}B^{-1}AB$, depending on convention), which is relatively seldom used in physics.
One for rings/associative algebras: 
$$\tag{2} [A,B]:=AB-BA,$$ 
which is the definition usually used in physics. (This latter definition (2) generalizes to a supercommutator in superalgebras.)


The identity 

$$\tag{*}  [A,B^n] ~=~ nB^{n-1}[A,B]$$ 

holds in the latter sense (2), if $[[A,B],B]=0$. (It is not necessary to demand $[A,[A,B]]=0$.) More generally, for a sufficiently well-behaved function $f$, we have

$$\tag{**} [A,f(B)] ~=~ f^{\prime}(B)[A,B], $$

if $[[A,B],B]=0$. 

The group commutator (1) is dimensionless, which (among other things) makes the identity (*) unnatural to demand for group commutators.
"
5931,5931,9399,most basic laser diode driver?,"Is a simple LM317-based laser diode driver safe for powering a laser diode?
https://www.youtube.com/watch?v=iuMngik0GR8 (the diagram is at 1:37)


I've been told the the proprietary drivers offer some extra protection from very short spikes (on power up and shutdown) in the current which laser diodes are very sensitive to and might be damaged from. But isn't the LM317 regulator taking care of that itself already?

I've been told this from people who actually sell commercial laser diodes so I'm thinking they might be showing some bias.
",Leo Ervin,https://electronics.stackexchange.com/users/75978,"The main issue with the circuit you've shared is transients.

Some linear regulator circuits will tend to overshoot on turn-on, or allow input transients to pass through to the load. Here's the ripple rejection curve for TI's LM317:



You can see that the LM317 will do very little to protect the laser from transients with characteristic times below about 1 us. And an ESD event can easily have a pulse width as short as 1 ns.

And many laser diodes are quite sensitive to over-voltage and over-current. They may also respond very quickly to transients compared to other devices that you might connect to an LM317.

A good laser driver circuit should have ESD protection, transient protection, and a slow-start behavior.

These things are more important if you are driving a low-cost CD laser, or a high-speed telecommunications laser than if you are driving a high-power material processing laser. They may also be less important today than they were 20 years ago due to improvements in the robustness and reliability of newer laser designs.
",The Photon,https://electronics.stackexchange.com/users/6334,http://electronics.stackexchange.com/questions/169383/most-basic-laser-diode-driver,SCIENCE,electronics.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.0,1.0,1.0,The most basic laser diode driver?,"Is a simple LM317-based laser diode driver safe for powering a laser diode?
https://www.youtube.com/watch?v=iuMngik0GR8 (the diagram is at 1:37)


I've been told the the proprietary drivers offer some extra protection from very short spikes (on power up and shutdown) in the current which laser diodes are very sensitive to and might be damaged from. But isn't the LM317 regulator taking care of that itself already?

I've been told this from people who actually sell commercial laser diodes so I'm thinking they might be showing some bias.
","The main issue with the circuit you've shared is transients.

Some linear regulator circuits will tend to overshoot on turn-on, or allow input transients to pass through to the load. Here's the ripple rejection curve for TI's LM317:



You can see that the LM317 will do very little to protect the laser from transients with characteristic times below about 1 us. And an ESD event can easily have a pulse width as short as 1 ns.

And many laser diodes are quite sensitive to over-voltage and over-current. They may also respond very quickly to transients compared to other devices that you might connect to an LM317.

A good laser driver circuit should have ESD protection, transient protection, and a slow-start behavior.

These things are more important if you are driving a low-cost CD laser, or a high-speed telecommunications laser than if you are driving a high-power material processing laser. They may also be less important today than they were 20 years ago due to improvements in the robustness and reliability of newer laser designs.
"
3378,3378,5386,97 Honda Civic dies in neutral,"I have a 97 Honda Civic that will occasionally die in neutral. This is what I have done so far:


Replace both O2 sensors
Replace MAP sensor
Replace Air filter
Added Lucas treatment to fuel tank 


Even after the above changes, occasionally when coasting in neutral the rpm's will eventually drop to 0 and the engine will die. It starts back up just fine. My engine and fuel mileage have definitively improved with all the changes, especially after using Lucas.
",BrandonG,https://mechanics.stackexchange.com/users/4549,"My suspicion is it's related to the fuel system. So I'd be testing the fuel pressure. If fuel pressure is fine, then check the injectors.
",SimpleSimon,https://mechanics.stackexchange.com/users/4518,http://mechanics.stackexchange.com/questions/8856/97-honda-civic-dies-in-neutral,CULTURE,mechanics.stackexchange.com,0.8888888888888888,0.6666666666666666,0.3333333333333333,0.6666666666666666,1.0,0.6666666666666666,0.5555555555555556,0.5555555555555556,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,1.0,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,1.0,0.8888888888888888,0.8,0.0,0.3333333333333333,0.6666666666666666,0.7777777777777778,97 Honda Civic died in neutral,"I have a 97 Honda Civic that will occasionally die in neutral. This is what I have done so far:


Replace both O2 sensors
Replace MAP sensor
Replace Air filter
Added Lucas treatment to fuel tank 


Even after the above changes, occasionally when coasting in neutral the rpm's will eventually drop to 0 and the engine will die. It starts back up just fine. My engine and fuel mileage have definitively improved with all the changes, especially after using Lucas.
","My suspicion is it's related to the fuel system. So I'd be testing the fuel pressure. If fuel pressure is fine, then check the injectors.
"
118,118,187,How should I design a table with nested categories for users?,"I am really confused with user interface design of the website.
I want to design the Detailed view of the student.

So on the page there will be information about the students like name , class roll number etc.

Then i will have many rows for his smemesters , then each semester will have many subjects , then each subject will have many assignments.

Now i am not able to figure out how can i design the layout of the page.

can anyone give me idea or show me something on , how should i go
",user2082226,https://ux.stackexchange.com/users/27595,"So, I wish I had the time to sketch this out but I'll see if I can describe it. First off, you're going to need more than just a table.

The student information is the parent of all the other. Have that be the head section of your page, it should stay constant and as the main ""breadcrumb"" of the data. Then, use the semesters (if you're tracking years, use those first) as containers for the classes.

For the semesters, you could use tabs. Under the student information you could tab across each semester to see the class listing. This could be a table list view or an accordion. There are lots of options here.

From the list view, I would have a detail view that you could bring in with a number of different interactions for the assignments (modals, accordions, etc). Depending on if the assignments are actionable or not; are they an archive of completed assignments or a way to get to current assignment information? That would change how you show them I think.

I know that's hard to process in words, so I'd take a look at other UI that's have similar issues. Ones that come to mind are project tracking or high-end todo list apps. I'd look at those and see what patterns they use to help guide you. @Michael Lai also had great advice about grabbing paper and pencil and quickly starting to explore ideas. Just breaking out of the constraint of the original idea for a bit to sketch can often produce great answers.
",Erik Hanson,https://ux.stackexchange.com/users/27975,http://ux.stackexchange.com/questions/35391/how-should-i-design-a-table-with-nested-categories-for-users,TECHNOLOGY,ux.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,0.0,1.0,0.0,0.5555555555555556,0.5555555555555556,0.3333333333333333,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.6666666666666666,0.8888888888888888,0.6666666666666666,1.0,1.0,0.9333333333333332,0.6666666666666666,0.3333333333333333,0.0,1.0,How to design tables with nested categories for users?,"I am really confused with user interface design of the website.
I want to design the Detailed view of the student.

So on the page there will be information about the students like name , class roll number etc.

Then i will have many rows for his smemesters , then each semester will have many subjects , then each subject will have many assignments.

Now i am not able to figure out how can i design the layout of the page.

can anyone give me idea or show me something on , how should i go
","So, I wish I had the time to sketch this out but I'll see if I can describe it. First off, you're going to need more than just a table.

The student information is the parent of all the other. Have that be the head section of your page, it should stay constant and as the main ""breadcrumb"" of the data. Then, use the semesters (if you're tracking years, use those first) as containers for the classes.

For the semesters, you could use tabs. Under the student information you could tab across each semester to see the class listing. This could be a table list view or an accordion. There are lots of options here.

From the list view, I would have a detail view that you could bring in with a number of different interactions for the assignments (modals, accordions, etc). Depending on if the assignments are actionable or not; are they an archive of completed assignments or a way to get to current assignment information? That would change how you show them I think.

I know that's hard to process in words, so I'd take a look at other UI that's have similar issues. Ones that come to mind are project tracking or high-end todo list apps. I'd look at those and see what patterns they use to help guide you. @Michael Lai also had great advice about grabbing paper and pencil and quickly starting to explore ideas. Just breaking out of the constraint of the original idea for a bit to sketch can often produce great answers.
"
2499,2499,3986,How long does it take for a calf to be full grown in Harvest Moon A New Beginning?,"How long does it take for a calf to be full grown in Harvest Moon A New Beginning?
And for that fact, what about the other animals? (chicks, sheeps, you get the deal)
",MaryAnn,https://gaming.stackexchange.com/users/66145,"Calfs and other animals take 20 days to grow up after they are being born.
",BadSnowflake,https://gaming.stackexchange.com/users/62277,http://gaming.stackexchange.com/questions/149850/how-long-does-it-take-for-a-calf-to-be-full-grown-in-harvest-moon-a-new-beginnin,CULTURE,gaming.stackexchange.com,1.0,1.0,0.0,1.0,1.0,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,0.3333333333333333,0.8888888888888888,How long does it take for a calf to grow into a new beginning on the harvest moon?,"How long does it take for a calf to be full grown in Harvest Moon A New Beginning?
And for that fact, what about the other animals? (chicks, sheeps, you get the deal)
","Calfs and other animals take 20 days to grow up after they are being born.
"
5124,5124,8150,Missing Setup File,"I am facing below error. I have created web part in SharePoint 2010 solution and deploying that web part in Sharepoint 2013 Foundation. After I install webpart I face bellow error in central administrator.


  [MissingSetupFile] File [Features\4Project\ChangePassword\ChangePassword.webpart] is referenced [1] times in the database [WSS_Content_5000], but exists only under Microsoft SharePoint Foundation 2010 setup folder. Consider upgrading the feature/solution which contains this file to the latest version. One or more setup files are referenced in the database [WSS_Content_4500], but are not installed on the current farm. Please install any feature or solution which contains these files.

",user1337886,https://sharepoint.stackexchange.com/users/14575,"As the warning suggests you need to update the solution created for SP 2010 to be compatible with SP 2013. For that you need to convert the VS 2010 project to VS 2012/2013. Main things which need to be upgraded are Dot Net framework, assembly versions, reference to /_layouts/, ~/_CONTROLTEMPLATES
More info here:
http://sharepointnadeem.blogspot.com/2013/12/sharepoint-2013-upgrade-sharepoint-2010.html
",Nadeem Yousuf,https://sharepoint.stackexchange.com/users/9472,http://sharepoint.stackexchange.com/questions/91575/missing-setup-file,TECHNOLOGY,sharepoint.stackexchange.com,0.5555555555555556,0.3333333333333333,0.0,0.5,0.5,0.5,0.6666666666666666,0.5,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.5,0.5,0.0,0.4444444444444444,0.8888888888888888,0.6666666666666666,1.0,1.0,0.9,1.0,0.3333333333333333,0.6666666666666666,1.0,Missing installation file,"I am facing below error. I have created web part in SharePoint 2010 solution and deploying that web part in Sharepoint 2013 Foundation. After I install webpart I face bellow error in central administrator.


  [MissingSetupFile] File [Features\4Project\ChangePassword\ChangePassword.webpart] is referenced [1] times in the database [WSS_Content_5000], but exists only under Microsoft SharePoint Foundation 2010 setup folder. Consider upgrading the feature/solution which contains this file to the latest version. One or more setup files are referenced in the database [WSS_Content_4500], but are not installed on the current farm. Please install any feature or solution which contains these files.

","As indicated in the warning, you need to update the solution created for SP 2010 to be compatible with SP 2013. To do this, you need to convert the VS2010 project to vs2012 / 2013. The main contents that need to be upgraded are. Net framework, assembly version, reference to /'layouts /, ~ /'controltemplates"
538,538,847,Can I use a shock pump to inflate a tube?,"I know that shock pumps are meant for high pressure applications so that they can withstand high pressures needed by suspension shocks. 

However, can I use a shock pump to inflate my tire in a pinch if I run out of CO2?  How would it compare to a standard mini-pump in terms of volume? 
",Benzo,https://bicycles.stackexchange.com/users/2997,"A shock pump is designed to fill a very small volume of space with very high air pressures.

A tire pump is designed to fill a large volume of air, to relatively low pressures, pretty quickly.

You can technically fill a schrader valve tube using a shock pump, but because the volume of air for each repetition of the pump will be so low, it might take a week to fill the tire.

A shock pump will not mate with a presta valve at all.

On a practical level, you should use a shock pump to fill your shocks, and a tire pump to fill your tires.  
",zenbike,https://bicycles.stackexchange.com/users/1259,http://bicycles.stackexchange.com/questions/14643/can-i-use-a-shock-pump-to-inflate-a-tube,CULTURE,bicycles.stackexchange.com,0.7777777777777778,0.8888888888888888,0.0,0.6666666666666666,1.0,1.0,0.6666666666666666,0.4444444444444444,1.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.8888888888888888,1.0,0.6666666666666666,0.8888888888888888,1.0,1.0,0.0,0.0,1.0,1.0,Can I inflate the pipe with an impact pump?,"I know that shock pumps are meant for high pressure applications so that they can withstand high pressures needed by suspension shocks. 

However, can I use a shock pump to inflate my tire in a pinch if I run out of CO2?  How would it compare to a standard mini-pump in terms of volume? 
","A shock pump is designed to fill a very small volume of space with very high air pressures.

A tire pump is designed to fill a large volume of air, to relatively low pressures, pretty quickly.

You can technically fill a schrader valve tube using a shock pump, but because the volume of air for each repetition of the pump will be so low, it might take a week to fill the tire.

A shock pump will not mate with a presta valve at all.

On a practical level, you should use a shock pump to fill your shocks, and a tire pump to fill your tires.  
"
5341,5341,8483,Why can't my C++ compiler deduce template argument for boost function?,"I define a method like so:

template &lt;class ArgT&gt;
void foo(ArgT arg, ::boost::function&lt; void(ArgT) &gt; func)
{
    func(arg);
}


and use it like this --for instance--:

foo(2, [](int i) -&gt; void { cout &lt;&lt; i &lt;&lt; endl; });


Why can't the compiler deduce the type since it's definitely an int?

I get 'void foo(ArgT,boost::function&lt;void(ArgT)&gt;)' : could not deduce template argument for 'boost::function&lt;void(ArgT)&gt;' from 'anonymous-namespace'::&lt;lambda0&gt;'.
",mister why,https://stackoverflow.com/users/685664,"You want a conversion from the lambda function to boost::function&lt;void(ArgT)&gt; where ArgT is to be deduced. As a general rule, you cannot have type deduction and conversion in the same argument of a function: no conversions take place when deducing a template parameter.

The reasoning behind this is as follows. There are three types involved here: (1) the template parameter, (2) the function parameter type, (3) the passed object type. Two of the types (1 and 2) can be deduced from one another, but both are unknown. If the compiler can assume 2 and 3 are the same type, the problem is solved, but if all the compiler knows is that 3 can be converted to 2 there could be any number of possible solutions, and the compiler is not expected to solve the problem. In practice we know that in this particular case there is only one possible solution, but the standard does not make a distinction between cases.

The rule above applies in all deducible contexts, even if the template parameter can be deduced from another function parameter. The solution here is make the relevant function parameter a non-deducible context, ie a context in which the compiler will never attempt to deduce the template parameter from the function parameter. This can be done as follows:

template &lt;class T&gt; struct identity { typename T type; };

template &lt;class ArgT&gt;
void foo(ArgT arg, typename identity&lt;::boost::function&lt;void(ArgT)&gt;&gt;::type func)
{
  func(arg);
} 

",ymett,https://stackoverflow.com/users/611142,http://stackoverflow.com/questions/5871044/why-cant-my-c-compiler-deduce-template-argument-for-boost-function,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.6666666666666666,0.0,1.0,0.3333333333333333,1.0,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.6666666666666666,0.0,1.0,1.0,Why can't my C + + compiler derive template parameters for boost functions?,"I define a method like so:

template &lt;class ArgT&gt;
void foo(ArgT arg, ::boost::function&lt; void(ArgT) &gt; func)
{
    func(arg);
}


and use it like this --for instance--:

foo(2, [](int i) -&gt; void { cout &lt;&lt; i &lt;&lt; endl; });


Why can't the compiler deduce the type since it's definitely an int?

I get 'void foo(ArgT,boost::function&lt;void(ArgT)&gt;)' : could not deduce template argument for 'boost::function&lt;void(ArgT)&gt;' from 'anonymous-namespace'::&lt;lambda0&gt;'.
","You want a conversion from the lambda function to boost::function&lt;void(ArgT)&gt; where ArgT is to be deduced. As a general rule, you cannot have type deduction and conversion in the same argument of a function: no conversions take place when deducing a template parameter.

The reasoning behind this is as follows. There are three types involved here: (1) the template parameter, (2) the function parameter type, (3) the passed object type. Two of the types (1 and 2) can be deduced from one another, but both are unknown. If the compiler can assume 2 and 3 are the same type, the problem is solved, but if all the compiler knows is that 3 can be converted to 2 there could be any number of possible solutions, and the compiler is not expected to solve the problem. In practice we know that in this particular case there is only one possible solution, but the standard does not make a distinction between cases.

The rule above applies in all deducible contexts, even if the template parameter can be deduced from another function parameter. The solution here is make the relevant function parameter a non-deducible context, ie a context in which the compiler will never attempt to deduce the template parameter from the function parameter. This can be done as follows:

template &lt;class T&gt; struct identity { typename T type; };

template &lt;class ArgT&gt;
void foo(ArgT arg, typename identity&lt;::boost::function&lt;void(ArgT)&gt;&gt;::type func)
{
  func(arg);
} 

"
3470,3470,5531,Can you use Divine Bond (Weapon) with Magic Weapon Spell?,"Can a Paladin use his Divine Bond (Weapon) on a weapon where Magic Weapon has been caste and does this count as a +1 for the purpose of adding a magic weapon feature?
",David Allan Finch,https://rpg.stackexchange.com/users/768,"According to the Pathfinder SRD site, 


  These bonuses can be added to the weapon, stacking with existing weapon bonuses to a maximum of +5


So you can take the +1 weapon after the Magic Weapon spell, and add up to +4 worth of bonus to it from the Bond.  So you won't supercede the bonus until level 17, where I imagine you'll have much better than just a level 1 Magic Weapon spell. 

EDIT: I forgot to address the DR question.  In which case I reference:


  Any weapon with at least a +1 magical enhancement bonus on attack and damage rolls overcomes the damage reduction of these monsters.


Also just to have the full ability written out:


  At 5th level, this spirit grants the weapon a +1 enhancement bonus. For every three levels beyond 5th, the weapon gains another +1 enhancement bonus, to a maximum of +6 at 20th level. These bonuses can be added to the weapon, stacking with existing weapon bonuses to a maximum of +5, or they can be used to add any of the following weapon properties: axiomatic, brilliant energy, defending, disruption, flaming, flaming burst, holy, keen, merciful, and speed. Adding these properties consumes an amount of bonus equal to the property's cost (see Table: Melee Weapon Special Abilities). These bonuses are added to any properties the weapon already has, but duplicate abilities do not stack. If the weapon is not magical, at least a +1 enhancement bonus must be added before any other properties can be added.


Therefore, whatever the final +X bonus comes out to be is the DR bypass.
",CatLord,https://rpg.stackexchange.com/users/3273,http://rpg.stackexchange.com/questions/14991/can-you-use-divine-bond-weapon-with-magic-weapon-spell,CULTURE,rpg.stackexchange.com,0.7777777777777778,0.7777777777777778,0.0,1.0,1.0,1.0,0.6666666666666666,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.8888888888888888,0.8888888888888888,1.0,0.8888888888888888,0.8888888888888888,0.8666666666666666,0.0,0.0,1.0,1.0,Can you use the holy combination (weapon) and magic weapon spell?,"Can a paladin use his holy enchantment on a weapon that has been cast with magic weapons? In order to add a magic weapon feature, will this value be calculated as + 1?","According to the Pathfinder SRD site, 


  These bonuses can be added to the weapon, stacking with existing weapon bonuses to a maximum of +5


So you can take the +1 weapon after the Magic Weapon spell, and add up to +4 worth of bonus to it from the Bond.  So you won't supercede the bonus until level 17, where I imagine you'll have much better than just a level 1 Magic Weapon spell. 

EDIT: I forgot to address the DR question.  In which case I reference:


  Any weapon with at least a +1 magical enhancement bonus on attack and damage rolls overcomes the damage reduction of these monsters.


Also just to have the full ability written out:


  At 5th level, this spirit grants the weapon a +1 enhancement bonus. For every three levels beyond 5th, the weapon gains another +1 enhancement bonus, to a maximum of +6 at 20th level. These bonuses can be added to the weapon, stacking with existing weapon bonuses to a maximum of +5, or they can be used to add any of the following weapon properties: axiomatic, brilliant energy, defending, disruption, flaming, flaming burst, holy, keen, merciful, and speed. Adding these properties consumes an amount of bonus equal to the property's cost (see Table: Melee Weapon Special Abilities). These bonuses are added to any properties the weapon already has, but duplicate abilities do not stack. If the weapon is not magical, at least a +1 enhancement bonus must be added before any other properties can be added.


Therefore, whatever the final +X bonus comes out to be is the DR bypass.
"
3390,3390,5404,most basic laser diode driver?,"Is a simple LM317-based laser diode driver safe for powering a laser diode?
https://www.youtube.com/watch?v=iuMngik0GR8 (the diagram is at 1:37)


I've been told the the proprietary drivers offer some extra protection from very short spikes (on power up and shutdown) in the current which laser diodes are very sensitive to and might be damaged from. But isn't the LM317 regulator taking care of that itself already?

I've been told this from people who actually sell commercial laser diodes so I'm thinking they might be showing some bias.
",Leo Ervin,https://electronics.stackexchange.com/users/75978,"If you have a regulated power supply, a simple resistor will do to take the laser above its threshold point. More complexity can involve a thermistor to lower resistance as temperature rises keeping the laser current at a slightly higher value at higher temperatures. Here is a typical laser characteristic for a device supplied by Hamamatsu: -



A more complex circuit would be needed if the laser were to be used as a datacomms device but this would involve only one extra inductor and a capacitor.

Going further, to higher powers and several manufacturers make chips that monitor the inbuilt photodiode inside a lot of lasers. They do this to protect the device from excessive currents.

Using an LM317 current limiting supply seems reasonable to me but the devil is in the detail and a circuit would be needed to be looked at for greater confidence (plus the data sheet of the laser).
",Andy aka,https://electronics.stackexchange.com/users/20218,http://electronics.stackexchange.com/questions/169383/most-basic-laser-diode-driver,SCIENCE,electronics.stackexchange.com,1.0,0.6666666666666666,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.0,1.0,0.8888888888888888,The most basic laser diode driver?,"Is a simple LM317-based laser diode driver safe for powering a laser diode?
https://www.youtube.com/watch?v=iuMngik0GR8 (the diagram is at 1:37)


I've been told the the proprietary drivers offer some extra protection from very short spikes (on power up and shutdown) in the current which laser diodes are very sensitive to and might be damaged from. But isn't the LM317 regulator taking care of that itself already?

I've been told this from people who actually sell commercial laser diodes so I'm thinking they might be showing some bias.
","If you have a regulated power supply, a simple resistor will do to take the laser above its threshold point. More complexity can involve a thermistor to lower resistance as temperature rises keeping the laser current at a slightly higher value at higher temperatures. Here is a typical laser characteristic for a device supplied by Hamamatsu: -



A more complex circuit would be needed if the laser were to be used as a datacomms device but this would involve only one extra inductor and a capacitor.

Going further, to higher powers and several manufacturers make chips that monitor the inbuilt photodiode inside a lot of lasers. They do this to protect the device from excessive currents.

Using an LM317 current limiting supply seems reasonable to me but the devil is in the detail and a circuit would be needed to be looked at for greater confidence (plus the data sheet of the laser).
"
168,168,265,Why is the pixel count of RAW images from the Panasonic LX5 slightly larger than the generated JPEGs?,"I'm new to working with RAW images, and I'm capturing simultaneous RAW+JPGs with my new Lumix LX5, and using Bibble to view/process the results.

I'm very surprised that the RAW images taken at 24mm wide 16x9 seem to capture a different (and larger) sensor area compared to the JPGs. The RAW images seem to contain the equivalent of about 100 extra pixels on left and right sides, and a smaller number top and bottom. I say ""equivalent"", because the actual pixel counts of RAW and JPG are only slightly different, which implies some resizing must be going on...?

JPG: 3968 x 2232
RAW: 3976 x 2238

I guess this small difference is because JPG images must be 16x16 multiples>

The raw image displays noticeable vignetting in the extra pixels, and there's a fair bit of chromatic aberration. I can crop off the 'extra' pixels, but then my RAW image has fewer pixels in it than the JPG, which doesn't feel right. 

I'll try and add samples shortly.
",Roddy,https://photo.stackexchange.com/users/562,"I think this is happening because Bibble (at least the version you're using) isn't applying the metadata in the LX5's RW2 file that tells it how to correct for the lens' deformations. Perhaps this is a setting in Bibble, or a missing feature in their RW2 converter. I'll bet if you convert your RW2's to DNG with Adobe's free DNG converter, Bibble be able to read and apply that data and produce a 'corrected' image. 

I've come to this conclusion (and found your question) by noticing the same artifacts you mentioned when using Picasa 3.8 to view images created using Adobe DNG Converter 6.4.0.139 from my LX5's RAW files. This happens when I ask Adobe DNG Converter to create files for ""Camera Raw 5.4 and later"", the max setting. This theory was backed up by the fact that the JPG preview looks corrected when compared to the image rendered by Picasa when it renders the DNG. Not only that, but the JPG preview rendered by Adobe DNG converter matches the JPG's that came straight from the camera for the same shot (clearly the converter is applying the same transformations that the camera did internally to make the JPG).

After playing around a bit, I discovered that the artifacts go away in Picasa 3.8 when I have the DNG Converter create files for ""Camera Raw 4.6 and later"". I assume this means Picasa 3.8 doesn't understand Camera Raw 5.4, but it CAN understand Camera Raw 4.6, and will apply the correction automatically to conforming DNG files. No more corner vignette and barrel distortion on the resulting DNG files in Picasa, and in theory all the information from the RW2 is in the DNG!

Also - I wouldn't be put off by the correction - it's a good thing - and supposedly no information is thrown away. The DNG / RW2 files contain the raw sensor data plus additional information on the lens / camera aberrations, and viewing software can elect to apply these transformations or not. The 'true' sensor data can always be accessed.
",Jeff Jones,https://photo.stackexchange.com/users/5394,http://photo.stackexchange.com/questions/4242/why-is-the-pixel-count-of-raw-images-from-the-panasonic-lx5-slightly-larger-than,LIFE_ARTS,photo.stackexchange.com,1.0,0.7777777777777778,0.0,0.3333333333333333,1.0,1.0,0.4444444444444444,0.4444444444444444,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.6666666666666666,1.0,0.8888888888888888,Why is the original image pixel number of Panasonic LX5 slightly larger than the generated JPEG?,"I'm new to working with RAW images, and I'm capturing simultaneous RAW+JPGs with my new Lumix LX5, and using Bibble to view/process the results.

I'm very surprised that the RAW images taken at 24mm wide 16x9 seem to capture a different (and larger) sensor area compared to the JPGs. The RAW images seem to contain the equivalent of about 100 extra pixels on left and right sides, and a smaller number top and bottom. I say ""equivalent"", because the actual pixel counts of RAW and JPG are only slightly different, which implies some resizing must be going on...?

JPG: 3968 x 2232
RAW: 3976 x 2238

I guess this small difference is because JPG images must be 16x16 multiples>

The raw image displays noticeable vignetting in the extra pixels, and there's a fair bit of chromatic aberration. I can crop off the 'extra' pixels, but then my RAW image has fewer pixels in it than the JPG, which doesn't feel right. 

I'll try and add samples shortly.
","I think this is happening because Bibble (at least the version you're using) isn't applying the metadata in the LX5's RW2 file that tells it how to correct for the lens' deformations. Perhaps this is a setting in Bibble, or a missing feature in their RW2 converter. I'll bet if you convert your RW2's to DNG with Adobe's free DNG converter, Bibble be able to read and apply that data and produce a 'corrected' image. 

I've come to this conclusion (and found your question) by noticing the same artifacts you mentioned when using Picasa 3.8 to view images created using Adobe DNG Converter 6.4.0.139 from my LX5's RAW files. This happens when I ask Adobe DNG Converter to create files for ""Camera Raw 5.4 and later"", the max setting. This theory was backed up by the fact that the JPG preview looks corrected when compared to the image rendered by Picasa when it renders the DNG. Not only that, but the JPG preview rendered by Adobe DNG converter matches the JPG's that came straight from the camera for the same shot (clearly the converter is applying the same transformations that the camera did internally to make the JPG).

After playing around a bit, I discovered that the artifacts go away in Picasa 3.8 when I have the DNG Converter create files for ""Camera Raw 4.6 and later"". I assume this means Picasa 3.8 doesn't understand Camera Raw 5.4, but it CAN understand Camera Raw 4.6, and will apply the correction automatically to conforming DNG files. No more corner vignette and barrel distortion on the resulting DNG files in Picasa, and in theory all the information from the RW2 is in the DNG!

Also - I wouldn't be put off by the correction - it's a good thing - and supposedly no information is thrown away. The DNG / RW2 files contain the raw sensor data plus additional information on the lens / camera aberrations, and viewing software can elect to apply these transformations or not. The 'true' sensor data can always be accessed.
"
5288,5288,8397,Highcharts - Cannot set x-axes categories in column charts with negative values,"Hi I have a column chart with negative values which is showing wrong x-axes categories value. I'm sending a pre-build JSON array from the server , but no matter what i can't get the x-axes categories to show the right values.

Here is the code :

     var chart_data = JSON.parse(data).avg_range;


                        console.log(chart_data.x_axes);

                        var safety_chart_average = {
                            chart: {
                                type: 'column',
                                renderTo: pattern + '-safety-mini-chart-section',
                                spacingRight: 20,
                                spacingLeft: 20,
                            },
                            rangeSelector: {
                                enabled: false
                            },
                            navigator: {
                                enabled: false
                            },
                            scrollbar: {
                                enabled: false
                            },
                            credits: {
                                enabled: false
                            },
                            title: {
                                text: ""Avg Changes"",
                                marginBottom: -10
                            },
                            xAxis: {
                                categories: chart_data.x_axes
                            },
                            series: chart_data.prices


 };


This is what i'm getting



The x-axes is showing wrong values, as you can see from the picture above. 

But console.log(chart_data.x_axes) gives 
[""Day 1"", ""Day 2"", ""Day 3""] which should be the correct x-axes label.

Please let me know how can i fix this x-axes label error. 
",Maxx,https://stackoverflow.com/users/2536469,"Highstock is containing all of Highcharts options. All you need is to change constructor. So in steps:


include Highstock: &lt;script scr=""http://code.highcharts.com/stock/highstock.js""&gt;&lt;/script&gt;
when you need Highstock, call: new Highcharts.StockChart(options)
when you need Highcharts, call: new Highcharts.Chart(options)

",Paweł Fus,https://stackoverflow.com/users/1451635,http://stackoverflow.com/questions/24596073/highcharts-cannot-set-x-axes-categories-in-column-charts-with-negative-values,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.6666666666666666,0.0,1.0,1.0,1.0,0.5555555555555556,0.5555555555555556,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,0.7777777777777778,Highcharts - cannot set the x-axis category in a column chart with negative values,"Hi I have a column chart with negative values which is showing wrong x-axes categories value. I'm sending a pre-build JSON array from the server , but no matter what i can't get the x-axes categories to show the right values.

Here is the code :

     var chart_data = JSON.parse(data).avg_range;


                        console.log(chart_data.x_axes);

                        var safety_chart_average = {
                            chart: {
                                type: 'column',
                                renderTo: pattern + '-safety-mini-chart-section',
                                spacingRight: 20,
                                spacingLeft: 20,
                            },
                            rangeSelector: {
                                enabled: false
                            },
                            navigator: {
                                enabled: false
                            },
                            scrollbar: {
                                enabled: false
                            },
                            credits: {
                                enabled: false
                            },
                            title: {
                                text: ""Avg Changes"",
                                marginBottom: -10
                            },
                            xAxis: {
                                categories: chart_data.x_axes
                            },
                            series: chart_data.prices


 };


This is what i'm getting



The x-axes is showing wrong values, as you can see from the picture above. 

But console.log(chart_data.x_axes) gives 
[""Day 1"", ""Day 2"", ""Day 3""] which should be the correct x-axes label.

Please let me know how can i fix this x-axes label error. 
","Highstock is containing all of Highcharts options. All you need is to change constructor. So in steps:


include Highstock: &lt;script scr=""http://code.highcharts.com/stock/highstock.js""&gt;&lt;/script&gt;
when you need Highstock, call: new Highcharts.StockChart(options)
when you need Highcharts, call: new Highcharts.Chart(options)

"
5466,5466,8677,Difficulties with re-using a variable,"here is a part of my code :

class projet(object):

    def nameCouche(self):

        valLissage = float(ui.valLissage.displayText())    
        return (valLissage)         
    valCouche = nameCouche() # asks for a positional argument but 'self' doesnt work   

    def choixTraitement(self):
        ui.okLissage.clicked.connect(p.goLissage)

    def goLissage(self, valCouche):
        if ui.chkboxLissage.isChecked():
            print(valCouche) # result is False
            os.system(r'""C:\Program Files\FME\fme.exe"" D:\Stelios\..... --MAX_NUM_POINTS {0}'.format(valCouche))


So I would like to use valCouche in goLissage method but it doesnt work.
I thought that valCouche would have the argument of valLissage but instead it gives False as a value.
I've tried different alternatives but still doesnt work.
",guy16,https://stackoverflow.com/users/4862605,"You've got multiple problems here.

First, if you write this in the middle of a class definition:

valCouche = nameCouche()


... you're creating a class attribute, which is shared by all instances, not a normal instance attribute.

Also, you're running this at class definition time. That means there is no self yet--there aren't any instances yet to be self--so you can't call a method like nameCouche, because you don't have anything to call it on.

What you want to do is call the method at instance initialization time, on the instance being initialized, and store the return value in an instance attribute:

def __init__(self):
    self.valCouche = self.nameCouche()


Then, when you want to access this value in another method later, you have to access it as self.valCouche.



If you make those changes, it will work. But your object model still doesn't make much sense. Why is nameCouche a method when it doesn't have anything to do with the object, and doesn't access any of its attributes? Maybe it makes sense as a @staticmethod, but really, I think it makes more sense just as a plain function outside the class. In fact, none of the code you've written seems to have anything to do with the class. 

This kind of cram-everything-into-the-class design is often a sign that you're trying to write Java code in Python, and haven't yet really understood how Python does OO. You might want to read a good tutorial on Python classes. But briefly: if you're writing a class just to have somewhere to dump a bunch of vaguely-related functions, what you want is a module, not a class. If you have some reason to have instances of that class, and the functions all act on the data of each instance, then you want a class.
",abarnert,https://stackoverflow.com/users/908494,http://stackoverflow.com/questions/30344855,STACKOVERFLOW,stackoverflow.com,0.5555555555555556,0.4444444444444444,0.0,1.0,1.0,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,0.0,0.5555555555555556,1.0,0.7777777777777778,1.0,1.0,0.9333333333333332,1.0,0.0,1.0,1.0,Difficulty in reusing variables,"here is a part of my code :

class projet(object):

    def nameCouche(self):

        valLissage = float(ui.valLissage.displayText())    
        return (valLissage)         
    valCouche = nameCouche() # asks for a positional argument but 'self' doesnt work   

    def choixTraitement(self):
        ui.okLissage.clicked.connect(p.goLissage)

    def goLissage(self, valCouche):
        if ui.chkboxLissage.isChecked():
            print(valCouche) # result is False
            os.system(r'""C:\Program Files\FME\fme.exe"" D:\Stelios\..... --MAX_NUM_POINTS {0}'.format(valCouche))


So I would like to use valCouche in goLissage method but it doesnt work.
I thought that valCouche would have the argument of valLissage but instead it gives False as a value.
I've tried different alternatives but still doesnt work.
","You've got multiple problems here.

First, if you write this in the middle of a class definition:

valCouche = nameCouche()


... you're creating a class attribute, which is shared by all instances, not a normal instance attribute.

Also, you're running this at class definition time. That means there is no self yet--there aren't any instances yet to be self--so you can't call a method like nameCouche, because you don't have anything to call it on.

What you want to do is call the method at instance initialization time, on the instance being initialized, and store the return value in an instance attribute:

def __init__(self):
    self.valCouche = self.nameCouche()


Then, when you want to access this value in another method later, you have to access it as self.valCouche.



If you make those changes, it will work. But your object model still doesn't make much sense. Why is nameCouche a method when it doesn't have anything to do with the object, and doesn't access any of its attributes? Maybe it makes sense as a @staticmethod, but really, I think it makes more sense just as a plain function outside the class. In fact, none of the code you've written seems to have anything to do with the class. 

This kind of cram-everything-into-the-class design is often a sign that you're trying to write Java code in Python, and haven't yet really understood how Python does OO. You might want to read a good tutorial on Python classes. But briefly: if you're writing a class just to have somewhere to dump a bunch of vaguely-related functions, what you want is a module, not a class. If you have some reason to have instances of that class, and the functions all act on the data of each instance, then you want a class.
"
2640,2640,4198,"Do electric fields generated by plane charges lose intensity over distance? If not, why?","Sparknotes' studyguide for the SAT II: Physics test says that for a point charge (1-dimensional, e.g. an electron), the formula for intensity of the generated electric field is given by $E=\frac{kq}{r^2}$. It also says that for a line charge (2-dimensional, e.g. a wire in a DC circuit), it's given by $E=\frac{kq}{r}$, and that for a plane charge (3-dimensional) it's given by $E=kq$. I have no example for a plane charge because I don't know what that would be, hence my question: How can a plane charge's electric field intensity NOT diminish over time? Shouldn't this violate Conservation of Energy?
",apparently_I_am_user35073,https://physics.stackexchange.com/users/35073,"A plane charge would be an infinite 2-dimensional sheet with constant charge density. Already in a line charge you have neglected edge effects, because the $1/r$ dependence holds true only near the line provided you are far away from the end-points. Similarly, for a plane, the constant electric field holds true provided that you are much closer to the plane than you are to it's edges. You make this approximation when you derive the electric field inside a parallel plate capacitor, for example. If you truly could assemble an infinite sheet of charge, conservation of energy would be the least of your worries. Good luck with the SAT.
",lionelbrits,https://physics.stackexchange.com/users/31635,http://physics.stackexchange.com/questions/88640/do-electric-fields-generated-by-plane-charges-lose-intensity-over-distance-if-n,SCIENCE,physics.stackexchange.com,1.0,0.7777777777777778,0.0,0.3333333333333333,1.0,1.0,0.8888888888888888,0.6666666666666666,0.6666666666666666,0.0,0.0,0.6666666666666666,0.0,0.0,0.3333333333333333,0.0,0.0,0.3333333333333333,1.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.3333333333333333,1.0,1.0,"Does the electric field generated by plane charge lose its strength in distance? If not, why?","SparkNotes's SAT II: physical experimental research guide says that for a point charge (1-D, such as an electron), the formula of the electric field intensity generated is given by $e = \ frac {KQ} {R ^ 2} $. It also says that for line charges (two dimensions, such as wires in a DC circuit), it is given by $e = \ frac {KQ} {r} $; for plane charges (three dimensions), it is given by $e = KQ $. I don't have an example of a plane charge, because I don't know what that is, so my question is: how can the electric field strength of a plane charge not decrease with time? Is this not against the conservation of energy?","A plane charge would be an infinite 2-dimensional sheet with constant charge density. Already in a line charge you have neglected edge effects, because the $1/r$ dependence holds true only near the line provided you are far away from the end-points. Similarly, for a plane, the constant electric field holds true provided that you are much closer to the plane than you are to it's edges. You make this approximation when you derive the electric field inside a parallel plate capacitor, for example. If you truly could assemble an infinite sheet of charge, conservation of energy would be the least of your worries. Good luck with the SAT.
"
493,493,768,"Usage of ""might"" and ""would"" to indicate doubt","Do the sentences 


  She might be only 28, but Jodie
  Whittaker....


and


  My parents would have walked along the
  Barrow


wrongly suggest doubt, or are they normal usage? Are there names for these constructions?
Taken from Irish Times .



I googled ""would have spent their time"". 
Many cases were counterfactuals (""... otherwise they would have spent their time...”)
But plenty simply describe past events, as the in the usage sited above.
I couldn't detect a regional bias.
As an Irish-English speaker this usage is unremarkable for example I might say


  This is the exact spot where Caesar
  would have crossed the Rubicon


I think the intention is to evoke the event rather than just record it.
",cindi,https://english.stackexchange.com/users/122,"Might implies possibility.


  She might be 28, but she very well could be older.


Would implies intent.


  My parents would have walked along the Barrow had they lived by it. 


I don't think either of your statements imply doubt of any kind.
",J A Terroba,https://english.stackexchange.com/users/67845,http://english.stackexchange.com/questions/3541/usage-of-might-and-would-to-indicate-doubt,CULTURE,english.stackexchange.com,1.0,0.4444444444444444,0.0,1.0,0.6666666666666666,1.0,0.6666666666666666,0.8888888888888888,0.6666666666666666,0.0,0.6666666666666666,0.0,0.3333333333333333,0.0,0.3333333333333333,0.0,0.0,0.0,0.6666666666666666,0.0,0.8888888888888888,0.7777777777777778,0.6666666666666666,0.8888888888888888,1.0,0.8,0.0,0.0,0.6666666666666666,1.0,"Use ""may"" and ""will"" to express doubt","Do the sentences 


  She might be only 28, but Jodie
  Whittaker....


and


  My parents would have walked along the
  Barrow


wrongly suggest doubt, or are they normal usage? Are there names for these constructions?
Taken from Irish Times .



I googled ""would have spent their time"". 
Many cases were counterfactuals (""... otherwise they would have spent their time...”)
But plenty simply describe past events, as the in the usage sited above.
I couldn't detect a regional bias.
As an Irish-English speaker this usage is unremarkable for example I might say


  This is the exact spot where Caesar
  would have crossed the Rubicon


I think the intention is to evoke the event rather than just record it.
","Might implies possibility.


  She might be 28, but she very well could be older.


Would implies intent.


  My parents would have walked along the Barrow had they lived by it. 


I don't think either of your statements imply doubt of any kind.
"
5685,5685,9013,Control 8V H-Bridge with microcontroller,"Good afternoon.

I've been trying to control an 8V H-Bridge (PMOS+NMOS) with a 4V microcontroller output signal. I thouth it would work but then i read that the PMOS source voltage had to be equal or smaller than the control voltage in the PMOS/NMOS gates. Does somebody know how to deal with this problem (without adding much more electronics)?


",Electronics_Guy,https://electronics.stackexchange.com/users/43113,"If you don't need to PWM very fast you can simply use a low-to-high logic level converter from the 4000 family (eg. CD40109B). Drive current is only a few mA so they'll not drive big MOSFETs fast. 

There are plenty of gate-driver chips if you need to drive a big MOSFET fast (hundreds of mA or amperes of current drive to supply the gate charge fast), but they tend to be more expensive. 
",Spehro Pefhany,https://electronics.stackexchange.com/users/35530,http://electronics.stackexchange.com/questions/111090/control-8v-h-bridge-with-microcontroller,SCIENCE,electronics.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.3333333333333333,1.0,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,0.0,1.0,Control 8V H bridge with single chip microcomputer,"Good afternoon.

I've been trying to control an 8V H-Bridge (PMOS+NMOS) with a 4V microcontroller output signal. I thouth it would work but then i read that the PMOS source voltage had to be equal or smaller than the control voltage in the PMOS/NMOS gates. Does somebody know how to deal with this problem (without adding much more electronics)?


","If you don't need fast PWM, you can simply use a low to high logic level converter from the 4000 series (such as the cd40109b). The driving current is only a few milliamps, so they will not drive large MOSFETs quickly."
2273,2273,3622,Firefox 4 Downgrades to Firefox 3.6 on Windows 7,"On my Windows 7 x64 computer, Firefox 4 has seamlessly downgraded itself to Firefox 3.6 twice.  I haven't determined exactly when this is occurring, but the second time was when restarting after adding GreaseMonkey.  It is possible the first time was also after adding an add-on.  

Re-upgrading to 4.0 seems to work perfectly.

How can I stop this from happening again?
",C. Ross,https://superuser.com/users/856,"It may be a problem within your profile.

Personally I would backup the contents of C:\Users\Username\AppData\Roaming\Mozilla\Firefox (Just Rename the directory)

Then uninstall Firefox completely, go to C:\Program Files (x86)\Mozilla\ (Mozilla Firefox, whatever it is) and make sure that directory doesn't exist or if it does, check the contents, backup if necessary and remove.

Re-install Firefox, it should be a fresh installation now, give the update a try and see what happens after.
",Sandeep Bansal,https://superuser.com/users/46390,http://superuser.com/questions/286444,TECHNOLOGY,superuser.com,1.0,0.5555555555555556,0.0,0.6666666666666666,1.0,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.8888888888888888,"On Windows 7, Firefox 4 is downgraded to Firefox 3.6","On my windows 7 X64 computer, Firefox 4 has seamlessly downgraded itself to Firefox 3.6 twice. I'm not sure when this happened, but the second time it was rebooted after adding Greasemonkey. It's possible that for the first time, it's also after adding add ons.","It may be a problem within your profile.

Personally I would backup the contents of C:\Users\Username\AppData\Roaming\Mozilla\Firefox (Just Rename the directory)

Then uninstall Firefox completely, go to C:\Program Files (x86)\Mozilla\ (Mozilla Firefox, whatever it is) and make sure that directory doesn't exist or if it does, check the contents, backup if necessary and remove.

Re-install Firefox, it should be a fresh installation now, give the update a try and see what happens after.
"
4707,4707,7462,"Msg 1833, File 'ABC.ndf' cannot be reused until after the next BACKUP LOG operation","I am having a Database.
The size of my database is near about 4GB(Only .mdf file).
In that database only few tables present which have the maximum data of database. One of them and the biggest table is Table1. This is a huge table means everyday near about 80000 data inserted and same no. of records deleted. There are 30 days * 80000 records present in that table. This table is used very frequently. Hence it takes time to query large data. So my development team decided to create Partition of same table. Table11 has four columns in primary key. 
Primary Key Columns :


ChequeDate Date
RunNo Int
SorterNo Int
SequenceNo Int


We decided to partition the table on the basis of SequenceNo column.

I created a partition script and ran it which partitions an existing table. This works perfectly.
Next I run a ""rollback"" script to remove the partitioning. This also runs perfectly.

When I try to reapply partitioning on the same table it gives me the error mentioned in title. I found a manual solution that worked for me.

My problem is this process should run from a script only. No manual work should be necessary.

I assume that the problem is in the rollback script:

ALTER TABLE [dbo].[Table1] DROP CONSTRAINT [PK_Table1] with (move to [primary]);
DROP PARTITION SCHEME Table1PartSch
DROP PARTITION FUNCTION Table1PartFunc

ALTER DATABASE [MyDataBase] REMOVE FILE Table125LData;
ALTER DATABASE [MyDataBase] REMOVE FILE Table117LData;
ALTER DATABASE [MyDataBase] REMOVE FILE Table17LData;
ALTER DATABASE [MyDataBase] REMOVE FILE Table12LData;
ALTER DATABASE [MyDataBase] REMOVE FILE Table1RestData;
GO
ALTER DATABASE [MyDataBase] REMOVE FILEGROUP Table125LFG;
ALTER DATABASE [MyDataBase] REMOVE FILEGROUP Table117LFG;
ALTER DATABASE [MyDataBase] REMOVE FILEGROUP Table17LFG;
ALTER DATABASE [MyDataBase] REMOVE FILEGROUP Table12LFG;
ALTER DATABASE [MyDataBase] REMOVE FILEGROUP Table1RestFG;
GO




If someone have better solution other than Partitioning, to this situation is Welcome.
",RJ1990,https://dba.stackexchange.com/users/25735,"
  File '%ls' cannot be reused until after the next BACKUP LOG operation.


SQL Server insists that a backup is taken before a file is reused so it can guarantee database recovery in case of disaster.

The minimum backup needed is a log backup, but the documentation recommends a full database backup after any operation that adds or removes files from a database:



By adding a file, removing it, and attempting to add it again, you run into this requirement.

If you have a genuine need to add and remove files, you will need to add a BACKUP DATABASE or BACKUP LOG statement to your script.

This backup will form part of the recovery chain, so it is important you keep it safe in case you need to recover the database.

See BACKUP (Transact-SQL) for syntax details and further information.
",Paul White,https://dba.stackexchange.com/users/1192,http://dba.stackexchange.com/questions/48475/msg-1833-file-abc-ndf-cannot-be-reused-until-after-the-next-backup-log-operat,TECHNOLOGY,dba.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.6666666666666666,1.0,"MSG 1833, file ""ABC. NDF"" can not be reused until the next log backup operation","I am having a Database.
The size of my database is near about 4GB(Only .mdf file).
In that database only few tables present which have the maximum data of database. One of them and the biggest table is Table1. This is a huge table means everyday near about 80000 data inserted and same no. of records deleted. There are 30 days * 80000 records present in that table. This table is used very frequently. Hence it takes time to query large data. So my development team decided to create Partition of same table. Table11 has four columns in primary key. 
Primary Key Columns :


ChequeDate Date
RunNo Int
SorterNo Int
SequenceNo Int


We decided to partition the table on the basis of SequenceNo column.

I created a partition script and ran it which partitions an existing table. This works perfectly.
Next I run a ""rollback"" script to remove the partitioning. This also runs perfectly.

When I try to reapply partitioning on the same table it gives me the error mentioned in title. I found a manual solution that worked for me.

My problem is this process should run from a script only. No manual work should be necessary.

I assume that the problem is in the rollback script:

ALTER TABLE [dbo].[Table1] DROP CONSTRAINT [PK_Table1] with (move to [primary]);
DROP PARTITION SCHEME Table1PartSch
DROP PARTITION FUNCTION Table1PartFunc

ALTER DATABASE [MyDataBase] REMOVE FILE Table125LData;
ALTER DATABASE [MyDataBase] REMOVE FILE Table117LData;
ALTER DATABASE [MyDataBase] REMOVE FILE Table17LData;
ALTER DATABASE [MyDataBase] REMOVE FILE Table12LData;
ALTER DATABASE [MyDataBase] REMOVE FILE Table1RestData;
GO
ALTER DATABASE [MyDataBase] REMOVE FILEGROUP Table125LFG;
ALTER DATABASE [MyDataBase] REMOVE FILEGROUP Table117LFG;
ALTER DATABASE [MyDataBase] REMOVE FILEGROUP Table17LFG;
ALTER DATABASE [MyDataBase] REMOVE FILEGROUP Table12LFG;
ALTER DATABASE [MyDataBase] REMOVE FILEGROUP Table1RestFG;
GO




If someone have better solution other than Partitioning, to this situation is Welcome.
","
  File '%ls' cannot be reused until after the next BACKUP LOG operation.


SQL Server insists that a backup is taken before a file is reused so it can guarantee database recovery in case of disaster.

The minimum backup needed is a log backup, but the documentation recommends a full database backup after any operation that adds or removes files from a database:



By adding a file, removing it, and attempting to add it again, you run into this requirement.

If you have a genuine need to add and remove files, you will need to add a BACKUP DATABASE or BACKUP LOG statement to your script.

This backup will form part of the recovery chain, so it is important you keep it safe in case you need to recover the database.

See BACKUP (Transact-SQL) for syntax details and further information.
"
4146,4146,6614,Can an iphone/android cell phone communicate with RFID?,"Is it possible for a cell phone to communicate with an RFID chip?

I'm looking for a low-powered solution to turn a device on/off wirelessly, using a cell phone.

Example: phone sends signal to RFID chip, circuit board switches on. 

It really looks like Bluetooth will take too much battery, as this will be a portable device.

Any suggestions ? 
",user3226576,https://electronics.stackexchange.com/users/40947,"No, not 'out of the box'. Some phones have a NFC (near-field communication) capability, which could be used if your device is NFC enabled. Note that although similar, NFC and RFID are not compatible.

To use NFC, you'd have to write an app for your phone to interface with your device. Because of this, and because there are no IOS/iDevices with NFC capability, you're limited to Android. For iPhone, the only option would be a commercial RFID add-on hardware and accompanying software.

What kind of 'interface' are you looking for? If you are looking for something that activates by close proximity, Bluetooth might not be suitable.
",RJR,https://electronics.stackexchange.com/users/1612,http://electronics.stackexchange.com/questions/108181/can-an-iphone-android-cell-phone-communicate-with-rfid,SCIENCE,electronics.stackexchange.com,1.0,0.7777777777777778,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.3333333333333333,0.0,1.0,1.0,Can the iPhone / Android phone communicate with RFID?,"Is it possible for a cell phone to communicate with an RFID chip?

I'm looking for a low-powered solution to turn a device on/off wirelessly, using a cell phone.

Example: phone sends signal to RFID chip, circuit board switches on. 

It really looks like Bluetooth will take too much battery, as this will be a portable device.

Any suggestions ? 
","No, not 'out of the box'. Some phones have a NFC (near-field communication) capability, which could be used if your device is NFC enabled. Note that although similar, NFC and RFID are not compatible.

To use NFC, you'd have to write an app for your phone to interface with your device. Because of this, and because there are no IOS/iDevices with NFC capability, you're limited to Android. For iPhone, the only option would be a commercial RFID add-on hardware and accompanying software.

What kind of 'interface' are you looking for? If you are looking for something that activates by close proximity, Bluetooth might not be suitable.
"
307,307,496,Can I change my loan term from 60 to 36 months?,"I am on a 60 months plan with USCCU and now they are offering APR rate of 1.36% for 36 months on used and new vehicles as shown here. Is it a good idea to change my loan term from 60 to 36 months considering the fact that I can afford the monthly installments which could be higher that what I am paying for in 60 months term with an APR rate of say, for example x%.
",John,https://money.stackexchange.com/users/13189,"Just call your credit union and ask if they will let you refinance at the lower rate. If they won't, then just increase your payment every month so that your car is paid off early (in 36 months instead of 60). You won't get the lower rate, but since your loan will be paid early, you'll be saving interest anyway. 
",Ben Miller,https://money.stackexchange.com/users/10997,http://money.stackexchange.com/questions/39781/can-i-change-my-loan-term-from-60-to-36-months,LIFE_ARTS,money.stackexchange.com,1.0,0.6666666666666666,0.0,1.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8666666666666666,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.8888888888888888,Can I change the loan term from 60 months to 36 months?,"I have a 60 month plan with usccu, and now they offer used cars and new cars with an APR rate of 1.36% for 36 months, as shown in the figure. Considering the fact that I can afford the monthly installment, is it a good idea to change my loan term from 60 months to 36 months? The monthly installments I can afford may be higher than the installments I pay in 60 months, for example, the interest rate in April is x%.","Call your credit union and ask if they will let you refinance at a lower rate. If they don't want to, increase your payment monthly so your car can be paid off in advance (36 months instead of 60 months). You won't get a lower interest rate, but because your loan will be repaid in advance, you will save interest anyway."
3576,3576,5716,Why do different pain killers have different effects on people?,"I've noticed some pain killers working great for me, while others have no effect.

Works for me


Aspirin
APC &dagger;
Naproxen


Doesn't work for me


Paracetamol
Diclofenac
Tramadol


I doubt there is much of a placebo effect at work, since most of these either did or did not work when I first took them, without having expectations either way.

Whenever I have a head ache, I take an APC. I suspect it's actually the aspirin in there that does the job, since when I take just paracetamol, it doesn't do squat. As a kid I got children's aspirin, which worked.

I once had a severe back ache. I was prescribed diclofenac (a heavier variant than the over the counter one), which didn't work. I was then prescribed tramadol &mdash; same results. I then tried naproxen, which worked rightaway.

Why do some pain killers work while others don't?

Is there an underlying mechanism, that explains why some of these work while others don't? Does that predict if pain killers that I haven't used yet will work?

Please note that I'm not looking for medical advice on which pain killers to take; I'm just curious about how my body interacts with the various ones.



&dagger;: the one consisting of aspirin, paracetamol, and caffeine, not the one containing phenaticin. Think Excedrin.
",SQB,https://biology.stackexchange.com/users/6800,"Short answer: different people have different amount of active receptors. 
In treatment, combination scores of Pharmacodynamics and Pharmacokinetics determine the final effect of the drug. 
Receptors determine many effects of the drug in many pathways. 
Different people also sense pains differently (Psychology). 

Review answer

The purpose of treatment is to relieve pain and maintain function. 
Your question is biased. 
You cannot only concentrate on painkilling in maintaining health. 
These both are the reasons for the complains of the patient, not only the pain.

For instance, in rheumatoid arthritis, response to therapy can be quantitated using many measures including American College of Rheumatology system values ACR20, ACR50 and ACR70, which denotes the percentage of patients showing an improvement of 20%, 50% or 70% in a global assessment of signs (maintaining function) and symptoms (pains).

Each patient has own health, different from one another. 
Our body adapts to the environment and individual conditions of the body to maintain homeostasis. 
Receptors adapt for instance. 
They can be active or inactive - in short-run and long-run - again depending on the conditions at hand. 

Painkillers i.e. analgesics have different properties:


anti-inflammatory effect - acute and chronic conditions (inflammation is the major mechanism under many pathologies) e.g. nonsteiroidal anti-inflammatory drugs (NSAIDs, please, see this answer about the particular mechanisms and how different people have different effects from NSAID painkillers) and glucocorticoids (most) 
symptoms relieving specific drugs e.g. disease-modifying antirheumatic drugs (DMARDs)
anti-platelet effect - e.g. the older you get, the more platelets stick together.
anti-pyretic effect
...


which all can be toxic. 
Note that many drugs alone or/and as combination can work as painkillers i.e. pain relievers. 
Aspirin for instance has both anti-inflammatory and anti-platelet properties. 
However, it is rarely anymore used as anti-inflammatory. 
The anti-platelet property is dependent on the exact dosage of the administration. 
Aspirin's mechanism of action is to inhibit platelet COX which antiplatelet effect lasts 8-10 days (life of the platelet). 
In other tissues, synthesis of new COX replaces the inactivated enzyme so that ordinary doses have a duration of 6-12 hours. 
Please, review any Pharmacology -textbook for more info about aspirin.

Each these drug has own Pharmacodynamics and Pharmacokinetics


Pharmacodynamics answers to the question What drug does to the body? It stimulates some receptors, activates some pathways, ...
Pharmacokinetics - What does body do to the drug? It metabolises it (enzymes, receptors). It distributes it. It excretes it (kidneys, feaces).  


In treatment, you consider what is the target organ. 
You need to think what is causing the dysfunction and the pain. 
You try to restore the function and relieve pain. 
The component of drug needs to reach the target tissue e.g. your pancreas' beta cells do no produce insulin so your blood glucose is high. 
Complications of this are polyuria and eventually exodus if untreated. 
Insulin is injected into the fatty tissue. 
We do not have long-term acting insulin administered orally - our metabolism start to break the drug so it does not have wanted treatment. 
If insulin administered to the muscle, the time of action is too times less, again because muscle is metabolising the insulin i.e. a chain of peptides (protein).

No all symptoms and diseases have painkillers. 
For instance, prehemorrhoid and some types of itching related to  posthemorrhoids. 
However, for both, there are some special salvas for proplylaxis but they are not complete.

Now, you can start to read something in SuperBest's answer about host's physiological variables and addiction/tolerance which alters the mechanisms (receptors) of pathways in Pharmacodynamics and Pharmacokinetics.

Sources


Basic and Clinical Pharmacology, 11th edition, 2009, Bertram Katzung.
My notes in Pharmacology classes during 2014.

",Léo Léopold Hertz 준영,https://biology.stackexchange.com/users/86,http://biology.stackexchange.com/questions/21632/why-do-different-pain-killers-have-different-effects-on-people,SCIENCE,biology.stackexchange.com,1.0,0.8888888888888888,0.0,0.3333333333333333,1.0,1.0,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.8888888888888888,1.0,0.7777777777777778,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,0.8888888888888888,Why do different painkillers have different effects on people?,"I've noticed some pain killers working great for me, while others have no effect.

Works for me


Aspirin
APC &dagger;
Naproxen


Doesn't work for me


Paracetamol
Diclofenac
Tramadol


I doubt there is much of a placebo effect at work, since most of these either did or did not work when I first took them, without having expectations either way.

Whenever I have a head ache, I take an APC. I suspect it's actually the aspirin in there that does the job, since when I take just paracetamol, it doesn't do squat. As a kid I got children's aspirin, which worked.

I once had a severe back ache. I was prescribed diclofenac (a heavier variant than the over the counter one), which didn't work. I was then prescribed tramadol &mdash; same results. I then tried naproxen, which worked rightaway.

Why do some pain killers work while others don't?

Is there an underlying mechanism, that explains why some of these work while others don't? Does that predict if pain killers that I haven't used yet will work?

Please note that I'm not looking for medical advice on which pain killers to take; I'm just curious about how my body interacts with the various ones.



&dagger;: the one consisting of aspirin, paracetamol, and caffeine, not the one containing phenaticin. Think Excedrin.
","Short answer: different people have different amount of active receptors. 
In treatment, combination scores of Pharmacodynamics and Pharmacokinetics determine the final effect of the drug. 
Receptors determine many effects of the drug in many pathways. 
Different people also sense pains differently (Psychology). 

Review answer

The purpose of treatment is to relieve pain and maintain function. 
Your question is biased. 
You cannot only concentrate on painkilling in maintaining health. 
These both are the reasons for the complains of the patient, not only the pain.

For instance, in rheumatoid arthritis, response to therapy can be quantitated using many measures including American College of Rheumatology system values ACR20, ACR50 and ACR70, which denotes the percentage of patients showing an improvement of 20%, 50% or 70% in a global assessment of signs (maintaining function) and symptoms (pains).

Each patient has own health, different from one another. 
Our body adapts to the environment and individual conditions of the body to maintain homeostasis. 
Receptors adapt for instance. 
They can be active or inactive - in short-run and long-run - again depending on the conditions at hand. 

Painkillers i.e. analgesics have different properties:


anti-inflammatory effect - acute and chronic conditions (inflammation is the major mechanism under many pathologies) e.g. nonsteiroidal anti-inflammatory drugs (NSAIDs, please, see this answer about the particular mechanisms and how different people have different effects from NSAID painkillers) and glucocorticoids (most) 
symptoms relieving specific drugs e.g. disease-modifying antirheumatic drugs (DMARDs)
anti-platelet effect - e.g. the older you get, the more platelets stick together.
anti-pyretic effect
...


which all can be toxic. 
Note that many drugs alone or/and as combination can work as painkillers i.e. pain relievers. 
Aspirin for instance has both anti-inflammatory and anti-platelet properties. 
However, it is rarely anymore used as anti-inflammatory. 
The anti-platelet property is dependent on the exact dosage of the administration. 
Aspirin's mechanism of action is to inhibit platelet COX which antiplatelet effect lasts 8-10 days (life of the platelet). 
In other tissues, synthesis of new COX replaces the inactivated enzyme so that ordinary doses have a duration of 6-12 hours. 
Please, review any Pharmacology -textbook for more info about aspirin.

Each these drug has own Pharmacodynamics and Pharmacokinetics


Pharmacodynamics answers to the question What drug does to the body? It stimulates some receptors, activates some pathways, ...
Pharmacokinetics - What does body do to the drug? It metabolises it (enzymes, receptors). It distributes it. It excretes it (kidneys, feaces).  


In treatment, you consider what is the target organ. 
You need to think what is causing the dysfunction and the pain. 
You try to restore the function and relieve pain. 
The component of drug needs to reach the target tissue e.g. your pancreas' beta cells do no produce insulin so your blood glucose is high. 
Complications of this are polyuria and eventually exodus if untreated. 
Insulin is injected into the fatty tissue. 
We do not have long-term acting insulin administered orally - our metabolism start to break the drug so it does not have wanted treatment. 
If insulin administered to the muscle, the time of action is too times less, again because muscle is metabolising the insulin i.e. a chain of peptides (protein).

No all symptoms and diseases have painkillers. 
For instance, prehemorrhoid and some types of itching related to  posthemorrhoids. 
However, for both, there are some special salvas for proplylaxis but they are not complete.

Now, you can start to read something in SuperBest's answer about host's physiological variables and addiction/tolerance which alters the mechanisms (receptors) of pathways in Pharmacodynamics and Pharmacokinetics.

Sources


Basic and Clinical Pharmacology, 11th edition, 2009, Bertram Katzung.
My notes in Pharmacology classes during 2014.

"
6064,6064,9622,Which parts of fresh Fenugreek am I supposed to throw off before attempting to dry them out completely?,"The fresh Fenugreek which I bought contains:
- long stems
- green leaves
- yellow leaves    

I wish to know what parts of fresh Fenugreek am I supposed to throw off before attempting to place them drying out completely?
",Aquarius_Girl,https://cooking.stackexchange.com/users/6168,"I would just pull off all the little stems with leaves on them off the big main stem and leave it at that.

You can remove the yellow leaves if you wish, but there's no harm in leaving them on. I presume once dry you will crush all the leaves and small stems for storage, so leaving the yellow leaves on will not make any difference.

Removing the big main stem will simply help speed up the drying time.

For convenience of moving and turning you can leave them complete, but you should remove the smaller stems with leaves once they're dry, the large stem doesn't generally get used.
",spiceyokooko,https://cooking.stackexchange.com/users/14539,http://cooking.stackexchange.com/questions/29292/which-parts-of-fresh-fenugreek-am-i-supposed-to-throw-off-before-attempting-to-d,LIFE_ARTS,cooking.stackexchange.com,1.0,1.0,0.0,1.0,0.6666666666666666,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,1.0,"What parts of fresh fenugreek should I throw away first, and then dry them completely?","The fresh Fenugreek which I bought contains:
- long stems
- green leaves
- yellow leaves    

I wish to know what parts of fresh Fenugreek am I supposed to throw off before attempting to place them drying out completely?
","I would just pull off all the little stems with leaves on them off the big main stem and leave it at that.

You can remove the yellow leaves if you wish, but there's no harm in leaving them on. I presume once dry you will crush all the leaves and small stems for storage, so leaving the yellow leaves on will not make any difference.

Removing the big main stem will simply help speed up the drying time.

For convenience of moving and turning you can leave them complete, but you should remove the smaller stems with leaves once they're dry, the large stem doesn't generally get used.
"
2855,2855,4545,Are prime lenses sharp across the whole frame while zoom lenses are soft in the corners?,"Somebody told me that there is a difference in sharpness between a zoom lens vs. prime lens. A  58-200mm will give sharp focus in the center of the frame but blurry performance at the corners,  while in the meantime a prime 200mm will give a sharp definition to the whole frame of the photograph. Is this true? 
",Reynol Cobreiro,https://photo.stackexchange.com/users/41380,"Lens sharpness is fairly complex topic as there are many variables that dictate what makes an image sharp and what does not.
Here I will try and keep it as basic as possible with a just a few areas that can be considered regarding sharpness.

It is generally true that Prime Lenses  are sharper than Zoom Lenses.
The reason for this is due to a prime Lens not having the extra lens elements to correct for diffraction as do zoom Lenses.

As a result, and this applies to even the cheapest of the Prime lenses, they are the masters of just one focal length with just one job to do, and generally, they do this fine, even the cheaper lenses.

Whereas, a zoom lens, has to get the sharpness correct over a much larger focal range. The bigger the range, the tougher the job and more scope for errors, but that is not to say that they are not able to correct for any errors and still produce a relatively sharp image.

A $100 50mm f/1.8 may result in very sharp, edge to edge images at say f/8, but a $300 70-200mm f4.0 may actually end up being sharper edge to edge at 80mm and f/16, better known as the lens' sweet spot.

On the other hand, a $2000 Zoom Lens may end up being way sharper throughout the entire focal range of 70-200mm, it can all be relative.

In Zoom lenses, to keep the overall lens size down and to keep focal issues at bay, correction has to be made by introducing a further lens element just behind the main lens to reduce the distance to the sensor. This second lens has to be positioned just right so that it does not produce any chromatic aberration. Several of these elements are positioned within these lenses and each group is there for the correction of CA, reflections, contrast and sharpness.

Therefore, we have to take note that each group is also creating its own set of challenges, and the subsequent groups, along with keeping the size down, are also trying to correct the previous groups reflections and errors.

However, we also have to assume that the more expensive zoom lenses, will have better quality glass, with higher quality elements and grouped more efficiently than say a budget Zoom, and therefore, yield a sharper edge to edge image.

As further research, you maybe interested in reading about MTF, Modulation Transfer Function and how this measure is used in determining sharpness of a lens
",Abdul N Quraishi,https://photo.stackexchange.com/users/34085,http://photo.stackexchange.com/questions/65562/are-prime-lenses-sharp-across-the-whole-frame-while-zoom-lenses-are-soft-in-the,LIFE_ARTS,photo.stackexchange.com,1.0,0.7777777777777778,0.0,1.0,1.0,1.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8888888888888888,0.8888888888888888,1.0,0.8888888888888888,1.0,0.8666666666666666,0.0,0.0,1.0,0.8888888888888888,"When the zoom lens becomes soft in the corner, is the main lens clear in the whole picture?","I was told that the sharpness of a zoom lens is different from that of a prime lens. The focal length of 58-200 mm will form a clear focus in the center of the picture, but the performance in the corner will be blurred. At the same time, the background color of 200 mm will bring a clear definition to the whole picture. But is it really the case?","Lens sharpness is fairly complex topic as there are many variables that dictate what makes an image sharp and what does not.
Here I will try and keep it as basic as possible with a just a few areas that can be considered regarding sharpness.

It is generally true that Prime Lenses  are sharper than Zoom Lenses.
The reason for this is due to a prime Lens not having the extra lens elements to correct for diffraction as do zoom Lenses.

As a result, and this applies to even the cheapest of the Prime lenses, they are the masters of just one focal length with just one job to do, and generally, they do this fine, even the cheaper lenses.

Whereas, a zoom lens, has to get the sharpness correct over a much larger focal range. The bigger the range, the tougher the job and more scope for errors, but that is not to say that they are not able to correct for any errors and still produce a relatively sharp image.

A $100 50mm f/1.8 may result in very sharp, edge to edge images at say f/8, but a $300 70-200mm f4.0 may actually end up being sharper edge to edge at 80mm and f/16, better known as the lens' sweet spot.

On the other hand, a $2000 Zoom Lens may end up being way sharper throughout the entire focal range of 70-200mm, it can all be relative.

In Zoom lenses, to keep the overall lens size down and to keep focal issues at bay, correction has to be made by introducing a further lens element just behind the main lens to reduce the distance to the sensor. This second lens has to be positioned just right so that it does not produce any chromatic aberration. Several of these elements are positioned within these lenses and each group is there for the correction of CA, reflections, contrast and sharpness.

Therefore, we have to take note that each group is also creating its own set of challenges, and the subsequent groups, along with keeping the size down, are also trying to correct the previous groups reflections and errors.

However, we also have to assume that the more expensive zoom lenses, will have better quality glass, with higher quality elements and grouped more efficiently than say a budget Zoom, and therefore, yield a sharper edge to edge image.

As further research, you maybe interested in reading about MTF, Modulation Transfer Function and how this measure is used in determining sharpness of a lens
"
4368,4368,6947,What are the rules of thumb for margins in web design?,"My web designer tells me that in a web page, the empty margins or padding should always be multiples of a standard. For example 6 px, 12px, 18px. This should produce nicely balanced lay-outs. I would like to learn a little bit more about it:

Should one really not violate this at all?

Should the standard be the same horizontally and vertically?
",Tintels,https://ux.stackexchange.com/users/4703,"
The best learning resource for this would be a good introduction on typography – probably the seminal classic by Bringhurst (see http://webtypography.net for a good roundup applied to the web), though e. g. Spiekermann's ‘Stop Stealing Sheep…’ is not bad for starters, either – and on design grids (see my answer here on UXexchange).
When designing grids you are mostly using a basic module (proportions ideally defined by working from the content outwards) that all content is fitted to (i.e. multiples of it).
Vertical and horizontal margins between blocks are in most cases different. Vertical whitespace is often oriented on the baseline grid (see e.g. Bringhurst, again). Using one is highly recommended to achieve at a unifying vertical rhythm.
The minimum amount of horizontal whitespace, i. e. primarily the separation between columns of body text (gutter), is governed by Gestalt psychology with font size, line spacing, and line width as main influencing factors. You should place text blocks far enough from another such that your recipients will be able to see them as distinct units of their own. A traditional rule of thumb would make the gutter at least 1.5 ems wide in order to appear significantly wider than any possible whitespace within a line of text. On the screen, good line spacing tends to be a little bit wider than in traditional print, though. Hence you will probably need a little bit more than that. Using the same value as your baseline grid is a good guess to start with in most cases.
BTW: design standards – unless significantly backed up by ergonomics or cognitive psychology – are never standards in the more rigid sense of the word. You may violate any ‘standard’ as long as you know why you are doing it. 

",Sascha Brossmann,https://ux.stackexchange.com/users/4611,http://ux.stackexchange.com/questions/6135/what-are-the-rules-of-thumb-for-margins-in-web-design,TECHNOLOGY,ux.stackexchange.com,0.8333333333333334,0.6666666666666666,0.0,1.0,1.0,1.0,0.5,0.3333333333333333,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,0.6666666666666666,1.0,0.6666666666666666,1.0,0.8,0.0,0.0,1.0,0.8333333333333334,What is the rule of thumb for margins in web design?,"My web designer told me that in a web page, blank margins or padding should always be a standard multiple. For example, 6 pixels, 12 pixels, 18 pixels. This will produce a good balanced layout. I would like to know more about:","
The best learning resource for this would be a good introduction on typography – probably the seminal classic by Bringhurst (see http://webtypography.net for a good roundup applied to the web), though e. g. Spiekermann's ‘Stop Stealing Sheep…’ is not bad for starters, either – and on design grids (see my answer here on UXexchange).
When designing grids you are mostly using a basic module (proportions ideally defined by working from the content outwards) that all content is fitted to (i.e. multiples of it).
Vertical and horizontal margins between blocks are in most cases different. Vertical whitespace is often oriented on the baseline grid (see e.g. Bringhurst, again). Using one is highly recommended to achieve at a unifying vertical rhythm.
The minimum amount of horizontal whitespace, i. e. primarily the separation between columns of body text (gutter), is governed by Gestalt psychology with font size, line spacing, and line width as main influencing factors. You should place text blocks far enough from another such that your recipients will be able to see them as distinct units of their own. A traditional rule of thumb would make the gutter at least 1.5 ems wide in order to appear significantly wider than any possible whitespace within a line of text. On the screen, good line spacing tends to be a little bit wider than in traditional print, though. Hence you will probably need a little bit more than that. Using the same value as your baseline grid is a good guess to start with in most cases.
BTW: design standards – unless significantly backed up by ergonomics or cognitive psychology – are never standards in the more rigid sense of the word. You may violate any ‘standard’ as long as you know why you are doing it. 

"
1508,1508,2373,Administer block permission let the user to see admin theme name,"I gave the site admin role permission to administer blocks, but the problem is in admin/structure/block page, there is a tab that shows the admin theme name (Rubik).

he can click on Rubik but doesn't have permission to see the page.
what I want is to hide the tab.

other issue is in admin_menu module under structure > blocks there is a Rubik item too, which shouldn't be there too since the user doesn't have the permission to edit admin theme blocks.

So I'm wondering why does rubik block page link shows up!
",Sohail,https://drupal.stackexchange.com/users/6362,"I have had such a issue in the recent past, the only solution to this is the ""Block Access"" Module.
",Gladiator,https://drupal.stackexchange.com/users/6680,http://drupal.stackexchange.com/questions/79408/administer-block-permission-let-the-user-to-see-admin-theme-name,TECHNOLOGY,drupal.stackexchange.com,1.0,0.3333333333333333,0.0,0.0,1.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.8,0.0,1.0,0.0,1.0,Management block permission allows users to view management topic names,"I gave the site admin role permission to administer blocks, but the problem is in admin/structure/block page, there is a tab that shows the admin theme name (Rubik).

he can click on Rubik but doesn't have permission to see the page.
what I want is to hide the tab.

other issue is in admin_menu module under structure > blocks there is a Rubik item too, which shouldn't be there too since the user doesn't have the permission to edit admin theme blocks.

So I'm wondering why does rubik block page link shows up!
","I have had such a issue in the recent past, the only solution to this is the ""Block Access"" Module.
"
2837,2837,4513,"create a list (or any variable) dynamically, add data to each list and later compare them in C#","I have a list of some strings and I want to create a list for each of them dynamically inside a loop.

The main idea is to get each string from this list through the loop and create a list with this string as a name. Then add some data to it. 

Example:

   List&lt;string&gt; names = new List&lt;string&gt;(); // this is the main list with strings

   foreach (string nm in name)
   {
     // Here create a new list with this name
     // Add data to the list
   }  

   // Now, compare all of them to find duplicate data

   // Give message if any duplicate data found


Update:
Basically, I am going to add data to the list using some database APIs on runtime and the string names are the keys in that API. So with each name in the main list, I will retrieve some data from the database, create a list with that name and add data to it. Later we will compare them together. So the basic question is still how do I create these lists at runtime.
",Indigo,https://stackoverflow.com/users/1584507,"You can use IList&lt;KeyValuePair&lt;String,IList&lt;SomethingData&gt;&gt;&gt; or Hastable&lt;String,IList&lt;SomethingData&gt;&gt;

 //fill data to lists
 IList&lt;KeyValuePair&lt;String,IList&lt;SomethingData&gt;&gt;&gt; dataSets=new  List&lt;KeyValuePair&lt;String,IList&lt;SomethingData&gt;&gt;&gt;();
 IList&lt;string&gt; names = new List&lt;String&gt;();
 foreach (string nm in names)
 {
     IList&lt;SomethingData&gt; data = new List&lt;SomethingData&gt;();
     //...fill data
     dataSets.Add(new KeyValuePair&lt;string, IList&lt;SomethingData&gt;&gt;(nm, data));
 } 

 //search lists by name
 String nameForSearch = ""test"";
 IEnumerable&lt;KeyValuePair&lt;String,IList&lt;SomethingData&gt;&gt;&gt; dataSetsByName = dataSets.Where(ds =&gt; ds.Key == nameForSearch);

",Frank59,https://stackoverflow.com/users/1735047,http://stackoverflow.com/questions/13341504/create-a-list-or-any-variable-dynamically-add-data-to-each-list-and-later-com,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.4444444444444444,0.0,0.6666666666666666,0.3333333333333333,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,1.0,"Create a list (or any variables) dynamically, add data to each list, and compare them in C#","I have a list of some strings and I want to create a list for each of them dynamically inside a loop.

The main idea is to get each string from this list through the loop and create a list with this string as a name. Then add some data to it. 

Example:

   List&lt;string&gt; names = new List&lt;string&gt;(); // this is the main list with strings

   foreach (string nm in name)
   {
     // Here create a new list with this name
     // Add data to the list
   }  

   // Now, compare all of them to find duplicate data

   // Give message if any duplicate data found


Update:
Basically, I am going to add data to the list using some database APIs on runtime and the string names are the keys in that API. So with each name in the main list, I will retrieve some data from the database, create a list with that name and add data to it. Later we will compare them together. So the basic question is still how do I create these lists at runtime.
","You can use IList&lt;KeyValuePair&lt;String,IList&lt;SomethingData&gt;&gt;&gt; or Hastable&lt;String,IList&lt;SomethingData&gt;&gt;

 //fill data to lists
 IList&lt;KeyValuePair&lt;String,IList&lt;SomethingData&gt;&gt;&gt; dataSets=new  List&lt;KeyValuePair&lt;String,IList&lt;SomethingData&gt;&gt;&gt;();
 IList&lt;string&gt; names = new List&lt;String&gt;();
 foreach (string nm in names)
 {
     IList&lt;SomethingData&gt; data = new List&lt;SomethingData&gt;();
     //...fill data
     dataSets.Add(new KeyValuePair&lt;string, IList&lt;SomethingData&gt;&gt;(nm, data));
 } 

 //search lists by name
 String nameForSearch = ""test"";
 IEnumerable&lt;KeyValuePair&lt;String,IList&lt;SomethingData&gt;&gt;&gt; dataSetsByName = dataSets.Where(ds =&gt; ds.Key == nameForSearch);

"
2082,2082,3315,Long-ish term trailer rentals?,"We're moving out of a flat in Paris next month and moving into another flat elsewhere in France at some indeterminate point between July and September after we travel for a while. 

Is there a way to avoid moving twice by renting a sealed trailer for an extended period, maybe leaving it with family elsewhere in France for a couple months? 
",Jeff Burdges,https://travel.stackexchange.com/users/1354,"You're probably looking for something like Mobilbox. They will drive a large (8m3) storage box to your home, you load your things into it, and then they store it until you're ready and then they will bring the box to your destination and you unload it again. For an additional fee they will also load and unload for you.
",Michael Hampton,https://travel.stackexchange.com/users/3221,http://travel.stackexchange.com/questions/47865/long-ish-term-trailer-rentals,CULTURE,travel.stackexchange.com,1.0,0.3333333333333333,0.0,0.3333333333333333,1.0,0.0,0.6666666666666666,1.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,1.0,0.7777777777777778,0.4444444444444444,1.0,0.8888888888888888,0.6666666666666667,0.0,0.0,1.0,0.8888888888888888,Long term Trailer rental?,"Next month we will move out of an apartment in Paris, after a period of travel, to another apartment in other parts of France at some uncertain time from July to September.","You're probably looking for something like Mobilbox. They will drive a large (8m3) storage box to your home, you load your things into it, and then they store it until you're ready and then they will bring the box to your destination and you unload it again. For an additional fee they will also load and unload for you.
"
730,730,1162,"GIN/GiST Full Text searches through openlayers, geoserver and postgres","I have a a web app that automatically maps recent tweets and allows you to search for certain keywords. it uses Postgres for the database, geoserver as the server, and openlayers as the cartographic library. Right now tweet keywords are done using the ILIKE query.

This works pretty well if the keyword i'm looking for is a commonly used word, like 'love' , 'friend', 'OMG', etc. but less common words like ""geospatial"" need to search through a lot more data in order to find the last n instances of the word. This is dead slow.

To combat my slowness I'm building a GIN index on my tweet field in postgres. Two days later and i'm still waiting for the index to complete. Once it's built though, I'll try a few queries using SQL view parameters and hopefully this will dramatically speed things up.

Even if this approach works though, it's not going to be all that useful if the index takes so long to create -- the maintenance of it will not be able to keep up will the incoming flood of data. I think I will try out the GiST index next and see how long it takes as I understand it is much faster to this build index. 

Beyond this, what can I do next? Do options like Solr work with Geoserver?? Are there any common approaches to this type of problem and data size/rate?
",mikedotonline,https://gis.stackexchange.com/users/24616,"You could also try the Full Text Search PostgreSQL capabilities and that would still match your architecture (OL, GeoServer and PostgreSQL).

Here you have a very nice resource on PostgreSQL FTS: 
http://blog.lostpropertyhq.com/postgres-full-text-search-is-good-enough/ 
According to it, you should build a GiST (and not a GIN) index because it works better with dynamic data.

By the way, avoid LIKE/ILIKE queries if you want good search performance, they are one of the SQL Anti-patterns! See p.135: http://www.scribd.com/doc/2670985/SQL-Antipatterns Better use PostgreSQL FTS!
",Germán Carrillo,https://gis.stackexchange.com/users/4972,http://gis.stackexchange.com/questions/82627/gin-gist-full-text-searches-through-openlayers-geoserver-and-postgres,TECHNOLOGY,gis.stackexchange.com,1.0,0.5555555555555556,0.3333333333333333,1.0,0.6666666666666666,1.0,0.4444444444444444,0.4444444444444444,0.6666666666666666,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.6666666666666666,1.0,0.3333333333333333,0.3333333333333333,0.0,0.8888888888888888,1.0,0.5555555555555556,1.0,1.0,0.8,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.8888888888888888,"Gin / gist full text search openlayers, GeoServer and Postgres","I have a a web app that automatically maps recent tweets and allows you to search for certain keywords. it uses Postgres for the database, geoserver as the server, and openlayers as the cartographic library. Right now tweet keywords are done using the ILIKE query.

This works pretty well if the keyword i'm looking for is a commonly used word, like 'love' , 'friend', 'OMG', etc. but less common words like ""geospatial"" need to search through a lot more data in order to find the last n instances of the word. This is dead slow.

To combat my slowness I'm building a GIN index on my tweet field in postgres. Two days later and i'm still waiting for the index to complete. Once it's built though, I'll try a few queries using SQL view parameters and hopefully this will dramatically speed things up.

Even if this approach works though, it's not going to be all that useful if the index takes so long to create -- the maintenance of it will not be able to keep up will the incoming flood of data. I think I will try out the GiST index next and see how long it takes as I understand it is much faster to this build index. 

Beyond this, what can I do next? Do options like Solr work with Geoserver?? Are there any common approaches to this type of problem and data size/rate?
","You could also try the Full Text Search PostgreSQL capabilities and that would still match your architecture (OL, GeoServer and PostgreSQL).

Here you have a very nice resource on PostgreSQL FTS: 
http://blog.lostpropertyhq.com/postgres-full-text-search-is-good-enough/ 
According to it, you should build a GiST (and not a GIN) index because it works better with dynamic data.

By the way, avoid LIKE/ILIKE queries if you want good search performance, they are one of the SQL Anti-patterns! See p.135: http://www.scribd.com/doc/2670985/SQL-Antipatterns Better use PostgreSQL FTS!
"
1754,1754,2778,Which Windows 7 to install?,"I have 2GB of RAM on my laptop, which is the max.  

Should I install 32 bit version or 64 bit version?
",AngryHacker,https://superuser.com/users/2805,"64 bit handles ram more effectively than 32 bit (i.e. u need to have more than 4gb)

Word of caution though before you install make sure that you can locate 64bit drivers (for your laptop) and 64 bit compatible software (depends on what software you use) especially if you are going to be running 3D applications.

If all the above parameters are certain then I'd say go with the 64 bit version

Edit: Atleast in terms of 64bit Windows Vista i have seen a marked difference in performance of 3D applications (3D Max and Maya) when compared to the 32 bit version (the configuration of the computers the OS was installed on being the same)
",rzlines,https://superuser.com/users/2573,http://superuser.com/questions/17917,TECHNOLOGY,superuser.com,1.0,0.5555555555555556,0.0,1.0,0.6666666666666666,0.5,0.5555555555555556,0.5555555555555556,0.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,0.3333333333333333,0.7777777777777778,Which Windows 7 do you want to install?,"I have 2GB of RAM on my laptop, which is the max.  

Should I install 32 bit version or 64 bit version?
","64 bit handles ram more effectively than 32 bit (i.e. u need to have more than 4gb)

Word of caution though before you install make sure that you can locate 64bit drivers (for your laptop) and 64 bit compatible software (depends on what software you use) especially if you are going to be running 3D applications.

If all the above parameters are certain then I'd say go with the 64 bit version

Edit: Atleast in terms of 64bit Windows Vista i have seen a marked difference in performance of 3D applications (3D Max and Maya) when compared to the 32 bit version (the configuration of the computers the OS was installed on being the same)
"
2268,2268,3615,Can you approximate Cardiac Output by Ohm's law?,"I found this sentence from my notes which I cannot understand

PR &lt; CO, CO $\uparrow$, PR &gt; CO $\downarrow$


where

\item CO = AP / PR, Cardiac Output = Arterial P / Peripheral Resistance


I cannot understand the first sentence.
I cannot understand how you can deduce by Ohm's law the relationship.

What is the point of the first sentence?
",Léo Léopold Hertz 준영,https://biology.stackexchange.com/users/86,"I don't get the first sentence either, since PR and CO in your notation are in fundamentally different units. It's like saying '4 Celsius &lt; 5 meters.' You will have to think about what you are implicitly holding constant and ignoring in that relationship to make it meaningful. I suspect the first sentence is just emphasizing the inverse relationship between CO and PR (PR goes up, CO goes down, etc). 

As for Ohm's law, absolutely! You have it written right there. I assume Cardiac output is the flow rate of fluid in a blood vessel, and AP is arterial pressure, and PR is peripheral resistance. Stated another way,

$\textrm{Flow} = \frac{\textrm{Pressure}}{\textrm{Resistance}}$,

which is exactly Ohm's law. Frequently electrical current is described with a Hydraulic analogy, with pressure$\rightarrow$voltage, fluid flow$\rightarrow$current, and flow resistance$\rightarrow$electrical resistance. It makes a lot of sense, since electric current is literally flow of electrons. Poiseuille's Law that makes this analogy rigorous, deriving an Ohmic relationship between those variables. Interestingly enough, Poiseuille derived the law in the context of blood flow, making it particularly applicable. 
",A. Kennard,https://biology.stackexchange.com/users/4840,http://biology.stackexchange.com/questions/14851/can-you-approximate-cardiac-output-by-ohms-law,SCIENCE,biology.stackexchange.com,0.8888888888888888,0.7777777777777778,0.0,1.0,1.0,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.3333333333333333,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,0.8888888888888888,Can you approximate the cardiac output with Ohm's law?,"I found this sentence from my notes which I cannot understand

PR &lt; CO, CO $\uparrow$, PR &gt; CO $\downarrow$


where

\item CO = AP / PR, Cardiac Output = Arterial P / Peripheral Resistance


I cannot understand the first sentence.
I cannot understand how you can deduce by Ohm's law the relationship.

What is the point of the first sentence?
","I don't get the first sentence either, since PR and CO in your notation are in fundamentally different units. It's like saying '4 Celsius &lt; 5 meters.' You will have to think about what you are implicitly holding constant and ignoring in that relationship to make it meaningful. I suspect the first sentence is just emphasizing the inverse relationship between CO and PR (PR goes up, CO goes down, etc). 

As for Ohm's law, absolutely! You have it written right there. I assume Cardiac output is the flow rate of fluid in a blood vessel, and AP is arterial pressure, and PR is peripheral resistance. Stated another way,

$\textrm{Flow} = \frac{\textrm{Pressure}}{\textrm{Resistance}}$,

which is exactly Ohm's law. Frequently electrical current is described with a Hydraulic analogy, with pressure$\rightarrow$voltage, fluid flow$\rightarrow$current, and flow resistance$\rightarrow$electrical resistance. It makes a lot of sense, since electric current is literally flow of electrons. Poiseuille's Law that makes this analogy rigorous, deriving an Ohmic relationship between those variables. Interestingly enough, Poiseuille derived the law in the context of blood flow, making it particularly applicable. 
"
3843,3843,6110,How to remove a column from the Posts page,"In a previous question I asked how to add a column to the Posts page in the Administration section, and got a working answer. But now I need to know how to delete an existing column (e.g. the Date column) so that my customized Date column replaces it.
",Justin Long,https://wordpress.stackexchange.com/users/5913,"function my_manage_columns( $columns ) {
  unset($columns['date']);
  return $columns;
}

function my_column_init() {
  add_filter( 'manage_posts_columns' , 'my_manage_columns' );
}
add_action( 'admin_init' , 'my_column_init' );

",Milo,https://wordpress.stackexchange.com/users/4771,http://wordpress.stackexchange.com/questions/19180/how-to-remove-a-column-from-the-posts-page,TECHNOLOGY,wordpress.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,1.0,1.0,1.0,0.5555555555555556,0.5555555555555556,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,1.0,How to remove columns from the article page,"In the previous question, I asked how to add a column to the posts page in the administration section and got an effective answer. But now I need to know how to delete an existing column (such as a date column) so that my custom date column can replace it.","function my_manage_columns( $columns ) {
  unset($columns['date']);
  return $columns;
}

function my_column_init() {
  add_filter( 'manage_posts_columns' , 'my_manage_columns' );
}
add_action( 'admin_init' , 'my_column_init' );

"
1784,1784,2835,Stocks and Bankruptcy,"Trying to understand what happens when a company goes in and out of bankruptcy. I'll use American Airlines as an example because it's what I've been following for some years.

In November 2011, AA announced its bankruptcy; its stock, which was sliding, dropped to 0.38. It stayed flat during 2012, and now that a merger deal has been approved, it climbed up to almost 12.

During 2012 I thought of buying some AA stock because it was so damn cheap. If I had, I could be selling it today for a nice 32x profit. But at the time I was adviced not to - I was told because the company was bankrupt, its stock was just for speculators, pump and dump schemes, and so on, and it would become worthless when the company merged (it would be delisted and a new one added).

So when I read that the merger was approved, I expected it to drop to near zero. Instead, it climbed sharply.

Can anyone explain what's going on? If I had bought in 2012, what would have been the risk to offset this fantastic 32x reward? What will actually happen to AA stock once it exits bankruptcy? It sounds too good to be true, so it probably is, but I can't see why. What am I missing? Why didn't everyone buy AA during 2012?
",ggambett,https://money.stackexchange.com/users/11263,"As Mhoran said, the risks of buying a bankrupt company are huge, and even successful bankruptcy turnarounds don't involve keeping the same stock. For instance, the GM bankruptcy was resolved by the company more or less selling all its valuable assets (brands, factories, inventory) to a new version of itself, using that money to pay off what liabilities it could, and then dissolving. The new company then issued new stock, and you had to buy the new stock to see it rise; the old stock became worthless.

AA could have gone the same way; Delta could have bought it out of bankruptcy and consumed it outright, with any remaining shareholders being paid off at market value. That's probably the best the market was hoping for. Instead, the deal is a much more equal merger; AMR brings a very large airport network and aircraft fleet to the table, and Delta brings its cash, an also-considerable fleet and network, and a management team that's kept that airline solvent. The stockholders, therefore, expect to be paid off at a much higher per-share price, either in a new combined stock, in Delta stock, or in cash.
",KeithS,https://money.stackexchange.com/users/4637,http://money.stackexchange.com/questions/26285/stocks-and-bankruptcy,LIFE_ARTS,money.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,0.5,0.6666666666666666,1.0,0.7777777777777778,0.4444444444444444,0.6666666666666666,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.0,1.0,0.8888888888888888,Stock and bankruptcy,"Trying to understand what happens when a company goes in and out of bankruptcy. I'll use American Airlines as an example because it's what I've been following for some years.

In November 2011, AA announced its bankruptcy; its stock, which was sliding, dropped to 0.38. It stayed flat during 2012, and now that a merger deal has been approved, it climbed up to almost 12.

During 2012 I thought of buying some AA stock because it was so damn cheap. If I had, I could be selling it today for a nice 32x profit. But at the time I was adviced not to - I was told because the company was bankrupt, its stock was just for speculators, pump and dump schemes, and so on, and it would become worthless when the company merged (it would be delisted and a new one added).

So when I read that the merger was approved, I expected it to drop to near zero. Instead, it climbed sharply.

Can anyone explain what's going on? If I had bought in 2012, what would have been the risk to offset this fantastic 32x reward? What will actually happen to AA stock once it exits bankruptcy? It sounds too good to be true, so it probably is, but I can't see why. What am I missing? Why didn't everyone buy AA during 2012?
","As Mhoran said, the risks of buying a bankrupt company are huge, and even successful bankruptcy turnarounds don't involve keeping the same stock. For instance, the GM bankruptcy was resolved by the company more or less selling all its valuable assets (brands, factories, inventory) to a new version of itself, using that money to pay off what liabilities it could, and then dissolving. The new company then issued new stock, and you had to buy the new stock to see it rise; the old stock became worthless.

AA could have gone the same way; Delta could have bought it out of bankruptcy and consumed it outright, with any remaining shareholders being paid off at market value. That's probably the best the market was hoping for. Instead, the deal is a much more equal merger; AMR brings a very large airport network and aircraft fleet to the table, and Delta brings its cash, an also-considerable fleet and network, and a management team that's kept that airline solvent. The stockholders, therefore, expect to be paid off at a much higher per-share price, either in a new combined stock, in Delta stock, or in cash.
"
2047,2047,3264,How to track malloc and free?,"
  Possible Duplicate:
  Simple C implementation to track memory malloc/free?  




I need to know how much memory I have used till now in a C program and here is the pseudo code

#include &lt;stdio.h&gt;

int usedMemory =0;

void *MyMalloc(int size){
 usedMemory = usedMemory +size ;
 return malloc(size);
}

void MyFree(void *pointer){
/*****************what should i write here????*************/
}
int main(int argc, char *argv[])
{
    char *temp1= (char *)MyMalloc(100);
    char *temp2= (char *)MyMalloc(100);

    /*......other operations.........*/

    MyFree(temp1);
    MyFree(temp2);

    return 0;
}


Can anyone tell me what to write in the MyFree method(which decrements the amount of memory freed from usedMemory.
",user650521,https://stackoverflow.com/users/650521,"You need to manage a list of all malloc() you have done with pointer + size. Then you can search for the size in that list, and decrement it in free().

Check for example in that example how they are doing:
http://developers.sun.com/solaris/articles/lib_interposers_code.html#malloc_interposer.c

You might have other possibilities to track memory, like:


Valgrind with massif tool for tracking memory usage over time. You can even generate png output graphics
Interposed libraries. You can found some libraries that you can use by LD_PRELOAD=thelib.so ./yourprogram, and they will output some statistics like jemalloc


(A side note, please accept some answers to your question !)
",tito,https://stackoverflow.com/users/69877,http://stackoverflow.com/questions/8259817/how-to-track-malloc-and-free,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.5555555555555556,0.0,1.0,1.0,1.0,0.6666666666666666,0.4444444444444444,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.7333333333333333,0.6666666666666666,0.3333333333333333,0.6666666666666666,1.0,How to trace marllock and freedom?,"
  Possible Duplicate:
  Simple C implementation to track memory malloc/free?  




I need to know how much memory I have used till now in a C program and here is the pseudo code

#include &lt;stdio.h&gt;

int usedMemory =0;

void *MyMalloc(int size){
 usedMemory = usedMemory +size ;
 return malloc(size);
}

void MyFree(void *pointer){
/*****************what should i write here????*************/
}
int main(int argc, char *argv[])
{
    char *temp1= (char *)MyMalloc(100);
    char *temp2= (char *)MyMalloc(100);

    /*......other operations.........*/

    MyFree(temp1);
    MyFree(temp2);

    return 0;
}


Can anyone tell me what to write in the MyFree method(which decrements the amount of memory freed from usedMemory.
","You need to manage a list of all malloc() you have done with pointer + size. Then you can search for the size in that list, and decrement it in free().

Check for example in that example how they are doing:
http://developers.sun.com/solaris/articles/lib_interposers_code.html#malloc_interposer.c

You might have other possibilities to track memory, like:


Valgrind with massif tool for tracking memory usage over time. You can even generate png output graphics
Interposed libraries. You can found some libraries that you can use by LD_PRELOAD=thelib.so ./yourprogram, and they will output some statistics like jemalloc


(A side note, please accept some answers to your question !)
"
522,522,823,"If $f: \mathbb Q\to \mathbb Q$ is a homomorphism, prove that $f(x)=0$ for all $x\in\mathbb Q$ or $f(x)=x$ for all $x$ in $\mathbb Q$.","If $f: \mathbb Q\to \mathbb Q$ is a homomorphism, prove that $f(x)=0$ for all $x\in\mathbb Q$ or $f(x)=x$ for all $x$ in $\mathbb Q$.

I'm wondering if you can help me with this one? 
",Mirna,https://math.stackexchange.com/users/36579,"There is also a related result that can be useful (see Atiyah Macdonald): If $A$ is a field, then every homomorphism of $A$ into a nonzero ring  $B$ is injective. So, you can conclude that necessarily $f(1)=1$ (otherwise is the zero homomorphism), then $f(n)=n$, for $n$ integer, and the result follows, since $f(n/m)=f(n)f(m)ˆ{-1}=n/m$.
",fmoura2005,https://math.stackexchange.com/users/34862,http://math.stackexchange.com/questions/175477/if-f-mathbb-q-to-mathbb-q-is-a-homomorphism-prove-that-fx-0-for-all-x,SCIENCE,math.stackexchange.com,0.7777777777777778,1.0,0.0,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.6666666666666666,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,0.8888888888888888,0.9,0.6666666666666666,0.0,0.6666666666666666,0.8888888888888888,"If $f: \ mathbb Q \ to \ mathbb q $is homomorphic, then prove that $f (x) = 0 $means all $X \ in \ mathbb q $, or $f (x) = x $means all $x $in $\ mathbb q $.","If $f: \ mathbb Q \ to \ mathbb q $is homomorphic, then prove that $f (x) = 0 $means all $X \ in \ mathbb q $, or $f (x) = x $means all $x $in $\ mathbb q $.","There is also a related result that can be useful (see Atiyah Macdonald): If $A$ is a field, then every homomorphism of $A$ into a nonzero ring  $B$ is injective. So, you can conclude that necessarily $f(1)=1$ (otherwise is the zero homomorphism), then $f(n)=n$, for $n$ integer, and the result follows, since $f(n/m)=f(n)f(m)ˆ{-1}=n/m$.
"
2455,2455,3918,Help understanding an egrep expression,"I stumbled across the following egrep expression:

egrep '^([^aieou]*[aieou]){5,7}[^aieou]*$' /usr/share/dict/words


on this page: http://matt.might.net/articles/sculpting-text

The expression is supposed to find the words that contain between 5 and 7 vowels.

I understand the first ^ meaning from the beginning of the line and the second ^ to negate any of the aieou followed by any number of characters and one of the aeiou between 5 and 7 times. But I did not get how the first and last expressions: [^aieou] help here?
",Ketan,https://unix.stackexchange.com/users/8141,"It looks for zero or more consonants ([^aieou]*) followed by 5 to 7 vowels (([aieou]){5,7}) followed by zero or more consonants ([^aieou]*). The entire regular expression is anchored to the beginning of the line (^) and the ending, ($).

Example

$ egrep '^([^aieou]*[aieou]){5,7}[^aieou]*$' \
        /usr/share/dict/words | head -10
abacinate
abacination
abacterial
abaisance
abalation
abalienate
abalienated
abalienating
abalienation
abandonable


Details

So when it matches say this first word, abacinate, the first letter a has 0 consonants to the left, so we match that part.

As additional vowels with either zero or more consonants are found on the left and/or right, we match those situations too. If we find 5 to 7 of them, then we match.
",slm,https://unix.stackexchange.com/users/7453,http://unix.stackexchange.com/questions/103727/help-understanding-an-egrep-expression,TECHNOLOGY,unix.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,1.0,0.6666666666666666,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.3333333333333333,1.0,0.6666666666666666,1.0,0.8888888888888888,0.9333333333333332,0.3333333333333333,0.0,0.6666666666666666,1.0,Help understand egrep expressions,"I stumbled across the following egrep expression:

egrep '^([^aieou]*[aieou]){5,7}[^aieou]*$' /usr/share/dict/words


on this page: http://matt.might.net/articles/sculpting-text

The expression is supposed to find the words that contain between 5 and 7 vowels.

I understand the first ^ meaning from the beginning of the line and the second ^ to negate any of the aieou followed by any number of characters and one of the aeiou between 5 and 7 times. But I did not get how the first and last expressions: [^aieou] help here?
","It looks for zero or more consonants ([^aieou]*) followed by 5 to 7 vowels (([aieou]){5,7}) followed by zero or more consonants ([^aieou]*). The entire regular expression is anchored to the beginning of the line (^) and the ending, ($).

Example

$ egrep '^([^aieou]*[aieou]){5,7}[^aieou]*$' \
        /usr/share/dict/words | head -10
abacinate
abacination
abacterial
abaisance
abalation
abalienate
abalienated
abalienating
abalienation
abandonable


Details

So when it matches say this first word, abacinate, the first letter a has 0 consonants to the left, so we match that part.

As additional vowels with either zero or more consonants are found on the left and/or right, we match those situations too. If we find 5 to 7 of them, then we match.
"
2236,2236,3566,Check if page has breadcrumbs from template,"I want to add a CSS class to my body tag depending on whether the current page has a breadcrumb trail. So I would rather not add a new block, since I don't need any HTML output, but just a PHP array or boolean in my PHTML file.

I tried $this-&gt;getLayout()-&gt;getBlock('breadcrumbs') without success, because the property of Mage_Page_Block_Html_Breadcrumbs which contains the trail (_crumbs) is protected.

What is the best way to achieve my goal?
",Plankje,https://magento.stackexchange.com/users/7794,"Personally I would go with what Pronto mentioned about using rewriting the class but if you do not fancy a rewrite you can get the breadcrumb array from the block's cache key information. The cache key information contains as serialized base64 encoded version of the breadcrumbs array so the following code snippet will allow you to get the crumbs array and then you can do what you want with it.

$breadcrumbs = Mage::app()-&gt;getLayout()-&gt;getBlock('breadcrumbs');
$cacheKeyInfo = $breadcrumbs-&gt;getCacheKeyInfo();
$breadcrumb = unserialize(base64_decode($cacheKeyInfo['crumbs']));


On pages with breadcrumbs this will be an array and on other pages this will be NULL.
",David Manners,https://magento.stackexchange.com/users/158,http://magento.stackexchange.com/questions/21416/check-if-page-has-breadcrumbs-from-template,TECHNOLOGY,magento.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,0.0,0.3333333333333333,0.0,0.7777777777777778,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.3333333333333333,0.6666666666666666,0.0,1.0,Check the page for crumbs from the template,"I want to add a CSS class to my body tag depending on whether the current page has a breadcrumb trail. So I would rather not add a new block, since I don't need any HTML output, but just a PHP array or boolean in my PHTML file.

I tried $this-&gt;getLayout()-&gt;getBlock('breadcrumbs') without success, because the property of Mage_Page_Block_Html_Breadcrumbs which contains the trail (_crumbs) is protected.

What is the best way to achieve my goal?
","Personally I would go with what Pronto mentioned about using rewriting the class but if you do not fancy a rewrite you can get the breadcrumb array from the block's cache key information. The cache key information contains as serialized base64 encoded version of the breadcrumbs array so the following code snippet will allow you to get the crumbs array and then you can do what you want with it.

$breadcrumbs = Mage::app()-&gt;getLayout()-&gt;getBlock('breadcrumbs');
$cacheKeyInfo = $breadcrumbs-&gt;getCacheKeyInfo();
$breadcrumb = unserialize(base64_decode($cacheKeyInfo['crumbs']));


On pages with breadcrumbs this will be an array and on other pages this will be NULL.
"
4285,4285,6827,Does one need a master's in math before taking a PhD in math in Europe?,"This question is a variation of my earlier questions.

Okay so in the US, I guess one does not need a master's in math before pursuing a PhD in math since the US apparently usually assumes only a bachelor's.

What about in Europe? Technically, my master's is in mathematical finance not mathematics. So I didn't have research experience in looking through (pure) math books or articles in order to try to prove something theoretical or anything like that except for a few problem sets.

On an answer to one of my previous questions, user deviantfan commented that:

""In many european countries, it´s not even allowed/possible to skip the master degree.""

Perhaps my question may be rephrased:


  Is the master's in X PhD requirement in Europe satisfied by a
  master's in Applied X rather than Pure X?

",Jack Bauer,https://academia.stackexchange.com/users/22511,"I'd say that one would need a Master's in Math or its equivalent. Then the question becomes, is your degree in Mathematical Finance an equivalent.""

Hopefully, you will have had the core courses in mathematics such as real and complex analysis and advanced calculus. Perhaps your mathematical Finance degree will differ from a true math degree in ""engineering type"" applications, such as stochastic partial differential equations. If that is the case, you may be ok. Perhaps, at worst, you need to take 2-3 ""traditional"" math courses as a special student to make up for what you lack.

If you lack a traditional core curriculum, that would be different of course. Ultimately, it is for the faculties of the schools you apply to, to decide. And there is no one university ""monolith"" in Europe, only numerous schools, with meaningful variations in their admissions criteria.
",Tom Au,https://academia.stackexchange.com/users/755,http://academia.stackexchange.com/questions/48237/does-one-need-a-masters-in-math-before-taking-a-phd-in-math-in-europe,LIFE_ARTS,academia.stackexchange.com,1.0,0.6666666666666666,0.0,1.0,1.0,1.0,0.6666666666666666,0.7777777777777778,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,1.0,0.8888888888888888,1.0,1.0,0.8666666666666666,0.0,0.0,1.0,1.0,Do you need to study for a master's degree in mathematics before studying for a Ph.D. in Mathematics in Europe?,"This question is a variation of my earlier questions.

Okay so in the US, I guess one does not need a master's in math before pursuing a PhD in math since the US apparently usually assumes only a bachelor's.

What about in Europe? Technically, my master's is in mathematical finance not mathematics. So I didn't have research experience in looking through (pure) math books or articles in order to try to prove something theoretical or anything like that except for a few problem sets.

On an answer to one of my previous questions, user deviantfan commented that:

""In many european countries, it´s not even allowed/possible to skip the master degree.""

Perhaps my question may be rephrased:


  Is the master's in X PhD requirement in Europe satisfied by a
  master's in Applied X rather than Pure X?

","I'd say that one would need a Master's in Math or its equivalent. Then the question becomes, is your degree in Mathematical Finance an equivalent.""

Hopefully, you will have had the core courses in mathematics such as real and complex analysis and advanced calculus. Perhaps your mathematical Finance degree will differ from a true math degree in ""engineering type"" applications, such as stochastic partial differential equations. If that is the case, you may be ok. Perhaps, at worst, you need to take 2-3 ""traditional"" math courses as a special student to make up for what you lack.

If you lack a traditional core curriculum, that would be different of course. Ultimately, it is for the faculties of the schools you apply to, to decide. And there is no one university ""monolith"" in Europe, only numerous schools, with meaningful variations in their admissions criteria.
"
2190,2190,3487,Converting string to NSDate,"I am trying to use NSDateFormatter to convert the following string to an NSDate: 2013-08-19 7:00 AM.

However, the following NSDate is created: 2013-08-19 04:00:00 +0000. The hour is wrong.

My code is below. I don't know what I am doing incorrectly.

NSDateFormatter *dateFormatter = [NSDateFormatter new];
[dateFormatter setTimeZone:[NSTimeZone systemTimeZone]];
[dateFormatter setDateFormat:@""yyyy-MM-dd HH:mm a""];
NSString *string = @""2013-08-19 7:00 AM"";
NSDate *dateFromString = [dateFormatter dateFromString:string];

",Jack Humphries,https://stackoverflow.com/users/775624,"You're attempting to use a 24-hour format for the hours and an AM/PM indicator, and that just won't work. Change your line:

[dateFormatter setDateFormat:@""yyyy-MM-dd HH:mm a""];


to this:

[dateFormatter setDateFormat:@""yyyy-MM-dd hh:mm a""];


and you'll find that your code now works.
",trudyscousin,https://stackoverflow.com/users/454697,http://stackoverflow.com/questions/18320930/converting-string-to-nsdate,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.3333333333333333,0.0,1.0,0.6666666666666666,1.0,0.6666666666666666,0.4444444444444444,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.6666666666666666,0.8888888888888888,Convert string to nsdate,"I am trying to use NSDateFormatter to convert the following string to an NSDate: 2013-08-19 7:00 AM.

However, the following NSDate is created: 2013-08-19 04:00:00 +0000. The hour is wrong.

My code is below. I don't know what I am doing incorrectly.

NSDateFormatter *dateFormatter = [NSDateFormatter new];
[dateFormatter setTimeZone:[NSTimeZone systemTimeZone]];
[dateFormatter setDateFormat:@""yyyy-MM-dd HH:mm a""];
NSString *string = @""2013-08-19 7:00 AM"";
NSDate *dateFromString = [dateFormatter dateFromString:string];

","You're attempting to use a 24-hour format for the hours and an AM/PM indicator, and that just won't work. Change your line:

[dateFormatter setDateFormat:@""yyyy-MM-dd HH:mm a""];


to this:

[dateFormatter setDateFormat:@""yyyy-MM-dd hh:mm a""];


and you'll find that your code now works.
"
2875,2875,4576,Asterisk for Small Business - Where to Start?,"I have been in IT for a long time now doing software development and some system/server administration, but all mostly software-related services.  I would like to help set up a small business (~50 employees) with Asterisk, but I am not very familiar with how the whole T1, data/voice channels, etc work.  I have set up a personal Asterisk server (functional), but have not done so with a pipe like a T1 (which sounds more complex than residential cable/DSL).

Are there any resources out there to help me understand what may be needed of me to help set this business up with Asterisk and re-use their existing T1 pipe?

Any help would be greatly appreciated.
",Benny,https://serverfault.com/users/42248,"Partial answer.

First, know that Asterisk configuration is more like a programming language than, say, Apache configuration. There are numerous ways to create ""nonsense"" configurations. On the other hand, you can create very nifty services.

There are three aspects to setting up an Asterisk installation:


call quality
what manner of phones will you be using?
which services do the users expect?


Quality

In my experience, your company suffers in reputation from bad phone lines, so make sure you get get decent quality from your installation. Quality is among other things: 


low upstream latency and high link uptime
Asterisk server uptime; use separate UPS. People tend to get cranky if they can't call the janitor and tell that there is a power failure in the house.
decent end-user equipment


Don't do a big bang implementation. Start with some users and work from there.

End user equipment

How are your users going to talk on the phone and how do you connect that equipment to Asterisk. Some users appreciate a headset connected to their PC, while others need a grey handset with analog dial pad or they will just be confused. Which will you provide and how will they connect to Asterisk?

For so called softphones (i.e. a SIP client installed on your PC) not much need to be done. You need a mechanism to handle accounts for these users (e.g. LDAP) and they need decent headsets. For connecting traditional analog phones, there are various sorts of equipment. For small installation, you may be able to get your hands on Zyxel Prestige 2002s (2 ports each), but for larger installations you need rack-mountable equipment of some sort.

Services

In my experience it is very difficult to get users to actually tell what they expect from a phone system, but once you give them something, they start having all sorts of opinions. So you need to be very clear about what services you provide and require a somewhat anal change management process (more so than is normally required in a small company).

Conclusion

This sounds dangerous and ominous, but know that the reward is equally great. The advantage of being able to create dedicated phone services, with the same sort of detailed control that you have with other IT services can be very rewarding. It will take some time for your users to get used to the thought that they can actually request fancy features from their phones, but once they get started, you can make their work a lot easier. Some features my users found very useful:


voice mail that sends mail with audio files
queues and fallback for all users
softphone and multiple phones for all users
phone conferences
redirection to mobile phones, and
routing calls through company phone system from private phones so that company picks up tab for international/expensive calls.


Also, traditionally, most phone extensions are personal, but in a modern company, most incoming calls are actually to a company function. You should probably consider not having personal extensions at all, and simply have an extension per function that rings all phones in that department/function.
",Bittrance,https://serverfault.com/users/67890,http://serverfault.com/questions/275107,TECHNOLOGY,serverfault.com,1.0,0.4444444444444444,0.0,1.0,0.3333333333333333,1.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,1.0,0.0,0.0,0.0,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,0.3333333333333333,1.0,Small business asterisk - where to start?,"I have worked in IT industry for a long time, now I am engaged in software development and some system / server management, but most of them are software related services. I want to help build a small business with an asterisk (about 50 employees), but I'm not familiar with the whole T1, data / voice channels, etc. I've built a personal asterisk server (functional), but I haven't used a T1 like conduit (sounds more complex than a residential cable / DSL).","Partial answer.

First, know that Asterisk configuration is more like a programming language than, say, Apache configuration. There are numerous ways to create ""nonsense"" configurations. On the other hand, you can create very nifty services.

There are three aspects to setting up an Asterisk installation:


call quality
what manner of phones will you be using?
which services do the users expect?


Quality

In my experience, your company suffers in reputation from bad phone lines, so make sure you get get decent quality from your installation. Quality is among other things: 


low upstream latency and high link uptime
Asterisk server uptime; use separate UPS. People tend to get cranky if they can't call the janitor and tell that there is a power failure in the house.
decent end-user equipment


Don't do a big bang implementation. Start with some users and work from there.

End user equipment

How are your users going to talk on the phone and how do you connect that equipment to Asterisk. Some users appreciate a headset connected to their PC, while others need a grey handset with analog dial pad or they will just be confused. Which will you provide and how will they connect to Asterisk?

For so called softphones (i.e. a SIP client installed on your PC) not much need to be done. You need a mechanism to handle accounts for these users (e.g. LDAP) and they need decent headsets. For connecting traditional analog phones, there are various sorts of equipment. For small installation, you may be able to get your hands on Zyxel Prestige 2002s (2 ports each), but for larger installations you need rack-mountable equipment of some sort.

Services

In my experience it is very difficult to get users to actually tell what they expect from a phone system, but once you give them something, they start having all sorts of opinions. So you need to be very clear about what services you provide and require a somewhat anal change management process (more so than is normally required in a small company).

Conclusion

This sounds dangerous and ominous, but know that the reward is equally great. The advantage of being able to create dedicated phone services, with the same sort of detailed control that you have with other IT services can be very rewarding. It will take some time for your users to get used to the thought that they can actually request fancy features from their phones, but once they get started, you can make their work a lot easier. Some features my users found very useful:


voice mail that sends mail with audio files
queues and fallback for all users
softphone and multiple phones for all users
phone conferences
redirection to mobile phones, and
routing calls through company phone system from private phones so that company picks up tab for international/expensive calls.


Also, traditionally, most phone extensions are personal, but in a modern company, most incoming calls are actually to a company function. You should probably consider not having personal extensions at all, and simply have an extension per function that rings all phones in that department/function.
"
2697,2697,4300,k-center algorithm in one-dimensional space,"I'm aware of the general k-center approximation algorithm, but my professor (this is a question from a CS class) says that in a one-dimensional space, the problem can be solved (optimal solution found, not an approximation) in O(n^2) polynomial time without depending on k or using dynamic programming.

A general description of the k-center problem: Given a set of nodes in an n-dimensional space, cluster them into k clusters such that the ""radius"" of each cluster (distance from furthest node to its center node) is minimized. A more formal and detailed description can be found at http://en.wikipedia.org/wiki/Metric_k-center

As you might expect, I can't figure out how this is possible. The part currently causing me problems is how the runtime can not rely on k.

The nature of the problem causes me to try to step through the nodes on a sort of number line and try to find points to put boundaries, marking off the edges of each cluster that way. But this would require a runtime based on k.

The O(n^2) runtime though makes me think it might involve filling out an nxn array with the distance between two nodes in each entry.

Any explanation on how this is works or tips on how to figure it out would be very helpful.
",philv,https://cs.stackexchange.com/users/22958,"Hint: In algorithms, if you're not sure how to solve the problem, sometimes it is helpful to look at a scaled down version of the problem.  I suggest you start by looking at the version of the problem where $k=1$.  I suspect you'll find that the problem is super-easy, when $k=1$ and you are on the 1-D line.

Next, see if you can solve it for $k=2$.  I think you'll find that case is pretty easy, too, using the ideas you got from the $k=1$ case.

The obvious next step is to generalize to arbitrary $k$.
",D.W.,https://cs.stackexchange.com/users/755,http://cs.stackexchange.com/questions/32218/k-center-algorithm-in-one-dimensional-space,SCIENCE,cs.stackexchange.com,0.6666666666666666,0.4444444444444444,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.5555555555555556,0.8888888888888888,0.5555555555555556,1.0,1.0,0.8,0.3333333333333333,0.0,1.0,0.8888888888888888,K-center algorithm in one dimensional space,"I'm aware of the general k-center approximation algorithm, but my professor (this is a question from a CS class) says that in a one-dimensional space, the problem can be solved (optimal solution found, not an approximation) in O(n^2) polynomial time without depending on k or using dynamic programming.

A general description of the k-center problem: Given a set of nodes in an n-dimensional space, cluster them into k clusters such that the ""radius"" of each cluster (distance from furthest node to its center node) is minimized. A more formal and detailed description can be found at http://en.wikipedia.org/wiki/Metric_k-center

As you might expect, I can't figure out how this is possible. The part currently causing me problems is how the runtime can not rely on k.

The nature of the problem causes me to try to step through the nodes on a sort of number line and try to find points to put boundaries, marking off the edges of each cluster that way. But this would require a runtime based on k.

The O(n^2) runtime though makes me think it might involve filling out an nxn array with the distance between two nodes in each entry.

Any explanation on how this is works or tips on how to figure it out would be very helpful.
","Hint: In algorithms, if you're not sure how to solve the problem, sometimes it is helpful to look at a scaled down version of the problem.  I suggest you start by looking at the version of the problem where $k=1$.  I suspect you'll find that the problem is super-easy, when $k=1$ and you are on the 1-D line.

Next, see if you can solve it for $k=2$.  I think you'll find that case is pretty easy, too, using the ideas you got from the $k=1$ case.

The obvious next step is to generalize to arbitrary $k$.
"
4846,4846,7713,Advice on using FORMAT_MODULE_PATH,"From what I have read FORMAT_MODULE_PATH allows to use custom formats.

How can I access the first value from DATETIME_INPUT_FORMATS in my application?

The DATETIME_INPUT_FORMATS variable for german should be '%d.%m.%Y', whereas for english should be '%Y-%m-%d'. I want to use the values from the formats.py files depending on the language.    

I followed the Django documentation for how to use the FORMAT_MODULE_PATH variable, but I don't get the expected results.

settings.py:
    USE_L10N = True
    USE_I18N = True
    FORMAT_MODULE_PATH = 'myproject.formats'


myproject/
    formats/
        __init__.py
        en/
            __init__.py
            formats.py
        de/
            __init__.py
            formats.py


I change the browser's language from English to German, and back and nothing happens with the date format. It is always '%Y-%m-%d'. The displayed date format is the value of settings.DATE_INPUT_FORMATS[0].

Django version is 1.2.5 and Python version is 2.5.4.
",Seitaridis,https://stackoverflow.com/users/472111,"I couldn't make it work using the FORMAT_MODULE_PATH setting, but I have managed to this using formats.get_format('DATE_INPUT_FORMATS')[0]. You can find this in my answer.
",Seitaridis,https://stackoverflow.com/users/472111,http://stackoverflow.com/questions/5165634/advice-on-using-format-module-path,STACKOVERFLOW,stackoverflow.com,1.0,0.3333333333333333,0.0,0.6666666666666666,0.3333333333333333,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.5555555555555556,0.7777777777777778,0.4444444444444444,1.0,0.7777777777777778,0.5333333333333333,1.0,0.0,0.0,0.8888888888888888,Suggestions on using format module path,"From what I have read FORMAT_MODULE_PATH allows to use custom formats.

How can I access the first value from DATETIME_INPUT_FORMATS in my application?

The DATETIME_INPUT_FORMATS variable for german should be '%d.%m.%Y', whereas for english should be '%Y-%m-%d'. I want to use the values from the formats.py files depending on the language.    

I followed the Django documentation for how to use the FORMAT_MODULE_PATH variable, but I don't get the expected results.

settings.py:
    USE_L10N = True
    USE_I18N = True
    FORMAT_MODULE_PATH = 'myproject.formats'


myproject/
    formats/
        __init__.py
        en/
            __init__.py
            formats.py
        de/
            __init__.py
            formats.py


I change the browser's language from English to German, and back and nothing happens with the date format. It is always '%Y-%m-%d'. The displayed date format is the value of settings.DATE_INPUT_FORMATS[0].

Django version is 1.2.5 and Python version is 2.5.4.
","I can't use the format? Module? Path setting to make it work, but I've successfully implemented it using formats. Get? Format ('date? Input? Formats') [0]. You can find this in my answer."
2018,2018,3218,What is the current flowing through this switch?,"I am looking at a circuit diagram like this:







simulate this circuit &ndash; Schematic created using CircuitLab

Switch 1 and switch 2 never are on at the same time (they alternate)
I turn on S2 and shut off S1, then after a while, I turn on S1 and shut off S2. At that point I think I can redraw the circuit like this:







simulate this circuit

But if I do that, I think the current through the switch would then be zero? And then the switch would be considered ""off?"" Or maybe I could arbitrarily define the current through the switch as being from either the left or right hand side circuits? But that seems to be not possible because originally the switch was shared between both of the circuits.

Can someone figure out what is wrong with my reasoning? What should the current through the circuit be in the ""on"" position?

Note: ignore the values of the circuit elements, they are not important.
",AAC,https://electronics.stackexchange.com/users/54447,"Do KCL at the node between C1 and L2:







simulate this circuit &ndash; Schematic created using CircuitLab

Then the current through the switch is just the difference (or sum, depending on sign definition) of the current in each of the two LC circuits drawn in the second diagram. It is clear in diagram 1 what is going on but possibly less clear in diagram 2.
",AAC,https://electronics.stackexchange.com/users/54447,http://electronics.stackexchange.com/questions/132001/what-is-the-current-flowing-through-this-switch,SCIENCE,electronics.stackexchange.com,1.0,0.3333333333333333,0.0,0.3333333333333333,1.0,1.0,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,1.0,0.0,0.8888888888888888,0.7777777777777778,0.5555555555555556,0.8888888888888888,1.0,0.7333333333333333,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.8888888888888888,What is the current flowing through the switch?,"I am looking at a circuit diagram like this:







simulate this circuit &ndash; Schematic created using CircuitLab

Switch 1 and switch 2 never are on at the same time (they alternate)
I turn on S2 and shut off S1, then after a while, I turn on S1 and shut off S2. At that point I think I can redraw the circuit like this:







simulate this circuit

But if I do that, I think the current through the switch would then be zero? And then the switch would be considered ""off?"" Or maybe I could arbitrarily define the current through the switch as being from either the left or right hand side circuits? But that seems to be not possible because originally the switch was shared between both of the circuits.

Can someone figure out what is wrong with my reasoning? What should the current through the circuit be in the ""on"" position?

Note: ignore the values of the circuit elements, they are not important.
","Do KCL at the node between C1 and L2:







simulate this circuit &ndash; Schematic created using CircuitLab

Then the current through the switch is just the difference (or sum, depending on sign definition) of the current in each of the two LC circuits drawn in the second diagram. It is clear in diagram 1 what is going on but possibly less clear in diagram 2.
"
4941,4941,7867,Why do different pain killers have different effects on people?,"I've noticed some pain killers working great for me, while others have no effect.

Works for me


Aspirin
APC &dagger;
Naproxen


Doesn't work for me


Paracetamol
Diclofenac
Tramadol


I doubt there is much of a placebo effect at work, since most of these either did or did not work when I first took them, without having expectations either way.

Whenever I have a head ache, I take an APC. I suspect it's actually the aspirin in there that does the job, since when I take just paracetamol, it doesn't do squat. As a kid I got children's aspirin, which worked.

I once had a severe back ache. I was prescribed diclofenac (a heavier variant than the over the counter one), which didn't work. I was then prescribed tramadol &mdash; same results. I then tried naproxen, which worked rightaway.

Why do some pain killers work while others don't?

Is there an underlying mechanism, that explains why some of these work while others don't? Does that predict if pain killers that I haven't used yet will work?

Please note that I'm not looking for medical advice on which pain killers to take; I'm just curious about how my body interacts with the various ones.



&dagger;: the one consisting of aspirin, paracetamol, and caffeine, not the one containing phenaticin. Think Excedrin.
",SQB,https://biology.stackexchange.com/users/6800,"I don't know of any interesting mechanism that is specific to pain killers, so I will instead answer for drugs in general.

Drug action is a complex process consisting of many steps. Let's take a simple example: A systemic direct inhibitor of a kinase. This drug would need to*:


Be absorbed into your bloodstream
Remain in your bloodstream for sufficient time
Be absorbed into the tissue
Be able to bind the target protein


1 can fail due to interaction with other concurrently taken drugs or food, or simply genetic factors affecting the particular functioning of the gut mucosa. 2 can fail because the kidneys are too good at eliminating it, or the liver is metabolizing it too agressively (both also subject to modulation by other drugs, foods and genetic factors). 3 can fail because the transports in the cells aren't working as rapidly, or represent an allele less likely to take in the drug, or are modulated by other drugs/foods. The tissue can also have efflux pumps or enzymes that break down the drug. 4 can fail because the drug was designed for a specific allele of that kinase, but you happen to have a different allele, which has a slightly different structure that is no longer targeted by this drug.

Then you have a host of physiological variables, and addiction/tolerance.

Apparently the most common genetic reason by far for variable drug sensitivity is the specific set of CYP genes you have. CYP enzymes are abundant in the liver and chemically process various molecules (including drugs).

Besides this, an interesting set of specific examples used to be available from 23andme. I'm not sure if they still provide this after the FDA ban on health information.


Clopidogrel sensitivity - CYP2C19 variation
Proton Pump Inhibitor (stomach acid reduction) - CYP2C19 variation
Abacavir (HIV drug) - HLA-B*5701 SNP
Acetaldehyde (alcohol flush) - ALDH2 mutation
5-fluorouracil (chemotherapy) - DPYD mutation
PEG-IFN-alpha/RBV combination (Hepatitis C medicine) - IL28B SNP
Phenytoin (epilepsy drug) - CYP2C9 variants
Choline esters (class of muscle relaxants) - BCHE (CE degrader) variants
Sulfonylurea (used for type 2 diabetes) - CYP2C9 variants
Thiopurine (immune suppressant) -  TPMT (enzyme that degrades thiopurine) variation
Warfarin (anticoagulant) - CYP2C9 variants
Caffeine - CYP1A2 SNP
Metformin (diabetes drug) - SNP rs11212617, near the ATM gene
Antidepressant - SNPs in ABCB1 affect likelihood of sexual dysfunction (common side effect)
Beta-Blocker (heart disease) - Mutations in ADRB1 which is normally blocked by the drug
Floxacillin (drug for staphylococcal infections) - SNPs in the MHC region affect liver toxicity of this drug
Heroin - OPRM1 receptor (target of heroin) SNPs affect efficacy
Lumiracoxib (used to treat pain and symptoms of osteoarthritis) - SNPs in the MHC region affect liver toxicity
Naltrexone (alcohol and narcotic addiction drug) - SNPs in OPRM1 affect how much it can reduce pleasurable feeling from narcotics
Statins (cardiovascular disease) - SNPs in COQ2 (mitochondrial component) affect risk of myopathy


As you can see, our friends the CYP family enzymes come up frequently, and some are even repeat offenders like CYP2C9. Besides that, there is a fair number of cases where variation in the specific target of the drug are relevant.

Note that this list is not comprehensive: Many drugs have not been studied in sufficient detail, and some may have complicated mechanisms instead of just ""bind and inhibit protein X"".

I have omitted many details and links to literature, I am sure you can easily find them by searching on Google Scholar with the keywords I already gave. Let me know if that doesn't work, though.



*: Note that these aren't necessarily required for all drugs. For example, some drugs can be applied directly to the skin and hence do not need to pass through blood.
",Superbest,https://biology.stackexchange.com/users/540,http://biology.stackexchange.com/questions/21632/why-do-different-pain-killers-have-different-effects-on-people,SCIENCE,biology.stackexchange.com,1.0,0.7777777777777778,0.0,0.6666666666666666,1.0,1.0,0.6666666666666666,0.4444444444444444,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,1.0,Why do different painkillers have different effects on people?,"I've noticed some pain killers working great for me, while others have no effect.

Works for me


Aspirin
APC &dagger;
Naproxen


Doesn't work for me


Paracetamol
Diclofenac
Tramadol


I doubt there is much of a placebo effect at work, since most of these either did or did not work when I first took them, without having expectations either way.

Whenever I have a head ache, I take an APC. I suspect it's actually the aspirin in there that does the job, since when I take just paracetamol, it doesn't do squat. As a kid I got children's aspirin, which worked.

I once had a severe back ache. I was prescribed diclofenac (a heavier variant than the over the counter one), which didn't work. I was then prescribed tramadol &mdash; same results. I then tried naproxen, which worked rightaway.

Why do some pain killers work while others don't?

Is there an underlying mechanism, that explains why some of these work while others don't? Does that predict if pain killers that I haven't used yet will work?

Please note that I'm not looking for medical advice on which pain killers to take; I'm just curious about how my body interacts with the various ones.



&dagger;: the one consisting of aspirin, paracetamol, and caffeine, not the one containing phenaticin. Think Excedrin.
","I don't know of any interesting mechanism that is specific to pain killers, so I will instead answer for drugs in general.

Drug action is a complex process consisting of many steps. Let's take a simple example: A systemic direct inhibitor of a kinase. This drug would need to*:


Be absorbed into your bloodstream
Remain in your bloodstream for sufficient time
Be absorbed into the tissue
Be able to bind the target protein


1 can fail due to interaction with other concurrently taken drugs or food, or simply genetic factors affecting the particular functioning of the gut mucosa. 2 can fail because the kidneys are too good at eliminating it, or the liver is metabolizing it too agressively (both also subject to modulation by other drugs, foods and genetic factors). 3 can fail because the transports in the cells aren't working as rapidly, or represent an allele less likely to take in the drug, or are modulated by other drugs/foods. The tissue can also have efflux pumps or enzymes that break down the drug. 4 can fail because the drug was designed for a specific allele of that kinase, but you happen to have a different allele, which has a slightly different structure that is no longer targeted by this drug.

Then you have a host of physiological variables, and addiction/tolerance.

Apparently the most common genetic reason by far for variable drug sensitivity is the specific set of CYP genes you have. CYP enzymes are abundant in the liver and chemically process various molecules (including drugs).

Besides this, an interesting set of specific examples used to be available from 23andme. I'm not sure if they still provide this after the FDA ban on health information.


Clopidogrel sensitivity - CYP2C19 variation
Proton Pump Inhibitor (stomach acid reduction) - CYP2C19 variation
Abacavir (HIV drug) - HLA-B*5701 SNP
Acetaldehyde (alcohol flush) - ALDH2 mutation
5-fluorouracil (chemotherapy) - DPYD mutation
PEG-IFN-alpha/RBV combination (Hepatitis C medicine) - IL28B SNP
Phenytoin (epilepsy drug) - CYP2C9 variants
Choline esters (class of muscle relaxants) - BCHE (CE degrader) variants
Sulfonylurea (used for type 2 diabetes) - CYP2C9 variants
Thiopurine (immune suppressant) -  TPMT (enzyme that degrades thiopurine) variation
Warfarin (anticoagulant) - CYP2C9 variants
Caffeine - CYP1A2 SNP
Metformin (diabetes drug) - SNP rs11212617, near the ATM gene
Antidepressant - SNPs in ABCB1 affect likelihood of sexual dysfunction (common side effect)
Beta-Blocker (heart disease) - Mutations in ADRB1 which is normally blocked by the drug
Floxacillin (drug for staphylococcal infections) - SNPs in the MHC region affect liver toxicity of this drug
Heroin - OPRM1 receptor (target of heroin) SNPs affect efficacy
Lumiracoxib (used to treat pain and symptoms of osteoarthritis) - SNPs in the MHC region affect liver toxicity
Naltrexone (alcohol and narcotic addiction drug) - SNPs in OPRM1 affect how much it can reduce pleasurable feeling from narcotics
Statins (cardiovascular disease) - SNPs in COQ2 (mitochondrial component) affect risk of myopathy


As you can see, our friends the CYP family enzymes come up frequently, and some are even repeat offenders like CYP2C9. Besides that, there is a fair number of cases where variation in the specific target of the drug are relevant.

Note that this list is not comprehensive: Many drugs have not been studied in sufficient detail, and some may have complicated mechanisms instead of just ""bind and inhibit protein X"".

I have omitted many details and links to literature, I am sure you can easily find them by searching on Google Scholar with the keywords I already gave. Let me know if that doesn't work, though.



*: Note that these aren't necessarily required for all drugs. For example, some drugs can be applied directly to the skin and hence do not need to pass through blood.
"
1054,1054,1656,Can I safely exclude sleepimage from OS X backups,"Crossposted to Stackoverflow:

I am using Chronosync to make a complete bootable backup of my OS X 10.6.4 machine to an external USB drive. It takes a LONG time (even incrementals) and part of the problem is the 8GB sleepimage. Can I safely exclude this from the backup? I realize that in case of a disaster requiring the use of the cloned drive, I would not be able to wake the Mac from sleep, but would need to reboot, but the point is to not have to reinstall all of my work from a Time Machine backup.

Thanks, Ralph
",Ralph,https://superuser.com/users/49636,"Your sleep image is typically just a dump of your machine's memory onto the hard drive so that in the event of a power loss you can resume slightly faster than a boot process.  You can safely ignore it.

Typically in my backups the only thing I grab is my Users folder. Occasionally I might be interested in things in /Library/Preferences, but rare is that event. There's nothing outside that system that can't be recovered through other means.  As for applications in /Applications, part of my backup scripts dump an ls of that directory into a file, so I know what I had there in the event of a drive failure, but I don't actively back up what can be reinstalled / redownloaded later.  'Tis a waste of backup space, especially since with new program versions, etc., that data changes quite often anyway.
",peelman,https://superuser.com/users/49207,http://superuser.com/questions/189745,TECHNOLOGY,superuser.com,1.0,0.6666666666666666,0.0,1.0,1.0,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.6666666666666666,0.0,1.0,1.0,0.7777777777777778,1.0,1.0,0.9333333333333332,0.6666666666666666,0.0,1.0,1.0,Can I safely exclude sleepimages from OSX backups,"Crossposted to Stackoverflow:

I am using Chronosync to make a complete bootable backup of my OS X 10.6.4 machine to an external USB drive. It takes a LONG time (even incrementals) and part of the problem is the 8GB sleepimage. Can I safely exclude this from the backup? I realize that in case of a disaster requiring the use of the cloned drive, I would not be able to wake the Mac from sleep, but would need to reboot, but the point is to not have to reinstall all of my work from a Time Machine backup.

Thanks, Ralph
","Your sleep image is typically just a dump of your machine's memory onto the hard drive so that in the event of a power loss you can resume slightly faster than a boot process.  You can safely ignore it.

Typically in my backups the only thing I grab is my Users folder. Occasionally I might be interested in things in /Library/Preferences, but rare is that event. There's nothing outside that system that can't be recovered through other means.  As for applications in /Applications, part of my backup scripts dump an ls of that directory into a file, so I know what I had there in the event of a drive failure, but I don't actively back up what can be reinstalled / redownloaded later.  'Tis a waste of backup space, especially since with new program versions, etc., that data changes quite often anyway.
"
2004,2004,3198,"What is a *slightly* less extreme equivalent to being ""fluent"" in a language?","tl;dr: What is a less extreme (but still noticeable) alternative to the word ""fluent"", when saying e.g. ""I am fluent in C++/Python/whatever?""



I think I can call myself ""fluent"" in C#, because I know the language and runtime very well, and I'm very familiar with the .NET framework's APIs and classes, etc.

I would like to claim the same thing for Python and C++.
But while I can program in Python (I did so for an entire summer, making a website with Django), for example, I would not call myself fluent because my code isn't always ""Pythonic"" (e.g. using map/filter vs. list comprehensions), and I'm not too intimate with some aspects of the language and standard library yet (e.g. the introspection API, etc.).

Is there a word or phrase I can use on e.g. a resume to describe what I know?

I can think of ""very familiar with"", but is there a better word/phrase I can use?
",Mehrdad,https://programmers.stackexchange.com/users/11833,"Would ""proficient"" be useful, if not that, ""competent"".  Both words suggesting a comfort with tasks given within a certain range.
",Irwin,https://programmers.stackexchange.com/users/35979,http://programmers.stackexchange.com/questions/106004/what-is-a-slightly-less-extreme-equivalent-to-being-fluent-in-a-language,TECHNOLOGY,programmers.stackexchange.com,1.0,0.7777777777777778,0.0,1.0,0.6666666666666666,0.0,0.5555555555555556,0.8888888888888888,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,0.3333333333333333,0.8888888888888888,"What is a *slightly* less extreme equivalent to being ""fluent"" in a language?","tl;dr: What is a less extreme (but still noticeable) alternative to the word ""fluent"", when saying e.g. ""I am fluent in C++/Python/whatever?""



I think I can call myself ""fluent"" in C#, because I know the language and runtime very well, and I'm very familiar with the .NET framework's APIs and classes, etc.

I would like to claim the same thing for Python and C++.
But while I can program in Python (I did so for an entire summer, making a website with Django), for example, I would not call myself fluent because my code isn't always ""Pythonic"" (e.g. using map/filter vs. list comprehensions), and I'm not too intimate with some aspects of the language and standard library yet (e.g. the introspection API, etc.).

Is there a word or phrase I can use on e.g. a resume to describe what I know?

I can think of ""very familiar with"", but is there a better word/phrase I can use?
","Would ""proficient"" be useful, if not that, ""competent"".  Both words suggesting a comfort with tasks given within a certain range.
"
3363,3363,5365,How can pKas differ across similar protons of the same atom?,"For example, citric acid has three acidic protons, all of which are carboxylic acids. Despite being part of the same functional groups, they all have very different pKas. Why (and how?) is this?
",peglegosaurus,https://chemistry.stackexchange.com/users/13183,"Here is a picture of citric acid.



As you noted, there are 3 carboxylic acid groups in citric acid, so there are 3 acidic protons. A chemist looking at this unionized molecule would say that the carboxylic acid group drawn on the right side of the molecule is equivalent to (the same as) the carboxylic acid group drawn on the left.  Therefore, these 2 equivalent carboxylic acid groups should have the same pKa.  The carboxylic acid group drawn in the middle of the diagram is different from the other two (it is not the same as the other two) and should therefore have a different $\ce{pKa}$.  In chemistry, groups are either the same or different.  If they are the same they must be indistinguishable in all aspects, including physical properties like $\ce{pKa}$

That said, we might expect when we treat citric acid with more and more base to see only 2 different $\ce{pKa}$'s, but that is not the case.  In actuality when we treat citric acid with base one of the two different (right and left or middle) carboxylic acid groups will ionize.  Once that happens the ionized citric acid molecule contains a negative charge.  It will be harder to ionize the molecule again and remove the second proton and place a second negative charge on the molecule (bringing like charges together is destabilizing and costs energy).  The same argument tells us that removing the third and final proton will be even more difficult because we wind up with 3 negative charges on the molecule.  As a consequence of this increasing difficulty to remove protons, we observe 3 different $\ce{pKa}$'s.
",ron,https://chemistry.stackexchange.com/users/4231,http://chemistry.stackexchange.com/questions/26366/how-can-pkas-differ-across-similar-protons-of-the-same-atom,SCIENCE,chemistry.stackexchange.com,1.0,1.0,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,1.0,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.3333333333333333,1.0,0.8888888888888888,What's the difference in pKas between protons of the same atom?,"For example, citric acid has three acid protons, all of which are carboxylic acids. Although they are part of the same functional group, their pKas are very different. Why (and how?) Is that right?","Here is a picture of citric acid.



As you noted, there are 3 carboxylic acid groups in citric acid, so there are 3 acidic protons. A chemist looking at this unionized molecule would say that the carboxylic acid group drawn on the right side of the molecule is equivalent to (the same as) the carboxylic acid group drawn on the left.  Therefore, these 2 equivalent carboxylic acid groups should have the same pKa.  The carboxylic acid group drawn in the middle of the diagram is different from the other two (it is not the same as the other two) and should therefore have a different $\ce{pKa}$.  In chemistry, groups are either the same or different.  If they are the same they must be indistinguishable in all aspects, including physical properties like $\ce{pKa}$

That said, we might expect when we treat citric acid with more and more base to see only 2 different $\ce{pKa}$'s, but that is not the case.  In actuality when we treat citric acid with base one of the two different (right and left or middle) carboxylic acid groups will ionize.  Once that happens the ionized citric acid molecule contains a negative charge.  It will be harder to ionize the molecule again and remove the second proton and place a second negative charge on the molecule (bringing like charges together is destabilizing and costs energy).  The same argument tells us that removing the third and final proton will be even more difficult because we wind up with 3 negative charges on the molecule.  As a consequence of this increasing difficulty to remove protons, we observe 3 different $\ce{pKa}$'s.
"
5804,5804,9193,Can I run 64-bit VM guests on a 32-bit host?,"Can I run 64-bit VM guests on a 32-bit host?

If I have a physical PC with 32 bit can I launch a VM that is 64 bit?
What virtual machine software (Virtual PC or VirtualBox or other) would allow this?

I read out there that VMware may support this but I am looking for something Open source or free.

Host would preferably be a Windows host but could be Linux. Guest needs to be Windows.

Thanks
",Maestro1024,https://serverfault.com/users/12050,"Depends what you mean by a ""32-bit host"".  If you mean hardware with a 32-bit processor that doesn't have 64-bit capabilities, then no, you can't do that through virtualisation - you would need an emulator rather than virtualisation and I'm not aware of one existing.

If you mean on a machine with a 32-bit OS, then again, it's not possible to run a 64-bit guest on a 32-bit OS without emulation (something would need to translate the 64-bit instructions into 32-bit instructions) unless either (a) the 32-bit OS allows 64-bit applications (like Mac OS X) or (b) you can bypass the OS with a hypervisor.  I'm not aware of a 32-bit type II virtualisation product for the Mac that allows a 64-bit OS to run as a 64-bit app.  In fact, I'm not aware of a type II virtualisation product for the Mac at all.

If you're using a hypervisor (type I virtualisation) like Hyper-V, VMWare ESX, Virtual Box, etc, then it should be possible, because the guest OS does not run on the host OS, but on the hypervisor.  Indeed, the ""host"" OS actually runs on the hypervisor too.
",Richard Gadsden,https://serverfault.com/users/247,http://serverfault.com/questions/64127,TECHNOLOGY,serverfault.com,0.8888888888888888,0.6666666666666666,0.0,0.6666666666666666,1.0,1.0,0.5555555555555556,0.3333333333333333,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9,0.3333333333333333,0.0,1.0,1.0,Can I run a 64 bit virtual machine guest on a 32-bit host?,"Can I run 64-bit VM guests on a 32-bit host?

If I have a physical PC with 32 bit can I launch a VM that is 64 bit?
What virtual machine software (Virtual PC or VirtualBox or other) would allow this?

I read out there that VMware may support this but I am looking for something Open source or free.

Host would preferably be a Windows host but could be Linux. Guest needs to be Windows.

Thanks
","Depends what you mean by a ""32-bit host"".  If you mean hardware with a 32-bit processor that doesn't have 64-bit capabilities, then no, you can't do that through virtualisation - you would need an emulator rather than virtualisation and I'm not aware of one existing.

If you mean on a machine with a 32-bit OS, then again, it's not possible to run a 64-bit guest on a 32-bit OS without emulation (something would need to translate the 64-bit instructions into 32-bit instructions) unless either (a) the 32-bit OS allows 64-bit applications (like Mac OS X) or (b) you can bypass the OS with a hypervisor.  I'm not aware of a 32-bit type II virtualisation product for the Mac that allows a 64-bit OS to run as a 64-bit app.  In fact, I'm not aware of a type II virtualisation product for the Mac at all.

If you're using a hypervisor (type I virtualisation) like Hyper-V, VMWare ESX, Virtual Box, etc, then it should be possible, because the guest OS does not run on the host OS, but on the hypervisor.  Indeed, the ""host"" OS actually runs on the hypervisor too.
"
1875,1875,2978,How do I map a key into the shift key in Windows? (see picture of Canadian French keyboard),"As luck would have it, my computer dealer shipped me a laptop with a Canadian French keyboard



instead of a US keyboard



Instead of saying how much Canadians from sea to sea hate this keyboard layout and hate being transitioned into it in the last couple of years, I'd like to ask for a software solution.  Is there a software that can map the [>>/&lt;&lt;] key to [Shift] and the [> &lt; }] to [Enter], et cetera?

+1 if you can suggest how to type the ""\"".

-1 if you suggest, 'Just order a US keyboard. Replacing it takes a minute.' :)
",William C,https://superuser.com/users/57438,"You might check out the question I asked earlier about key mapping. I put up a tut there for how to assign keys using the registry and another user, Yosh, put a link to some software that will do this for you.

I've never tried this on a french keyboard before but if you decide to do it manually, this hex key should map '\' to alt+1

00,00,00,00,00,00,00,00,3,00,00,00,2B,00,78,00,78,00,2B,00,00,00,00,00

",Blomkvist,https://superuser.com/users/79522,http://superuser.com/questions/282339,TECHNOLOGY,superuser.com,1.0,0.6666666666666666,0.0,0.3333333333333333,1.0,1.0,0.5555555555555556,0.4444444444444444,0.6666666666666666,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.7777777777777778,"In windows, how do I map keys to shift keys? (see Canadian French keyboard picture)","As luck would have it, my computer dealer shipped me a laptop with a Canadian French keyboard



instead of a US keyboard



Instead of saying how much Canadians from sea to sea hate this keyboard layout and hate being transitioned into it in the last couple of years, I'd like to ask for a software solution.  Is there a software that can map the [>>/&lt;&lt;] key to [Shift] and the [> &lt; }] to [Enter], et cetera?

+1 if you can suggest how to type the ""\"".

-1 if you suggest, 'Just order a US keyboard. Replacing it takes a minute.' :)
","You might check out the question I asked earlier about key mapping. I put up a tut there for how to assign keys using the registry and another user, Yosh, put a link to some software that will do this for you.

I've never tried this on a french keyboard before but if you decide to do it manually, this hex key should map '\' to alt+1

00,00,00,00,00,00,00,00,3,00,00,00,2B,00,78,00,78,00,2B,00,00,00,00,00

"
3631,3631,5796,"Implementing a custom FormsAuthenticationProvider using Owin, Katana, and Nancy","I am working on implementing a custom FormsAuthenticationProvider and I'm getting a middleware conversion error.

No conversion available between System.Func`2[System.Collections.Generic.IDictionary`2
[System.String,System.Object],System.Threading.Tasks.Task] and Microsoft.Owin.OwinMiddleware
Parameter name: signature


My stack includes 


Owin
Katana
Nancy


My specific question would be any advice on where to look for an example on how to implement a custom FormsAuthenticationProvider? Unless someone can spot my problem.

My implementation looks like:

Startup.cs

app.UseFormsAuthentication(new FormsAuthenticationOptions
            {
                LoginPath = ""/login"",
                LogoutPath = ""/logout"",
                CookieHttpOnly = true,
                AuthenticationType = Constants.ChainLinkAuthType,
                CookieName = ""chainlink.id"",
                ExpireTimeSpan = TimeSpan.FromDays(30),
                Provider = kernel.Get&lt;IFormsAuthenticationProvider&gt;()
            });


If I remove the app.UseFormsAuthentication(...) the application runs without error.

Full Stack Trace

[ArgumentException: No conversion available between System.Func`2[System.Collections.Generic.IDictionary`2[System.String,System.Object],System.Threading.Tasks.Task] and Microsoft.Owin.OwinMiddleware
Parameter name: signature]
   Owin.Builder.AppBuilder.Convert(Type signature, Object app) +328
   Owin.Builder.AppBuilder.BuildInternal(Type signature) +336
   Owin.Builder.AppBuilder.Build(Type returnType) +42
   Microsoft.Owin.Host.SystemWeb.OwinAppContext.Initialize(Action`1 startup) +650
   Microsoft.Owin.Host.SystemWeb.OwinBuilder.Build(Action`1 startup) +86
   Microsoft.Owin.Host.SystemWeb.OwinBuilder.Build() +185
   System.Lazy`1.CreateValue() +416
   System.Lazy`1.LazyInitValue() +152
   System.Lazy`1.get_Value() +75
   Microsoft.Owin.Host.SystemWeb.OwinApplication.get_Instance() +35
   Microsoft.Owin.Host.SystemWeb.OwinHttpModule.Init(HttpApplication context) +106
   System.Web.HttpApplication.RegisterEventSubscriptionsWithIIS(IntPtr appContext, HttpContext context, MethodInfo[] handlers) +418
   System.Web.HttpApplication.InitSpecial(HttpApplicationState state, MethodInfo[] handlers, IntPtr appContext, HttpContext context) +172
   System.Web.HttpApplicationFactory.GetSpecialApplicationInstance(IntPtr appContext, HttpContext context) +336
   System.Web.Hosting.PipelineRuntime.InitializeApplication(IntPtr appContext) +296

[HttpException (0x80004005): No conversion available between     System.Func`2[System.Collections.Generic.IDictionary`2[System.String,System.Object],System.Threading.Tasks.Task] and Microsoft.Owin.OwinMiddleware
Parameter name: signature]
   System.Web.HttpRuntime.FirstRequestInit(HttpContext context) +9874568
   System.Web.HttpRuntime.EnsureFirstRequestInit(HttpContext context) +101
   System.Web.HttpRuntime.ProcessRequestNotificationPrivate(IIS7WorkerRequest wr,  HttpContext context) +254


Executable Source Code (Just F5 it and you'll get the error immediately)

https://github.com/cnwilkin/ChainLink/tree/spike
",Chad Wilkin,https://stackoverflow.com/users/1607996,"Can you try updating the version of Microsoft.Owin.Host.SystemWeb package to the latest RC as well and try? You have all other Owin* dlls in rc but this is 1.0.0. Could be causing the issue. Also please use Microsoft.Owin.Security.Cookies instead of Microsoft.Owin.Security.Forms. The Forms package has been renamed to Cookies now. 
",Praburaj,https://stackoverflow.com/users/1621178,http://stackoverflow.com/questions/17595434/implementing-a-custom-formsauthenticationprovider-using-owin-katana-and-nancy,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.5555555555555556,0.0,1.0,0.3333333333333333,0.5,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.8,1.0,0.3333333333333333,0.0,1.0,"Using owin, Katana and Nancy to implement custom formsauthenticationprovider","I am working on implementing a custom FormsAuthenticationProvider and I'm getting a middleware conversion error.

No conversion available between System.Func`2[System.Collections.Generic.IDictionary`2
[System.String,System.Object],System.Threading.Tasks.Task] and Microsoft.Owin.OwinMiddleware
Parameter name: signature


My stack includes 


Owin
Katana
Nancy


My specific question would be any advice on where to look for an example on how to implement a custom FormsAuthenticationProvider? Unless someone can spot my problem.

My implementation looks like:

Startup.cs

app.UseFormsAuthentication(new FormsAuthenticationOptions
            {
                LoginPath = ""/login"",
                LogoutPath = ""/logout"",
                CookieHttpOnly = true,
                AuthenticationType = Constants.ChainLinkAuthType,
                CookieName = ""chainlink.id"",
                ExpireTimeSpan = TimeSpan.FromDays(30),
                Provider = kernel.Get&lt;IFormsAuthenticationProvider&gt;()
            });


If I remove the app.UseFormsAuthentication(...) the application runs without error.

Full Stack Trace

[ArgumentException: No conversion available between System.Func`2[System.Collections.Generic.IDictionary`2[System.String,System.Object],System.Threading.Tasks.Task] and Microsoft.Owin.OwinMiddleware
Parameter name: signature]
   Owin.Builder.AppBuilder.Convert(Type signature, Object app) +328
   Owin.Builder.AppBuilder.BuildInternal(Type signature) +336
   Owin.Builder.AppBuilder.Build(Type returnType) +42
   Microsoft.Owin.Host.SystemWeb.OwinAppContext.Initialize(Action`1 startup) +650
   Microsoft.Owin.Host.SystemWeb.OwinBuilder.Build(Action`1 startup) +86
   Microsoft.Owin.Host.SystemWeb.OwinBuilder.Build() +185
   System.Lazy`1.CreateValue() +416
   System.Lazy`1.LazyInitValue() +152
   System.Lazy`1.get_Value() +75
   Microsoft.Owin.Host.SystemWeb.OwinApplication.get_Instance() +35
   Microsoft.Owin.Host.SystemWeb.OwinHttpModule.Init(HttpApplication context) +106
   System.Web.HttpApplication.RegisterEventSubscriptionsWithIIS(IntPtr appContext, HttpContext context, MethodInfo[] handlers) +418
   System.Web.HttpApplication.InitSpecial(HttpApplicationState state, MethodInfo[] handlers, IntPtr appContext, HttpContext context) +172
   System.Web.HttpApplicationFactory.GetSpecialApplicationInstance(IntPtr appContext, HttpContext context) +336
   System.Web.Hosting.PipelineRuntime.InitializeApplication(IntPtr appContext) +296

[HttpException (0x80004005): No conversion available between     System.Func`2[System.Collections.Generic.IDictionary`2[System.String,System.Object],System.Threading.Tasks.Task] and Microsoft.Owin.OwinMiddleware
Parameter name: signature]
   System.Web.HttpRuntime.FirstRequestInit(HttpContext context) +9874568
   System.Web.HttpRuntime.EnsureFirstRequestInit(HttpContext context) +101
   System.Web.HttpRuntime.ProcessRequestNotificationPrivate(IIS7WorkerRequest wr,  HttpContext context) +254


Executable Source Code (Just F5 it and you'll get the error immediately)

https://github.com/cnwilkin/ChainLink/tree/spike
","Can you try updating the version of Microsoft.Owin.Host.SystemWeb package to the latest RC as well and try? You have all other Owin* dlls in rc but this is 1.0.0. Could be causing the issue. Also please use Microsoft.Owin.Security.Cookies instead of Microsoft.Owin.Security.Forms. The Forms package has been renamed to Cookies now. 
"
4339,4339,6911,"If $f: \mathbb Q\to \mathbb Q$ is a homomorphism, prove that $f(x)=0$ for all $x\in\mathbb Q$ or $f(x)=x$ for all $x$ in $\mathbb Q$.","If $f: \mathbb Q\to \mathbb Q$ is a homomorphism, prove that $f(x)=0$ for all $x\in\mathbb Q$ or $f(x)=x$ for all $x$ in $\mathbb Q$.

I'm wondering if you can help me with this one? 
",Mirna,https://math.stackexchange.com/users/36579,"I understand that we're looking at rationals as a ring (as a group it is obviously false).

Pick an arbitrary homomorphism $\varphi:\mathbf Q\to \mathbf Q$. Put $e:=\varphi(1)$.

If $e=0$, then for any $x\in \mathbf Q$ we have $\varphi(x)=\varphi(1)\varphi(x)=0\cdot\varphi(x)=0$, so  $\varphi$ is zero.

If $e\neq 0$, then $e\cdot e=\varphi(1)\varphi(1)=\varphi(1\cdot 1)=e$, so $e=1$ (since $e\neq 0$ and $0,1$ are the only solutions of the equation $x^2-x=0$). Furthermore, for any $\frac{p}{q}$ we have $1+\ldots+1=p\cdot 1= p=\frac{p}{q}+\ldots \frac{p}{q}=q\cdot \frac{p}{q}$, so $e+\ldots +e=p\cdot e= q\cdot \varphi(\frac{p}{q})$, so $\varphi(\frac{p}{q})=e\cdot \frac{p}{q}=\frac{p}{q}$ and we're done (for negative $p$ we can use $\frac{p}{q}=(-1)\cdot \frac{-p}{q}$ so $\varphi(\frac{p}{q})=-e\cdot\varphi(\frac{-p}{q})=\frac{p}{q}$).
",tomasz,https://math.stackexchange.com/users/30222,http://math.stackexchange.com/questions/175477/if-f-mathbb-q-to-mathbb-q-is-a-homomorphism-prove-that-fx-0-for-all-x,SCIENCE,math.stackexchange.com,1.0,0.5555555555555556,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8666666666666666,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.8888888888888888,"If $f: \ mathbb Q \ to \ mathbb q $is homomorphic, then prove that $f (x) = 0 $means all $X \ in \ mathbb q $, or $f (x) = x $means all $x $in $\ mathbb q $.","If $f: \ mathbb Q \ to \ mathbb q $is homomorphic, then prove that $f (x) = 0 $means all $X \ in \ mathbb q $, or $f (x) = x $means all $x $in $\ mathbb q $.","I understand that we're looking at rationals as a ring (as a group it is obviously false).

Pick an arbitrary homomorphism $\varphi:\mathbf Q\to \mathbf Q$. Put $e:=\varphi(1)$.

If $e=0$, then for any $x\in \mathbf Q$ we have $\varphi(x)=\varphi(1)\varphi(x)=0\cdot\varphi(x)=0$, so  $\varphi$ is zero.

If $e\neq 0$, then $e\cdot e=\varphi(1)\varphi(1)=\varphi(1\cdot 1)=e$, so $e=1$ (since $e\neq 0$ and $0,1$ are the only solutions of the equation $x^2-x=0$). Furthermore, for any $\frac{p}{q}$ we have $1+\ldots+1=p\cdot 1= p=\frac{p}{q}+\ldots \frac{p}{q}=q\cdot \frac{p}{q}$, so $e+\ldots +e=p\cdot e= q\cdot \varphi(\frac{p}{q})$, so $\varphi(\frac{p}{q})=e\cdot \frac{p}{q}=\frac{p}{q}$ and we're done (for negative $p$ we can use $\frac{p}{q}=(-1)\cdot \frac{-p}{q}$ so $\varphi(\frac{p}{q})=-e\cdot\varphi(\frac{-p}{q})=\frac{p}{q}$).
"
5990,5990,9495,Why Have The System Builder Market Not Migrated to the BTX Form Factor from ATX yet?,"I'm starting to build my first computer from the parts that I have purchased and a question that had been nagging me for the past few weeks was why the ATX form factor is still currently used when there is the newer BTX formfactor. 
",JFW,https://superuser.com/users/27043,"There seems to be insufficient drive to make the change.

There was some noise that BTX offered better component layouts (speed) and airflow for hotter components, but when you look at the requirements for case manufacturers to change their case designs (or as some manufacturers attempted - offer convertible designs), motherboard manufacturers to change their layouts, etc... it's not enough benefit to drive the costs and make the change.
",Chris Thorpe,https://superuser.com/users/80272,http://superuser.com/questions/176689,TECHNOLOGY,superuser.com,1.0,1.0,0.5,1.0,1.0,0.5,0.3333333333333333,0.6666666666666666,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,0.8333333333333334,Why hasn't the system builder market moved from ATX to BTX forms?,"I started to build my first computer with the parts I bought, and the question that has been bothering me for the past few weeks is why the ATX for M factor is still in use when there is a new BTX for M factor.","There seems to be insufficient drive to make the change.

There was some noise that BTX offered better component layouts (speed) and airflow for hotter components, but when you look at the requirements for case manufacturers to change their case designs (or as some manufacturers attempted - offer convertible designs), motherboard manufacturers to change their layouts, etc... it's not enough benefit to drive the costs and make the change.
"
5227,5227,8309,Why don't spinning tops fall over?,"One topic which was covered in university, but which I never understood, is how a spinning top ""magically"" resists the force of gravity. The conservation of energy explanations make sense, but I don't believe that they provide as much insight as a mechanical explanation would.

The hyperphysics link Cedric provided looks similar to a diagram that I saw in my physics textbook. This diagram illustrates precession nicely, but doesn't explain why the top doesn't fall. Since the angular acceleration is always tangential, I would expect that the top should spiral outwards until it falls to the ground. However, the diagram seems to indicate that the top should be precessing in a circle, not a spiral. Another reason I am not satisfied with this explanation is that the calculation is apparently limited to situations where: ""the spin angular velocity $\omega$ is much greater than the precession angular velocity $\omega_P$"". The calculation gives no explanation of why this is not the case.
",Casebash,https://physics.stackexchange.com/users/119,"The point is that conservation principles are not generally intuitive. For example, why should energy be conserved? One must have a grip of the dynamics involved in order to understand them. 

Anyway, the precession of the spinning top doesn't have to do with the conservation of angular momentum. It has to do with the strange nature of torque and its interaction with angular momentum. When a force acts on a spinning top, it excerpts a torque perpendicular to the plane defined by the axis of the top and the direction of gravity, which is a vertical plane. That direction is horizontal. 
On the other hand, the torque is the rate of change of angular momentum. That means that the direction of the torque is the direction towards which the vector of angular momentum changes. Thus, since the torque is horizontal and perpendicular to the angular momentum, it can only change the direction of angular momentum along the horizontal direction and not towards the ground. That means that the vector of angular momentum has its back on the ground, at the point that the tip of the top touches the ground, and its head is performing a circle on a plane that is parallel to the ground. That motion is the precession of the spinning top.   

Finally, I think that the reason for assuming a much faster rotation than precession for the top, is to simplify the calculations and consider the top as a gyroscope. 
",Vagelford,https://physics.stackexchange.com/users/383,http://physics.stackexchange.com/questions/271/why-dont-spinning-tops-fall-over,SCIENCE,physics.stackexchange.com,0.7777777777777778,0.6666666666666666,0.0,1.0,1.0,1.0,0.7777777777777778,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.8888888888888888,0.6666666666666666,0.7777777777777778,0.8888888888888888,0.8,0.0,0.0,1.0,1.0,Why didn't the top fall off?,"One topic which was covered in university, but which I never understood, is how a spinning top ""magically"" resists the force of gravity. The conservation of energy explanations make sense, but I don't believe that they provide as much insight as a mechanical explanation would.

The hyperphysics link Cedric provided looks similar to a diagram that I saw in my physics textbook. This diagram illustrates precession nicely, but doesn't explain why the top doesn't fall. Since the angular acceleration is always tangential, I would expect that the top should spiral outwards until it falls to the ground. However, the diagram seems to indicate that the top should be precessing in a circle, not a spiral. Another reason I am not satisfied with this explanation is that the calculation is apparently limited to situations where: ""the spin angular velocity $\omega$ is much greater than the precession angular velocity $\omega_P$"". The calculation gives no explanation of why this is not the case.
","The point is that conservation principles are not generally intuitive. For example, why should energy be conserved? One must have a grip of the dynamics involved in order to understand them. 

Anyway, the precession of the spinning top doesn't have to do with the conservation of angular momentum. It has to do with the strange nature of torque and its interaction with angular momentum. When a force acts on a spinning top, it excerpts a torque perpendicular to the plane defined by the axis of the top and the direction of gravity, which is a vertical plane. That direction is horizontal. 
On the other hand, the torque is the rate of change of angular momentum. That means that the direction of the torque is the direction towards which the vector of angular momentum changes. Thus, since the torque is horizontal and perpendicular to the angular momentum, it can only change the direction of angular momentum along the horizontal direction and not towards the ground. That means that the vector of angular momentum has its back on the ground, at the point that the tip of the top touches the ground, and its head is performing a circle on a plane that is parallel to the ground. That motion is the precession of the spinning top.   

Finally, I think that the reason for assuming a much faster rotation than precession for the top, is to simplify the calculations and consider the top as a gyroscope. 
"
3178,3178,5063,Can I change my loan term from 60 to 36 months?,"I am on a 60 months plan with USCCU and now they are offering APR rate of 1.36% for 36 months on used and new vehicles as shown here. Is it a good idea to change my loan term from 60 to 36 months considering the fact that I can afford the monthly installments which could be higher that what I am paying for in 60 months term with an APR rate of say, for example x%.
",John,https://money.stackexchange.com/users/13189,"Some places banks/Credit Unions will allow you to refinance a auto loan. My credit Union only does this if the original loan was with another lender. They will send the money to the old lender, then give you a loan under the new terms. They are trying to get your business, not necessarily looking for a way make less money for themselves. 

You will have to see how much you will save. Which will be based on the delta of the length of the loan or the change in interest rate, or both. My Credit Union has a calculator to show you the numbers based on keeping the size of the payments the same, or keeping the number of payments the same. 

Make sure you understand any limitations regarding the refinance based on the age of the car, and if you are underwater.
",mhoran_psprep,https://money.stackexchange.com/users/5414,http://money.stackexchange.com/questions/39781/can-i-change-my-loan-term-from-60-to-36-months,LIFE_ARTS,money.stackexchange.com,1.0,0.6666666666666666,0.3333333333333333,0.5,0.6666666666666666,0.5,0.5555555555555556,0.5555555555555556,0.3333333333333333,0.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.8888888888888888,0.8888888888888888,0.7777777777777778,1.0,0.7777777777777778,0.8,0.3333333333333333,0.0,1.0,0.7777777777777778,Can I change the loan term from 60 months to 36 months?,"I have a 60 month plan with usccu, and now they offer used cars and new cars with an APR rate of 1.36% for 36 months, as shown in the figure. Considering the fact that I can afford the monthly installment, is it a good idea to change my loan term from 60 months to 36 months? The monthly installments I can afford may be higher than the installments I pay in 60 months, for example, the interest rate in April is x%.","Some places banks/Credit Unions will allow you to refinance a auto loan. My credit Union only does this if the original loan was with another lender. They will send the money to the old lender, then give you a loan under the new terms. They are trying to get your business, not necessarily looking for a way make less money for themselves. 

You will have to see how much you will save. Which will be based on the delta of the length of the loan or the change in interest rate, or both. My Credit Union has a calculator to show you the numbers based on keeping the size of the payments the same, or keeping the number of payments the same. 

Make sure you understand any limitations regarding the refinance based on the age of the car, and if you are underwater.
"
4493,4493,7125,Add class via command line,"Classes can be added to an Android project in Eclipse via New -> Class, and this will supposedly add it to the project somehow, but how can I do this via the command line? I set up the class in src/(reverse.dns.path)/CLASS.java, but I couldn't find anything in http://developer.android.com/tools/building/building-cmdline.html, but I would appreciate any guidance
",Marco Scannadinari,https://stackoverflow.com/users/1526894,"There is no command for adding class from command line. Just add necessary .java file with a text editor. Java compiler will compile that class.
",Atilla Ozgur,https://stackoverflow.com/users/41782,http://stackoverflow.com/questions/27583357/add-class-via-command-line,STACKOVERFLOW,stackoverflow.com,1.0,0.4444444444444444,0.0,0.5,1.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.0,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.8666666666666666,0.6666666666666666,0.6666666666666666,0.0,0.8888888888888888,Adding classes from the command line,"Classes can be added to Android projects in eclipse through new - > class, which may be added to projects in some way, but how can I do this from the command line? I set this class in Src / (reverse. DNS. Path) / class. Java, but I can't find anything in http://developer.android.com/tools/building/building-cmdline.html, but I want to get any guidance",There are no commands to add classes from the command line. Just use the text editor to add the necessary. Java files. The java compiler compiles the class.
5367,5367,8525,Is there any performance difference between ++i and i++ in C#?,"Is there any performance difference between using something like

for(int i = 0; i &lt; 10; i++) { ... }


and

for(int i = 0; i &lt; 10; ++i) { ... }


or is the compiler able to optimize in such a way that they are equally fast in the case where they are functionally equivalent?

Edit:
This was asked because I had a discussion with a co-worker about it, not because I think its a useful optimization in any practical sense. It is largely academic. 
",Anton,https://stackoverflow.com/users/341413,"Ah... Open again.  OK. Here's the deal.

ILDASM is a start, but not an end.  The key is: What will the JIT generate for assembly code?

Here's what you want to do.

Take a couple samples of what you are trying to look at.  Obviously you can wall-clock time them if you want - but I assume you want to know more than that.

Here's what's not obvious.  The C# compiler generates some MSIL sequences that are non-optimal in a lot of situations.  The JIT it tuned to deal with these and quirks from other languages.  The problem: Only 'quirks' someone has noticed have been tuned.

You really want to make a sample that has your implementations to try, returns back up to main (or wherever), Sleep()s, or something where you can attach a debugger, then run the routines again.

You DO NOT want to start the code under the debugger or the JIT will generate non-optimized code - and it sounds like you want to know how it will behave in a real environment.  The JIT does this to maximize debug info and minimize the current source location from 'jumping around'.  Never start a perf evaluation under the debugger.

OK.  So once the code has run once (ie: The JIT has generated code for it), then attach the debugger during the sleep (or whatever).  Then look at the x86/x64 that was generated for the two routines.

My gut tells me that if you are using ++i/i++ as you described - ie: in a stand alone expression where the rvalue result is not re-used - there won't be a difference.  But won't it be fun to go find out and see all the neat stuff! :)
",Joe,https://stackoverflow.com/users/21950,http://stackoverflow.com/questions/467322/is-there-any-performance-difference-between-i-and-i-in-c,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,1.0,0.0,0.6666666666666666,1.0,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.8,0.0,1.0,1.0,0.8888888888888888,Is there any performance difference between + + I and I + + in C + +?,"Is there any performance difference between using something like

for(int i = 0; i &lt; 10; i++) { ... }


and

for(int i = 0; i &lt; 10; ++i) { ... }


or is the compiler able to optimize in such a way that they are equally fast in the case where they are functionally equivalent?

Edit:
This was asked because I had a discussion with a co-worker about it, not because I think its a useful optimization in any practical sense. It is largely academic. 
","Ah... Open again.  OK. Here's the deal.

ILDASM is a start, but not an end.  The key is: What will the JIT generate for assembly code?

Here's what you want to do.

Take a couple samples of what you are trying to look at.  Obviously you can wall-clock time them if you want - but I assume you want to know more than that.

Here's what's not obvious.  The C# compiler generates some MSIL sequences that are non-optimal in a lot of situations.  The JIT it tuned to deal with these and quirks from other languages.  The problem: Only 'quirks' someone has noticed have been tuned.

You really want to make a sample that has your implementations to try, returns back up to main (or wherever), Sleep()s, or something where you can attach a debugger, then run the routines again.

You DO NOT want to start the code under the debugger or the JIT will generate non-optimized code - and it sounds like you want to know how it will behave in a real environment.  The JIT does this to maximize debug info and minimize the current source location from 'jumping around'.  Never start a perf evaluation under the debugger.

OK.  So once the code has run once (ie: The JIT has generated code for it), then attach the debugger during the sleep (or whatever).  Then look at the x86/x64 that was generated for the two routines.

My gut tells me that if you are using ++i/i++ as you described - ie: in a stand alone expression where the rvalue result is not re-used - there won't be a difference.  But won't it be fun to go find out and see all the neat stuff! :)
"
4106,4106,6554,User @include url Precedence over Script @include url,"I don't like scripts that use: 

// @include http://*


they overload many pages, where we didn't want to, also because I had problems in past, while writing a script, console was full of errors produced by scripts of this kind. I recognize scripts like these ones anti-adblock , noPicAds are on my required list, but in order to use them I change the includes to the specific page I use. Let's suppose, I entered on a webpage and it says: ""You need to disable Adblock"" so I grab the url, go manually and edit the anti-adblock script adding 

// @include http://example.com/*


refresh the page and it's working.
Now when the scripts update, everything is lost. No I don't want to stop updating, because I think these kind of scripts are essentially needed to stay updated. 

My question is, there's anyway to keep include changes after update?
",Comentarist,https://stackoverflow.com/users/805070,"If the problem is include/exclude, you can override it with your own user preferences which stays on after script update.

Go to Add-ons - User Scripts ('Ctrl+ Shift + a' on Firefox)
Click on the Script's Option
Under User Settings Tab, Add Included/Excluded Pages that you want the script to run on
Click OK

More Info: User Specified Rules


  Since Greasemonkey 0.9.9, users have been able to specify their own
  exclude and include values through the script options dialog in the
  Add Ons Manager. Thus, each script has its own rules plus optionally
  the user's rules.
  
  The user's rules are checked first, then the script's rules are
  checked. If any exclude matches the page, the script does not run. If
  any include matches the page, the script will run. If a script include
  matches, but a user exclude also matches, the user exclude will take
  precedence over the script, and it will not run. If a script exclude
  matches, but a user include also matches, the user include will take
  precedence over the script, and it will run.


For example under Excluded Pages try: http://*
",erosman,https://stackoverflow.com/users/3529456,http://stackoverflow.com/questions/25170485/user-include-url-precedence-over-script-include-url,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.4444444444444444,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,0.3333333333333333,0.8888888888888888,User @ include URL takes precedence over script @ include URL,"I don't like scripts that use: 

// @include http://*


they overload many pages, where we didn't want to, also because I had problems in past, while writing a script, console was full of errors produced by scripts of this kind. I recognize scripts like these ones anti-adblock , noPicAds are on my required list, but in order to use them I change the includes to the specific page I use. Let's suppose, I entered on a webpage and it says: ""You need to disable Adblock"" so I grab the url, go manually and edit the anti-adblock script adding 

// @include http://example.com/*


refresh the page and it's working.
Now when the scripts update, everything is lost. No I don't want to stop updating, because I think these kind of scripts are essentially needed to stay updated. 

My question is, there's anyway to keep include changes after update?
","If the problem is include/exclude, you can override it with your own user preferences which stays on after script update.

Go to Add-ons - User Scripts ('Ctrl+ Shift + a' on Firefox)
Click on the Script's Option
Under User Settings Tab, Add Included/Excluded Pages that you want the script to run on
Click OK

More Info: User Specified Rules


  Since Greasemonkey 0.9.9, users have been able to specify their own
  exclude and include values through the script options dialog in the
  Add Ons Manager. Thus, each script has its own rules plus optionally
  the user's rules.
  
  The user's rules are checked first, then the script's rules are
  checked. If any exclude matches the page, the script does not run. If
  any include matches the page, the script will run. If a script include
  matches, but a user exclude also matches, the user exclude will take
  precedence over the script, and it will not run. If a script exclude
  matches, but a user include also matches, the user include will take
  precedence over the script, and it will run.


For example under Excluded Pages try: http://*
"
5687,5687,9015,Can Noether's theorem be understood intuitively?,"Noether's theorem is one of those surprisingly clear results of mathematical calculations, for which I am inclined to think that some kind of intuitive understanding should or must be possible. However I don't know of any, do you?

Independence of time &lt;=> energy conservation.
Independence of position &lt;=> momentum conservation.
Independence of direction &lt;=> angular momentum conservation.  

I know that the mathematics leads in the direction of Lie-algebra and such but I would like to discuss whether this theorem can be understood from a non-mathematical point of view also.
",Gerard,https://physics.stackexchange.com/users/139,"It's intuitively clear that the energy most accurately describes how much the state of the system is changing with time. So if the laws of physics don't depend on time, then the amount how much the state of the system changes with time has to be conserved because it's still changing in the same way.

In the same way, and perhaps even more intuitively, if the laws don't depend on position, you may hit the objects, and hit them a little bit more, and so on. The momentum measures how much the objects depend on space, so if the laws themselves don't depend on the position on space, the momentum has to be conserved.

The angular momentum with respect to an axis is determining how much the state changes if you rotate it around the axis - how much it depends on the angle (therefore ""angular"" in the name). So the symmetry is linked to the conservation law once again. 

If your intuition doesn't find the comments intuitive enough, maybe you should train your intuition because your current intuition apparently misses the most important properties of time, space, angles, energy, momentum, and angular momentum. ;-)
",Luboš Motl,https://physics.stackexchange.com/users/1236,http://physics.stackexchange.com/questions/4959/can-noethers-theorem-be-understood-intuitively,SCIENCE,physics.stackexchange.com,0.8888888888888888,0.7777777777777778,1.0,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,1.0,0.8333333333333334,0.6666666666666666,0.8333333333333334,0.8888888888888888,0.7,0.0,0.0,1.0,1.0,Can we understand the Noether's theorem intuitively?,"Noether's theorem is one of those surprisingly clear results of mathematical calculations, for which I am inclined to think that some kind of intuitive understanding should or must be possible. However I don't know of any, do you?

Independence of time &lt;=> energy conservation.
Independence of position &lt;=> momentum conservation.
Independence of direction &lt;=> angular momentum conservation.  

I know that the mathematics leads in the direction of Lie-algebra and such but I would like to discuss whether this theorem can be understood from a non-mathematical point of view also.
","It's intuitively clear that the energy most accurately describes how much the state of the system is changing with time. So if the laws of physics don't depend on time, then the amount how much the state of the system changes with time has to be conserved because it's still changing in the same way.

In the same way, and perhaps even more intuitively, if the laws don't depend on position, you may hit the objects, and hit them a little bit more, and so on. The momentum measures how much the objects depend on space, so if the laws themselves don't depend on the position on space, the momentum has to be conserved.

The angular momentum with respect to an axis is determining how much the state changes if you rotate it around the axis - how much it depends on the angle (therefore ""angular"" in the name). So the symmetry is linked to the conservation law once again. 

If your intuition doesn't find the comments intuitive enough, maybe you should train your intuition because your current intuition apparently misses the most important properties of time, space, angles, energy, momentum, and angular momentum. ;-)
"
3523,3523,5616,Bash - use loop to make backup script more efficient,"I've a backup script (bash). Part of it is shown below. This script does a 14 day rotation of the backup. If I want to change this to say 30 days, I'd have to write out 30 such if-then blocks. I'm sure this could be replaced by a nifty for-loop. What would it be?

# step 1: delete the oldest snapshot, if it exists:
if [ -d $BACKUP_DIR/daily.14 ] ; then                   \
$RM -rf $BACKUP_DIR/daily.14 ;                          \
fi ;

# step 2: shift the middle snapshot(s) back by one, if they exist
if [ -d $BACKUP_DIR/daily.13 ] ; then                   \
$MV $BACKUP_DIR/daily.13 $BACKUP_DIR/daily.14 ; \
fi;

if [ -d $BACKUP_DIR/daily.12 ] ; then                   \
$MV $BACKUP_DIR/daily.12 $BACKUP_DIR/daily.13 ; \
fi;

if [ -d $BACKUP_DIR/daily.11 ] ; then                   \
$MV $BACKUP_DIR/daily.11 $BACKUP_DIR/daily.12 ; \
fi;

if [ -d $BACKUP_DIR/daily.10 ] ; then                   \
$MV $BACKUP_DIR/daily.10 $BACKUP_DIR/daily.11 ; \
fi;

if [ -d $BACKUP_DIR/daily.9 ] ; then                    \
$MV $BACKUP_DIR/daily.9 $BACKUP_DIR/daily.10 ;  \
fi;

if [ -d $BACKUP_DIR/daily.8 ] ; then                    \
$MV $BACKUP_DIR/daily.8 $BACKUP_DIR/daily.9 ;   \
fi;

if [ -d $BACKUP_DIR/daily.7 ] ; then                    \
$MV $BACKUP_DIR/daily.7 $BACKUP_DIR/daily.8 ;   \
fi;

if [ -d $BACKUP_DIR/daily.6 ] ; then                    \
$MV $BACKUP_DIR/daily.6 $BACKUP_DIR/daily.7 ;   \
fi;

if [ -d $BACKUP_DIR/daily.5 ] ; then                    \
$MV $BACKUP_DIR/daily.5 $BACKUP_DIR/daily.6 ;   \
fi;

if [ -d $BACKUP_DIR/daily.4 ] ; then                    \
$MV $BACKUP_DIR/daily.4 $BACKUP_DIR/daily.5 ;   \
fi;

if [ -d $BACKUP_DIR/daily.3 ] ; then                    \
$MV $BACKUP_DIR/daily.3 $BACKUP_DIR/daily.4 ;   \
fi;

if [ -d $BACKUP_DIR/daily.2 ] ; then                    \
$MV $BACKUP_DIR/daily.2 $BACKUP_DIR/daily.3 ;   \
fi;

if [ -d $BACKUP_DIR/daily.1 ] ; then                    \
$MV $BACKUP_DIR/daily.1 $BACKUP_DIR/daily.2 ;   \
fi;


# step 3: make a hard-link-only (except for dirs) copy of the latest snapshot, if that exists
if [ -d $BACKUP_DIR/daily.0 ] ; then                    \
$CP -al $BACKUP_DIR/daily.0 $BACKUP_DIR/daily.1 ;       \
fi;

",Sparctus,https://superuser.com/users/107329,"for i in {7..1};
do
        #echo ""$i""

        if [ -d $BACKUP_DIR/daily.${i} ]
        then
                z=$(($i+1));
                #echo ""$z""
                echo ""moving daily.$i to daily.$z""
                $MV $BACKUP_DIR/daily.$i $BACKUP_DIR/daily.$z ;
        fi;
done

",Sparctus,https://superuser.com/users/107329,http://superuser.com/questions/459658,TECHNOLOGY,superuser.com,1.0,0.6666666666666666,0.0,1.0,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.6666666666666666,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.8,1.0,0.3333333333333333,0.0,0.7777777777777778,Bash - use cycle to improve the efficiency of backup scripts,"I've a backup script (bash). Part of it is shown below. This script does a 14 day rotation of the backup. If I want to change this to say 30 days, I'd have to write out 30 such if-then blocks. I'm sure this could be replaced by a nifty for-loop. What would it be?

# step 1: delete the oldest snapshot, if it exists:
if [ -d $BACKUP_DIR/daily.14 ] ; then                   \
$RM -rf $BACKUP_DIR/daily.14 ;                          \
fi ;

# step 2: shift the middle snapshot(s) back by one, if they exist
if [ -d $BACKUP_DIR/daily.13 ] ; then                   \
$MV $BACKUP_DIR/daily.13 $BACKUP_DIR/daily.14 ; \
fi;

if [ -d $BACKUP_DIR/daily.12 ] ; then                   \
$MV $BACKUP_DIR/daily.12 $BACKUP_DIR/daily.13 ; \
fi;

if [ -d $BACKUP_DIR/daily.11 ] ; then                   \
$MV $BACKUP_DIR/daily.11 $BACKUP_DIR/daily.12 ; \
fi;

if [ -d $BACKUP_DIR/daily.10 ] ; then                   \
$MV $BACKUP_DIR/daily.10 $BACKUP_DIR/daily.11 ; \
fi;

if [ -d $BACKUP_DIR/daily.9 ] ; then                    \
$MV $BACKUP_DIR/daily.9 $BACKUP_DIR/daily.10 ;  \
fi;

if [ -d $BACKUP_DIR/daily.8 ] ; then                    \
$MV $BACKUP_DIR/daily.8 $BACKUP_DIR/daily.9 ;   \
fi;

if [ -d $BACKUP_DIR/daily.7 ] ; then                    \
$MV $BACKUP_DIR/daily.7 $BACKUP_DIR/daily.8 ;   \
fi;

if [ -d $BACKUP_DIR/daily.6 ] ; then                    \
$MV $BACKUP_DIR/daily.6 $BACKUP_DIR/daily.7 ;   \
fi;

if [ -d $BACKUP_DIR/daily.5 ] ; then                    \
$MV $BACKUP_DIR/daily.5 $BACKUP_DIR/daily.6 ;   \
fi;

if [ -d $BACKUP_DIR/daily.4 ] ; then                    \
$MV $BACKUP_DIR/daily.4 $BACKUP_DIR/daily.5 ;   \
fi;

if [ -d $BACKUP_DIR/daily.3 ] ; then                    \
$MV $BACKUP_DIR/daily.3 $BACKUP_DIR/daily.4 ;   \
fi;

if [ -d $BACKUP_DIR/daily.2 ] ; then                    \
$MV $BACKUP_DIR/daily.2 $BACKUP_DIR/daily.3 ;   \
fi;

if [ -d $BACKUP_DIR/daily.1 ] ; then                    \
$MV $BACKUP_DIR/daily.1 $BACKUP_DIR/daily.2 ;   \
fi;


# step 3: make a hard-link-only (except for dirs) copy of the latest snapshot, if that exists
if [ -d $BACKUP_DIR/daily.0 ] ; then                    \
$CP -al $BACKUP_DIR/daily.0 $BACKUP_DIR/daily.1 ;       \
fi;

","for i in {7..1};
do
        #echo ""$i""

        if [ -d $BACKUP_DIR/daily.${i} ]
        then
                z=$(($i+1));
                #echo ""$z""
                echo ""moving daily.$i to daily.$z""
                $MV $BACKUP_DIR/daily.$i $BACKUP_DIR/daily.$z ;
        fi;
done

"
3186,3186,5077,How to restore function attributes to default,"Adding an attribute to a function is easy and clearing attribute is easy also. But I don't know really how to restore the attributes of a function to its defaults. All I do is quit the kernel or close Mathematica and open again.

any idea?

Update

For example :

Log // Attributes
(* {Listable, NumericFunction, Protected} *)

ClearAttributes[Log, Listable]
Log // Attributes
(* {NumericFunction, Protected} *)


Now is there any way to restore the attributes of Log to its defaults other than SetAttributes or quitting Mathematica?

Thanks.
",Algohi,https://mathematica.stackexchange.com/users/13548,"Save defaults before any changes

attrLog = Log // Attributes;

ClearAttributes[Log, Listable]

Log // Attributes



  {NumericFunction, Protected}


Restore defaults

Attributes[Log] = attrLog



  {Listable, NumericFunction, Protected}

",Bob Hanlon,https://mathematica.stackexchange.com/users/9362,http://mathematica.stackexchange.com/questions/60382/how-to-restore-function-attributes-to-default,TECHNOLOGY,mathematica.stackexchange.com,1.0,0.4444444444444444,0.0,1.0,1.0,1.0,0.5555555555555556,0.5555555555555556,0.3333333333333333,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,0.8888888888888888,How to restore function properties to default values,"Adding an attribute to a function is easy and clearing attribute is easy also. But I don't know really how to restore the attributes of a function to its defaults. All I do is quit the kernel or close Mathematica and open again.

any idea?

Update

For example :

Log // Attributes
(* {Listable, NumericFunction, Protected} *)

ClearAttributes[Log, Listable]
Log // Attributes
(* {NumericFunction, Protected} *)


Now is there any way to restore the attributes of Log to its defaults other than SetAttributes or quitting Mathematica?

Thanks.
","Save defaults before any changes

attrLog = Log // Attributes;

ClearAttributes[Log, Listable]

Log // Attributes



  {NumericFunction, Protected}


Restore defaults

Attributes[Log] = attrLog



  {Listable, NumericFunction, Protected}

"
3645,3645,5817,Are there statistics of the more played games?,"Looking the questions of this site, it seems that D&amp;D, in all its versions and variants, is by far the most played game. But that's not quite true in the people I know, so I think the proportions in Europe and USA may be different.

Are there any real statistic about the most played games? I'm specially interested in per-country or at least per continent statistics.

Note: I don't know which tags would be appropriate. I accept suggestions in the form of comments.
",Flamma,https://rpg.stackexchange.com/users/5641,"I don't think there's a great deal of published, general information on this topic.

Among podcast listeners, there's an annual survey that includes what games listeners are playing. Informally, I would assume that RPG podcast listeners probably play a broader range of RPGs than the gaming population as a whole. Jennisodes has a discussion of the survey results.
",okeefe,https://rpg.stackexchange.com/users/307,http://rpg.stackexchange.com/questions/23008/are-there-statistics-of-the-more-played-games,CULTURE,rpg.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.8888888888888888,0.6666666666666666,1.0,0.8888888888888888,0.8666666666666666,0.0,0.0,0.6666666666666666,0.8888888888888888,Do you have more game statistics?,"Looking the questions of this site, it seems that D&amp;D, in all its versions and variants, is by far the most played game. But that's not quite true in the people I know, so I think the proportions in Europe and USA may be different.

Are there any real statistic about the most played games? I'm specially interested in per-country or at least per continent statistics.

Note: I don't know which tags would be appropriate. I accept suggestions in the form of comments.
","I don't think there's a great deal of published, general information on this topic.

Among podcast listeners, there's an annual survey that includes what games listeners are playing. Informally, I would assume that RPG podcast listeners probably play a broader range of RPGs than the gaming population as a whole. Jennisodes has a discussion of the survey results.
"
5861,5861,9281,OCR software for handwritten notes,"I am looking for a way to recognize handwriting of scanned notes (in PDF format).

It doesn't have to be perfect, and it doesn't have to free, but before paying I would like to try it (even with just a single page).

It doesn't necessarily have to be a native Mac OS X application. I would be OK with an online application, or a Unix application to install or compile. In other words, anything that works somewhat decently would be OK.

I am also not necessarily looking for a perfect result. Even transforming my notes into a searchable PDF with just some of the text recognized would be better than nothing.
",Matteo,https://apple.stackexchange.com/users/10888,"I realize that you are looking for a Mac OS application, but for the benefit of readers drawn to this topic by the search for handwriting recognition, I'd like to mention MyScript Memo and Notes Plus on iOS. They share a handwriting recognition engine that seems to work very well in my hands. MyScript memo has a free version that anyone with an iOS device can try.

(I also see that you are looking to recognize handwritten notes scanned from paper, which these apps will not do. They recognize handwritten notes written directly on the iOS device.)
",Ash,https://apple.stackexchange.com/users/19022,http://apple.stackexchange.com/questions/48807/ocr-software-for-handwritten-notes,TECHNOLOGY,apple.stackexchange.com,0.7777777777777778,0.7777777777777778,0.0,1.0,1.0,0.0,0.4444444444444444,0.5555555555555556,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,1.0,0.5555555555555556,0.3333333333333333,0.4444444444444444,0.5555555555555556,0.2,0.0,0.0,0.0,1.0,OCR software for handwritten notes,"I am looking for a way to recognize handwriting of scanned notes (in PDF format).

It doesn't have to be perfect, and it doesn't have to free, but before paying I would like to try it (even with just a single page).

It doesn't necessarily have to be a native Mac OS X application. I would be OK with an online application, or a Unix application to install or compile. In other words, anything that works somewhat decently would be OK.

I am also not necessarily looking for a perfect result. Even transforming my notes into a searchable PDF with just some of the text recognized would be better than nothing.
","I know you are looking for a Mac OS application, but in order for readers to understand this topic by searching for handwriting recognition, I want to mention myscript memo and notes plus on IOS. They share a handwriting recognition engine, which seems to work well in my hands. Myscript memo has a free version that anyone with an IOS device can try."
5594,5594,8880,How do I change the MySQL database directory?,"I am using CentOS with cPanel. On my server, all MySQL databases save at /var/lib/mysql. Now /var is 100% full and MySQL has stopped working. How can I move the databases to a new directory like /home/mysql especially considering that this server is managed with cPanel?
",user111175,https://serverfault.com/users/111175,"I can't confirm this from cpanel, as I don't have access, but this is an example from the console connected by ssh and sudo to root. There are arguments for using a bind entry in /etc/fstab instead of a symlink, but this works for me.

My normal procedure is to stop mysql, move the directory contents, link the original, and restart mysqld. 

[tomh@workstation001 ~]$ sudo su -
[root@workstation001 ~]# 

[root@workstation001 ~]# service mysqld stop
Stopping mysqld (via systemctl):  
                                                           [  OK  ]

[root@workstation001 ~]# mv /var/lib/mysql/ /opt/

[root@workstation001 ~]# ln -s /opt/mysql /var/lib/


[root@workstation001 ~]# ls -la /var/lib/mysql
lrwxrwxrwx 1 root root 10 Feb 26 23:02 /var/lib/mysql -&gt; /opt/mysql

[root@workstation001 ~]# service mysqld start
Starting mysqld (via systemctl):                           [  OK  ]


[root@workstation001 ~]# mysql -uroot 
Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 2
Server version: 5.5.18-log MySQL Community Server (GPL)

mysql&gt; show databases;
...
| Database              |
+-----------------------+
| information_schema    |
| mysql                 |
| performance_schema    |
| test   


I just noticed a similar question, of which this is close to a duplicate of, which mentions some issues of doing that above with selinux enabled;
http://crashmag.net/change-the-default-mysql-data-directory-with-selinux-enabled

So if you have selinux there are some additional steps.
",Tom H,https://serverfault.com/users/47650,http://serverfault.com/questions/363958,TECHNOLOGY,serverfault.com,1.0,0.5555555555555556,0.0,1.0,1.0,1.0,0.5555555555555556,0.5555555555555556,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,0.0,0.8888888888888888,How to change MySQL database directory?,"I'm using CentOS and cPanel. On my server, all MySQL databases are stored in / var / lib / MySQL. Now / var is 100% full and MySQL has stopped working. How to move the database to a new directory (such as / home / MySQL), especially considering that this server is managed by cPanel?","I can't confirm this from cpanel, as I don't have access, but this is an example from the console connected by ssh and sudo to root. There are arguments for using a bind entry in /etc/fstab instead of a symlink, but this works for me.

My normal procedure is to stop mysql, move the directory contents, link the original, and restart mysqld. 

[tomh@workstation001 ~]$ sudo su -
[root@workstation001 ~]# 

[root@workstation001 ~]# service mysqld stop
Stopping mysqld (via systemctl):  
                                                           [  OK  ]

[root@workstation001 ~]# mv /var/lib/mysql/ /opt/

[root@workstation001 ~]# ln -s /opt/mysql /var/lib/


[root@workstation001 ~]# ls -la /var/lib/mysql
lrwxrwxrwx 1 root root 10 Feb 26 23:02 /var/lib/mysql -&gt; /opt/mysql

[root@workstation001 ~]# service mysqld start
Starting mysqld (via systemctl):                           [  OK  ]


[root@workstation001 ~]# mysql -uroot 
Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 2
Server version: 5.5.18-log MySQL Community Server (GPL)

mysql&gt; show databases;
...
| Database              |
+-----------------------+
| information_schema    |
| mysql                 |
| performance_schema    |
| test   


I just noticed a similar question, of which this is close to a duplicate of, which mentions some issues of doing that above with selinux enabled;
http://crashmag.net/change-the-default-mysql-data-directory-with-selinux-enabled

So if you have selinux there are some additional steps.
"
4638,4638,7356,Photoshop/Illustrator: generate vector graphic from bitmap,"
  Possible Duplicate:
  Vectorization graphics approach  




Folks,
Photoshop newbie here with what I think is a simple question, but clearly, I am not searching for the right keywords on Google.

I have a hand-sketched pattern that I have scanned into a (bitmap) image. It is a crisp black and white image. I would like for a way to get Photoshop (or Illustrator) to detect the edges and extract paths from it, thereby converting it into a vector graphic.

Is there a simple way to accomplish this?

Thanks.

-Raj
",user49692,https://superuser.com/users/49692,"Since you're using Illustrator then use the tools built into it for doing exactly what you're doing. But if you don't have / want to use the Adobe software there are several free alternatives:

Potrace is Free (as in FOSS) vectorisation software, these days it comes as a plugin for the free vector graphics package Inkscape

The brilliant commercial / open source vector graphics package Xara is available free for Linux, it has an excellent built-in tracing tool (and it kicks illustrator's 4rse for speed and ease of use)

Other free vectorisation software includes AutoTrace and Deliniate.

Also there's a free web app called vector magic here, they sell a desktop version as well.

-stib
",stib,https://superuser.com/users/26250,http://superuser.com/questions/188330,TECHNOLOGY,superuser.com,0.7777777777777778,0.4444444444444444,0.0,1.0,1.0,0.0,0.5555555555555556,0.4444444444444444,0.6666666666666666,0.0,1.0,0.6666666666666666,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.0,0.0,0.7777777777777778,1.0,0.7777777777777778,1.0,1.0,0.8666666666666666,0.3333333333333333,0.6666666666666666,0.0,1.0,Photoshop / illustrator: generating vector graphics from bitmaps,"
  Possible Duplicate:
  Vectorization graphics approach  




Folks,
Photoshop newbie here with what I think is a simple question, but clearly, I am not searching for the right keywords on Google.

I have a hand-sketched pattern that I have scanned into a (bitmap) image. It is a crisp black and white image. I would like for a way to get Photoshop (or Illustrator) to detect the edges and extract paths from it, thereby converting it into a vector graphic.

Is there a simple way to accomplish this?

Thanks.

-Raj
","Since you're using Illustrator then use the tools built into it for doing exactly what you're doing. But if you don't have / want to use the Adobe software there are several free alternatives:

Potrace is Free (as in FOSS) vectorisation software, these days it comes as a plugin for the free vector graphics package Inkscape

The brilliant commercial / open source vector graphics package Xara is available free for Linux, it has an excellent built-in tracing tool (and it kicks illustrator's 4rse for speed and ease of use)

Other free vectorisation software includes AutoTrace and Deliniate.

Also there's a free web app called vector magic here, they sell a desktop version as well.

-stib
"
3955,3955,6311,What package managers do popular Unix Distributions Use?,"I am creating a Script and I need to know what package manager each Popular Unix Distribution Uses (especially those distros that are commonly-used for Servers)...

I mean:
Debian uses apt-get
Fedora uses yum
",ant0nisk,https://unix.stackexchange.com/users/19942,"I'll comment about the specific *BSD tools:


OpenBSD.
DragonFlyBSD and NetBSD.
FreeBSD.


Warning: the *BSD systems use the same name convention for the tools (pkg_add, pkg_info, etc) but all are completely different. 
",Rufo El Magufo,https://unix.stackexchange.com/users/9316,http://unix.stackexchange.com/questions/40989/what-package-managers-do-popular-unix-distributions-use,TECHNOLOGY,unix.stackexchange.com,1.0,1.0,0.0,1.0,1.0,1.0,0.5,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.5,0.0,0.5,0.0,0.8333333333333334,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,0.0,1.0,What package managers do popular UNIX distributions use?,"I'm creating a script, and I need to know what package managers are used for each popular UNIX distribution (especially those that are commonly used for servers)...","I'll comment about the specific *BSD tools:


OpenBSD.
DragonFlyBSD and NetBSD.
FreeBSD.


Warning: the *BSD systems use the same name convention for the tools (pkg_add, pkg_info, etc) but all are completely different. 
"
765,765,1208,How to extract name/data from database and use it as my folder name which is created dynamically in asp.net c# using server.MapPath()?,"I have used AjaxFileUpload to upload multiple image files. Now i want to store the uploaded images inside rootfolder>subfolder. 

The rootfolder is in the name of the user.
The rootfolder is created dynamically by taking the session of the user who has logged in 
Like this:  

string username = Session[""username""].ToString();


I am able to create this folder and save images in it. but i want to save it in subfolder.

the subfolder is also created dynamically but this time i have to take the value(id) from the database and name the folder by that id name. (this is so that i can refer to the database)

I know how to create a new folder using Server.MapPath();
Here is the code for it in brief

using System.IO
if (Directory.Exists(Server.MapPath(uploadPath))) return;
else Directory.CreateDirectory(Server.MapPath(uploadPath));


where uploadPath is the folder's name i want to create dynamiclly.

but how do I include the subfolder too in my Server.MapPath() so as to make my path as rootfolder/subfolder ?

Small example to make the question understandable.
I am a seller. I have posted 4 ads online.
Now when i am posting my 5th ad i want to include many images. 
these images should be saved in the folder 

Seller/5/imagename.jpg. 
(where Seller is the username(main folder), 5 is the advertID in the database and the name of the subfolder)

How do i do this? Please help.
I am using asp.net c# 
",user2106271,https://stackoverflow.com/users/2106271,"As far as I know, you can't do one statement to create folder and subfolders because you need the folder to be created first.

You have all of the code you need, you just need to repeat it.  Check to see if the main folder (username) exists.  If it doesn't create it, if it does, check to see if the subfolder exists.  If it doesn't, create it. 

Just work through that logic and you'll be set. 
",Dave Mroz,https://stackoverflow.com/users/1102128,http://stackoverflow.com/questions/21164125/how-to-extract-name-data-from-database-and-use-it-as-my-folder-name-which-is-cre,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.6666666666666666,0.0,1.0,1.0,1.0,0.6666666666666666,0.5555555555555556,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.8888888888888888,How to extract the name / data from the database and use it as a folder name created dynamically in ASP. Net C using server. Mappath()?,"I have used AjaxFileUpload to upload multiple image files. Now i want to store the uploaded images inside rootfolder>subfolder. 

The rootfolder is in the name of the user.
The rootfolder is created dynamically by taking the session of the user who has logged in 
Like this:  

string username = Session[""username""].ToString();


I am able to create this folder and save images in it. but i want to save it in subfolder.

the subfolder is also created dynamically but this time i have to take the value(id) from the database and name the folder by that id name. (this is so that i can refer to the database)

I know how to create a new folder using Server.MapPath();
Here is the code for it in brief

using System.IO
if (Directory.Exists(Server.MapPath(uploadPath))) return;
else Directory.CreateDirectory(Server.MapPath(uploadPath));


where uploadPath is the folder's name i want to create dynamiclly.

but how do I include the subfolder too in my Server.MapPath() so as to make my path as rootfolder/subfolder ?

Small example to make the question understandable.
I am a seller. I have posted 4 ads online.
Now when i am posting my 5th ad i want to include many images. 
these images should be saved in the folder 

Seller/5/imagename.jpg. 
(where Seller is the username(main folder), 5 is the advertID in the database and the name of the subfolder)

How do i do this? Please help.
I am using asp.net c# 
","As far as I know, you can't do one statement to create folder and subfolders because you need the folder to be created first.

You have all of the code you need, you just need to repeat it.  Check to see if the main folder (username) exists.  If it doesn't create it, if it does, check to see if the subfolder exists.  If it doesn't, create it. 

Just work through that logic and you'll be set. 
"
4328,4328,6893,jQuery AJAX IE - skipped functions ajax,"$(""#multiselect"").hide();
$(""#multiselect_container"").append('&lt;img id=""loader"" src=""/loader.gif"" /&gt;');


Above 2 functions inside the $(""#list"").click() block are being skipped for some reason in IE, not FF, Chrome

$(""#list"").click(function() 
{           
    var selection = $(this).val();

    $(""#multiselect"").hide();
    $(""#multiselect_container"").append('&lt;img id=""loader"" src=""/loader.gif"" /&gt;');

    $.ajax(
    {
        url: 'include/ajax.php?id='+selection,
        async: false,
        dataType: 'json',
        success: function (json) 
        {       
            $(""#loader"").remove();
            $(""#multiselect"").show();

            //parse json
        } 
    });//json
});


What's going on:

There is a button #list and a container #multiselect_container which holds #multiselect which is a select box of it's container's size.

When #list is clicked, the select box is hidden and the container beneath it is shown, with a loading bar.

When the ajax call is finished the loading bar is removed and the select box is shown again.

In Firefox this works perfectly fine. In IE it does not.

Things that I have tried:


$('#list').ajaxComplete(function() {}); in the success section
Sleeping the php file for 3 seconds. Same results, except with a delay.
Removing the ajax block, those 2 calls are made properly.
caching is not the issue, ajax calls are being made

",lewicki,https://stackoverflow.com/users/255543,"You should change async: false to async: true. With async: false it would be normal behaviour for the display to not be updated until after the ajax call has completed. So that change might be enough to fix it. Otherwise read on...

I've had a similar problem with IE before, where it just didn't want to update the display to show a ""loading"" type message while doing Ajax - even though the Ajax is asynchronous. It's not that the functions themselves are skipped, just that the display doesn't get updated until after the Ajax complete callback had executed too - and since the complete processing removes the ""loading"" message it's as if it never existed from the user's point of view. As with your code, my project worked fine in Firefox. It was a while ago, but if I remember rightly I got it to work in IE by introducing a short timeout on the Ajax call, something like this:

$(""#list"").click(function() 
{           
    var selection = $(this).val();

    $(""#multiselect"").hide();
    $(""#multiselect_container"").append('&lt;img id=""loader"" src=""/loader.gif"" /&gt;');

    setTimeout(function() {
       $.ajax(
       {
           url: 'include/ajax.php?id='+selection,
           async: true,  // changed from false
           dataType: 'json',
           success: function (json) 
           {       
               $(""#loader"").remove();
               $(""#multiselect"").show();

               //parse json
           } 
       });//json
    }, 5);
});

",nnnnnn,https://stackoverflow.com/users/615754,http://stackoverflow.com/questions/10646789/jquery-ajax-ie-skipped-functions-ajax,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.4444444444444444,0.0,1.0,0.6666666666666666,1.0,0.4444444444444444,0.4444444444444444,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.6666666666666666,0.8888888888888888,JQuery Ajax ie - function Ajax skipped,"$(""#multiselect"").hide();
$(""#multiselect_container"").append('&lt;img id=""loader"" src=""/loader.gif"" /&gt;');


Above 2 functions inside the $(""#list"").click() block are being skipped for some reason in IE, not FF, Chrome

$(""#list"").click(function() 
{           
    var selection = $(this).val();

    $(""#multiselect"").hide();
    $(""#multiselect_container"").append('&lt;img id=""loader"" src=""/loader.gif"" /&gt;');

    $.ajax(
    {
        url: 'include/ajax.php?id='+selection,
        async: false,
        dataType: 'json',
        success: function (json) 
        {       
            $(""#loader"").remove();
            $(""#multiselect"").show();

            //parse json
        } 
    });//json
});


What's going on:

There is a button #list and a container #multiselect_container which holds #multiselect which is a select box of it's container's size.

When #list is clicked, the select box is hidden and the container beneath it is shown, with a loading bar.

When the ajax call is finished the loading bar is removed and the select box is shown again.

In Firefox this works perfectly fine. In IE it does not.

Things that I have tried:


$('#list').ajaxComplete(function() {}); in the success section
Sleeping the php file for 3 seconds. Same results, except with a delay.
Removing the ajax block, those 2 calls are made properly.
caching is not the issue, ajax calls are being made

","You should change async: false to async: true. With async: false it would be normal behaviour for the display to not be updated until after the ajax call has completed. So that change might be enough to fix it. Otherwise read on...

I've had a similar problem with IE before, where it just didn't want to update the display to show a ""loading"" type message while doing Ajax - even though the Ajax is asynchronous. It's not that the functions themselves are skipped, just that the display doesn't get updated until after the Ajax complete callback had executed too - and since the complete processing removes the ""loading"" message it's as if it never existed from the user's point of view. As with your code, my project worked fine in Firefox. It was a while ago, but if I remember rightly I got it to work in IE by introducing a short timeout on the Ajax call, something like this:

$(""#list"").click(function() 
{           
    var selection = $(this).val();

    $(""#multiselect"").hide();
    $(""#multiselect_container"").append('&lt;img id=""loader"" src=""/loader.gif"" /&gt;');

    setTimeout(function() {
       $.ajax(
       {
           url: 'include/ajax.php?id='+selection,
           async: true,  // changed from false
           dataType: 'json',
           success: function (json) 
           {       
               $(""#loader"").remove();
               $(""#multiselect"").show();

               //parse json
           } 
       });//json
    }, 5);
});

"
5798,5798,9185,Does becoming martyr have an evolutionary advantage?,"This is related to 
How does &quot;be altruist to those who are similar to you&quot; evolve?

Altruism that is


Not reciprocal
Not familiar


has little explanation. One possible explanation is that the trait itself may correlate well with genetics. One great answer there is that often the cost of altruism is small anyway. It can explain why people vote. Here the expense is small anyway.

Still there seems to be some factors that are even bigger.

Let's take a look at people that die for their ideology. Christian martyrs, Muslim suicide bombers, or Communist guerilla fighters. They seem to get so little and well, die.

And that's pretty common. It seems pretty easy for a leader or pedagogue to rouse men to be soldiers. Of course, becoming a soldier is a pretty shitty job, yet most men don't mind.

These people make a huge sacrifice for the sake of their country, ideology, or people that are not even genetically related to them.

Why?
",J. Chang,https://biology.stackexchange.com/users/554,"There isn an effect called ""Indirect reciprocity"" where individuals just give to everyone they meet without direct requirement of reciprocity.  

This sort of benefit to others is common - hospitality to strangers, general politeness, good customer service all fall along these lines.  You hope they will come back and benefit you again, but maybe they will tell someone else who will know you are a good community member. 

It is only sustainable in a system where the cost/benefit ratio is less than the reputation benefit of the act.  It sounds as if this is only good for public acts but if the benefit is transferred to a social entity that outlasts the individual (like your children, a relative's children, a religion or a corporation say), the result could still hold.  

If you think about typical morality/ethics really it still makes sense to think that what we call altruism must still have a net positive benefit.  If there is no benefit long term or to anyone, it really isn't useful or even good, its random.  What we usually call altruism is usually some sort of reciprocal cooperation.  

A soldier who dies in combat or someone who dies for their beliefs but everyone knows about it as a public statement benefits from their act indirectly.  I don't think its altruism in the pure sense of the word. Defending the nation, ones' beliefs or whatever is, in its sense its own reward.  Veterans come back from a war are hopefully respected for their work.  Having a purple heart can be a good thing to show people.  I'm not saying these people are adequately compensated for what they have been through, but just trying to draw a distinction between pure biological altruism and 'indirect reciprocity'.

Examples of Indirect reciprocity might be the use of tax money to build highways and build power and water infrastructure.  Its important - its the glue that holds a nation or a group together.  If you got punished for doing these things we wouldn't be hanging as a nation very long!

A martyr with no family at all who would benefit would still count as an altruism I think, but most acts of public piety and sacrifice do benefit the individual by reputation. Something to think about. 
",shigeta,https://biology.stackexchange.com/users/3632,http://biology.stackexchange.com/questions/2366/does-becoming-martyr-have-an-evolutionary-advantage,SCIENCE,biology.stackexchange.com,1.0,0.5555555555555556,0.3333333333333333,0.5,0.3333333333333333,0.5,0.6666666666666666,0.7777777777777778,0.3333333333333333,0.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,1.0,Is there an evolutionary advantage to being a martyr?,"This is related to 
How does &quot;be altruist to those who are similar to you&quot; evolve?

Altruism that is


Not reciprocal
Not familiar


has little explanation. One possible explanation is that the trait itself may correlate well with genetics. One great answer there is that often the cost of altruism is small anyway. It can explain why people vote. Here the expense is small anyway.

Still there seems to be some factors that are even bigger.

Let's take a look at people that die for their ideology. Christian martyrs, Muslim suicide bombers, or Communist guerilla fighters. They seem to get so little and well, die.

And that's pretty common. It seems pretty easy for a leader or pedagogue to rouse men to be soldiers. Of course, becoming a soldier is a pretty shitty job, yet most men don't mind.

These people make a huge sacrifice for the sake of their country, ideology, or people that are not even genetically related to them.

Why?
","There isn an effect called ""Indirect reciprocity"" where individuals just give to everyone they meet without direct requirement of reciprocity.  

This sort of benefit to others is common - hospitality to strangers, general politeness, good customer service all fall along these lines.  You hope they will come back and benefit you again, but maybe they will tell someone else who will know you are a good community member. 

It is only sustainable in a system where the cost/benefit ratio is less than the reputation benefit of the act.  It sounds as if this is only good for public acts but if the benefit is transferred to a social entity that outlasts the individual (like your children, a relative's children, a religion or a corporation say), the result could still hold.  

If you think about typical morality/ethics really it still makes sense to think that what we call altruism must still have a net positive benefit.  If there is no benefit long term or to anyone, it really isn't useful or even good, its random.  What we usually call altruism is usually some sort of reciprocal cooperation.  

A soldier who dies in combat or someone who dies for their beliefs but everyone knows about it as a public statement benefits from their act indirectly.  I don't think its altruism in the pure sense of the word. Defending the nation, ones' beliefs or whatever is, in its sense its own reward.  Veterans come back from a war are hopefully respected for their work.  Having a purple heart can be a good thing to show people.  I'm not saying these people are adequately compensated for what they have been through, but just trying to draw a distinction between pure biological altruism and 'indirect reciprocity'.

Examples of Indirect reciprocity might be the use of tax money to build highways and build power and water infrastructure.  Its important - its the glue that holds a nation or a group together.  If you got punished for doing these things we wouldn't be hanging as a nation very long!

A martyr with no family at all who would benefit would still count as an altruism I think, but most acts of public piety and sacrifice do benefit the individual by reputation. Something to think about. 
"
5354,5354,8501,In assasin creed 4 can we fast travel within cities?,"For example, rather than running from places to places, I saw many fast travel icons on the map. Can I fast travel there?

I know I can fast travel to save sailing time. What about if I am not sailing? Why are they so many fast travel icons on one city? If fast travel is only when sailing, then we need only one fast travel icons per city right?

I am using PS4. In world map, I can fast travel with square key. What button I should press if I am within a city. I select a fast travel icon, press square, nothing happen.
",J. Chang,https://gaming.stackexchange.com/users/20631,"Fast travel can be done to any fast travel icon that you have unlocked by synchronizing at. This will then take you to that fast travel icon. If it is in a city it will take you to that point. If you are already in the city you can still use it.
",Chris,https://gaming.stackexchange.com/users/2067,http://gaming.stackexchange.com/questions/165031/in-assasin-creed-4-can-we-fast-travel-within-cities,CULTURE,gaming.stackexchange.com,1.0,0.5555555555555556,0.0,0.3333333333333333,1.0,1.0,0.7777777777777778,0.5555555555555556,0.6666666666666666,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,1.0,0.0,0.6666666666666666,0.8888888888888888,0.4444444444444444,1.0,1.0,0.7333333333333333,0.0,0.6666666666666666,1.0,0.8888888888888888,"In Assad creed 4, can we travel fast in the city?","For example, rather than running from places to places, I saw many fast travel icons on the map. Can I fast travel there?

I know I can fast travel to save sailing time. What about if I am not sailing? Why are they so many fast travel icons on one city? If fast travel is only when sailing, then we need only one fast travel icons per city right?

I am using PS4. In world map, I can fast travel with square key. What button I should press if I am within a city. I select a fast travel icon, press square, nothing happen.
","Quick move can be performed on any quick move icon that you have unlocked in sync on. This will take you to the fast travel icon. If it's in a city, it will take you there. If you're already in town, you can use it."
2441,2441,3896,.xlsx and xls(Latest Versions) to pdf using python,"With the help of this .doc to pdf using python
Link I am trying for excel (.xlsx and xls formats)

Following is modified Code for Excel:

import os
from win32com import client

folder = ""C:\\Oprance\\Excel\\XlsxWriter-0.5.1""
file_type = 'xlsx'
out_folder = folder + ""\\PDF_excel""

os.chdir(folder)

if not os.path.exists(out_folder):
    print 'Creating output folder...'
    os.makedirs(out_folder)
    print out_folder, 'created.'
else:
    print out_folder, 'already exists.\n'

for files in os.listdir("".""):
    if files.endswith("".xlsx""):
        print files

print '\n\n'

word = client.DispatchEx(""Excel.Application"")
for files in os.listdir("".""):
    if files.endswith("".xlsx"") or files.endswith('xls'):
        out_name = files.replace(file_type, r""pdf"")
        in_file = os.path.abspath(folder + ""\\"" + files)
        out_file = os.path.abspath(out_folder + ""\\"" + out_name)
        doc = word.Workbooks.Open(in_file)
        print 'Exporting', out_file
        doc.SaveAs(out_file, FileFormat=56)
        doc.Close()


It is showing following error : 

&gt;&gt;&gt; execfile('excel_to_pdf.py')
Creating output folder...
C:\Excel\XlsxWriter-0.5.1\PDF_excel created.
apms_trial.xlsx
~$apms_trial.xlsx

Exporting C:\Excel\XlsxWriter-0.5.1\PDF_excel\apms_trial.pdf
Traceback (most recent call last):
  File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
  File ""excel_to_pdf.py"", line 30, in &lt;module&gt;
    doc = word.Workbooks.Open(in_file)
  File ""&lt;COMObject &lt;unknown&gt;&gt;"", line 8, in Open
pywintypes.com_error: (-2147352567, 'Exception occurred.', (0, u'Microsoft Excel
', u""Excel cannot open the file '~$apms_trial.xlsx' because the file format or f
ile extension is not valid. Verify that the file has not been corrupted and that
 the file extension matches the format of the file."", u'xlmain11.chm', 0, -21468
27284), None)
&gt;&gt;&gt;


There is problem in

doc.SaveAs(out_file, FileFormat=56)

What should be FileFormat file format?
Please Help
",eegloo,https://stackoverflow.com/users/2621678,"Link of xlsxwriter :

https://xlsxwriter.readthedocs.org/en/latest/contents.html

With the help of this you can generate excel file with .xlsx and .xls

for example excel file generated name is trial.xls

Now if you want to generate pdf of that excel file then do the following :

from win32com import client
xlApp = win32com.client.Dispatch(""Excel.Application"")
books = xlApp.Workbooks.Open('C:\\excel\\trial.xls')
ws = books.Worksheets[0]
ws.Visible = 1
ws.ExportAsFixedFormat(0, 'C:\\excel\\trial.pdf')

",eegloo,https://stackoverflow.com/users/2621678,http://stackoverflow.com/questions/20854840/xlsx-and-xlslatest-versions-to-pdf-using-python,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.5555555555555556,0.0,1.0,1.0,1.0,0.5555555555555556,0.7777777777777778,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,0.7777777777777778,0.4444444444444444,0.7777777777777778,1.0,0.6666666666666667,1.0,0.0,0.0,0.7777777777777778,Convert. Xlsx and XLS (latest version) to PDF using Python,"With the help of this .doc to pdf using python
Link I am trying for excel (.xlsx and xls formats)

Following is modified Code for Excel:

import os
from win32com import client

folder = ""C:\\Oprance\\Excel\\XlsxWriter-0.5.1""
file_type = 'xlsx'
out_folder = folder + ""\\PDF_excel""

os.chdir(folder)

if not os.path.exists(out_folder):
    print 'Creating output folder...'
    os.makedirs(out_folder)
    print out_folder, 'created.'
else:
    print out_folder, 'already exists.\n'

for files in os.listdir("".""):
    if files.endswith("".xlsx""):
        print files

print '\n\n'

word = client.DispatchEx(""Excel.Application"")
for files in os.listdir("".""):
    if files.endswith("".xlsx"") or files.endswith('xls'):
        out_name = files.replace(file_type, r""pdf"")
        in_file = os.path.abspath(folder + ""\\"" + files)
        out_file = os.path.abspath(out_folder + ""\\"" + out_name)
        doc = word.Workbooks.Open(in_file)
        print 'Exporting', out_file
        doc.SaveAs(out_file, FileFormat=56)
        doc.Close()


It is showing following error : 

&gt;&gt;&gt; execfile('excel_to_pdf.py')
Creating output folder...
C:\Excel\XlsxWriter-0.5.1\PDF_excel created.
apms_trial.xlsx
~$apms_trial.xlsx

Exporting C:\Excel\XlsxWriter-0.5.1\PDF_excel\apms_trial.pdf
Traceback (most recent call last):
  File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
  File ""excel_to_pdf.py"", line 30, in &lt;module&gt;
    doc = word.Workbooks.Open(in_file)
  File ""&lt;COMObject &lt;unknown&gt;&gt;"", line 8, in Open
pywintypes.com_error: (-2147352567, 'Exception occurred.', (0, u'Microsoft Excel
', u""Excel cannot open the file '~$apms_trial.xlsx' because the file format or f
ile extension is not valid. Verify that the file has not been corrupted and that
 the file extension matches the format of the file."", u'xlmain11.chm', 0, -21468
27284), None)
&gt;&gt;&gt;


There is problem in

doc.SaveAs(out_file, FileFormat=56)

What should be FileFormat file format?
Please Help
","Link of xlsxwriter :

https://xlsxwriter.readthedocs.org/en/latest/contents.html

With the help of this you can generate excel file with .xlsx and .xls

for example excel file generated name is trial.xls

Now if you want to generate pdf of that excel file then do the following :

from win32com import client
xlApp = win32com.client.Dispatch(""Excel.Application"")
books = xlApp.Workbooks.Open('C:\\excel\\trial.xls')
ws = books.Worksheets[0]
ws.Visible = 1
ws.ExportAsFixedFormat(0, 'C:\\excel\\trial.pdf')

"
2745,2745,4377,Facebook Batch Request recognizing access token as user for page admin,"I am developing an app to post multiple post messages in one time. Say I have 5 fan pages and 10 groups. It will post them all. I have used graph api method and its working well when using for loop and executing one at a time. But I came to know about facebook batch request. Now the problem is when I to fan pages using fan page access token from (https://graph.facebook.com/100000598120816/accounts) its working fine

$param = array( 'message' =&gt; ""Demo test "" , 'access_token' =&gt; ""&lt;fan page access token&gt;"");
try { 
    $posted = $facebook-&gt;api('/425355934226513/feed/', 'post', $param);
    if (strlen($posted[""id""]) &gt; 0 ) $success = TRUE;
} catch  (FacebookApiException $e) {
    $errMsg = $e-&gt;getMessage();
    $error = TRUE;
}


But when I try to do the same using batch request, It post as the USER, not as PAGE ADMIN.

$arr1[] = array(  ""method""=&gt;""POST"", 'relative_url' =&gt; '&lt;fan page id&gt;/feed',""body"" =&gt; ""message=Apps testing..Please ignore this message for page."" , 'access_token' =&gt; ""&lt;FAN PAGE TOKEN&gt;"");
$arr1[] = array(  ""method""=&gt;""POST"", 'relative_url' =&gt; '&lt;my group id&gt;/feed',""body"" =&gt; ""message=Apps testing..Please ignore this message for page."" , 'access_token' =&gt; ""&lt;USER PAGE TOKEN&gt;"");
try { 
    $posted = $facebook-&gt;api(""/?batch="".urlencode(json_encode($arr1)), 'post');
    $success = TRUE;
} catch  (FacebookApiException $e) {
    $errMsg = $e-&gt;getMessage();
    $error = TRUE;

}


P.S Both the above code runs successfully. But in fan page its showing as the USER not PAGE ADMIN.

Thanks in Advance.
",thesoftwareguy,https://stackoverflow.com/users/3149113,"You should try specifying a ""fallback"" Access Token as described in https://developers.facebook.com/docs/graph-api/making-multiple-requests/#differentaccesstokens This Access Token should be an App Access Token.

Also, I'm not sure if you're not overwriting your $arr1[] variable...
",Tobi,https://stackoverflow.com/users/1603357,http://stackoverflow.com/questions/23500962/facebook-batch-request-recognizing-access-token-as-user-for-page-admin,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.5555555555555556,0.0,0.3333333333333333,1.0,0.6666666666666666,0.6666666666666666,0.4444444444444444,0.3333333333333333,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,0.8333333333333334,0.8,1.0,1.0,0.5,0.8333333333333334,Facebook bulk request to identify access token as page management user,"I am developing an app to post multiple post messages in one time. Say I have 5 fan pages and 10 groups. It will post them all. I have used graph api method and its working well when using for loop and executing one at a time. But I came to know about facebook batch request. Now the problem is when I to fan pages using fan page access token from (https://graph.facebook.com/100000598120816/accounts) its working fine

$param = array( 'message' =&gt; ""Demo test "" , 'access_token' =&gt; ""&lt;fan page access token&gt;"");
try { 
    $posted = $facebook-&gt;api('/425355934226513/feed/', 'post', $param);
    if (strlen($posted[""id""]) &gt; 0 ) $success = TRUE;
} catch  (FacebookApiException $e) {
    $errMsg = $e-&gt;getMessage();
    $error = TRUE;
}


But when I try to do the same using batch request, It post as the USER, not as PAGE ADMIN.

$arr1[] = array(  ""method""=&gt;""POST"", 'relative_url' =&gt; '&lt;fan page id&gt;/feed',""body"" =&gt; ""message=Apps testing..Please ignore this message for page."" , 'access_token' =&gt; ""&lt;FAN PAGE TOKEN&gt;"");
$arr1[] = array(  ""method""=&gt;""POST"", 'relative_url' =&gt; '&lt;my group id&gt;/feed',""body"" =&gt; ""message=Apps testing..Please ignore this message for page."" , 'access_token' =&gt; ""&lt;USER PAGE TOKEN&gt;"");
try { 
    $posted = $facebook-&gt;api(""/?batch="".urlencode(json_encode($arr1)), 'post');
    $success = TRUE;
} catch  (FacebookApiException $e) {
    $errMsg = $e-&gt;getMessage();
    $error = TRUE;

}


P.S Both the above code runs successfully. But in fan page its showing as the USER not PAGE ADMIN.

Thanks in Advance.
","You should try specifying a ""fallback"" Access Token as described in https://developers.facebook.com/docs/graph-api/making-multiple-requests/#differentaccesstokens This Access Token should be an App Access Token.

Also, I'm not sure if you're not overwriting your $arr1[] variable...
"
106,106,174,Recover Console Text Output after Using fbi App to display image on /dev/fb0,"I am not using X and I'm using fbi to display an image on the /dev/fb0 framebuffer device. When I boot up my Pi, I see all the usual text and it boots up to where I can log in on the console. After I use fbi like this:

fbi -T 2 -d /dev/fb0 -a myimage.png


My image is displayed and replaces the text.

How do I 'discard' the image painted in fb0 and recover my text session so I can type?
",PhilBot,https://raspberrypi.stackexchange.com/users/10182,"From man fbi:


  COMMAND USAGE
  
  ESQ, q Quit.


I think that should be ""ESC"" -- anyway, lots of informative stuff in the man page.

In case you are unaware, there are 6 virtual terminals (VTs) with log-in prompts created at boot, but only the first one is where init messages appear.  You can access these via CtrlAltF1-6.

Which I think you know since you are using -T 2, making it sort of a strange question...
",goldilocks,https://raspberrypi.stackexchange.com/users/5538,http://raspberrypi.stackexchange.com/questions/28398/recover-console-text-output-after-using-fbi-app-to-display-image-on-dev-fb0,TECHNOLOGY,raspberrypi.stackexchange.com,1.0,0.4444444444444444,0.0,0.6666666666666666,0.3333333333333333,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,0.8888888888888888,0.6666666666666666,1.0,0.8888888888888888,0.8666666666666666,1.0,0.0,0.0,0.8888888888888888,Restore console text output after displaying images on / dev / fb0 using the FBI application,"Instead of using X, I used FBI to display images on the / dev / fb0 framebuffer device. When I launch my PI, I see all the commonly used text that leads to where I can log in on the console. After I used the FBI like this:","From man fbi:


  COMMAND USAGE
  
  ESQ, q Quit.


I think that should be ""ESC"" -- anyway, lots of informative stuff in the man page.

In case you are unaware, there are 6 virtual terminals (VTs) with log-in prompts created at boot, but only the first one is where init messages appear.  You can access these via CtrlAltF1-6.

Which I think you know since you are using -T 2, making it sort of a strange question...
"
3404,3404,5426,"Omnifaces validateMultiple component only takes UIInput values, any workaround for considering UIOutput too?","So, I have an Address to validate and it has 4 input fields and 4 output fields, basically the 4 output fields are city,state,county and municipality. There are not editable, so they will be populated by zipCode lookup only. But when I validate , I need to pass in all the values, the lookup values too.
&lt;o:validateMultiple&gt; only takes in Input Component values, so I tried to make them h:inputText too and then disabled=true since they aren't editable, but looks like &lt;o:validateMultiple&gt; ignores values of disabled input components as well. So, any alternatives?

Initially I did it bu embedding all the ids with respective bindings using f:attributes on the first inputText component and used JSF validator to grab getAttributes and validated that way, which worked OK, but since validateMultiple reduces lot of that, I wanted to use this , but looks like it is not straight forward.

Something like this could have helped :

&lt;o:validateMultiple id=""myId"" components=""foo bar baz"" validator=""#{bean.validateValues}"" /&gt;
    &lt;h:message for=""myId"" /&gt;
    &lt;h:inputText id=""foo"" /&gt;
    &lt;h:inputText id=""bar"" /&gt;
    &lt;h:inputText id=""baz"" /&gt;

public boolean validateValues(FacesContext context, List&lt;UIComponent&gt; components, List&lt;Object&gt; values) {
    // ...
}


Any help is appreciated!
Thanks!
",PavanSandeep,https://stackoverflow.com/users/2030797,"Use &lt;h:inputHidden&gt; if you need hidden inputs.
",BalusC,https://stackoverflow.com/users/157882,http://stackoverflow.com/questions/21741805/omnifaces-validatemultiple-component-only-takes-uiinput-values-any-workaround-f,STACKOVERFLOW,stackoverflow.com,1.0,0.7777777777777778,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.8888888888888888,0.8888888888888888,0.4444444444444444,1.0,0.8888888888888888,0.6,1.0,0.3333333333333333,0.0,1.0,Omnifaces validatemultiple component only accepts uiinput value. Can uioutput also be considered?,"So, I have an Address to validate and it has 4 input fields and 4 output fields, basically the 4 output fields are city,state,county and municipality. There are not editable, so they will be populated by zipCode lookup only. But when I validate , I need to pass in all the values, the lookup values too.
&lt;o:validateMultiple&gt; only takes in Input Component values, so I tried to make them h:inputText too and then disabled=true since they aren't editable, but looks like &lt;o:validateMultiple&gt; ignores values of disabled input components as well. So, any alternatives?

Initially I did it bu embedding all the ids with respective bindings using f:attributes on the first inputText component and used JSF validator to grab getAttributes and validated that way, which worked OK, but since validateMultiple reduces lot of that, I wanted to use this , but looks like it is not straight forward.

Something like this could have helped :

&lt;o:validateMultiple id=""myId"" components=""foo bar baz"" validator=""#{bean.validateValues}"" /&gt;
    &lt;h:message for=""myId"" /&gt;
    &lt;h:inputText id=""foo"" /&gt;
    &lt;h:inputText id=""bar"" /&gt;
    &lt;h:inputText id=""baz"" /&gt;

public boolean validateValues(FacesContext context, List&lt;UIComponent&gt; components, List&lt;Object&gt; values) {
    // ...
}


Any help is appreciated!
Thanks!
","Use &lt;h:inputHidden&gt; if you need hidden inputs.
"
2664,2664,4243,Show Windows 7 logon time?,"On Windows 7 Ultimate, is there a way to see when I logged on into the current session?

I want to find out how long I have been at the PC / when I started it up.
",magnattic,https://superuser.com/users/69189,"I had the same issue for a network PC and this gave me results I was looking for:

wmic netlogin get name, fullname, lastlogon


...this will provide info for all users that have logged in.
",Zachery,https://superuser.com/users/391476,http://superuser.com/questions/310128,TECHNOLOGY,superuser.com,1.0,0.6666666666666666,0.0,1.0,1.0,1.0,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,1.0,0.8888888888888888,0.6666666666666666,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.8888888888888888,Show windows 7 login time?,"On Windows 7 ultimate, is there any way to see when I log in to the current session?","I had the same issue for a network PC and this gave me results I was looking for:

wmic netlogin get name, fullname, lastlogon


...this will provide info for all users that have logged in.
"
5596,5596,8882,Server compromised - How do I find out what is sending mail,"A friend of mine has a few small businesses and hosts Wordpress-based sites for them on a dedicated host. The Wordpress installs were neglected for awhile and the host ended up getting compromised. There's now 100's of spam messages going out every second. What can I look at to determine what's generating the mail?

The only way I can get the spam to stop is to shutdown Postfix. We've had it off for a few days to prevent spamming, but this also means he can't send mail from his businesses addresses.

If I shutdown both apache and postfix, netstat shows no remote connections except my SSH login. If I then start postfix (but leave apache stopped), 100's of remote connections to port 25 immediately open. This leads me to believe that some process on the host is doing this, rather than something coming in through Wordpress/some rogue script that we missed in the clean-up. There were also IRC bots on here, but we've removed those, and netstat no longer shows any open connections to IRC.

When I look at ps axjf - all of the smtp processes roll up to /usr/libexec/postfix/master, which has a parent id of 1. This doesn't really give me an idea of where the mail is being generated.

Neither ps nor top show any suspicious processes (as far as I can tell).

What else can I look at to see what's creating/sending the mail? I can post the output of ps whatever_flags_you_want both with and without postfix running, if it will help.

Thanks.
",pata,https://unix.stackexchange.com/users/103244,"You'll need to wipe out the OS entirely and reinstall. So many things could have been altered.
",Pete Cornell,https://unix.stackexchange.com/users/36378,http://unix.stackexchange.com/questions/185023/server-compromised-how-do-i-find-out-what-is-sending-mail,TECHNOLOGY,unix.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,0.5,1.0,1.0,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.3333333333333333,0.0,0.0,0.7777777777777778,0.6666666666666666,0.4444444444444444,1.0,1.0,0.6,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.8888888888888888,Server compromised - how to find out what to send,"A friend of mine has a few small businesses and hosts Wordpress-based sites for them on a dedicated host. The Wordpress installs were neglected for awhile and the host ended up getting compromised. There's now 100's of spam messages going out every second. What can I look at to determine what's generating the mail?

The only way I can get the spam to stop is to shutdown Postfix. We've had it off for a few days to prevent spamming, but this also means he can't send mail from his businesses addresses.

If I shutdown both apache and postfix, netstat shows no remote connections except my SSH login. If I then start postfix (but leave apache stopped), 100's of remote connections to port 25 immediately open. This leads me to believe that some process on the host is doing this, rather than something coming in through Wordpress/some rogue script that we missed in the clean-up. There were also IRC bots on here, but we've removed those, and netstat no longer shows any open connections to IRC.

When I look at ps axjf - all of the smtp processes roll up to /usr/libexec/postfix/master, which has a parent id of 1. This doesn't really give me an idea of where the mail is being generated.

Neither ps nor top show any suspicious processes (as far as I can tell).

What else can I look at to see what's creating/sending the mail? I can post the output of ps whatever_flags_you_want both with and without postfix running, if it will help.

Thanks.
",You need to clean up the operating system and reinstall it. A lot of things can change.
5656,5656,8968,Should we allow or avoid non-standard pronouns?,"This question brings up an important question:

Do we want to allow or avoid the use of non-standard English such as the words zie and zir as non gender specific pronouns on this site?
",Flimzy,https://meta.christianity.stackexchange.com/users/20,"No.

English has a singular they and it's fine for situations where the gender of a person is unknown. It has a long history of usage, and is very logical compared to you that is also available for both singular and plural usage.

Singular they is a standard way to refer to someone in a gender-neutral way.
",dancek,https://meta.christianity.stackexchange.com/users/60,http://meta.christianity.stackexchange.com/questions/514/should-we-allow-or-avoid-non-standard-pronouns,CULTURE,meta.christianity.stackexchange.com,0.8888888888888888,1.0,1.0,1.0,0.0,0.0,0.5555555555555556,0.7777777777777778,0.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,1.0,0.7777777777777778,1.0,0.8888888888888888,0.8,0.0,0.0,0.6666666666666666,0.8888888888888888,Should we allow or avoid the use of non-standard pronouns?,"This question brings up an important question:

Do we want to allow or avoid the use of non-standard English such as the words zie and zir as non gender specific pronouns on this site?
","No.

English has a singular they and it's fine for situations where the gender of a person is unknown. It has a long history of usage, and is very logical compared to you that is also available for both singular and plural usage.

Singular they is a standard way to refer to someone in a gender-neutral way.
"
3877,3877,6174,Show Windows 7 logon time?,"On Windows 7 Ultimate, is there a way to see when I logged on into the current session?

I want to find out how long I have been at the PC / when I started it up.
",magnattic,https://superuser.com/users/69189,"You can also use

quser


to see the login time.
",Catalyst,https://superuser.com/users/88534,http://superuser.com/questions/310128,TECHNOLOGY,superuser.com,1.0,0.5555555555555556,0.0,1.0,1.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,0.0,0.8888888888888888,0.8888888888888888,0.5555555555555556,1.0,1.0,0.8666666666666666,0.6666666666666666,0.0,0.0,0.7777777777777778,Show windows 7 login time?,"On Windows 7 ultimate, is there any way to see when I log in to the current session?","You can also use

quser


to see the login time.
"
4259,4259,6789,Why did Benjen Stark take the Black?,"OK, I've waited until I finished ADWD in case there was any explanation there.

Why was Benjen Stark on the Wall? Was there an explanation I have missed?

I appreciate, as a younger brother, he would have had less opportunity than Brandon (or Eddard), and may have been looking for adventure or honour, but the Wall, by the time he would have joined, was hardly at the height of its renown.

Joining the Black wouldn't be, I would have thought, a particularly obvious option for Benjen, if he was simply looking for a title or a role in life to fit the name of Stark.
",johnc,https://scifi.stackexchange.com/users/34,"There was no direct answer in anything I've read either. But the Starks have always taken the Wall more seriously than the other Great Houses. They are, after all, close enough to the Wall that Wildling raids are a real threat. And I suspect Stark sons were under more pressure (socially) to join up if they had no other prospects.
",System Down,https://scifi.stackexchange.com/users/887,http://scifi.stackexchange.com/questions/5895/why-did-benjen-stark-take-the-black,LIFE_ARTS,scifi.stackexchange.com,1.0,1.0,0.5,0.5,0.5,1.0,0.8333333333333334,0.6666666666666666,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.6666666666666666,0.5,1.0,1.0,0.5,0.0,0.0,1.0,1.0,Why is Benyon stark taking the black one?,"OK, I've waited until I finished ADWD in case there was any explanation there.

Why was Benjen Stark on the Wall? Was there an explanation I have missed?

I appreciate, as a younger brother, he would have had less opportunity than Brandon (or Eddard), and may have been looking for adventure or honour, but the Wall, by the time he would have joined, was hardly at the height of its renown.

Joining the Black wouldn't be, I would have thought, a particularly obvious option for Benjen, if he was simply looking for a title or a role in life to fit the name of Stark.
","There is no direct answer to anything I have read. But the stark always valued the great wall more than any other big house. After all, they are close to the wall, and violent attacks are the real threat. I suspect Stark's sons will be under more pressure (in society) to join if they have no other future."
4140,4140,6605,HowTo: Add Class to Sidebar Widget List-Items,"The newest version of Bootstrap (v3.0) adds a new List Group component which has the following structure:

&lt;ul class=""list-group""&gt;
  &lt;li class=""list-group-item""&gt;Cras justo odio&lt;/li&gt;
  &lt;li class=""list-group-item""&gt;Dapibus ac facilisis in&lt;/li&gt;
  &lt;li class=""list-group-item""&gt;Morbi leo risus&lt;/li&gt;
  &lt;li class=""list-group-item""&gt;Porta ac consectetur ac&lt;/li&gt;
  &lt;li class=""list-group-item""&gt;Vestibulum at eros&lt;/li&gt;
&lt;/ul&gt;



I would like to be able to add a class to the ul (i.e. &lt;ul class=""list-group""&gt;)
I would like to style my Category sidebar widget to support this new component, but as you see, this requires classes on each li item.


In reading some similar posts, one option I found is to use jQuery to add the class to each li, but I am concerned about the dreaded FOUC. 

Is there some WordPress function that gets me to my goal?

Please advise,

Update: 

I was able to add classes to the individual li's by creating a Custom Walker which extends Walker_Category (see code below), but this still does not get me to the ul which also needs a class added (eg &lt;ul class=""list-group""&gt;). 

class Walker_Category_BS extends Walker_Category {
    function start_el( &amp;$output, $category, $depth = 0, $args = array() ) {
        extract($args);

        $cat_name = esc_attr( $category-&gt;name );
        $cat_name = apply_filters( 'list_cats', $cat_name, $category );
        $link = '&lt;a href=""' . esc_url( get_term_link($category) ) . '"" ';
        if ( $use_desc_for_title == 0 || empty($category-&gt;description) )
            $link .= 'title=""' . esc_attr( sprintf(__( 'View all posts filed under %s' ), $cat_name) ) . '""';
        else
            $link .= 'title=""' . esc_attr( strip_tags( apply_filters( 'category_description', $category-&gt;description, $category ) ) ) . '""';
        $link .= '&gt;';
        $link .= $cat_name . '&lt;/a&gt;';

        if ( !empty($feed_image) || !empty($feed) ) {
            $link .= ' ';

            if ( empty($feed_image) )
                $link .= '(';

            $link .= '&lt;a href=""' . esc_url( get_term_feed_link( $category-&gt;term_id, $category-&gt;taxonomy, $feed_type ) ) . '""';

            if ( empty($feed) ) {
                $alt = ' alt=""' . sprintf(__( 'Feed for all posts filed under %s' ), $cat_name ) . '""';
            } else {
                $title = ' title=""' . $feed . '""';
                $alt = ' alt=""' . $feed . '""';
                $name = $feed;
                $link .= $title;
            }

            $link .= '&gt;';

            if ( empty($feed_image) )
                $link .= $name;
            else
                $link .= ""&lt;img src='$feed_image'$alt$title"" . ' /&gt;';

            $link .= '&lt;/a&gt;';

            if ( empty($feed_image) )
                $link .= ')';
        }

        if ( !empty($show_count) )
            $link .= ' (' . intval($category-&gt;count) . ')';

        if ( 'list' == $args['style'] ) {
            $output .= ""\t&lt;li"";
            $class = 'list-group-item cat-item cat-item-' . $category-&gt;term_id;
            if ( !empty($current_category) ) {
                $_current_category = get_term( $current_category, $category-&gt;taxonomy );
                if ( $category-&gt;term_id == $current_category )
                    $class .=  ' current-cat';
                elseif ( $category-&gt;term_id == $_current_category-&gt;parent )
                    $class .=  ' current-cat-parent';
            }
            $output .=  ' class=""' . $class . '""';
            $output .= ""&gt;$link\n"";
        } else {
            $output .= ""\t$link&lt;br /&gt;\n"";
        }
    } /* end start_el */

} /* end Walker_Category_BS */


Update 02: 

After viewing default-widgets.php in the core, I decided to create a new widget (WP_Widget_Categories_BS, see code below) wherein I basically, copied all the code from the default category widget and simply modified the the UL to add the necessary class. 

&lt;?php 

/**
 * Categories widget class
 *
 * @since 2.8.0
 */
class WP_Widget_Categories_BS extends WP_Widget {

    function __construct() {
        $widget_ops = array( 'classname' =&gt; 'widget_categories_bs', 'description' =&gt; __( ""A list or dropdown of categories for Bootstrap 3.0"" ) );
        parent::__construct('categories', __('Boostrap Categories'), $widget_ops);
    }

    function widget( $args, $instance ) {
        extract( $args );

        $title = apply_filters('widget_title', empty( $instance['title'] ) ? __( 'Categories' ) : $instance['title'], $instance, $this-&gt;id_base);
        $c = ! empty( $instance['count'] ) ? '1' : '0';
        $h = ! empty( $instance['hierarchical'] ) ? '1' : '0';
        $d = ! empty( $instance['dropdown'] ) ? '1' : '0';

        echo $before_widget;
        if ( $title )
            echo $before_title . $title . $after_title;

        $cat_args = array('orderby' =&gt; 'name', 'show_count' =&gt; $c, 'hierarchical' =&gt; $h);
        if ( $d ) {
            $cat_args['show_option_none'] = __('Select Category');
            wp_dropdown_categories(apply_filters('widget_categories_dropdown_args', $cat_args));
?&gt;

&lt;script type='text/javascript'&gt;
/* &lt;![CDATA[ */
    var dropdown = document.getElementById(""cat"");
    function onCatChange() {
        if ( dropdown.options[dropdown.selectedIndex].value &gt; 0 ) {
            location.href = ""&lt;?php echo home_url(); ?&gt;/?cat=""+dropdown.options[dropdown.selectedIndex].value;
        }
    }
    dropdown.onchange = onCatChange;
/* ]]&gt; */
&lt;/script&gt;

&lt;?php
        } else {
?&gt;
        &lt;ul class=""list-group""&gt;
&lt;?php
        $cat_args['title_li'] = '';
        wp_list_categories(apply_filters('widget_categories_args', $cat_args));
?&gt;
        &lt;/ul&gt;
&lt;?php
        }

        echo $after_widget;
    }

    function update( $new_instance, $old_instance ) {
        $instance = $old_instance;
        $instance['title'] = strip_tags($new_instance['title']);
        $instance['count'] = !empty($new_instance['count']) ? 1 : 0;
        $instance['hierarchical'] = !empty($new_instance['hierarchical']) ? 1 : 0;
        $instance['dropdown'] = !empty($new_instance['dropdown']) ? 1 : 0;

        return $instance;
    }

    function form( $instance ) {
        //Defaults
        $instance = wp_parse_args( (array) $instance, array( 'title' =&gt; '') );
        $title = esc_attr( $instance['title'] );
        $count = isset($instance['count']) ? (bool) $instance['count'] :false;
        $hierarchical = isset( $instance['hierarchical'] ) ? (bool) $instance['hierarchical'] : false;
        $dropdown = isset( $instance['dropdown'] ) ? (bool) $instance['dropdown'] : false;
?&gt;
        &lt;p&gt;&lt;label for=""&lt;?php echo $this-&gt;get_field_id('title'); ?&gt;""&gt;&lt;?php _e( 'Title:' ); ?&gt;&lt;/label&gt;
        &lt;input class=""widefat"" id=""&lt;?php echo $this-&gt;get_field_id('title'); ?&gt;"" name=""&lt;?php echo $this-&gt;get_field_name('title'); ?&gt;"" type=""text"" value=""&lt;?php echo $title; ?&gt;"" /&gt;&lt;/p&gt;

        &lt;p&gt;&lt;input type=""checkbox"" class=""checkbox"" id=""&lt;?php echo $this-&gt;get_field_id('dropdown'); ?&gt;"" name=""&lt;?php echo $this-&gt;get_field_name('dropdown'); ?&gt;""&lt;?php checked( $dropdown ); ?&gt; /&gt;
        &lt;label for=""&lt;?php echo $this-&gt;get_field_id('dropdown'); ?&gt;""&gt;&lt;?php _e( 'Display as dropdown' ); ?&gt;&lt;/label&gt;&lt;br /&gt;

        &lt;input type=""checkbox"" class=""checkbox"" id=""&lt;?php echo $this-&gt;get_field_id('count'); ?&gt;"" name=""&lt;?php echo $this-&gt;get_field_name('count'); ?&gt;""&lt;?php checked( $count ); ?&gt; /&gt;
        &lt;label for=""&lt;?php echo $this-&gt;get_field_id('count'); ?&gt;""&gt;&lt;?php _e( 'Show post counts' ); ?&gt;&lt;/label&gt;&lt;br /&gt;

        &lt;input type=""checkbox"" class=""checkbox"" id=""&lt;?php echo $this-&gt;get_field_id('hierarchical'); ?&gt;"" name=""&lt;?php echo $this-&gt;get_field_name('hierarchical'); ?&gt;""&lt;?php checked( $hierarchical ); ?&gt; /&gt;
        &lt;label for=""&lt;?php echo $this-&gt;get_field_id('hierarchical'); ?&gt;""&gt;&lt;?php _e( 'Show hierarchy' ); ?&gt;&lt;/label&gt;&lt;/p&gt;
&lt;?php
    }

} // end WP_Widget_Categories_BS


Combined with a Custom Walker I created (Walker_Category_BS) I now have what I wanted. 

Analysis

Is this the best way to do it? Don't know as I have have received zero feedback so far, and this is the first time i've done this (hence the question), but ...it works! I could use a review.

Debug Warning

Concerning my Custom Category Walker Walker_Category_BS, i'm seeing this message


  ""Strict standards: Declaration of Walker_Category_BS::start_el() should be compatible with Walker::start_el(&amp;$output, $object, $depth = 0, $args = Array, $current_object_id = 0) in C:\wamp\www\mysite\wp-content\themes\mytheme\assets\inc\Walker_Category_BS.php""


It appears to be a warning, of some sort.
",sleeper,https://wordpress.stackexchange.com/users/12116,"Update: I fixed the debug warning and everything appears to be working. In the absence of any other comments, I will accept my own solution outlined in the original questions updates.
",sleeper,https://wordpress.stackexchange.com/users/12116,http://wordpress.stackexchange.com/questions/113233/howto-add-class-to-sidebar-widget-list-items,TECHNOLOGY,wordpress.stackexchange.com,1.0,0.6666666666666666,0.0,0.6666666666666666,0.3333333333333333,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,1.0,0.6666666666666666,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.7777777777777778,0.7777777777777778,0.5555555555555556,1.0,1.0,0.7333333333333333,0.5,0.0,0.5,0.8888888888888888,How to: add a class to a sidebar widget list item,"The newest version of Bootstrap (v3.0) adds a new List Group component which has the following structure:

&lt;ul class=""list-group""&gt;
  &lt;li class=""list-group-item""&gt;Cras justo odio&lt;/li&gt;
  &lt;li class=""list-group-item""&gt;Dapibus ac facilisis in&lt;/li&gt;
  &lt;li class=""list-group-item""&gt;Morbi leo risus&lt;/li&gt;
  &lt;li class=""list-group-item""&gt;Porta ac consectetur ac&lt;/li&gt;
  &lt;li class=""list-group-item""&gt;Vestibulum at eros&lt;/li&gt;
&lt;/ul&gt;



I would like to be able to add a class to the ul (i.e. &lt;ul class=""list-group""&gt;)
I would like to style my Category sidebar widget to support this new component, but as you see, this requires classes on each li item.


In reading some similar posts, one option I found is to use jQuery to add the class to each li, but I am concerned about the dreaded FOUC. 

Is there some WordPress function that gets me to my goal?

Please advise,

Update: 

I was able to add classes to the individual li's by creating a Custom Walker which extends Walker_Category (see code below), but this still does not get me to the ul which also needs a class added (eg &lt;ul class=""list-group""&gt;). 

class Walker_Category_BS extends Walker_Category {
    function start_el( &amp;$output, $category, $depth = 0, $args = array() ) {
        extract($args);

        $cat_name = esc_attr( $category-&gt;name );
        $cat_name = apply_filters( 'list_cats', $cat_name, $category );
        $link = '&lt;a href=""' . esc_url( get_term_link($category) ) . '"" ';
        if ( $use_desc_for_title == 0 || empty($category-&gt;description) )
            $link .= 'title=""' . esc_attr( sprintf(__( 'View all posts filed under %s' ), $cat_name) ) . '""';
        else
            $link .= 'title=""' . esc_attr( strip_tags( apply_filters( 'category_description', $category-&gt;description, $category ) ) ) . '""';
        $link .= '&gt;';
        $link .= $cat_name . '&lt;/a&gt;';

        if ( !empty($feed_image) || !empty($feed) ) {
            $link .= ' ';

            if ( empty($feed_image) )
                $link .= '(';

            $link .= '&lt;a href=""' . esc_url( get_term_feed_link( $category-&gt;term_id, $category-&gt;taxonomy, $feed_type ) ) . '""';

            if ( empty($feed) ) {
                $alt = ' alt=""' . sprintf(__( 'Feed for all posts filed under %s' ), $cat_name ) . '""';
            } else {
                $title = ' title=""' . $feed . '""';
                $alt = ' alt=""' . $feed . '""';
                $name = $feed;
                $link .= $title;
            }

            $link .= '&gt;';

            if ( empty($feed_image) )
                $link .= $name;
            else
                $link .= ""&lt;img src='$feed_image'$alt$title"" . ' /&gt;';

            $link .= '&lt;/a&gt;';

            if ( empty($feed_image) )
                $link .= ')';
        }

        if ( !empty($show_count) )
            $link .= ' (' . intval($category-&gt;count) . ')';

        if ( 'list' == $args['style'] ) {
            $output .= ""\t&lt;li"";
            $class = 'list-group-item cat-item cat-item-' . $category-&gt;term_id;
            if ( !empty($current_category) ) {
                $_current_category = get_term( $current_category, $category-&gt;taxonomy );
                if ( $category-&gt;term_id == $current_category )
                    $class .=  ' current-cat';
                elseif ( $category-&gt;term_id == $_current_category-&gt;parent )
                    $class .=  ' current-cat-parent';
            }
            $output .=  ' class=""' . $class . '""';
            $output .= ""&gt;$link\n"";
        } else {
            $output .= ""\t$link&lt;br /&gt;\n"";
        }
    } /* end start_el */

} /* end Walker_Category_BS */


Update 02: 

After viewing default-widgets.php in the core, I decided to create a new widget (WP_Widget_Categories_BS, see code below) wherein I basically, copied all the code from the default category widget and simply modified the the UL to add the necessary class. 

&lt;?php 

/**
 * Categories widget class
 *
 * @since 2.8.0
 */
class WP_Widget_Categories_BS extends WP_Widget {

    function __construct() {
        $widget_ops = array( 'classname' =&gt; 'widget_categories_bs', 'description' =&gt; __( ""A list or dropdown of categories for Bootstrap 3.0"" ) );
        parent::__construct('categories', __('Boostrap Categories'), $widget_ops);
    }

    function widget( $args, $instance ) {
        extract( $args );

        $title = apply_filters('widget_title', empty( $instance['title'] ) ? __( 'Categories' ) : $instance['title'], $instance, $this-&gt;id_base);
        $c = ! empty( $instance['count'] ) ? '1' : '0';
        $h = ! empty( $instance['hierarchical'] ) ? '1' : '0';
        $d = ! empty( $instance['dropdown'] ) ? '1' : '0';

        echo $before_widget;
        if ( $title )
            echo $before_title . $title . $after_title;

        $cat_args = array('orderby' =&gt; 'name', 'show_count' =&gt; $c, 'hierarchical' =&gt; $h);
        if ( $d ) {
            $cat_args['show_option_none'] = __('Select Category');
            wp_dropdown_categories(apply_filters('widget_categories_dropdown_args', $cat_args));
?&gt;

&lt;script type='text/javascript'&gt;
/* &lt;![CDATA[ */
    var dropdown = document.getElementById(""cat"");
    function onCatChange() {
        if ( dropdown.options[dropdown.selectedIndex].value &gt; 0 ) {
            location.href = ""&lt;?php echo home_url(); ?&gt;/?cat=""+dropdown.options[dropdown.selectedIndex].value;
        }
    }
    dropdown.onchange = onCatChange;
/* ]]&gt; */
&lt;/script&gt;

&lt;?php
        } else {
?&gt;
        &lt;ul class=""list-group""&gt;
&lt;?php
        $cat_args['title_li'] = '';
        wp_list_categories(apply_filters('widget_categories_args', $cat_args));
?&gt;
        &lt;/ul&gt;
&lt;?php
        }

        echo $after_widget;
    }

    function update( $new_instance, $old_instance ) {
        $instance = $old_instance;
        $instance['title'] = strip_tags($new_instance['title']);
        $instance['count'] = !empty($new_instance['count']) ? 1 : 0;
        $instance['hierarchical'] = !empty($new_instance['hierarchical']) ? 1 : 0;
        $instance['dropdown'] = !empty($new_instance['dropdown']) ? 1 : 0;

        return $instance;
    }

    function form( $instance ) {
        //Defaults
        $instance = wp_parse_args( (array) $instance, array( 'title' =&gt; '') );
        $title = esc_attr( $instance['title'] );
        $count = isset($instance['count']) ? (bool) $instance['count'] :false;
        $hierarchical = isset( $instance['hierarchical'] ) ? (bool) $instance['hierarchical'] : false;
        $dropdown = isset( $instance['dropdown'] ) ? (bool) $instance['dropdown'] : false;
?&gt;
        &lt;p&gt;&lt;label for=""&lt;?php echo $this-&gt;get_field_id('title'); ?&gt;""&gt;&lt;?php _e( 'Title:' ); ?&gt;&lt;/label&gt;
        &lt;input class=""widefat"" id=""&lt;?php echo $this-&gt;get_field_id('title'); ?&gt;"" name=""&lt;?php echo $this-&gt;get_field_name('title'); ?&gt;"" type=""text"" value=""&lt;?php echo $title; ?&gt;"" /&gt;&lt;/p&gt;

        &lt;p&gt;&lt;input type=""checkbox"" class=""checkbox"" id=""&lt;?php echo $this-&gt;get_field_id('dropdown'); ?&gt;"" name=""&lt;?php echo $this-&gt;get_field_name('dropdown'); ?&gt;""&lt;?php checked( $dropdown ); ?&gt; /&gt;
        &lt;label for=""&lt;?php echo $this-&gt;get_field_id('dropdown'); ?&gt;""&gt;&lt;?php _e( 'Display as dropdown' ); ?&gt;&lt;/label&gt;&lt;br /&gt;

        &lt;input type=""checkbox"" class=""checkbox"" id=""&lt;?php echo $this-&gt;get_field_id('count'); ?&gt;"" name=""&lt;?php echo $this-&gt;get_field_name('count'); ?&gt;""&lt;?php checked( $count ); ?&gt; /&gt;
        &lt;label for=""&lt;?php echo $this-&gt;get_field_id('count'); ?&gt;""&gt;&lt;?php _e( 'Show post counts' ); ?&gt;&lt;/label&gt;&lt;br /&gt;

        &lt;input type=""checkbox"" class=""checkbox"" id=""&lt;?php echo $this-&gt;get_field_id('hierarchical'); ?&gt;"" name=""&lt;?php echo $this-&gt;get_field_name('hierarchical'); ?&gt;""&lt;?php checked( $hierarchical ); ?&gt; /&gt;
        &lt;label for=""&lt;?php echo $this-&gt;get_field_id('hierarchical'); ?&gt;""&gt;&lt;?php _e( 'Show hierarchy' ); ?&gt;&lt;/label&gt;&lt;/p&gt;
&lt;?php
    }

} // end WP_Widget_Categories_BS


Combined with a Custom Walker I created (Walker_Category_BS) I now have what I wanted. 

Analysis

Is this the best way to do it? Don't know as I have have received zero feedback so far, and this is the first time i've done this (hence the question), but ...it works! I could use a review.

Debug Warning

Concerning my Custom Category Walker Walker_Category_BS, i'm seeing this message


  ""Strict standards: Declaration of Walker_Category_BS::start_el() should be compatible with Walker::start_el(&amp;$output, $object, $depth = 0, $args = Array, $current_object_id = 0) in C:\wamp\www\mysite\wp-content\themes\mytheme\assets\inc\Walker_Category_BS.php""


It appears to be a warning, of some sort.
","Update: I fixed the debug warning, everything seems to be OK. In the absence of any other comments, I will accept my own solution outlined in the original issue update."
1614,1614,2532,User @include url Precedence over Script @include url,"I don't like scripts that use: 

// @include http://*


they overload many pages, where we didn't want to, also because I had problems in past, while writing a script, console was full of errors produced by scripts of this kind. I recognize scripts like these ones anti-adblock , noPicAds are on my required list, but in order to use them I change the includes to the specific page I use. Let's suppose, I entered on a webpage and it says: ""You need to disable Adblock"" so I grab the url, go manually and edit the anti-adblock script adding 

// @include http://example.com/*


refresh the page and it's working.
Now when the scripts update, everything is lost. No I don't want to stop updating, because I think these kind of scripts are essentially needed to stay updated. 

My question is, there's anyway to keep include changes after update?
",Comentarist,https://stackoverflow.com/users/805070,"I was told and verified that with scriptish extension it is possible to solve.
This topic.

I hope the greasemonkey developers implement this.
So the best answer so far would be, migrate to scriptish and use the check box that disables script include patterns. Unfortunately, I've already experimented scriptish in past and didn't familiarize.

While greasemonkey doesn't has a solution, I'm going to use both, scriptish only for the scripts with @include http://*
",Comentarist,https://stackoverflow.com/users/805070,http://stackoverflow.com/questions/25170485/user-include-url-precedence-over-script-include-url,STACKOVERFLOW,stackoverflow.com,1.0,0.4444444444444444,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.0,0.0,0.7777777777777778,User @ include URL takes precedence over script @ include URL,"I don't like scripts that use: 

// @include http://*


they overload many pages, where we didn't want to, also because I had problems in past, while writing a script, console was full of errors produced by scripts of this kind. I recognize scripts like these ones anti-adblock , noPicAds are on my required list, but in order to use them I change the includes to the specific page I use. Let's suppose, I entered on a webpage and it says: ""You need to disable Adblock"" so I grab the url, go manually and edit the anti-adblock script adding 

// @include http://example.com/*


refresh the page and it's working.
Now when the scripts update, everything is lost. No I don't want to stop updating, because I think these kind of scripts are essentially needed to stay updated. 

My question is, there's anyway to keep include changes after update?
","I was told and verified that with scriptish extension it is possible to solve.
This topic.

I hope the greasemonkey developers implement this.
So the best answer so far would be, migrate to scriptish and use the check box that disables script include patterns. Unfortunately, I've already experimented scriptish in past and didn't familiarize.

While greasemonkey doesn't has a solution, I'm going to use both, scriptish only for the scripts with @include http://*
"
1234,1234,1933,Laws of addition of Vectors,"How Triangle Law and
Parallelogram law of addition of
Vectors are different?Ain't they.

Please don't tell me the things
written in book......give me the
appropriate reason.And how do i distinguish between the two while adding vectors,what am i trying to say is i get really confused where to use parallelogram law and where triangle law

P.s:my basics are really weak though!May be the question might not be right
",Uzair,https://physics.stackexchange.com/users/36559,"
  How Triangle Law**and **Parallelogram law of addition of Vectors are different?Ain't they.


They are not different.

They are the same thing. There is only one real law which is the head to tail rule. When adding any number vectors put head to tail, head to tail, head to tail... until all the vectors are used up and then draw a line from the tail to the head and that is your resultant vector.

The parallelogram law is essentially just using the triangle law twice in a different order, and they both get the same answer because order does not matter I.E. $\vec A+ \vec B = \vec B + \vec A$.

Here shows the addition of three vectors, the ""triangle"" rule has been used twice in a row to get $\vec A+ \vec B + \vec C = \vec R$. If yo tried to use the parallelogram to get this answer the resulting diagram would be a mess of repeatedly writing the same vector and over.
",user288447,https://physics.stackexchange.com/users/37070,http://physics.stackexchange.com/questions/100027/laws-of-addition-of-vectors,SCIENCE,physics.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,0.3333333333333333,1.0,1.0,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,0.8888888888888888,Law of vector addition,"How Triangle Law and
Parallelogram law of addition of
Vectors are different?Ain't they.

Please don't tell me the things
written in book......give me the
appropriate reason.And how do i distinguish between the two while adding vectors,what am i trying to say is i get really confused where to use parallelogram law and where triangle law

P.s:my basics are really weak though!May be the question might not be right
","
  How Triangle Law**and **Parallelogram law of addition of Vectors are different?Ain't they.


They are not different.

They are the same thing. There is only one real law which is the head to tail rule. When adding any number vectors put head to tail, head to tail, head to tail... until all the vectors are used up and then draw a line from the tail to the head and that is your resultant vector.

The parallelogram law is essentially just using the triangle law twice in a different order, and they both get the same answer because order does not matter I.E. $\vec A+ \vec B = \vec B + \vec A$.

Here shows the addition of three vectors, the ""triangle"" rule has been used twice in a row to get $\vec A+ \vec B + \vec C = \vec R$. If yo tried to use the parallelogram to get this answer the resulting diagram would be a mess of repeatedly writing the same vector and over.
"
4196,4196,6690,UNIX semaphores,"I wrote an example program about UNIX semaphores, where a process and its child lock/unlock the same semaphore. I would appreciate your feedback about what I could improve in my C style. Generally I feel that the program flow is hard to read because of all those error checks, but I didn't find a better way to write it. It's also breaking the rule of ""one vertical screen maximum per function"" but I don't see a logical way to split it into functions.

#include &lt;semaphore.h&gt;
#include &lt;stdio.h&gt;
#include &lt;errno.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;unistd.h&gt;
#include &lt;sys/types.h&gt;
#include &lt;sys/stat.h&gt;
#include &lt;fcntl.h&gt;
#include &lt;sys/mman.h&gt;

int main(void)
{ 
  /* place semaphore in shared memory */
  sem_t *sema = mmap(NULL, sizeof(sema), 
          PROT_READ |PROT_WRITE,MAP_SHARED|MAP_ANONYMOUS, -1, 0);
  if (!sema) {
    perror(""Out of memory"");
    exit(EXIT_FAILURE);
  }

  /* create, initialize semaphore */
  if (sem_init(sema, 1, 0) &lt; 0) {
    perror(""semaphore initilization"");
    exit(EXIT_FAILURE);
  }

  int i, nloop=10;
  int ret = fork();
  if (ret &lt; 0) {
    perror(""fork failed"");
    exit(EXIT_FAILURE);
  }

  if (ret == 0) { 
    /* child process*/
    for (i = 0; i &lt; nloop; i++) {
      printf(""child unlocks semaphore: %d\n"", i);
      sem_post(sema);
      sleep(1);
    }
    if (munmap(sema, sizeof(sema)) &lt; 0) {
      perror(""munmap failed"");
      exit(EXIT_FAILURE);
    }
    exit(EXIT_SUCCESS);
  }

  if (ret &gt; 0) {
    /* back to parent process */
    for (i = 0; i &lt; nloop; i++) {
      printf(""parent starts waiting: %d\n"", i);
      sem_wait(sema);
      printf(""parent finished waiting: %d\n"", i);
    }
    if (sem_destroy(sema) &lt; 0) {
      perror(""sem_destroy failed"");
      exit(EXIT_FAILURE);
    }
    if (munmap(sema, sizeof(sema)) &lt; 0) {
      perror(""munmap failed"");
      exit(EXIT_FAILURE);
    }
    exit(EXIT_SUCCESS);
  }
}

",Étienne,https://codereview.stackexchange.com/users/25742,"
main() must always return an int. return 0 at the end of your function.
The consensus is that, when possible, return instead of exit.
You could make a helper function that accepts a bool (from stdbool.h) and a const char *, and if the bool is false then perror and exit(EXIT_FAILURE) are called.

",Reinderien,https://codereview.stackexchange.com/users/25834,http://codereview.stackexchange.com/questions/27000/unix-semaphores,TECHNOLOGY,codereview.stackexchange.com,0.8888888888888888,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.5555555555555556,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.7333333333333333,0.3333333333333333,0.0,0.3333333333333333,1.0,UNIX semaphore,"I wrote an example program about UNIX semaphores, where a process and its child lock/unlock the same semaphore. I would appreciate your feedback about what I could improve in my C style. Generally I feel that the program flow is hard to read because of all those error checks, but I didn't find a better way to write it. It's also breaking the rule of ""one vertical screen maximum per function"" but I don't see a logical way to split it into functions.

#include &lt;semaphore.h&gt;
#include &lt;stdio.h&gt;
#include &lt;errno.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;unistd.h&gt;
#include &lt;sys/types.h&gt;
#include &lt;sys/stat.h&gt;
#include &lt;fcntl.h&gt;
#include &lt;sys/mman.h&gt;

int main(void)
{ 
  /* place semaphore in shared memory */
  sem_t *sema = mmap(NULL, sizeof(sema), 
          PROT_READ |PROT_WRITE,MAP_SHARED|MAP_ANONYMOUS, -1, 0);
  if (!sema) {
    perror(""Out of memory"");
    exit(EXIT_FAILURE);
  }

  /* create, initialize semaphore */
  if (sem_init(sema, 1, 0) &lt; 0) {
    perror(""semaphore initilization"");
    exit(EXIT_FAILURE);
  }

  int i, nloop=10;
  int ret = fork();
  if (ret &lt; 0) {
    perror(""fork failed"");
    exit(EXIT_FAILURE);
  }

  if (ret == 0) { 
    /* child process*/
    for (i = 0; i &lt; nloop; i++) {
      printf(""child unlocks semaphore: %d\n"", i);
      sem_post(sema);
      sleep(1);
    }
    if (munmap(sema, sizeof(sema)) &lt; 0) {
      perror(""munmap failed"");
      exit(EXIT_FAILURE);
    }
    exit(EXIT_SUCCESS);
  }

  if (ret &gt; 0) {
    /* back to parent process */
    for (i = 0; i &lt; nloop; i++) {
      printf(""parent starts waiting: %d\n"", i);
      sem_wait(sema);
      printf(""parent finished waiting: %d\n"", i);
    }
    if (sem_destroy(sema) &lt; 0) {
      perror(""sem_destroy failed"");
      exit(EXIT_FAILURE);
    }
    if (munmap(sema, sizeof(sema)) &lt; 0) {
      perror(""munmap failed"");
      exit(EXIT_FAILURE);
    }
    exit(EXIT_SUCCESS);
  }
}

","
main() must always return an int. return 0 at the end of your function.
The consensus is that, when possible, return instead of exit.
You could make a helper function that accepts a bool (from stdbool.h) and a const char *, and if the bool is false then perror and exit(EXIT_FAILURE) are called.

"
5684,5684,9012,"""going to"" vs ""will""","I know several questions were asked about the difference between ""going to"" and ""will"".
Based on several answers (see, for instance, here, here and here), I understood that ""will"" is more spontaneous and ""going to"" is used with more planned actions.

So, it seems that everything is pretty fine. However, in this question, Kosmonaut has an answer in which he states:
""Let's say that tomorrow you will walk your dog from 7 - 8 AM"".

On the one hand, you probably planned to walk your dog long before and thus I should use ""Let's say that tomorrow you're going to walk your dog from 7 - 8 am"". 

On the other hand, since I'm saying ""let's say..."", I'm deciding right now (thus, unplanned) that you will walk your dog. So, even though in this hypothetical situation you made a plan, I'm in a more spontaneous mood deciding right now that that's what you will do tomorrow, and, thus, I should use ""will"".

Which one (if any) of the above explanations is right?
",Manoel Galdino,https://english.stackexchange.com/users/21109,"In most contexts, I am going to [verb] and I will [verb] are interchangeable. Sometimes the former may place more emphasis on the fact of your current intention/expectation, where the latter emphasises the future action.

There are some contexts where the difference is clear, and this may have some bearing on why OP thinks there's a planned/spontaneous distinction (usually there isn't). Say you're round a friend's house watching a football match on TV, and at half-time the beer runs out...


  You: ""I'll nip down the shop and get some more beer.""
  
  Friend: ""It's raining - I'll find my umbrella for you.""


If you reply ""Don't bother - I'm going to use my car"", the implication is you had already decided you were going to use the car before you first said you'd get the beer. But if you say ""Don't bother - I will use my car"", this implies you just made that decision in response to what your friend said.

@Peter Shor mentions another context (""It's going to/It will bite!"") where native speakers often make a distinction. In that case, going to usually signifies immediate danger (it's just about to bite), but will can just mean it's bitten others before, and will/may bite you soon if you're not careful (effectively, the same as ""Careful! It bites!"" where present tense indicates ""habitual"" action).



Kosmonaut's ""Let's say that tomorrow you will walk your dog"" isn't really relevant to the current issue. It could just as well have been ""...tomorrow you are going to walk..."" or even just ""...tomorrow you walk..."". They all mean the same, and in that context there's no real reason to prefer one over another.
",FumbleFingers,https://english.stackexchange.com/users/2637,http://english.stackexchange.com/questions/87900/going-to-vs-will,CULTURE,english.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,0.0,1.0,0.0,0.6666666666666666,0.7777777777777778,0.6666666666666666,0.0,0.0,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.5555555555555556,1.0,0.8888888888888888,1.0,1.0,0.7333333333333333,0.0,0.0,0.3333333333333333,0.7777777777777778,"Go to ""vs"" will","I know several questions were asked about the difference between ""going to"" and ""will"".
Based on several answers (see, for instance, here, here and here), I understood that ""will"" is more spontaneous and ""going to"" is used with more planned actions.

So, it seems that everything is pretty fine. However, in this question, Kosmonaut has an answer in which he states:
""Let's say that tomorrow you will walk your dog from 7 - 8 AM"".

On the one hand, you probably planned to walk your dog long before and thus I should use ""Let's say that tomorrow you're going to walk your dog from 7 - 8 am"". 

On the other hand, since I'm saying ""let's say..."", I'm deciding right now (thus, unplanned) that you will walk your dog. So, even though in this hypothetical situation you made a plan, I'm in a more spontaneous mood deciding right now that that's what you will do tomorrow, and, thus, I should use ""will"".

Which one (if any) of the above explanations is right?
","In most contexts, I am going to [verb] and I will [verb] are interchangeable. Sometimes the former may place more emphasis on the fact of your current intention/expectation, where the latter emphasises the future action.

There are some contexts where the difference is clear, and this may have some bearing on why OP thinks there's a planned/spontaneous distinction (usually there isn't). Say you're round a friend's house watching a football match on TV, and at half-time the beer runs out...


  You: ""I'll nip down the shop and get some more beer.""
  
  Friend: ""It's raining - I'll find my umbrella for you.""


If you reply ""Don't bother - I'm going to use my car"", the implication is you had already decided you were going to use the car before you first said you'd get the beer. But if you say ""Don't bother - I will use my car"", this implies you just made that decision in response to what your friend said.

@Peter Shor mentions another context (""It's going to/It will bite!"") where native speakers often make a distinction. In that case, going to usually signifies immediate danger (it's just about to bite), but will can just mean it's bitten others before, and will/may bite you soon if you're not careful (effectively, the same as ""Careful! It bites!"" where present tense indicates ""habitual"" action).



Kosmonaut's ""Let's say that tomorrow you will walk your dog"" isn't really relevant to the current issue. It could just as well have been ""...tomorrow you are going to walk..."" or even just ""...tomorrow you walk..."". They all mean the same, and in that context there's no real reason to prefer one over another.
"
5041,5041,8023,Can I use a shock pump to inflate a tube?,"I know that shock pumps are meant for high pressure applications so that they can withstand high pressures needed by suspension shocks. 

However, can I use a shock pump to inflate my tire in a pinch if I run out of CO2?  How would it compare to a standard mini-pump in terms of volume? 
",Benzo,https://bicycles.stackexchange.com/users/2997,"Note: this calculation makes many assumptions, so it's only useful in an 'average use case', not some sort of exact measurement. If you find better information, please post it and I'll update the answer.

How many pumps you would need to fill up a tire depends on many variables. First, the volume of your inner tube, which can be approximated as a torus (doughnut-shape) atop the rim size of a given diameter. You can find yours approximated on this graph.


26"" Mountain Bike, 2.1"" tire width = 4.8L
29"" Mountain Bike, 2.1"" tire width = 5.2L
700C Road Bike, 35mm tire width = 2L
20"" BMX Bike, 1.85"" tire width = 3L


I'm finding pump specifications quite difficult to find (I need piston diameter and stroke length), but here's a comparison of some shock pumps on an empty shock cylinder of a 2007 Fox 36 RLC 160mm Fork.


Average Accu-Gage Pressure Reading after 100 strokes: 77.2 psi
My best guess at RC2 air chamber specifications: 1"" (25.4mm) diameter, 160mm length (max travel). If someone can find accurate specs or the true volume, I'd appreciate it.
Fox RC2 Air Volume (estimated): Vcylinder = pi*r^2*h = 81 mL


So then, IF pumping air into different volumes is linearly proportional (it's not, but somewhere in the ball park), and you wanted to inflate the tires listed above to ~77.2psi, it'd take about this number of pumps with the 'average' shock pump:

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Tire Volume&nbsp;Ratio of Tire to Air Shock&nbsp;&nbsp;Number of Pumps to ~77.2 psi&nbsp;&nbsp;&nbsp;
26"" Mountain Bike, 2.1"" tire width&nbsp;4.8L&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;59:1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;5,900&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
29"" Mountain Bike, 2.1"" tire width&nbsp;5.2L&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;64:1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;6,400&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
700C Road Bike, 35mm tire width&nbsp;2L&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;25:1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2,500&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
20"" BMX Bike, 1.85"" tire width&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3L&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;37:1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3,700&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;

So, perhaps if it was a life or death situation, you have a lot of time on your hands, or you just can't afford that gym membership, you might want to pump a few thousand times to fill your tire. You probably don't.

By contrast, if you're just looking for this functionality in one device, you could just use a dual purpose model, such as this Specialized Pump, that can inflate both high pressure, low volume containers (like your shock) and low pressure, high volume containers (like your tire).



You twist the handle to select between uses, and save yourself a few thousand pumps.
",Ehryk,https://bicycles.stackexchange.com/users/3777,http://bicycles.stackexchange.com/questions/14643/can-i-use-a-shock-pump-to-inflate-a-tube,CULTURE,bicycles.stackexchange.com,1.0,0.4444444444444444,0.0,0.3333333333333333,1.0,1.0,0.8888888888888888,0.8888888888888888,1.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,0.0,0.0,0.6666666666666666,0.0,0.3333333333333333,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,1.0,Can I inflate the pipe with an impact pump?,"I know that shock pumps are meant for high pressure applications so that they can withstand high pressures needed by suspension shocks. 

However, can I use a shock pump to inflate my tire in a pinch if I run out of CO2?  How would it compare to a standard mini-pump in terms of volume? 
","Note: this calculation makes many assumptions, so it's only useful in an 'average use case', not some sort of exact measurement. If you find better information, please post it and I'll update the answer.

How many pumps you would need to fill up a tire depends on many variables. First, the volume of your inner tube, which can be approximated as a torus (doughnut-shape) atop the rim size of a given diameter. You can find yours approximated on this graph.


26"" Mountain Bike, 2.1"" tire width = 4.8L
29"" Mountain Bike, 2.1"" tire width = 5.2L
700C Road Bike, 35mm tire width = 2L
20"" BMX Bike, 1.85"" tire width = 3L


I'm finding pump specifications quite difficult to find (I need piston diameter and stroke length), but here's a comparison of some shock pumps on an empty shock cylinder of a 2007 Fox 36 RLC 160mm Fork.


Average Accu-Gage Pressure Reading after 100 strokes: 77.2 psi
My best guess at RC2 air chamber specifications: 1"" (25.4mm) diameter, 160mm length (max travel). If someone can find accurate specs or the true volume, I'd appreciate it.
Fox RC2 Air Volume (estimated): Vcylinder = pi*r^2*h = 81 mL


So then, IF pumping air into different volumes is linearly proportional (it's not, but somewhere in the ball park), and you wanted to inflate the tires listed above to ~77.2psi, it'd take about this number of pumps with the 'average' shock pump:

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Tire Volume&nbsp;Ratio of Tire to Air Shock&nbsp;&nbsp;Number of Pumps to ~77.2 psi&nbsp;&nbsp;&nbsp;
26"" Mountain Bike, 2.1"" tire width&nbsp;4.8L&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;59:1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;5,900&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
29"" Mountain Bike, 2.1"" tire width&nbsp;5.2L&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;64:1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;6,400&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
700C Road Bike, 35mm tire width&nbsp;2L&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;25:1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2,500&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
20"" BMX Bike, 1.85"" tire width&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3L&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;37:1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3,700&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;

So, perhaps if it was a life or death situation, you have a lot of time on your hands, or you just can't afford that gym membership, you might want to pump a few thousand times to fill your tire. You probably don't.

By contrast, if you're just looking for this functionality in one device, you could just use a dual purpose model, such as this Specialized Pump, that can inflate both high pressure, low volume containers (like your shock) and low pressure, high volume containers (like your tire).



You twist the handle to select between uses, and save yourself a few thousand pumps.
"
4093,4093,6529,Where did Kagami Taiga live when he lived in the US?,"We see a flashback to when Kagami lived in the US in episode 1 of season 2 (26Q). 



Judging from all the palm trees, I'd hazard a guess that he was probably in California. California also seems like the most likely option on a demographic basis (i.e. where are Japanese temporary immigrants most likely to end up?).

Is it ever explicitly stated where he lived? And if it is California, is it ever stated whether he's in SoCal or NorCal (or somewhere else)?
",senshin,https://anime.stackexchange.com/users/1908,"It was explicitly stated in the manga by Seirin's coach in Chap 112. He used to live in LA.
Note this page may spoil events that have yet to come in the Anime


   

",krikara,https://anime.stackexchange.com/users/2178,http://anime.stackexchange.com/questions/5417/where-did-kagami-taiga-live-when-he-lived-in-the-us,CULTURE,anime.stackexchange.com,1.0,0.7777777777777778,0.0,0.6666666666666666,1.0,0.3333333333333333,0.7777777777777778,0.6666666666666666,0.6666666666666666,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,0.0,1.0,Where did Kagame taga live when he was in America?,"We see a flashback to when Kagami lived in the US in episode 1 of season 2 (26Q). 



Judging from all the palm trees, I'd hazard a guess that he was probably in California. California also seems like the most likely option on a demographic basis (i.e. where are Japanese temporary immigrants most likely to end up?).

Is it ever explicitly stated where he lived? And if it is California, is it ever stated whether he's in SoCal or NorCal (or somewhere else)?
","It was explicitly stated in the manga by Seirin's coach in Chap 112. He used to live in LA.
Note this page may spoil events that have yet to come in the Anime


   

"
1813,1813,2876,"GIN/GiST Full Text searches through openlayers, geoserver and postgres","I have a a web app that automatically maps recent tweets and allows you to search for certain keywords. it uses Postgres for the database, geoserver as the server, and openlayers as the cartographic library. Right now tweet keywords are done using the ILIKE query.

This works pretty well if the keyword i'm looking for is a commonly used word, like 'love' , 'friend', 'OMG', etc. but less common words like ""geospatial"" need to search through a lot more data in order to find the last n instances of the word. This is dead slow.

To combat my slowness I'm building a GIN index on my tweet field in postgres. Two days later and i'm still waiting for the index to complete. Once it's built though, I'll try a few queries using SQL view parameters and hopefully this will dramatically speed things up.

Even if this approach works though, it's not going to be all that useful if the index takes so long to create -- the maintenance of it will not be able to keep up will the incoming flood of data. I think I will try out the GiST index next and see how long it takes as I understand it is much faster to this build index. 

Beyond this, what can I do next? Do options like Solr work with Geoserver?? Are there any common approaches to this type of problem and data size/rate?
",mikedotonline,https://gis.stackexchange.com/users/24616,"It sounds like you could do it with with Solr. However, I would use ElasticSearch its easier to get started with. Since you are working with points it seems like a good fit. 

You would use it standalone as a datasource to Openlayers, it doesn't act act as a ""store"" to geoserver.
",user23747,https://gis.stackexchange.com/users/23747,http://gis.stackexchange.com/questions/82627/gin-gist-full-text-searches-through-openlayers-geoserver-and-postgres,TECHNOLOGY,gis.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.3333333333333333,1.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.3333333333333333,1.0,"Gin / gist full text search openlayers, GeoServer and Postgres","I have a a web app that automatically maps recent tweets and allows you to search for certain keywords. it uses Postgres for the database, geoserver as the server, and openlayers as the cartographic library. Right now tweet keywords are done using the ILIKE query.

This works pretty well if the keyword i'm looking for is a commonly used word, like 'love' , 'friend', 'OMG', etc. but less common words like ""geospatial"" need to search through a lot more data in order to find the last n instances of the word. This is dead slow.

To combat my slowness I'm building a GIN index on my tweet field in postgres. Two days later and i'm still waiting for the index to complete. Once it's built though, I'll try a few queries using SQL view parameters and hopefully this will dramatically speed things up.

Even if this approach works though, it's not going to be all that useful if the index takes so long to create -- the maintenance of it will not be able to keep up will the incoming flood of data. I think I will try out the GiST index next and see how long it takes as I understand it is much faster to this build index. 

Beyond this, what can I do next? Do options like Solr work with Geoserver?? Are there any common approaches to this type of problem and data size/rate?
","It sounds like you could do it with with Solr. However, I would use ElasticSearch its easier to get started with. Since you are working with points it seems like a good fit. 

You would use it standalone as a datasource to Openlayers, it doesn't act act as a ""store"" to geoserver.
"
4531,4531,7182,Why did DC Comics change The Daily Star to The Daily Planet?,"When Superman first appeared in comics he worked for The Daily Star (first refereed to in Action Comics #7, Dec 1938 ).  Then in the 1940s that all changed, without any in-story explanation and  during a multi-issue story line, the paper had suddenly become The Daily Planet.



According to Wikipedia: 


  the fictional newspaper's name was changed to avoid a name conflict
  with actual papers that had ""Star"" in their titles.




This explanation seems a little... lame (for lack of a better word), especially as Superman co-creator Joe Shuster named the Daily Star after his hometown's Toronto Daily Star which he related to be 'a great influence on his life.'



Does anyone know anything further about this change, perhaps gleamed from a biography or other historical text on comics in general or Superman in specific?
",22nd Century Fza,https://scifi.stackexchange.com/users/17795,"Henry Mietkiewicz, the last person to interview Joe Schuster described the reason for the change as being ""on orders from a New York editor"".

Because there's no direct quote from Schuster he may have simply been speculating (e.g. as opposed to having been told) but I see no reason to assume that that's the case.



Prior to 1940, the newspaper was named the Daily Star. Siegel and Schuster had recently pitched the new and improved comic strip (shortly to be made into a nationally broadcast radio show) to the McClure Syndicate, who then resold the cartoon strip to hundreds of newspapers nationally.

Although the radio show's first episode accidentally described the newspaper as ""The Daily Flash"" this was hastily retconned by the second episode and on the day after the radio show was launched, the newpaper strip, comic books and radio show all changed to ""the Daily Planet"". 

In 1940 there were over 20 newspapers across the US named ""The Daily Star"" so in order to avoid the suggestion that Superman worked for an existing newspaper (or because of the connections with the very recently bankrupted ""New York Star"") it made sense for them to rename it.

As to the identity of the fabled ""New York Editor"", my guess would be that it was alleged Fascist Agent(!) and Owner / Editor-in-Chief of the McClure Syndicate, Richard H Waldo.

Before:


After:


",Valorum,https://scifi.stackexchange.com/users/20774,http://scifi.stackexchange.com/questions/49432/why-did-dc-comics-change-the-daily-star-to-the-daily-planet,LIFE_ARTS,scifi.stackexchange.com,1.0,1.0,0.0,0.3333333333333333,1.0,0.3333333333333333,0.8888888888888888,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,1.0,Why did DC Comics turn Daily Star into daily star?,"When Superman first appeared in comics he worked for The Daily Star (first refereed to in Action Comics #7, Dec 1938 ).  Then in the 1940s that all changed, without any in-story explanation and  during a multi-issue story line, the paper had suddenly become The Daily Planet.



According to Wikipedia: 


  the fictional newspaper's name was changed to avoid a name conflict
  with actual papers that had ""Star"" in their titles.




This explanation seems a little... lame (for lack of a better word), especially as Superman co-creator Joe Shuster named the Daily Star after his hometown's Toronto Daily Star which he related to be 'a great influence on his life.'



Does anyone know anything further about this change, perhaps gleamed from a biography or other historical text on comics in general or Superman in specific?
","Henry Mietkiewicz, the last person to interview Joe Schuster described the reason for the change as being ""on orders from a New York editor"".

Because there's no direct quote from Schuster he may have simply been speculating (e.g. as opposed to having been told) but I see no reason to assume that that's the case.



Prior to 1940, the newspaper was named the Daily Star. Siegel and Schuster had recently pitched the new and improved comic strip (shortly to be made into a nationally broadcast radio show) to the McClure Syndicate, who then resold the cartoon strip to hundreds of newspapers nationally.

Although the radio show's first episode accidentally described the newspaper as ""The Daily Flash"" this was hastily retconned by the second episode and on the day after the radio show was launched, the newpaper strip, comic books and radio show all changed to ""the Daily Planet"". 

In 1940 there were over 20 newspapers across the US named ""The Daily Star"" so in order to avoid the suggestion that Superman worked for an existing newspaper (or because of the connections with the very recently bankrupted ""New York Star"") it made sense for them to rename it.

As to the identity of the fabled ""New York Editor"", my guess would be that it was alleged Fascist Agent(!) and Owner / Editor-in-Chief of the McClure Syndicate, Richard H Waldo.

Before:


After:


"
5618,5618,8911,How does an embryo know where to grow limbs etc,"For example you have a cell or already a bunch of cells. Those cell(s) divide and after several week you have a grown organism, for example a human with limbs, several different organs etc. 
However, how do cells know where up, down, left, right etc. is?
I know left and right can be defined clearly in physics. However how do cells define those directions and what are mechanisms for them to grow into a certain direction? 
Is there a paper or a longer article dealing with that question/problem?

I don't think my knowledge on Biology goes far beyond high school level maybe 1. term at a university. If I have to, I would read and learn everything I need to know to understand the matter. 
",Imago,https://biology.stackexchange.com/users/9370,"I wanted to add some helpful references. The 6th edition of the Gilbert Developmental Biology textbook is available on NCBI bookshelf. It's a bit old (2000), but much of the information is still relevant. You can search this textbook for specific terms but not browse.

There is also a collaborative science/fashion project between the Storey sisters, called Primitive Streak, which documents the early stages of human development.

For any given developmental process, there are a number of genes being activated and/or inactivated at that stage that determine how and when structures grow. Events can determine axes too; for instance, the dorsal/ventral axis of the embryo is determine by how the embryo blastocyst implants in the uterine wall. The left-right axis of the body is determined by the direction that fluid travels through a structure called the node, which is directed by hair-like structures called cilia. If nodal flow is backwards, your internal organs will switch sides, called situs inversus.

Back to the limb example... in tetrapods, or animals with 4 limbs, the area where limbs emerge is based on Hox gene expression, and whether or not it will become a forelimb (arms) or hindlimb (legs) is determined by either Tbx5 or Tbx4 gene expression, respectively.

The proximal-distal axis (proximal = towards the trunk; distal = away from the trunk) is determined by FGF gene expression, which induces formation of a structure called the apical ectodermal ridge (AER).

The anterior-posterior axis (head to tail) is determined by Sonic hedgehog gene expression in a region called the zone of polarizing activity (ZPA).

The dorsal-ventral axis (back-front; or back of the hand/arm - palm/inside of arm) is determined by the Wnt7a gene being expressed on the dorsal side.

The outgrowth of the limb is determined by Hox gene expression.

Digit (finger) formation is dependent on cell death between the fingers - hands start webbed, kind of like ducks, and then genes such as the BMPs cause cells between the fingers to die.

Terms to look up for more detail, since I don't have enough street cred here to post more than 2 links yet:


Snapshot Summary: The Tetrapod Limb (Gilbert book)
apical ectodermal ridge (AER)
zone of polarizing activity (ZPA)
situs inversus
Hox genes

",ehutchins,https://biology.stackexchange.com/users/10518,http://biology.stackexchange.com/questions/21881/how-does-an-embryo-know-where-to-grow-limbs-etc,SCIENCE,biology.stackexchange.com,1.0,0.6666666666666666,0.0,0.0,1.0,1.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.3333333333333333,1.0,0.0,0.8888888888888888,1.0,0.7777777777777778,1.0,1.0,1.0,0.0,0.3333333333333333,1.0,1.0,"How do embryos know where to grow limbs, etc","For example you have a cell or already a bunch of cells. Those cell(s) divide and after several week you have a grown organism, for example a human with limbs, several different organs etc. 
However, how do cells know where up, down, left, right etc. is?
I know left and right can be defined clearly in physics. However how do cells define those directions and what are mechanisms for them to grow into a certain direction? 
Is there a paper or a longer article dealing with that question/problem?

I don't think my knowledge on Biology goes far beyond high school level maybe 1. term at a university. If I have to, I would read and learn everything I need to know to understand the matter. 
","I wanted to add some helpful references. The 6th edition of the Gilbert Developmental Biology textbook is available on NCBI bookshelf. It's a bit old (2000), but much of the information is still relevant. You can search this textbook for specific terms but not browse.

There is also a collaborative science/fashion project between the Storey sisters, called Primitive Streak, which documents the early stages of human development.

For any given developmental process, there are a number of genes being activated and/or inactivated at that stage that determine how and when structures grow. Events can determine axes too; for instance, the dorsal/ventral axis of the embryo is determine by how the embryo blastocyst implants in the uterine wall. The left-right axis of the body is determined by the direction that fluid travels through a structure called the node, which is directed by hair-like structures called cilia. If nodal flow is backwards, your internal organs will switch sides, called situs inversus.

Back to the limb example... in tetrapods, or animals with 4 limbs, the area where limbs emerge is based on Hox gene expression, and whether or not it will become a forelimb (arms) or hindlimb (legs) is determined by either Tbx5 or Tbx4 gene expression, respectively.

The proximal-distal axis (proximal = towards the trunk; distal = away from the trunk) is determined by FGF gene expression, which induces formation of a structure called the apical ectodermal ridge (AER).

The anterior-posterior axis (head to tail) is determined by Sonic hedgehog gene expression in a region called the zone of polarizing activity (ZPA).

The dorsal-ventral axis (back-front; or back of the hand/arm - palm/inside of arm) is determined by the Wnt7a gene being expressed on the dorsal side.

The outgrowth of the limb is determined by Hox gene expression.

Digit (finger) formation is dependent on cell death between the fingers - hands start webbed, kind of like ducks, and then genes such as the BMPs cause cells between the fingers to die.

Terms to look up for more detail, since I don't have enough street cred here to post more than 2 links yet:


Snapshot Summary: The Tetrapod Limb (Gilbert book)
apical ectodermal ridge (AER)
zone of polarizing activity (ZPA)
situs inversus
Hox genes

"
2328,2328,3711,Can Noether's theorem be understood intuitively?,"Noether's theorem is one of those surprisingly clear results of mathematical calculations, for which I am inclined to think that some kind of intuitive understanding should or must be possible. However I don't know of any, do you?

Independence of time &lt;=> energy conservation.
Independence of position &lt;=> momentum conservation.
Independence of direction &lt;=> angular momentum conservation.  

I know that the mathematics leads in the direction of Lie-algebra and such but I would like to discuss whether this theorem can be understood from a non-mathematical point of view also.
",Gerard,https://physics.stackexchange.com/users/139,"Here are my two cents. Read the proof it will help you understand and build intuition because it is constructive. It explicitly shows you what the conserved quantity is, given the group of symmetries. If it is too hard to follow and you can't see the forest because of the trees, try a few examples it should help. Also here is a link that may help a bit.

http://math.ucr.edu/home/baez/noether.html
",MBN,https://physics.stackexchange.com/users/1382,http://physics.stackexchange.com/questions/4959/can-noethers-theorem-be-understood-intuitively,SCIENCE,physics.stackexchange.com,1.0,0.6666666666666666,0.0,1.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.3333333333333333,1.0,1.0,1.0,0.0,0.0,0.0,1.0,Can we understand the Noether's theorem intuitively?,"Noether's theorem is one of those surprisingly clear results of mathematical calculations, for which I am inclined to think that some kind of intuitive understanding should or must be possible. However I don't know of any, do you?

Independence of time &lt;=> energy conservation.
Independence of position &lt;=> momentum conservation.
Independence of direction &lt;=> angular momentum conservation.  

I know that the mathematics leads in the direction of Lie-algebra and such but I would like to discuss whether this theorem can be understood from a non-mathematical point of view also.
","Here are my two cents. Read the proof it will help you understand and build intuition because it is constructive. It explicitly shows you what the conserved quantity is, given the group of symmetries. If it is too hard to follow and you can't see the forest because of the trees, try a few examples it should help. Also here is a link that may help a bit.

http://math.ucr.edu/home/baez/noether.html
"
1836,1836,2914,How does an embryo know where to grow limbs etc,"For example you have a cell or already a bunch of cells. Those cell(s) divide and after several week you have a grown organism, for example a human with limbs, several different organs etc. 
However, how do cells know where up, down, left, right etc. is?
I know left and right can be defined clearly in physics. However how do cells define those directions and what are mechanisms for them to grow into a certain direction? 
Is there a paper or a longer article dealing with that question/problem?

I don't think my knowledge on Biology goes far beyond high school level maybe 1. term at a university. If I have to, I would read and learn everything I need to know to understand the matter. 
",Imago,https://biology.stackexchange.com/users/9370,"Embryonic cells ""know"" where they are relative to each other by chemical signals, same as in adults. These molecules are known as morphogens (specific examples include the sonic hedgehog and β-catenin). The amount of morphogen in a region of cells determines which gene gets turned on and thus what it develops into. And the amount varies by how far they are from the source of the morphogen. Though AFAIK, scientists don't fully understand their mechanisms yet (like how they are dispersed, how the different concentrations are kept rigidly, etc.).

As for arms, etc., the earliest cells are unspecialized (stem cells). They ""define"" which becomes what early on by how they are arranged. Remember that their ""up, down, left, and right"" is relative to them, not to their surroundings. The first multicellular hollow ball of stem cells, the blastula, separates into distinct germ layers during gastrulation - the ectoderm, mesoderm, endoderm. Each of these layers develop into something different upon further division. What develops after that is basically a worm, composed of a series of repeating ""segments"" (somites) with a distinct head and tail area. Somites are initially undifferentiated. The job of determining which segment becomes what falls on Hox genes. So that for example, one segment becomes the head, another becomes the arm and pectoral girdle, another becomes a rib+vertebra, etc. Hox genes are arranged in clusters within the DNA relative to which gets expressed first. The first hox gene is for the head for example, while the last is for the tip of the tail (the tipmost segment of the coccyx in humans). Though these clusters themselves are often repeated into a kind of redundant failsafes. This page from the University of Utah explains it pretty well. It helps if you view embryogenesis as more or less echoes of evolution in fast forward.
",Ganesh Ujwal,https://biology.stackexchange.com/users/9033,http://biology.stackexchange.com/questions/21881/how-does-an-embryo-know-where-to-grow-limbs-etc,SCIENCE,biology.stackexchange.com,0.7777777777777778,0.5555555555555556,0.0,0.0,1.0,1.0,0.4444444444444444,0.5555555555555556,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.0,0.7777777777777778,1.0,0.8888888888888888,1.0,1.0,1.0,0.0,1.0,0.6666666666666666,1.0,"How do embryos know where to grow limbs, etc","For example you have a cell or already a bunch of cells. Those cell(s) divide and after several week you have a grown organism, for example a human with limbs, several different organs etc. 
However, how do cells know where up, down, left, right etc. is?
I know left and right can be defined clearly in physics. However how do cells define those directions and what are mechanisms for them to grow into a certain direction? 
Is there a paper or a longer article dealing with that question/problem?

I don't think my knowledge on Biology goes far beyond high school level maybe 1. term at a university. If I have to, I would read and learn everything I need to know to understand the matter. 
","Embryonic cells ""know"" where they are relative to each other by chemical signals, same as in adults. These molecules are known as morphogens (specific examples include the sonic hedgehog and β-catenin). The amount of morphogen in a region of cells determines which gene gets turned on and thus what it develops into. And the amount varies by how far they are from the source of the morphogen. Though AFAIK, scientists don't fully understand their mechanisms yet (like how they are dispersed, how the different concentrations are kept rigidly, etc.).

As for arms, etc., the earliest cells are unspecialized (stem cells). They ""define"" which becomes what early on by how they are arranged. Remember that their ""up, down, left, and right"" is relative to them, not to their surroundings. The first multicellular hollow ball of stem cells, the blastula, separates into distinct germ layers during gastrulation - the ectoderm, mesoderm, endoderm. Each of these layers develop into something different upon further division. What develops after that is basically a worm, composed of a series of repeating ""segments"" (somites) with a distinct head and tail area. Somites are initially undifferentiated. The job of determining which segment becomes what falls on Hox genes. So that for example, one segment becomes the head, another becomes the arm and pectoral girdle, another becomes a rib+vertebra, etc. Hox genes are arranged in clusters within the DNA relative to which gets expressed first. The first hox gene is for the head for example, while the last is for the tip of the tail (the tipmost segment of the coccyx in humans). Though these clusters themselves are often repeated into a kind of redundant failsafes. This page from the University of Utah explains it pretty well. It helps if you view embryogenesis as more or less echoes of evolution in fast forward.
"
4274,4274,6811,"Which words may start with ""al-""?","Is there a rule which determines whether it allowable for a word to be ""merged"" with ""all"" to make a new word starting ""al-""

e.g.


  1)All together -> Altogether
  
  2)All right -> Alright


The first is generally accepted. Whereas I believe the second is technically not (certainly my English teacher used to condemn it).
",Urbycoz,https://english.stackexchange.com/users/7451,"As far as I know, it's just a convenience, like words with the prefix in- followed by a p. Since n and p are hard to pronounce in a row, the n is replaced by an m, and all of a sudden we have a new prefix im-.
",Shathur,https://english.stackexchange.com/users/8148,http://english.stackexchange.com/questions/23936/which-words-may-start-with-al,CULTURE,english.stackexchange.com,1.0,0.7777777777777778,0.0,1.0,1.0,1.0,0.5555555555555556,0.7777777777777778,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.6666666666666666,0.0,0.7777777777777778,0.7777777777777778,0.5555555555555556,0.6666666666666666,1.0,0.6666666666666667,0.0,0.0,1.0,0.7777777777777778,"Which words can start with ""Al -?""?","Is there a rule which determines whether it allowable for a word to be ""merged"" with ""all"" to make a new word starting ""al-""

e.g.


  1)All together -> Altogether
  
  2)All right -> Alright


The first is generally accepted. Whereas I believe the second is technically not (certainly my English teacher used to condemn it).
","As far as I know, it's just a convenience, like a p followed by a prefix of I n. Because N and P are difficult to pronounce continuously, n is replaced by m, and suddenly we have a new prefix im -."
988,988,1563,"Silent, extremely portable instrument to learn music","I am currently off work for more or less a month, so I decided it could be a great time to learn an instrument and how to compose some simple tunes.

I am 29, never played anything meaningful in my life, know very little to nothing about music theory but I can comfortably read notes on a score.



Asking a search engine for suggestions brought me to the music section of stackexchange and particulary to this question. After some thought I am planning to buy the Kaossilator 2 becase I feel/think:


it is not too expensive for me (less than 200$) (otherwise I would have fancied a Teenage engineering OP1;
it can be completely silent (commuting home->work->home takes quite a long time, I would like to be able to practice in crowded places (without annoying anyone);
it is extremely portable (for the above commuting);
it can be played even without being plugged to a pc (otherwise I would have chosen this korg nano keyboard);
it can study some music theory with it;
in some six months I will be able to show some decent performance with it (so to say, I hope it has a bit of depth and is not just a toy).


Since (as I said), I know nothing of music and musical instruments, I would like to have someone savvy to 'validate' my points; alternative suggestions/idead would be appreciated, too!

I am sorry I haven't 'linkified' but, as it is my first question, stackexchange only allows me to have two hyperlinks.
",Pal Lito,https://music.stackexchange.com/users/3098,"This may just be my opinion but I don't think a kaossilator will help with learning music theory, as it isn't an instrument as such. It is likely to help with rhythm though. 

If you do want to learn, get an electric instrument and use headphones. 
",Dr Mayhem,https://music.stackexchange.com/users/104,http://music.stackexchange.com/questions/7615/silent-extremely-portable-instrument-to-learn-music,LIFE_ARTS,music.stackexchange.com,1.0,0.6666666666666666,0.0,1.0,0.3333333333333333,0.6666666666666666,0.8888888888888888,0.7777777777777778,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.7777777777777778,0.6666666666666666,0.5555555555555556,0.6666666666666666,0.8888888888888888,0.5333333333333333,0.0,0.3333333333333333,0.0,1.0,"Silent, very portable instruments to learn music","I am currently off work for more or less a month, so I decided it could be a great time to learn an instrument and how to compose some simple tunes.

I am 29, never played anything meaningful in my life, know very little to nothing about music theory but I can comfortably read notes on a score.



Asking a search engine for suggestions brought me to the music section of stackexchange and particulary to this question. After some thought I am planning to buy the Kaossilator 2 becase I feel/think:


it is not too expensive for me (less than 200$) (otherwise I would have fancied a Teenage engineering OP1;
it can be completely silent (commuting home->work->home takes quite a long time, I would like to be able to practice in crowded places (without annoying anyone);
it is extremely portable (for the above commuting);
it can be played even without being plugged to a pc (otherwise I would have chosen this korg nano keyboard);
it can study some music theory with it;
in some six months I will be able to show some decent performance with it (so to say, I hope it has a bit of depth and is not just a toy).


Since (as I said), I know nothing of music and musical instruments, I would like to have someone savvy to 'validate' my points; alternative suggestions/idead would be appreciated, too!

I am sorry I haven't 'linkified' but, as it is my first question, stackexchange only allows me to have two hyperlinks.
","This may just be my opinion but I don't think a kaossilator will help with learning music theory, as it isn't an instrument as such. It is likely to help with rhythm though. 

If you do want to learn, get an electric instrument and use headphones. 
"
167,167,264,Voltage ratings of capacitors: ceramic vs electrolytic,"Now I know when it comes to electrolytic capacitors it's usually good practice to use a voltage rating 1.5x - 2.5x the maximum rating you ever expect the capacitor to be exposed to, as the lifetime can be significantly reduced by running it near its limits.

But does the same protocol apply to ceramic capacitors? For example, assume a 25V ceramic capacitor - will running it at 24V reduce its lifespan significantly?

I'm currently designing a PSU which needs to be reliable, so at the moment I'm using 50V caps for a maximum 20V input (35V caps aren't available), but I'd like to switch to 25V caps if possible.
",Thomas O,https://electronics.stackexchange.com/users/1225,"You do not have the same lifespan issues with ceramic caps. You will lose 
capacitance as the voltage increases. The amount you lose is dependant
on the dielectric.

When choosing the electrolytics you also need to look at the ESR, temperature
rating and the maximum operating temperature. Since the lifetime is predicted
using the Arrhenius activation energy law running using a 105°C rated
cap will give you a significant increase over running a 85°C cap (assuming
all other conditions are the same). There are some 5000 hour rated electrolytics.
",jluciani,https://electronics.stackexchange.com/users/424,http://electronics.stackexchange.com/questions/5274/voltage-ratings-of-capacitors-ceramic-vs-electrolytic,TECHNOLOGY,electronics.stackexchange.com,1.0,0.3333333333333333,0.0,1.0,1.0,1.0,0.4444444444444444,0.3333333333333333,0.6666666666666666,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,0.3333333333333333,0.0,1.0,0.8888888888888888,Rated voltage of capacitor: ceramics and electrolysis,"Now I know when it comes to electrolytic capacitors it's usually good practice to use a voltage rating 1.5x - 2.5x the maximum rating you ever expect the capacitor to be exposed to, as the lifetime can be significantly reduced by running it near its limits.

But does the same protocol apply to ceramic capacitors? For example, assume a 25V ceramic capacitor - will running it at 24V reduce its lifespan significantly?

I'm currently designing a PSU which needs to be reliable, so at the moment I'm using 50V caps for a maximum 20V input (35V caps aren't available), but I'd like to switch to 25V caps if possible.
","You do not have the same lifespan issues with ceramic caps. You will lose 
capacitance as the voltage increases. The amount you lose is dependant
on the dielectric.

When choosing the electrolytics you also need to look at the ESR, temperature
rating and the maximum operating temperature. Since the lifetime is predicted
using the Arrhenius activation energy law running using a 105°C rated
cap will give you a significant increase over running a 85°C cap (assuming
all other conditions are the same). There are some 5000 hour rated electrolytics.
"
5378,5378,8544,Cubic graphs without a perfect matching and a vertex incident to three bridges,"The example shown below (courtesy of David Eppstein) is a common example of a cubic graph  that admits no perfect matching:



Are there other examples of cubic graphs that do not admit a perfect matching and, unlike the above example, do not contain a vertex that lies at the intersection of three bridges (i.e. an edge whose removal increases the number of connected components in the graph)?
",Anthony Labarre,https://mathoverflow.net/users/3356,"Substitute your central vertex in your graph with a 3-cycle $abc$ so that the graph stays cubic. Now subdivide each edge in this 3-cycle. So we have new vertices $u$ connected to $a$ and $b$, $v$ connected to $b$ and $c$, $w$ connected to $c$ and $a$. Now add a final vertex $x$ and connect it to $u,v$ and $w$. This graph has exactly three bridges, none of which intersect the other at a vertex, and moreover has no perfect matching!

One result which relates the existence of a perfect matching in a cubic graph and its bridges is the following theorem of Petersen from ""Die theorie der regularen graphen"", Acta Math. 15
(1891), 163-220:


  Theorem: Every cubic graph with at most two bridges contains a perfect matching. 


As well as this strengthening by Errera, ""Du colorage des cartes"", Mathesis 36 (1922), 56-60:


  Theorem: If all the bridges of a connected cubic graph $G$ lie on a single path of $G$, then $G$ has a perfect matching.


So your instinct is true, in the sense that if the graph has no perfect matching, its bridges do not lie on a path. However the example in the beginning of this answer shows that they are not necessarily incident at the same vertex.
",Gjergji Zaimi,https://mathoverflow.net/users/2384,http://mathoverflow.net/questions/98385,SCIENCE,mathoverflow.net,1.0,0.6666666666666666,0.0,0.6666666666666666,1.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.8888888888888888,1.0,0.7777777777777778,1.0,1.0,0.9333333333333332,0.6666666666666666,0.6666666666666666,1.0,0.8888888888888888,A cubic graph with no perfect match and vertex intersecting three bridges,"The example shown below (courtesy of David Eppstein) is a common example of a cubic graph  that admits no perfect matching:



Are there other examples of cubic graphs that do not admit a perfect matching and, unlike the above example, do not contain a vertex that lies at the intersection of three bridges (i.e. an edge whose removal increases the number of connected components in the graph)?
","Substitute your central vertex in your graph with a 3-cycle $abc$ so that the graph stays cubic. Now subdivide each edge in this 3-cycle. So we have new vertices $u$ connected to $a$ and $b$, $v$ connected to $b$ and $c$, $w$ connected to $c$ and $a$. Now add a final vertex $x$ and connect it to $u,v$ and $w$. This graph has exactly three bridges, none of which intersect the other at a vertex, and moreover has no perfect matching!

One result which relates the existence of a perfect matching in a cubic graph and its bridges is the following theorem of Petersen from ""Die theorie der regularen graphen"", Acta Math. 15
(1891), 163-220:


  Theorem: Every cubic graph with at most two bridges contains a perfect matching. 


As well as this strengthening by Errera, ""Du colorage des cartes"", Mathesis 36 (1922), 56-60:


  Theorem: If all the bridges of a connected cubic graph $G$ lie on a single path of $G$, then $G$ has a perfect matching.


So your instinct is true, in the sense that if the graph has no perfect matching, its bridges do not lie on a path. However the example in the beginning of this answer shows that they are not necessarily incident at the same vertex.
"
3999,3999,6388,How to make extra crispy and crunchy breading like KFC?,"I'm wondering how I would go about making extra crispy chicken breading like they do at many places like KFC and the like. Is there a certain ingredient that makes the breading like that?

Any assistance would be very much appreciated, and feel free to share any of your own recipes for crispy chicken breading if you have them. I'll be sure to put them to good use!

Thanks!
",James Mowery,https://cooking.stackexchange.com/users/2109,"You only need to add your favorite seasonings to a bowl of rice flour. Then you coat the chicken with the rice flour, fry and eat it. 
",tomen,https://cooking.stackexchange.com/users/11202,http://cooking.stackexchange.com/questions/5764/how-to-make-extra-crispy-and-crunchy-breading-like-kfc,LIFE_ARTS,cooking.stackexchange.com,1.0,1.0,0.0,0.0,1.0,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.6666666666666666,0.8888888888888888,1.0,0.8666666666666666,1.0,0.0,0.0,1.0,How to make crisp bread like KFC?,"I'm wondering how I would go about making extra crispy chicken breading like they do at many places like KFC and the like. Is there a certain ingredient that makes the breading like that?

Any assistance would be very much appreciated, and feel free to share any of your own recipes for crispy chicken breading if you have them. I'll be sure to put them to good use!

Thanks!
","You only need to add your favorite seasonings to a bowl of rice flour. Then you coat the chicken with the rice flour, fry and eat it. 
"
4568,4568,7238,Why can't my C++ compiler deduce template argument for boost function?,"I define a method like so:

template &lt;class ArgT&gt;
void foo(ArgT arg, ::boost::function&lt; void(ArgT) &gt; func)
{
    func(arg);
}


and use it like this --for instance--:

foo(2, [](int i) -&gt; void { cout &lt;&lt; i &lt;&lt; endl; });


Why can't the compiler deduce the type since it's definitely an int?

I get 'void foo(ArgT,boost::function&lt;void(ArgT)&gt;)' : could not deduce template argument for 'boost::function&lt;void(ArgT)&gt;' from 'anonymous-namespace'::&lt;lambda0&gt;'.
",mister why,https://stackoverflow.com/users/685664,"While C++ lambdas are strictly monomorphic, they are merely shorthand for function objects (aka functors), and in general functors can be polymorphic; i.e., their call operators can be overloaded or templated. As a result, functors (and, consequently, lambdas) are never implicitly convertible to templated std::function&lt;&gt; (or boost::function&lt;&gt;) instances because functors' operator() argument types are not automatically inferable.

To phrase it slightly differently, the natural type of your lambda expression is a functor with a parameterless constructor and an operator() with the signature void operator ()(int) const. However obvious this fact may be to you and I, it's not automatically inferrable that ArgT should resolve to int because lambdas are functors and functors' operator()s are possible to overload and template.

TL;DR: What you want isn't possible.
",ildjarn,https://stackoverflow.com/users/636019,http://stackoverflow.com/questions/5871044/why-cant-my-c-compiler-deduce-template-argument-for-boost-function,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.5555555555555556,0.0,0.5,1.0,1.0,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,1.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.3333333333333333,0.3333333333333333,1.0,0.7777777777777778,Why can't my C + + compiler derive template parameters for boost functions?,"I define a method like so:

template &lt;class ArgT&gt;
void foo(ArgT arg, ::boost::function&lt; void(ArgT) &gt; func)
{
    func(arg);
}


and use it like this --for instance--:

foo(2, [](int i) -&gt; void { cout &lt;&lt; i &lt;&lt; endl; });


Why can't the compiler deduce the type since it's definitely an int?

I get 'void foo(ArgT,boost::function&lt;void(ArgT)&gt;)' : could not deduce template argument for 'boost::function&lt;void(ArgT)&gt;' from 'anonymous-namespace'::&lt;lambda0&gt;'.
","Although C + + Lambdas are strictly monomorphic, they are only shorthand (aka functor) of function objects, and in general, functors can be polymorphic; that is, their call operators can be overloaded or templated. Therefore, since the operator() parameter type of functor cannot be inferred automatically, functor (and resulting Lambdas) can never be implicitly converted to template STD:: Function & lt; gt; (or boost:: Function & lt; gt;) instances."
2711,2711,4324,How to display zero value as blank cell in mac numbers 3.1,"How do I display zero value as blank cell in mac numbers 3.1 yet maintain a formula.  I want a running balance column that only shows balance to the line of the last entry like a checkbook register.
Thanks.
",user69881,https://apple.stackexchange.com/users/69881,"Here's a simple approach:  =If(A1&lt;=0,"" "",A1)

You're simple saying:  If the result displayed in Cell A1 is less than or equal to 0, display what's between the parenthesis.  It could be Yes, No, Blue, Green, or just Blank space.  If Cell A1 is greater than 0, display the value of that cell.

You don't have to leave a space between the """" for the formula to work.  Try a simple test of the formula on different values and watch as the cell will switch to a Blank value, if the Cell is less than or equal to 0.  Logic formulas using If, And, Or and If And switches are powerful tools in many calculations goals.
",user73700,https://apple.stackexchange.com/users/73700,http://apple.stackexchange.com/questions/120359/how-to-display-zero-value-as-blank-cell-in-mac-numbers-3-1,TECHNOLOGY,apple.stackexchange.com,0.8888888888888888,0.8888888888888888,0.0,0.0,1.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,1.0,0.8888888888888888,1.0,1.0,0.9333333333333332,1.0,0.6666666666666666,0.0,1.0,How to display zero value as blank cell in MAC number 3.1,"How to display the zero value as a blank cell in MAC number 3.1 while keeping the formula. I want a running balance column that shows only the balance to the last entry row, just like a checkbook register.","Here's a simple approach:  =If(A1&lt;=0,"" "",A1)

You're simple saying:  If the result displayed in Cell A1 is less than or equal to 0, display what's between the parenthesis.  It could be Yes, No, Blue, Green, or just Blank space.  If Cell A1 is greater than 0, display the value of that cell.

You don't have to leave a space between the """" for the formula to work.  Try a simple test of the formula on different values and watch as the cell will switch to a Blank value, if the Cell is less than or equal to 0.  Logic formulas using If, And, Or and If And switches are powerful tools in many calculations goals.
"
659,659,1048,Cubic graphs without a perfect matching and a vertex incident to three bridges,"The example shown below (courtesy of David Eppstein) is a common example of a cubic graph  that admits no perfect matching:



Are there other examples of cubic graphs that do not admit a perfect matching and, unlike the above example, do not contain a vertex that lies at the intersection of three bridges (i.e. an edge whose removal increases the number of connected components in the graph)?
",Anthony Labarre,https://mathoverflow.net/users/3356,"I think there are no such graphs. 

It was shown by Sumner and Las Vergnas (you can find the references here: http://mathsci.kaist.ac.kr/~sangil/pdf/2009claw.pdf) that a claw-free connected graph has a perfect matching (assuming even number of vertices, of course!).  An intersection of three bridges is clearly a claw.
",Felix Goldberg,https://mathoverflow.net/users/22051,http://mathoverflow.net/questions/98385,SCIENCE,mathoverflow.net,0.7777777777777778,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,1.0,A cubic graph with no perfect match and vertex intersecting three bridges,"The example shown below (courtesy of David Eppstein) is a common example of a cubic graph  that admits no perfect matching:



Are there other examples of cubic graphs that do not admit a perfect matching and, unlike the above example, do not contain a vertex that lies at the intersection of three bridges (i.e. an edge whose removal increases the number of connected components in the graph)?
","I think there are no such graphs. 

It was shown by Sumner and Las Vergnas (you can find the references here: http://mathsci.kaist.ac.kr/~sangil/pdf/2009claw.pdf) that a claw-free connected graph has a perfect matching (assuming even number of vertices, of course!).  An intersection of three bridges is clearly a claw.
"
3741,3741,5959,basic date comparsion for expiration checking,"i want to create a traffic lights system that will tell me how many days are left to go until a document reaches its expiration date.
I want it to be marked by colors in my html.


green: if the document has 31 days or more to go until it expires.
amber: 30 days or less until it expires.
red: for 7 days or less.


I also want to display a text, telling me how many days until expiration.
The expiration date comes from my database in the field called insurance_date

Heres my code i am new to php so struggling to put my code together, if someone could show me how to restructure my code in order to achieve what im trying to do id be greatful, thanks.

my code:

 &lt;?php 

   include 'config.php';
   $data = mysql_query(""SELECT * FROM supplier_stats"") 
   or die(mysql_error()); 

   while($info = mysql_fetch_array( $data )) 
   { 
     echo ""&lt;p&gt;Insurance Expires ! - &lt;font color=\""red\""&gt;"".$info['insurance_date'] . ""&lt;/font&gt;&lt;/p&gt;""; 

   } 

   $date_diff = 60*60*24*7; // 7 days
   // time()+$date_diff will be a timestamp 7 days in the future
   if ($info['insurance_date'] &lt; time()+$date_diff) {
    echo ""less than 7 days left!"";
   }

",user3488706,https://stackoverflow.com/users/3488706,"I'm guessing $info['insurance_date'] is a datetime string in the format YYYY-mm-dd HH:ii:ss, right?

If this is the case, you will need to run it through strtotime before comparing it to a numeric time (time()+$date_diff)
",Niet the Dark Absol,https://stackoverflow.com/users/507674,http://stackoverflow.com/questions/23060541/basic-date-comparsion-for-expiration-checking,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.3333333333333333,0.0,1.0,0.6666666666666666,1.0,0.6666666666666666,0.4444444444444444,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,0.9,1.0,0.0,0.0,0.8888888888888888,Basic date comparison of overdue inspection,"i want to create a traffic lights system that will tell me how many days are left to go until a document reaches its expiration date.
I want it to be marked by colors in my html.


green: if the document has 31 days or more to go until it expires.
amber: 30 days or less until it expires.
red: for 7 days or less.


I also want to display a text, telling me how many days until expiration.
The expiration date comes from my database in the field called insurance_date

Heres my code i am new to php so struggling to put my code together, if someone could show me how to restructure my code in order to achieve what im trying to do id be greatful, thanks.

my code:

 &lt;?php 

   include 'config.php';
   $data = mysql_query(""SELECT * FROM supplier_stats"") 
   or die(mysql_error()); 

   while($info = mysql_fetch_array( $data )) 
   { 
     echo ""&lt;p&gt;Insurance Expires ! - &lt;font color=\""red\""&gt;"".$info['insurance_date'] . ""&lt;/font&gt;&lt;/p&gt;""; 

   } 

   $date_diff = 60*60*24*7; // 7 days
   // time()+$date_diff will be a timestamp 7 days in the future
   if ($info['insurance_date'] &lt; time()+$date_diff) {
    echo ""less than 7 days left!"";
   }

","I'm guessing $info['insurance_date'] is a datetime string in the format YYYY-mm-dd HH:ii:ss, right?

If this is the case, you will need to run it through strtotime before comparing it to a numeric time (time()+$date_diff)
"
46,46,71,Get term weight in node object for ordering with EntityFieldQuery,"Is it posiible to expose taxonomy term weight in node object ?

I need to sort nodes using EntityFieldQuery by term reference field, but weight is not exposed to node object so i can say for example 

-&gt;fieldOrderBy('field_custom_terms', 'weight', 'ASC');


and sort nodes by weight of terms.
",NenadP,https://drupal.stackexchange.com/users/5970,"No, this is not possible. You can only order on actual field values, the term weight would require a JOIN to a non-field table and EFQ is not capable of doing that.

You will have to create a manual SQL query to do this. Note that Drupal by default maintains the node &lt;-> term associations in the taxonomy_index table, that one is easier and more reliable to query than a field data table.
",Berdir,https://drupal.stackexchange.com/users/31,http://drupal.stackexchange.com/questions/40815/get-term-weight-in-node-object-for-ordering-with-entityfieldquery,TECHNOLOGY,drupal.stackexchange.com,1.0,0.6666666666666666,0.0,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,1.0,0.3333333333333333,1.0,1.0,0.4,1.0,0.0,1.0,1.0,Gets the weight of the item in the node object used to sort using entityfieldquery,"Is it posiible to expose taxonomy term weight in node object ?

I need to sort nodes using EntityFieldQuery by term reference field, but weight is not exposed to node object so i can say for example 

-&gt;fieldOrderBy('field_custom_terms', 'weight', 'ASC');


and sort nodes by weight of terms.
","No, this is not possible. You can only order on actual field values, the term weight would require a JOIN to a non-field table and EFQ is not capable of doing that.

You will have to create a manual SQL query to do this. Note that Drupal by default maintains the node &lt;-> term associations in the taxonomy_index table, that one is easier and more reliable to query than a field data table.
"
4872,4872,7752,Does using a Power-attack while sneaking increase your chances of being detected?,"According to the Skyrim Wiki, ""daggers are silent, meaning that enemies are not alerted to your dagger swings, even missed ones."" However,  there is generally a sound (grunt or guttural throat noise) to go along with a power attack animation.

Is this noise just for effect (like the passive spell-in-hand glow) or is the sound audible by potential victims/enemies?
",Bravo840,https://gaming.stackexchange.com/users/3046,"I think the power attack is just as silent as a normal swing, the grunt/yell is purely for effect.  I went up behind an enemy and whiffed a bunch of power attacks on purpose and he had no reaction whatsoever, then I finished him off with a power attack and a nearby patrolling enemy didn't react.

I have to add an addendum to this:

Power attacks can sometimes push your character forward a little bit on the swing, and this can cause you to be detected before the attack connects, making you lose the sneak attack bonus.  Make sure you are standing far back enough for this to not happen.
",l I,https://gaming.stackexchange.com/users/3917,http://gaming.stackexchange.com/questions/40532/does-using-a-power-attack-while-sneaking-increase-your-chances-of-being-detected,CULTURE,gaming.stackexchange.com,1.0,0.6666666666666666,0.0,1.0,1.0,1.0,0.5555555555555556,0.3333333333333333,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,0.8888888888888888,Does the use of powerful attacks increase the chance of detection?,"According to skyrim wiki, ""the dagger is silent, which means the enemy won't notice your dagger swing, or even miss it."" However, there is usually a sound (grunt or guttural) accompanied by a power attack animation.","I think the power attack is just as silent as a normal swing, the grunt/yell is purely for effect.  I went up behind an enemy and whiffed a bunch of power attacks on purpose and he had no reaction whatsoever, then I finished him off with a power attack and a nearby patrolling enemy didn't react.

I have to add an addendum to this:

Power attacks can sometimes push your character forward a little bit on the swing, and this can cause you to be detected before the attack connects, making you lose the sneak attack bonus.  Make sure you are standing far back enough for this to not happen.
"
1539,1539,2417,"Silent, extremely portable instrument to learn music","I am currently off work for more or less a month, so I decided it could be a great time to learn an instrument and how to compose some simple tunes.

I am 29, never played anything meaningful in my life, know very little to nothing about music theory but I can comfortably read notes on a score.



Asking a search engine for suggestions brought me to the music section of stackexchange and particulary to this question. After some thought I am planning to buy the Kaossilator 2 becase I feel/think:


it is not too expensive for me (less than 200$) (otherwise I would have fancied a Teenage engineering OP1;
it can be completely silent (commuting home->work->home takes quite a long time, I would like to be able to practice in crowded places (without annoying anyone);
it is extremely portable (for the above commuting);
it can be played even without being plugged to a pc (otherwise I would have chosen this korg nano keyboard);
it can study some music theory with it;
in some six months I will be able to show some decent performance with it (so to say, I hope it has a bit of depth and is not just a toy).


Since (as I said), I know nothing of music and musical instruments, I would like to have someone savvy to 'validate' my points; alternative suggestions/idead would be appreciated, too!

I am sorry I haven't 'linkified' but, as it is my first question, stackexchange only allows me to have two hyperlinks.
",Pal Lito,https://music.stackexchange.com/users/3098,"I want a Kaossilator, but to learn music, it is strongly preferable to have more control over it.

I am a guitarist, but my recommendation would be something with a keyboard. A keyboard app on an iPad would be most portable, and there are low-end beginner keyboards available for just around the $100 level. 
",Dave Jacoby,https://music.stackexchange.com/users/195,http://music.stackexchange.com/questions/7615/silent-extremely-portable-instrument-to-learn-music,LIFE_ARTS,music.stackexchange.com,0.8888888888888888,0.7777777777777778,0.0,1.0,0.3333333333333333,0.3333333333333333,0.7777777777777778,0.7777777777777778,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.9333333333333332,0.0,0.0,0.6666666666666666,1.0,"Silent, very portable instruments to learn music","I am currently off work for more or less a month, so I decided it could be a great time to learn an instrument and how to compose some simple tunes.

I am 29, never played anything meaningful in my life, know very little to nothing about music theory but I can comfortably read notes on a score.



Asking a search engine for suggestions brought me to the music section of stackexchange and particulary to this question. After some thought I am planning to buy the Kaossilator 2 becase I feel/think:


it is not too expensive for me (less than 200$) (otherwise I would have fancied a Teenage engineering OP1;
it can be completely silent (commuting home->work->home takes quite a long time, I would like to be able to practice in crowded places (without annoying anyone);
it is extremely portable (for the above commuting);
it can be played even without being plugged to a pc (otherwise I would have chosen this korg nano keyboard);
it can study some music theory with it;
in some six months I will be able to show some decent performance with it (so to say, I hope it has a bit of depth and is not just a toy).


Since (as I said), I know nothing of music and musical instruments, I would like to have someone savvy to 'validate' my points; alternative suggestions/idead would be appreciated, too!

I am sorry I haven't 'linkified' but, as it is my first question, stackexchange only allows me to have two hyperlinks.
","I want a Kaossilator, but to learn music, it is strongly preferable to have more control over it.

I am a guitarist, but my recommendation would be something with a keyboard. A keyboard app on an iPad would be most portable, and there are low-end beginner keyboards available for just around the $100 level. 
"
1162,1162,1823,"create a list (or any variable) dynamically, add data to each list and later compare them in C#","I have a list of some strings and I want to create a list for each of them dynamically inside a loop.

The main idea is to get each string from this list through the loop and create a list with this string as a name. Then add some data to it. 

Example:

   List&lt;string&gt; names = new List&lt;string&gt;(); // this is the main list with strings

   foreach (string nm in name)
   {
     // Here create a new list with this name
     // Add data to the list
   }  

   // Now, compare all of them to find duplicate data

   // Give message if any duplicate data found


Update:
Basically, I am going to add data to the list using some database APIs on runtime and the string names are the keys in that API. So with each name in the main list, I will retrieve some data from the database, create a list with that name and add data to it. Later we will compare them together. So the basic question is still how do I create these lists at runtime.
",Indigo,https://stackoverflow.com/users/1584507,"Use a generic Dictionary:

List&lt;string&gt; names = new List&lt;string&gt;(); // this is the main list with strings
Dictionary&lt;string, List&lt;string&gt;&gt; dict = new Dictionary&lt;string, List&lt;string&gt;&gt;();

foreach (string name in names)
{
    if (!dict.ContainsKey(name))
        dict.Add(name, new List&lt;string&gt;());
    dict[name].Add(""another one bytes the dust :)"");
}  


In the above example, you will have a Dictionary with amount of keys equals to the number of unique names, and you can find duplicates by keys having more than one item in their associated List.

For example:

string[] dupes = dict.Keys.ToList().Find(k =&gt; dict[k].Count &gt; 1).ToArray();

",Shadow Wizard,https://stackoverflow.com/users/447356,http://stackoverflow.com/questions/13341504/create-a-list-or-any-variable-dynamically-add-data-to-each-list-and-later-com,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.5555555555555556,0.0,1.0,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.3333333333333333,0.0,1.0,"Create a list (or any variables) dynamically, add data to each list, and compare them in C#","I have a list of some strings and I want to create a list for each of them dynamically inside a loop.

The main idea is to get each string from this list through the loop and create a list with this string as a name. Then add some data to it. 

Example:

   List&lt;string&gt; names = new List&lt;string&gt;(); // this is the main list with strings

   foreach (string nm in name)
   {
     // Here create a new list with this name
     // Add data to the list
   }  

   // Now, compare all of them to find duplicate data

   // Give message if any duplicate data found


Update:
Basically, I am going to add data to the list using some database APIs on runtime and the string names are the keys in that API. So with each name in the main list, I will retrieve some data from the database, create a list with that name and add data to it. Later we will compare them together. So the basic question is still how do I create these lists at runtime.
","Use a generic Dictionary:

List&lt;string&gt; names = new List&lt;string&gt;(); // this is the main list with strings
Dictionary&lt;string, List&lt;string&gt;&gt; dict = new Dictionary&lt;string, List&lt;string&gt;&gt;();

foreach (string name in names)
{
    if (!dict.ContainsKey(name))
        dict.Add(name, new List&lt;string&gt;());
    dict[name].Add(""another one bytes the dust :)"");
}  


In the above example, you will have a Dictionary with amount of keys equals to the number of unique names, and you can find duplicates by keys having more than one item in their associated List.

For example:

string[] dupes = dict.Keys.ToList().Find(k =&gt; dict[k].Count &gt; 1).ToArray();

"
1111,1111,1746,Recover Server 2008 R2 Domain Admin Password,"So I did the ultimate silly thing: I lost my domain admin password for my Server 2008 R2 box. 

Sure, I could just re-install but that's going to be a huge pain. I tried rebooting with the Windows Install DVD and replacing utilman.exe with cmd.exe, but switching to C: displayed no files.

I can still log into the machine as a regular user, though. 

And I see there's been some local privilege escalation vulnerabilities patched in the last couple months (specifically MS13-046 looks promising). And it's been a little while since I've logged in to apply MSFT patches (which oddly enough was what I was trying to log in to do).

Are there any publicly available exploits for these bugs? I don't see any in Metasploit. Or is there just a better way altogether? I full physical access to the machine, but I think BitLocker is enabled (which is why I think replacing utilman.exe failed).  
",mikhailzhan,https://security.stackexchange.com/users/26617,"If you've got a local account but not a domain admin, IIRC you could try metasploit with the psexec payload to put meterpreter down on the server and then use the getsystem command to try and get admin on the box.

EDIT Per @void_in this won't work with W2K8 and UAC, to you'd need to use an exploit to elevate privileges, e.g. the MS12-042 one linked in comments

if that's succcessful you can dump the domain password hashes and try and crack them (this will be easier if you can remember anything about the password like length or character set that you did/did not include).

What I'm not sure about, but which might work is, if you can use getsystem on the domain controller whether you can then use meterpreters add user commands to add a new domain admin, may be worth a try :)
",Rоry McCune,https://security.stackexchange.com/users/37,http://security.stackexchange.com/questions/36780/recover-server-2008-r2-domain-admin-password,TECHNOLOGY,security.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.8,1.0,0.0,0.0,0.8888888888888888,Recover Server 2008 R2 domain management password,"So I did the ultimate silly thing: I lost my domain admin password for my Server 2008 R2 box. 

Sure, I could just re-install but that's going to be a huge pain. I tried rebooting with the Windows Install DVD and replacing utilman.exe with cmd.exe, but switching to C: displayed no files.

I can still log into the machine as a regular user, though. 

And I see there's been some local privilege escalation vulnerabilities patched in the last couple months (specifically MS13-046 looks promising). And it's been a little while since I've logged in to apply MSFT patches (which oddly enough was what I was trying to log in to do).

Are there any publicly available exploits for these bugs? I don't see any in Metasploit. Or is there just a better way altogether? I full physical access to the machine, but I think BitLocker is enabled (which is why I think replacing utilman.exe failed).  
","If you've got a local account but not a domain admin, IIRC you could try metasploit with the psexec payload to put meterpreter down on the server and then use the getsystem command to try and get admin on the box.

EDIT Per @void_in this won't work with W2K8 and UAC, to you'd need to use an exploit to elevate privileges, e.g. the MS12-042 one linked in comments

if that's succcessful you can dump the domain password hashes and try and crack them (this will be easier if you can remember anything about the password like length or character set that you did/did not include).

What I'm not sure about, but which might work is, if you can use getsystem on the domain controller whether you can then use meterpreters add user commands to add a new domain admin, may be worth a try :)
"
1023,1023,1614,Saturated Density Plots,"I am making some density and contour plots in Mathematica. These plots have very high peaks which saturate with color and prevent me from seeing differences in the peaks. Is there a way I can tone down the color scale so my peaks are not just white blobs?

Trying other color schemes has not worked out, and playing with the range of color data has not been very useful. Is there some way to have the colors on a log scale???

Here is my code.

ListDensityPlot[photo, PlotLegends -&gt; Automatic, Frame -&gt; {True}, 
FrameLabel -&gt; {""Electron Bunch Energy (MeV)"", ""Photon Energy (keV)"", 
"""", ""Yield (Photons/Sr e-KeV)"" }, LabelStyle -&gt; {15}, 
InterpolationOrder -&gt; 10]




Cheers, Ben
",user1558881,https://mathematica.stackexchange.com/users/9185,"Borrowing Murta's data we can also try out Rahul Narain's Log recommendation:

data = Table[Exp[-10 (x^2 + y^2)], {x, -1, 1, 0.02}, {y, -1, 1, 0.02}];

ListDensityPlot[data]

ListDensityPlot[Log @ data]


 

If your data is in the (x,y,z) form you will need something like {#, #2, Log@#3} &amp; @@@ data as Kuba comments above.
",Mr.Wizard,https://mathematica.stackexchange.com/users/121,http://mathematica.stackexchange.com/questions/30934/saturated-density-plots,TECHNOLOGY,mathematica.stackexchange.com,1.0,0.3333333333333333,0.0,0.3333333333333333,1.0,1.0,0.4444444444444444,0.3333333333333333,1.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,1.0,0.8333333333333334,0.6666666666666666,0.8333333333333334,0.8888888888888888,0.8,0.0,0.6666666666666666,0.0,1.0,Saturation density diagram,"I am making some density and contour plots in Mathematica. These plots have very high peaks which saturate with color and prevent me from seeing differences in the peaks. Is there a way I can tone down the color scale so my peaks are not just white blobs?

Trying other color schemes has not worked out, and playing with the range of color data has not been very useful. Is there some way to have the colors on a log scale???

Here is my code.

ListDensityPlot[photo, PlotLegends -&gt; Automatic, Frame -&gt; {True}, 
FrameLabel -&gt; {""Electron Bunch Energy (MeV)"", ""Photon Energy (keV)"", 
"""", ""Yield (Photons/Sr e-KeV)"" }, LabelStyle -&gt; {15}, 
InterpolationOrder -&gt; 10]




Cheers, Ben
","Borrowing Murta's data we can also try out Rahul Narain's Log recommendation:

data = Table[Exp[-10 (x^2 + y^2)], {x, -1, 1, 0.02}, {y, -1, 1, 0.02}];

ListDensityPlot[data]

ListDensityPlot[Log @ data]


 

If your data is in the (x,y,z) form you will need something like {#, #2, Log@#3} &amp; @@@ data as Kuba comments above.
"
1812,1812,2875,Why can't the compiler infer this type argument from usage,"This question is based off of the results from another SO question of mine. My new question is not a question of how can I get X to work, but why doesn't X work.

I've created a simplified example of my problem, however if you want to see the practical application/situation I'm using this, look at my original question (the below functions don't actually do anything useful).

T bar&lt;T&gt;(Func&lt;T, bool&gt; f) { return default(T); }
bool foo(int i) { return true; }


Now I have 3 lines of code that do work as expected and all do the same thing purpose wise.

int num;
num = bar&lt;int&gt;(foo);
num = bar(new Func&lt;int, bool&gt;(foo));
num = bar((int i) =&gt; true );


My question is ""Why do I need to explicitly specify T for bar for the first example?"" The reason I wonder this is because the compiler turns the first two examples into the same line of code. Using ILSpy I see that the code compiles to this.

num = Program.bar&lt;int&gt;(new Func&lt;int, bool&gt;(Program.foo));
num = Program.bar&lt;int&gt;(new Func&lt;int, bool&gt;(Program.foo));
num = Program.bar&lt;int&gt;((int i) =&gt; true);


I don't understand why the compiler can't infer the type from the fact that I only have one function called foo, and it does fit the template so to speak. Now if I had created another function bool foo(bool i) I would understand if the compiler complained that there was some ambiguity and it didn't know which one I wanted and that I should specify the type argument explicitly.

This of course is just me being lazy, but it is just something I was expecting and was surprised when the compiler wasn't picking up my slack.
",BenVlodgi,https://stackoverflow.com/users/1812944,"I'm on the bus, so, short answer.

type inference of t requires knowing the formal parameter type of the delegate type in the argument.

conversion of the method group to the delegate type does overload resolution as though the method group was invoked with the arguments of the formal parameter types of the target delegate.

but those types are what we are trying to deduce!

this is circular reasoning, so type inference rejects it. A method group conversion requires that the formal parameter types be deduced from some other argument.

you have no other arguments.

so inference fails.

that the group contains only one method is irrelevant. It would be bizarre if adding more methods to the group caused inference to fail. The rule that a group of overloads is resolved through overload resolution is a sensible one, and that requires knowing the parameters. You don't get to run the inferences backwards just because a method group happens to be a singleton.

see the type inference tag on my msdn blog for a longer article on this topic.

http://blogs.msdn.com/b/ericlippert/archive/2007/11/05/c-3-0-return-type-inference-does-not-work-on-member-groups.aspx
",Eric Lippert,https://stackoverflow.com/users/88656,http://stackoverflow.com/questions/22413909/why-cant-the-compiler-infer-this-type-argument-from-usage,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.4444444444444444,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.0,1.0,0.8888888888888888,Why the compiler cannot infer this type of parameter from usage,"This question is based off of the results from another SO question of mine. My new question is not a question of how can I get X to work, but why doesn't X work.

I've created a simplified example of my problem, however if you want to see the practical application/situation I'm using this, look at my original question (the below functions don't actually do anything useful).

T bar&lt;T&gt;(Func&lt;T, bool&gt; f) { return default(T); }
bool foo(int i) { return true; }


Now I have 3 lines of code that do work as expected and all do the same thing purpose wise.

int num;
num = bar&lt;int&gt;(foo);
num = bar(new Func&lt;int, bool&gt;(foo));
num = bar((int i) =&gt; true );


My question is ""Why do I need to explicitly specify T for bar for the first example?"" The reason I wonder this is because the compiler turns the first two examples into the same line of code. Using ILSpy I see that the code compiles to this.

num = Program.bar&lt;int&gt;(new Func&lt;int, bool&gt;(Program.foo));
num = Program.bar&lt;int&gt;(new Func&lt;int, bool&gt;(Program.foo));
num = Program.bar&lt;int&gt;((int i) =&gt; true);


I don't understand why the compiler can't infer the type from the fact that I only have one function called foo, and it does fit the template so to speak. Now if I had created another function bool foo(bool i) I would understand if the compiler complained that there was some ambiguity and it didn't know which one I wanted and that I should specify the type argument explicitly.

This of course is just me being lazy, but it is just something I was expecting and was surprised when the compiler wasn't picking up my slack.
","I'm on the bus, so, short answer.

type inference of t requires knowing the formal parameter type of the delegate type in the argument.

conversion of the method group to the delegate type does overload resolution as though the method group was invoked with the arguments of the formal parameter types of the target delegate.

but those types are what we are trying to deduce!

this is circular reasoning, so type inference rejects it. A method group conversion requires that the formal parameter types be deduced from some other argument.

you have no other arguments.

so inference fails.

that the group contains only one method is irrelevant. It would be bizarre if adding more methods to the group caused inference to fail. The rule that a group of overloads is resolved through overload resolution is a sensible one, and that requires knowing the parameters. You don't get to run the inferences backwards just because a method group happens to be a singleton.

see the type inference tag on my msdn blog for a longer article on this topic.

http://blogs.msdn.com/b/ericlippert/archive/2007/11/05/c-3-0-return-type-inference-does-not-work-on-member-groups.aspx
"
1235,1235,1935,Effective game mechanics for handling conflicts with spirits,"A very effective set piece can be conflict with the spirit world.  A nice example of the kind of thing I am thinking of is from the 1982 Conan film, where the wizard opens a gateway to the spirit world to get demons to revive Conan, and where Valeria fights incorporeal demons to save Conan (YouTube, from 6:45 into the clip to the end &amp; onto next clip).

RQ3 had nice mechanics for dealing with these situations, with shamans who can take characters to the other side through their fetch, spirit combat to handle attacks by hostile spirits, using magic points as an orthogonal measure of strength to hit points.  

AD&amp;D was pretty lousy for this kind of thing back in the day: its distinction between combat involving the incorporeal attribute or in the ethereal and astral realms didn't really work for setting up situations.  But newer D&amp;Ds seem to have better resources, though I've not seen this in action.

What good game mechanics are there for handling conflicts with spirits?

Postscript

The kind of thing game mechanics need, I think, to sustain interest in spirits and spirit combat are:


Spirits are immaterial and that means you have to do different sorts of things to influence them.  E.g., if the best way to deal with an ancient ghost is to chop it up with an axe, that'll spil that atmosphere a bit;
Likewise, spirits are potentially powerful adversaries.  Not very high-powered spells that can get rid of most spirits with a 65% chance of success detract from interest;
Characters can be experts in spirits, and it is good if the nature of those experts draws on resonant real-world and fictional atmospheric devices such as shamans, ancestor worship, fetches, and the like.  It's also good if characters regularly need the services of these figures. 

",Alticamelus,https://rpg.stackexchange.com/users/973,"The Dresden Files

The fate-powered Dresden Files RPG has very good rules for summoning, containing, and controlling spirits / faeries / ghosts / demons.

Each of those three tasks - summoning, containing, and controlling - is dealt with in sufficient detail to be flavorful, but like most of the dresden-files rules, you can skip the boring parts. 

Is your wizard calling a minor friendly, like Toot-Toot? You can probably get away with a single roll. 

Pulling up something from the wrong side of the Nevernever? A big bad Thing that would pick his teeth with your athame if it weren't for that pesky summoning circle? Oh, and is that a pack of howling ghouls hammering at your door while you chat with this critter? Then you're in for all the rolls and attention that such a dramatic, possibly climactic moment deserves.

Sorcerer

Ron Edwards' Sorcerer is all about summoning, binding, and interacting with demons. I have never played it, but I hope to remedy that soon!
",gomad,https://rpg.stackexchange.com/users/696,http://rpg.stackexchange.com/questions/8106/effective-game-mechanics-for-handling-conflicts-with-spirits,CULTURE,rpg.stackexchange.com,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.0,0.6666666666666666,0.0,0.6666666666666666,0.5555555555555556,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,0.7777777777777778,1.0,0.8666666666666666,0.3333333333333333,0.0,0.3333333333333333,1.0,An effective game mechanism to deal with spiritual conflicts,"A very effective set piece can be conflict with the spirit world.  A nice example of the kind of thing I am thinking of is from the 1982 Conan film, where the wizard opens a gateway to the spirit world to get demons to revive Conan, and where Valeria fights incorporeal demons to save Conan (YouTube, from 6:45 into the clip to the end &amp; onto next clip).

RQ3 had nice mechanics for dealing with these situations, with shamans who can take characters to the other side through their fetch, spirit combat to handle attacks by hostile spirits, using magic points as an orthogonal measure of strength to hit points.  

AD&amp;D was pretty lousy for this kind of thing back in the day: its distinction between combat involving the incorporeal attribute or in the ethereal and astral realms didn't really work for setting up situations.  But newer D&amp;Ds seem to have better resources, though I've not seen this in action.

What good game mechanics are there for handling conflicts with spirits?

Postscript

The kind of thing game mechanics need, I think, to sustain interest in spirits and spirit combat are:


Spirits are immaterial and that means you have to do different sorts of things to influence them.  E.g., if the best way to deal with an ancient ghost is to chop it up with an axe, that'll spil that atmosphere a bit;
Likewise, spirits are potentially powerful adversaries.  Not very high-powered spells that can get rid of most spirits with a 65% chance of success detract from interest;
Characters can be experts in spirits, and it is good if the nature of those experts draws on resonant real-world and fictional atmospheric devices such as shamans, ancestor worship, fetches, and the like.  It's also good if characters regularly need the services of these figures. 

","The Dresden Files

The fate-powered Dresden Files RPG has very good rules for summoning, containing, and controlling spirits / faeries / ghosts / demons.

Each of those three tasks - summoning, containing, and controlling - is dealt with in sufficient detail to be flavorful, but like most of the dresden-files rules, you can skip the boring parts. 

Is your wizard calling a minor friendly, like Toot-Toot? You can probably get away with a single roll. 

Pulling up something from the wrong side of the Nevernever? A big bad Thing that would pick his teeth with your athame if it weren't for that pesky summoning circle? Oh, and is that a pack of howling ghouls hammering at your door while you chat with this critter? Then you're in for all the rolls and attention that such a dramatic, possibly climactic moment deserves.

Sorcerer

Ron Edwards' Sorcerer is all about summoning, binding, and interacting with demons. I have never played it, but I hope to remedy that soon!
"
3769,3769,6001,How has sneaking changed from 3.5 to Pathfinder?,"Was researching this in order to answer How can a Shadowdancer use spring attack with Hide in Plain Sight? I learned a fair amount about these changes and since they&rsquo;re pretty significant, I wanted to write it down.

How have the rules regarding sneaking around changed from Dungeons and Dragons 3.5 to Pathfinder?
",KRyan,https://rpg.stackexchange.com/users/4563,"Skill Consolidation

Hide and Move Silently are now one skill, Stealth. A nice perk for rogues; a nicer perk for those who don&rsquo;t have 8+Int skill points and still want to be sneaky. Also very nice that it&rsquo;s only one roll: less chance of rolling very low and messing up your attempt to sneak. Or, if you do roll high, you don&rsquo;t have to worry about having a mediocre roll on the other.

On the flip side, Spot and Listen have also been consolidated into one skill, Perception. This is still to your benefit when you&rsquo;re sneaking, though, since it means those trying to find you only get to roll one check; there&rsquo;s less chance of an abnormally high roll.

Changes to the effect of Hiding

In 3.5, the effect of hiding was left vague until Rules Compendium. Thankfully, Rules Compendium clarified some things, including the fact that those who fail their Spot check treat you the same way they treat invisible creatures, which means they are flat-footed with respect to you. This is important because that&rsquo;s one of the conditions that qualifies for Sneak Attack.

In Pathfinder, not so much: a successful Stealth check gets you Concealment. In most cases, this is basically useless because you usually need Concealment to use Stealth in the first place. That is, Stealth is often literally giving you what you already had. You can use Stealth with Cover instead of Concealment, in which case you get both, but Cover is much more difficult to manufacture, which makes it much less reliable.

With Hide in Plain Sight, you can give yourself Concealment when you wouldn&rsquo;t have had it. That&rsquo;s nice, but the costs of getting Hide in Plain Sight are very high, and Concealment just isn&rsquo;t that good. All Concealment does is give attackers a 20% chance to miss you. It does not improve your attack or damage in any way. Notably, Concealment is insufficient to trigger Sneak Attack.

Changes to triggering Sneak Attack

On the plus side, constructs, plants, and undead are no longer immune to Sneak Attack. Elementals and oozes still are, as are the new proteans, and things with the incorporeal subtype are immune unless you have Ghost Touch. The 3.5 rogue could overcome these limitations, but it was tricky (required particular wands or feats or ACFs, and often still only did half damage), so this is good.

The good news ends there. As stated, Stealth cannot trigger Sneak Attack. Nor can grease in most cases (and the rules are ambiguous about the cases where it would work), and the blink spell is right-out. Alchemical weapons no longer work either, which is a shame for low-level rogues. Marbles no longer exist. That means a lot of the ways for a solo rogue to generate the conditions required to get Sneak Attack are gone.

As such, you are either going to have to ignore the &ldquo;Sneak&rdquo; aspect of Sneak Attack entirely (and just use Flanking to trigger it), or you&rsquo;re going to need magic, preferably greater invisibility. Rogues get Use Magic Device, but that&rsquo;s an expensive wand.
",KRyan,https://rpg.stackexchange.com/users/4563,http://rpg.stackexchange.com/questions/28864/how-has-sneaking-changed-from-3-5-to-pathfinder,CULTURE,rpg.stackexchange.com,0.7777777777777778,0.7777777777777778,0.0,1.0,0.6666666666666666,1.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.3333333333333333,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,1.0,Sneak attack changed from 3.5 to Pathfinder?,"The purpose of this study is to answer how a shadow dancer can use the spring to attack and hide in sight? I know a lot about these changes, because they are very important, so I want to write them down.","Skill Consolidation

Hide and Move Silently are now one skill, Stealth. A nice perk for rogues; a nicer perk for those who don&rsquo;t have 8+Int skill points and still want to be sneaky. Also very nice that it&rsquo;s only one roll: less chance of rolling very low and messing up your attempt to sneak. Or, if you do roll high, you don&rsquo;t have to worry about having a mediocre roll on the other.

On the flip side, Spot and Listen have also been consolidated into one skill, Perception. This is still to your benefit when you&rsquo;re sneaking, though, since it means those trying to find you only get to roll one check; there&rsquo;s less chance of an abnormally high roll.

Changes to the effect of Hiding

In 3.5, the effect of hiding was left vague until Rules Compendium. Thankfully, Rules Compendium clarified some things, including the fact that those who fail their Spot check treat you the same way they treat invisible creatures, which means they are flat-footed with respect to you. This is important because that&rsquo;s one of the conditions that qualifies for Sneak Attack.

In Pathfinder, not so much: a successful Stealth check gets you Concealment. In most cases, this is basically useless because you usually need Concealment to use Stealth in the first place. That is, Stealth is often literally giving you what you already had. You can use Stealth with Cover instead of Concealment, in which case you get both, but Cover is much more difficult to manufacture, which makes it much less reliable.

With Hide in Plain Sight, you can give yourself Concealment when you wouldn&rsquo;t have had it. That&rsquo;s nice, but the costs of getting Hide in Plain Sight are very high, and Concealment just isn&rsquo;t that good. All Concealment does is give attackers a 20% chance to miss you. It does not improve your attack or damage in any way. Notably, Concealment is insufficient to trigger Sneak Attack.

Changes to triggering Sneak Attack

On the plus side, constructs, plants, and undead are no longer immune to Sneak Attack. Elementals and oozes still are, as are the new proteans, and things with the incorporeal subtype are immune unless you have Ghost Touch. The 3.5 rogue could overcome these limitations, but it was tricky (required particular wands or feats or ACFs, and often still only did half damage), so this is good.

The good news ends there. As stated, Stealth cannot trigger Sneak Attack. Nor can grease in most cases (and the rules are ambiguous about the cases where it would work), and the blink spell is right-out. Alchemical weapons no longer work either, which is a shame for low-level rogues. Marbles no longer exist. That means a lot of the ways for a solo rogue to generate the conditions required to get Sneak Attack are gone.

As such, you are either going to have to ignore the &ldquo;Sneak&rdquo; aspect of Sneak Attack entirely (and just use Flanking to trigger it), or you&rsquo;re going to need magic, preferably greater invisibility. Rogues get Use Magic Device, but that&rsquo;s an expensive wand.
"
2067,2067,3295,How to mount a NTFS USB harddrive to Mac OS X that was unsave removed from Windows?,"I have a hard drive that gets plugged into several machines. One MacBook Pro running Mac OS X, some Ubuntu and Fedora Installations and sometimes Windows XP or Vista. Therefore, I formatted it NTFS to be able to read and write on it no matter which machine is used. On Mac OS I installed MacFUSE to do this. 

The Problem is, when the USB device is removed from a Windows box, without using the ""remove hardware"" function from the task bar, the drive is locked. When I wnat to mount it in Mac OS, I get an error message and have to connect it to back to Windows and cleanly unmount it.

So, my question is: Is there an easy way to use the drive on every computer / OS without mounting problems? 
",Tim Büthe,https://superuser.com/users/3124,"The latest version of NTFS-3G for Mac allows you to force mount the disk, even when it wasn't disconnected properly.
",Loïc Wolff,https://superuser.com/users/51,http://superuser.com/questions/10024,TECHNOLOGY,superuser.com,0.7777777777777778,0.4444444444444444,0.0,0.3333333333333333,1.0,1.0,0.6666666666666666,0.8888888888888888,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.8888888888888888,0.3333333333333333,1.0,1.0,0.6666666666666667,0.6666666666666666,0.0,0.0,1.0,How do I install an unsaved NTFS USB hard disk removed from windows to Mac OS X?,"I have a hard drive that gets plugged into several machines. One MacBook Pro running Mac OS X, some Ubuntu and Fedora Installations and sometimes Windows XP or Vista. Therefore, I formatted it NTFS to be able to read and write on it no matter which machine is used. On Mac OS I installed MacFUSE to do this. 

The Problem is, when the USB device is removed from a Windows box, without using the ""remove hardware"" function from the task bar, the drive is locked. When I wnat to mount it in Mac OS, I get an error message and have to connect it to back to Windows and cleanly unmount it.

So, my question is: Is there an easy way to use the drive on every computer / OS without mounting problems? 
","The latest version of NTFS-3G for Mac allows you to force mount the disk, even when it wasn't disconnected properly.
"
4515,4515,7157,Is there added value in having your own presentation layout and using it consistently?,"From the perspective of a Ph.D. student, how much of an added value is it to have your own presentation slides layout, that is used consistently throughout your Ph.D. conference presentations and other talks (and possibly throughout your academic career afterwards)?

Here is one such example from the Computer Science community.

This as as opposed to using existing Beamer templates with LaTeX, or built-in PowerPoint templates, or simply preparing each presentation on its own (without a specific layout).

A couple of axes I can think along:


Creating a signature layout that distinguishes one in their community
Ease of preparation of presentations (especially over time), maybe overcoming constraints with existing templates.


Note that I am not concerned with the question of content, but just design and layout.
",lyes,https://academia.stackexchange.com/users/15902,"I always appreciate when someone cares about their presentation. There are some things that are just inexcusable (e.g., tables that are left aligned on one slide and centered on another), and make you look lazy, so to the extent a consistent template would mitigate those then it can't hurt. 

My presentations tend to look the same and stand out against my peers. I do all of my writing in Markdown, analyses in R, and create dynamic presentations with some available R packages. Therefore, all of my graphs tend to have a style (ggplot2), tables look the same in HTML, fonts (and related consistencies between headings and body text) work together nicely. It's not just about the style of the presentation, as I know a few people who give presentations and have a very distinctive voice in their text, and a welcomed minimalism in slide content. 

I never thought too much about it, but I do have a ""style"" or ""brand"" in my presentations that most people who have met me and seen me present a few times recognize as clearly a presentation I crafted. However, this ""brand"" is really just me using a specific set of tools that most people don't use. What's the standard for most fields? Unfortunately Powerpoint, and some use the Mac Office Suite, while a few others use Prezi (and most use that tool poorly). 

There's a range of tools out there that you can utilize that might help develop a consistent ""style"" for you, but also will help to vastly improve your workflow, and also make your scholarship better (i.e., tools with an emphasis on reproducibility).

Whatever you do just do it well and make sure it works for you and our audiences. 
",bfoste01,https://academia.stackexchange.com/users/19610,http://academia.stackexchange.com/questions/25822/is-there-added-value-in-having-your-own-presentation-layout-and-using-it-consist,LIFE_ARTS,academia.stackexchange.com,1.0,0.7777777777777778,0.0,0.3333333333333333,1.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,1.0,1.0,0.7777777777777778,1.0,1.0,0.8666666666666666,0.0,0.0,0.6666666666666666,1.0,Is there added value in having your own presentation layout and using it consistently?,"From the perspective of a Ph.D. student, how much of an added value is it to have your own presentation slides layout, that is used consistently throughout your Ph.D. conference presentations and other talks (and possibly throughout your academic career afterwards)?

Here is one such example from the Computer Science community.

This as as opposed to using existing Beamer templates with LaTeX, or built-in PowerPoint templates, or simply preparing each presentation on its own (without a specific layout).

A couple of axes I can think along:


Creating a signature layout that distinguishes one in their community
Ease of preparation of presentations (especially over time), maybe overcoming constraints with existing templates.


Note that I am not concerned with the question of content, but just design and layout.
","I always appreciate when someone cares about their presentation. There are some things that are just inexcusable (e.g., tables that are left aligned on one slide and centered on another), and make you look lazy, so to the extent a consistent template would mitigate those then it can't hurt. 

My presentations tend to look the same and stand out against my peers. I do all of my writing in Markdown, analyses in R, and create dynamic presentations with some available R packages. Therefore, all of my graphs tend to have a style (ggplot2), tables look the same in HTML, fonts (and related consistencies between headings and body text) work together nicely. It's not just about the style of the presentation, as I know a few people who give presentations and have a very distinctive voice in their text, and a welcomed minimalism in slide content. 

I never thought too much about it, but I do have a ""style"" or ""brand"" in my presentations that most people who have met me and seen me present a few times recognize as clearly a presentation I crafted. However, this ""brand"" is really just me using a specific set of tools that most people don't use. What's the standard for most fields? Unfortunately Powerpoint, and some use the Mac Office Suite, while a few others use Prezi (and most use that tool poorly). 

There's a range of tools out there that you can utilize that might help develop a consistent ""style"" for you, but also will help to vastly improve your workflow, and also make your scholarship better (i.e., tools with an emphasis on reproducibility).

Whatever you do just do it well and make sure it works for you and our audiences. 
"
5663,5663,8979,Ideas for synchronizing records programmatically,"I need to synchronize records, say a list of clients, between a local and distant database. The database on both sides has the same structure. I've thought of using some kind of marker (date field, hash/checksum on field values...) but what would you advise ?

Edit: Distant database is on web hosting so PHP will be needed for transferring data.
",James P.,https://stackoverflow.com/users/225899,"If you want to sync two databases by code, you're looking for trouble. 

First of all, you need to handle your own primary key generation, because when inserting records on different sites, primary keys can/will be the same. Unique primary key generation is not easy to accomplish. 

Furthermore, you need some conflict resolution. Updates or Deletes made on either side have to be reflected to the other site. Often, you cannot solve conflicts without user intervention.  

My advise: look at built-in (two-way) replication, native to the database. It will save you a lot of headache.
",JvdBerg,https://stackoverflow.com/users/1617954,http://stackoverflow.com/questions/12437437/ideas-for-synchronizing-records-programmatically,STACKOVERFLOW,stackoverflow.com,1.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,1.0,1.0,1.0,1.0,1.0,0.0,1.0,1.0,1.0,The idea of synchronizing records programmatically,"I need to synchronize records, such as client lists, between local and remote databases. The database structure of both parties is the same. I've considered using some kind of tag (date field, hash / checksum of field values...) , but what do you suggest?","If you want to sync two databases by code, you're looking for trouble. 

First of all, you need to handle your own primary key generation, because when inserting records on different sites, primary keys can/will be the same. Unique primary key generation is not easy to accomplish. 

Furthermore, you need some conflict resolution. Updates or Deletes made on either side have to be reflected to the other site. Often, you cannot solve conflicts without user intervention.  

My advise: look at built-in (two-way) replication, native to the database. It will save you a lot of headache.
"
1029,1029,1620,Is it appropriate to follow up on a faculty application?,"I am currently applying to faculty positions, primarily teaching positions at 4 year colleges and universities. I am told many of these jobs have more than 100-200 applicants. Some of the jobs ads themselves say they get hundreds of applicants, and go on to say something to the effect 'you probably aren't going to hear anything from us', which says to me - 'don't bother us'. I have 3 questions, which overlap:


If I don't hear back from them at all, is it appropriate to contact the department?
If I hear back that they got my application and materials, is it appropriate to contact the department?
People that I know from the business world encourage me to be more aggressive by calling the departments to check in, and even asking if I can come visit the department. I am concerned that this sort of attitude can have a backlash effect. Is this sort of aggressive approach accepted in academia?

",DJBunk,https://academia.stackexchange.com/users/4269,"You should keep in mind that the people running searches are busy academics who are doing this as service to the department. Checking-in aggressively — following your intuition for how this would work in business — will annoy and will be very unlikely to help. At the moment (early/mid- February), it is still early enough in some job markets that interviews have not been scheduled so asking for updates might be seen as pushy. I think it's unlikely that your chances will go down if you ask, but it still might be nicer to wait.

That said, there are many situations where contacting in normal and you might to do it through one of those channels:


For example, if you have another offer from somewhere with a deadline, it is normal — and a good idea — to contact other departments to let them know that you will have to move forward without them. I've had friends who have had interviews offers within hours of telling a department this. 
Also, if you have updated material on your CV (e.g., a paper accepted, positions changed, an award, whatever) go ahead and send your updated CV. You can mention in that email that you're excited to hear about any updates from their search.


Contacting search committees in this context is normal and can signal that you continue to be very interested in a job. I was told by a search committee that ended up making an offer that they thought I might be unlikely to accept an offer and that one of these update emails rovided a useful signal. Of course, if they're not interested, emailing will probably just be noise and extra work for them.

I think that emailing or not-emailing is unlikely to tip the scale either way. They're going to make a decision based on the intersection of the quality of your work and what they're interested in having in their department. But out of kindness for the work of the search committee and its chair, try to do it as little as possible.
",Benjamin Mako Hill,https://academia.stackexchange.com/users/5962,http://academia.stackexchange.com/questions/7955/is-it-appropriate-to-follow-up-on-a-faculty-application,LIFE_ARTS,academia.stackexchange.com,1.0,0.7777777777777778,0.0,0.6666666666666666,0.0,0.6666666666666666,0.8888888888888888,1.0,0.3333333333333333,0.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,1.0,1.0,0.7777777777777778,1.0,1.0,0.9333333333333332,0.0,0.6666666666666666,0.3333333333333333,1.0,Is it appropriate to follow up the teacher application?,"I am currently applying to faculty positions, primarily teaching positions at 4 year colleges and universities. I am told many of these jobs have more than 100-200 applicants. Some of the jobs ads themselves say they get hundreds of applicants, and go on to say something to the effect 'you probably aren't going to hear anything from us', which says to me - 'don't bother us'. I have 3 questions, which overlap:


If I don't hear back from them at all, is it appropriate to contact the department?
If I hear back that they got my application and materials, is it appropriate to contact the department?
People that I know from the business world encourage me to be more aggressive by calling the departments to check in, and even asking if I can come visit the department. I am concerned that this sort of attitude can have a backlash effect. Is this sort of aggressive approach accepted in academia?

","You should keep in mind that the people running searches are busy academics who are doing this as service to the department. Checking-in aggressively — following your intuition for how this would work in business — will annoy and will be very unlikely to help. At the moment (early/mid- February), it is still early enough in some job markets that interviews have not been scheduled so asking for updates might be seen as pushy. I think it's unlikely that your chances will go down if you ask, but it still might be nicer to wait.

That said, there are many situations where contacting in normal and you might to do it through one of those channels:


For example, if you have another offer from somewhere with a deadline, it is normal — and a good idea — to contact other departments to let them know that you will have to move forward without them. I've had friends who have had interviews offers within hours of telling a department this. 
Also, if you have updated material on your CV (e.g., a paper accepted, positions changed, an award, whatever) go ahead and send your updated CV. You can mention in that email that you're excited to hear about any updates from their search.


Contacting search committees in this context is normal and can signal that you continue to be very interested in a job. I was told by a search committee that ended up making an offer that they thought I might be unlikely to accept an offer and that one of these update emails rovided a useful signal. Of course, if they're not interested, emailing will probably just be noise and extra work for them.

I think that emailing or not-emailing is unlikely to tip the scale either way. They're going to make a decision based on the intersection of the quality of your work and what they're interested in having in their department. But out of kindness for the work of the search committee and its chair, try to do it as little as possible.
"
3665,3665,5845,What does 'liberal to' mean here?,"
  Any state
  that makes its choices after most others do will find itself playing in the
  late innings of a game, as the West Virginia Supreme Court found in a
  case about whether car makers were responsible if their vehicles failed to
  protect people who negligently got into accidents:
  
  
    ...[I]n some world other than the one in which we live, where this Court
    were called upon to make national policy, we might very well take a meat
    ax to some current product liability rules. Therefore, we do not claim that
    our adoption of rules liberal to plaintiffs comports[,] necessarily, with some
    Platonic ideal of perfect justice.
  


Source: p 124, The Legal Analyst, Ward Farnsworth

My guess is Definition 1.1 below. Yet is this use right? 


  Favourable to or respectful of individual rights and freedoms:


The definition concerns 'right and freedoms', while the context is individuals (as plaintiffs)
",Canada - Area 51 Proposal,https://ell.stackexchange.com/users/8712,"""Liberal""in this context means ""generous."" The liberal to, part is  in reference to a certain group, the plaintiffs. So the whole phrase means generous to the plaintiffs.
",Tom Au,https://ell.stackexchange.com/users/1355,http://ell.stackexchange.com/questions/31990/what-does-liberal-to-mean-here,CULTURE,ell.stackexchange.com,1.0,0.3333333333333333,0.0,1.0,1.0,1.0,0.4444444444444444,0.7777777777777778,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,0.3333333333333333,0.8888888888888888,"What does ""freedom"" mean here?","
  Any state
  that makes its choices after most others do will find itself playing in the
  late innings of a game, as the West Virginia Supreme Court found in a
  case about whether car makers were responsible if their vehicles failed to
  protect people who negligently got into accidents:
  
  
    ...[I]n some world other than the one in which we live, where this Court
    were called upon to make national policy, we might very well take a meat
    ax to some current product liability rules. Therefore, we do not claim that
    our adoption of rules liberal to plaintiffs comports[,] necessarily, with some
    Platonic ideal of perfect justice.
  


Source: p 124, The Legal Analyst, Ward Farnsworth

My guess is Definition 1.1 below. Yet is this use right? 


  Favourable to or respectful of individual rights and freedoms:


The definition concerns 'right and freedoms', while the context is individuals (as plaintiffs)
","""Liberal""in this context means ""generous."" The liberal to, part is  in reference to a certain group, the plaintiffs. So the whole phrase means generous to the plaintiffs.
"
3054,3054,4864,Is there an algorithm to generate digitally signed URL links?,"Scenario:


Alice prepares an URL link to Bob's web service (e.g., http://www.bob.com/sensitiveData/123?login=mallory).
Alice gives the URL link to Mallory.
Mallory follows the link to trigger an action in Bob's system.


Alice's link is intended for Mallory. Note that Mallory is authenticated by Alice but not by Bob. Bob does not know Mallory, but he trusts Alice. So if Alice has authorized Mallory to perform the action, Bob will blindly execute it.

The problem: How can Bob be sure that it is really Alice's link and that Mallory has not modified it in step 2?

In theory, such problems can be solved by a digital signature with a public-key algorithm. Alice could generate a signature of the link with her private key and append it to the URL, for example, http://www.bob.com/sensitiveData/123?login=mallory&amp;signiture=&lt;SOME-SIGNITURE&gt;).

How do you generate the signature? As an experiment, I just tried gpg --encrypt but the results are quite huge. Additionally, it has to be encoded to use it inside an URL (e.g., with Base64), which will make it even larger.

As I'm not very experienced with cryptographic algorithms and protocols, I wanted to ask whether there is an well-known solution to the problem of generating signed URLs?

If not, do you see any flaw in my approach? Do you have any recommendation for the generation of the signature that can be appended to the link? If possible, it should be relatively short.



Just for clarification: Unfortunately, it is not possible to change the overall protocol. Of course, it would be safer if Alice and Bob could directly communicate over an encrypted connection. Additionally, Mallory should have to ask Alice to tell Bob to trigger the action, or Bob should have the option to ask Alice to authorize the action.
",Philipp Claßen,https://security.stackexchange.com/users/18241,"A RSA signature has the length of the modulus: if using the usual 2048-bit key size, then signatures are 256-byte long. Since you want to fit the signature within a URL, which is text-based, you must have some sort of encoding such as Base64, which implies some size overhead; with Base64, 256 bytes will become 342 characters -- that makes for URL of quite respectable length.

DSA (and its highly fashionable elliptic-curve variant ECDSA) offers smaller signatures; you can get very decent security (as much as 2048-bit RSA) with signatures of size 60 bytes or so -- there again, Base64 encoding inflates that to 80 characters.

If you need even smaller signatures, then you must go to less mainstream algorithms, e.g. BLS, which offers signatures twice smaller than DSA. But the maths are fiendishly more complex, and there is no standard, only scientific papers.

Alternatively, you may want to use RSA with ISO 9796-2 signatures (not PKCS#1). You will get 256-byte signatures, but you may then smuggle some of your application data within the signature itself. As a rough approximation, you will get your n-bit security with a total overhead of about 3n bits; albeit with a minimal message size of 256 bytes.

Theoretical limit: if you want a security level of n bits (meaning that attackers are assumed not to be able to run computations which need more than 2n elementary operations), then the signature size cannot be less than n bits either. Indeed, an attacker could try brute force on the signature, trying out all possible signature values and using the signature verification algorithm (which uses Alice's public key, which is public, hence known to the attacker) until a matching signature is found.

However, there is no currently known secure digital signature algorithm which offers n-bit security with n-bit signatures. DSA needs to use 4n-bit signatures to offer n-bit security. BLS lowers that to 2n bits. There have been proposals for some other algorithm types which could reach down to 1.5n bits or so, but right now they all turned out to be flawed in some way.



It may be possible that you could change your model slightly. For instance, Alice and Bob may share some secret value; Bob then does not really trust ""Alice"" but rather ""whoever knows the secret value, which happens to be known to both Alice and Bob"". In that case, you can rely on a MAC algorithm instead of a digital signature; you can think of MAC algorithms as signatures where the key to sign and the key to verify are the same.

It is a change of context. Depending on who Alice and Bob are in your system, sharing a secret may or may not be possible. Using a MAC forfeits most chances at non-repudiation. It also means that Bob can himself produce URL that he will accept. Yet, if you can tolerate the use of a MAC, then you can get very short verification elements. In fact, you can even get below n bits because exhaustive search can no longer be applied: since the MAC verification key is secret, the attacker cannot try MAC values and decide whether they are correct on his own machines. To ""try"" a potential MAC value, the attacker MUST then send it to Bob, and see if Bob is happy with it or not. After a million tries or so, Bob may begin to suspect foul play and apply countermeasures (e.g. cease to respond to that decidedly dodgy requester).

In that sense, a MAC value of length 64 bits ought to be sufficient. That's just 8 bytes -- encodable with Base64 as 11 characters. HMAC is a widely implemented MAC algorithm with good repute.



There is no well-established standard for ""signed URL"". Every site designer works out his own scheme, which is unfortunate because homemade cryptography is one of the surest paths to disaster. The conceptual model, though, is sound: basically, you want Mallory to convey a message from Alice to Bob, such that Bob can know that the message really comes from Alice, and was not altered or even invented altogether by Mallory. That the message travels as a ""URL"" is a mere encoding constraint which has no impact on the concept.

A MAC or a signature is indeed the right tool here. Beware, though, of replay attacks: if Mallory has an Alice-signed URL that Bob will accept, Mallory may try to send that URL twice to Bob, to get twice the effect. Depending on your context, this may or may not be a problem. If it is, then Bob MUST enforce some protection mechanism, e.g. remembering past requests to reject duplicates. A time stamp within the URL data (under cover of the MAC or signature) can help Bob keep track of seen URL (i.e. Bob can forget ""expired"" URL since he won't accept them any more).
",Thomas Pornin,https://security.stackexchange.com/users/655,http://security.stackexchange.com/questions/58000/is-there-an-algorithm-to-generate-digitally-signed-url-links,TECHNOLOGY,security.stackexchange.com,0.7777777777777778,0.5555555555555556,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.5555555555555556,0.3333333333333333,0.6666666666666666,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.0,1.0,1.0,0.7777777777777778,1.0,1.0,0.9,0.3333333333333333,0.3333333333333333,0.6666666666666666,1.0,Is there an algorithm for generating digitally signed URL links?,"Scenario:


Alice prepares an URL link to Bob's web service (e.g., http://www.bob.com/sensitiveData/123?login=mallory).
Alice gives the URL link to Mallory.
Mallory follows the link to trigger an action in Bob's system.


Alice's link is intended for Mallory. Note that Mallory is authenticated by Alice but not by Bob. Bob does not know Mallory, but he trusts Alice. So if Alice has authorized Mallory to perform the action, Bob will blindly execute it.

The problem: How can Bob be sure that it is really Alice's link and that Mallory has not modified it in step 2?

In theory, such problems can be solved by a digital signature with a public-key algorithm. Alice could generate a signature of the link with her private key and append it to the URL, for example, http://www.bob.com/sensitiveData/123?login=mallory&amp;signiture=&lt;SOME-SIGNITURE&gt;).

How do you generate the signature? As an experiment, I just tried gpg --encrypt but the results are quite huge. Additionally, it has to be encoded to use it inside an URL (e.g., with Base64), which will make it even larger.

As I'm not very experienced with cryptographic algorithms and protocols, I wanted to ask whether there is an well-known solution to the problem of generating signed URLs?

If not, do you see any flaw in my approach? Do you have any recommendation for the generation of the signature that can be appended to the link? If possible, it should be relatively short.



Just for clarification: Unfortunately, it is not possible to change the overall protocol. Of course, it would be safer if Alice and Bob could directly communicate over an encrypted connection. Additionally, Mallory should have to ask Alice to tell Bob to trigger the action, or Bob should have the option to ask Alice to authorize the action.
","A RSA signature has the length of the modulus: if using the usual 2048-bit key size, then signatures are 256-byte long. Since you want to fit the signature within a URL, which is text-based, you must have some sort of encoding such as Base64, which implies some size overhead; with Base64, 256 bytes will become 342 characters -- that makes for URL of quite respectable length.

DSA (and its highly fashionable elliptic-curve variant ECDSA) offers smaller signatures; you can get very decent security (as much as 2048-bit RSA) with signatures of size 60 bytes or so -- there again, Base64 encoding inflates that to 80 characters.

If you need even smaller signatures, then you must go to less mainstream algorithms, e.g. BLS, which offers signatures twice smaller than DSA. But the maths are fiendishly more complex, and there is no standard, only scientific papers.

Alternatively, you may want to use RSA with ISO 9796-2 signatures (not PKCS#1). You will get 256-byte signatures, but you may then smuggle some of your application data within the signature itself. As a rough approximation, you will get your n-bit security with a total overhead of about 3n bits; albeit with a minimal message size of 256 bytes.

Theoretical limit: if you want a security level of n bits (meaning that attackers are assumed not to be able to run computations which need more than 2n elementary operations), then the signature size cannot be less than n bits either. Indeed, an attacker could try brute force on the signature, trying out all possible signature values and using the signature verification algorithm (which uses Alice's public key, which is public, hence known to the attacker) until a matching signature is found.

However, there is no currently known secure digital signature algorithm which offers n-bit security with n-bit signatures. DSA needs to use 4n-bit signatures to offer n-bit security. BLS lowers that to 2n bits. There have been proposals for some other algorithm types which could reach down to 1.5n bits or so, but right now they all turned out to be flawed in some way.



It may be possible that you could change your model slightly. For instance, Alice and Bob may share some secret value; Bob then does not really trust ""Alice"" but rather ""whoever knows the secret value, which happens to be known to both Alice and Bob"". In that case, you can rely on a MAC algorithm instead of a digital signature; you can think of MAC algorithms as signatures where the key to sign and the key to verify are the same.

It is a change of context. Depending on who Alice and Bob are in your system, sharing a secret may or may not be possible. Using a MAC forfeits most chances at non-repudiation. It also means that Bob can himself produce URL that he will accept. Yet, if you can tolerate the use of a MAC, then you can get very short verification elements. In fact, you can even get below n bits because exhaustive search can no longer be applied: since the MAC verification key is secret, the attacker cannot try MAC values and decide whether they are correct on his own machines. To ""try"" a potential MAC value, the attacker MUST then send it to Bob, and see if Bob is happy with it or not. After a million tries or so, Bob may begin to suspect foul play and apply countermeasures (e.g. cease to respond to that decidedly dodgy requester).

In that sense, a MAC value of length 64 bits ought to be sufficient. That's just 8 bytes -- encodable with Base64 as 11 characters. HMAC is a widely implemented MAC algorithm with good repute.



There is no well-established standard for ""signed URL"". Every site designer works out his own scheme, which is unfortunate because homemade cryptography is one of the surest paths to disaster. The conceptual model, though, is sound: basically, you want Mallory to convey a message from Alice to Bob, such that Bob can know that the message really comes from Alice, and was not altered or even invented altogether by Mallory. That the message travels as a ""URL"" is a mere encoding constraint which has no impact on the concept.

A MAC or a signature is indeed the right tool here. Beware, though, of replay attacks: if Mallory has an Alice-signed URL that Bob will accept, Mallory may try to send that URL twice to Bob, to get twice the effect. Depending on your context, this may or may not be a problem. If it is, then Bob MUST enforce some protection mechanism, e.g. remembering past requests to reject duplicates. A time stamp within the URL data (under cover of the MAC or signature) can help Bob keep track of seen URL (i.e. Bob can forget ""expired"" URL since he won't accept them any more).
"
4662,4662,7386,Why did OCP build Robocop?,"It seems like building the Robocop was a really stupid business approach:


You can't build them on industrial scale (to put it somewhat insensitively, OCP didn't have a ready supply of highly trained and freshly killed police officers)

So, Robocop seemed like a prototype that could never have entered production. Total waste of R&amp;D money.
And having a police brain (because he already know police procedure) seems not necessary since at the same time OCP could build fully AI robots (from robot chicken, flawed as it was, in Robocop 1, to Ninja Androids in Robocop 3).

",DVK-on-Ahch-To,https://scifi.stackexchange.com/users/976,"The concept of Robocop is not to substitute human police, it is the idea of a super reinforcement for police departments.

Of course they won't be able to enter on an industrial production scale, however, maybe one or two of them could be deployed in almost every big city, that would be a huge business as I can assure you that such a project is not a cheap one, although it's results are out of question. I'm sure every city mayor would like to have one or two of them on their police departments.

Also... he's a prototype. The I+D research is a continual loop where you evolve your product, getting better functionalities with each iteration and cutting down construction costs. With time the cyborg integration would probably be applied to live volunteers, in fact I supose that's the real objective, however you cannot risk human volunteer lives in such a project withour previous tests, usually you use rats, or monkeys, but for this project they needed a human-like system to build.
",Bardo,https://scifi.stackexchange.com/users/11069,http://scifi.stackexchange.com/questions/46596/why-did-ocp-build-robocop,LIFE_ARTS,scifi.stackexchange.com,1.0,1.0,1.0,1.0,0.0,0.0,0.8333333333333334,0.6666666666666666,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,1.0,Why does OCP build Robocop?,"It seems like building the Robocop was a really stupid business approach:


You can't build them on industrial scale (to put it somewhat insensitively, OCP didn't have a ready supply of highly trained and freshly killed police officers)

So, Robocop seemed like a prototype that could never have entered production. Total waste of R&amp;D money.
And having a police brain (because he already know police procedure) seems not necessary since at the same time OCP could build fully AI robots (from robot chicken, flawed as it was, in Robocop 1, to Ninja Androids in Robocop 3).

","The concept of Robocop is not to substitute human police, it is the idea of a super reinforcement for police departments.

Of course they won't be able to enter on an industrial production scale, however, maybe one or two of them could be deployed in almost every big city, that would be a huge business as I can assure you that such a project is not a cheap one, although it's results are out of question. I'm sure every city mayor would like to have one or two of them on their police departments.

Also... he's a prototype. The I+D research is a continual loop where you evolve your product, getting better functionalities with each iteration and cutting down construction costs. With time the cyborg integration would probably be applied to live volunteers, in fact I supose that's the real objective, however you cannot risk human volunteer lives in such a project withour previous tests, usually you use rats, or monkeys, but for this project they needed a human-like system to build.
"
2418,2418,3857,"Without using dowels, how do I join 2x4s edge to edge to be 1.5"" x 7""?","I am trying to join a 2x4 supporting a workbench tabletop to another to make a backsplash of sorts. Any ideas how to do this without dowels? (No, I can't use 2x8)


",Jens Turner,https://diy.stackexchange.com/users/15656,"I would definitely use Pocket-hole joinery

My brother got me a jig that is very easy to use, and the joints are incredibly strong even without wood glue; also if you use glue the joins are ""self clamping"".

Basically this allows you to edge-join, or do 45 degree angles, etc. just by drilling a couple of perfectly angled holes and screwing the pieces together such that the screw doesn't protrude from your work.

Obviously, I wouldn't get a jig for just one project, but I have totally stopped using dowels, biscuits, and other fancy techniques in favor of pocket holes.

Hope this helps!
",bebryan,https://diy.stackexchange.com/users/15667,http://diy.stackexchange.com/questions/32868/without-using-dowels-how-do-i-join-2x4s-edge-to-edge-to-be-1-5-x-7,LIFE_ARTS,diy.stackexchange.com,1.0,0.6666666666666666,0.0,0.3333333333333333,1.0,0.6666666666666666,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.7777777777777778,"How do I connect 2x4s edge to edge as 1.5 ""x 7"" without the use of dowels?","I'm trying to add a 2x4 support to one workbench desktop to another, to make one backward. Is there any way to do it without pins? (no, I can't use 2x8)","I would definitely use Pocket-hole joinery

My brother got me a jig that is very easy to use, and the joints are incredibly strong even without wood glue; also if you use glue the joins are ""self clamping"".

Basically this allows you to edge-join, or do 45 degree angles, etc. just by drilling a couple of perfectly angled holes and screwing the pieces together such that the screw doesn't protrude from your work.

Obviously, I wouldn't get a jig for just one project, but I have totally stopped using dowels, biscuits, and other fancy techniques in favor of pocket holes.

Hope this helps!
"
5219,5219,8297,How to display zero value as blank cell in mac numbers 3.1,"How do I display zero value as blank cell in mac numbers 3.1 yet maintain a formula.  I want a running balance column that only shows balance to the line of the last entry like a checkbook register.
Thanks.
",user69881,https://apple.stackexchange.com/users/69881,"The easiest way is to use ""Conditional Highlighting..."" found under the ""Format"" menu.

Select the cell you want to have blank as zero then select ""Conditional Highlighting"" you then set a highlight when the cell is equal to zero. Choose  ""Custom Highlighting"" at the bottom of the style list and then you can set the text colour to white. A ""blank"" cell on zero.
",Tony Williams,https://apple.stackexchange.com/users/40544,http://apple.stackexchange.com/questions/120359/how-to-display-zero-value-as-blank-cell-in-mac-numbers-3-1,TECHNOLOGY,apple.stackexchange.com,0.8888888888888888,0.7777777777777778,0.0,1.0,0.6666666666666666,1.0,0.5,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.0,0.0,0.8888888888888888,How to display zero value as blank cell in MAC number 3.1,"How to display the zero value as a blank cell in MAC number 3.1 while keeping the formula. I want a running balance column that shows only the balance to the last entry row, just like a checkbook register.","The easiest way is to use ""Conditional Highlighting..."" found under the ""Format"" menu.

Select the cell you want to have blank as zero then select ""Conditional Highlighting"" you then set a highlight when the cell is equal to zero. Choose  ""Custom Highlighting"" at the bottom of the style list and then you can set the text colour to white. A ""blank"" cell on zero.
"
5285,5285,8393,JQuery .replaceWith() html element to div class,"I want to replace 

&lt;div class=""blog""&gt;Blog&lt;/h1&gt;


with

&lt;h1&gt;Blog&lt;/h1&gt;


which is inside a class name ""sidebar""

I used this code but didn't work:

$(window).load(function() {
    $( "".sidebar h1"" ).replaceWith( ""&lt;div class=""blog""&gt;Blog&lt;/h1&gt;"" );
}


What is wrong on my code?
",Chris Phi,https://stackoverflow.com/users/5170888,"Firstly, your opening a div tag and closing an h1 tag.

Secondly, your quotes are mismatched within the .replaceWith bit.

I would do this instead:

&lt;h1 id=""replaceme""&gt;Blog&lt;/h1&gt;
&lt;script&gt;
$(window).load(function() {
    $(""#replaceme"").replaceWith('&lt;div class=""blog""&gt;Blog&lt;/div&gt;');

",SteJ,https://stackoverflow.com/users/2946845,http://stackoverflow.com/questions/31710021/jquery-replacewith-html-element-to-div-class,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.3333333333333333,0.0,1.0,1.0,1.0,0.6666666666666666,0.4444444444444444,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.8888888888888888,JQuery. Replacewith() HTML element to div class,"I want to replace 

&lt;div class=""blog""&gt;Blog&lt;/h1&gt;


with

&lt;h1&gt;Blog&lt;/h1&gt;


which is inside a class name ""sidebar""

I used this code but didn't work:

$(window).load(function() {
    $( "".sidebar h1"" ).replaceWith( ""&lt;div class=""blog""&gt;Blog&lt;/h1&gt;"" );
}


What is wrong on my code?
","Firstly, your opening a div tag and closing an h1 tag.

Secondly, your quotes are mismatched within the .replaceWith bit.

I would do this instead:

&lt;h1 id=""replaceme""&gt;Blog&lt;/h1&gt;
&lt;script&gt;
$(window).load(function() {
    $(""#replaceme"").replaceWith('&lt;div class=""blog""&gt;Blog&lt;/div&gt;');

"
3888,3888,6194,Powering a Futaba S3003 servo,"I'm working on a project and I need to use a Futaba S3003 servo, I'm about to buy a transformer that gives 6v, the thing I'm not sure about is the amperage.

Is this transformer ok? I can choose 3V, 4.5V, 6V, 7.5V, 9V and 12V, but its 800mA and I don't know if it is OK with the servo.

EDIT:
Link to servo datasheet: http://www.es.co.th/schemetic/pdf/et-servo-s3003.pdf

The transformer is only for powering the servo


",elunicotomas,https://electronics.stackexchange.com/users/54454,"I'm going to do a bit of math on this and make some outlandish assumptions because the data sheet does not give enough information. Stall torque is reckoned to be about ~3.5 kg.cm and full speed is reckoned to be about ~0.2 seconds per 60 degrees of rotation.

Many thanks to Brian Drummond for correcting my stupid math mistake so here's the corrected answer with a bit more theory. First, it is a fair assumption that the servo will contain a small dc motor and, generally, this is the torque-speed characteristic for such a motor: -



Note the blue line - at zero speed, torque is maximum (stall torque) and with no load (zero mechanical torque other than losses in the bearings), speed is maximum. This is just a graph of any old motor I stole from the internet BUT it is largely representative of all DC motors.

Now look at the red curve - this is mechanical power out and equates to: -

Mechanical power = \$2\pi n T\$ where n is revs per second and T is torque in newton metres (N.m)

So, the 3.5 kg.cm translates to approximately 35 N.cm or about 0.35 N.m 

A ""speed"" of 0.2 seconds per 60 degrees is upside down but, rearranging, it basically means 0.166 revs per fifth of a second and this translates to 0.833 revs per second.

Go back to the graph and note that max power is roughly when both torque and speed are at their respective half values therefore,

Power is \$2 \times\pi \times (0.833/2) \times (0.35/2)\$ = 0.458 watts

This is the peak mechanical output power I have estimated from the limited information in the data sheet. Of course it might be a bit higher or lower. 

Next, a motor this small may not be very efficient at converting electrical power to mechancial power so we need to apply a ""frig"" factor. Let's say it's 50% efficient. This now means the input electical power might be about 0.9 watts.

There is a lot of hand waving here and to play a little more safely you might assume that the power supply needs to supply maybe double this value. I suspect there will be a little H bridge controller inside the servo and this might only be 50% efficient so maybe 2 watts should cover most eventualities.

Please insert your own numbers and frig factors into the equations if you think I may have over-egged the omelette.
",Andy aka,https://electronics.stackexchange.com/users/20218,http://electronics.stackexchange.com/questions/178416/powering-a-futaba-s3003-servo,TECHNOLOGY,electronics.stackexchange.com,0.8333333333333334,0.5,0.0,1.0,1.0,1.0,0.5,0.3333333333333333,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.5,0.0,1.0,0.0,0.6666666666666666,1.0,0.8333333333333334,1.0,0.6666666666666666,0.9,0.5,0.0,1.0,1.0,Power supply for Futaba s3003 servo,"I'm working on a project and I need to use a Futaba S3003 servo, I'm about to buy a transformer that gives 6v, the thing I'm not sure about is the amperage.

Is this transformer ok? I can choose 3V, 4.5V, 6V, 7.5V, 9V and 12V, but its 800mA and I don't know if it is OK with the servo.

EDIT:
Link to servo datasheet: http://www.es.co.th/schemetic/pdf/et-servo-s3003.pdf

The transformer is only for powering the servo


","I'm going to do a bit of math on this and make some outlandish assumptions because the data sheet does not give enough information. Stall torque is reckoned to be about ~3.5 kg.cm and full speed is reckoned to be about ~0.2 seconds per 60 degrees of rotation.

Many thanks to Brian Drummond for correcting my stupid math mistake so here's the corrected answer with a bit more theory. First, it is a fair assumption that the servo will contain a small dc motor and, generally, this is the torque-speed characteristic for such a motor: -



Note the blue line - at zero speed, torque is maximum (stall torque) and with no load (zero mechanical torque other than losses in the bearings), speed is maximum. This is just a graph of any old motor I stole from the internet BUT it is largely representative of all DC motors.

Now look at the red curve - this is mechanical power out and equates to: -

Mechanical power = \$2\pi n T\$ where n is revs per second and T is torque in newton metres (N.m)

So, the 3.5 kg.cm translates to approximately 35 N.cm or about 0.35 N.m 

A ""speed"" of 0.2 seconds per 60 degrees is upside down but, rearranging, it basically means 0.166 revs per fifth of a second and this translates to 0.833 revs per second.

Go back to the graph and note that max power is roughly when both torque and speed are at their respective half values therefore,

Power is \$2 \times\pi \times (0.833/2) \times (0.35/2)\$ = 0.458 watts

This is the peak mechanical output power I have estimated from the limited information in the data sheet. Of course it might be a bit higher or lower. 

Next, a motor this small may not be very efficient at converting electrical power to mechancial power so we need to apply a ""frig"" factor. Let's say it's 50% efficient. This now means the input electical power might be about 0.9 watts.

There is a lot of hand waving here and to play a little more safely you might assume that the power supply needs to supply maybe double this value. I suspect there will be a little H bridge controller inside the servo and this might only be 50% efficient so maybe 2 watts should cover most eventualities.

Please insert your own numbers and frig factors into the equations if you think I may have over-egged the omelette.
"
5431,5431,8622,How to extract name/data from database and use it as my folder name which is created dynamically in asp.net c# using server.MapPath()?,"I have used AjaxFileUpload to upload multiple image files. Now i want to store the uploaded images inside rootfolder>subfolder. 

The rootfolder is in the name of the user.
The rootfolder is created dynamically by taking the session of the user who has logged in 
Like this:  

string username = Session[""username""].ToString();


I am able to create this folder and save images in it. but i want to save it in subfolder.

the subfolder is also created dynamically but this time i have to take the value(id) from the database and name the folder by that id name. (this is so that i can refer to the database)

I know how to create a new folder using Server.MapPath();
Here is the code for it in brief

using System.IO
if (Directory.Exists(Server.MapPath(uploadPath))) return;
else Directory.CreateDirectory(Server.MapPath(uploadPath));


where uploadPath is the folder's name i want to create dynamiclly.

but how do I include the subfolder too in my Server.MapPath() so as to make my path as rootfolder/subfolder ?

Small example to make the question understandable.
I am a seller. I have posted 4 ads online.
Now when i am posting my 5th ad i want to include many images. 
these images should be saved in the folder 

Seller/5/imagename.jpg. 
(where Seller is the username(main folder), 5 is the advertID in the database and the name of the subfolder)

How do i do this? Please help.
I am using asp.net c# 
",user2106271,https://stackoverflow.com/users/2106271,"User Path.Combine to add your root and the user id:

   var userPath = Path.Combine(uploadPath,userID) 


This is the safest way to create what you need. The Directory.CreateDirectory method will create all the subfolders as needed:

 var userPath = Path.Combine(uploadPath,userID) 
if (Directory.Exists(Server.MapPath(userPath))) return;
else Directory.CreateDirectory(Server.MapPath(userPath));

",Almond,https://stackoverflow.com/users/1603,http://stackoverflow.com/questions/21164125/how-to-extract-name-data-from-database-and-use-it-as-my-folder-name-which-is-cre,STACKOVERFLOW,stackoverflow.com,0.8333333333333334,0.6666666666666666,0.0,0.0,1.0,1.0,0.6666666666666666,0.4444444444444444,0.5,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,0.8333333333333334,0.6666666666666666,1.0,0.8333333333333334,0.8,1.0,0.5,0.5,0.8333333333333334,How to extract the name / data from the database and use it as a folder name created dynamically in ASP. Net C using server. Mappath()?,"I have used AjaxFileUpload to upload multiple image files. Now i want to store the uploaded images inside rootfolder>subfolder. 

The rootfolder is in the name of the user.
The rootfolder is created dynamically by taking the session of the user who has logged in 
Like this:  

string username = Session[""username""].ToString();


I am able to create this folder and save images in it. but i want to save it in subfolder.

the subfolder is also created dynamically but this time i have to take the value(id) from the database and name the folder by that id name. (this is so that i can refer to the database)

I know how to create a new folder using Server.MapPath();
Here is the code for it in brief

using System.IO
if (Directory.Exists(Server.MapPath(uploadPath))) return;
else Directory.CreateDirectory(Server.MapPath(uploadPath));


where uploadPath is the folder's name i want to create dynamiclly.

but how do I include the subfolder too in my Server.MapPath() so as to make my path as rootfolder/subfolder ?

Small example to make the question understandable.
I am a seller. I have posted 4 ads online.
Now when i am posting my 5th ad i want to include many images. 
these images should be saved in the folder 

Seller/5/imagename.jpg. 
(where Seller is the username(main folder), 5 is the advertID in the database and the name of the subfolder)

How do i do this? Please help.
I am using asp.net c# 
","User Path.Combine to add your root and the user id:

   var userPath = Path.Combine(uploadPath,userID) 


This is the safest way to create what you need. The Directory.CreateDirectory method will create all the subfolders as needed:

 var userPath = Path.Combine(uploadPath,userID) 
if (Directory.Exists(Server.MapPath(userPath))) return;
else Directory.CreateDirectory(Server.MapPath(userPath));

"
3867,3867,6157,Can Noether's theorem be understood intuitively?,"Noether's theorem is one of those surprisingly clear results of mathematical calculations, for which I am inclined to think that some kind of intuitive understanding should or must be possible. However I don't know of any, do you?

Independence of time &lt;=> energy conservation.
Independence of position &lt;=> momentum conservation.
Independence of direction &lt;=> angular momentum conservation.  

I know that the mathematics leads in the direction of Lie-algebra and such but I would like to discuss whether this theorem can be understood from a non-mathematical point of view also.
",Gerard,https://physics.stackexchange.com/users/139,"Well, I don't know about any intuitive explanation besides intuition gained by understanding the underlying math (mainly differential geometry, Hamiltonian mechanics and group theory). So with the risk of not giving you quite what you want, I'll try to approach the problem mathematically.

If you know Hamiltonian mechanics then the statement of the theorem is exceedingly simple. Assume we have a Hamiltonian $H$. To this there is associated a unique Hamiltonian flow (i.e. a one-parameter family of symplectomorphisms -- which is just a fancy name for diffeomorphisms preserving the symplectic structure) $\Phi_H(t)$ on the manifold. From the point of view of Lie theory, the flow is a group action and there exists its generator (which is a vector field) $V_H$ (this can also be obtained from $\omega(\cdot, V_H) = dH$ with $\omega$ being the symplectic form). Now, the completely same stuff can be written for some other function $A$, with generator $V_A$ and flow $\Phi_A(s)$. Think of this $A$ as some conserved quantity and of $\Phi_A(s)$ as a continuous family of symmetries.

Now, starting from Hamiltonian equation ${{\rm d} A \over {\rm d} t} = \left\{A,H\right\}$ we see that if $A$ Poisson-commutes with $H$ it is conserved. Now, this is not the end of the story. From the second paragraph it should be clear that $A$ and $H$ don't differ that much. Actually, what if we swapped them? Then we'd get ${{\rm d} H \over {\rm d} s} = \left\{H,A\right\}$. So we see that $A$ is constant along Hamiltonian flow (i.e. conserved) if and only if $H$ is constant along the symmetry flow (i.e. the physical laws are symmetric).

So much for why the stuff works. Now, how do we get from symmetries to conserved quantities? This actually isn't hard at all but requires some knowledge of differential geometry. Let's start with most simple example.

Translation

This is a symmetry such that $x \to x^\prime = x + a$. You can imagine that we move our coordinates along the $x$ direction. With $a$ being a parameter, this is a symmetry flow. If we differentiate with respect to this parameter, we'll get a vector field. Here it'll be $\partial_x$ (i.e. constant vector field aiming in the direction $x$). Now, what function on the symplectic manifold does it correspond to? Easy, it must be $p$ because by differentiating this we'll get a constant 1-form field $dp$ and then we have to use $\omega$ to get a vector field $\partial_x$.

Other way to see that it must be $p$: suppose you have a wave $\exp(ipx)$. Then $\partial_x \exp(ipx) = ip \exp(ipx)$ so momentum and partial derivatives are morally the same thing. Here we're of course exploiting the similarity between Fourier transform (which connects $x$ and $p$ images) and symplectic structure (which combines $x$ and $p$).

Rotation

Now onto something a bit harder. Suppose we have a flow 
$$\pmatrix{x \cr y} \to \pmatrix{x' \cr y'}=  \pmatrix{\cos(\phi) &amp; \sin(\phi) \cr - \sin(\phi) &amp; \cos(\phi)} \pmatrix {x \cr y} $$
 This is of course a rotational flow. Here we'll get a field $y {\rm d}x - x {\rm d} y$ and the conserved quantity of the form $y p_x - x p_y$ which can in three dimensions be thought of as a third component of angular momentum $L_z$.

Note that the above was done mainly for illustrative purposes as we could have worked in polar coordinates and then it would be actually the same problem as the first one because we'd get the field $\partial_{\phi}$ and conserved quantity $p_{\phi}$ (which is angular momentum).
",Marek,https://physics.stackexchange.com/users/329,http://physics.stackexchange.com/questions/4959/can-noethers-theorem-be-understood-intuitively,SCIENCE,physics.stackexchange.com,0.6666666666666666,0.7777777777777778,1.0,0.3333333333333333,0.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,1.0,0.6666666666666666,1.0,0.6666666666666666,0.8333333333333334,0.8,0.0,0.3333333333333333,1.0,1.0,Can we understand the Noether's theorem intuitively?,"Noether's theorem is one of those surprisingly clear results of mathematical calculations, for which I am inclined to think that some kind of intuitive understanding should or must be possible. However I don't know of any, do you?

Independence of time &lt;=> energy conservation.
Independence of position &lt;=> momentum conservation.
Independence of direction &lt;=> angular momentum conservation.  

I know that the mathematics leads in the direction of Lie-algebra and such but I would like to discuss whether this theorem can be understood from a non-mathematical point of view also.
","Well, I don't know about any intuitive explanation besides intuition gained by understanding the underlying math (mainly differential geometry, Hamiltonian mechanics and group theory). So with the risk of not giving you quite what you want, I'll try to approach the problem mathematically.

If you know Hamiltonian mechanics then the statement of the theorem is exceedingly simple. Assume we have a Hamiltonian $H$. To this there is associated a unique Hamiltonian flow (i.e. a one-parameter family of symplectomorphisms -- which is just a fancy name for diffeomorphisms preserving the symplectic structure) $\Phi_H(t)$ on the manifold. From the point of view of Lie theory, the flow is a group action and there exists its generator (which is a vector field) $V_H$ (this can also be obtained from $\omega(\cdot, V_H) = dH$ with $\omega$ being the symplectic form). Now, the completely same stuff can be written for some other function $A$, with generator $V_A$ and flow $\Phi_A(s)$. Think of this $A$ as some conserved quantity and of $\Phi_A(s)$ as a continuous family of symmetries.

Now, starting from Hamiltonian equation ${{\rm d} A \over {\rm d} t} = \left\{A,H\right\}$ we see that if $A$ Poisson-commutes with $H$ it is conserved. Now, this is not the end of the story. From the second paragraph it should be clear that $A$ and $H$ don't differ that much. Actually, what if we swapped them? Then we'd get ${{\rm d} H \over {\rm d} s} = \left\{H,A\right\}$. So we see that $A$ is constant along Hamiltonian flow (i.e. conserved) if and only if $H$ is constant along the symmetry flow (i.e. the physical laws are symmetric).

So much for why the stuff works. Now, how do we get from symmetries to conserved quantities? This actually isn't hard at all but requires some knowledge of differential geometry. Let's start with most simple example.

Translation

This is a symmetry such that $x \to x^\prime = x + a$. You can imagine that we move our coordinates along the $x$ direction. With $a$ being a parameter, this is a symmetry flow. If we differentiate with respect to this parameter, we'll get a vector field. Here it'll be $\partial_x$ (i.e. constant vector field aiming in the direction $x$). Now, what function on the symplectic manifold does it correspond to? Easy, it must be $p$ because by differentiating this we'll get a constant 1-form field $dp$ and then we have to use $\omega$ to get a vector field $\partial_x$.

Other way to see that it must be $p$: suppose you have a wave $\exp(ipx)$. Then $\partial_x \exp(ipx) = ip \exp(ipx)$ so momentum and partial derivatives are morally the same thing. Here we're of course exploiting the similarity between Fourier transform (which connects $x$ and $p$ images) and symplectic structure (which combines $x$ and $p$).

Rotation

Now onto something a bit harder. Suppose we have a flow 
$$\pmatrix{x \cr y} \to \pmatrix{x' \cr y'}=  \pmatrix{\cos(\phi) &amp; \sin(\phi) \cr - \sin(\phi) &amp; \cos(\phi)} \pmatrix {x \cr y} $$
 This is of course a rotational flow. Here we'll get a field $y {\rm d}x - x {\rm d} y$ and the conserved quantity of the form $y p_x - x p_y$ which can in three dimensions be thought of as a third component of angular momentum $L_z$.

Note that the above was done mainly for illustrative purposes as we could have worked in polar coordinates and then it would be actually the same problem as the first one because we'd get the field $\partial_{\phi}$ and conserved quantity $p_{\phi}$ (which is angular momentum).
"
6028,6028,9564,Ripening bananas artificially: What is the biological reason,"I am a resident of the tropical island of Sri Lanka, and we have a strange traditional method to ripen our bananas quickly.

What we do is this: We dig a pit in earth that is enough to put the whole banana cluster in. Then, after the safely laying the bananas in the pit, we cover up the pit with a sheet such that only a small hole from a side remains: visualize a small 3-4 inch door to the pit.

After that, we light a fire with semi-dry leaves just outside the pit's door. (Semi-dry leaves are used to get as much smoke as possible. Dry leaves do not give that much smoke, because they completely oxidize quickly). And the smoke is sent through the door by blowing it with the aid of a bamboo.



This sends a good amount of smoke and warms the inside of the pit considerably. And by experience I can tell you that this makes the bananas to ripen really quickly. I have done a controlled experiment where half of the cluster was not put into the pit. Bananas in the pit ripen overnight and the control sample took days to ripen.

Can anybody explain what are the bio-mechanisms that are working here?
",Krumia,https://biology.stackexchange.com/users/9948,"Ripening of bananas is induced by ethylene (see reference 1), which acts as a hormone and induces the ripening process. The incomplete combustion of the leaves produces ethylene, additionally the warmth of the process will help the enzymes as well. There is even a paper about this technique (although it is unfortunately not accessible), see reference 2 for more information. Smoking Chambers are routinely used in this process, see reference 3 and 4.

References:


Role of Ethylene in Fruit Ripening
Effects of smoking on some physiological changes in bananas.
Fruit Ripening
Technology for ripening fruits as important as marketing them

",Chris,https://biology.stackexchange.com/users/5144,http://biology.stackexchange.com/questions/23793/ripening-bananas-artificially-what-is-the-biological-reason,SCIENCE,biology.stackexchange.com,1.0,0.7777777777777778,0.0,0.3333333333333333,1.0,1.0,0.6666666666666666,0.8888888888888888,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,1.0,Biological reasons of artificial ripening banana,"I am a resident of the tropical island of Sri Lanka, and we have a strange traditional method to ripen our bananas quickly.

What we do is this: We dig a pit in earth that is enough to put the whole banana cluster in. Then, after the safely laying the bananas in the pit, we cover up the pit with a sheet such that only a small hole from a side remains: visualize a small 3-4 inch door to the pit.

After that, we light a fire with semi-dry leaves just outside the pit's door. (Semi-dry leaves are used to get as much smoke as possible. Dry leaves do not give that much smoke, because they completely oxidize quickly). And the smoke is sent through the door by blowing it with the aid of a bamboo.



This sends a good amount of smoke and warms the inside of the pit considerably. And by experience I can tell you that this makes the bananas to ripen really quickly. I have done a controlled experiment where half of the cluster was not put into the pit. Bananas in the pit ripen overnight and the control sample took days to ripen.

Can anybody explain what are the bio-mechanisms that are working here?
","Banana ripening is induced by ethylene (see reference 1), which acts as a hormone and induces the ripening process. Incomplete burning of leaves produces ethylene, and the heat in the process helps enzymes. There's even a paper on this technology (although unfortunately it's not accessible), see reference 2 for more information. Smoking rooms are often used in this process, see references 3 and 4."
967,967,1533,"How to prevent the ""Too awesome to use"" syndrome","When you give the player a rare but powerful item which can only be used once but is never really required to proceed, most players will not use it at all, because they are waiting for the perfect moment. But even when this moment comes, they will still be reluctant to use it, because there might be an even better moment later. So they keep hoarding it for a moment which will never come. 

In the end, they will carry the item around until it is outclassed by other, more readily available resources, or even until the very end of the game. That means that such one-shot items don't provide any gameplay-value at all. They are simply too awesome to use.

What can you do to encourage the player to make use of their one-shot items and not hoard them?
",Philipp,https://gamedev.stackexchange.com/users/21890,"The most common reason for hoarding it is that the user doesn't know what is the best time to use it. so, one simple way is to name it in such a way to make it obvious where its best use lies. The more generically powerful an item is, more the likelihood that the user will hoard it as he cannot zero in on its optimal use.
",Tapan Chandra,https://gamedev.stackexchange.com/users/30765,http://gamedev.stackexchange.com/questions/55558/how-to-prevent-the-too-awesome-to-use-syndrome,TECHNOLOGY,gamedev.stackexchange.com,0.6666666666666666,0.3333333333333333,0.0,1.0,0.0,0.0,1.0,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9,0.0,0.0,1.0,1.0,"How to prevent ""too good to use"" syndrome","When you give the player a rare but powerful item which can only be used once but is never really required to proceed, most players will not use it at all, because they are waiting for the perfect moment. But even when this moment comes, they will still be reluctant to use it, because there might be an even better moment later. So they keep hoarding it for a moment which will never come. 

In the end, they will carry the item around until it is outclassed by other, more readily available resources, or even until the very end of the game. That means that such one-shot items don't provide any gameplay-value at all. They are simply too awesome to use.

What can you do to encourage the player to make use of their one-shot items and not hoard them?
","The most common reason for hoarding it is that the user doesn't know what is the best time to use it. so, one simple way is to name it in such a way to make it obvious where its best use lies. The more generically powerful an item is, more the likelihood that the user will hoard it as he cannot zero in on its optimal use.
"
4859,4859,7730,Why Have The System Builder Market Not Migrated to the BTX Form Factor from ATX yet?,"I'm starting to build my first computer from the parts that I have purchased and a question that had been nagging me for the past few weeks was why the ATX form factor is still currently used when there is the newer BTX formfactor. 
",JFW,https://superuser.com/users/27043,"BTX was an Intel-driven formfactor oriented towards mass market manufacturers. Its primary promise was to reduce the number of system fans to One (Two counting the Power Supply). A single large fan at the back of the system would draw air through the CPU heatsink, and past memory and other components in front of that.

It was introduced in 2005/06 when AMD Athlon 64 and x2's reigned in the custom builder performance arena. AMD motherboards could not be easily adapted to the BTX design because it assumed an Intel system architecture and attendant m/b layout.

On top of that it offered nothing new for cooling add-in graphics adapters (such as all graphics NOT manufactured by Intel). 

Since it was primarily a single vendor solution for mass market manufacturers, it was only adopted for some mass produced systems while the ATX home builder and custom builder market continued unabated.
",kmarsh,https://superuser.com/users/4969,http://superuser.com/questions/176689,TECHNOLOGY,superuser.com,1.0,1.0,0.3333333333333333,0.5,1.0,1.0,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,0.8888888888888888,Why hasn't the system builder market moved from ATX to BTX forms?,"I started to build my first computer with the parts I bought, and the question that has been bothering me for the past few weeks is why the ATX for M factor is still in use when there is a new BTX for M factor.","BTX was an Intel-driven formfactor oriented towards mass market manufacturers. Its primary promise was to reduce the number of system fans to One (Two counting the Power Supply). A single large fan at the back of the system would draw air through the CPU heatsink, and past memory and other components in front of that.

It was introduced in 2005/06 when AMD Athlon 64 and x2's reigned in the custom builder performance arena. AMD motherboards could not be easily adapted to the BTX design because it assumed an Intel system architecture and attendant m/b layout.

On top of that it offered nothing new for cooling add-in graphics adapters (such as all graphics NOT manufactured by Intel). 

Since it was primarily a single vendor solution for mass market manufacturers, it was only adopted for some mass produced systems while the ATX home builder and custom builder market continued unabated.
"
2182,2182,3475,How to read NTFS drives in Linux (RHEL 6)?,"My system is on dual boot. I have installed both RHEL 6 and win7 in it. I use RHEL mostly and I want to use my windows' NTFS drive in RHEL. How can I do it? Tell me the procedure.


",Chankey Pathak,https://unix.stackexchange.com/users/2063,"I don't have RHEL, but yum install fuse-ntfs-3g should work AFAIK.
",Philomath,https://unix.stackexchange.com/users/8997,http://unix.stackexchange.com/questions/16893/how-to-read-ntfs-drives-in-linux-rhel-6,TECHNOLOGY,unix.stackexchange.com,1.0,0.8333333333333334,0.0,1.0,1.0,1.0,0.5,0.5,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.3333333333333333,1.0,0.3333333333333333,0.2,1.0,0.0,0.0,0.6666666666666666,How do I read NTFS drives in Linux (RHEL 6)?,"My system is dual booted. I have installed rhel6 and win7. I mainly use RHEL, and I want to use my windows NTFS drive in RHEL. What shall I do? Tell me the procedure.","I don't have RHEL, but yum install fuse-ntfs-3g should work AFAIK.
"
4500,4500,7135,How to enable or disable services?,"I read about how to enable and disable services in Ubuntu and it seems that there are different possibilities to manage them.

The first method I found is update-rc.d to add new services to startup, which aims on the /etc/init.d folder and its contents.

The other one I found is to edit .conf files in the /etc/init folder.

What's the recommended way to enable / disable / add services and why?

Could you please give a short bulletproof step by step example on how to add a service in Ubuntu and enable and disable it?
",NES,https://askubuntu.com/users/7155,"There are services that can be enabled/disabled using the GUI (Like the startup application) and then other ways of doing the same through the terminal.

For the Terminal you have several options. Open a terminal (Type ""terminal"" in the dash for example and open it) and keep on reading:

Enabling / Disabling a service

To toggle a service from starting or stopping permanently you would need to:

echo manual | sudo tee /etc/init/SERVICE.override


where the stanza manual will stop Upstart from automatically loading the service on next boot. Any service with the .override ending will take precedence over the original service file. You will only be able to start the service manually afterwards. If you do not want this then simply delete the .override. For example:

echo manual | sudo tee /etc/init/mysql.override


Will put the MySQL service into manual mode. If you do not want this, afterwards you can simply do

sudo rm /etc/init/mysql.override


and Reboot for the service to start automatically again. Of course to enable a service, the most common way is by installing it. If you install Apache, Nginx, MySQL or others, they automatically start upon finishing installation and will start every time the computer boots. Disabling as mentioned above will make state of the service manual.

Temporary enabling/disabling services

To stop and start services temporarily (Does not enable / disable them for future boots), you can type service SERVICE_NAME. For example:


sudo service apache2 stop (Will STOP the Apache service until Reboot or until you start it again). 
sudo service apache2 start (Will START the Apache service assuming it was stopped before.).
service apache2 status (Will tell you the STATUS of the service, if it is either enabled/running of disabled/NOT running.). 
sudo service apache2 restart (Will RESTART the service. This is most commonly used when you have changed, a config file. For example in this case, if you have changed either a PHP configuration or a Apache configuration. Restart will save you from having to stop/start with 2 command lines)
service apache2 (In this case, since you did not mention the ACTION to execute for the service, so it will show you all options available for that specific service.)


This of course can vary depending on the service, for example, with MySQL it would only mention that it is missing a parameter. For other services like networking service it would mention the small list of all options available.

UPSTART

If we would wanted to use the official Upstart way (Note that, for the moment, not all services have been converted to Upstart), we could use the following commands:

status SERVICE - This will tell us if a converted service is running or not. Note that this is deprecated in favor of start, stop, status &amp; restart. It will also tell us if a service was not yet been converted to upstart:

A converted service would typically output the current status (Starting, Running, Stopping...) and process ID. A non converted service would give an error about an unknown job.

Some shortcuts may only work with the service command above but not with the commands below unless they are 100% converted to upstart services:


START - sudo start mysql
STOP - sudo stop mysql
RESTART - sudo restart mysql
STATUS - sudo status smbd


SYSTEMD

Starting with Ubuntu 15.04, Upstart will be deprecated in favor of Systemd. With Systemd to manage the services we can do the following:

systemctl start SERVICE.service - Use it to start a service. Does not persist after reboot   

systemctl stop SERVICE.service - Use it to stop a service. Does not persist after reboot

systemctl restart SERVICE.service - Use it to restart a service

systemctl reload SERVICE.service - If the service supports it, it will reload the config files related to it without interrupting any process that is using the service.

systemctl status SERVICE.service - Shows the status of a serviceTells whether a service is currently running.

systemctl enable SERVICE.service - Turns the service on, on the next reboot or on the next start event. It persists after reboot.

systemctl disable SERVICE.service - Turns the service off on the next reboot or on the next stop event. It persists after reboot.

systemctl is-enabled SERVICE.service - Check if a service is currently configured to start or not on the next reboot.

systemctl is-active SERVICE.service - Check if a service is currently active.

systemctl show SERVICE.service - Show all the information about the service.
",Luis Alvarado,https://askubuntu.com/users/7035,http://askubuntu.com/questions/19320/how-to-enable-or-disable-services,TECHNOLOGY,askubuntu.com,0.8888888888888888,0.5555555555555556,0.0,0.5,1.0,1.0,0.6666666666666666,0.5555555555555556,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.7777777777777778,0.8888888888888888,0.7,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.7777777777777778,How do I enable or disable services?,"I read about how to enable and disable services in Ubuntu and it seems that there are different possibilities to manage them.

The first method I found is update-rc.d to add new services to startup, which aims on the /etc/init.d folder and its contents.

The other one I found is to edit .conf files in the /etc/init folder.

What's the recommended way to enable / disable / add services and why?

Could you please give a short bulletproof step by step example on how to add a service in Ubuntu and enable and disable it?
","There are services that can be enabled/disabled using the GUI (Like the startup application) and then other ways of doing the same through the terminal.

For the Terminal you have several options. Open a terminal (Type ""terminal"" in the dash for example and open it) and keep on reading:

Enabling / Disabling a service

To toggle a service from starting or stopping permanently you would need to:

echo manual | sudo tee /etc/init/SERVICE.override


where the stanza manual will stop Upstart from automatically loading the service on next boot. Any service with the .override ending will take precedence over the original service file. You will only be able to start the service manually afterwards. If you do not want this then simply delete the .override. For example:

echo manual | sudo tee /etc/init/mysql.override


Will put the MySQL service into manual mode. If you do not want this, afterwards you can simply do

sudo rm /etc/init/mysql.override


and Reboot for the service to start automatically again. Of course to enable a service, the most common way is by installing it. If you install Apache, Nginx, MySQL or others, they automatically start upon finishing installation and will start every time the computer boots. Disabling as mentioned above will make state of the service manual.

Temporary enabling/disabling services

To stop and start services temporarily (Does not enable / disable them for future boots), you can type service SERVICE_NAME. For example:


sudo service apache2 stop (Will STOP the Apache service until Reboot or until you start it again). 
sudo service apache2 start (Will START the Apache service assuming it was stopped before.).
service apache2 status (Will tell you the STATUS of the service, if it is either enabled/running of disabled/NOT running.). 
sudo service apache2 restart (Will RESTART the service. This is most commonly used when you have changed, a config file. For example in this case, if you have changed either a PHP configuration or a Apache configuration. Restart will save you from having to stop/start with 2 command lines)
service apache2 (In this case, since you did not mention the ACTION to execute for the service, so it will show you all options available for that specific service.)


This of course can vary depending on the service, for example, with MySQL it would only mention that it is missing a parameter. For other services like networking service it would mention the small list of all options available.

UPSTART

If we would wanted to use the official Upstart way (Note that, for the moment, not all services have been converted to Upstart), we could use the following commands:

status SERVICE - This will tell us if a converted service is running or not. Note that this is deprecated in favor of start, stop, status &amp; restart. It will also tell us if a service was not yet been converted to upstart:

A converted service would typically output the current status (Starting, Running, Stopping...) and process ID. A non converted service would give an error about an unknown job.

Some shortcuts may only work with the service command above but not with the commands below unless they are 100% converted to upstart services:


START - sudo start mysql
STOP - sudo stop mysql
RESTART - sudo restart mysql
STATUS - sudo status smbd


SYSTEMD

Starting with Ubuntu 15.04, Upstart will be deprecated in favor of Systemd. With Systemd to manage the services we can do the following:

systemctl start SERVICE.service - Use it to start a service. Does not persist after reboot   

systemctl stop SERVICE.service - Use it to stop a service. Does not persist after reboot

systemctl restart SERVICE.service - Use it to restart a service

systemctl reload SERVICE.service - If the service supports it, it will reload the config files related to it without interrupting any process that is using the service.

systemctl status SERVICE.service - Shows the status of a serviceTells whether a service is currently running.

systemctl enable SERVICE.service - Turns the service on, on the next reboot or on the next start event. It persists after reboot.

systemctl disable SERVICE.service - Turns the service off on the next reboot or on the next stop event. It persists after reboot.

systemctl is-enabled SERVICE.service - Check if a service is currently configured to start or not on the next reboot.

systemctl is-active SERVICE.service - Check if a service is currently active.

systemctl show SERVICE.service - Show all the information about the service.
"
3918,3918,6248,What happens if I destroy a minipet placed in the Devotion monument in Guild Wars?,"Will I lose my statue? Will I lose my Hall of Monuments point progression? Or is it safe? What happens if I destroy a minipet dedicated at the Hall of Monuments?
",Bastien Vandamme,https://gaming.stackexchange.com/users/7346,"Nothing, once you have dedicated the minipet to your monument, you can trade, give away, or destroy the minipet with no consequences.  Your monument statue will always be there and count towards your account.  It just can't be rededicated by anyone else.  Typically dedicated minipets are worth only 10-20% of the undedicated value because of this reason.
",l I,https://gaming.stackexchange.com/users/3917,http://gaming.stackexchange.com/questions/19224/what-happens-if-i-destroy-a-minipet-placed-in-the-devotion-monument-in-guild-war,CULTURE,gaming.stackexchange.com,1.0,0.7777777777777778,0.0,0.6666666666666666,1.0,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,0.6666666666666666,0.8888888888888888,What if I destroyed a pet placed in a dedication monument in the guild war?,Will I lose my statue? I will lose my memorial point progress? Or is it safe? What if I destroyed the pets in the memorial hall?,"Nothing, once you have dedicated the minipet to your monument, you can trade, give away, or destroy the minipet with no consequences.  Your monument statue will always be there and count towards your account.  It just can't be rededicated by anyone else.  Typically dedicated minipets are worth only 10-20% of the undedicated value because of this reason.
"
3139,3139,5004,cancel(getIntent().getExtras().getInt(“notificationID”)); what is the return...?,"cancel(getIntent().getExtras().getInt(“notificationID”));

why we use of dot operator in between these methods? as cancel(int) method takes only one integer parameter.it has 3 methods as parametr.....what exactly the code will do..?
",sanjay,https://stackoverflow.com/users/871340,"You should try going through the concepts of object oriented programming first.

To answer your question, getIntent() returns an object of type intent. We call the getExtras() on the Intent object which returns an object of type Bundle. Then we call getInt() on the Bundle object to finally get the int we want to pass to the cancel() method.

The statement is equivalent to :

Intent i = getIntent();
Bundle b = i.getExtras();
int id = b.getInt(""notificationID"");
cancel(id);


If we don't need any of the intermediate objects, we can write the whole thing in a single line.

Hope that helps.
",Arnab Chakraborty,https://stackoverflow.com/users/802799,http://stackoverflow.com/questions/6897701/cancelgetintent-getextras-getint-notificationid-what-is-the-return,STACKOVERFLOW,stackoverflow.com,0.6666666666666666,0.3333333333333333,0.0,0.3333333333333333,1.0,0.3333333333333333,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.6666666666666666,0.7777777777777778,0.6666666666666666,0.7777777777777778,1.0,0.9333333333333332,0.3333333333333333,0.0,0.6666666666666666,1.0,"Cancel (getintent(). Getextras(). GetInt (""notificationid"")); what is returned...?","cancel(getIntent().getExtras().getInt(“notificationID”));

why we use of dot operator in between these methods? as cancel(int) method takes only one integer parameter.it has 3 methods as parametr.....what exactly the code will do..?
","You should try going through the concepts of object oriented programming first.

To answer your question, getIntent() returns an object of type intent. We call the getExtras() on the Intent object which returns an object of type Bundle. Then we call getInt() on the Bundle object to finally get the int we want to pass to the cancel() method.

The statement is equivalent to :

Intent i = getIntent();
Bundle b = i.getExtras();
int id = b.getInt(""notificationID"");
cancel(id);


If we don't need any of the intermediate objects, we can write the whole thing in a single line.

Hope that helps.
"
4854,4854,7723,What magic items are there to capture or restrain someone?,"I'm looking for items to specifically address the strengths and weaknesses of the PC's.

For example, our wizard who has lots of teleport spells will be restrained with Dimensional Shackles.

How can I best restrain, for example, our high-strength fighter and our high-dex ranger, outside of typical mundane methods (ropes, shackles, cages, etc)? Are there any magic items to do this? 

This should be for an extended period of time (being transported in a wagon, for example), not during combat.

Criteria for ""capturing"" a PC:


Effect doesn't end on a save
One of the following conditions is imposed:

Restrained
Immobilized
Slowed
Cannot attack
Unconscious
Stunned
Dazed
Misc negative effects (cannot teleport, cannot run, who knows what else is out there...)


",dpatchery,https://rpg.stackexchange.com/users/1069,"Unfortunately, there are extraordinarily few effects that last past a short rest. There are extraordinarily few effects for a PC. However, the magic of 4e is that monsters do not use the same magic items, skills, or plot macguffins as a PC.

The most effective PC MacGuffin is the Executioner Assassin's Carrion Crawler Brain Juice. This Executioner only poison that takes the place of one of their daily powers:


  Power (Consumable * Poison): Minor Action. You apply the poison to a single handheld object. Within the next hour, the first creature other than you to hold or wear the object for more than 1 minute is immobilized until the end of its next extended rest.


While this doesn't prevent teleportation, a Dimensional Anchor neatly solves that problem: Property: Any creature within 10 squares of this statue can’t teleport.

The act of applying this poison and the use of this statue, while effective and almost impossible for PCs to combat, completely destroys their agency. It is far more effective to get them in a ""teleportation trap"" (some sort of handwavy trap/almost-completed ritual) or equivalent instant transport that doesn't involve 

""you put on your armor like normal, right?""

""Yeah...?""

""Okay, well, you're immobilized until you sleep next, which can't happen for another 16 hours.""

A teleportation trap accomplishes the same thing, but doesn't actively interfere with the player's character's interactions with themselves and their own mental models.
",Brian Ballsun-Stanton,https://rpg.stackexchange.com/users/760,http://rpg.stackexchange.com/questions/8791/what-magic-items-are-there-to-capture-or-restrain-someone,CULTURE,rpg.stackexchange.com,1.0,0.7777777777777778,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.3333333333333333,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,1.0,1.0,0.3333333333333333,0.3333333333333333,0.0,1.0,1.0,0.7777777777777778,1.0,1.0,0.9333333333333332,0.6666666666666666,0.0,1.0,1.0,What magic items can capture or restrict someone?,"I'm looking for items to specifically address the strengths and weaknesses of the PC's.

For example, our wizard who has lots of teleport spells will be restrained with Dimensional Shackles.

How can I best restrain, for example, our high-strength fighter and our high-dex ranger, outside of typical mundane methods (ropes, shackles, cages, etc)? Are there any magic items to do this? 

This should be for an extended period of time (being transported in a wagon, for example), not during combat.

Criteria for ""capturing"" a PC:


Effect doesn't end on a save
One of the following conditions is imposed:

Restrained
Immobilized
Slowed
Cannot attack
Unconscious
Stunned
Dazed
Misc negative effects (cannot teleport, cannot run, who knows what else is out there...)


","Unfortunately, there are extraordinarily few effects that last past a short rest. There are extraordinarily few effects for a PC. However, the magic of 4e is that monsters do not use the same magic items, skills, or plot macguffins as a PC.

The most effective PC MacGuffin is the Executioner Assassin's Carrion Crawler Brain Juice. This Executioner only poison that takes the place of one of their daily powers:


  Power (Consumable * Poison): Minor Action. You apply the poison to a single handheld object. Within the next hour, the first creature other than you to hold or wear the object for more than 1 minute is immobilized until the end of its next extended rest.


While this doesn't prevent teleportation, a Dimensional Anchor neatly solves that problem: Property: Any creature within 10 squares of this statue can’t teleport.

The act of applying this poison and the use of this statue, while effective and almost impossible for PCs to combat, completely destroys their agency. It is far more effective to get them in a ""teleportation trap"" (some sort of handwavy trap/almost-completed ritual) or equivalent instant transport that doesn't involve 

""you put on your armor like normal, right?""

""Yeah...?""

""Okay, well, you're immobilized until you sleep next, which can't happen for another 16 hours.""

A teleportation trap accomplishes the same thing, but doesn't actively interfere with the player's character's interactions with themselves and their own mental models.
"
2820,2820,4489,"Is there a word for ""rule by criminals""?","Is there a word for ""rule by criminals""? Not kleptocracy, which is rule by thieves, but more broadly by criminals.
",EdL,https://english.stackexchange.com/users/68265,"This is an interesting question because it depends upon your meaning:

If you mean the government is filled with people who are not adhering to the laws of that they enforce:  this would just be a corrupt government, riddled with corruption, etc. etc.

If you mean the government is filled with people who've committed crimes, but are now functioning as a standard government that is a different story.  The government would be whatever form it took.  (e.g. A republic of thieves doesn't cease to be a republic.)

Carribean Pirate crews were well known for their democratic governance.

But, several terms have been used to describe ""legitimate"" governments whose members' morality was questionable.  I've seen criminocracy used in the manner you're describing.  (Also, thugocracy, and others.)  For the most part, if you use the suffix -ocracy with a criminal sounding prefix, people will get your meaning. 
",David M,https://english.stackexchange.com/users/59527,http://english.stackexchange.com/questions/156373/is-there-a-word-for-rule-by-criminals,CULTURE,english.stackexchange.com,1.0,1.0,0.0,1.0,1.0,1.0,0.5555555555555556,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.8888888888888888,0.5555555555555556,1.0,0.8888888888888888,0.6,0.3333333333333333,0.0,0.0,1.0,"Is there the word ""criminal rule""?","Is there the word ""criminal rule""? It's not thief rule, it's broader criminal rule.","This is an interesting question because it depends upon your meaning:

If you mean the government is filled with people who are not adhering to the laws of that they enforce:  this would just be a corrupt government, riddled with corruption, etc. etc.

If you mean the government is filled with people who've committed crimes, but are now functioning as a standard government that is a different story.  The government would be whatever form it took.  (e.g. A republic of thieves doesn't cease to be a republic.)

Carribean Pirate crews were well known for their democratic governance.

But, several terms have been used to describe ""legitimate"" governments whose members' morality was questionable.  I've seen criminocracy used in the manner you're describing.  (Also, thugocracy, and others.)  For the most part, if you use the suffix -ocracy with a criminal sounding prefix, people will get your meaning. 
"
3424,3424,5448,"Christian description of ""self-love"" (from Matthew 22)","Matthew 22: 


  39 And the second command is like the first: ‘Love your neighbor
  the same as you love yourself.


Self love, esteem, worth, etc are matters of the spirit and personality - that are foundations for how we live our lives.  

What is the description of self-love Christians are expected to have for themselves and their neighbors?

Another issue, what is meant by this in a society where self love is low or rare (and why wasn't that considered when Jesus said this)?
",Greg McNulty,https://christianity.stackexchange.com/users/1400,"My answer is based on a definition of love that is implied in Scripture, but not necessarily spelled out in chapter and verse.  I learned it from Les Feldick's ""Through The Bible"" program. Any child can grasp the definition of Biblical love.  It's simply seeking the other's highest good.  (and only God is good).

When Jesus commands us to love our neighbor as our selves.  We simply seek eternal life for them as we desire it for ourselves.  Jesus further commands his apostles ""love one another as I have loved you""  Jesus loved us by doing His Father's will.  Believers love one another likewise, by doing our Father's will.  For some, this love manifests itself in working toward getting God's Word out,  the Gospel of grace, so that every man and woman, boy and girl can come to the saving knowledge of Jesus Christ.
",barney,https://christianity.stackexchange.com/users/3796,http://christianity.stackexchange.com/questions/13718/christian-description-of-self-love-from-matthew-22,CULTURE,christianity.stackexchange.com,1.0,0.3333333333333333,1.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.7777777777777778,1.0,0.0,1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.0,0.7777777777777778,0.7777777777777778,0.3333333333333333,0.7777777777777778,0.8888888888888888,0.6,0.0,0.0,0.6666666666666666,0.8888888888888888,"Christian description of ""self love"" (from Matthew 22)","Matthew 22: 


  39 And the second command is like the first: ‘Love your neighbor
  the same as you love yourself.


Self love, esteem, worth, etc are matters of the spirit and personality - that are foundations for how we live our lives.  

What is the description of self-love Christians are expected to have for themselves and their neighbors?

Another issue, what is meant by this in a society where self love is low or rare (and why wasn't that considered when Jesus said this)?
","My answer is based on a definition of love that is implied in Scripture, but not necessarily spelled out in chapter and verse.  I learned it from Les Feldick's ""Through The Bible"" program. Any child can grasp the definition of Biblical love.  It's simply seeking the other's highest good.  (and only God is good).

When Jesus commands us to love our neighbor as our selves.  We simply seek eternal life for them as we desire it for ourselves.  Jesus further commands his apostles ""love one another as I have loved you""  Jesus loved us by doing His Father's will.  Believers love one another likewise, by doing our Father's will.  For some, this love manifests itself in working toward getting God's Word out,  the Gospel of grace, so that every man and woman, boy and girl can come to the saving knowledge of Jesus Christ.
"
5963,5963,9450,Why don't spinning tops fall over?,"One topic which was covered in university, but which I never understood, is how a spinning top ""magically"" resists the force of gravity. The conservation of energy explanations make sense, but I don't believe that they provide as much insight as a mechanical explanation would.

The hyperphysics link Cedric provided looks similar to a diagram that I saw in my physics textbook. This diagram illustrates precession nicely, but doesn't explain why the top doesn't fall. Since the angular acceleration is always tangential, I would expect that the top should spiral outwards until it falls to the ground. However, the diagram seems to indicate that the top should be precessing in a circle, not a spiral. Another reason I am not satisfied with this explanation is that the calculation is apparently limited to situations where: ""the spin angular velocity $\omega$ is much greater than the precession angular velocity $\omega_P$"". The calculation gives no explanation of why this is not the case.
",Casebash,https://physics.stackexchange.com/users/119,"All the explanations given involve conservation of angular momentum, which is perfectly correct, but I feel that people with no thorough background in physics and mathematics will be left unsatisfied with this.

Is there a way to explain conservation of angular momentum in terms which would be understandable to the layman? It's a pedagogical problem I have given a lot of thought and I have yet to find a satisfactory answer.

Surely, you need to start from something, some basic axiom that the person will be willing to accept at face value. I thought about using either the law of action and reaction or conservation of momentum. I think these are relatively easy to describe ""pictorially"". But going from these to angular momentum using a vector product, is a mathematical procedure I'm not sure I can explain to someone who doesn't know anything about math. So, this should be circumvented in some way by a nice visual example again to make things clearer and I haven't found one. 

Anybody having ideas?
",Raskolnikov,https://physics.stackexchange.com/users/369,http://physics.stackexchange.com/questions/271/why-dont-spinning-tops-fall-over,SCIENCE,physics.stackexchange.com,0.6666666666666666,1.0,0.0,0.6666666666666666,1.0,1.0,0.7777777777777778,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.3333333333333333,1.0,1.0,1.0,0.2,0.0,0.0,0.0,1.0,Why didn't the top fall off?,"One topic which was covered in university, but which I never understood, is how a spinning top ""magically"" resists the force of gravity. The conservation of energy explanations make sense, but I don't believe that they provide as much insight as a mechanical explanation would.

The hyperphysics link Cedric provided looks similar to a diagram that I saw in my physics textbook. This diagram illustrates precession nicely, but doesn't explain why the top doesn't fall. Since the angular acceleration is always tangential, I would expect that the top should spiral outwards until it falls to the ground. However, the diagram seems to indicate that the top should be precessing in a circle, not a spiral. Another reason I am not satisfied with this explanation is that the calculation is apparently limited to situations where: ""the spin angular velocity $\omega$ is much greater than the precession angular velocity $\omega_P$"". The calculation gives no explanation of why this is not the case.
","All the explanations given involve conservation of angular momentum, which is perfectly correct, but I feel that people with no thorough background in physics and mathematics will be left unsatisfied with this.

Is there a way to explain conservation of angular momentum in terms which would be understandable to the layman? It's a pedagogical problem I have given a lot of thought and I have yet to find a satisfactory answer.

Surely, you need to start from something, some basic axiom that the person will be willing to accept at face value. I thought about using either the law of action and reaction or conservation of momentum. I think these are relatively easy to describe ""pictorially"". But going from these to angular momentum using a vector product, is a mathematical procedure I'm not sure I can explain to someone who doesn't know anything about math. So, this should be circumvented in some way by a nice visual example again to make things clearer and I haven't found one. 

Anybody having ideas?
"
5737,5737,9086,What is the fastest way to merge similar uv islands,"I've just started uv unwrapping a simple object in Blender and am trying to get more useable texture resolution by using the same uvs for multiple similar uv islands (in this case, the mesh is simple, so the islands I want to merge are single polygons). Although I can manually flip the top uv island and move it onto the similar one below, I was wondering if there is a quicker, preferably automated way that works with more complicated uv islands

(sorry my example is so simple... imagine more complex islands).


",MrFlamey,https://blender.stackexchange.com/users/328,"You can use UV Align\Distribute addon which will do what you want.



Here is how to use it: https://www.youtube.com/watch?v=clgrf0DUvso
",Jaroslav Jerryno Novotny,https://blender.stackexchange.com/users/7777,http://blender.stackexchange.com/questions/21025/what-is-the-fastest-way-to-merge-similar-uv-islands,TECHNOLOGY,blender.stackexchange.com,1.0,0.5555555555555556,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,1.0,What's the fastest way to merge similar UV Islands,"I just started UV unfolding a simple object in blender, and tried to get more usable texture resolution by using the same UV for multiple similar UV Islands (in this case, the mesh is simple, so the islands I want to merge are single polygons). Although I can manually flip the top UV island and move it to a similar location below, I wonder if there is a faster, better automated way to deal with more complex UV Islands","You can use UV Align\Distribute addon which will do what you want.



Here is how to use it: https://www.youtube.com/watch?v=clgrf0DUvso
"
422,422,655,Online broker available in Europe - to buy index funds or ETF with small investments,"So i am trying to start investing periodically some small amounts.
I am particularly interested in index funds or ETF.

I would like to be able buy, track, sell them, and etc online.
There are a lot of online brokers like : TD Ameritrade, etrade and etc. , but i cant seem to find the one that would allow to register fro Europe citizen, like from Denmark. (all the top ones require USA citizenship or etc).

Is there any like that at all ? If not - what other options there are to make such investments ?
",XFaktor,https://money.stackexchange.com/users/17734,"You should try Nordnet. I think they should have a monthly saving plan on ETFs over there too.
",kliq,https://money.stackexchange.com/users/17811,http://money.stackexchange.com/questions/33724/online-broker-available-in-europe-to-buy-index-funds-or-etf-with-small-investm,LIFE_ARTS,money.stackexchange.com,0.8888888888888888,0.6666666666666666,0.0,1.0,1.0,1.0,0.6666666666666666,0.5555555555555556,0.6666666666666666,0.0,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.0,0.0,0.8888888888888888,Online brokers in Europe - buying index funds or ETFs with small investments,"So i am trying to start investing periodically some small amounts.
I am particularly interested in index funds or ETF.

I would like to be able buy, track, sell them, and etc online.
There are a lot of online brokers like : TD Ameritrade, etrade and etc. , but i cant seem to find the one that would allow to register fro Europe citizen, like from Denmark. (all the top ones require USA citizenship or etc).

Is there any like that at all ? If not - what other options there are to make such investments ?
",You should try nordnet. I think they should also have a monthly savings plan for ETFs.
807,807,1277,Can I substitute a stainless steel pot for the traditional iron dutch oven?,"I have very limited options in my kitchen, and while the dutch oven is the preferred method for getting an 'oven spring' while baking sourdough, I do not have a cast iron pot to do it.

IF stainless steel is a good substitute, should I consider extra precautions?
",erasmortg,https://cooking.stackexchange.com/users/23068,"Cast iron is ideal, but any pot that can take the heat and has a tight lid will work. Like @talon8 said in his comment, it doesn't even have to be metal.

This article from Around the World in 80 Bakes specifically uses terracotta for sourdough, not cast iron.

Just as an FYI, this related question deals with preheating (for no-knead bread, not sourdough), and the differing answers are interesting. To me it just goes to show that bread-making doesn't always have to follow super-strict rules. Preheat the Dutch oven (and the oven itself) for No-Knead Bread? (experiment results)
",Jolenealaska,https://cooking.stackexchange.com/users/20183,http://cooking.stackexchange.com/questions/47833/can-i-substitute-a-stainless-steel-pot-for-the-traditional-iron-dutch-oven,LIFE_ARTS,cooking.stackexchange.com,1.0,0.8888888888888888,0.0,0.5,0.3333333333333333,0.5,0.5555555555555556,0.5555555555555556,0.6666666666666666,0.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.8888888888888888,1.0,0.7777777777777778,1.0,1.0,0.9333333333333332,0.3333333333333333,0.0,0.3333333333333333,0.8888888888888888,Can I use a stainless steel pot instead of the traditional Dutch oven?,"My choice in the kitchen is very limited, although the Dutch oven is the preferred way to get ""oven spring"" when baking yogurt, but I don't have a cast iron pot to do it.","Cast iron is ideal, but any pot that can take the heat and has a tight lid will work. Like @talon8 said in his comment, it doesn't even have to be metal.

This article from Around the World in 80 Bakes specifically uses terracotta for sourdough, not cast iron.

Just as an FYI, this related question deals with preheating (for no-knead bread, not sourdough), and the differing answers are interesting. To me it just goes to show that bread-making doesn't always have to follow super-strict rules. Preheat the Dutch oven (and the oven itself) for No-Knead Bread? (experiment results)
"
4625,4625,7337,Hydraulic brakes feel loose,"I have a bike with Avid hydraulic brakes. The levers feel loose and at the end of pushing it, there is a ""soft"" feeling (like when V-brakes pads aren't adjusted properly).
As I understand, it's air inside the pipes. Is there something I can try to do to fix it without opening it / refilling liquid?
",Alexander,https://bicycles.stackexchange.com/users/7999,"You need a kit to bleed that brake.  Disc Brake Bleed Kit
It is one of those tools/kits that as an individual it is not worth buying. 
Even on Amazon the kit it $40.

A (quality) bleed replaces the fluid. 
",Paparazzi,https://bicycles.stackexchange.com/users/7785,http://bicycles.stackexchange.com/questions/23353/hydraulic-brakes-feel-loose,CULTURE,bicycles.stackexchange.com,0.7777777777777778,0.6666666666666666,0.0,1.0,0.6666666666666666,1.0,0.7777777777777778,0.4444444444444444,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,1.0,0.6666666666666666,0.0,0.6666666666666666,1.0,Hydraulic brake release,"I have a bike with hydraulic brakes. The lever feels loose, and at the end of pushing it, there is a ""soft"" feel (like the V-brake pads are not adjusted properly).","You need a kit to bleed that brake.  Disc Brake Bleed Kit
It is one of those tools/kits that as an individual it is not worth buying. 
Even on Amazon the kit it $40.

A (quality) bleed replaces the fluid. 
"
5927,5927,9387,"Problem in blitting a clean, crisp sprite","I am having a bit of a tooling problem...and I am unsure of how to solve it.

I am currently using PyGame to try and write a simple Minesweeper clone, except my sprites that I made are hexagon based and therefore have diagonal lines.

I drew up a nice, clean, crisp vector sprite set which looks very nice in Inkscape, however once I export it everything goes to hell.  I'm going to outline what I've done below and hopefully somebody here can set me straight :D

Disclaimer: Unfortunately I'm behind a proxy and cannot provide screenshots at the moment..I'll do my best to describe.

If I attempt to use a color key (0xFF00FF), then when I set the color key in PyGame I get a bunch of jagged pink edges along my sprite.  I believe this could be an anti-aliasing issue with Inkscape, but unfortunately my Googling didn't turn up a way to disable it.

If I import my PNG into Photoshop or the Gimp and delete the background, then I run into an issue where the background appears to be black when running the game.  I have tried to follow the instructions I saw on SO, but to no avail.

I am open to suggestions, but at this point I'm debating importing another library which can handle SVG graphics, in order to keep my clean, crisp diagonal lines.
",espais,https://gamedev.stackexchange.com/users/1743,"Try this in Photoshop:


Make a new document.
Make a new layer. It will be transparent.
Delete the background layer.
Your document should be all transparent now. It will look like a checkerboard.
Draw the hexagon onto that transparent layer.
Save this as a 24-bit PNG with transparency.


Now bring that into PyGame. You may need to do some convert_alpha() thing to enable the alpha channel. That should give you correct anti-aliased transparency.
",munificent,https://gamedev.stackexchange.com/users/160,http://gamedev.stackexchange.com/questions/15450/problem-in-blitting-a-clean-crisp-sprite,TECHNOLOGY,gamedev.stackexchange.com,0.6666666666666666,0.3333333333333333,0.0,0.5,1.0,1.0,0.6666666666666666,0.5555555555555556,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.0,1.0,1.0,0.6666666666666666,1.0,0.8888888888888888,0.8,0.6666666666666666,0.3333333333333333,0.3333333333333333,1.0,"The problem of cutting a clean, crisp sprite into small pieces","I am having a bit of a tooling problem...and I am unsure of how to solve it.

I am currently using PyGame to try and write a simple Minesweeper clone, except my sprites that I made are hexagon based and therefore have diagonal lines.

I drew up a nice, clean, crisp vector sprite set which looks very nice in Inkscape, however once I export it everything goes to hell.  I'm going to outline what I've done below and hopefully somebody here can set me straight :D

Disclaimer: Unfortunately I'm behind a proxy and cannot provide screenshots at the moment..I'll do my best to describe.

If I attempt to use a color key (0xFF00FF), then when I set the color key in PyGame I get a bunch of jagged pink edges along my sprite.  I believe this could be an anti-aliasing issue with Inkscape, but unfortunately my Googling didn't turn up a way to disable it.

If I import my PNG into Photoshop or the Gimp and delete the background, then I run into an issue where the background appears to be black when running the game.  I have tried to follow the instructions I saw on SO, but to no avail.

I am open to suggestions, but at this point I'm debating importing another library which can handle SVG graphics, in order to keep my clean, crisp diagonal lines.
","Try this in Photoshop:


Make a new document.
Make a new layer. It will be transparent.
Delete the background layer.
Your document should be all transparent now. It will look like a checkerboard.
Draw the hexagon onto that transparent layer.
Save this as a 24-bit PNG with transparency.


Now bring that into PyGame. You may need to do some convert_alpha() thing to enable the alpha channel. That should give you correct anti-aliased transparency.
"
1585,1585,2495,Why do so many people have group O blood?,"Please forgive me in case my question wouldn't make much sense. I was reading about ABO blood groups on Wikipedia, where I learnt that O is a recessive allele, and that it seems the A allele predates the O allele. My question is, therefore, how is it possible that almost half of the human population is group O?

For instance, I would expect (quite naively I reckon), if only alleles A and O existed, that around 75% of the population should be A, and 25% should be O.
",scozy,https://biology.stackexchange.com/users/6504,"There are many different variants of O (all loss-of-function) indicating that this mutation has arisen many times in the human population. The prevalence of O is indeed taken as evidence of balancing selection. Various pathogens use the A or B antigens as receptors. The cited paper presents evidence about the phylogeny of the ABO gene in human populations and reports that there is clear evidence of balancing selection.


  We propose several hypotheses for the cause of [balancing selection], which most likely involved interactions with multiple pathogens at different geographic regions and timescales.
  
  Calafell et al (2008) Evolutionary dynamics of the human ABO gene. Human Genetics 124: 123-135

",Alan Boyd,https://biology.stackexchange.com/users/1320,http://biology.stackexchange.com/questions/16910/why-do-so-many-people-have-group-o-blood,SCIENCE,biology.stackexchange.com,1.0,0.8888888888888888,0.0,0.0,1.0,0.6666666666666666,0.8888888888888888,1.0,0.3333333333333333,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,1.0,Why do so many people have type O blood?,"If my question doesn't make sense, please forgive me. I read ABO blood group on Wikipedia, where I learned that O is a recessive allele, and it seems that a allele is earlier than o allele. So my question is, how is it possible that nearly half of the population is in group O?","There are many different variants of O (all loss-of-function) indicating that this mutation has arisen many times in the human population. The prevalence of O is indeed taken as evidence of balancing selection. Various pathogens use the A or B antigens as receptors. The cited paper presents evidence about the phylogeny of the ABO gene in human populations and reports that there is clear evidence of balancing selection.


  We propose several hypotheses for the cause of [balancing selection], which most likely involved interactions with multiple pathogens at different geographic regions and timescales.
  
  Calafell et al (2008) Evolutionary dynamics of the human ABO gene. Human Genetics 124: 123-135

"
2748,2748,4380,Removing blanks from a column in Excel,"
",Mike,https://superuser.com/users/79906,"If you select the column and press F5, click Special, choose Blanks then right click the selected cells and delete - that'll get rid of the empty cells.



Not my bag but I also found this.
",Ian Wood,https://superuser.com/users/92720,http://superuser.com/questions/271627,TECHNOLOGY,superuser.com,0.6666666666666666,0.6666666666666666,0.5,0.5,1.0,1.0,0.8333333333333334,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,0.8333333333333334,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,1.0,Remove blanks from columns in Excel,"
","If you select the column and press F5, click Special, choose Blanks then right click the selected cells and delete - that'll get rid of the empty cells.



Not my bag but I also found this.
"
2753,2753,4389,In assasin creed 4 can we fast travel within cities?,"For example, rather than running from places to places, I saw many fast travel icons on the map. Can I fast travel there?

I know I can fast travel to save sailing time. What about if I am not sailing? Why are they so many fast travel icons on one city? If fast travel is only when sailing, then we need only one fast travel icons per city right?

I am using PS4. In world map, I can fast travel with square key. What button I should press if I am within a city. I select a fast travel icon, press square, nothing happen.
",J. Chang,https://gaming.stackexchange.com/users/20631,"I think this is where the confusion start.

Within city, you can fast travel to synchronize point. You cannot fast travel to ""fast travel"" point.

What you can do is you go by foot to ""fast travel"" points and you will have an option to teleport to another ""fast travel"" points.

The fast travel points look like small boats that usually teleport us to our ship. Instead, it teleport us to other fast travel points.
",J. Chang,https://gaming.stackexchange.com/users/20631,http://gaming.stackexchange.com/questions/165031/in-assasin-creed-4-can-we-fast-travel-within-cities,CULTURE,gaming.stackexchange.com,1.0,0.6666666666666666,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,0.8888888888888888,"In Assad creed 4, can we travel fast in the city?","For example, rather than running from places to places, I saw many fast travel icons on the map. Can I fast travel there?

I know I can fast travel to save sailing time. What about if I am not sailing? Why are they so many fast travel icons on one city? If fast travel is only when sailing, then we need only one fast travel icons per city right?

I am using PS4. In world map, I can fast travel with square key. What button I should press if I am within a city. I select a fast travel icon, press square, nothing happen.
","I think this is where the confusion start.

Within city, you can fast travel to synchronize point. You cannot fast travel to ""fast travel"" point.

What you can do is you go by foot to ""fast travel"" points and you will have an option to teleport to another ""fast travel"" points.

The fast travel points look like small boats that usually teleport us to our ship. Instead, it teleport us to other fast travel points.
"
4706,4706,7460,Should we allow or avoid non-standard pronouns?,"This question brings up an important question:

Do we want to allow or avoid the use of non-standard English such as the words zie and zir as non gender specific pronouns on this site?
",Flimzy,https://meta.christianity.stackexchange.com/users/20,"Considering we are accepting all comers as far as self claiming Christians, we might as well accept all comers as far as self proclaimed pronouns too. It is in the spirit of religious and lingual tolerance that we accept them. This tolerance is of course limited by the fact that this is an English site, these however, while not exactly English are an attempt at correcting an issue in the English language..
",wax eagle,https://meta.christianity.stackexchange.com/users/49,http://meta.christianity.stackexchange.com/questions/514/should-we-allow-or-avoid-non-standard-pronouns,CULTURE,meta.christianity.stackexchange.com,0.6666666666666666,0.6666666666666666,0.0,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.6,0.0,0.0,1.0,1.0,Should we allow or avoid the use of non-standard pronouns?,"This question brings up an important question:

Do we want to allow or avoid the use of non-standard English such as the words zie and zir as non gender specific pronouns on this site?
","Considering that we accept all of us as self proclaimed Christians, we may as well accept all of us as pronouns of self assertion. It is in the spirit of religious and linguistic tolerance that we accept them. Of course, this tolerance is limited by the fact that this is an English website, however, these websites are not entirely English websites, but try to correct the problem in English.."
3225,3225,5145,Significant error conversion,"So here is my question: Say we have measured something to be 15,67 mm and the significant error is $\pm 0,01$mm. then we convert the measurement to meter to be 0,01567m would the significant error then be $\pm 0.00001$m?
",user3463859,https://physics.stackexchange.com/users/43738,"You are correct that an uncertainty of 0.01 mm is the same as an uncertainty of 0.000 01 m.  The unedited version of your question contained a factor-of-ten error.

For numbers with many significant digits, or numbers which are for whatever reason written in cumbersome units, there are a couple of tricks people use to avoid getting confused and making factor-of-ten errors.  One is to write the digits in groups separated by spaces.  (And if you're fussy about such things and your software supports it, you can use non-breaking thin spaces).  Another is to write the uncertainty in the last digits of a measurement in parentheses next to the measurement — in your case, 
$$15.67(1)\text{ mm} \quad\text{or}\quad 0.015\,67(1)\text{ m}.$$  This format is common among precision measurement folks.
",rob,https://physics.stackexchange.com/users/44126,http://physics.stackexchange.com/questions/112081/significant-error-conversion,SCIENCE,physics.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,1.0,1.0,1.0,0.6666666666666666,1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,0.3333333333333333,1.0,Significant error conversion,"So my problem is: let's say that what we measure is 15, 67mm, and the significant error is $\ PM 0, 01 $mm. Then we convert the measured value to the instrument value of US $001.567 billion, so is the significant error $\ PM 0.00001 $m?","You are correct that an uncertainty of 0.01 mm is the same as an uncertainty of 0.000 01 m.  The unedited version of your question contained a factor-of-ten error.

For numbers with many significant digits, or numbers which are for whatever reason written in cumbersome units, there are a couple of tricks people use to avoid getting confused and making factor-of-ten errors.  One is to write the digits in groups separated by spaces.  (And if you're fussy about such things and your software supports it, you can use non-breaking thin spaces).  Another is to write the uncertainty in the last digits of a measurement in parentheses next to the measurement — in your case, 
$$15.67(1)\text{ mm} \quad\text{or}\quad 0.015\,67(1)\text{ m}.$$  This format is common among precision measurement folks.
"
3541,3541,5648,Can Spoils be trashed by Counterfeit?,"I'm looking for an authoritative answer here. Where does the Spoils card end up after being played twice by Counterfeit?

In fact, can Spoils be trashed at all? My understanding is that yes it can when it isn't played, e.g. in order to increase the value of Forager.
",John Robertson,https://boardgames.stackexchange.com/users/800,"Spoils is played twice, but is returned to the Spoils pile and not trashed.

Spoils is a treasure providing three coins that reads:


  When you play this, return it to the Spoils pile.


Counterfeit reads:


  When you play this, you may play a Treasure from your hand twice. If you do, trash that Treasure.


According to the Dark Ages rulebook (PDF), page 11:


  If you use Counterfeit to play Spoils twice, you will get [six coins], (in addition to the [one coin] from Counterfeit) and return Spoils to the Spoils pile; you will be unable to trash it.


To answer your second question, Spoils can be trashed, but not when it is played, exactly as you expect.
",Johno,https://boardgames.stackexchange.com/users/1678,http://boardgames.stackexchange.com/questions/12673/can-spoils-be-trashed-by-counterfeit,CULTURE,boardgames.stackexchange.com,0.3333333333333333,1.0,0.0,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,1.0,Can stolen goods be spoiled by fake things?,"I'm looking for an authoritative answer here. Where does the Spoils card end up after being played twice by Counterfeit?

In fact, can Spoils be trashed at all? My understanding is that yes it can when it isn't played, e.g. in order to increase the value of Forager.
","Spoils is played twice, but is returned to the Spoils pile and not trashed.

Spoils is a treasure providing three coins that reads:


  When you play this, return it to the Spoils pile.


Counterfeit reads:


  When you play this, you may play a Treasure from your hand twice. If you do, trash that Treasure.


According to the Dark Ages rulebook (PDF), page 11:


  If you use Counterfeit to play Spoils twice, you will get [six coins], (in addition to the [one coin] from Counterfeit) and return Spoils to the Spoils pile; you will be unable to trash it.


To answer your second question, Spoils can be trashed, but not when it is played, exactly as you expect.
"
1833,1833,2910,What kind of metrics should I collect for a website/web app,"I have a website that allows users to register for accounts, login, and renew an annual membership fee. They can also update their personal profile, their personal profile, look at a list of their employees, make bulk payments for their employees, view receipts and invoices, etc.

For non-members it's a regular website with a lot of pages, but for members, it has quite a few member only areas, with more to come (Such as forums). It also has a job listings page, course registrations, etc.

What are some useful ""metrics"" I can collect to give me meaningful information about the site, that I can share with my clients. I really don't know a lot about collecting data about this kind of thing, and would like to learn.

I already have a dashboard where the admins can view/export registrations this week and registrations by week for the past 30 weeks. I've been able to show them that registrations spiked after sending out an email about the new system.

I'm think I'll also be adding stats about how often users update their profiles and how many users have updated their profile that day/week. 

Thanks
",Brandon Wamboldt,https://programmers.stackexchange.com/users/3382,"Robert has a good set of metrics for site use.

For performance metrics I collect (for all page):


number of visits to the page.
total time spend serving the page.
average time spent serving the page.
maximum time spent serving the page.


For application pages it can useful to record separate statistics for gets and posts.  This information can be extremely useful in finding bottlenecks and selecting pages to optimize.
",BillThor,https://programmers.stackexchange.com/users/17320,http://programmers.stackexchange.com/questions/115036/what-kind-of-metrics-should-i-collect-for-a-website-web-app,TECHNOLOGY,programmers.stackexchange.com,0.8333333333333334,0.6666666666666666,0.0,0.5,1.0,0.5,0.6666666666666666,0.5,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.8333333333333334,0.8333333333333334,0.6666666666666666,0.8333333333333334,1.0,0.8,0.5,0.5,0.0,1.0,What metrics should I collect for a website / Web Application,"I have a website that allows users to register for accounts, login, and renew an annual membership fee. They can also update their personal profile, their personal profile, look at a list of their employees, make bulk payments for their employees, view receipts and invoices, etc.

For non-members it's a regular website with a lot of pages, but for members, it has quite a few member only areas, with more to come (Such as forums). It also has a job listings page, course registrations, etc.

What are some useful ""metrics"" I can collect to give me meaningful information about the site, that I can share with my clients. I really don't know a lot about collecting data about this kind of thing, and would like to learn.

I already have a dashboard where the admins can view/export registrations this week and registrations by week for the past 30 weeks. I've been able to show them that registrations spiked after sending out an email about the new system.

I'm think I'll also be adding stats about how often users update their profiles and how many users have updated their profile that day/week. 

Thanks
","Robert has a good set of metrics for site use.

For performance metrics I collect (for all page):


number of visits to the page.
total time spend serving the page.
average time spent serving the page.
maximum time spent serving the page.


For application pages it can useful to record separate statistics for gets and posts.  This information can be extremely useful in finding bottlenecks and selecting pages to optimize.
"
1722,1722,2726,"WLAN roaming on same, or different channel","I've setup a router in my basement, and an access point in my attic floor. They are connected with a patch cable. Both have the same SSID and WPA2 security. Roaming does work. But, what I want to know is, if I need to set them on different channels, or do they need the exact same channel to share. I've read many community forums and manuals, but yet it is not clear what to do because they have different opinions.


Router: Fritz!Box 7270
Accesspoint: Netgear WN604

",JohannesM,https://superuser.com/users/60317,"If you use WDS you need to use the same channel. If you use cable network between them, use different channels - roaming is based on SSID, not channel and if you've got less interference using different channels.
",Jens Erat,https://superuser.com/users/102155,http://superuser.com/questions/345487,TECHNOLOGY,superuser.com,0.8888888888888888,0.4444444444444444,0.0,1.0,0.6666666666666666,1.0,0.6666666666666666,0.5555555555555556,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.0,0.7777777777777778,1.0,0.7777777777777778,1.0,1.0,0.9333333333333332,0.3333333333333333,0.3333333333333333,1.0,1.0,WLAN roaming on the same or different channels,"I installed a router in the basement and an access point in the attic. They are connected by patch cables. Both have the same SSID and WPA2 security. Roaming does work. But what I want to know is if I need to set them up on different channels, or if they need to share exactly the same channel. I've read many community forums and manuals, but I don't know what to do because they have different opinions.","If you use WDS you need to use the same channel. If you use cable network between them, use different channels - roaming is based on SSID, not channel and if you've got less interference using different channels.
"
2420,2420,3859,Update query showing old data after submitting,"I have the following code:

$sql = mysql_query(""UPDATE users SET name='$name' WHERE email='$email'"") or die(mysql_error());
echo ""&lt;h4&gt;Your information has been updated&lt;/h4&gt;&lt;br /&gt;"";


&lt;form method=""post"" action=""&lt;?php echo $_SERVER['PHP_SELF']; ?&gt;""&gt;
    &lt;p&gt;
        &lt;label for='name'&gt;Name&lt;/label&gt;&lt;br /&gt;&lt;br /&gt;
        &lt;input class=""input-text required"" name=""name"" type=""text"" value=""&lt;?php echo $row[name]; ?&gt;"" /&gt;
    &lt;/p&gt;
    &lt;p&gt;&lt;input type=""submit"" name=""update"" value=""Update"" /&gt;&lt;/p&gt;
&lt;/form&gt;


After clicking Update, it updates the information in the database, but the &lt;?php echo $row['name']; ?&gt; still shows the old value. Only after refreshing the page does it show the updated information. I could have it refresh the page after updating by echoing meta refresh but I want it to still show the echo saying ""Your info has been updated"" which doesn't happen if I set it to refresh. Is there any solution?
",robk27,https://stackoverflow.com/users/1253477,"You will need to requery the database to repopulate $row or explicitly set the $row variable to your values (I would recommend repopulating it, just to be safe).

Or echo $name, instead of $row[name]
",Adam Plocher,https://stackoverflow.com/users/730566,http://stackoverflow.com/questions/12763489/update-query-showing-old-data-after-submitting,STACKOVERFLOW,stackoverflow.com,1.0,0.6666666666666666,0.0,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.6666666666666666,1.0,0.8,1.0,0.0,0.0,0.6666666666666666,Update query showing old data after submission,"I have the following code:

$sql = mysql_query(""UPDATE users SET name='$name' WHERE email='$email'"") or die(mysql_error());
echo ""&lt;h4&gt;Your information has been updated&lt;/h4&gt;&lt;br /&gt;"";


&lt;form method=""post"" action=""&lt;?php echo $_SERVER['PHP_SELF']; ?&gt;""&gt;
    &lt;p&gt;
        &lt;label for='name'&gt;Name&lt;/label&gt;&lt;br /&gt;&lt;br /&gt;
        &lt;input class=""input-text required"" name=""name"" type=""text"" value=""&lt;?php echo $row[name]; ?&gt;"" /&gt;
    &lt;/p&gt;
    &lt;p&gt;&lt;input type=""submit"" name=""update"" value=""Update"" /&gt;&lt;/p&gt;
&lt;/form&gt;


After clicking Update, it updates the information in the database, but the &lt;?php echo $row['name']; ?&gt; still shows the old value. Only after refreshing the page does it show the updated information. I could have it refresh the page after updating by echoing meta refresh but I want it to still show the echo saying ""Your info has been updated"" which doesn't happen if I set it to refresh. Is there any solution?
","You will need to requery the database to repopulate $row or explicitly set the $row variable to your values (I would recommend repopulating it, just to be safe).

Or echo $name, instead of $row[name]
"
3985,3985,6363,Theming Form Fields: Alter all fields,"In Drupal 7, you can put the following code in template.php to add the class 'vr-paragraphs' to the field called 'field_title'

function THEMENAME_form_alter(&amp;$form, &amp;$form_state, $form_id) {
       $form['field_title']['#attributes']['class'][] = 'vr-paragraphs';
}


How can I modify this code to target all fields on the form and not just 'field_title'.

Also, this code only adds the class to the form-wrapper part of the filed. How can I alter the label part?

Thanks for any help!
",big_smile,https://drupal.stackexchange.com/users/1606,"When you need to find the child items present in a form, you need to use element_children(), as Drupal functions like filter_process_format() do.  

The reason is simple: In a Drupal form array, as well as in a render array, not all the keys are child items; those keys with a name that starts with # are properties. Consider, for example, the form returned from forum_form_forum(); if you loop through it with the following code, you would add values where you should not.

foreach($form as $key =&gt; $value) {
  $form[$key]['#attributes']['class'][] = 'vr-paragraphs';
}


In fact, $form['#submit'] is not a child item, nor is $form['#theme']. In particular, when your code will be executed for the last key, you would get a PHP error. $form['#theme'] is a string, and $form['#theme']['#attributes'] would select a character of that string, supposing that '#attributes' would be evaluated as the integer 0; even in that case, $form['#theme']['#attributes']['class'][] would not be a valid PHP construct.

The correct code would be the following one.

foreach(element_children($form) as $key) {
  $form[$key]['#attributes']['class'][] = 'vr-paragraphs';
}

",kiamlaluno,https://drupal.stackexchange.com/users/199,http://drupal.stackexchange.com/questions/60557/theming-form-fields-alter-all-fields,TECHNOLOGY,drupal.stackexchange.com,1.0,0.3333333333333333,0.0,1.0,1.0,1.0,0.5,0.5,1.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,1.0,0.5,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.5,1.0,Create form field subject: change all fields,"In Drupal 7, you can put the following code in template.php to add the class 'vr-paragraphs' to the field called 'field_title'

function THEMENAME_form_alter(&amp;$form, &amp;$form_state, $form_id) {
       $form['field_title']['#attributes']['class'][] = 'vr-paragraphs';
}


How can I modify this code to target all fields on the form and not just 'field_title'.

Also, this code only adds the class to the form-wrapper part of the filed. How can I alter the label part?

Thanks for any help!
","When you need to find the child items present in a form, you need to use element_children(), as Drupal functions like filter_process_format() do.  

The reason is simple: In a Drupal form array, as well as in a render array, not all the keys are child items; those keys with a name that starts with # are properties. Consider, for example, the form returned from forum_form_forum(); if you loop through it with the following code, you would add values where you should not.

foreach($form as $key =&gt; $value) {
  $form[$key]['#attributes']['class'][] = 'vr-paragraphs';
}


In fact, $form['#submit'] is not a child item, nor is $form['#theme']. In particular, when your code will be executed for the last key, you would get a PHP error. $form['#theme'] is a string, and $form['#theme']['#attributes'] would select a character of that string, supposing that '#attributes' would be evaluated as the integer 0; even in that case, $form['#theme']['#attributes']['class'][] would not be a valid PHP construct.

The correct code would be the following one.

foreach(element_children($form) as $key) {
  $form[$key]['#attributes']['class'][] = 'vr-paragraphs';
}

"
5952,5952,9430,Identifying sequential patterns,"I am working with sequence data which are long lists of malware win-api calls. I am trying to cast the problem of identifying 'malware behavior' into one of finding sequential patterns. I treat each api call as a single item Itemset. The number of different possible items (api calls) is quite large. 

Now, when I apply the SPADE algorithm (see also, Zaki, SPADE: An Efficient Algorithm for Mining Frequent Sequences, Machine Learning, 42, 31–60, 2001) I run into memory problems.
Is there a better alternative way to find sequential patterns among large high vocabulary sequences?
",chet,https://stats.stackexchange.com/users/4534,"You can map the data into a feature space where sequence is important, along with both statistics calculated over sliding windows &amp; cumulative statistics, and use that in a decision tree.

A decision tree could handle both sequences and non-sequential data.  This may substantially reduce your data complexity.
",Iterator,https://stats.stackexchange.com/users/5256,http://stats.stackexchange.com/questions/14651/identifying-sequential-patterns,SCIENCE,stats.stackexchange.com,0.7777777777777778,0.4444444444444444,0.0,1.0,0.6666666666666666,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.3333333333333333,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.0,0.3333333333333333,1.0,Identify sequence patterns,"I'm working on sequence data, which is a long list of malware win API calls. I try to turn the problem of identifying ""malware behavior"" into the problem of finding sequential patterns. I treat each API call as a single set of items. The number of different possible items (API calls) is quite large.","You can map data to feature spaces where sequences are important, as well as statistics and cumulative statistics computed on sliding windows, and use them in decision trees."
4687,4687,7432,How to forcibly disconnect a application listening on a port,"I have an app that doesn't properly stop listening on a port.

How do I force it to stop so I can open the application again/use that port again?
",bobber205,https://serverfault.com/users/24088,"If the application is running under unix,

Kill -9 &lt;pid&gt; 


will forcefully kill a process releasing all it's resources. The 

&lt;pid&gt; 


can be found by doing a 

ps aex


at the command line.
",Stephen Thompson,https://serverfault.com/users/25622,http://serverfault.com/questions/115194,TECHNOLOGY,serverfault.com,1.0,1.0,0.0,1.0,0.6666666666666666,1.0,0.7777777777777778,0.4444444444444444,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.3333333333333333,0.8888888888888888,How to forcibly disconnect an application listening to a port,"I have an app that doesn't properly stop listening on a port.

How do I force it to stop so I can open the application again/use that port again?
","If the application is running under unix,

Kill -9 &lt;pid&gt; 


will forcefully kill a process releasing all it's resources. The 

&lt;pid&gt; 


can be found by doing a 

ps aex


at the command line.
"
5615,5615,8908,Show Windows 7 logon time?,"On Windows 7 Ultimate, is there a way to see when I logged on into the current session?

I want to find out how long I have been at the PC / when I started it up.
",magnattic,https://superuser.com/users/69189,"You can also use 

systeminfo


and next to 

System Boot Time:


It will be in the format

9/17/2011, 10:16:38 PM

",Alpine,https://superuser.com/users/71055,http://superuser.com/questions/310128,TECHNOLOGY,superuser.com,1.0,0.6666666666666666,0.0,1.0,1.0,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.7777777777777778,1.0,0.5555555555555556,1.0,1.0,0.9333333333333332,0.6666666666666666,0.3333333333333333,0.0,0.8888888888888888,Show windows 7 login time?,"On Windows 7 ultimate, is there any way to see when I log in to the current session?","You can also use 

systeminfo


and next to 

System Boot Time:


It will be in the format

9/17/2011, 10:16:38 PM

"
1535,1535,2410,How to mount a ham?,"I bought a Serrano ham on sale. It's the whole pig's leg, and it comes with a kind of a stand. However, the stand was delivered in pieces like IKEA furniture, but unlike IKEA, it has no manual explaining what goes where. 

I'm especially puzzled about the large ring and the small trapez-without-base shaped pieces. Once must go up to hold the ankle, the other one down to hold the haunch. But which goes where, and how do I fasten the ham to the metal? Do I have to screw the metal screws through the bone? 


The picture shows all parts delivered, only the inbus key is not in the frame. I put the trapezoid part onto the lower hole and started fastening it with a pointy screw; it's quite a long screw (7-8cm). 
",rumtscho,https://cooking.stackexchange.com/users/4638,"This should help, it's not precisely exact, but you can probably figure it out from here.


",Jolenealaska,https://cooking.stackexchange.com/users/20183,http://cooking.stackexchange.com/questions/53944/how-to-mount-a-ham,LIFE_ARTS,cooking.stackexchange.com,0.7777777777777778,0.5555555555555556,0.0,0.0,1.0,0.6666666666666666,0.6666666666666666,0.4444444444444444,1.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.8888888888888888,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.2,0.0,0.0,0.0,1.0,How do I pack the ham?,"I bought a Serrano ham on sale. It's the whole pig's leg, and it comes with a kind of a stand. However, the stand was delivered in pieces like IKEA furniture, but unlike IKEA, it has no manual explaining what goes where. 

I'm especially puzzled about the large ring and the small trapez-without-base shaped pieces. Once must go up to hold the ankle, the other one down to hold the haunch. But which goes where, and how do I fasten the ham to the metal? Do I have to screw the metal screws through the bone? 


The picture shows all parts delivered, only the inbus key is not in the frame. I put the trapezoid part onto the lower hole and started fastening it with a pointy screw; it's quite a long screw (7-8cm). 
","This should help, it's not precisely exact, but you can probably figure it out from here.


"
3227,3227,5148,How to make extra crispy and crunchy breading like KFC?,"I'm wondering how I would go about making extra crispy chicken breading like they do at many places like KFC and the like. Is there a certain ingredient that makes the breading like that?

Any assistance would be very much appreciated, and feel free to share any of your own recipes for crispy chicken breading if you have them. I'll be sure to put them to good use!

Thanks!
",James Mowery,https://cooking.stackexchange.com/users/2109,"First boil the chicken in  cocacola, and then fry it with flour + egg
",Sadin Suraweera,https://cooking.stackexchange.com/users/14098,http://cooking.stackexchange.com/questions/5764/how-to-make-extra-crispy-and-crunchy-breading-like-kfc,LIFE_ARTS,cooking.stackexchange.com,1.0,0.8888888888888888,0.0,0.6666666666666666,1.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.7777777777777778,0.8888888888888888,0.5555555555555556,0.6666666666666666,1.0,0.7333333333333333,0.3333333333333333,0.6666666666666666,0.0,0.6666666666666666,How to make crisp bread like KFC?,"I'm wondering how I would go about making extra crispy chicken breading like they do at many places like KFC and the like. Is there a certain ingredient that makes the breading like that?

Any assistance would be very much appreciated, and feel free to share any of your own recipes for crispy chicken breading if you have them. I'll be sure to put them to good use!

Thanks!
","First boil the chicken in  cocacola, and then fry it with flour + egg
"
5764,5764,9134,Migration Assistant fails on Ethernet Mavericks-to-Mavericks migration,"I have the following setup and am attempting the use Migration Assistant over Ethernet:


Source machine: Early 2009 24-inch iMac running OS X 10.9 
Destination
machine: Latest MacBook Pro Retina running OS X 10.9
Connection: direct Ethernet cable between machines


When I use Migration assistant following Apple's documentation I pass through the confirmation code step on both machines, and then get as far as the ""Checking Source Machine"" screen on the destination, and am stuck there for about 10 minutes, at which point the destination machine jumps back to the language selection setup page, and the source machine says ""This machine is attempting to reconnect to your other Mac"".

At this point I'm at a dead end: Attempting to proceed through the setup again on the destination gets me nowhere, and the only option on the source machine is ""Cancel Transfer"", which quits Migration Assistant there and ends the whole process.

On the source machine I've turned off LittleSnitch, which I normally have running, turned off Apple's firewall, and enabled file sharing.

What am I missing? Are there other settings somewhere that I need to check? I've also tried using FireWire to connect my machines, but have a different set of issues there.
",orome,https://apple.stackexchange.com/users/4395,"I have the same setup except my iMac sports Thunderbolt. I had the same problem and never solved it, but I did find the following work-around helpful:

Place the iMac in Target Mode by going to Apple|System Preferences|Startup Disk, make sure your startup disk is highlighted, select Target Disk Mode and confirm. Connect the computers by Firewire or Thunderbolt (TDM does not support Ethernet). Start Migration Assistant on the MacBook Pro, allow it to change your system, and select the iMac's startup disk.

From there it is easy sailing - choose what you want and how to handle the user accounts and you are home and dry! Don't forget to eject all connected iMac drives before unplugging the cables.
",TonyM,https://apple.stackexchange.com/users/64412,http://apple.stackexchange.com/questions/111615/migration-assistant-fails-on-ethernet-mavericks-to-mavericks-migration,TECHNOLOGY,apple.stackexchange.com,0.8888888888888888,0.4444444444444444,0.0,0.3333333333333333,1.0,0.6666666666666666,0.6666666666666666,0.4444444444444444,0.6666666666666666,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.0,0.8888888888888888,0.7777777777777778,0.5555555555555556,0.8888888888888888,1.0,0.7333333333333333,1.0,0.3333333333333333,0.6666666666666666,0.8888888888888888,The migration assistant failed in the Ethernet calf to calf migration,"I have the following setup and am attempting the use Migration Assistant over Ethernet:


Source machine: Early 2009 24-inch iMac running OS X 10.9 
Destination
machine: Latest MacBook Pro Retina running OS X 10.9
Connection: direct Ethernet cable between machines


When I use Migration assistant following Apple's documentation I pass through the confirmation code step on both machines, and then get as far as the ""Checking Source Machine"" screen on the destination, and am stuck there for about 10 minutes, at which point the destination machine jumps back to the language selection setup page, and the source machine says ""This machine is attempting to reconnect to your other Mac"".

At this point I'm at a dead end: Attempting to proceed through the setup again on the destination gets me nowhere, and the only option on the source machine is ""Cancel Transfer"", which quits Migration Assistant there and ends the whole process.

On the source machine I've turned off LittleSnitch, which I normally have running, turned off Apple's firewall, and enabled file sharing.

What am I missing? Are there other settings somewhere that I need to check? I've also tried using FireWire to connect my machines, but have a different set of issues there.
","I have the same setup except my iMac sports Thunderbolt. I had the same problem and never solved it, but I did find the following work-around helpful:

Place the iMac in Target Mode by going to Apple|System Preferences|Startup Disk, make sure your startup disk is highlighted, select Target Disk Mode and confirm. Connect the computers by Firewire or Thunderbolt (TDM does not support Ethernet). Start Migration Assistant on the MacBook Pro, allow it to change your system, and select the iMac's startup disk.

From there it is easy sailing - choose what you want and how to handle the user accounts and you are home and dry! Don't forget to eject all connected iMac drives before unplugging the cables.
"
2709,2709,4319,"Variations in the pronunciation of ""the""","Although there are rather simple rules determining the pronunciation of ""the"", native speakers quite often deviate from these rules (including, e.g., TV shows). According to the Longman Pronunciation Dictionary,


  The EFL learner is advised to use [ðə] before a consonant sound (the
  boy, the house), [ði] before a vowel sound (the egg, the hour). Native
  speakers, however, sometimes ignore this distribution, in particular
  by using [ðə] before a vowel (which is in turn usually reinforced by a
  preceding ʔ), or by using [ði:] in any
  environment, though especially before a hesitation pause. Furthermore,
  some speakers use stressed [ðə] as a strong form, rather than the
  usual [ði:].


My question is: when native speakers use [ðə] instead of [ði] before a vowel sound, do they do it on purpose or accidentally? If it is on purpose, how do they (typically) decide which pronunciation to use? What is a valid reason to use [ðə] before a vowel sound?
",painfulenglish,https://english.stackexchange.com/users/71165,"To summarize the discussion here and elsewhere:

In contrast to the pronunciation-based distinction between a and an, the pronunciation of ""the"" is not strictly determined by the pronunciation of the following word. The guidelines in, for example, the Longman Pronunciation Dictionary are in fact just guidelines for non-native speakers. If one listens closely to native speakers, it becomes obvious that [ðə] and [ði] are chosen relatively freely, irrespective of the following word. Hence, it is interesting that people who learn English as a foreign language are usually told by teachers and textbooks that the pronunciation of ""the"" follows the same strict rule as the distinction between a and an. This misconception can even be found on English language sites such as here.

A similar answer was given here.
",painfulenglish,https://english.stackexchange.com/users/71165,http://english.stackexchange.com/questions/191979/variations-in-the-pronunciation-of-the,CULTURE,english.stackexchange.com,0.7777777777777778,0.3333333333333333,0.6666666666666666,0.3333333333333333,1.0,0.3333333333333333,0.7777777777777778,0.8888888888888888,1.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,1.0,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,1.0,0.0,0.3333333333333333,1.0,1.0,"The pronunciation change of ""the""","Although there are rather simple rules determining the pronunciation of ""the"", native speakers quite often deviate from these rules (including, e.g., TV shows). According to the Longman Pronunciation Dictionary,


  The EFL learner is advised to use [ðə] before a consonant sound (the
  boy, the house), [ði] before a vowel sound (the egg, the hour). Native
  speakers, however, sometimes ignore this distribution, in particular
  by using [ðə] before a vowel (which is in turn usually reinforced by a
  preceding ʔ), or by using [ði:] in any
  environment, though especially before a hesitation pause. Furthermore,
  some speakers use stressed [ðə] as a strong form, rather than the
  usual [ði:].


My question is: when native speakers use [ðə] instead of [ði] before a vowel sound, do they do it on purpose or accidentally? If it is on purpose, how do they (typically) decide which pronunciation to use? What is a valid reason to use [ðə] before a vowel sound?
","To summarize the discussion here and elsewhere:

In contrast to the pronunciation-based distinction between a and an, the pronunciation of ""the"" is not strictly determined by the pronunciation of the following word. The guidelines in, for example, the Longman Pronunciation Dictionary are in fact just guidelines for non-native speakers. If one listens closely to native speakers, it becomes obvious that [ðə] and [ði] are chosen relatively freely, irrespective of the following word. Hence, it is interesting that people who learn English as a foreign language are usually told by teachers and textbooks that the pronunciation of ""the"" follows the same strict rule as the distinction between a and an. This misconception can even be found on English language sites such as here.

A similar answer was given here.
"
3592,3592,5736,PostGIS to GeoJSON with GDAL: how to get lat/longs?,"I'm trying to convert line features from PostGIS to GeoJSON files, as follows:

from psycopg2 import *
from subprocess import call

conn = connect(dbname='gis')
cur=conn.cursor()

cur.execute(""SELECT distinct osm_id,route_name from planet_osm_line where route_name like '%Rail Trail' and network='rcn';"")

for record in cur:
  print ""%s"" % record[1]
  call ([""ogr2ogr"", ""-f"", ""GeoJSON"", record[1] + "".json"",  'PG:dbname=\'gis\'', ""-sql"", 'SELECT route_name,osm_id,tags::hstore-&gt;\'state\' as state,way from planet_osm_line where osm_id=%d' % record[0]])


That is, ultimately ogr2ogr gets called like this:

ogr2ogr -f GeoJSON blah.json ""PG:dbname='gis'"" -sql 'SELECT route_name,osm_id,tags::hstore-&gt;\'state\' as state,way from planet_osm_line where osm_id=-12345'


The GeoJSON files that get created have coordinates that look like this [ 16153119.78, -4561568.23 ]:

{ ""type"": ""Feature"", ""properties"": { ""route_name"": ""Waverley Rail Trail"", ""osm_id"": -64660, ""state"": null }, ""geometry"": { ""type"": ""LineString"", ""coordinates"": [ [ 16153119.78, -4561568.23 ], [ 16153117.1, -4561567.48 ], [ 16153114.81, -4561565.86 ], [ 16153113.24, -4561563.55 ], [ 16153112.64, -4561561.63 ], [ 16153112.64, -4561558.82 ], [ 16153113.6, -4561556.2 ], [ 16153115.39, -4561554.05 ], [ 16153117.82, -4561552.66 ], [ 16153119.98, -4561552.2 ], [ 16153122.76, -4561552.48 ], [ 16153125.28, -4561553.69 ], [ 16153127.35, -4561555.88 ], [ 16153128.43, -4561558.46 ], [ 16153128.62, -4561560.38 ], [ 16153128.08, -4561563.13 ], [ 16153126.64, -4561565.51 ], [ 16153124.47, -4561567.26 ], [ 16153121.82, -4561568.17 ], [ 16153119.78, -4561568.23 ] ] } }


Please forgive my ignorance, but what am I doing wrong here? I assume what is being written is some kind of projected value rather than the raw lat/long - so how do I get those? 

I've tried using t_srs=ESPG:3857 but that didn't fix it.
",Steve Bennett,https://gis.stackexchange.com/users/8442,"Gene's answer pointed me in the right direction. The simple answer seems to be that the data in PostGIS is in Web Mercator (EPSG 3786) and so if I want lat/long it needs to be re-projected (or de-projected...), with an SRID like EPSG 4326.

call ([""ogr2ogr"", ""-f"", ""GeoJSON"", record[1] + "".json"",  'PG:dbname=\'gis\'', ""-sql"", 'SELECT route_name,osm_id,tags::hstore-&gt;\'state\' as state,way from planet_osm_line where osm_id=%d' % record[0], ""-t_srs"", ""EPSG: 4326""])




EDIT
Turns out you need to explicitly state the source SRS as well:

call ([""ogr2ogr"", ""-f"", ""GeoJSON"", record[1] + "".json"",  'PG:dbname=\'gis\'', ""-sql"", 'SELECT ...', ""-t_srs"", ""EPSG: 4326"", ""-s_srs"", ""EPSG:3857""])

",Steve Bennett,https://gis.stackexchange.com/users/8442,http://gis.stackexchange.com/questions/92960/postgis-to-geojson-with-gdal-how-to-get-lat-longs,TECHNOLOGY,gis.stackexchange.com,0.6666666666666666,0.6666666666666666,0.0,1.0,1.0,1.0,0.4444444444444444,0.4444444444444444,0.3333333333333333,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.6666666666666666,0.8888888888888888,Using GDAL to add PostGIS to geojson: how to get lat / long?,"I'm trying to convert line features from PostGIS to GeoJSON files, as follows:

from psycopg2 import *
from subprocess import call

conn = connect(dbname='gis')
cur=conn.cursor()

cur.execute(""SELECT distinct osm_id,route_name from planet_osm_line where route_name like '%Rail Trail' and network='rcn';"")

for record in cur:
  print ""%s"" % record[1]
  call ([""ogr2ogr"", ""-f"", ""GeoJSON"", record[1] + "".json"",  'PG:dbname=\'gis\'', ""-sql"", 'SELECT route_name,osm_id,tags::hstore-&gt;\'state\' as state,way from planet_osm_line where osm_id=%d' % record[0]])


That is, ultimately ogr2ogr gets called like this:

ogr2ogr -f GeoJSON blah.json ""PG:dbname='gis'"" -sql 'SELECT route_name,osm_id,tags::hstore-&gt;\'state\' as state,way from planet_osm_line where osm_id=-12345'


The GeoJSON files that get created have coordinates that look like this [ 16153119.78, -4561568.23 ]:

{ ""type"": ""Feature"", ""properties"": { ""route_name"": ""Waverley Rail Trail"", ""osm_id"": -64660, ""state"": null }, ""geometry"": { ""type"": ""LineString"", ""coordinates"": [ [ 16153119.78, -4561568.23 ], [ 16153117.1, -4561567.48 ], [ 16153114.81, -4561565.86 ], [ 16153113.24, -4561563.55 ], [ 16153112.64, -4561561.63 ], [ 16153112.64, -4561558.82 ], [ 16153113.6, -4561556.2 ], [ 16153115.39, -4561554.05 ], [ 16153117.82, -4561552.66 ], [ 16153119.98, -4561552.2 ], [ 16153122.76, -4561552.48 ], [ 16153125.28, -4561553.69 ], [ 16153127.35, -4561555.88 ], [ 16153128.43, -4561558.46 ], [ 16153128.62, -4561560.38 ], [ 16153128.08, -4561563.13 ], [ 16153126.64, -4561565.51 ], [ 16153124.47, -4561567.26 ], [ 16153121.82, -4561568.17 ], [ 16153119.78, -4561568.23 ] ] } }


Please forgive my ignorance, but what am I doing wrong here? I assume what is being written is some kind of projected value rather than the raw lat/long - so how do I get those? 

I've tried using t_srs=ESPG:3857 but that didn't fix it.
","Gene's answer pointed me in the right direction. The simple answer seems to be that the data in PostGIS is in Web Mercator (EPSG 3786) and so if I want lat/long it needs to be re-projected (or de-projected...), with an SRID like EPSG 4326.

call ([""ogr2ogr"", ""-f"", ""GeoJSON"", record[1] + "".json"",  'PG:dbname=\'gis\'', ""-sql"", 'SELECT route_name,osm_id,tags::hstore-&gt;\'state\' as state,way from planet_osm_line where osm_id=%d' % record[0], ""-t_srs"", ""EPSG: 4326""])




EDIT
Turns out you need to explicitly state the source SRS as well:

call ([""ogr2ogr"", ""-f"", ""GeoJSON"", record[1] + "".json"",  'PG:dbname=\'gis\'', ""-sql"", 'SELECT ...', ""-t_srs"", ""EPSG: 4326"", ""-s_srs"", ""EPSG:3857""])

"
1372,1372,2158,gradle execute task after build,"I am using the build in gradle.

My build.gradle file like this:

project('a'){
    apply plugin: 'java'
    apply plugin: 'eclipse'
    apply plugin: 'application'

    buildDir = 'build'

    [compileJava, compileTestJava]*.options*.encoding = 'UTF-8'
    repositories {
        mavenCentral()
    }
    dependencies {
        compile 'org.slf4j:slf4j-api:1.7.7'
    } 
}


When I input the gradle build in the command, I want gradle execute task after build.
I found a mustRunAfter on the Internet.
I have tried a variety of ways but failed.
Please tell me if you know how.
",jake,https://stackoverflow.com/users/4310818,"What you need is finalizedBy, see the following script:

apply plugin: 'java'

task finalize &lt;&lt; {
    println('finally!')
}

build.finalizedBy(finalize)


Here are the docs.
",Opal,https://stackoverflow.com/users/542270,http://stackoverflow.com/questions/30857350/gradle-execute-task-after-build,STACKOVERFLOW,stackoverflow.com,1.0,0.3333333333333333,0.0,0.0,1.0,0.0,1.0,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,0.0,1.0,Gradually implement the task after completion,"I am using the build in gradle.

My build.gradle file like this:

project('a'){
    apply plugin: 'java'
    apply plugin: 'eclipse'
    apply plugin: 'application'

    buildDir = 'build'

    [compileJava, compileTestJava]*.options*.encoding = 'UTF-8'
    repositories {
        mavenCentral()
    }
    dependencies {
        compile 'org.slf4j:slf4j-api:1.7.7'
    } 
}


When I input the gradle build in the command, I want gradle execute task after build.
I found a mustRunAfter on the Internet.
I have tried a variety of ways but failed.
Please tell me if you know how.
","What you need is finalizedBy, see the following script:

apply plugin: 'java'

task finalize &lt;&lt; {
    println('finally!')
}

build.finalizedBy(finalize)


Here are the docs.
"
2950,2950,4694,How to enable or disable services?,"I read about how to enable and disable services in Ubuntu and it seems that there are different possibilities to manage them.

The first method I found is update-rc.d to add new services to startup, which aims on the /etc/init.d folder and its contents.

The other one I found is to edit .conf files in the /etc/init folder.

What's the recommended way to enable / disable / add services and why?

Could you please give a short bulletproof step by step example on how to add a service in Ubuntu and enable and disable it?
",NES,https://askubuntu.com/users/7155,"For those of us who run Ubuntu over ssh, I think the nicest option is rcconf - a text based program: 

sudo apt-get install rcconf
sudo rcconf




Navigate with tab and arrow keys, press spacebar to enable/disable. Changes are persistent across restarts.

Screenshot borrowed from this blogpost, which also shows sysv-rc-conf - a similar tool that also lets you set the runlevel. (For those who happen to care enough about runlevels to wish to change them :) 

Unfortunately, rcconf doesn't work with upstart (services listed in /etc/init/*), just with the traditional mechanism (ls -l /etc/init.d/* - the ones that are not symbolic links).

Fortunately, many of the services that are relevant when ssh-ing in to a server (Apache, Tomcat, mdadm, boinc-client...) haven't been moved to upstart yet. 
",j-g-faustus,https://askubuntu.com/users/2337,http://askubuntu.com/questions/19320/how-to-enable-or-disable-services,TECHNOLOGY,askubuntu.com,0.6666666666666666,0.3333333333333333,0.0,0.0,1.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,1.0,1.0,1.0,How do I enable or disable services?,"I read about how to enable and disable services in Ubuntu and it seems that there are different possibilities to manage them.

The first method I found is update-rc.d to add new services to startup, which aims on the /etc/init.d folder and its contents.

The other one I found is to edit .conf files in the /etc/init folder.

What's the recommended way to enable / disable / add services and why?

Could you please give a short bulletproof step by step example on how to add a service in Ubuntu and enable and disable it?
","For those of us who run Ubuntu over ssh, I think the nicest option is rcconf - a text based program: 

sudo apt-get install rcconf
sudo rcconf




Navigate with tab and arrow keys, press spacebar to enable/disable. Changes are persistent across restarts.

Screenshot borrowed from this blogpost, which also shows sysv-rc-conf - a similar tool that also lets you set the runlevel. (For those who happen to care enough about runlevels to wish to change them :) 

Unfortunately, rcconf doesn't work with upstart (services listed in /etc/init/*), just with the traditional mechanism (ls -l /etc/init.d/* - the ones that are not symbolic links).

Fortunately, many of the services that are relevant when ssh-ing in to a server (Apache, Tomcat, mdadm, boinc-client...) haven't been moved to upstart yet. 
"
5537,5537,8797,ASP.NET MVC 2.0 NHibernate Configure() issue,"I have installed NHibernate for my ASP.NET web app although I'm getting a problem in real-time on the following line of code:

            if (_sessionFactory == null)
            {
                _sessionFactory = new Configuration().Configure().BuildSessionFactory();

            }


Looking at the inner exception the problem is this:

{""Could not find file 'D:\Websites\Test\Test\Test\bin\hibernate.cfg.xml'."":""D:\Websites\Test\Test\Test\bin\hibernate.cfg.xml""}

This makes sense, as the file doesnt exist in that location.  This line of code is within my Core project.  File hibernate.cfg.xml is currently in my Infrastucture project, not my Core.  Should this be?  I have copied the file into this location although I still get problems.  If I manually copy the file into this location within windows explorer I then get the following error during runtime.


  {""Could not load file or assembly
  'Infrastructure' or one of its
  dependencies. The system cannot find
  the file specified."":""Infrastructure""}


Also, I'm missing DynamicProxy.dll as I'm using castle and I couldnt see a version of the DynamicProxy in the castle folder that I downloaded from http://sourceforge.net/projects/nhibernate/

any suggestions?  I can see LinFu.DynamicProxy.dll within the download although it says I only need one of the folders, Linfu or Castle, and I'm using Castle for this experiment.  Not sure if this has anything to do with it, just thought it might help.

any ideas?  Many thanks,
James
",JamesRadford,https://stackoverflow.com/users/561951,"About ""Could not find hibernate.cfg.xml"": you can either set it to ""Copy to Output"" (see this) or configure it as an embedded resource.

About ""Could not load assembly Infrastructure"": you're missing Infrastructure.dll in your bin, or one of its dependencies, just as the error says.

About missing DynamicProxy.dll: if you're using NHibernate 3.x all you need to use the Castle bytecode provider is NHibernate.ByteCode.Castle.dll and Castle.Core.dll
",Mauricio Scheffer,https://stackoverflow.com/users/21239,http://stackoverflow.com/questions/4611119/asp-net-mvc-2-0-nhibernate-configure-issue,STACKOVERFLOW,stackoverflow.com,0.6666666666666666,0.4444444444444444,0.0,1.0,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,0.0,0.6666666666666666,1.0,0.5555555555555556,1.0,1.0,0.8666666666666666,1.0,0.0,0.6666666666666666,0.8888888888888888,Asp.net MVC 2.0 NHibernate configuration() problem,"I have installed NHibernate for my ASP.NET web app although I'm getting a problem in real-time on the following line of code:

            if (_sessionFactory == null)
            {
                _sessionFactory = new Configuration().Configure().BuildSessionFactory();

            }


Looking at the inner exception the problem is this:

{""Could not find file 'D:\Websites\Test\Test\Test\bin\hibernate.cfg.xml'."":""D:\Websites\Test\Test\Test\bin\hibernate.cfg.xml""}

This makes sense, as the file doesnt exist in that location.  This line of code is within my Core project.  File hibernate.cfg.xml is currently in my Infrastucture project, not my Core.  Should this be?  I have copied the file into this location although I still get problems.  If I manually copy the file into this location within windows explorer I then get the following error during runtime.


  {""Could not load file or assembly
  'Infrastructure' or one of its
  dependencies. The system cannot find
  the file specified."":""Infrastructure""}


Also, I'm missing DynamicProxy.dll as I'm using castle and I couldnt see a version of the DynamicProxy in the castle folder that I downloaded from http://sourceforge.net/projects/nhibernate/

any suggestions?  I can see LinFu.DynamicProxy.dll within the download although it says I only need one of the folders, Linfu or Castle, and I'm using Castle for this experiment.  Not sure if this has anything to do with it, just thought it might help.

any ideas?  Many thanks,
James
","About ""Could not find hibernate.cfg.xml"": you can either set it to ""Copy to Output"" (see this) or configure it as an embedded resource.

About ""Could not load assembly Infrastructure"": you're missing Infrastructure.dll in your bin, or one of its dependencies, just as the error says.

About missing DynamicProxy.dll: if you're using NHibernate 3.x all you need to use the Castle bytecode provider is NHibernate.ByteCode.Castle.dll and Castle.Core.dll
"
1431,1431,2248,"If $f: \mathbb Q\to \mathbb Q$ is a homomorphism, prove that $f(x)=0$ for all $x\in\mathbb Q$ or $f(x)=x$ for all $x$ in $\mathbb Q$.","If $f: \mathbb Q\to \mathbb Q$ is a homomorphism, prove that $f(x)=0$ for all $x\in\mathbb Q$ or $f(x)=x$ for all $x$ in $\mathbb Q$.

I'm wondering if you can help me with this one? 
",Mirna,https://math.stackexchange.com/users/36579,"If $f$ is a homomorphism of rings, we know the kernel of $f$ has to be an ideal of $\mathbb{Q}$, but as $\mathbb{Q}$ is a field, the only ideals of $\mathbb{Q}$ are $0$ and $\mathbb{Q}$ itself.
",Kris,https://math.stackexchange.com/users/35940,http://math.stackexchange.com/questions/175477/if-f-mathbb-q-to-mathbb-q-is-a-homomorphism-prove-that-fx-0-for-all-x,SCIENCE,math.stackexchange.com,0.8888888888888888,0.6666666666666666,0.0,1.0,0.6666666666666666,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.3333333333333333,0.6666666666666666,1.0,"If $f: \ mathbb Q \ to \ mathbb q $is homomorphic, then prove that $f (x) = 0 $means all $X \ in \ mathbb q $, or $f (x) = x $means all $x $in $\ mathbb q $.","If $f: \ mathbb Q \ to \ mathbb q $is homomorphic, then prove that $f (x) = 0 $means all $X \ in \ mathbb q $, or $f (x) = x $means all $x $in $\ mathbb q $.","If $f$ is a homomorphism of rings, we know the kernel of $f$ has to be an ideal of $\mathbb{Q}$, but as $\mathbb{Q}$ is a field, the only ideals of $\mathbb{Q}$ are $0$ and $\mathbb{Q}$ itself.
"
462,462,718,How does my app know what private key to use,"I have an app that runs on GlassFish 3.x. It communicates to a remote server over https. In my cacerts file I've added the server certs. In my keystore.jks I added the private key the company running the remote server issued me. This works great on Glassfish 2.x, however on 3.x they remote server keeps complaining that the key I have is invalid.

If I remove the key from the keystore I get the same error. It's as if it's not even loading the key, which has got me wondering how does the app / container know which key I need

My connection code looks like this:

public class SSLSocket {

private static Logger logger = LoggerFactory.getLogger(SSLSocket.class);
private ConnectionProperties connectionProperties;

public TuSSLSocket(ConnectionProperties connectionProperties) {
    this.connectionProperties = connectionProperties;
}

public SSLSocket getSSLSocket() throws Exception{
    SSLSocketFactory factory = (SSLSocketFactory) SSLSocketFactory.getDefault();
    SSLSocket socket = (SSLSocket) factory.createSocket(connectionProperties.getHost(), connectionProperties.getPort());
    socket.setSoTimeout(90000);

    return socket;
}

}


I set the Host and Port accordingly, but no where do I say go look for this alias in the keystore. So... how does the app know what alias to grab?
",Preston,https://stackoverflow.com/users/57907,"Explaining two way ssl and all that jazz is exhausting. I will try to find a useful link. However, for your information when an applicaiton deployed in glassfish acts as a client to communicating with a server over SSL ( for instance LDAP server realm configured through an SSL port), it will use glassfish server's identity certificate (from its keystore) as its client certificate.

But if you are explicitly coding for SSL handshake, client application is responsible for selecting the keystore, and presenting the certificate as part of the handshake.

Since it is working in a previous version of Glassfish, the same code should work for you. It is very likely that your problem is related to configuration. I am a bit confused about what you had added to server's keystore.jks generally the other server's certificate is added to the trust store cacerts.jks

A useful glassfish ssl example

An SSL Socket client example

Example of choosing keystore in client.
",ring bearer,https://stackoverflow.com/users/212211,http://stackoverflow.com/questions/10097708/how-does-my-app-know-what-private-key-to-use,STACKOVERFLOW,stackoverflow.com,1.0,0.4444444444444444,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.4444444444444444,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,1.0,0.0,0.7777777777777778,1.0,0.5555555555555556,1.0,1.0,0.6,0.0,0.3333333333333333,1.0,0.8888888888888888,How does my application know which private key to use,"I have an app that runs on GlassFish 3.x. It communicates to a remote server over https. In my cacerts file I've added the server certs. In my keystore.jks I added the private key the company running the remote server issued me. This works great on Glassfish 2.x, however on 3.x they remote server keeps complaining that the key I have is invalid.

If I remove the key from the keystore I get the same error. It's as if it's not even loading the key, which has got me wondering how does the app / container know which key I need

My connection code looks like this:

public class SSLSocket {

private static Logger logger = LoggerFactory.getLogger(SSLSocket.class);
private ConnectionProperties connectionProperties;

public TuSSLSocket(ConnectionProperties connectionProperties) {
    this.connectionProperties = connectionProperties;
}

public SSLSocket getSSLSocket() throws Exception{
    SSLSocketFactory factory = (SSLSocketFactory) SSLSocketFactory.getDefault();
    SSLSocket socket = (SSLSocket) factory.createSocket(connectionProperties.getHost(), connectionProperties.getPort());
    socket.setSoTimeout(90000);

    return socket;
}

}


I set the Host and Port accordingly, but no where do I say go look for this alias in the keystore. So... how does the app know what alias to grab?
","Explaining two way ssl and all that jazz is exhausting. I will try to find a useful link. However, for your information when an applicaiton deployed in glassfish acts as a client to communicating with a server over SSL ( for instance LDAP server realm configured through an SSL port), it will use glassfish server's identity certificate (from its keystore) as its client certificate.

But if you are explicitly coding for SSL handshake, client application is responsible for selecting the keystore, and presenting the certificate as part of the handshake.

Since it is working in a previous version of Glassfish, the same code should work for you. It is very likely that your problem is related to configuration. I am a bit confused about what you had added to server's keystore.jks generally the other server's certificate is added to the trust store cacerts.jks

A useful glassfish ssl example

An SSL Socket client example

Example of choosing keystore in client.
"
3075,3075,4896,Unable to apply publish properties?,"I don't know what caused Visual Studio to start thinking it needs to publish my project, but now whenever I build it, I get several ""Unable to apply publish properties for item 'blah'"" warnings. How do I stop Visual&nbsp;Studio&nbsp;2005's publishing facilities from working on my project completely? I use InstallShield, so I don't have any use for Visual Studio's publishing system.
",jasonh,https://stackoverflow.com/users/116176,"Open your project, select Project Properties->Publish(ing)->Application Files and click the reset all button. Does that help?
",RCIX,https://stackoverflow.com/users/117069,http://stackoverflow.com/questions/982316/unable-to-apply-publish-properties,STACKOVERFLOW,stackoverflow.com,1.0,0.5555555555555556,0.0,0.6666666666666666,0.3333333333333333,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.5555555555555556,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.0,0.0,0.8888888888888888,Can't apply publishing properties?,"I don't know why visual studio started to think it needed to publish my project, but now every time I build it, I get several warnings that I can't publish properties for project ""blah"" application. How can I prevent visual studio 2005 publishing facilities from completely stopping my project? I use InstallShield, so it's useless for visual studio's publishing system.","Open your project, select Project Properties->Publish(ing)->Application Files and click the reset all button. Does that help?
"
4152,4152,6620,Difficulties with re-using a variable,"here is a part of my code :

class projet(object):

    def nameCouche(self):

        valLissage = float(ui.valLissage.displayText())    
        return (valLissage)         
    valCouche = nameCouche() # asks for a positional argument but 'self' doesnt work   

    def choixTraitement(self):
        ui.okLissage.clicked.connect(p.goLissage)

    def goLissage(self, valCouche):
        if ui.chkboxLissage.isChecked():
            print(valCouche) # result is False
            os.system(r'""C:\Program Files\FME\fme.exe"" D:\Stelios\..... --MAX_NUM_POINTS {0}'.format(valCouche))


So I would like to use valCouche in goLissage method but it doesnt work.
I thought that valCouche would have the argument of valLissage but instead it gives False as a value.
I've tried different alternatives but still doesnt work.
",guy16,https://stackoverflow.com/users/4862605,"you have to define an initialization function: def__init__(self)
defining valCouche as an instance attribute make it accessible on all the method so we have the following

class projet(object):

    def __init__(self):
        self.valCouche = ''

    def nameCouche(self):
        self.valCouche =  float(ui.valLissage.displayText())

    @staticmethod #here there is no need for self so it is a method of class
    def choixTraitement():
        ui.okLissage.clicked.connect(p.goLissage)

    def goLissage(self):
        if ui.chkboxLissage.isChecked():
           print(self.valCouche) # result is False
           os.system(r'""C:\Program Files\FME\fme.exe"" D:\Stelios\..... --MAX_NUM_POINTS {0}'.format(self.valCouche))

",Narcisse Doudieu Siewe,https://stackoverflow.com/users/3238855,http://stackoverflow.com/questions/30344855,STACKOVERFLOW,stackoverflow.com,0.6666666666666666,0.3333333333333333,0.0,1.0,0.6666666666666666,1.0,0.6666666666666666,0.4444444444444444,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.6666666666666666,0.0,0.5555555555555556,0.8888888888888888,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.3333333333333333,0.7777777777777778,Difficulty in reusing variables,"here is a part of my code :

class projet(object):

    def nameCouche(self):

        valLissage = float(ui.valLissage.displayText())    
        return (valLissage)         
    valCouche = nameCouche() # asks for a positional argument but 'self' doesnt work   

    def choixTraitement(self):
        ui.okLissage.clicked.connect(p.goLissage)

    def goLissage(self, valCouche):
        if ui.chkboxLissage.isChecked():
            print(valCouche) # result is False
            os.system(r'""C:\Program Files\FME\fme.exe"" D:\Stelios\..... --MAX_NUM_POINTS {0}'.format(valCouche))


So I would like to use valCouche in goLissage method but it doesnt work.
I thought that valCouche would have the argument of valLissage but instead it gives False as a value.
I've tried different alternatives but still doesnt work.
","you have to define an initialization function: def__init__(self)
defining valCouche as an instance attribute make it accessible on all the method so we have the following

class projet(object):

    def __init__(self):
        self.valCouche = ''

    def nameCouche(self):
        self.valCouche =  float(ui.valLissage.displayText())

    @staticmethod #here there is no need for self so it is a method of class
    def choixTraitement():
        ui.okLissage.clicked.connect(p.goLissage)

    def goLissage(self):
        if ui.chkboxLissage.isChecked():
           print(self.valCouche) # result is False
           os.system(r'""C:\Program Files\FME\fme.exe"" D:\Stelios\..... --MAX_NUM_POINTS {0}'.format(self.valCouche))

"
929,929,1467,MySQL 5.5 Replication to Galera/Percona XtraDB Cluster,"We are currently investigating moving our current MySQL 5.5 Master > 5 x Slaves (with Statement Based Replication, apx 250GB data and growing) to a HA clustering option. Mainly to provide greater resilience, write scaling, and easier to carry out admin stuff like Optimising tables without taking the master offline.

We have ruled out (for the moment) MySQL ndb Cluster as it would require too many changes to our current database structure (large number of BLOB fields amongst other problems).

So we are looking at either Galera Cluster or Percona Cluster as the alternatives, as the they seem to do what we want, without 'too' steep a learning curve.

We would want to start off by setting the Cluster up as a Slave to the main Master (for testing etc), before moving over to the Cluster as our Primary system in the future. Is this possible? Reading through the documentation doesn't seem to really talk about this side of things (unless I've missed it).
",IGGt,https://dba.stackexchange.com/users/40876,"Yes, it is very possible.

As the Documentation says, you should have a minimum of three nodes in a Percona XtraDB Cluster. You only need one node out of the three nodes.


Make sure all nodes in the PXC have unique server_ids.
Make sure the Master you are replicating from has a unique server_id from the PXC nodes
Make sure the master and every PXC node is configured with the following

binlog_format=ROW
log-slave-updates

Make sure the master and every PXC node is using binlog_format=ROW


Pick one node and set it up as you would a DB Server designated as a Slave via CHANGE MASTER TO.

If you are going to set up any replication filters, restrict it to just the PXC node that is your Slave. Personally, I would stay away from using replication filters altogether in this setup since one of Percona's Galera Instructors does not feel good about it.

Please be aware that data takes time to be on all nodes at the same instant of time (See Investigating MySQL Replication Latency in Percona XtraDB Cluster)

By the way, you can use any PXC as a Master to StandAlone Slaves as well


Jun 07, 2013 : Percona XtraDB Cluster and MySQL Replication
Jan 29, 2014 : Native replication from Percona XtraDB Cluster to a standard stand-alone slave
Nov 24, 2014 : What is the Best way to set Disaster recovery setup for percona Xtra DB Cluster?


HEADS UP #1

Don't be surprised by replication lag in the PXC node acting as the MySQL Slave. After all, three nodes must write data and become eventually consistent before all committing changes together. See Follow these basics when migrating to Percona XtraDB Cluster for MySQL for more info.

HEADS UP #2

Since you are using MySQL 5.5, do not use PXC 5.6. Use PXC 5.5. Why ? Row-based binlogging in MySQL 5.5 can sometimes not be properly interpreted by a MySQL 5.6 mysqld process. This can break replication from MySQL 5.5 to MySQL 5.6. I wrote a post about this two months ago. The work around was to switch to binlog_format=STATEMENT, but you cannot do that for Percona XtraDB Cluster as it requires binlog_format=ROW.
",RolandoMySQLDBA,https://dba.stackexchange.com/users/877,http://dba.stackexchange.com/questions/94271/mysql-5-5-replication-to-galera-percona-xtradb-cluster,TECHNOLOGY,dba.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,1.0,1.0,1.0,0.6666666666666666,0.4444444444444444,0.0,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.4444444444444444,1.0,0.7777777777777778,1.0,1.0,0.9333333333333332,1.0,0.0,0.3333333333333333,0.8888888888888888,MySQL 5.5 replication to Galera / percona xtradb cluster,"We are currently investigating moving our current MySQL 5.5 Master > 5 x Slaves (with Statement Based Replication, apx 250GB data and growing) to a HA clustering option. Mainly to provide greater resilience, write scaling, and easier to carry out admin stuff like Optimising tables without taking the master offline.

We have ruled out (for the moment) MySQL ndb Cluster as it would require too many changes to our current database structure (large number of BLOB fields amongst other problems).

So we are looking at either Galera Cluster or Percona Cluster as the alternatives, as the they seem to do what we want, without 'too' steep a learning curve.

We would want to start off by setting the Cluster up as a Slave to the main Master (for testing etc), before moving over to the Cluster as our Primary system in the future. Is this possible? Reading through the documentation doesn't seem to really talk about this side of things (unless I've missed it).
","Yes, it is very possible.

As the Documentation says, you should have a minimum of three nodes in a Percona XtraDB Cluster. You only need one node out of the three nodes.


Make sure all nodes in the PXC have unique server_ids.
Make sure the Master you are replicating from has a unique server_id from the PXC nodes
Make sure the master and every PXC node is configured with the following

binlog_format=ROW
log-slave-updates

Make sure the master and every PXC node is using binlog_format=ROW


Pick one node and set it up as you would a DB Server designated as a Slave via CHANGE MASTER TO.

If you are going to set up any replication filters, restrict it to just the PXC node that is your Slave. Personally, I would stay away from using replication filters altogether in this setup since one of Percona's Galera Instructors does not feel good about it.

Please be aware that data takes time to be on all nodes at the same instant of time (See Investigating MySQL Replication Latency in Percona XtraDB Cluster)

By the way, you can use any PXC as a Master to StandAlone Slaves as well


Jun 07, 2013 : Percona XtraDB Cluster and MySQL Replication
Jan 29, 2014 : Native replication from Percona XtraDB Cluster to a standard stand-alone slave
Nov 24, 2014 : What is the Best way to set Disaster recovery setup for percona Xtra DB Cluster?


HEADS UP #1

Don't be surprised by replication lag in the PXC node acting as the MySQL Slave. After all, three nodes must write data and become eventually consistent before all committing changes together. See Follow these basics when migrating to Percona XtraDB Cluster for MySQL for more info.

HEADS UP #2

Since you are using MySQL 5.5, do not use PXC 5.6. Use PXC 5.5. Why ? Row-based binlogging in MySQL 5.5 can sometimes not be properly interpreted by a MySQL 5.6 mysqld process. This can break replication from MySQL 5.5 to MySQL 5.6. I wrote a post about this two months ago. The work around was to switch to binlog_format=STATEMENT, but you cannot do that for Percona XtraDB Cluster as it requires binlog_format=ROW.
"
62,62,96,Nexus 7 is stuck in reboot loop after full discharge,"I have a few day old Nexus 7 tablet, unrooted, bootloader still locked, and otherwise in factory condition. This morning, it ran its charge out. When I plugged in it, this happens:


Google Logo appears.
Nexus Logo appears.
Lock screen which shows charging: 0%.
White screen, device powers off.
Repeat.


What is happening? Thanks!
",Eric,https://android.stackexchange.com/users/25632,"If you've just plugged it in to the charger, leave it a while before you try to turn it on.  The boot sequence uses power faster than USB can provide it, so you will need a little juice in the battery in order for it to boot up all the way.
",Tim,https://android.stackexchange.com/users/25209,http://android.stackexchange.com/questions/36220/nexus-7-is-stuck-in-reboot-loop-after-full-discharge,TECHNOLOGY,android.stackexchange.com,0.8888888888888888,0.7777777777777778,0.0,1.0,1.0,1.0,0.7777777777777778,0.4444444444444444,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,1.0,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.6666666666666666,1.0,Nexus7 stuck in restart cycle after full release,"I had a few days ago on the nexus 7 tablet, it didn't start, the boot loader was still locked, otherwise in factory conditions. This morning, it ran out of electricity. When I turn on the power, the following occurs:","If you just plugged it into the charger, put it on for a while before you turn it on. The power supply used by the startup program is faster than that provided by USB, so you need to inject a little power into the battery to start the whole process."
3111,3111,4957,"""you will"" vs ""will you""","Which sentence is Correct Among both


How much will you pay for me
How you will pay for me

",ethan lucas,https://ell.stackexchange.com/users/20061,"""How much"" is asking for a quantity. ""How"" by itself is asking for a means or method.

Example 1:


  How much will you pay for me?
  
  I'd pay up to $20.


Example 2:


  How will you pay for me?
  
  I'll pay with a credit card.


By the way, both sentences sound, at least taken out of context, like the speaker is asking the person about buying him or her, like you would buy a slave or a prostitute. Perhaps the intent is that they are asking about buying something on behalf of him or her?
",Jay,https://ell.stackexchange.com/users/803,http://ell.stackexchange.com/questions/62601/you-will-vs-will-you,CULTURE,ell.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,1.0,1.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.3333333333333333,0.0,0.3333333333333333,1.0,0.7777777777777778,1.0,0.8888888888888888,0.8666666666666666,0.0,0.0,1.0,0.8888888888888888,"""You will"" to ""you will""","Which sentence is Correct Among both


How much will you pay for me
How you will pay for me

","""How much"" is asking for a quantity. ""How"" by itself is asking for a means or method.

Example 1:


  How much will you pay for me?
  
  I'd pay up to $20.


Example 2:


  How will you pay for me?
  
  I'll pay with a credit card.


By the way, both sentences sound, at least taken out of context, like the speaker is asking the person about buying him or her, like you would buy a slave or a prostitute. Perhaps the intent is that they are asking about buying something on behalf of him or her?
"
4867,4867,7742,-ic -ous nomenclature,"I recently came across a practice problem in my textbook asking me to name a few compounds using -ic and -ous endings. The exact wording is:

Write the name of each of the following ionic substances, using -ous and -ic endings to indicate the charge of the cation.

The first one was CoCl2. However, cobalt has more than just two oxidization states (3, 2, 0, and -1).

So if it is one of the states in the middle, how do I decide whether to use -ous or -ic
",735Tesla,https://chemistry.stackexchange.com/users/7286,"Cobalt may possibly have all those other oxidation states (and others too) for this nomenclature system, we only care about the two most common oxidation states in ionic compounds: $\ce{Co^{2+}}$ and $\ce{Co^{3+}}$. Cobalt(II) compounds would thus be named  cobaltous and cobalt(III) compounds would be cobaltic. Which is yours?
",Ben Norris,https://chemistry.stackexchange.com/users/275,http://chemistry.stackexchange.com/questions/14766/ic-ous-nomenclature,SCIENCE,chemistry.stackexchange.com,1.0,0.3333333333333333,0.0,1.0,1.0,1.0,0.6666666666666666,0.5555555555555556,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,0.8888888888888888,-IC ous nomenclature,"I recently came across a practice problem in my textbook asking me to name a few compounds using -ic and -ous endings. The exact wording is:

Write the name of each of the following ionic substances, using -ous and -ic endings to indicate the charge of the cation.

The first one was CoCl2. However, cobalt has more than just two oxidization states (3, 2, 0, and -1).

So if it is one of the states in the middle, how do I decide whether to use -ous or -ic
","For this naming system, cobalt may have all other oxidation states (as well as other oxidation states). We only care about the two most common oxidation states in ionic compounds: $C {C {2 +}} $and $C {C {3 +}}. Therefore, cobalt (II) compounds will be named cobalt salts, while cobalt (III) compounds will be named cobalt salts. Which is yours?"
700,700,1106,Are there /ɔ/ and /ʌ/ sounds in informal American English?,"I read a book about American English. It reports that, in standard informal conversations, American English doesn't use the /ɔ/ sound; it uses the /ɑ/ sound and /ʌ/ and /ə/ are not different. Are they really?
That book would not use the /ɔ/ and /ʌ/ sounds, but when I look in my American English Dictionary for some words, such as more, door, and love, they are reported to be pronounced /mɔr/, /dɔr/, and /lʌv/.
How should I pronounce these words, if there are no /ɔ/and /ʌ/ sounds?  Should they be /mɑr/, /dɑr/, and /ləv/?
Can /ɑ/ sound replace /ɔ/, and /ə/ replace /ʌ/ in every word?
What about formal American English? Does it have /ɔ /and /ʌ/ sounds or not?
",Kas,https://english.stackexchange.com/users/10792,"The /ɔ/ as described by Wikipedia is an unelisioned ""aw"" sound, as in the pure Latin vowel ""o"" for those singers out there. The /ʌ/ sound, as found in the word ""plus"", is an open-backed ""uh"". Close off the back of the throat by dropping the soft palate, bringing the jaw back and/or raising the back of the tongue and you have what most Americans would call a ""schwa"" (/ə/) as in the second syllable of ""special"".

In most American English dialects/accents, the mouth is held in a more open, relaxed position while speaking than for most British accents. This can tend to make ""aw"" sound more like more like ""ah"", and ""ah"" like an open short ""a"" as in ""bat"". Similarly, the opening of the lips leads to closing off the back of the throat to provide nuances between vowels, which can make ""uh"" sound like ""ugh"", ""oo"" sound like ""eu"", etc. Vocal coaches tear their hair out over this natural accent, especially in the deep South and Texas, where the ""twang"" pollutes the ""pure"" Latin vowels normally desired for singing in almost any language.

However, I doubt you will find an English dialect where a particular vowel shape is never heard. First of all, there will always be a word in the language that even a heavily-accented speaker will pronounce using the shape you're looking for. It may be misplaced, but it'll be there. 

Second, there are degrees of vowel modification from what we would consider ""neutral"" American English to ""accented"", no matter the accent, so you will always find a person who speaks with just the right level of accent to use the vowel shape you're looking for at least some of the time. Urban residents tend to accent less than suburban and rural in my experience, and higher education, which normally involves a mingling of people from many locations nationwide, also tends to reduce accenting. Watching national broadcast TV also tends to reduce accenting, as most actors have their natural accents trained, coached, and/or beaten out of them while on camera.
",KeithS,https://english.stackexchange.com/users/9887,http://english.stackexchange.com/questions/33392/are-there-%C9%94-and-%CA%8C-sounds-in-informal-american-english,CULTURE,english.stackexchange.com,1.0,0.4444444444444444,0.0,0.6666666666666666,1.0,1.0,0.5555555555555556,0.6666666666666666,1.0,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,1.0,0.3333333333333333,0.7777777777777778,1.0,0.7777777777777778,0.8888888888888888,0.8888888888888888,0.8,0.0,0.3333333333333333,1.0,0.8888888888888888,Is there / ɔ / and / ʌ / in informal American English?,"I read a book about American English. It reports that, in standard informal conversations, American English doesn't use the /ɔ/ sound; it uses the /ɑ/ sound and /ʌ/ and /ə/ are not different. Are they really?
That book would not use the /ɔ/ and /ʌ/ sounds, but when I look in my American English Dictionary for some words, such as more, door, and love, they are reported to be pronounced /mɔr/, /dɔr/, and /lʌv/.
How should I pronounce these words, if there are no /ɔ/and /ʌ/ sounds?  Should they be /mɑr/, /dɑr/, and /ləv/?
Can /ɑ/ sound replace /ɔ/, and /ə/ replace /ʌ/ in every word?
What about formal American English? Does it have /ɔ /and /ʌ/ sounds or not?
","The /ɔ/ as described by Wikipedia is an unelisioned ""aw"" sound, as in the pure Latin vowel ""o"" for those singers out there. The /ʌ/ sound, as found in the word ""plus"", is an open-backed ""uh"". Close off the back of the throat by dropping the soft palate, bringing the jaw back and/or raising the back of the tongue and you have what most Americans would call a ""schwa"" (/ə/) as in the second syllable of ""special"".

In most American English dialects/accents, the mouth is held in a more open, relaxed position while speaking than for most British accents. This can tend to make ""aw"" sound more like more like ""ah"", and ""ah"" like an open short ""a"" as in ""bat"". Similarly, the opening of the lips leads to closing off the back of the throat to provide nuances between vowels, which can make ""uh"" sound like ""ugh"", ""oo"" sound like ""eu"", etc. Vocal coaches tear their hair out over this natural accent, especially in the deep South and Texas, where the ""twang"" pollutes the ""pure"" Latin vowels normally desired for singing in almost any language.

However, I doubt you will find an English dialect where a particular vowel shape is never heard. First of all, there will always be a word in the language that even a heavily-accented speaker will pronounce using the shape you're looking for. It may be misplaced, but it'll be there. 

Second, there are degrees of vowel modification from what we would consider ""neutral"" American English to ""accented"", no matter the accent, so you will always find a person who speaks with just the right level of accent to use the vowel shape you're looking for at least some of the time. Urban residents tend to accent less than suburban and rural in my experience, and higher education, which normally involves a mingling of people from many locations nationwide, also tends to reduce accenting. Watching national broadcast TV also tends to reduce accenting, as most actors have their natural accents trained, coached, and/or beaten out of them while on camera.
"
2275,2275,3624,How to remove a column from the Posts page,"In a previous question I asked how to add a column to the Posts page in the Administration section, and got a working answer. But now I need to know how to delete an existing column (e.g. the Date column) so that my customized Date column replaces it.
",Justin Long,https://wordpress.stackexchange.com/users/5913,"On a different fields it is also possible you deactivate the function of WP; as example comments and author:

add_action( 'admin_init', 'fb_deactivate_support' );
function fb_deactivate_support() {
    remove_post_type_support( 'post', 'comments' );
    remove_post_type_support( 'post', 'author' );
}


the post-string is for the post_type, you can also use this for all post types via:

foreach ( get_post_types() as $post_type ) {
    remove_post_type_support( $post_type, 'comments' );
} 



",bueltge,https://wordpress.stackexchange.com/users/170,http://wordpress.stackexchange.com/questions/19180/how-to-remove-a-column-from-the-posts-page,TECHNOLOGY,wordpress.stackexchange.com,1.0,1.0,0.0,0.5,1.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.0,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.3333333333333333,0.0,0.8888888888888888,How to remove columns from the article page,"In the previous question, I asked how to add a column to the posts page in the administration section and got an effective answer. But now I need to know how to delete an existing column (such as a date column) so that my custom date column can replace it.","On a different fields it is also possible you deactivate the function of WP; as example comments and author:

add_action( 'admin_init', 'fb_deactivate_support' );
function fb_deactivate_support() {
    remove_post_type_support( 'post', 'comments' );
    remove_post_type_support( 'post', 'author' );
}


the post-string is for the post_type, you can also use this for all post types via:

foreach ( get_post_types() as $post_type ) {
    remove_post_type_support( $post_type, 'comments' );
} 



"
3539,3539,5644,How old is Captain America when he receives the 'Super-Soldier Serum'?,"Steve Rogers is said to have been born in the 1920's.  WWII started roughly in 1939 with the invasion of Poland by Germany.  Rogers attempts to enlist in the US Army in 1940, however due to his frail physical state he is denied entry.

Having been observed by certain key Army officials attempting to enlist several more times after being denied, he is inducted in to Project Rebirth as its first candidate for Dr. Erskin's Super-Soldier Serum.  After receiving said serum, and becoming the pinnacle of human potential he operates in the European theater of war for several years alongside Bucky Barnes and, on occasion members of the Invaders.

On his final mission during the war he and Barnes are presumed dead when the experimental bomb they are attempting to stop from destroying Washington DC explodes dumping Cap in the Arctic waters to be frozen and preserved for many years before he is found and revived by the founding members of the Avengers.

I'm trying to figure out how old he was when he received his serum treatments and became Captain America, and/or how old he was when he was frozen in the ice.
",Monty129,https://scifi.stackexchange.com/users/8226,"According to Captain America's biography on ComicVine; The comic version of Steve Rogers was born on July 4th, 1920. He was given the Super-Serum in March 1941 (aged 20).

This is flatly contradicted by the film version which states that he was born on July 4th, 1918 and turned into a superhero aged 21.

Both versions agree that was frozen in 1945 (aged 25 and 27 respectively).
",Valorum,https://scifi.stackexchange.com/users/20774,http://scifi.stackexchange.com/questions/53219/how-old-is-captain-america-when-he-receives-the-super-soldier-serum,LIFE_ARTS,scifi.stackexchange.com,1.0,1.0,0.0,1.0,0.6666666666666666,1.0,0.4444444444444444,0.6666666666666666,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,0.3333333333333333,0.8888888888888888,"How old was the American captain when he received ""super soldier serum""?","Steve Rogers is said to have been born in the 1920's.  WWII started roughly in 1939 with the invasion of Poland by Germany.  Rogers attempts to enlist in the US Army in 1940, however due to his frail physical state he is denied entry.

Having been observed by certain key Army officials attempting to enlist several more times after being denied, he is inducted in to Project Rebirth as its first candidate for Dr. Erskin's Super-Soldier Serum.  After receiving said serum, and becoming the pinnacle of human potential he operates in the European theater of war for several years alongside Bucky Barnes and, on occasion members of the Invaders.

On his final mission during the war he and Barnes are presumed dead when the experimental bomb they are attempting to stop from destroying Washington DC explodes dumping Cap in the Arctic waters to be frozen and preserved for many years before he is found and revived by the founding members of the Avengers.

I'm trying to figure out how old he was when he received his serum treatments and became Captain America, and/or how old he was when he was frozen in the ice.
","According to Captain America's biography on ComicVine; The comic version of Steve Rogers was born on July 4th, 1920. He was given the Super-Serum in March 1941 (aged 20).

This is flatly contradicted by the film version which states that he was born on July 4th, 1918 and turned into a superhero aged 21.

Both versions agree that was frozen in 1945 (aged 25 and 27 respectively).
"
1163,1163,1824,Why does WPF toggle button pulse once unchecked,"Within a Desktop app I have a toggle button: 

&lt;ToggleButton x:Name=""CFStglBtn"" Checked=""cfsCBox_Checked""
              Unchecked=""cfsCBox_Unchecked""
              IsChecked=""True"" HorizontalAlignment=""Left"" Margin=""5,0,0,0""&gt;
    &lt;StackPanel Orientation=""Horizontal""&gt;
        &lt;Image Source=""assets\telephone.png"" Margin=""3,0,0,0"" /&gt;
        &lt;TextBlock Text=""CFS"" FontSize=""10"" Margin=""5,5,5,0""
                   Foreground=""DarkSlateGray""/&gt;
    &lt;/StackPanel&gt;
&lt;/ToggleButton&gt;


For the Checked event I am setting a value and then executing a method FilterView(); 
//ommitting code 

Unchecked state is just the opposite. resets a variable and executed the method again

The question I have is I noticed when I uncheck the toggle button the button continues to pulse or flash ( going from blue to chrome) as if it still has focus. The button will stay like this until another button is clicked.

Is there a way to remove this focus so that when the button is unchecked the button goes back to a unchecked state without the flashing / pulsing color. 


As you can see from above this is a standard toggle button no styles or custom 
I tested this on just a regular button and I found the same occured when clicked the button will continue to pulse / flash until another button is clicked. 


How do you work around this or prevent this effect from happening.

Thank you
",rlcrews,https://stackoverflow.com/users/290645,"This is happening because of the button chrome built into the default template for the control. Your only workaround is to re-template the Button. This article should get you started.
",Charlie,https://stackoverflow.com/users/117638,http://stackoverflow.com/questions/3048140/why-does-wpf-toggle-button-pulse-once-unchecked,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.4444444444444444,0.0,1.0,0.6666666666666666,1.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,1.0,1.0,Why WPF toggle button pulse is unchecked,"Within a Desktop app I have a toggle button: 

&lt;ToggleButton x:Name=""CFStglBtn"" Checked=""cfsCBox_Checked""
              Unchecked=""cfsCBox_Unchecked""
              IsChecked=""True"" HorizontalAlignment=""Left"" Margin=""5,0,0,0""&gt;
    &lt;StackPanel Orientation=""Horizontal""&gt;
        &lt;Image Source=""assets\telephone.png"" Margin=""3,0,0,0"" /&gt;
        &lt;TextBlock Text=""CFS"" FontSize=""10"" Margin=""5,5,5,0""
                   Foreground=""DarkSlateGray""/&gt;
    &lt;/StackPanel&gt;
&lt;/ToggleButton&gt;


For the Checked event I am setting a value and then executing a method FilterView(); 
//ommitting code 

Unchecked state is just the opposite. resets a variable and executed the method again

The question I have is I noticed when I uncheck the toggle button the button continues to pulse or flash ( going from blue to chrome) as if it still has focus. The button will stay like this until another button is clicked.

Is there a way to remove this focus so that when the button is unchecked the button goes back to a unchecked state without the flashing / pulsing color. 


As you can see from above this is a standard toggle button no styles or custom 
I tested this on just a regular button and I found the same occured when clicked the button will continue to pulse / flash until another button is clicked. 


How do you work around this or prevent this effect from happening.

Thank you
","This is happening because of the button chrome built into the default template for the control. Your only workaround is to re-template the Button. This article should get you started.
"
3170,3170,5047,Decoding Matrix Encoded Surround Sound Through Convolution,"I wish to create a finite impulse response filter to decode a dolby digital matrix encoded 2 channel signal into 5 channels. These filters would then be used in a realtime pipeline on a Linux machine using jack and jconvolver to do the convolution.

The equation is as follows:

 

The reference for the above equation is: http://en.wikipedia.org/wiki/Matrix_decoder

It would seem this should be able to be done but I haven't the faintest how. Any help, and in particular working code that could generate the filters (Octave or other open source preferred) would be much appreciated!
",psandersen,https://dsp.stackexchange.com/users/3142,"Suppose that we had two channels encoded in some form in two signals according to a matrix.  Recovering the original signals would be straightforward using the matrix inverse (or impossible, if the inverse did not exist).  The situation is no different here, except that the matrix is not square, so you cannot use the conventional matrix inverse.  You can, however, use a pseudoinverse or generalized inverse to reconstruct the original signals.  

Other matrices which are not equal to an inverse may work also succeed, and may in fact sound better.  I don't know the psychoacoustic situation, but it may more sense to do some transform based on the position of speakers for example. Certainly, the inverse seems like a good place to start.

I rewrote your encoder table as a 2x5 input matrix $ E $, and used Wolfram Alpha to determine the inverse, $ D = E^{-1} $.  Here is the 5x2 result it provided, using $ i $ as the imaginary unit, with $ j = i $ and $ k = -i $.

$$
D = \frac{1}{18(46+6\sqrt{2})} \begin{bmatrix}
405 &amp; -3(27 - 36\sqrt{2}) \\
-3(27 - 36\sqrt{2}) &amp; 405 \\
6(18+27\sqrt{2}) &amp; 6(18+27\sqrt{2}) \\
-i(27\sqrt{3} + 99\sqrt{6}) &amp; i(63\sqrt{3} + 27\sqrt{6}) \\
-i(63\sqrt{3} + 27\sqrt{6}) &amp; i(27\sqrt{3} + 99\sqrt{6}) 
\end{bmatrix}
$$

As one would expect, the decoding matrix shows left/right symmetry.

Now we can express the encoding/decoding operations as:
$$
\begin{bmatrix}
L_{encoded} \\
R_{encoded}
\end{bmatrix} = E \space{} \begin{bmatrix}
L \\
R \\
C \\
L_{rear} \\
R_{rear} \\
\end{bmatrix}
$$
$$
\begin{bmatrix}
L' \\
R' \\
C' \\
L_{rear}' \\
R_{rear}' \\
\end{bmatrix} = D \space{} \begin{bmatrix}
L_{encoded} \\
R_{encoded}
\end{bmatrix}
$$

Now you can easily obtain formulas to express the three front components as functions of the encoded left and right signals.  For the two rear components, you have an equation in the time domain with a complex component.

Looking at the left rear component, and converting constants from the matrix $ D $ to numeric form:
$$
L_{rear}'[n] = -i0.2949 L_{encoded}[n] + i0.1787 R_{encoded}[n]
$$

The Hilbert transform can be used to remove the imaginary unit, because this has the same effect on the frequency domain of performing a ±90º phase shift.  The Hilbert transform only needs to be applied once, since convolution ($ * $) is distributive and commutative and all other good things.
$$
L_{rear}'[n] = (-0.2949 L_{encoded}[n] + 0.1787 R_{encoded}[n]) * H[n]
$$

The operating principle, then, is that the encoding technique functions in part by encoding the left/right rear components in quadrature.

The Hilbert transform is infinitely long, so it must be truncated and expressed as either a FIR filter, or depending on your circumstances, a FFT-IFFT operation.  A causal Hilbert transform will delay the rear channels, so your other filters will need to be delayed by some amount to compensate.

For example, if $ k $ is the group delay of a causal approximation of a Hilbert filter $ H_k[n] $ then you delay must delay the three front channels by $ k $ as well:
$$
C'[n] = (0.3437L_{encoded}[n] + 0.3437R_{encoded}[n]) * \delta[n-k]
$$

In practice, all of the output signals depend on the two input signals.  That is, you take two input channels and produce one output channel five times.  Your JACK pipeline will need to accommodate this.
",jbarlow,https://dsp.stackexchange.com/users/3191,http://dsp.stackexchange.com/questions/4743/decoding-matrix-encoded-surround-sound-through-convolution,TECHNOLOGY,dsp.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,0.6666666666666666,1.0,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.6666666666666666,1.0,0.8888888888888888,1.0,1.0,0.9333333333333332,1.0,0.3333333333333333,1.0,1.0,Convolutional matrix coding for surround sound decoding,"I wish to create a finite impulse response filter to decode a dolby digital matrix encoded 2 channel signal into 5 channels. These filters would then be used in a realtime pipeline on a Linux machine using jack and jconvolver to do the convolution.

The equation is as follows:

 

The reference for the above equation is: http://en.wikipedia.org/wiki/Matrix_decoder

It would seem this should be able to be done but I haven't the faintest how. Any help, and in particular working code that could generate the filters (Octave or other open source preferred) would be much appreciated!
","Suppose that we had two channels encoded in some form in two signals according to a matrix.  Recovering the original signals would be straightforward using the matrix inverse (or impossible, if the inverse did not exist).  The situation is no different here, except that the matrix is not square, so you cannot use the conventional matrix inverse.  You can, however, use a pseudoinverse or generalized inverse to reconstruct the original signals.  

Other matrices which are not equal to an inverse may work also succeed, and may in fact sound better.  I don't know the psychoacoustic situation, but it may more sense to do some transform based on the position of speakers for example. Certainly, the inverse seems like a good place to start.

I rewrote your encoder table as a 2x5 input matrix $ E $, and used Wolfram Alpha to determine the inverse, $ D = E^{-1} $.  Here is the 5x2 result it provided, using $ i $ as the imaginary unit, with $ j = i $ and $ k = -i $.

$$
D = \frac{1}{18(46+6\sqrt{2})} \begin{bmatrix}
405 &amp; -3(27 - 36\sqrt{2}) \\
-3(27 - 36\sqrt{2}) &amp; 405 \\
6(18+27\sqrt{2}) &amp; 6(18+27\sqrt{2}) \\
-i(27\sqrt{3} + 99\sqrt{6}) &amp; i(63\sqrt{3} + 27\sqrt{6}) \\
-i(63\sqrt{3} + 27\sqrt{6}) &amp; i(27\sqrt{3} + 99\sqrt{6}) 
\end{bmatrix}
$$

As one would expect, the decoding matrix shows left/right symmetry.

Now we can express the encoding/decoding operations as:
$$
\begin{bmatrix}
L_{encoded} \\
R_{encoded}
\end{bmatrix} = E \space{} \begin{bmatrix}
L \\
R \\
C \\
L_{rear} \\
R_{rear} \\
\end{bmatrix}
$$
$$
\begin{bmatrix}
L' \\
R' \\
C' \\
L_{rear}' \\
R_{rear}' \\
\end{bmatrix} = D \space{} \begin{bmatrix}
L_{encoded} \\
R_{encoded}
\end{bmatrix}
$$

Now you can easily obtain formulas to express the three front components as functions of the encoded left and right signals.  For the two rear components, you have an equation in the time domain with a complex component.

Looking at the left rear component, and converting constants from the matrix $ D $ to numeric form:
$$
L_{rear}'[n] = -i0.2949 L_{encoded}[n] + i0.1787 R_{encoded}[n]
$$

The Hilbert transform can be used to remove the imaginary unit, because this has the same effect on the frequency domain of performing a ±90º phase shift.  The Hilbert transform only needs to be applied once, since convolution ($ * $) is distributive and commutative and all other good things.
$$
L_{rear}'[n] = (-0.2949 L_{encoded}[n] + 0.1787 R_{encoded}[n]) * H[n]
$$

The operating principle, then, is that the encoding technique functions in part by encoding the left/right rear components in quadrature.

The Hilbert transform is infinitely long, so it must be truncated and expressed as either a FIR filter, or depending on your circumstances, a FFT-IFFT operation.  A causal Hilbert transform will delay the rear channels, so your other filters will need to be delayed by some amount to compensate.

For example, if $ k $ is the group delay of a causal approximation of a Hilbert filter $ H_k[n] $ then you delay must delay the three front channels by $ k $ as well:
$$
C'[n] = (0.3437L_{encoded}[n] + 0.3437R_{encoded}[n]) * \delta[n-k]
$$

In practice, all of the output signals depend on the two input signals.  That is, you take two input channels and produce one output channel five times.  Your JACK pipeline will need to accommodate this.
"
6067,6067,9627,OCR software for handwritten notes,"I am looking for a way to recognize handwriting of scanned notes (in PDF format).

It doesn't have to be perfect, and it doesn't have to free, but before paying I would like to try it (even with just a single page).

It doesn't necessarily have to be a native Mac OS X application. I would be OK with an online application, or a Unix application to install or compile. In other words, anything that works somewhat decently would be OK.

I am also not necessarily looking for a perfect result. Even transforming my notes into a searchable PDF with just some of the text recognized would be better than nothing.
",Matteo,https://apple.stackexchange.com/users/10888,"http://www.VelOCRaptor.com/ seems to be an affordable (FREE!) solution for OS X. It has a very simple drag-and-drop user interface. It is based on Google's OCR technology so you can rest assured that it will work properly.

Hope this helps!
",sgonzalez,https://apple.stackexchange.com/users/21693,http://apple.stackexchange.com/questions/48807/ocr-software-for-handwritten-notes,TECHNOLOGY,apple.stackexchange.com,1.0,0.6666666666666666,0.0,1.0,1.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,1.0,0.8333333333333334,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,0.0,1.0,OCR software for handwritten notes,"I am looking for a way to recognize handwriting of scanned notes (in PDF format).

It doesn't have to be perfect, and it doesn't have to free, but before paying I would like to try it (even with just a single page).

It doesn't necessarily have to be a native Mac OS X application. I would be OK with an online application, or a Unix application to install or compile. In other words, anything that works somewhat decently would be OK.

I am also not necessarily looking for a perfect result. Even transforming my notes into a searchable PDF with just some of the text recognized would be better than nothing.
","Http://www.velocraptor.com/ seems to be an affordable (free!) OSX solution. It has a very simple drag and drop user interface. It's based on Google's OCR technology, so you can rest assured that it will work."
4085,4085,6520,JavaScript Equivalent Of PHP __invoke,"I'm developing a small framework (in JS) and for esthetic reasons and simplicity I was wondering if there could be a way to implement something like PHP ""__invoke"".

For example:

var myClass = function(config) {
    this.config = config;
    this.method = function(){};
    this.execute = function() {
        return this.method.apply(this, arguments);
    }
}
var execCustom = new myClass({ wait: 100 });
execCustom.method = function() {
    console.log(""called method with ""+arguments.length+"" argument(s):"");
    for(var a in arguments) console.log(arguments[a]);
    return true;
};
execCustom.execute(""someval"",""other"");  


Desired way to execute:

execCustom(""someval"",""other"");


Any ideas? Thanks.
",lepe,https://stackoverflow.com/users/196507,"Just return a function that will form the public interface:

function myClass(config)
{
  var pubif = function() {
    return pubif.method.apply(pubif, arguments);
  };
  pubif.config = config;
  pubif.method = function() { };

  return pubif;
}


The rest of the code remains the same.
",Ja͢ck,https://stackoverflow.com/users/1338292,http://stackoverflow.com/questions/19018912/javascript-equivalent-of-php-invoke,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.6666666666666666,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.3333333333333333,0.0,1.0,JavaScript equivalent to PHP \ UU invoke,"I'm developing a small framework (in JS) and for esthetic reasons and simplicity I was wondering if there could be a way to implement something like PHP ""__invoke"".

For example:

var myClass = function(config) {
    this.config = config;
    this.method = function(){};
    this.execute = function() {
        return this.method.apply(this, arguments);
    }
}
var execCustom = new myClass({ wait: 100 });
execCustom.method = function() {
    console.log(""called method with ""+arguments.length+"" argument(s):"");
    for(var a in arguments) console.log(arguments[a]);
    return true;
};
execCustom.execute(""someval"",""other"");  


Desired way to execute:

execCustom(""someval"",""other"");


Any ideas? Thanks.
","Just return a function that will form the public interface:

function myClass(config)
{
  var pubif = function() {
    return pubif.method.apply(pubif, arguments);
  };
  pubif.config = config;
  pubif.method = function() { };

  return pubif;
}


The rest of the code remains the same.
"
761,761,1204,What is the current flowing through this switch?,"I am looking at a circuit diagram like this:







simulate this circuit &ndash; Schematic created using CircuitLab

Switch 1 and switch 2 never are on at the same time (they alternate)
I turn on S2 and shut off S1, then after a while, I turn on S1 and shut off S2. At that point I think I can redraw the circuit like this:







simulate this circuit

But if I do that, I think the current through the switch would then be zero? And then the switch would be considered ""off?"" Or maybe I could arbitrarily define the current through the switch as being from either the left or right hand side circuits? But that seems to be not possible because originally the switch was shared between both of the circuits.

Can someone figure out what is wrong with my reasoning? What should the current through the circuit be in the ""on"" position?

Note: ignore the values of the circuit elements, they are not important.
",AAC,https://electronics.stackexchange.com/users/54447,"If you turn S1 on and wait long enough, the currents will eventually decay to zero (assuming non-ideal components). In the meantime,
the S1 current is equal to the sum of the two inductor currents. Redrawing the circuit like you did removes S1 altogether, which is okay unless you want to know the switch current. :-)

This circuit looks like a fancy switching regulator, so probably you wouldn't wait a long time. You would switch frequently, and vary the duty cycle to control the output voltage. It's easiest to understand if you look at it over two cycles:

1a. S2 on, V1 boosts the current in L1.

1b. S1 on, L1 pulls current through S1 and C1, charging up C2 (positive end away from V1).

2a. S2 on, C1 discharges through L2, boosting its current and feeding the load.

2b. S1 on, L2 pulls current through S1, feeding the load.

C2 acts as a filtering capacitor to reduce voltage ripple at the load. You can see that when S1 is on (steps 1b and 2b), both inductors are pulling current from ground through S1.
",Adam Haun,https://electronics.stackexchange.com/users/56411,http://electronics.stackexchange.com/questions/132001/what-is-the-current-flowing-through-this-switch,SCIENCE,electronics.stackexchange.com,1.0,0.3333333333333333,0.0,1.0,1.0,1.0,0.5555555555555556,0.4444444444444444,0.6666666666666666,0.0,0.0,0.3333333333333333,0.0,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,0.3333333333333333,0.0,1.0,0.8888888888888888,What is the current flowing through the switch?,"I am looking at a circuit diagram like this:







simulate this circuit &ndash; Schematic created using CircuitLab

Switch 1 and switch 2 never are on at the same time (they alternate)
I turn on S2 and shut off S1, then after a while, I turn on S1 and shut off S2. At that point I think I can redraw the circuit like this:







simulate this circuit

But if I do that, I think the current through the switch would then be zero? And then the switch would be considered ""off?"" Or maybe I could arbitrarily define the current through the switch as being from either the left or right hand side circuits? But that seems to be not possible because originally the switch was shared between both of the circuits.

Can someone figure out what is wrong with my reasoning? What should the current through the circuit be in the ""on"" position?

Note: ignore the values of the circuit elements, they are not important.
","If you turn S1 on and wait long enough, the currents will eventually decay to zero (assuming non-ideal components). In the meantime,
the S1 current is equal to the sum of the two inductor currents. Redrawing the circuit like you did removes S1 altogether, which is okay unless you want to know the switch current. :-)

This circuit looks like a fancy switching regulator, so probably you wouldn't wait a long time. You would switch frequently, and vary the duty cycle to control the output voltage. It's easiest to understand if you look at it over two cycles:

1a. S2 on, V1 boosts the current in L1.

1b. S1 on, L1 pulls current through S1 and C1, charging up C2 (positive end away from V1).

2a. S2 on, C1 discharges through L2, boosting its current and feeding the load.

2b. S1 on, L2 pulls current through S1, feeding the load.

C2 acts as a filtering capacitor to reduce voltage ripple at the load. You can see that when S1 is on (steps 1b and 2b), both inductors are pulling current from ground through S1.
"
2249,2249,3586,Is it possible to get a popup to ignore MenuDropAlignment in a WPF / Touch app?,"As a bit of background - Windows has a facility for Touch/TabletPCs whereby it shifts the position of popups/menus depending on your ""handedness"" (to prevent the menu appearing under your hand). 

Essentially what this does is if you are set to ""right handed"" (which it seems to default to once you've connected a touch device), every popup you open is artificially kicked to the left - this causes massive layout issues where we try and line up a popup with the item it ""popped up from"" :

Tablet PC Settings set to Left handed - no artificial correction from Windows


Tablet PC Settings set to Right handed - Windows artificially adjusts our positioning


We can detect what this setting is set to with SystemParameters.MenuDropAlignment, and for trivial popups we can adjust this using the actual width of the popup - but for dynamic popups and when we throw right to left support into the mix, this just doesn't work.

Currently it's looking more likely that we are going to have to go through every popup, manually work out a value to adjust the kick, and add something like this to every one:

&lt;MultiDataTrigger&gt;
    &lt;MultiDataTrigger.Conditions&gt;
        &lt;Condition Binding=""{Binding Source={x:Static SystemParameters.MenuDropAlignment}}"" Value=""True""/&gt;
        &lt;Condition Binding=""{Binding RelativeSource={RelativeSource Mode=Self}, Path=FlowDirection}"" Value=""RightToLeft""/&gt;
    &lt;/MultiDataTrigger.Conditions&gt;
    &lt;MultiDataTrigger.Setters&gt;
        &lt;Setter Property=""HorizontalOffset"" Value=""-50""/&gt; &lt;!-- Set to arbitrary value to test --&gt;
    &lt;/MultiDataTrigger.Setters&gt;
&lt;/MultiDataTrigger&gt;


So.. back to the question :-) Does anyone know of a way to stop a WPF popup looking at this setting at all? 

For those that don't have a touch device you can access the Tablet PC settings by running:

C:\Windows\explorer.exe shell:::{80F3F1D5-FECA-45F3-BC32-752C152E456E}

And see the mess it makes for yourself :-)
",Steven Robbins,https://stackoverflow.com/users/26507,"It would appear this just isn't possible, so we are resorting to the MultiDataTrigger in the question to compensate.
",Steven Robbins,https://stackoverflow.com/users/26507,http://stackoverflow.com/questions/5027204/is-it-possible-to-get-a-popup-to-ignore-menudropalignment-in-a-wpf-touch-app,STACKOVERFLOW,stackoverflow.com,0.6666666666666666,0.8333333333333334,0.0,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.8333333333333334,0.8333333333333334,0.5,0.8333333333333334,1.0,0.4,0.0,0.0,1.0,0.8333333333333334,Can I get a pop-up window in the WPF / touch application that ignores menudropalignment?,"As a bit of background - Windows has a facility for Touch/TabletPCs whereby it shifts the position of popups/menus depending on your ""handedness"" (to prevent the menu appearing under your hand). 

Essentially what this does is if you are set to ""right handed"" (which it seems to default to once you've connected a touch device), every popup you open is artificially kicked to the left - this causes massive layout issues where we try and line up a popup with the item it ""popped up from"" :

Tablet PC Settings set to Left handed - no artificial correction from Windows


Tablet PC Settings set to Right handed - Windows artificially adjusts our positioning


We can detect what this setting is set to with SystemParameters.MenuDropAlignment, and for trivial popups we can adjust this using the actual width of the popup - but for dynamic popups and when we throw right to left support into the mix, this just doesn't work.

Currently it's looking more likely that we are going to have to go through every popup, manually work out a value to adjust the kick, and add something like this to every one:

&lt;MultiDataTrigger&gt;
    &lt;MultiDataTrigger.Conditions&gt;
        &lt;Condition Binding=""{Binding Source={x:Static SystemParameters.MenuDropAlignment}}"" Value=""True""/&gt;
        &lt;Condition Binding=""{Binding RelativeSource={RelativeSource Mode=Self}, Path=FlowDirection}"" Value=""RightToLeft""/&gt;
    &lt;/MultiDataTrigger.Conditions&gt;
    &lt;MultiDataTrigger.Setters&gt;
        &lt;Setter Property=""HorizontalOffset"" Value=""-50""/&gt; &lt;!-- Set to arbitrary value to test --&gt;
    &lt;/MultiDataTrigger.Setters&gt;
&lt;/MultiDataTrigger&gt;


So.. back to the question :-) Does anyone know of a way to stop a WPF popup looking at this setting at all? 

For those that don't have a touch device you can access the Tablet PC settings by running:

C:\Windows\explorer.exe shell:::{80F3F1D5-FECA-45F3-BC32-752C152E456E}

And see the mess it makes for yourself :-)
","It would appear this just isn't possible, so we are resorting to the MultiDataTrigger in the question to compensate.
"
5278,5278,8385,Background-attachment: fixed is not working in iPad,"I use this css button working  background-attachment: fixed;in ipad.
    please help me.Below the link

Link is here

.home #bottom-header {
    background-attachment: fixed !important;
    background-clip: border-box;
    background-color: rgb(255, 255, 255);
    background-image: url(""images/hero_bg.jpg"");
    background-origin: padding-box;
    background-position: center top;
    background-repeat: no-repeat;
    background-size: 100% auto;
    height: 100%;
    position: relative;
    width: 100%;
}

",user1844884,https://stackoverflow.com/users/1844884,"This process is quite costly to the render process on mobile browsers so it is disabled.

See this post:
How to replicate background-attachment fixed on iOS
",BennyTicklez,https://stackoverflow.com/users/2970221,http://stackoverflow.com/questions/31295953/background-attachment-fixed-is-not-working-in-ipad,STACKOVERFLOW,stackoverflow.com,0.5555555555555556,0.3333333333333333,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.3333333333333333,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.3333333333333333,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.6666666666666666,0.0,1.0,1.0,Background attachment: fixed does not work in iPad,"I use this css button working  background-attachment: fixed;in ipad.
    please help me.Below the link

Link is here

.home #bottom-header {
    background-attachment: fixed !important;
    background-clip: border-box;
    background-color: rgb(255, 255, 255);
    background-image: url(""images/hero_bg.jpg"");
    background-origin: padding-box;
    background-position: center top;
    background-repeat: no-repeat;
    background-size: 100% auto;
    height: 100%;
    position: relative;
    width: 100%;
}

",This process is very expensive for rendering on mobile browsers and is therefore disabled.
5852,5852,9270,Does one need a master's in math before taking a PhD in math in Europe?,"This question is a variation of my earlier questions.

Okay so in the US, I guess one does not need a master's in math before pursuing a PhD in math since the US apparently usually assumes only a bachelor's.

What about in Europe? Technically, my master's is in mathematical finance not mathematics. So I didn't have research experience in looking through (pure) math books or articles in order to try to prove something theoretical or anything like that except for a few problem sets.

On an answer to one of my previous questions, user deviantfan commented that:

""In many european countries, it´s not even allowed/possible to skip the master degree.""

Perhaps my question may be rephrased:


  Is the master's in X PhD requirement in Europe satisfied by a
  master's in Applied X rather than Pure X?

",Jack Bauer,https://academia.stackexchange.com/users/22511,"I will try to respond to the abstract question, with a perspective from Germany (that may or may not be valid for other European countries):


  Is the master's in X PhD requirement in Europe satisfied by a master's in Applied X rather than Pure X?


The general answer to this is yes.

As opposed to the subject chosen for the Bachelor and Master degree, which is usually supposed to be the same or closely related in Europe, as Bachelor and Master curricula are closely coupled here, a PhD is often completely disconnected from the former studies.

Note that the Austrian website that Moritz linked to in the original version of his answer does not require a particular Master's degree, but a ""relevant Master's degree"". Without any further restrictions, this means that anything closely related to the subject (and the relationship between Applied X and Pure X might very well be sufficient) should do. At least, that would be the interpretation in Germany; it is possible Austrians interpret this differently.

However, it is also very well possible that the suitability of the Master's major is determined based on the research projects at hand. In that case, it depends entirely on the decision of the respective department chair, and it would be worthwhile to contact departments you are interested in. As a concrete example, it is completely normal in Germany to see Masters of Physics, Linguistics, and Maths starting PhDs in Computer Science, not only Masters in Computer Science.

EDIT: To clarify the last remark: None of them have to take any extra courses; rather, they are expected to bring their professional subject-specific knowledge from physics, linguistics, and maths, respectively, into their computer science research (while ""informally"" (i.e. without a class) catching up with the CS knowledge), just like Masters in CS are expected to use their professional CS-specific knowledge in their computer science research, while ""informally"" acquiring knowledge on (w.l.o.g.) physics, linguistics, and maths, as required for their respective research.
",O. R. Mapper,https://academia.stackexchange.com/users/14017,http://academia.stackexchange.com/questions/48237/does-one-need-a-masters-in-math-before-taking-a-phd-in-math-in-europe,LIFE_ARTS,academia.stackexchange.com,1.0,1.0,0.0,1.0,1.0,1.0,0.7777777777777778,0.6666666666666666,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.8888888888888888,1.0,1.0,0.8888888888888888,0.8,0.0,0.0,1.0,0.8888888888888888,Do you need to study for a master's degree in mathematics before studying for a Ph.D. in Mathematics in Europe?,"This question is a variation of my earlier questions.

Okay so in the US, I guess one does not need a master's in math before pursuing a PhD in math since the US apparently usually assumes only a bachelor's.

What about in Europe? Technically, my master's is in mathematical finance not mathematics. So I didn't have research experience in looking through (pure) math books or articles in order to try to prove something theoretical or anything like that except for a few problem sets.

On an answer to one of my previous questions, user deviantfan commented that:

""In many european countries, it´s not even allowed/possible to skip the master degree.""

Perhaps my question may be rephrased:


  Is the master's in X PhD requirement in Europe satisfied by a
  master's in Applied X rather than Pure X?

","I will try to respond to the abstract question, with a perspective from Germany (that may or may not be valid for other European countries):


  Is the master's in X PhD requirement in Europe satisfied by a master's in Applied X rather than Pure X?


The general answer to this is yes.

As opposed to the subject chosen for the Bachelor and Master degree, which is usually supposed to be the same or closely related in Europe, as Bachelor and Master curricula are closely coupled here, a PhD is often completely disconnected from the former studies.

Note that the Austrian website that Moritz linked to in the original version of his answer does not require a particular Master's degree, but a ""relevant Master's degree"". Without any further restrictions, this means that anything closely related to the subject (and the relationship between Applied X and Pure X might very well be sufficient) should do. At least, that would be the interpretation in Germany; it is possible Austrians interpret this differently.

However, it is also very well possible that the suitability of the Master's major is determined based on the research projects at hand. In that case, it depends entirely on the decision of the respective department chair, and it would be worthwhile to contact departments you are interested in. As a concrete example, it is completely normal in Germany to see Masters of Physics, Linguistics, and Maths starting PhDs in Computer Science, not only Masters in Computer Science.

EDIT: To clarify the last remark: None of them have to take any extra courses; rather, they are expected to bring their professional subject-specific knowledge from physics, linguistics, and maths, respectively, into their computer science research (while ""informally"" (i.e. without a class) catching up with the CS knowledge), just like Masters in CS are expected to use their professional CS-specific knowledge in their computer science research, while ""informally"" acquiring knowledge on (w.l.o.g.) physics, linguistics, and maths, as required for their respective research.
"
5352,5352,8497,How can I get to view the North Face of the Eiger in Switzerland?,"I can't seem to find information online about trains, buses, to take to get there etc. I would be travelling in from Stainach in Austria.

Is there a mountain station or similar that I can view it from?

e: I see from VMA's comment that I can go there via Grindelwald. What is the best way to get there from Stainach?

I'm thinking the train in the way of Stainach - Salzburg - Zurich - Bern - Grindelwald, but I can't get fares online for the Salzburg-Zurich-Bern portion. Anyone have an idea of the rough estimate of the fare?
",victoriah,https://travel.stackexchange.com/users/30,"According to Google maps and sbb.ch, the most closer railroad station is Alpiglen:
. According sattelite map, you'll get beautiful view from there.  

Not sure where are you getting from to the Eiger, so you can search trains by youself.
If you have more specific information, please provide it.



Update:
According oebb.at, route and prices are (used local time just for example):  


30.06.11 Stainach-Irdning 09:37 - Bischofshofen 10:48 - from 15.70 euro for 2d class without VORTEILScard
30.06.11 Bischofshofen 11:08 - Mannheim Hbf 16:56 - from 106.80 euro for 2d class without VORTEAILScard
30.06.11 Mannheim Hbf 17:36 - Interlaken Ost 21:56 - unknown by oebb.at, unfortunately, but by http://bahn.de - from 95.60 euro for 2d class
01.07.11 Interlaken Ost 06:04 - Grindelwald 06:38 - unknown by oebb.at, unfortunately, but by http://sbb.ch - from CHF 5.20 (near 4.4 euro) for 2d class
01.07.11 Grindelwald 07:17 - Alpiglen 07:38 - unknown by oebb.at, unfortunately, and by http://sbb.ch there is a bug with no founded station, but I think it is not very expensive


Also you can see [this question][11] to get some more sites to search prices and trains.
",VMAtm,https://travel.stackexchange.com/users/19,http://travel.stackexchange.com/questions/539/how-can-i-get-to-view-the-north-face-of-the-eiger-in-switzerland,CULTURE,travel.stackexchange.com,1.0,0.4444444444444444,0.0,1.0,1.0,0.6666666666666666,0.5555555555555556,0.7777777777777778,1.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,0.8888888888888888,0.8,1.0,0.0,0.0,0.6666666666666666,How can I see the north of the egger River in Switzerland?,"I can't seem to find information online about trains, buses, to take to get there etc. I would be travelling in from Stainach in Austria.

Is there a mountain station or similar that I can view it from?

e: I see from VMA's comment that I can go there via Grindelwald. What is the best way to get there from Stainach?

I'm thinking the train in the way of Stainach - Salzburg - Zurich - Bern - Grindelwald, but I can't get fares online for the Salzburg-Zurich-Bern portion. Anyone have an idea of the rough estimate of the fare?
","According to Google maps and sbb.ch, the most closer railroad station is Alpiglen:
. According sattelite map, you'll get beautiful view from there.  

Not sure where are you getting from to the Eiger, so you can search trains by youself.
If you have more specific information, please provide it.



Update:
According oebb.at, route and prices are (used local time just for example):  


30.06.11 Stainach-Irdning 09:37 - Bischofshofen 10:48 - from 15.70 euro for 2d class without VORTEILScard
30.06.11 Bischofshofen 11:08 - Mannheim Hbf 16:56 - from 106.80 euro for 2d class without VORTEAILScard
30.06.11 Mannheim Hbf 17:36 - Interlaken Ost 21:56 - unknown by oebb.at, unfortunately, but by http://bahn.de - from 95.60 euro for 2d class
01.07.11 Interlaken Ost 06:04 - Grindelwald 06:38 - unknown by oebb.at, unfortunately, but by http://sbb.ch - from CHF 5.20 (near 4.4 euro) for 2d class
01.07.11 Grindelwald 07:17 - Alpiglen 07:38 - unknown by oebb.at, unfortunately, and by http://sbb.ch there is a bug with no founded station, but I think it is not very expensive


Also you can see [this question][11] to get some more sites to search prices and trains.
"
3535,3535,5639,Eved Knani versus a Woman,"In terms of obligation in mitzvos, what is the difference between an Eved Knani and a woman? And if they are the same, why do we have two separate brachos for each in the morning prayers?
",WhoKnows,https://judaism.stackexchange.com/users/2726,"The שלמי חגיגה in 6:(4) (starting on page 30) has 2 long pieces discussing this – and from what I understand, women and Eved Knani are incidentally similar in their obligations.

(Not completely incidental, as their dispensations have the same source: both the Eved Knani and the Married Woman have another Boss besides for the Torah. He discusses that too.)

He brings – based on Rishonim – that an Eved Knani is either a non-Jew with some Jewish obligations or else ""2nd class"" Jew with limited obligations.

Either way, an Eved Knani is not a fully fledged Jew - and is therefore on a higher level than a non-Jew but a lower level than a Jewish woman.

As a result, the Bracha for Eved Knani is between the one where we thank for not being non-Jews with no obligations, and the one where we [men] thank for not being women who are fully fledged Jews with certain dispensations.
",Danny Schoemann,https://judaism.stackexchange.com/users/501,http://judaism.stackexchange.com/questions/36927/eved-knani-versus-a-woman,CULTURE,judaism.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,0.3333333333333333,1.0,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.0,0.3333333333333333,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.0,0.3333333333333333,1.0,Eve kernani's battle with women,"What's the difference between a loved villain and a woman in the obligation of the rite of passage? If they are the same, why should we prepare two independent arms for each person in the morning prayers?","The שלמי חגיגה in 6:(4) (starting on page 30) has 2 long pieces discussing this – and from what I understand, women and Eved Knani are incidentally similar in their obligations.

(Not completely incidental, as their dispensations have the same source: both the Eved Knani and the Married Woman have another Boss besides for the Torah. He discusses that too.)

He brings – based on Rishonim – that an Eved Knani is either a non-Jew with some Jewish obligations or else ""2nd class"" Jew with limited obligations.

Either way, an Eved Knani is not a fully fledged Jew - and is therefore on a higher level than a non-Jew but a lower level than a Jewish woman.

As a result, the Bracha for Eved Knani is between the one where we thank for not being non-Jews with no obligations, and the one where we [men] thank for not being women who are fully fledged Jews with certain dispensations.
"
5555,5555,8824,"In a Derby DBMS, How can I pad a number with zeros?","VALUES TRIM(CAST(CAST(YEAR( { fn  TIMESTAMPADD(SQL_TSI_MONTH,  -6  ,  
        CURRENT_DATE) }) AS CHAR(4) ) AS VARCHAR(4)))  || '-' ||     
        TRIM(CAST(CAST(MONTH( { fn  TIMESTAMPADD(SQL_TSI_MONTH, -6  ,   
          CURRENT_DATE) }) AS CHAR(2) ) AS VARCHAR(2))) 


The above statement returns 5 instead of 05 for MONTH(xxx)
which is not desired. It is not correct for comparisons
as 11 is smaller than 5 where in essense 11 is actually bigger
than 5

Edit:
With the JavaDB/Derby SQL statement above, I'd like to get
for example today is 2013-11-23, six months before was 2013-05-23
When comparing 

select p.ProductCode , p.ProductName as pn, sum( od.NetSales) AS Sales      
 from   
  products p   

  INNER JOIN order_details od ON (p.ProductCode = od.ProductCode)  
  INNER JOIN orders o ON (od.OrderCode = o.OrderCode)   
  where   TRIM(CAST(CAST(YEAR(o.PurchaseDateTime) AS CHAR(4)) AS VARCHAR(4))) || '-' ||    
  TRIM(CAST(CAST(MONTH(o.PurchaseDateTime)  AS CHAR(2)) AS VARCHAR(2)))      
              &gt;

  TRIM(CAST(CAST(YEAR( { fn  TIMESTAMPADD(SQL_TSI_MONTH,  -6   ,   CURRENT_DATE) }) AS CHAR(4) ) AS VARCHAR(4)))  || '-' ||    
  TRIM(CAST(CAST(MONTH( { fn  TIMESTAMPADD(SQL_TSI_MONTH, -6  ,   CURRENT_DATE) }) AS CHAR(2) ) AS VARCHAR(2)))         

       group by p.ProductCode, p.PRODUCTNAME


orders that are within the range are not included.
Whereas I want to include them
Hope you understand

Thanks
Jack
",user3024062,https://stackoverflow.com/users/3024062,"I find it easier to format my data in my application. Use SQL to select the data that you want; use JDBC to fetch that data into variables in your program (e.g., use ResultSet.getDate() to get the value of a date column); use the Java libraries to format the data as you desire (e.g., use SimpleDateFormat to format your date data).

To learn how to use the ResultSet methods such as getDate: http://docs.oracle.com/javase/7/docs/api/java/sql/ResultSet.html#getDate(int)

To learn how to use SimpleDateFormat: http://docs.oracle.com/javase/7/docs/api/java/text/SimpleDateFormat.html
",Bryan Pendleton,https://stackoverflow.com/users/193453,http://stackoverflow.com/questions/20158463/in-a-derby-dbms-how-can-i-pad-a-number-with-zeros,STACKOVERFLOW,stackoverflow.com,0.6666666666666666,0.5,0.0,0.0,1.0,1.0,0.5,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.5,0.0,0.0,0.6666666666666666,0.8333333333333334,0.3333333333333333,1.0,1.0,0.6,0.5,0.5,0.0,1.0,"In Derby DBMS, how to fill numbers with zeros?","VALUES TRIM(CAST(CAST(YEAR( { fn  TIMESTAMPADD(SQL_TSI_MONTH,  -6  ,  
        CURRENT_DATE) }) AS CHAR(4) ) AS VARCHAR(4)))  || '-' ||     
        TRIM(CAST(CAST(MONTH( { fn  TIMESTAMPADD(SQL_TSI_MONTH, -6  ,   
          CURRENT_DATE) }) AS CHAR(2) ) AS VARCHAR(2))) 


The above statement returns 5 instead of 05 for MONTH(xxx)
which is not desired. It is not correct for comparisons
as 11 is smaller than 5 where in essense 11 is actually bigger
than 5

Edit:
With the JavaDB/Derby SQL statement above, I'd like to get
for example today is 2013-11-23, six months before was 2013-05-23
When comparing 

select p.ProductCode , p.ProductName as pn, sum( od.NetSales) AS Sales      
 from   
  products p   

  INNER JOIN order_details od ON (p.ProductCode = od.ProductCode)  
  INNER JOIN orders o ON (od.OrderCode = o.OrderCode)   
  where   TRIM(CAST(CAST(YEAR(o.PurchaseDateTime) AS CHAR(4)) AS VARCHAR(4))) || '-' ||    
  TRIM(CAST(CAST(MONTH(o.PurchaseDateTime)  AS CHAR(2)) AS VARCHAR(2)))      
              &gt;

  TRIM(CAST(CAST(YEAR( { fn  TIMESTAMPADD(SQL_TSI_MONTH,  -6   ,   CURRENT_DATE) }) AS CHAR(4) ) AS VARCHAR(4)))  || '-' ||    
  TRIM(CAST(CAST(MONTH( { fn  TIMESTAMPADD(SQL_TSI_MONTH, -6  ,   CURRENT_DATE) }) AS CHAR(2) ) AS VARCHAR(2)))         

       group by p.ProductCode, p.PRODUCTNAME


orders that are within the range are not included.
Whereas I want to include them
Hope you understand

Thanks
Jack
","I find it easier to format data in an application. Use SQL to select the required data; use JDBC to extract the data into variables in the program (for example, use resultset. Get date() to get the value of the date column); use Java library to format the data as needed (for example, use simpledatformat to format the date data)."
2958,2958,4705,Java and JVM license,"Does Java license allow other companies to create their own versions of Java language or just implement it accurately? Same question about JVM.

I heard about Sun suing Microsoft for changing their .NET version of Java implementation and Java for Google Android, but I just can't grasp the whole concept as a totality.
",Sergey,https://programmers.stackexchange.com/users/9437,"You can write a compiler that implements the Java Language Specification or write a JVM that implements the Java Virtual Machine specification, but when you officially want to call it ""Java"", you have to prove it is compatible by passing the tests of the TCK (technology compatibility kit) and pay for a license from Oracle.

Oracle doesn't make it easy for other parties to do this, though. Apache has their own implementation of the JVM (Apache Harmony) but previously Sun, now Oracle, is not cooperating in making the TCK available nor let Apache get a license, which has led to a lot of resentment between Apache and Oracle.

Long ago Microsoft had their own version of Java (that was indeed called ""Java""). They tried to change it to make it Windows-specific, which Sun of course didn't like. Microsoft lost, quit their own Java version and created .NET, which is a completely different thing that just happens to work a lot like how Java works...

The lawsuit about Android isn't based on this at all; Google isn't saying that Android is Java. That lawsuit is about patents; Oracle has patents on a number of ideas and concepts in their own JVM implementation and is claiming that Google is using the same patented ideas in Android without getting a patent license from Oracle.
",Jesper,https://programmers.stackexchange.com/users/22262,http://programmers.stackexchange.com/questions/71561/java-and-jvm-license,TECHNOLOGY,programmers.stackexchange.com,0.6666666666666666,0.3333333333333333,0.0,1.0,1.0,1.0,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.8888888888888888,0.8888888888888888,0.8888888888888888,1.0,1.0,0.9333333333333332,0.0,0.0,0.6666666666666666,1.0,Java and JVM licenses,"Does Java license allow other companies to create their own versions of Java language or just implement it accurately? Same question about JVM.

I heard about Sun suing Microsoft for changing their .NET version of Java implementation and Java for Google Android, but I just can't grasp the whole concept as a totality.
","You can write a compiler that implements the Java Language Specification or write a JVM that implements the Java Virtual Machine specification, but when you officially want to call it ""Java"", you have to prove it is compatible by passing the tests of the TCK (technology compatibility kit) and pay for a license from Oracle.

Oracle doesn't make it easy for other parties to do this, though. Apache has their own implementation of the JVM (Apache Harmony) but previously Sun, now Oracle, is not cooperating in making the TCK available nor let Apache get a license, which has led to a lot of resentment between Apache and Oracle.

Long ago Microsoft had their own version of Java (that was indeed called ""Java""). They tried to change it to make it Windows-specific, which Sun of course didn't like. Microsoft lost, quit their own Java version and created .NET, which is a completely different thing that just happens to work a lot like how Java works...

The lawsuit about Android isn't based on this at all; Google isn't saying that Android is Java. That lawsuit is about patents; Oracle has patents on a number of ideas and concepts in their own JVM implementation and is claiming that Google is using the same patented ideas in Android without getting a patent license from Oracle.
"
5087,5087,8093,Can I replace an old closet light with multiple electrical outlets?,"I have asked a family member to replace an old light fixture in a large walk in closet with an actual electrical strip. The house is an 101 year old craftsman. There aren't any electrical outlets in that corner of the small house. The closet(has windows so it will be my office) I will need electricity for  desktop pc, printer, at least one light, and just outside the closet I need to run at least two more lamps. Is that safe? Is it too much? We won't be doing iside wiring. Again only an old light fixture that has electrity running though an old fashion ""flex tube"" for lack of a better word.It is on the outside of the wall. ANY precautions or ideas?
",Sharon Smith,https://diy.stackexchange.com/users/11421,"The best answer to this is to leave the light as a light and have a qualified electrician run a three wire circuit (hot, neutral, ground) direct to your soon-to-be office. Your modern equipment needs it and disturbing any old turn of the century wiring is asking for disaster. 

Having lived in an old house with Range, Pump and four circuits, adding any extra load to an ancient system without upgrading the wiring is a good indicator for having several fire detectors located in strategic places and keeping their batteries up to date.
",Fiasco Labs,https://diy.stackexchange.com/users/7020,http://diy.stackexchange.com/questions/24978/can-i-replace-an-old-closet-light-with-multiple-electrical-outlets,LIFE_ARTS,diy.stackexchange.com,1.0,0.7777777777777778,0.3333333333333333,1.0,0.6666666666666666,1.0,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.0,0.3333333333333333,0.8888888888888888,Can I use multiple power outlets instead of the old closet lights?,"I've asked a family member to replace an old light fixture in a large closet with a real strip. The house is a 101 year old craftsman. There is no electrical outlet in that corner of the small house. Closet (with windows, so it's my office) I need to power my desktop computer, printer, at least one light. Just outside the closet, I need to run at least two more lights. Is that safe? Is it too much? We don't do iside cabling. Similarly, there is only one old lamp, because of the lack of a better word, its power runs through an old fashionable ""flexible tube"". It's outside the wall. Are there any precautions or ideas?","The best answer to this is to leave the light as a light and have a qualified electrician run a three wire circuit (hot, neutral, ground) direct to your soon-to-be office. Your modern equipment needs it and disturbing any old turn of the century wiring is asking for disaster. 

Having lived in an old house with Range, Pump and four circuits, adding any extra load to an ancient system without upgrading the wiring is a good indicator for having several fire detectors located in strategic places and keeping their batteries up to date.
"
376,376,593,Stop image resizing in particular case - is that possible?,"As for an ad management plugin, I'm using WordPress' default media uploader. And WP Media Uploader automatically resizes images. But as the ad image is already resized (i.e.: 225 x 100px) it need not to resize into a new file for thumbnail (100 x 100px); because, that thumbnail is unnecessary for the site.

The cause I presented here, may be a very minute for such a solution, but in case, there is any other massive issue that, in such plugin we can stop the auto resizing with WP Media Uploader only on that plugin-uploads - I think that can be a good solution for any site.

Is there a way to use WP Media Uploader, but can stop auto resizing images only onto that particular case uploads?

But I also know that, plugin like Regenerate Thumbnails can override the rules and can do what I prohibited in my plugins for the site's space-savvy consumption.
",Mayeenul Islam,https://wordpress.stackexchange.com/users/22728,"Use the Filter Hook intermediate_image_sizes_advanced for control the resize function for different sizes. This hook get a array of different sizes and can control your resize with your requirements. Add your logic inside a plugin and remove sizes via this hook.

 // the hook in core
 $sizes = apply_filters( 'intermediate_image_sizes_advanced', $sizes );


A small example to remove the resize for mediumsize.

add_filter( 'intermediate_image_sizes_advanced', 'fb_filter_image_sizes');
function fb_filter_image_sizes( $sizes) {

    unset( $sizes['thumbnail']);

    return $sizes;
}

",bueltge,https://wordpress.stackexchange.com/users/170,http://wordpress.stackexchange.com/questions/131829/stop-image-resizing-in-particular-case-is-that-possible,TECHNOLOGY,wordpress.stackexchange.com,0.8888888888888888,0.4444444444444444,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.0,0.0,0.7777777777777778,Stop resizing images in certain situations - is this possible?,"As for an ad management plugin, I'm using WordPress' default media uploader. And WP Media Uploader automatically resizes images. But as the ad image is already resized (i.e.: 225 x 100px) it need not to resize into a new file for thumbnail (100 x 100px); because, that thumbnail is unnecessary for the site.

The cause I presented here, may be a very minute for such a solution, but in case, there is any other massive issue that, in such plugin we can stop the auto resizing with WP Media Uploader only on that plugin-uploads - I think that can be a good solution for any site.

Is there a way to use WP Media Uploader, but can stop auto resizing images only onto that particular case uploads?

But I also know that, plugin like Regenerate Thumbnails can override the rules and can do what I prohibited in my plugins for the site's space-savvy consumption.
","Use the Filter Hook intermediate_image_sizes_advanced for control the resize function for different sizes. This hook get a array of different sizes and can control your resize with your requirements. Add your logic inside a plugin and remove sizes via this hook.

 // the hook in core
 $sizes = apply_filters( 'intermediate_image_sizes_advanced', $sizes );


A small example to remove the resize for mediumsize.

add_filter( 'intermediate_image_sizes_advanced', 'fb_filter_image_sizes');
function fb_filter_image_sizes( $sizes) {

    unset( $sizes['thumbnail']);

    return $sizes;
}

"
5818,5818,9218,"Who was the ""Starship Troopers"" representative who appeared in ""The Cat Who Walks Through Walls""?","From ""The Cat Who Walks Through Walls"" Wiki article:


  During a meeting of the Council of the Time Scouts, representatives from every major time line and setting written by Heinlein appear, including Glory Road and Starship Troopers; and a reference is made to other authors' works as well.


Who was the representative from Starship Troopers?
",DVK-on-Ahch-To,https://scifi.stackexchange.com/users/976,"The members of the Circle of the Ouroboros are introduced as:

Master Mobyas Toras of Barsoom (Timeline 1, Coded John Carter)

Her Wisdom Star, Arbitrar of the Ninety Universes (Composite timeline, Coded Cyrano)

Woodrow Wilson Smith, Senior of the Howard Families (Timeline 2, Coded Leslie LeCroix)

Dr. Jubal Harshaw (Timeline 3, Coded Neil Armstrong)

Dr. Hilda Mae Burroughs (Timeline 4, Coded Ballox O'Malley)

Commander Ted Smith (Timeline 5, Coded DuQuesne)

Captain John Sterling (Timeline 6, Coded Neil Armstrong Alternate)

Sky Marshal Samuel Beaux (Timeline 7, Coded Fairacre)

In Starship Troopers, the person with the rank of Sky Marshal commands Earth's entire military, so we can reasonably assume that the representative from Starship Troopers is Sky Marshal Samuel Beaux.
",Bob Warwick,https://scifi.stackexchange.com/users/4937,http://scifi.stackexchange.com/questions/13716/who-was-the-starship-troopers-representative-who-appeared-in-the-cat-who-walk,LIFE_ARTS,scifi.stackexchange.com,1.0,1.0,0.0,1.0,1.0,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.8888888888888888,1.0,0.7777777777777778,1.0,1.0,1.0,0.0,0.0,0.6666666666666666,0.8888888888888888,"Who is the representative of ""starship soldier"" in ""through the wall cat""?","From ""The Cat Who Walks Through Walls"" Wiki article:


  During a meeting of the Council of the Time Scouts, representatives from every major time line and setting written by Heinlein appear, including Glory Road and Starship Troopers; and a reference is made to other authors' works as well.


Who was the representative from Starship Troopers?
","The members of the Circle of the Ouroboros are introduced as:

Master Mobyas Toras of Barsoom (Timeline 1, Coded John Carter)

Her Wisdom Star, Arbitrar of the Ninety Universes (Composite timeline, Coded Cyrano)

Woodrow Wilson Smith, Senior of the Howard Families (Timeline 2, Coded Leslie LeCroix)

Dr. Jubal Harshaw (Timeline 3, Coded Neil Armstrong)

Dr. Hilda Mae Burroughs (Timeline 4, Coded Ballox O'Malley)

Commander Ted Smith (Timeline 5, Coded DuQuesne)

Captain John Sterling (Timeline 6, Coded Neil Armstrong Alternate)

Sky Marshal Samuel Beaux (Timeline 7, Coded Fairacre)

In Starship Troopers, the person with the rank of Sky Marshal commands Earth's entire military, so we can reasonably assume that the representative from Starship Troopers is Sky Marshal Samuel Beaux.
"
1713,1713,2712,Eclipse can't find javaw.exe. Already changed eclipse.ini,"I have trouble starting a new eclipse distribution, that I downloaded from a server at work. 

I extracted the folder to my desktop but running the eclipse.exe gives me the error: A JRE must be available. No java runtime was found at C:Users\my desktop\eclipse etc.

Of course it can not find the javaw.exe in the folder on my desktop as it is installed at program files. I already edited the eclipse.ini and added: -vm C:\Program Files\Java\jre7\bin\javaw.exe 

but it still gives me the same error so it searches for java in the wrong folder. 

What should i try next?
",McButch,https://stackoverflow.com/users/4706989,"Your eclipse ini file should be like this:

--launcher.XXMaxPermSize
256m
--launcher.defaultAction
openFile
-vm
C:\Program Files\Java\jre7\bin\javaw.exe
-vmargs
...


-vm option on a line, path on an other line
",Steph,https://stackoverflow.com/users/4729284,http://stackoverflow.com/questions/29937180/eclipse-cant-find-javaw-exe-already-changed-eclipse-ini,STACKOVERFLOW,stackoverflow.com,1.0,0.6666666666666666,0.0,0.0,1.0,1.0,0.5,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.8333333333333334,0.8333333333333334,0.6666666666666666,1.0,1.0,0.9,1.0,0.0,0.0,0.8333333333333334,Eclipse cannot find javaw.exe. Eclipse.ini changed,"I have trouble starting a new eclipse distribution, that I downloaded from a server at work. 

I extracted the folder to my desktop but running the eclipse.exe gives me the error: A JRE must be available. No java runtime was found at C:Users\my desktop\eclipse etc.

Of course it can not find the javaw.exe in the folder on my desktop as it is installed at program files. I already edited the eclipse.ini and added: -vm C:\Program Files\Java\jre7\bin\javaw.exe 

but it still gives me the same error so it searches for java in the wrong folder. 

What should i try next?
","Your eclipse ini file should be like this:

--launcher.XXMaxPermSize
256m
--launcher.defaultAction
openFile
-vm
C:\Program Files\Java\jre7\bin\javaw.exe
-vmargs
...


-vm option on a line, path on an other line
"
675,675,1068,Can an iphone/android cell phone communicate with RFID?,"Is it possible for a cell phone to communicate with an RFID chip?

I'm looking for a low-powered solution to turn a device on/off wirelessly, using a cell phone.

Example: phone sends signal to RFID chip, circuit board switches on. 

It really looks like Bluetooth will take too much battery, as this will be a portable device.

Any suggestions ? 
",user3226576,https://electronics.stackexchange.com/users/40947,"RFID is typically Tag sending a message, usually just an ID number, to a Device, which reads it. You want the other way around, which is not how RFID is used. NFC can be used for two way transmission (Like touching the back of two NFC phones to pass data), but it's also mainly used as an ID system, Tag to Device.

You can have a NFC device act as a tag, which your circuit would then scan for. For this you need a NFC reader as well as your microcontroller.

Bluetooth, and Bluetooth LE are the way to go.
",Passerby,https://electronics.stackexchange.com/users/17178,http://electronics.stackexchange.com/questions/108181/can-an-iphone-android-cell-phone-communicate-with-rfid,SCIENCE,electronics.stackexchange.com,1.0,0.8888888888888888,0.0,1.0,0.6666666666666666,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,0.6666666666666666,1.0,Can the iPhone / Android phone communicate with RFID?,"Is it possible for a cell phone to communicate with an RFID chip?

I'm looking for a low-powered solution to turn a device on/off wirelessly, using a cell phone.

Example: phone sends signal to RFID chip, circuit board switches on. 

It really looks like Bluetooth will take too much battery, as this will be a portable device.

Any suggestions ? 
","RFID is typically Tag sending a message, usually just an ID number, to a Device, which reads it. You want the other way around, which is not how RFID is used. NFC can be used for two way transmission (Like touching the back of two NFC phones to pass data), but it's also mainly used as an ID system, Tag to Device.

You can have a NFC device act as a tag, which your circuit would then scan for. For this you need a NFC reader as well as your microcontroller.

Bluetooth, and Bluetooth LE are the way to go.
"
4177,4177,6666,Why do I get the wrong result from this program to compute gross pay?,"This is actually a homework. Here is the question.


  Write a program to prompt the user for hours and rate per hour using raw_input to compute gross pay. Pay the hourly rate for the hours up to 40 and 1.5 times the hourly rate for all hours worked above 40 hours. Use 45 hours and a rate of 10.50 per hour to test the program (the pay should be 498.75). You should use raw_input to read a string and float() to convert the string to a number. Do not worry about error checking the user input - assume the user types numbers properly.


I've tried this, but it doesn't work correctly.

hrs = raw_input(""Enter Hours:"")
h = float(hrs)
rate_hour = raw_input(""Enter rate:"")
r = float(rate_hour)
if h &lt;= 40:
    r = 1
else :
    r = 1.5
print h * r 

",coder123,https://stackoverflow.com/users/4776843,"What you are doing is - 


if the person has worked more than 40 hours, you pay him 1.5 times for complete hours worked.
if the person has worked less than 40 hours, you pay him 1 times for complete hours worked.


This works correctly if the amount of hours is less than 40, but according to your question, what you have to do is -


if the person has worked more than 40 hours, pay 1 times for up to 40 hours, and then 1.5 times after 40 hours (that is total hours - 40).

",Anand S Kumar,https://stackoverflow.com/users/795990,http://stackoverflow.com/questions/30993708/why-do-i-get-the-wrong-result-from-this-program-to-compute-gross-pay,STACKOVERFLOW,stackoverflow.com,1.0,0.5,0.0,1.0,0.5,1.0,0.8333333333333334,0.5,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.5,0.0,1.0,0.8333333333333334,0.5,1.0,1.0,0.9,0.5,0.0,1.0,1.0,Why do I get the wrong result from this program to calculate the payroll?,"This is actually a homework. Here is the question.


  Write a program to prompt the user for hours and rate per hour using raw_input to compute gross pay. Pay the hourly rate for the hours up to 40 and 1.5 times the hourly rate for all hours worked above 40 hours. Use 45 hours and a rate of 10.50 per hour to test the program (the pay should be 498.75). You should use raw_input to read a string and float() to convert the string to a number. Do not worry about error checking the user input - assume the user types numbers properly.


I've tried this, but it doesn't work correctly.

hrs = raw_input(""Enter Hours:"")
h = float(hrs)
rate_hour = raw_input(""Enter rate:"")
r = float(rate_hour)
if h &lt;= 40:
    r = 1
else :
    r = 1.5
print h * r 

","What you are doing is - 


if the person has worked more than 40 hours, you pay him 1.5 times for complete hours worked.
if the person has worked less than 40 hours, you pay him 1 times for complete hours worked.


This works correctly if the amount of hours is less than 40, but according to your question, what you have to do is -


if the person has worked more than 40 hours, pay 1 times for up to 40 hours, and then 1.5 times after 40 hours (that is total hours - 40).

"
304,304,492,Git: How can I merge changes made between two tags to another branch?,"I'm trying to manage our Moodle instance on our own branch of the Moodle repo. I checked out tag ""v1.9.11"" of branch ""MOODLE_19_STABLE"", then copied that to a new branch ""COE"", where I've added in our custom theme, etc.

Now that tag ""v1.9.12"" exists, I want to merge the commits up to that tag into my ""COE"" branch (and not the commits that came after).

Can I do this with something like git cherry-pick? 
",Steve Clay,https://stackoverflow.com/users/3779,"$ git merge v1.9.12


will merge all the commits up to, and including, v1.9.12, and nothing after that.
",mipadi,https://stackoverflow.com/users/28804,http://stackoverflow.com/questions/6075032/git-how-can-i-merge-changes-made-between-two-tags-to-another-branch,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.6666666666666666,0.0,1.0,1.0,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,0.8888888888888888,0.9,0.3333333333333333,0.3333333333333333,0.0,1.0,Git: how do I merge changes between two tags into another branch?,"I'm trying to manage our Moodle instance on our own branch of the Moodle repo. I checked out tag ""v1.9.11"" of branch ""MOODLE_19_STABLE"", then copied that to a new branch ""COE"", where I've added in our custom theme, etc.

Now that tag ""v1.9.12"" exists, I want to merge the commits up to that tag into my ""COE"" branch (and not the commits that came after).

Can I do this with something like git cherry-pick? 
","$ git merge v1.9.12


will merge all the commits up to, and including, v1.9.12, and nothing after that.
"
4581,4581,7262,Order by collection member in Neo4j,"I have the following query for getting an actor, roles and movies from the example movie database in Neo4j like this:

MATCH (actor:Person {name:""Meg Ryan""})-[role:ACTED_IN]-&gt;(movies)
RETURN actor, collect({roles: role.roles, movies: movies}) as movies


It all works nice, but when I want to order the collection by movies release year, I'm encountering some issues. 

I tried to do it like this: 

MATCH (actor:Person {name:""Meg Ryan""})-[role:ACTED_IN]-&gt;(movies)
ORDER BY movies.released DESC
RETURN actor, collect({roles: role.roles, movies: movies}) as movies


but i get this error: 

Invalid input 'R': expected 'p/P' (line 2, column 2)
""ORDER BY movies.released DESC""
  ^


How can i order the collection by the Movies release year before putting it in a collection?
",Srdjan Marjanovic,https://stackoverflow.com/users/2016358,"Use WITH keyword befor ORDER BY to sort the results before collect:

Beware that the WITH part needs to contain all variables that are used later in the query (actor,role,movies in this case).

MATCH (actor:Person {name:""Meg Ryan""})-[role:ACTED_IN]-&gt;(movies)
WITH actor,role,movies 
ORDER BY movies.released DESC
RETURN actor, collect({roles: role.roles, movies: movies}) as movies


Similar example is given in the documentation.
",frant.hartm,https://stackoverflow.com/users/951609,http://stackoverflow.com/questions/28433163/order-by-collection-member-in-neo4j,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.3333333333333333,0.0,1.0,0.3333333333333333,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,1.0,Sort by set member in neo4j,"I have the following query for getting an actor, roles and movies from the example movie database in Neo4j like this:

MATCH (actor:Person {name:""Meg Ryan""})-[role:ACTED_IN]-&gt;(movies)
RETURN actor, collect({roles: role.roles, movies: movies}) as movies


It all works nice, but when I want to order the collection by movies release year, I'm encountering some issues. 

I tried to do it like this: 

MATCH (actor:Person {name:""Meg Ryan""})-[role:ACTED_IN]-&gt;(movies)
ORDER BY movies.released DESC
RETURN actor, collect({roles: role.roles, movies: movies}) as movies


but i get this error: 

Invalid input 'R': expected 'p/P' (line 2, column 2)
""ORDER BY movies.released DESC""
  ^


How can i order the collection by the Movies release year before putting it in a collection?
","Use WITH keyword befor ORDER BY to sort the results before collect:

Beware that the WITH part needs to contain all variables that are used later in the query (actor,role,movies in this case).

MATCH (actor:Person {name:""Meg Ryan""})-[role:ACTED_IN]-&gt;(movies)
WITH actor,role,movies 
ORDER BY movies.released DESC
RETURN actor, collect({roles: role.roles, movies: movies}) as movies


Similar example is given in the documentation.
"
4920,4920,7832,How to use part of a file name as a link within a word document,"How do I have a link within a word document to certain text strings of the file name?

For example, I am editing a word document where the file name is: 'File 075 - Test result 101.doc', and would like to only use the strings 'File 075' rather than the full file name in the word document as a automatic link / field that updates itself when the file name changes.

How would you proceed with it?
",John L,https://superuser.com/users/44824,"I think you are talking about a field and not a link as in hyperlink.  A hyperlink can have its display text different from its url.  A field cannot change its display text though.
",surfasb,https://superuser.com/users/24500,http://superuser.com/questions/170664,TECHNOLOGY,superuser.com,0.7777777777777778,0.8888888888888888,0.0,0.6666666666666666,1.0,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.8888888888888888,0.6666666666666666,0.5555555555555556,1.0,1.0,0.6666666666666667,0.0,0.0,0.3333333333333333,0.8888888888888888,How to use some file names as links in word documents,"How do I have a link within a word document to certain text strings of the file name?

For example, I am editing a word document where the file name is: 'File 075 - Test result 101.doc', and would like to only use the strings 'File 075' rather than the full file name in the word document as a automatic link / field that updates itself when the file name changes.

How would you proceed with it?
","I think you're talking about a field, not a link in a hyperlink. The display text of a hyperlink can be different from its URL. But a field cannot change its display text."
3533,3533,5636,"Can you designate your craft, perform, or profession skill even if you have no ranks in it?","Could you, for example, have one of your craft skills filled in as carpenter, but have no ranks in it?  Being a very bad carpenter, but a carpenter nevertheless.
",Nerevar,https://rpg.stackexchange.com/users/11514,"Not only can you, you have to. You never roll a &ldquo;Craft check&rdquo; or &ldquo;Perform check,&rdquo; those skills don&rsquo;t exist. Rather, they are categories of skills, like &ldquo;Craft (basketweaving)&rdquo; or &ldquo;Perform (underwater basketweaving).&rdquo; That&rsquo;s still true even if you have no ranks, and it&rsquo;s relevant for things like feats or instruments, which may need to be compatible with the chosen Craft or Perform skill.

Craft and Perform may be used without ranks, so if you have high Intelligence or high Charisma, and/or other bonuses to those skills, you could even be good at them without any training (e.g. ranks). It&rsquo;d be hard to keep up with someone who is actually training it, though.

Profession&rsquo;s much the same, but unless you are trained, you cannot roll the specific Profession skill at all (instead, you just get a flat 1 sp/day as unskilled labor). So having ranks in Profession (woven-basket critic) doesn&rsquo;t let you roll for Profession (woven-basket recycler) checks; they are separate skills, and you have no ranks in the latter. But you still have to make the distinction between the two.
",KRyan,https://rpg.stackexchange.com/users/4563,http://rpg.stackexchange.com/questions/37160/can-you-designate-your-craft-perform-or-profession-skill-even-if-you-have-no-r,CULTURE,rpg.stackexchange.com,0.7777777777777778,0.8888888888888888,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.7777777777777778,0.5555555555555556,0.0,0.0,0.3333333333333333,1.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7777777777777778,0.8888888888888888,0.8888888888888888,0.8888888888888888,1.0,1.0,0.0,0.0,0.6666666666666666,1.0,"Even if you don't have a level, can you specify your skills, acting or professional skills?","For example, can you fill in one of your crafts as a carpenter, but there is no grade? Be a bad carpenter, but still a carpenter.","Not only can you, you have to. You never roll a &ldquo;Craft check&rdquo; or &ldquo;Perform check,&rdquo; those skills don&rsquo;t exist. Rather, they are categories of skills, like &ldquo;Craft (basketweaving)&rdquo; or &ldquo;Perform (underwater basketweaving).&rdquo; That&rsquo;s still true even if you have no ranks, and it&rsquo;s relevant for things like feats or instruments, which may need to be compatible with the chosen Craft or Perform skill.

Craft and Perform may be used without ranks, so if you have high Intelligence or high Charisma, and/or other bonuses to those skills, you could even be good at them without any training (e.g. ranks). It&rsquo;d be hard to keep up with someone who is actually training it, though.

Profession&rsquo;s much the same, but unless you are trained, you cannot roll the specific Profession skill at all (instead, you just get a flat 1 sp/day as unskilled labor). So having ranks in Profession (woven-basket critic) doesn&rsquo;t let you roll for Profession (woven-basket recycler) checks; they are separate skills, and you have no ranks in the latter. But you still have to make the distinction between the two.
"
54,54,81,Is there added value in having your own presentation layout and using it consistently?,"From the perspective of a Ph.D. student, how much of an added value is it to have your own presentation slides layout, that is used consistently throughout your Ph.D. conference presentations and other talks (and possibly throughout your academic career afterwards)?

Here is one such example from the Computer Science community.

This as as opposed to using existing Beamer templates with LaTeX, or built-in PowerPoint templates, or simply preparing each presentation on its own (without a specific layout).

A couple of axes I can think along:


Creating a signature layout that distinguishes one in their community
Ease of preparation of presentations (especially over time), maybe overcoming constraints with existing templates.


Note that I am not concerned with the question of content, but just design and layout.
",lyes,https://academia.stackexchange.com/users/15902,"First of all, I do not think that having a signature layout is any good for its own sake. In most fields, few people (apart from your workgroup) will attend more than one of your talks and even those who will, will likely not notice the consistency of your layout¹ – unless it’s particularly memorable, which is almost certainly not a good thing². And even if somebody notices, they will likely (and hopefully) value the quality of your design more, let alone the quality of your content.

Considering the required work, there are two aspects: (1) Creating (or choosing) a layout and (2) Using the layout throughout your presentations.

Aspect 1 takes a few hours, if you are sufficiently apt with your presentation program (and it does not suck) and know some basics of graphic design (which I suppose you do, if you are asking such a question).
Mostly it’s selecting a colour scheme, one or two fonts and a default arrangement of your slides and realising them in your presentation program and in the programs you use to generate your figures.
Regarding the constraints of existing templates, remember that (unless your problems are very individual) if no templates are the way you want them, it is very likely that you should be careful what you are wishing for.
Also beware that the fact that you have to rely on (usually unknown) projectors imposes some constraints on your font and colour selections.

Aspect 2 will usually save you some time, whether you are using a prebuilt design or your own: For example, you are very likely to reuse some material – in particular figures. And if you care about your slides being consistent (which I suppose you do), you avoid spending some time in adapting colour schemes, for example. In particular, there is usually no benefit in switching designs.

From personal experience, I have spent some time in working out a design and have not regretted it yet.

¹ Just think about, how few people give horribly designed presentations and thus can be assumed not even to notice the flaws in their own presentations, let alone the qualities of your’s.
² As you should not notice good design that much.
",Wrzlprmft,https://academia.stackexchange.com/users/7734,http://academia.stackexchange.com/questions/25822/is-there-added-value-in-having-your-own-presentation-layout-and-using-it-consist,LIFE_ARTS,academia.stackexchange.com,1.0,0.8333333333333334,0.3333333333333333,1.0,0.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,0.0,1.0,Is there added value in having your own presentation layout and using it consistently?,"From the perspective of a Ph.D. student, how much of an added value is it to have your own presentation slides layout, that is used consistently throughout your Ph.D. conference presentations and other talks (and possibly throughout your academic career afterwards)?

Here is one such example from the Computer Science community.

This as as opposed to using existing Beamer templates with LaTeX, or built-in PowerPoint templates, or simply preparing each presentation on its own (without a specific layout).

A couple of axes I can think along:


Creating a signature layout that distinguishes one in their community
Ease of preparation of presentations (especially over time), maybe overcoming constraints with existing templates.


Note that I am not concerned with the question of content, but just design and layout.
","First of all, I do not think that having a signature layout is any good for its own sake. In most fields, few people (apart from your workgroup) will attend more than one of your talks and even those who will, will likely not notice the consistency of your layout¹ – unless it’s particularly memorable, which is almost certainly not a good thing². And even if somebody notices, they will likely (and hopefully) value the quality of your design more, let alone the quality of your content.

Considering the required work, there are two aspects: (1) Creating (or choosing) a layout and (2) Using the layout throughout your presentations.

Aspect 1 takes a few hours, if you are sufficiently apt with your presentation program (and it does not suck) and know some basics of graphic design (which I suppose you do, if you are asking such a question).
Mostly it’s selecting a colour scheme, one or two fonts and a default arrangement of your slides and realising them in your presentation program and in the programs you use to generate your figures.
Regarding the constraints of existing templates, remember that (unless your problems are very individual) if no templates are the way you want them, it is very likely that you should be careful what you are wishing for.
Also beware that the fact that you have to rely on (usually unknown) projectors imposes some constraints on your font and colour selections.

Aspect 2 will usually save you some time, whether you are using a prebuilt design or your own: For example, you are very likely to reuse some material – in particular figures. And if you care about your slides being consistent (which I suppose you do), you avoid spending some time in adapting colour schemes, for example. In particular, there is usually no benefit in switching designs.

From personal experience, I have spent some time in working out a design and have not regretted it yet.

¹ Just think about, how few people give horribly designed presentations and thus can be assumed not even to notice the flaws in their own presentations, let alone the qualities of your’s.
² As you should not notice good design that much.
"
158,158,249,where to put .sty and .cls file for project,"I want to use my own .sty and .cls file in a project. I know of the following two possibilities of placing them:


in my local tex tree (or the general tex tree, which is worse)
in the same directory as the .tex file


Both of these I find unsatisfactory for the following reasons:

The local tex tree is unsatisfactory since the .sty file is specific for the project, so I want it to be close to the project, so I easily remember where it is etc. Also, I am using dropbox to synchronize the project files between different computers automatically, so the .sty file should be in the dropbox folder.

The 'same directory' is unsatisfactory since the project is in a directory with many subdirectories. The .tex files in all these subdirectories should be able to access the same .sty file.

What I would like to do is: create a subdirectory 'style files' in the project directory, where I put style and class files (there are several for the project), then tell tex somehow where to find them.

How can I do this?

I am using a recent TexLive on  Mac OS X.6

I know there have been questions about placement of .sty files, but I did not find an answer to this question.
",Daniel,https://tex.stackexchange.com/users/9171,"Probably the easiest trick to do is to create aliases of every .sty and .cls file (located in your 'style files' directory) and put them wherever you need them. This is not (only) for saving space, but for unity.
",Vladimir,https://tex.stackexchange.com/users/26140,http://tex.stackexchange.com/questions/34203/where-to-put-sty-and-cls-file-for-project,TECHNOLOGY,tex.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,0.3333333333333333,1.0,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.6666666666666666,0.3333333333333333,0.3333333333333333,1.0,Where to store. Sty and. CLS files for the project,"I want to use my own .sty and .cls file in a project. I know of the following two possibilities of placing them:


in my local tex tree (or the general tex tree, which is worse)
in the same directory as the .tex file


Both of these I find unsatisfactory for the following reasons:

The local tex tree is unsatisfactory since the .sty file is specific for the project, so I want it to be close to the project, so I easily remember where it is etc. Also, I am using dropbox to synchronize the project files between different computers automatically, so the .sty file should be in the dropbox folder.

The 'same directory' is unsatisfactory since the project is in a directory with many subdirectories. The .tex files in all these subdirectories should be able to access the same .sty file.

What I would like to do is: create a subdirectory 'style files' in the project directory, where I put style and class files (there are several for the project), then tell tex somehow where to find them.

How can I do this?

I am using a recent TexLive on  Mac OS X.6

I know there have been questions about placement of .sty files, but I did not find an answer to this question.
","Perhaps the easiest way is to create aliases for each. Sty and. CLS file (located in the style files directory) and place them where you need them. This is not only to save space, but also to unite."
787,787,1252,using the new facebook payments reports API,"been trying to get data from the facebook payments reports API, since they say on november 7th no more reports will be sent by email.
tried php and got an error - ""SSL connection timeout"".
this is the php curl code i'm using:

$set_action_url = ""https://paymentreports.facebook.com/"".$company_id.""/report?date="".$date.""&amp;type="".$type.""&amp;access_token="".$company_token;
$ch = curl_init($set_action_url);
curl_setopt($ch, CURLOPT_RETURNTRANSFER, true);
curl_setopt($ch,CURLOPT_TIMEOUT,5);
curl_setopt($ch, CURLOPT_CONNECTTIMEOUT ,0);
curl_setopt($ch, CURLOPT_SSL_VERIFYPEER, false);
$result = curl_exec($ch);


i logged the url and query string just before the call, and if i use it in a browser
i do get the file.

what am i doing wrong?
",user1750618,https://stackoverflow.com/users/1750618,"Try to add :

curl_setopt($ch, CURLOPT_SSLVERSION, 3);

",j0k,https://stackoverflow.com/users/569101,http://stackoverflow.com/questions/12919057/using-the-new-facebook-payments-reports-api,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.3333333333333333,0.0,1.0,0.6666666666666666,1.0,0.6666666666666666,0.4444444444444444,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,0.0,0.4444444444444444,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.9,1.0,0.0,0.0,0.8888888888888888,Using the new Facebook payment reporting API,"been trying to get data from the facebook payments reports API, since they say on november 7th no more reports will be sent by email.
tried php and got an error - ""SSL connection timeout"".
this is the php curl code i'm using:

$set_action_url = ""https://paymentreports.facebook.com/"".$company_id.""/report?date="".$date.""&amp;type="".$type.""&amp;access_token="".$company_token;
$ch = curl_init($set_action_url);
curl_setopt($ch, CURLOPT_RETURNTRANSFER, true);
curl_setopt($ch,CURLOPT_TIMEOUT,5);
curl_setopt($ch, CURLOPT_CONNECTTIMEOUT ,0);
curl_setopt($ch, CURLOPT_SSL_VERIFYPEER, false);
$result = curl_exec($ch);


i logged the url and query string just before the call, and if i use it in a browser
i do get the file.

what am i doing wrong?
","Try to add :

curl_setopt($ch, CURLOPT_SSLVERSION, 3);

"
4095,4095,6533,Why does hand sanitizer leave your skin feeling cool?,"I noticed, and perhaps many others have too, that the application of hand sanitizer (mainly ethanol), leaves one's hands feeling rather chilly after application. 

What is responsible for this phenomena? Is it the high heat of vaporization of hand sanitizer? However, explanation doesn't hold water; water has a standard heat of vaporization of 40.65 kJ/mol while ethanol has a heat of vaporization of 38.56 kJ/mol. 

Could it be the low boiling point of ethanol? Hand sanitizer disappears (vaporizes) within seconds upon rubbing the hands together. Water, however, does not.

Additionally, how does one square a high heat of vaporization with a low boiling point? If it takes a lot of energy to vaporize something, then how can that something have a low boiling point? 
",Dissenter,https://chemistry.stackexchange.com/users/5084,"Hand sanitizer leaves your hands feeling cool because the particles in the gel which posses the most amount of energy are able to evaporate from the gel and off your hands. This results in only the particles with low energy levels to be left on your hand which therefore reduces the hands overall temperature. 
",lara,https://chemistry.stackexchange.com/users/16567,http://chemistry.stackexchange.com/questions/15885/why-does-hand-sanitizer-leave-your-skin-feeling-cool,SCIENCE,chemistry.stackexchange.com,1.0,0.7777777777777778,0.0,1.0,1.0,1.0,0.6666666666666666,0.8888888888888888,0.3333333333333333,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.5555555555555556,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,0.8888888888888888,Why does hand sanitizer keep your skin cool?,"I noticed, and perhaps many others have too, that the application of hand sanitizer (mainly ethanol), leaves one's hands feeling rather chilly after application. 

What is responsible for this phenomena? Is it the high heat of vaporization of hand sanitizer? However, explanation doesn't hold water; water has a standard heat of vaporization of 40.65 kJ/mol while ethanol has a heat of vaporization of 38.56 kJ/mol. 

Could it be the low boiling point of ethanol? Hand sanitizer disappears (vaporizes) within seconds upon rubbing the hands together. Water, however, does not.

Additionally, how does one square a high heat of vaporization with a low boiling point? If it takes a lot of energy to vaporize something, then how can that something have a low boiling point? 
","Hand sanitizer leaves your hands feeling cool because the particles in the gel which posses the most amount of energy are able to evaporate from the gel and off your hands. This results in only the particles with low energy levels to be left on your hand which therefore reduces the hands overall temperature. 
"
5262,5262,8363,Decoding Matrix Encoded Surround Sound Through Convolution,"I wish to create a finite impulse response filter to decode a dolby digital matrix encoded 2 channel signal into 5 channels. These filters would then be used in a realtime pipeline on a Linux machine using jack and jconvolver to do the convolution.

The equation is as follows:

 

The reference for the above equation is: http://en.wikipedia.org/wiki/Matrix_decoder

It would seem this should be able to be done but I haven't the faintest how. Any help, and in particular working code that could generate the filters (Octave or other open source preferred) would be much appreciated!
",psandersen,https://dsp.stackexchange.com/users/3142,"Jbarlow's answer is excellently derived but misses a major issue: Almost all of the ""better"" surround sound decoders such as Dolby Prologic, DTS Neo 6, Lexicon, Bose Videostage are ""dynmaic"", i.e. they looks constantly at the signal conditions and adjust the decoding matrix in the fly based on an estimate what the original signals may have been.

The main problem here is that the encoder is ""lossy"", i.e. a lot of information is lost during the encoding process and you can't fully recover the original signal. A simple example: let's say you start a ""left"" signal. That encodes to Lt = 1 and Rt = 0. Decoding this again then leads to signal in all five channels and not just in the left like the original condition. The only way around this is to dynamically look at correlation and panning of the input signals and adjust the decoder matrix on the fly.

Finally, while jbarlow's equations are mathematically correct, it's typically not done this way, even if it's only a static decoder. The main issue is that this creates side to side cross talk, i.e. signals that where original in the left front can end up partially in the right front which highly undesirable from a perceptual point of view. What's typically used is roughly something like this (properly normalized that is)

L= Lt, R = Rt;
C = .707*Lt + .707Rt;
Ls = .6*Lt - .3*Rt;
Rs = .6*Rt - 0.3 *Lt;


In practice most people also don't bother with the Hilbert Transformer since most encoders that do a real time downmix (such as Blu ray players, set top boxes, or TVs) don't implement it in anyway.
",Hilmar,https://dsp.stackexchange.com/users/224,http://dsp.stackexchange.com/questions/4743/decoding-matrix-encoded-surround-sound-through-convolution,TECHNOLOGY,dsp.stackexchange.com,0.7777777777777778,0.6666666666666666,0.0,1.0,1.0,1.0,0.5555555555555556,0.5555555555555556,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,1.0,1.0,1.0,0.3333333333333333,0.3333333333333333,1.0,0.7777777777777778,Convolutional matrix coding for surround sound decoding,"I wish to create a finite impulse response filter to decode a dolby digital matrix encoded 2 channel signal into 5 channels. These filters would then be used in a realtime pipeline on a Linux machine using jack and jconvolver to do the convolution.

The equation is as follows:

 

The reference for the above equation is: http://en.wikipedia.org/wiki/Matrix_decoder

It would seem this should be able to be done but I haven't the faintest how. Any help, and in particular working code that could generate the filters (Octave or other open source preferred) would be much appreciated!
","Jbarlow's answer is excellently derived but misses a major issue: Almost all of the ""better"" surround sound decoders such as Dolby Prologic, DTS Neo 6, Lexicon, Bose Videostage are ""dynmaic"", i.e. they looks constantly at the signal conditions and adjust the decoding matrix in the fly based on an estimate what the original signals may have been.

The main problem here is that the encoder is ""lossy"", i.e. a lot of information is lost during the encoding process and you can't fully recover the original signal. A simple example: let's say you start a ""left"" signal. That encodes to Lt = 1 and Rt = 0. Decoding this again then leads to signal in all five channels and not just in the left like the original condition. The only way around this is to dynamically look at correlation and panning of the input signals and adjust the decoder matrix on the fly.

Finally, while jbarlow's equations are mathematically correct, it's typically not done this way, even if it's only a static decoder. The main issue is that this creates side to side cross talk, i.e. signals that where original in the left front can end up partially in the right front which highly undesirable from a perceptual point of view. What's typically used is roughly something like this (properly normalized that is)

L= Lt, R = Rt;
C = .707*Lt + .707Rt;
Ls = .6*Lt - .3*Rt;
Rs = .6*Rt - 0.3 *Lt;


In practice most people also don't bother with the Hilbert Transformer since most encoders that do a real time downmix (such as Blu ray players, set top boxes, or TVs) don't implement it in anyway.
"
379,379,597,PostGIS is rejecting an srid code for my projection. I've found a nearly identical projection w/ a legit srid. Will it work?,"My projection is this: NAD 1983 StatePlane North Carolina FIPS 3200 Feet, which has a proj4 string that looks like this:

+proj=lcc +lat_1=34.33333333333334 +lat_2=36.16666666666666 +lat_0=33.75 +lon_0=-79 +x_0=609601.2199999999 +y_0=0 +ellps=GRS80 +datum=NAD83 +to_meter=0.3048006096012192 +no_defs


Its SRID is 102719. I've tried to create a db column in PostGIS with an srid option for this projection, but its rejecting the srid, calling it invalid.

I've found a similar projection with a valid srid code, NAD83 / North Carolina (ftUS) (srid=2264), which has a proj4 string nearly identical to the above:

+proj=lcc +lat_1=36.16666666666666 +lat_2=34.33333333333334 +lat_0=33.75 +lon_0=-79 +x_0=609601.2192024384 +y_0=0 +ellps=GRS80 +datum=NAD83 +to_meter=0.3048006096012192 +no_defs 


As you can see, the only difference between these two is that the lat_1 and lat_2 degrees are swapped. They even use the same three degrees, only the first two are differently ordered.

Can I use this second projection?

UPDATE: The answer seems to be leaning towards 'yes', I just ran projection-to-projection transformations from a single projection to the NC projection using the ""legitimate"" and ""illegitimate"" proj4's and got similar results down to the 7th decimal place
",boulder_ruby,https://gis.stackexchange.com/users/20514,"You have an ESRI projection (ESRI:102719) however PostGIS (and everyone else but ESRI) are expecting EPSG:2264 (or possibly EPSG:3359 or EPSG:3632). You can use the ESRI one (just be aware that this will not interoperate well with others) - just run the following: 

INSERT into spatial_ref_sys (srid, auth_name, auth_srid, proj4text, srtext) values ( 9102719, 'esri', 102719, '+proj=lcc +lat_1=34.33333333333334 +lat_2=36.16666666666666 +lat_0=33.75 +lon_0=-79 +x_0=609601.2199999999 +y_0=0 +ellps=GRS80 +datum=NAD83 +to_meter=0.3048006096012192 +no_defs ', 'PROJCS[""NAD_1983_StatePlane_North_Carolina_FIPS_3200_Feet"",GEOGCS[""GCS_North_American_1983"",DATUM[""North_American_Datum_1983"",SPHEROID[""GRS_1980"",6378137,298.257222101]],PRIMEM[""Greenwich"",0],UNIT[""Degree"",0.017453292519943295]],PROJECTION[""Lambert_Conformal_Conic_2SP""],PARAMETER[""False_Easting"",2000000.002616666],PARAMETER[""False_Northing"",0],PARAMETER[""Central_Meridian"",-79],PARAMETER[""Standard_Parallel_1"",34.33333333333334],PARAMETER[""Standard_Parallel_2"",36.16666666666666],PARAMETER[""Latitude_Of_Origin"",33.75],UNIT[""Foot_US"",0.30480060960121924],AUTHORITY[""EPSG"",""102719""]]');

",Ian Turton,https://gis.stackexchange.com/users/79,http://gis.stackexchange.com/questions/69864/postgis-is-rejecting-an-srid-code-for-my-projection-ive-found-a-nearly-identic,TECHNOLOGY,gis.stackexchange.com,0.8888888888888888,0.6666666666666666,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8,1.0,0.3333333333333333,0.3333333333333333,0.8888888888888888,PostGIS rejected my projected SRID code. I found an almost identical projection w/a legal SRID. Can it be used?,"My projection is this: NAD 1983 StatePlane North Carolina FIPS 3200 Feet, which has a proj4 string that looks like this:

+proj=lcc +lat_1=34.33333333333334 +lat_2=36.16666666666666 +lat_0=33.75 +lon_0=-79 +x_0=609601.2199999999 +y_0=0 +ellps=GRS80 +datum=NAD83 +to_meter=0.3048006096012192 +no_defs


Its SRID is 102719. I've tried to create a db column in PostGIS with an srid option for this projection, but its rejecting the srid, calling it invalid.

I've found a similar projection with a valid srid code, NAD83 / North Carolina (ftUS) (srid=2264), which has a proj4 string nearly identical to the above:

+proj=lcc +lat_1=36.16666666666666 +lat_2=34.33333333333334 +lat_0=33.75 +lon_0=-79 +x_0=609601.2192024384 +y_0=0 +ellps=GRS80 +datum=NAD83 +to_meter=0.3048006096012192 +no_defs 


As you can see, the only difference between these two is that the lat_1 and lat_2 degrees are swapped. They even use the same three degrees, only the first two are differently ordered.

Can I use this second projection?

UPDATE: The answer seems to be leaning towards 'yes', I just ran projection-to-projection transformations from a single projection to the NC projection using the ""legitimate"" and ""illegitimate"" proj4's and got similar results down to the 7th decimal place
","You have an ESRI projection (ESRI:102719) however PostGIS (and everyone else but ESRI) are expecting EPSG:2264 (or possibly EPSG:3359 or EPSG:3632). You can use the ESRI one (just be aware that this will not interoperate well with others) - just run the following: 

INSERT into spatial_ref_sys (srid, auth_name, auth_srid, proj4text, srtext) values ( 9102719, 'esri', 102719, '+proj=lcc +lat_1=34.33333333333334 +lat_2=36.16666666666666 +lat_0=33.75 +lon_0=-79 +x_0=609601.2199999999 +y_0=0 +ellps=GRS80 +datum=NAD83 +to_meter=0.3048006096012192 +no_defs ', 'PROJCS[""NAD_1983_StatePlane_North_Carolina_FIPS_3200_Feet"",GEOGCS[""GCS_North_American_1983"",DATUM[""North_American_Datum_1983"",SPHEROID[""GRS_1980"",6378137,298.257222101]],PRIMEM[""Greenwich"",0],UNIT[""Degree"",0.017453292519943295]],PROJECTION[""Lambert_Conformal_Conic_2SP""],PARAMETER[""False_Easting"",2000000.002616666],PARAMETER[""False_Northing"",0],PARAMETER[""Central_Meridian"",-79],PARAMETER[""Standard_Parallel_1"",34.33333333333334],PARAMETER[""Standard_Parallel_2"",36.16666666666666],PARAMETER[""Latitude_Of_Origin"",33.75],UNIT[""Foot_US"",0.30480060960121924],AUTHORITY[""EPSG"",""102719""]]');

"
2804,2804,4469,Difficulties with re-using a variable,"here is a part of my code :

class projet(object):

    def nameCouche(self):

        valLissage = float(ui.valLissage.displayText())    
        return (valLissage)         
    valCouche = nameCouche() # asks for a positional argument but 'self' doesnt work   

    def choixTraitement(self):
        ui.okLissage.clicked.connect(p.goLissage)

    def goLissage(self, valCouche):
        if ui.chkboxLissage.isChecked():
            print(valCouche) # result is False
            os.system(r'""C:\Program Files\FME\fme.exe"" D:\Stelios\..... --MAX_NUM_POINTS {0}'.format(valCouche))


So I would like to use valCouche in goLissage method but it doesnt work.
I thought that valCouche would have the argument of valLissage but instead it gives False as a value.
I've tried different alternatives but still doesnt work.
",guy16,https://stackoverflow.com/users/4862605,"You have to declare variabile in the __init__ method (constructor) and then use it in your code

ex:

class projet(object):
    def __init__(self):
        self.valCouche = ''

    def nameCouche(self):
        valLissage = float(ui.valLissage.displayText())     
        return (valLissage)         


    def choixTraitement(self):
        ui.okLissage.clicked.connect(p.goLissage)

    def goLissage(self, valCouche):
        if ui.chkboxLissage.isChecked():
            self.valCouche = self.nameCouche() 
            print(self.valCouche) # result is False
            os.system(r'""C:\Program Files\FME\fme.exe"" D:\Stelios\..... --MAX_NUM_POINTS {0}'.format(self.valCouche))

",Nerkyator,https://stackoverflow.com/users/2475007,http://stackoverflow.com/questions/30344855,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,0.8888888888888888,Difficulty in reusing variables,"here is a part of my code :

class projet(object):

    def nameCouche(self):

        valLissage = float(ui.valLissage.displayText())    
        return (valLissage)         
    valCouche = nameCouche() # asks for a positional argument but 'self' doesnt work   

    def choixTraitement(self):
        ui.okLissage.clicked.connect(p.goLissage)

    def goLissage(self, valCouche):
        if ui.chkboxLissage.isChecked():
            print(valCouche) # result is False
            os.system(r'""C:\Program Files\FME\fme.exe"" D:\Stelios\..... --MAX_NUM_POINTS {0}'.format(valCouche))


So I would like to use valCouche in goLissage method but it doesnt work.
I thought that valCouche would have the argument of valLissage but instead it gives False as a value.
I've tried different alternatives but still doesnt work.
","You have to declare variabile in the __init__ method (constructor) and then use it in your code

ex:

class projet(object):
    def __init__(self):
        self.valCouche = ''

    def nameCouche(self):
        valLissage = float(ui.valLissage.displayText())     
        return (valLissage)         


    def choixTraitement(self):
        ui.okLissage.clicked.connect(p.goLissage)

    def goLissage(self, valCouche):
        if ui.chkboxLissage.isChecked():
            self.valCouche = self.nameCouche() 
            print(self.valCouche) # result is False
            os.system(r'""C:\Program Files\FME\fme.exe"" D:\Stelios\..... --MAX_NUM_POINTS {0}'.format(self.valCouche))

"
2260,2260,3602,Why do I have to explicitly add perl before the script for getops to run properly?,"When i run my script like so: 

C:\>perl script.pl -f file

It works fine. But, if I just do:

C:\>script.pl -f file

then I don't get any errors but getopts doesn't assign anything to $opt_f

This works just fine on perl 5.8 Windows XP, but it doesn't work on perl 5.12 on Windows 7.
There aren't any other versions of perl installed (its a new OS build).

Code:

use Getopt::Std;
our ($opt_f);
getopts('f:');
print ""input file is: $opt_f \n"";
print ""$0\n


Run with:

C:\&gt; perl get.pl -f sadf
input file is: sadf
get.pl


Run without:

C:\&gt;get.pl -f sadf
input file is:


Nothing!

EDIT:  fixed and this question was a repeat...
http://stackoverflow.com/questions/1695188/how-do-i-make-perl-scripts-recognize-parameters-in-the-win32-cmd-console

The OP of that post figured it out.
I had to do the same but also recreate the assoc in the gui (in addition to in the reg and on the command line with ftype.)  
",Alex,https://stackoverflow.com/users/8676,"What are Perl scripts associated with (.pl extension to be precise) on the Windows7 system where the ""script.pl"" call doesn't work?

Also, could you please try running (with and without ""perl "" prefix):

use Data::Dumper;
print Data::Dumper->Dump([$*, $0, $1])
",DVK,https://stackoverflow.com/users/119280,http://stackoverflow.com/questions/4065054/why-do-i-have-to-explicitly-add-perl-before-the-script-for-getops-to-run-properl,STACKOVERFLOW,stackoverflow.com,1.0,0.6666666666666666,0.0,1.0,0.6666666666666666,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.0,1.0,1.0,0.5555555555555556,1.0,1.0,0.7333333333333333,1.0,0.0,0.0,1.0,Why add Perl explicitly before the getops script runs properly?,"When i run my script like so: 

C:\>perl script.pl -f file

It works fine. But, if I just do:

C:\>script.pl -f file

then I don't get any errors but getopts doesn't assign anything to $opt_f

This works just fine on perl 5.8 Windows XP, but it doesn't work on perl 5.12 on Windows 7.
There aren't any other versions of perl installed (its a new OS build).

Code:

use Getopt::Std;
our ($opt_f);
getopts('f:');
print ""input file is: $opt_f \n"";
print ""$0\n


Run with:

C:\&gt; perl get.pl -f sadf
input file is: sadf
get.pl


Run without:

C:\&gt;get.pl -f sadf
input file is:


Nothing!

EDIT:  fixed and this question was a repeat...
http://stackoverflow.com/questions/1695188/how-do-i-make-perl-scripts-recognize-parameters-in-the-win32-cmd-console

The OP of that post figured it out.
I had to do the same but also recreate the assoc in the gui (in addition to in the reg and on the command line with ftype.)  
","What are Perl scripts associated with (.pl extension to be precise) on the Windows7 system where the ""script.pl"" call doesn't work?

Also, could you please try running (with and without ""perl "" prefix):

use Data::Dumper;
print Data::Dumper->Dump([$*, $0, $1])
"
4289,4289,6833,Which Windows 7 to install?,"I have 2GB of RAM on my laptop, which is the max.  

Should I install 32 bit version or 64 bit version?
",AngryHacker,https://superuser.com/users/2805,"The biggest issue you should care about is drivers. 

Do 64bit drivers exist for your laptop? Check that before you do anything, as lot of hardware companies don't have any available. If you can't find Windows 7 drivers, usually the Vista drivers will work.

Ontop of that, if you are using your laptop for heavy-lifting applications that require a lot of memory, then 64bit is better. Though with 2gb of RAM it's barely going to make any difference for you, as 64bit excels because it can support more than the ~3gb limit of 32 bit windows. So the advantage is once you have more than 4gb of ram.

The heavy-lifting applications usually are 3D software: Maya, 3DS Max, or graphics applications such as Photoshop and Gimp. Also gaming on 64bit gives slightly faster framerates, though that's a product of the processor and motherboard not the operating system. Your existing games may not work on 64 bit Windows.

You are also likely to find some installers refuse to install on a 64bit version too, mostly from dumb installers looking at registry keys.

My choice would be stick with 32 bit Windows 7, as a laptop (atleast one that only has 2gb of RAM) is probably not going to be used for any of those applications, or gaming.

If you want another opinion Tomshardware has a few threads on it.
",Chris S,https://superuser.com/users/784,http://superuser.com/questions/17917,TECHNOLOGY,superuser.com,1.0,0.5555555555555556,0.0,1.0,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.5555555555555556,0.0,0.0,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.0,0.3333333333333333,0.0,1.0,1.0,0.8888888888888888,1.0,1.0,1.0,0.3333333333333333,0.0,0.6666666666666666,0.8888888888888888,Which Windows 7 do you want to install?,"I have 2GB of RAM on my laptop, which is the max.  

Should I install 32 bit version or 64 bit version?
","The biggest issue you should care about is drivers. 

Do 64bit drivers exist for your laptop? Check that before you do anything, as lot of hardware companies don't have any available. If you can't find Windows 7 drivers, usually the Vista drivers will work.

Ontop of that, if you are using your laptop for heavy-lifting applications that require a lot of memory, then 64bit is better. Though with 2gb of RAM it's barely going to make any difference for you, as 64bit excels because it can support more than the ~3gb limit of 32 bit windows. So the advantage is once you have more than 4gb of ram.

The heavy-lifting applications usually are 3D software: Maya, 3DS Max, or graphics applications such as Photoshop and Gimp. Also gaming on 64bit gives slightly faster framerates, though that's a product of the processor and motherboard not the operating system. Your existing games may not work on 64 bit Windows.

You are also likely to find some installers refuse to install on a 64bit version too, mostly from dumb installers looking at registry keys.

My choice would be stick with 32 bit Windows 7, as a laptop (atleast one that only has 2gb of RAM) is probably not going to be used for any of those applications, or gaming.

If you want another opinion Tomshardware has a few threads on it.
"
5510,5510,8743,Presentation of Case Sensitive fields in standard layouts,"Say I have a field that contains data that is sensitive to errors like telling the difference between an I and l. That's I and l, which may appear identical depending on the font your browser is using. 0 and O (0 and O) is another common example of characters than can be difficult to distinguish.

If I show this field on a standard page layout users won't be able to easily pick the differences between the characters. The default font-family for a dataCol td is Arial, Helvetica, sans-serif.

How can I change the font-family for this field in a standard layout?

If I was using this field in a Visualforce page in an apex:outputText I could use the style attribute to change the font-family.
",Daniel Ballinger,https://salesforce.stackexchange.com/users/102,"Create an inline VF page for your standard layout which renders the field as per your font requirements. You can make this as small as a standard field on the layout and enable the Label for the VF page to be displayed, thus giving the VF page label the field label, the appearance you get is much the same as the standard layout displaying the field.
",Andrew Fawcett,https://salesforce.stackexchange.com/users/286,http://salesforce.stackexchange.com/questions/13060/presentation-of-case-sensitive-fields-in-standard-layouts,TECHNOLOGY,salesforce.stackexchange.com,0.8888888888888888,0.4444444444444444,0.0,1.0,1.0,1.0,0.5555555555555556,0.5555555555555556,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,0.8888888888888888,Show case sensitive fields in standard layout,"Say I have a field that contains data that is sensitive to errors like telling the difference between an I and l. That's I and l, which may appear identical depending on the font your browser is using. 0 and O (0 and O) is another common example of characters than can be difficult to distinguish.

If I show this field on a standard page layout users won't be able to easily pick the differences between the characters. The default font-family for a dataCol td is Arial, Helvetica, sans-serif.

How can I change the font-family for this field in a standard layout?

If I was using this field in a Visualforce page in an apex:outputText I could use the style attribute to change the font-family.
","Create an inline VF page for the standard layout that renders fields according to font requirements. You can set it to be as small as the standard field on the layout, and allow the label of VF page to be displayed, so that the VF page label has the field label, and you get the appearance basically the same as the standard layout that displays the field."
2591,2591,4121,Are there /ɔ/ and /ʌ/ sounds in informal American English?,"I read a book about American English. It reports that, in standard informal conversations, American English doesn't use the /ɔ/ sound; it uses the /ɑ/ sound and /ʌ/ and /ə/ are not different. Are they really?
That book would not use the /ɔ/ and /ʌ/ sounds, but when I look in my American English Dictionary for some words, such as more, door, and love, they are reported to be pronounced /mɔr/, /dɔr/, and /lʌv/.
How should I pronounce these words, if there are no /ɔ/and /ʌ/ sounds?  Should they be /mɑr/, /dɑr/, and /ləv/?
Can /ɑ/ sound replace /ɔ/, and /ə/ replace /ʌ/ in every word?
What about formal American English? Does it have /ɔ /and /ʌ/ sounds or not?
",Kas,https://english.stackexchange.com/users/10792,"Standard English has all of the sounds you mention, but, yes there are some quirks.

Some dialects of English don't distinguish between /ɔ/ and /ɑ/; this is known as the caught-cot merger.  It is so called because caught and cot are both pronounced the same: (/kɒːt/ or /kɑt/ depending on the region).  As you can see in the Wikipedia article and the accompanying map, some dialects have merged these vowels together, but many have not.

Now, as for /ə/ and /ʌ/ — AmE does have both of these sounds, but in most cases the pattern is totally predictable.  In stressed syllables, /ʌ/ can occur, while in unstressed syllables, only /ə/ is used.  

In Standard British English, there is more use of /ə/, in part because Standard BrE doesn't pronounce /ɹ/ (henceforth /r/) syllable-finally.  So a word like nurse, which in American English would be pronounced /nɝs/ (with an r-colored vowel), can be pronounced /nə:s/ in British English (though it isn't always).

So, with this information in mind, on to your examples:

""More"" and ""door""

Examples with syllable-final /r/ are generally going to be special, as indeed these are.  In Standard AmE, these are pronounced /mɔr/ and /dɔr/, as you read.  In dialects that don't pronounce /ɔ/, the words are pronounced /mor/ and /dor/.  In situations that aren't r-colored, it is indeed /ɑ/ (again, in certain US dialects).

""Love""

Following the rules I laid out above, you may have figured out that love is pronounced /lʌv/ in AmE, as it is a stressed syllable.  But, if it were unstressed, it would theoretically be pronounced with a schwa.  

So, let's take a different example: the word ""just"" /dʒʌst/ is sometimes stressed and sometimes unstressed.  When unstressed (often when saying something like ""just do it already""), the word becomes /dʒəst/.
",Kosmonaut,https://english.stackexchange.com/users/449,http://english.stackexchange.com/questions/33392/are-there-%C9%94-and-%CA%8C-sounds-in-informal-american-english,CULTURE,english.stackexchange.com,1.0,0.7777777777777778,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.7777777777777778,0.6666666666666666,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,1.0,1.0,0.7777777777777778,1.0,1.0,1.0,0.0,0.0,1.0,1.0,Is there / ɔ / and / ʌ / in informal American English?,"I read a book about American English. It reports that, in standard informal conversations, American English doesn't use the /ɔ/ sound; it uses the /ɑ/ sound and /ʌ/ and /ə/ are not different. Are they really?
That book would not use the /ɔ/ and /ʌ/ sounds, but when I look in my American English Dictionary for some words, such as more, door, and love, they are reported to be pronounced /mɔr/, /dɔr/, and /lʌv/.
How should I pronounce these words, if there are no /ɔ/and /ʌ/ sounds?  Should they be /mɑr/, /dɑr/, and /ləv/?
Can /ɑ/ sound replace /ɔ/, and /ə/ replace /ʌ/ in every word?
What about formal American English? Does it have /ɔ /and /ʌ/ sounds or not?
","Standard English has all of the sounds you mention, but, yes there are some quirks.

Some dialects of English don't distinguish between /ɔ/ and /ɑ/; this is known as the caught-cot merger.  It is so called because caught and cot are both pronounced the same: (/kɒːt/ or /kɑt/ depending on the region).  As you can see in the Wikipedia article and the accompanying map, some dialects have merged these vowels together, but many have not.

Now, as for /ə/ and /ʌ/ — AmE does have both of these sounds, but in most cases the pattern is totally predictable.  In stressed syllables, /ʌ/ can occur, while in unstressed syllables, only /ə/ is used.  

In Standard British English, there is more use of /ə/, in part because Standard BrE doesn't pronounce /ɹ/ (henceforth /r/) syllable-finally.  So a word like nurse, which in American English would be pronounced /nɝs/ (with an r-colored vowel), can be pronounced /nə:s/ in British English (though it isn't always).

So, with this information in mind, on to your examples:

""More"" and ""door""

Examples with syllable-final /r/ are generally going to be special, as indeed these are.  In Standard AmE, these are pronounced /mɔr/ and /dɔr/, as you read.  In dialects that don't pronounce /ɔ/, the words are pronounced /mor/ and /dor/.  In situations that aren't r-colored, it is indeed /ɑ/ (again, in certain US dialects).

""Love""

Following the rules I laid out above, you may have figured out that love is pronounced /lʌv/ in AmE, as it is a stressed syllable.  But, if it were unstressed, it would theoretically be pronounced with a schwa.  

So, let's take a different example: the word ""just"" /dʒʌst/ is sometimes stressed and sometimes unstressed.  When unstressed (often when saying something like ""just do it already""), the word becomes /dʒəst/.
"
5469,5469,8686,"What is the feminine equivalent of ""guy""?","Is there a word that is the feminine equivalent of guy? I thought of gal, but I think it is used for a girl, or a young woman. I am looking for a word that can be used to generally mean woman, and similar to guy.
",kiamlaluno,https://ell.stackexchange.com/users/95,"According to the writers of this musical, it’s gal. In more recent times, however, guy seems to have become unisex.
",Barrie England,https://ell.stackexchange.com/users/217,http://ell.stackexchange.com/questions/2513/what-is-the-feminine-equivalent-of-guy,CULTURE,ell.stackexchange.com,1.0,1.0,0.3333333333333333,1.0,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.6666666666666666,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,0.0,0.8888888888888888,"What is a woman's ""man""?","Is there a word as feminine as a man? I think of gal, but I think it's used to describe a girl, or a young woman. I want to find a word that can be used in the general sense of women, and similar to men.","According to the writer of the musical, it's gal. In recent times, however, guy seems to have become neutral."
295,295,475,Is PC2700 ECC backwards compatible with PC2100 ECC?,"Because if it's not, it should be!
I'm trying to get 2 x 1GB PC2700 ECC Registered DDR333 DIMMs (Micron brand) to work in my computer, but it won't POST: the computer starts, fans and hard drive spin up, but the monitors don't power up.


Motherboard: Supermicro X5-DAE, E7505 chipset
CPU: (2) Xeon 2.4 GHz 
BIOS: 1.3b, the latest


Crucial recommends PC2700.  Corsair even recommends PC3200.  So I figured PC2700 would be ok.  Admittedly, the manual (section 2-5) states


  The X5DAE/X5DA8 supports up to 12 GB of ECC registered DDR-266/200 (PC2100/1600) memory.


but manufacturers are usually conservative.

So here's the Q: Is it supposed to work?  Can I prep the BIOS beforehand, change some timings or something, or is this type of thing just a no-go in ECC land?

If you can find an example of others using PC2700 with this board let me know.



Update:  I removed all cards, USB devices, cables and swapped the AGP video card out with a known good PCI just to mix things up.

Computer gives 1 beep on startup, which is normal.  No other beep codes.  Monitor still blank.  I've tried the PC2700 pair in all 3 banks, no change.  My good RAM is 2 x 512MB PC2100 ECC Crucial brand and works in all 3 banks.  I tried putting the PC2100 in bank 1 and PC2700 in bank 2 hoping bank 1 would force everything to PC2100.  Still nothing.  Anything else I miss?



This has been resolved with the vendor as a high density memory incompatibility issue.  Ebay has some literature on it:


  JEDEC standard/guideline specifies
  that 64Mx8 and 32Mx16 devices are to
  be used to construct a 1GB Unbuffered
  module. Any 1GB Unbuffered module
  constructed by using 128Mx4 device
  BREAKS all the JEDEC
  standard/guideline in which is
  supposed to be designed only for
  Registered module. Since JEDEC doesn't
  want the modules to be built that way,
  so the companies who make them (a lot
  are generic and 3rd parties), don't
  put their company label on the
  Unbuffered modules.

",hyperslug,https://superuser.com/users/542,"According to Super Micro's ""Test Memory List"" for the motherboard, PC2700 and PC3200 is supported.


The tested memory for PC2700 is:

ATP Electronics AG64L72T8SQB3C 512MB (Qimonda chips -- Qimonda is out of business)

The tested memory for PC3200 is:

Smart Modular Technologies SM6472DDR2N1-1 512MB (Qimonda chips as well)



When you say the system won't POST, I assume POST code of 00. What POST code are you really getting? If the memory isn't supported then you should get to a POST code in the 20's (28 is a common memory failure POST code). Your motherboard is supposed to try to initialize video and display the POST code on the top line.



Something to check is to make sure the DIMM modules are fully seated.
",hanleyp,https://superuser.com/users/1050,http://superuser.com/questions/53468,TECHNOLOGY,superuser.com,0.3333333333333333,0.6666666666666666,0.0,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.8333333333333334,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.8333333333333334,0.6,0.0,0.0,1.0,1.0,Is pc2700 ECC backward compatible with pc2100 ECC?,"Because if it's not, it should be!
I'm trying to get 2 x 1GB PC2700 ECC Registered DDR333 DIMMs (Micron brand) to work in my computer, but it won't POST: the computer starts, fans and hard drive spin up, but the monitors don't power up.


Motherboard: Supermicro X5-DAE, E7505 chipset
CPU: (2) Xeon 2.4 GHz 
BIOS: 1.3b, the latest


Crucial recommends PC2700.  Corsair even recommends PC3200.  So I figured PC2700 would be ok.  Admittedly, the manual (section 2-5) states


  The X5DAE/X5DA8 supports up to 12 GB of ECC registered DDR-266/200 (PC2100/1600) memory.


but manufacturers are usually conservative.

So here's the Q: Is it supposed to work?  Can I prep the BIOS beforehand, change some timings or something, or is this type of thing just a no-go in ECC land?

If you can find an example of others using PC2700 with this board let me know.



Update:  I removed all cards, USB devices, cables and swapped the AGP video card out with a known good PCI just to mix things up.

Computer gives 1 beep on startup, which is normal.  No other beep codes.  Monitor still blank.  I've tried the PC2700 pair in all 3 banks, no change.  My good RAM is 2 x 512MB PC2100 ECC Crucial brand and works in all 3 banks.  I tried putting the PC2100 in bank 1 and PC2700 in bank 2 hoping bank 1 would force everything to PC2100.  Still nothing.  Anything else I miss?



This has been resolved with the vendor as a high density memory incompatibility issue.  Ebay has some literature on it:


  JEDEC standard/guideline specifies
  that 64Mx8 and 32Mx16 devices are to
  be used to construct a 1GB Unbuffered
  module. Any 1GB Unbuffered module
  constructed by using 128Mx4 device
  BREAKS all the JEDEC
  standard/guideline in which is
  supposed to be designed only for
  Registered module. Since JEDEC doesn't
  want the modules to be built that way,
  so the companies who make them (a lot
  are generic and 3rd parties), don't
  put their company label on the
  Unbuffered modules.

","According to Super Micro's ""Test Memory List"" for the motherboard, PC2700 and PC3200 is supported.


The tested memory for PC2700 is:

ATP Electronics AG64L72T8SQB3C 512MB (Qimonda chips -- Qimonda is out of business)

The tested memory for PC3200 is:

Smart Modular Technologies SM6472DDR2N1-1 512MB (Qimonda chips as well)



When you say the system won't POST, I assume POST code of 00. What POST code are you really getting? If the memory isn't supported then you should get to a POST code in the 20's (28 is a common memory failure POST code). Your motherboard is supposed to try to initialize video and display the POST code on the top line.



Something to check is to make sure the DIMM modules are fully seated.
"
691,691,1089,Lyx itemize returning to last number,"I would like to have the following output:


Text

(a) Text

Text
Text


That is, after a subitem, I want to return to the last number without creating a new one. Is there any way to do this without ERT?
",LuizMMB,https://tex.stackexchange.com/users/41960,"Yes, simply use Ctrl-Enter to break the item text. This is like  insert \\ in LaTeX.

Lyx MWE:     

LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\use_hyperref false
\papersize default
\use_geometry false
\use_amsmath 1
\use_esint 1
\use_mhchem 1
\use_mathdots 1
\cite_engine basic
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Enumerate
Text
\end_layout

\begin_deeper
\begin_layout Enumerate
Text 
\begin_inset Newline newline
\end_inset


\begin_inset Newline newline
\end_inset

Text
\end_layout

\end_deeper
\begin_layout Enumerate
Text
\begin_inset Newline newline
\end_inset


\end_layout

\end_body
\end_document




LaTeX version:   

\documentclass[english]{article}
\usepackage[T1]{fontenc}
\usepackage[latin9]{inputenc}
\usepackage{babel}
\begin{document}
\begin{enumerate}
\item Text

\begin{enumerate}
\item Text \\
\\
Text
\end{enumerate}
\item Text
\end{enumerate}

\end{document}


Edit: If you want the text aligned with the item (a), you are looking for a linguist package as  linguex, but there are no module for LyX (but using ERT boxes are not very intrusive in this case):  

\documentclass{article}
\usepackage{linguex}

\begin{document}

\ex. Text
    \a. Text
\z. Text

\ex. Text 

\end{document}



",Fran,https://tex.stackexchange.com/users/11604,http://tex.stackexchange.com/questions/177214/lyx-itemize-returning-to-last-number,TECHNOLOGY,tex.stackexchange.com,1.0,0.4444444444444444,0.0,0.6666666666666666,0.3333333333333333,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,1.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,0.8888888888888888,Lyx returns to the last number one by one,"I would like to have the following output:


Text

(a) Text

Text
Text


That is, after a subitem, I want to return to the last number without creating a new one. Is there any way to do this without ERT?
","Yes, simply use Ctrl-Enter to break the item text. This is like  insert \\ in LaTeX.

Lyx MWE:     

LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\use_hyperref false
\papersize default
\use_geometry false
\use_amsmath 1
\use_esint 1
\use_mhchem 1
\use_mathdots 1
\cite_engine basic
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Enumerate
Text
\end_layout

\begin_deeper
\begin_layout Enumerate
Text 
\begin_inset Newline newline
\end_inset


\begin_inset Newline newline
\end_inset

Text
\end_layout

\end_deeper
\begin_layout Enumerate
Text
\begin_inset Newline newline
\end_inset


\end_layout

\end_body
\end_document




LaTeX version:   

\documentclass[english]{article}
\usepackage[T1]{fontenc}
\usepackage[latin9]{inputenc}
\usepackage{babel}
\begin{document}
\begin{enumerate}
\item Text

\begin{enumerate}
\item Text \\
\\
Text
\end{enumerate}
\item Text
\end{enumerate}

\end{document}


Edit: If you want the text aligned with the item (a), you are looking for a linguist package as  linguex, but there are no module for LyX (but using ERT boxes are not very intrusive in this case):  

\documentclass{article}
\usepackage{linguex}

\begin{document}

\ex. Text
    \a. Text
\z. Text

\ex. Text 

\end{document}



"
3800,3800,6040,"WLAN roaming on same, or different channel","I've setup a router in my basement, and an access point in my attic floor. They are connected with a patch cable. Both have the same SSID and WPA2 security. Roaming does work. But, what I want to know is, if I need to set them on different channels, or do they need the exact same channel to share. I've read many community forums and manuals, but yet it is not clear what to do because they have different opinions.


Router: Fritz!Box 7270
Accesspoint: Netgear WN604

",JohannesM,https://superuser.com/users/60317,"Your access points are using WDS to bridge the network. It requires you have to have same channel, ssid and encryption settings on both APs.
",micke,https://superuser.com/users/97333,http://superuser.com/questions/345487,TECHNOLOGY,superuser.com,0.8888888888888888,0.5555555555555556,0.0,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.6666666666666666,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.8666666666666666,0.0,0.0,0.6666666666666666,0.7777777777777778,WLAN roaming on the same or different channels,"I installed a router in the basement and an access point in the attic. They are connected by patch cables. Both have the same SSID and WPA2 security. Roaming does work. But what I want to know is if I need to set them up on different channels, or if they need to share exactly the same channel. I've read many community forums and manuals, but I don't know what to do because they have different opinions.","Your access points are using WDS to bridge the network. It requires you have to have same channel, ssid and encryption settings on both APs.
"
3425,3425,5450,Is there added value in having your own presentation layout and using it consistently?,"From the perspective of a Ph.D. student, how much of an added value is it to have your own presentation slides layout, that is used consistently throughout your Ph.D. conference presentations and other talks (and possibly throughout your academic career afterwards)?

Here is one such example from the Computer Science community.

This as as opposed to using existing Beamer templates with LaTeX, or built-in PowerPoint templates, or simply preparing each presentation on its own (without a specific layout).

A couple of axes I can think along:


Creating a signature layout that distinguishes one in their community
Ease of preparation of presentations (especially over time), maybe overcoming constraints with existing templates.


Note that I am not concerned with the question of content, but just design and layout.
",lyes,https://academia.stackexchange.com/users/15902,"Standardising layouts have three advantages:


You can reuse slides across presentation without changing the styling.  
When you create presentations, you don't need to think about styling; the templates are already set up for you.
Creating templates and styling can be delegated to someone with design skills, and everyone else gets to use them.


The first two points are applicable whether you have your own signature style, or you follow a team or corporate style.

The last point is different. In theory, having a corporate style is a really good idea because everyone gets the benefit of using templates created by the design genius in the marketing department.  In practice, corporate templates are almost universally awful.

So, if a corporate template exists, and you are lucky enough to like it, then use that.  There's no point in reinventing the wheel.

If there is no template, or it is dreadful, then create one for yourself and stick to that.  

Either way, you don't want to have to keep deciding on new fonts to use for every presentation that you make.
",Richie Cotton,https://academia.stackexchange.com/users/19549,http://academia.stackexchange.com/questions/25822/is-there-added-value-in-having-your-own-presentation-layout-and-using-it-consist,LIFE_ARTS,academia.stackexchange.com,0.7777777777777778,0.6666666666666666,0.6666666666666666,1.0,0.0,0.0,0.4444444444444444,0.5555555555555556,0.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.8888888888888888,0.7777777777777778,0.6666666666666666,0.8888888888888888,1.0,0.8,0.3333333333333333,0.0,0.3333333333333333,0.7777777777777778,Is there added value in having your own presentation layout and using it consistently?,"From the perspective of a Ph.D. student, how much of an added value is it to have your own presentation slides layout, that is used consistently throughout your Ph.D. conference presentations and other talks (and possibly throughout your academic career afterwards)?

Here is one such example from the Computer Science community.

This as as opposed to using existing Beamer templates with LaTeX, or built-in PowerPoint templates, or simply preparing each presentation on its own (without a specific layout).

A couple of axes I can think along:


Creating a signature layout that distinguishes one in their community
Ease of preparation of presentations (especially over time), maybe overcoming constraints with existing templates.


Note that I am not concerned with the question of content, but just design and layout.
","Standardising layouts have three advantages:


You can reuse slides across presentation without changing the styling.  
When you create presentations, you don't need to think about styling; the templates are already set up for you.
Creating templates and styling can be delegated to someone with design skills, and everyone else gets to use them.


The first two points are applicable whether you have your own signature style, or you follow a team or corporate style.

The last point is different. In theory, having a corporate style is a really good idea because everyone gets the benefit of using templates created by the design genius in the marketing department.  In practice, corporate templates are almost universally awful.

So, if a corporate template exists, and you are lucky enough to like it, then use that.  There's no point in reinventing the wheel.

If there is no template, or it is dreadful, then create one for yourself and stick to that.  

Either way, you don't want to have to keep deciding on new fonts to use for every presentation that you make.
"
2084,2084,3318,How does my app know what private key to use,"I have an app that runs on GlassFish 3.x. It communicates to a remote server over https. In my cacerts file I've added the server certs. In my keystore.jks I added the private key the company running the remote server issued me. This works great on Glassfish 2.x, however on 3.x they remote server keeps complaining that the key I have is invalid.

If I remove the key from the keystore I get the same error. It's as if it's not even loading the key, which has got me wondering how does the app / container know which key I need

My connection code looks like this:

public class SSLSocket {

private static Logger logger = LoggerFactory.getLogger(SSLSocket.class);
private ConnectionProperties connectionProperties;

public TuSSLSocket(ConnectionProperties connectionProperties) {
    this.connectionProperties = connectionProperties;
}

public SSLSocket getSSLSocket() throws Exception{
    SSLSocketFactory factory = (SSLSocketFactory) SSLSocketFactory.getDefault();
    SSLSocket socket = (SSLSocket) factory.createSocket(connectionProperties.getHost(), connectionProperties.getPort());
    socket.setSoTimeout(90000);

    return socket;
}

}


I set the Host and Port accordingly, but no where do I say go look for this alias in the keystore. So... how does the app know what alias to grab?
",Preston,https://stackoverflow.com/users/57907,"There are two ways to accomplish this
The first:

Open the following path from the admin console page.


configuration
your cluster/instance configuration.
jvm settings
jvm options
you will find this line some where in the list of items
-Dcom.sun.enterprise.security.httpsOutboundKeyAlias=s1as


Change the s1as value to the certificate alias you want to use.

The other option is to add a system property to your code
System.setProperty(""com.sun.enterprise.security.httpsOutboundKeyAlias"", ""your certificate alias"");
",darthanakel,https://stackoverflow.com/users/3606506,http://stackoverflow.com/questions/10097708/how-does-my-app-know-what-private-key-to-use,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.6666666666666666,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.7777777777777778,0.8888888888888888,0.5555555555555556,1.0,0.8888888888888888,0.6666666666666667,1.0,0.0,0.0,0.7777777777777778,How does my application know which private key to use,"I have an app that runs on GlassFish 3.x. It communicates to a remote server over https. In my cacerts file I've added the server certs. In my keystore.jks I added the private key the company running the remote server issued me. This works great on Glassfish 2.x, however on 3.x they remote server keeps complaining that the key I have is invalid.

If I remove the key from the keystore I get the same error. It's as if it's not even loading the key, which has got me wondering how does the app / container know which key I need

My connection code looks like this:

public class SSLSocket {

private static Logger logger = LoggerFactory.getLogger(SSLSocket.class);
private ConnectionProperties connectionProperties;

public TuSSLSocket(ConnectionProperties connectionProperties) {
    this.connectionProperties = connectionProperties;
}

public SSLSocket getSSLSocket() throws Exception{
    SSLSocketFactory factory = (SSLSocketFactory) SSLSocketFactory.getDefault();
    SSLSocket socket = (SSLSocket) factory.createSocket(connectionProperties.getHost(), connectionProperties.getPort());
    socket.setSoTimeout(90000);

    return socket;
}

}


I set the Host and Port accordingly, but no where do I say go look for this alias in the keystore. So... how does the app know what alias to grab?
","There are two ways to accomplish this
The first:

Open the following path from the admin console page.


configuration
your cluster/instance configuration.
jvm settings
jvm options
you will find this line some where in the list of items
-Dcom.sun.enterprise.security.httpsOutboundKeyAlias=s1as


Change the s1as value to the certificate alias you want to use.

The other option is to add a system property to your code
System.setProperty(""com.sun.enterprise.security.httpsOutboundKeyAlias"", ""your certificate alias"");
"
2438,2438,3890,Is there added value in having your own presentation layout and using it consistently?,"From the perspective of a Ph.D. student, how much of an added value is it to have your own presentation slides layout, that is used consistently throughout your Ph.D. conference presentations and other talks (and possibly throughout your academic career afterwards)?

Here is one such example from the Computer Science community.

This as as opposed to using existing Beamer templates with LaTeX, or built-in PowerPoint templates, or simply preparing each presentation on its own (without a specific layout).

A couple of axes I can think along:


Creating a signature layout that distinguishes one in their community
Ease of preparation of presentations (especially over time), maybe overcoming constraints with existing templates.


Note that I am not concerned with the question of content, but just design and layout.
",lyes,https://academia.stackexchange.com/users/15902,"I see pros and cons; which ends up winning out depends on your skill mix.

First - designing a good layout takes effort and expertise. Graphics designers study many years to get good at it. Just because tools are provided to make it easy doesn't mean everyone is suddenly a graphical designer. The right blend of colors, fonts, space etc is not an easy thing to achieve. 99% of ""I can do better"" layouts look horrid.

Having said that, I have at times come across layouts that made me go ""wow"". This is where the layout really supported the flow of the presentation, and while I was not getting distracted by the details, I came away more impressed. This was mostly because the presentation itself was very good - the contents were impressive, the speaker was very clear, and the layout of the presentation supported the spoken words.

In those cases, the personal layout was the icing on the cake - not a substitute for good work. There is a lot you can do to improve your presentation without spending any time on the layout. Fiddling with layouts (like fiddling with LaTex) can become an easy distraction from the real issues with your presentation. I urge you to consider whether your interest in the ""look"" is coming at the right time: in other words, is every other aspect of your presentation skills (content, pacing, connecting with the audience) so good that layout is the only thing left to play with?

If the answer is ""yes"", then my answer to your question is ""yes"". Otherwise, I think it's a bit early to work on creating your brand through a custom layout. Many people in the scientific community - especially at the PhD level - could do with honing their presentation skills. They could learn not to confuse slides with notes. They could learn to connect with their audience. They could learn to speak at an appropriate pace, and project their voice. They could learn to focus on the essentials and not bombard the audience with details. They could learn to use slides as visual aids - not ""the main course"" of the presentation. 

While I don't know you or your skills, I would say that I have statistics (based on 25+ years of empirical evidence) on my side when I answer ""probably not"" to your original title question.
",Floris,https://academia.stackexchange.com/users/15062,http://academia.stackexchange.com/questions/25822/is-there-added-value-in-having-your-own-presentation-layout-and-using-it-consist,LIFE_ARTS,academia.stackexchange.com,0.8888888888888888,0.8888888888888888,1.0,0.3333333333333333,0.0,0.0,0.6666666666666666,0.7777777777777778,0.0,0.0,1.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.8888888888888888,1.0,0.7777777777777778,1.0,1.0,0.8666666666666666,0.0,0.0,1.0,1.0,Is there added value in having your own presentation layout and using it consistently?,"From the perspective of a Ph.D. student, how much of an added value is it to have your own presentation slides layout, that is used consistently throughout your Ph.D. conference presentations and other talks (and possibly throughout your academic career afterwards)?

Here is one such example from the Computer Science community.

This as as opposed to using existing Beamer templates with LaTeX, or built-in PowerPoint templates, or simply preparing each presentation on its own (without a specific layout).

A couple of axes I can think along:


Creating a signature layout that distinguishes one in their community
Ease of preparation of presentations (especially over time), maybe overcoming constraints with existing templates.


Note that I am not concerned with the question of content, but just design and layout.
","I see pros and cons; which ends up winning out depends on your skill mix.

First - designing a good layout takes effort and expertise. Graphics designers study many years to get good at it. Just because tools are provided to make it easy doesn't mean everyone is suddenly a graphical designer. The right blend of colors, fonts, space etc is not an easy thing to achieve. 99% of ""I can do better"" layouts look horrid.

Having said that, I have at times come across layouts that made me go ""wow"". This is where the layout really supported the flow of the presentation, and while I was not getting distracted by the details, I came away more impressed. This was mostly because the presentation itself was very good - the contents were impressive, the speaker was very clear, and the layout of the presentation supported the spoken words.

In those cases, the personal layout was the icing on the cake - not a substitute for good work. There is a lot you can do to improve your presentation without spending any time on the layout. Fiddling with layouts (like fiddling with LaTex) can become an easy distraction from the real issues with your presentation. I urge you to consider whether your interest in the ""look"" is coming at the right time: in other words, is every other aspect of your presentation skills (content, pacing, connecting with the audience) so good that layout is the only thing left to play with?

If the answer is ""yes"", then my answer to your question is ""yes"". Otherwise, I think it's a bit early to work on creating your brand through a custom layout. Many people in the scientific community - especially at the PhD level - could do with honing their presentation skills. They could learn not to confuse slides with notes. They could learn to connect with their audience. They could learn to speak at an appropriate pace, and project their voice. They could learn to focus on the essentials and not bombard the audience with details. They could learn to use slides as visual aids - not ""the main course"" of the presentation. 

While I don't know you or your skills, I would say that I have statistics (based on 25+ years of empirical evidence) on my side when I answer ""probably not"" to your original title question.
"
5706,5706,9044,Firefox 4 Downgrades to Firefox 3.6 on Windows 7,"On my Windows 7 x64 computer, Firefox 4 has seamlessly downgraded itself to Firefox 3.6 twice.  I haven't determined exactly when this is occurring, but the second time was when restarting after adding GreaseMonkey.  It is possible the first time was also after adding an add-on.  

Re-upgrading to 4.0 seems to work perfectly.

How can I stop this from happening again?
",C. Ross,https://superuser.com/users/856,"When I went to look at uninstalling I noticed that I had Firefox 3 Beta 5 still installed.  I have uninstalled it, and expect it will solve my problems.
",C. Ross,https://superuser.com/users/856,http://superuser.com/questions/286444,TECHNOLOGY,superuser.com,0.7777777777777778,0.4444444444444444,0.0,1.0,0.6666666666666666,1.0,0.7777777777777778,0.5555555555555556,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,0.8888888888888888,"On Windows 7, Firefox 4 is downgraded to Firefox 3.6","On my windows 7 X64 computer, Firefox 4 has seamlessly downgraded itself to Firefox 3.6 twice. I'm not sure when this happened, but the second time it was rebooted after adding Greasemonkey. It's possible that for the first time, it's also after adding add ons.","When I went to see the uninstall, I noticed that I still had Firefox 3 beta 5 installed. I've uninstalled it and hope it solves my problem."
2090,2090,3328,c# - how to validate sharepoint list column against ValidationFormula programmatically,"I need to validate a string that user submit against SPField.ValidationFormula while adding new record to custom list in c#.

Line to add new record is 

SPListItem item = mylist.Items.Add();

I have formula in

column.ValidationFormula

and my string to validate is in this variable

mystringtovalidate

How can I validate mystringtovalidate against column.ValidationFormula then if is valid I'll do item.Update();
",Ergec,https://sharepoint.stackexchange.com/users/17816,"You can use following pattern

try {
    item.Update();
}
catch(SPListDataValidationException ex) {
    //ex.Message
}


https://msdn.microsoft.com/en-us/library/microsoft.sharepoint.splistdatavalidationexception_members(v=office.14).aspx
",Amal Hashim,https://sharepoint.stackexchange.com/users/34350,http://sharepoint.stackexchange.com/questions/129941/c-how-to-validate-sharepoint-list-column-against-validationformula-programmat,TECHNOLOGY,sharepoint.stackexchange.com,1.0,0.6666666666666666,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.8888888888888888,1.0,0.7777777777777778,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,1.0,How to programmatically verify the SharePoint list column according to the validationformula,"I need to validate a string that user submit against SPField.ValidationFormula while adding new record to custom list in c#.

Line to add new record is 

SPListItem item = mylist.Items.Add();

I have formula in

column.ValidationFormula

and my string to validate is in this variable

mystringtovalidate

How can I validate mystringtovalidate against column.ValidationFormula then if is valid I'll do item.Update();
","You can use following pattern

try {
    item.Update();
}
catch(SPListDataValidationException ex) {
    //ex.Message
}


https://msdn.microsoft.com/en-us/library/microsoft.sharepoint.splistdatavalidationexception_members(v=office.14).aspx
"
5328,5328,8467,"Which words may start with ""al-""?","Is there a rule which determines whether it allowable for a word to be ""merged"" with ""all"" to make a new word starting ""al-""

e.g.


  1)All together -> Altogether
  
  2)All right -> Alright


The first is generally accepted. Whereas I believe the second is technically not (certainly my English teacher used to condemn it).
",Urbycoz,https://english.stackexchange.com/users/7451,"I'll quote what my NOAD says:


  USAGE - The merging of all and right to form the one-word spelling alright is first recorded toward the end of the 19th century (unlike other similar merged spellings such as altogether and already, which date from much earlier). There is no logical reason for insisting that all right be two words when other single-word forms such as altogether have long been accepted. Nevertheless, although found widely, alright remains nonstandard.


So, although alright is ""older"", altogether is considered to be standard.

Plus, as the OALD states, altogether and all together are not synonyms:


  Altogether and all together do not mean the same thing. 
  
  
  Altogether means ‘in total’ or (in British English) ‘completely’: We have invited fifty people altogether. ◇ I am not altogether convinced by this argument.
  All together means ‘all in one place’ or ‘all at once’: Can you put your books all together in this box? ◇ Let’s sing ‘Happy Birthday’. All together now!
  


And, as @Matt Ellen reminded me (us), not even all right and alright are synonyms, see his comment.

Other terms are already, as mentioned above, and about the al- prefix, the Oxford English Dictionary, says:


  obs. form of all, retained in comp. in albeit, almighty, almost, alone, already, although, always.

",Alenanno,https://english.stackexchange.com/users/6550,http://english.stackexchange.com/questions/23936/which-words-may-start-with-al,CULTURE,english.stackexchange.com,1.0,0.5555555555555556,0.0,0.3333333333333333,1.0,1.0,0.8888888888888888,1.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.6666666666666666,1.0,1.0,"Which words can start with ""Al -?""?","Is there a rule which determines whether it allowable for a word to be ""merged"" with ""all"" to make a new word starting ""al-""

e.g.


  1)All together -> Altogether
  
  2)All right -> Alright


The first is generally accepted. Whereas I believe the second is technically not (certainly my English teacher used to condemn it).
","I'll quote what my NOAD says:


  USAGE - The merging of all and right to form the one-word spelling alright is first recorded toward the end of the 19th century (unlike other similar merged spellings such as altogether and already, which date from much earlier). There is no logical reason for insisting that all right be two words when other single-word forms such as altogether have long been accepted. Nevertheless, although found widely, alright remains nonstandard.


So, although alright is ""older"", altogether is considered to be standard.

Plus, as the OALD states, altogether and all together are not synonyms:


  Altogether and all together do not mean the same thing. 
  
  
  Altogether means ‘in total’ or (in British English) ‘completely’: We have invited fifty people altogether. ◇ I am not altogether convinced by this argument.
  All together means ‘all in one place’ or ‘all at once’: Can you put your books all together in this box? ◇ Let’s sing ‘Happy Birthday’. All together now!
  


And, as @Matt Ellen reminded me (us), not even all right and alright are synonyms, see his comment.

Other terms are already, as mentioned above, and about the al- prefix, the Oxford English Dictionary, says:


  obs. form of all, retained in comp. in albeit, almighty, almost, alone, already, although, always.

"
4639,4639,7358,"Is there a difference between ""brainstorming"" and ""mindstorming""?","Some people use brainstorming, others use mindstorming. I could not find the difference between the two words. 
",Rami Al-Muhtaseb,https://english.stackexchange.com/users/24218,"Mindstorming doesn't appear in the most common dictionaries.

Aside from the fact that mindstorming is uncommon to the point of invisibility, its meaning is fairly clear, especially in the context of brainstorming. But the difference is that it's never used, or as good as never used.

Consequently, if you have a choice, use brainstorming.
",Andrew Leach,https://english.stackexchange.com/users/18696,http://english.stackexchange.com/questions/93575/is-there-a-difference-between-brainstorming-and-mindstorming,CULTURE,english.stackexchange.com,1.0,1.0,0.0,0.3333333333333333,1.0,1.0,0.5555555555555556,0.6666666666666666,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,0.6666666666666666,1.0,"Is there any difference between ""brainstorming"" and ""brainstorming""?","Some people use brainstorming, some people use brainstorming. I can't find the difference between the two words.","Mindstorming doesn't appear in the most common dictionaries.

Aside from the fact that mindstorming is uncommon to the point of invisibility, its meaning is fairly clear, especially in the context of brainstorming. But the difference is that it's never used, or as good as never used.

Consequently, if you have a choice, use brainstorming.
"
4587,4587,7269,Server 2008 DNS forwarders,"I am trying to add a static DNS forward under DNS in Windows Server 2008 R2 however I can't figure it out.

Under Server 2003 you simply add an DNS domain name with it's forwarder IP list.

However under Server 2008 you only seem to be able to add IP addresses. The IP's I enter will not resolve/validate, plus it doesn't appear to allow you to enter a matching DNS domain name.

Can someone please help?
",Ash,https://serverfault.com/users/97034,"You are trying to set up a ""conditional forwarder"" - a feature which has been moved to a different place in the MMC snapin GUI. It has an own node within the DNS server tree at the same level as the forward and reverse lookup zones now:



(Screenshot from http://alicain.blogspot.de/2008/09/windows-2008-conditional-forwarding.html)
",the-wabbit,https://serverfault.com/users/76595,http://serverfault.com/questions/388863,TECHNOLOGY,serverfault.com,1.0,0.4444444444444444,0.0,1.0,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,0.8888888888888888,0.8888888888888888,1.0,1.0,0.0,1.0,0.8888888888888888,Server 2008 DNS forwarder,"I am trying to add a static DNS forward under DNS in Windows Server 2008 R2 however I can't figure it out.

Under Server 2003 you simply add an DNS domain name with it's forwarder IP list.

However under Server 2008 you only seem to be able to add IP addresses. The IP's I enter will not resolve/validate, plus it doesn't appear to allow you to enter a matching DNS domain name.

Can someone please help?
",You are trying to set up a conditional forwarder - a feature that has been moved to another location in the MMC snap in GUI. It has its own nodes in the DNS server tree at the same level as forward and reverse lookup zones:
4796,4796,7618,"Bash reserved words vs. built-in commands, and formatting the output of the time command","What's the difference between bash reserved words and built-in commands?

Can I disable bash's time, and use /usr/bin/time? If not, how can I format its output?
",TheoYou,https://superuser.com/users/46465,"You can use builtin &lt;cmd&gt; and command &lt;cmd&gt; to force calling a bash built-in or an external command.
",grawity,https://superuser.com/users/1686,http://superuser.com/questions/301090,TECHNOLOGY,superuser.com,1.0,0.3333333333333333,0.0,0.0,1.0,0.0,0.6666666666666666,0.8333333333333334,1.0,0.0,0.0,0.0,0.5,0.0,1.0,0.0,1.0,0.0,0.0,0.0,1.0,1.0,0.3333333333333333,1.0,0.6666666666666666,0.5,1.0,0.0,0.0,0.8333333333333334,"Bash preserves words and built-in commands, and formats the output of the time command","What's the difference between bash reserved words and built-in commands?

Can I disable bash's time, and use /usr/bin/time? If not, how can I format its output?
",You can use built-in commands & lt; CMD & gt; and commands & lt; CMD & gt; to force calls to bash built-in or external commands.
476,476,741,Is this a bug? Angular removes object params when corresponding input is not valid,"Please see this:

http://plnkr.co/edit/soubKCayeLAqgDOel8AL?p=preview

&lt;!DOCTYPE html&gt;
&lt;html ng-app=""testApp""&gt;
  &lt;head&gt;
    &lt;script data-require=""angular.js@1.4.1"" data-semver=""1.4.1"" src=""https://code.angularjs.org/1.4.1/angular.js""&gt;&lt;/script&gt;
    &lt;script src=""script.js""&gt;&lt;/script&gt;
  &lt;/head&gt;
  &lt;body ng-controller=""testCtlr""&gt;
    &lt;pre&gt;{{contacts | json}}&lt;/pre&gt;
    &lt;div ng-repeat=""contact in contacts""&gt;
      &lt;div ng-repeat=""email in contact.emails""&gt;
        &lt;input type=""email"" name=""email"" ng-model=""email.email""&gt;
        &lt;input type=""text"" name=""text"" ng-model=""email.text""&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/body&gt;
&lt;/html&gt;


var app = angular.module('testApp', []);
app.controller('testCtlr', [""$scope"", function ($scope) {
    $scope.contacts = [
        {
            id:'',
            name:'',
            emails:[
                {
                    email: 'e1',
                    text: 'fghfgh'
                },
                {
                    email: 'e2',
                    text: 'hjkhjk'
                }
            ],
        }
    ];
}]);


you see if you change the text in the email text box it is removed from the obj unless it is a valid email...
",user1804318,https://stackoverflow.com/users/1804318,"It is not a bug, this is by design. The input type email uses regex to validate email address inputs. If the input is not valid it is removed from the model. 

On another note - if you wrap your stuff in a form - you can determine the validation state of the inputs. Also, as you are using a repeat, you will need an index. 

Here is an example of what I mean:

&lt;form name=""myForm""&gt;
    &lt;div ng-repeat=""contact in contacts""&gt;
      &lt;div ng-repeat=""email in contact.emails track by $index""&gt;
        &lt;div ng-show=""myForm.email{{$index}}.$invalid""&gt;Invalid email.&lt;/div&gt;
        &lt;input type=""email"" name=""email{{$index}}"" ng-model=""email.email""&gt;
        &lt;input type=""text"" name=""text"" ng-model=""email.text""&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/form&gt;


I have updated your Plunker here.

These are the validation states you can use:

//[formName].[inputFieldName].property 
myForm.email1.$pristine;
// Boolean. True if the user has not yet modified the form.
myForm.email1.$dirty
// Boolean. True if the user has already modified the form.
myForm.email1.$valid
// Boolean.True if the the form passes the validation.
myForm.email1.$invalid
// Boolean. True if the the form doesn't pass the validation.
myForm.email1.$error

",Donal,https://stackoverflow.com/users/379855,http://stackoverflow.com/questions/31062344/is-this-a-bug-angular-removes-object-params-when-corresponding-input-is-not-val,STACKOVERFLOW,stackoverflow.com,0.4444444444444444,0.3333333333333333,0.0,1.0,1.0,1.0,0.6666666666666666,0.4444444444444444,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,1.0,0.0,0.6666666666666666,1.0,0.7777777777777778,1.0,1.0,0.9333333333333332,0.3333333333333333,0.0,1.0,0.8888888888888888,"Is this a bug? When the corresponding input is invalid, angular deletes the object parameter","Please see this:

http://plnkr.co/edit/soubKCayeLAqgDOel8AL?p=preview

&lt;!DOCTYPE html&gt;
&lt;html ng-app=""testApp""&gt;
  &lt;head&gt;
    &lt;script data-require=""angular.js@1.4.1"" data-semver=""1.4.1"" src=""https://code.angularjs.org/1.4.1/angular.js""&gt;&lt;/script&gt;
    &lt;script src=""script.js""&gt;&lt;/script&gt;
  &lt;/head&gt;
  &lt;body ng-controller=""testCtlr""&gt;
    &lt;pre&gt;{{contacts | json}}&lt;/pre&gt;
    &lt;div ng-repeat=""contact in contacts""&gt;
      &lt;div ng-repeat=""email in contact.emails""&gt;
        &lt;input type=""email"" name=""email"" ng-model=""email.email""&gt;
        &lt;input type=""text"" name=""text"" ng-model=""email.text""&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/body&gt;
&lt;/html&gt;


var app = angular.module('testApp', []);
app.controller('testCtlr', [""$scope"", function ($scope) {
    $scope.contacts = [
        {
            id:'',
            name:'',
            emails:[
                {
                    email: 'e1',
                    text: 'fghfgh'
                },
                {
                    email: 'e2',
                    text: 'hjkhjk'
                }
            ],
        }
    ];
}]);


you see if you change the text in the email text box it is removed from the obj unless it is a valid email...
","It is not a bug, this is by design. The input type email uses regex to validate email address inputs. If the input is not valid it is removed from the model. 

On another note - if you wrap your stuff in a form - you can determine the validation state of the inputs. Also, as you are using a repeat, you will need an index. 

Here is an example of what I mean:

&lt;form name=""myForm""&gt;
    &lt;div ng-repeat=""contact in contacts""&gt;
      &lt;div ng-repeat=""email in contact.emails track by $index""&gt;
        &lt;div ng-show=""myForm.email{{$index}}.$invalid""&gt;Invalid email.&lt;/div&gt;
        &lt;input type=""email"" name=""email{{$index}}"" ng-model=""email.email""&gt;
        &lt;input type=""text"" name=""text"" ng-model=""email.text""&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/form&gt;


I have updated your Plunker here.

These are the validation states you can use:

//[formName].[inputFieldName].property 
myForm.email1.$pristine;
// Boolean. True if the user has not yet modified the form.
myForm.email1.$dirty
// Boolean. True if the user has already modified the form.
myForm.email1.$valid
// Boolean.True if the the form passes the validation.
myForm.email1.$invalid
// Boolean. True if the the form doesn't pass the validation.
myForm.email1.$error

"
3434,3434,5460,how to pass value from visual force page (InputField) to controller?,"I have created a Vf page from which i need to fetch the value of new owner and need to save the value in property defined in controller:

Following is my vf page code:

&lt;apex:pageBlockSection&gt;
    &lt;apex:InputField label=""user"" value=""{!a.ownerid}""/&gt;
&lt;/apex:pageBlockSection&gt;


here a is object of opportunity

Controller code:

used one property to store the value:

public string ownername {get;set;}


Note: user will input the value through lookup field.

Any suggestions on this?
",jack,https://salesforce.stackexchange.com/users/8706,"When you submit the page, Visualforce will update the OwnerId field of your opportunity object a automatically for you. If you want to use that value elsewhere (e.g. in a save method), you can just reference the value directly:

Id newApproverId = a.OwnerId;
...


and you can query for the corresponding name (if you need that):

String newApproverName = [select Name from User where Id = :a.OwnerId].Name;
...

",Keith C,https://salesforce.stackexchange.com/users/887,http://salesforce.stackexchange.com/questions/38651/how-to-pass-value-from-visual-force-page-inputfield-to-controller,TECHNOLOGY,salesforce.stackexchange.com,1.0,0.7777777777777778,0.0,0.6666666666666666,0.3333333333333333,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,0.8888888888888888,How do I pass values from the visual force page (inputfield) to the controller?,"I have created a Vf page from which i need to fetch the value of new owner and need to save the value in property defined in controller:

Following is my vf page code:

&lt;apex:pageBlockSection&gt;
    &lt;apex:InputField label=""user"" value=""{!a.ownerid}""/&gt;
&lt;/apex:pageBlockSection&gt;


here a is object of opportunity

Controller code:

used one property to store the value:

public string ownername {get;set;}


Note: user will input the value through lookup field.

Any suggestions on this?
","When you submit the page, Visualforce will update the OwnerId field of your opportunity object a automatically for you. If you want to use that value elsewhere (e.g. in a save method), you can just reference the value directly:

Id newApproverId = a.OwnerId;
...


and you can query for the corresponding name (if you need that):

String newApproverName = [select Name from User where Id = :a.OwnerId].Name;
...

"
3781,3781,6015,Is it safe to eat freshwater fish raw?,"According to this question freshwater fish should not be used in Ceviche--why not?
",Jay,https://cooking.stackexchange.com/users/2299,"To reduce the mercury issue with freshwater fish trim away the belly meat because that is where the majority of mercury settles. Also, most areas will have pollution warning for specific fisheries.
",Bob Murray,https://cooking.stackexchange.com/users/36665,http://cooking.stackexchange.com/questions/7268/is-it-safe-to-eat-freshwater-fish-raw,LIFE_ARTS,cooking.stackexchange.com,0.8888888888888888,0.4444444444444444,0.0,1.0,1.0,1.0,0.7777777777777778,0.7777777777777778,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.8888888888888888,0.7777777777777778,0.3333333333333333,1.0,0.6666666666666666,0.4666666666666667,1.0,0.0,0.0,0.8888888888888888,Is it safe to eat fresh water fish raw?,"According to this question, freshwater fish should not be used in the womb - why not?","To reduce the mercury issue with freshwater fish trim away the belly meat because that is where the majority of mercury settles. Also, most areas will have pollution warning for specific fisheries.
"
2688,2688,4289,How can adversarial game mechanics be added to a game?,"Some systems have the concept of an adversarial relationship between the game master and the players. These games typically have a series of mechanics to enforce this behavior and prevent one side from becoming too powerful and running away with the game - essentially accentuating the ""game"" aspect of a RPG. What mechanics of this nature  are most likely to be easily adapted into another role-playing game?

To illustrate what I'm talking about, in D&amp;D, there are guidelines for encounter creation to create balanced encounters. How could we change this to add hard game mechanics that would enforce fairness in encounter design? As an addenda, it would also be nice to see what games these mechanics come from and how easy they are to extract from the system they were built for.
",rjstreet,https://rpg.stackexchange.com/users/545,"In Rune, Robin Laws' Viking RPG, the GM has to create all challenges via a very strict budgeting system as players earn Victory Points with the goal of ""winning"" the game. This allows for adversarial play within tightly defined bounds.  Unfortunately, it also means it's a colossal pain to create adventures for as a GM - I'm a big Laws fan and bought Rune sight unseen on the heels of Feng Shui but then it just sat on my shelf, as my desire to be a Norse accountant is extremely low.

This is similar to the direction D&amp;D has taken in 3e and 4e with set rules for encounter CR and now in 4e with set treasure parcels. Although in my opinion that's less fostering GM vs players as it is attempting to remove the GM or at best make them the engine under the hood.

Paranoia is a good game where the gamemaster is encouraged to ""hose"" the players.  This is mitigated by a) them having six clones, so an arbitrary death isn't the worst thing in the world and b) it being a humor game, so effectively you win by the GM stomping you out in entertaining ways. This is before everyone was obsessed with ""mechanical rewards"" for the point of the game, though, so it's not like you get extra ""points"" of some sort when it happens. But people have played it and had fun for many years.

In Mutants &amp; Masterminds they had Hero Points and when they'd spend them the villains would get Villain Points.  This went over very poorly with my group - rightly or wrongly, they felt like people besides themselves having resource driven plot immunity sucked.
",mxyzplk,https://rpg.stackexchange.com/users/140,http://rpg.stackexchange.com/questions/13073/how-can-adversarial-game-mechanics-be-added-to-a-game,CULTURE,rpg.stackexchange.com,1.0,1.0,0.0,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,1.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,1.0,0.8,1.0,0.0,1.0,1.0,How to add Antagonistic Game mechanism to the game?,"Some systems have the concept of an adversarial relationship between the game master and the players. These games typically have a series of mechanics to enforce this behavior and prevent one side from becoming too powerful and running away with the game - essentially accentuating the ""game"" aspect of a RPG. What mechanics of this nature  are most likely to be easily adapted into another role-playing game?

To illustrate what I'm talking about, in D&amp;D, there are guidelines for encounter creation to create balanced encounters. How could we change this to add hard game mechanics that would enforce fairness in encounter design? As an addenda, it would also be nice to see what games these mechanics come from and how easy they are to extract from the system they were built for.
","In Rune, Robin Laws' Viking RPG, the GM has to create all challenges via a very strict budgeting system as players earn Victory Points with the goal of ""winning"" the game. This allows for adversarial play within tightly defined bounds.  Unfortunately, it also means it's a colossal pain to create adventures for as a GM - I'm a big Laws fan and bought Rune sight unseen on the heels of Feng Shui but then it just sat on my shelf, as my desire to be a Norse accountant is extremely low.

This is similar to the direction D&amp;D has taken in 3e and 4e with set rules for encounter CR and now in 4e with set treasure parcels. Although in my opinion that's less fostering GM vs players as it is attempting to remove the GM or at best make them the engine under the hood.

Paranoia is a good game where the gamemaster is encouraged to ""hose"" the players.  This is mitigated by a) them having six clones, so an arbitrary death isn't the worst thing in the world and b) it being a humor game, so effectively you win by the GM stomping you out in entertaining ways. This is before everyone was obsessed with ""mechanical rewards"" for the point of the game, though, so it's not like you get extra ""points"" of some sort when it happens. But people have played it and had fun for many years.

In Mutants &amp; Masterminds they had Hero Points and when they'd spend them the villains would get Villain Points.  This went over very poorly with my group - rightly or wrongly, they felt like people besides themselves having resource driven plot immunity sucked.
"
2259,2259,3601,How to fix a Macbook Pro trackpad where the mouse pointer is randomly moving?,"The trackpad on my Macbook Pro just started acting oddly. It's randomly clicking (which might cause me to switch programs), right-clicking and even once my screen even showed the swiping animation as if I was trying to switch to a different desktop.    

Part of me fears that this is some sort of joke hacking attempt (I know of a USB device you plug into someones computer and it randomly moves their mouse and types on their keyboard), but there is nothing plugged into my machine and I just turned off the Wi-Fi and watched as this web page tried to close, the mouse right clicked twice, highlighted a word and clicked ""Paste and Match Style"" in the Chrome right-click menu.
Also as I've been typing (with my Wi-Fi turned off) the mouse has randomly been clicking inside this question and changing where I am typing.  

I just plugged in a USB mouse which seems to work fine but the trackpad is now nearly useless. I can't even move the mouse cursor more than a few centimeters with it.

Is this a common issue?
EDIT
I think it is dying actually. I can now click but not move at all with the trackpad, while a regular mouse works fine.
EDIT 2
And now it seems to be working again. I turned on the option for ""Ignore Trackpad when Mouse is plugged in"" under Universal Access. I cleaned the trackpad with rubbing alcohol, I whined and complained for a few minutes to my dog, turned off the ""Ignore Trackpad"" setting, unplugged the USB mouse, and the Trackpad appears to be working mostly normally.
If I run my finger across it at the top or bottom portion of the mouse, it works, but there is a line horizontally across it (almost exactly where a physical trackpad button would end on the old trackpads) that is ""dead"".  The mouse stops moving, or moves sluggishly when hitting that spot and that ""spot"" goes across the whole trackpad.
",James P. Wright,https://apple.stackexchange.com/users/4049,"I've heard dust and dirt inside the MB/MBP can cause the trackpad to act very weird. I'm having issues with my mouse now and am thinking of taking apart my MBP and blowing it out with a compressor.
",Big Paul,https://apple.stackexchange.com/users/40313,http://apple.stackexchange.com/questions/62146/how-to-fix-a-macbook-pro-trackpad-where-the-mouse-pointer-is-randomly-moving,TECHNOLOGY,apple.stackexchange.com,1.0,0.7777777777777778,0.0,0.3333333333333333,1.0,0.3333333333333333,0.6666666666666666,0.5555555555555556,0.3333333333333333,0.0,0.3333333333333333,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.6666666666666666,0.0,0.6666666666666666,0.0,1.0,0.5555555555555556,0.5555555555555556,0.5555555555555556,0.7777777777777778,0.5333333333333333,0.6666666666666666,0.0,0.6666666666666666,0.7777777777777778,How to repair the MacBook Pro touchpad with randomly moving mouse pointer?,"The trackpad on my Macbook Pro just started acting oddly. It's randomly clicking (which might cause me to switch programs), right-clicking and even once my screen even showed the swiping animation as if I was trying to switch to a different desktop.    

Part of me fears that this is some sort of joke hacking attempt (I know of a USB device you plug into someones computer and it randomly moves their mouse and types on their keyboard), but there is nothing plugged into my machine and I just turned off the Wi-Fi and watched as this web page tried to close, the mouse right clicked twice, highlighted a word and clicked ""Paste and Match Style"" in the Chrome right-click menu.
Also as I've been typing (with my Wi-Fi turned off) the mouse has randomly been clicking inside this question and changing where I am typing.  

I just plugged in a USB mouse which seems to work fine but the trackpad is now nearly useless. I can't even move the mouse cursor more than a few centimeters with it.

Is this a common issue?
EDIT
I think it is dying actually. I can now click but not move at all with the trackpad, while a regular mouse works fine.
EDIT 2
And now it seems to be working again. I turned on the option for ""Ignore Trackpad when Mouse is plugged in"" under Universal Access. I cleaned the trackpad with rubbing alcohol, I whined and complained for a few minutes to my dog, turned off the ""Ignore Trackpad"" setting, unplugged the USB mouse, and the Trackpad appears to be working mostly normally.
If I run my finger across it at the top or bottom portion of the mouse, it works, but there is a line horizontally across it (almost exactly where a physical trackpad button would end on the old trackpads) that is ""dead"".  The mouse stops moving, or moves sluggishly when hitting that spot and that ""spot"" goes across the whole trackpad.
","I've heard dust and dirt inside the MB/MBP can cause the trackpad to act very weird. I'm having issues with my mouse now and am thinking of taking apart my MBP and blowing it out with a compressor.
"
1655,1655,2613,How to make extra crispy and crunchy breading like KFC?,"I'm wondering how I would go about making extra crispy chicken breading like they do at many places like KFC and the like. Is there a certain ingredient that makes the breading like that?

Any assistance would be very much appreciated, and feel free to share any of your own recipes for crispy chicken breading if you have them. I'll be sure to put them to good use!

Thanks!
",James Mowery,https://cooking.stackexchange.com/users/2109,"Use bread crumbs and egg white for coating the chicken. First mix up corn flour, garlic powder, onion powder and little pepper powder. Then coat the chicken with this. Then dip the chicken in egg white, then bread crumbs coating. Fry it in medium flamed oil. Try this very crispy chicken which is equal to KFC chicken.
",user15503,https://cooking.stackexchange.com/users/15503,http://cooking.stackexchange.com/questions/5764/how-to-make-extra-crispy-and-crunchy-breading-like-kfc,LIFE_ARTS,cooking.stackexchange.com,0.8888888888888888,0.7777777777777778,0.0,0.0,0.0,0.6666666666666666,0.7777777777777778,0.7777777777777778,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.8,1.0,0.3333333333333333,0.0,0.8888888888888888,How to make crisp bread like KFC?,"I'm wondering how I would go about making extra crispy chicken breading like they do at many places like KFC and the like. Is there a certain ingredient that makes the breading like that?

Any assistance would be very much appreciated, and feel free to share any of your own recipes for crispy chicken breading if you have them. I'll be sure to put them to good use!

Thanks!
","Use bread crumbs and egg white for coating the chicken. First mix up corn flour, garlic powder, onion powder and little pepper powder. Then coat the chicken with this. Then dip the chicken in egg white, then bread crumbs coating. Fry it in medium flamed oil. Try this very crispy chicken which is equal to KFC chicken.
"
2008,2008,3203,Advice on using FORMAT_MODULE_PATH,"From what I have read FORMAT_MODULE_PATH allows to use custom formats.

How can I access the first value from DATETIME_INPUT_FORMATS in my application?

The DATETIME_INPUT_FORMATS variable for german should be '%d.%m.%Y', whereas for english should be '%Y-%m-%d'. I want to use the values from the formats.py files depending on the language.    

I followed the Django documentation for how to use the FORMAT_MODULE_PATH variable, but I don't get the expected results.

settings.py:
    USE_L10N = True
    USE_I18N = True
    FORMAT_MODULE_PATH = 'myproject.formats'


myproject/
    formats/
        __init__.py
        en/
            __init__.py
            formats.py
        de/
            __init__.py
            formats.py


I change the browser's language from English to German, and back and nothing happens with the date format. It is always '%Y-%m-%d'. The displayed date format is the value of settings.DATE_INPUT_FORMATS[0].

Django version is 1.2.5 and Python version is 2.5.4.
",Seitaridis,https://stackoverflow.com/users/472111,"In Django 1.3, I have this working properly:

in settings.py:

USE_I18N = True
USE_L10N = True
TIME_ZONE = 'Europe/Amsterdam'
LANGUAGE_CODE = 'nl_NL'
FORMAT_MODULE_PATH = 'settings.locale'


In settings/locale/nl/formats.py:

DATETIME_FORMAT = 'j F Y \o\m H:i'

",vdboor,https://stackoverflow.com/users/146289,http://stackoverflow.com/questions/5165634/advice-on-using-format-module-path,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.3333333333333333,0.0,1.0,0.6666666666666666,1.0,0.6666666666666666,0.4444444444444444,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,0.8888888888888888,Suggestions on using format module path,"From what I have read FORMAT_MODULE_PATH allows to use custom formats.

How can I access the first value from DATETIME_INPUT_FORMATS in my application?

The DATETIME_INPUT_FORMATS variable for german should be '%d.%m.%Y', whereas for english should be '%Y-%m-%d'. I want to use the values from the formats.py files depending on the language.    

I followed the Django documentation for how to use the FORMAT_MODULE_PATH variable, but I don't get the expected results.

settings.py:
    USE_L10N = True
    USE_I18N = True
    FORMAT_MODULE_PATH = 'myproject.formats'


myproject/
    formats/
        __init__.py
        en/
            __init__.py
            formats.py
        de/
            __init__.py
            formats.py


I change the browser's language from English to German, and back and nothing happens with the date format. It is always '%Y-%m-%d'. The displayed date format is the value of settings.DATE_INPUT_FORMATS[0].

Django version is 1.2.5 and Python version is 2.5.4.
","In Django 1.3, I have this working properly:

in settings.py:

USE_I18N = True
USE_L10N = True
TIME_ZONE = 'Europe/Amsterdam'
LANGUAGE_CODE = 'nl_NL'
FORMAT_MODULE_PATH = 'settings.locale'


In settings/locale/nl/formats.py:

DATETIME_FORMAT = 'j F Y \o\m H:i'

"
2832,2832,4507,What package managers do popular Unix Distributions Use?,"I am creating a Script and I need to know what package manager each Popular Unix Distribution Uses (especially those distros that are commonly-used for Servers)...

I mean:
Debian uses apt-get
Fedora uses yum
",ant0nisk,https://unix.stackexchange.com/users/19942,"You would probably be better off creating a .deb package for Debian based distros (including Ubuntu), and .rpm package for Red-Hat based distros (including Fedora), and making the .tar file available for everybody else. Don't concern yourself with which package manager each distro uses. For instance, although I run a Debian-derived distro, I personally use the aptitude package manager. But and .deb package will install for me, assuming that it targets the versions of dependencies that I have installed.
",dotancohen,https://unix.stackexchange.com/users/9760,http://unix.stackexchange.com/questions/40989/what-package-managers-do-popular-unix-distributions-use,TECHNOLOGY,unix.stackexchange.com,0.8888888888888888,0.8888888888888888,0.0,1.0,0.6666666666666666,0.6666666666666666,0.4444444444444444,0.4444444444444444,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.0,0.0,0.6666666666666666,0.8888888888888888,0.6666666666666666,0.7777777777777778,0.8888888888888888,0.8,0.3333333333333333,0.0,0.3333333333333333,0.6666666666666666,What package managers do popular UNIX distributions use?,"I'm creating a script, and I need to know what package managers are used for each popular UNIX distribution (especially those that are commonly used for servers)...","You would probably be better off creating a .deb package for Debian based distros (including Ubuntu), and .rpm package for Red-Hat based distros (including Fedora), and making the .tar file available for everybody else. Don't concern yourself with which package manager each distro uses. For instance, although I run a Debian-derived distro, I personally use the aptitude package manager. But and .deb package will install for me, assuming that it targets the versions of dependencies that I have installed.
"
1277,1277,2012,How to show the integers have same cardinality as the natural numbers?,"How would I show the following have a bijection. Which is one to one and onto ofcourse.

$\mathbb{Z}\rightarrow \mathbb{N}$

I know I need to find a function. But I do not see the pattern that makes integer go to natural. I already did this problem from natural to integer but now I want to see it done this way.

I have listed some numbers

$,..,-4,-3,-2,-1,0,1,2,3,4,5,6,7,8,9,..$

$1,2,3,4,5,6,7,8,9,10,11,12,13,14,.$
",Fernando Martinez,https://math.stackexchange.com/users/37244,"I like the one that snake around, $0, -1, 1, -2, 2, -3, 3,\ldots$

So it goes


  $$\begin{cases}f: \Bbb N\to \Bbb Z \\ f(2n)=n-1 \\ f(2n-1)=-n\end{cases}$$


If you want it to go the other way, you just reverse the idea and compute the inverse of $f$.
",Adam Hughes,https://math.stackexchange.com/users/58831,http://math.stackexchange.com/questions/873927/how-to-show-the-integers-have-same-cardinality-as-the-natural-numbers,SCIENCE,math.stackexchange.com,0.8888888888888888,0.8888888888888888,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,1.0,0.8888888888888888,0.8666666666666666,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.7777777777777778,How to show that integers have the same cardinality as natural numbers?,"How would I show the following have a bijection. Which is one to one and onto ofcourse.

$\mathbb{Z}\rightarrow \mathbb{N}$

I know I need to find a function. But I do not see the pattern that makes integer go to natural. I already did this problem from natural to integer but now I want to see it done this way.

I have listed some numbers

$,..,-4,-3,-2,-1,0,1,2,3,4,5,6,7,8,9,..$

$1,2,3,4,5,6,7,8,9,10,11,12,13,14,.$
","I like the one that snake around, $0, -1, 1, -2, 2, -3, 3,\ldots$

So it goes


  $$\begin{cases}f: \Bbb N\to \Bbb Z \\ f(2n)=n-1 \\ f(2n-1)=-n\end{cases}$$


If you want it to go the other way, you just reverse the idea and compute the inverse of $f$.
"
2489,2489,3970,Can summoned creatures take items back with them?,"If you summon a creature and give it any item then dismiss it, does the item go with it?
",Axel_690,https://rpg.stackexchange.com/users/6004,"The items remain per the Main FAQ (p91).


  What happens to a summoned monster’s equipment when it dies or the spell ends? What if it’s not carrying the equipment any more? What if
  it’s carrying something new? When a summoned creature goes away, so
  does everything it came with. If it’s holding or wearing something it
  didn’t appear with, that item drops to the ground in the creature’s
  space after it disappears.


The only arguement (besides Main FAQ haters;)) I can see here is if you believe ""spell ending"" and dismissing the spell are different but I believe they are the same.
",joedragons,https://rpg.stackexchange.com/users/19541,http://rpg.stackexchange.com/questions/63767/can-summoned-creatures-take-items-back-with-them,CULTURE,rpg.stackexchange.com,1.0,1.0,0.0,1.0,1.0,1.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,0.8888888888888888,0.6666666666666666,0.8888888888888888,0.8888888888888888,0.8,0.0,0.0,1.0,1.0,Can the summoned creature take the item back?,"If you summon a creature and give it anything and then disband it, is this thing with it?","The items remain per the Main FAQ (p91).


  What happens to a summoned monster’s equipment when it dies or the spell ends? What if it’s not carrying the equipment any more? What if
  it’s carrying something new? When a summoned creature goes away, so
  does everything it came with. If it’s holding or wearing something it
  didn’t appear with, that item drops to the ground in the creature’s
  space after it disappears.


The only arguement (besides Main FAQ haters;)) I can see here is if you believe ""spell ending"" and dismissing the spell are different but I believe they are the same.
"
2087,2087,3325,Why do you multiply one way and divide the other way with these trig problems?,"I am practicing finding a side of an angle on Khan Academy. I understand SOH CAH TOA and which sin, cos, tan to choose from. But, I don't understand why they multiply sometimes to find the side and divide other times. I am using a calculator.

Here is a multiply example


and a divide example


thanks.
",Tyler Zika,https://math.stackexchange.com/users/45831,"In the 1st problem, I think you understand it as far as the next-to-last line, $$\sin A={BC\over\sqrt{97}}$$ Also, you are given the value $$\sin A={9\sqrt{97}\over97}$$ So you have $${9\sqrt{97}\over97}={BC\over\sqrt{97}}$$ Since you want $BC$, you multiply both sides of this equation by $\sqrt{97}$ --- that gets $BC$ all by itself on one side of the equation, which is what you want. 

In the second problem, you understand $$\tan A={10\over AC}$$ You want to isolate $AC$. This can be done by multiplying both sides by $AC$, getting $$(AC)(\tan A)=10$$ and then dividing both sides by $\tan A$ to get $$AC={10\over\tan A}$$

Now you are given $$\tan A={10\over3}$$ so you have $$AC={10\over10/3}$$ which simplifies to $3$. 

OK?
",Gerry Myerson,https://math.stackexchange.com/users/8269,http://math.stackexchange.com/questions/283989/why-do-you-multiply-one-way-and-divide-the-other-way-with-these-trig-problems,SCIENCE,math.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,0.3333333333333333,1.0,1.0,0.7777777777777778,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.8888888888888888,0.8888888888888888,0.4444444444444444,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,1.0,Why use these trigonometric problems to multiply one direction by another?,"I'm practicing looking for an angle in Khan college. I know what crime you should choose, because, tan. But I don't understand why they sometimes multiply to find the edge and then divide by other times. I'm using a calculator.","In the 1st problem, I think you understand it as far as the next-to-last line, $$\sin A={BC\over\sqrt{97}}$$ Also, you are given the value $$\sin A={9\sqrt{97}\over97}$$ So you have $${9\sqrt{97}\over97}={BC\over\sqrt{97}}$$ Since you want $BC$, you multiply both sides of this equation by $\sqrt{97}$ --- that gets $BC$ all by itself on one side of the equation, which is what you want. 

In the second problem, you understand $$\tan A={10\over AC}$$ You want to isolate $AC$. This can be done by multiplying both sides by $AC$, getting $$(AC)(\tan A)=10$$ and then dividing both sides by $\tan A$ to get $$AC={10\over\tan A}$$

Now you are given $$\tan A={10\over3}$$ so you have $$AC={10\over10/3}$$ which simplifies to $3$. 

OK?
"
829,829,1321,Ideas for synchronizing records programmatically,"I need to synchronize records, say a list of clients, between a local and distant database. The database on both sides has the same structure. I've thought of using some kind of marker (date field, hash/checksum on field values...) but what would you advise ?

Edit: Distant database is on web hosting so PHP will be needed for transferring data.
",James P.,https://stackoverflow.com/users/225899,"It's always a good idea to have a last change field (date) on your records. Keep in mind that, if you start to synchronize, you have to take care of conflicts.

If both sides can insert, use a partitioning scheme for your primary keys. Example: Site A starts from 1000000000, Site B from 2000000000 (make this numbers large enough or simply divide your primary key size by the number of concurrent sites).

Rough synchronize plot:


Get the modified records from source A, beginning from the last sync cycle.
For each record, check:

Is it newly inserted in A? Then insert it in B
Is it modified in A, but not in B: update B
Is it modified in A and in B: resolve conflicts on a field level.

Get the modified records from source B, beginning from the last sync cycle
For each record, check:

Is it newly inserted in B? Then insert it in A
Is it modified in B, but not in A: update A
Is it modified in B and in A: resolve conflicts on a field level.


",Gregor,https://stackoverflow.com/users/1171172,http://stackoverflow.com/questions/12437437/ideas-for-synchronizing-records-programmatically,STACKOVERFLOW,stackoverflow.com,1.0,0.4444444444444444,0.0,0.0,1.0,0.0,0.4444444444444444,0.8888888888888888,0.0,0.0,1.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,1.0,The idea of synchronizing records programmatically,"I need to synchronize records, such as client lists, between local and remote databases. The database structure of both parties is the same. I've considered using some kind of tag (date field, hash / checksum of field values...) , but what do you suggest?","It's always a good idea to have a last change field (date) on your records. Keep in mind that, if you start to synchronize, you have to take care of conflicts.

If both sides can insert, use a partitioning scheme for your primary keys. Example: Site A starts from 1000000000, Site B from 2000000000 (make this numbers large enough or simply divide your primary key size by the number of concurrent sites).

Rough synchronize plot:


Get the modified records from source A, beginning from the last sync cycle.
For each record, check:

Is it newly inserted in A? Then insert it in B
Is it modified in A, but not in B: update B
Is it modified in A and in B: resolve conflicts on a field level.

Get the modified records from source B, beginning from the last sync cycle
For each record, check:

Is it newly inserted in B? Then insert it in A
Is it modified in B, but not in A: update A
Is it modified in B and in A: resolve conflicts on a field level.


"
607,607,950,How to mount a NTFS USB harddrive to Mac OS X that was unsave removed from Windows?,"I have a hard drive that gets plugged into several machines. One MacBook Pro running Mac OS X, some Ubuntu and Fedora Installations and sometimes Windows XP or Vista. Therefore, I formatted it NTFS to be able to read and write on it no matter which machine is used. On Mac OS I installed MacFUSE to do this. 

The Problem is, when the USB device is removed from a Windows box, without using the ""remove hardware"" function from the task bar, the drive is locked. When I wnat to mount it in Mac OS, I get an error message and have to connect it to back to Windows and cleanly unmount it.

So, my question is: Is there an easy way to use the drive on every computer / OS without mounting problems? 
",Tim Büthe,https://superuser.com/users/3124,"You should really unmount your drive properly.

The reason why you need to do that is Windows write-caches for that USB stick, so it may say it's done writing files to yoru app, to make it more responsive, but it could still be hard at work finishing the job.

If you remove the stick before that's done, you lose data, and it's for your data's protection that it is doing that.
",calyth,https://superuser.com/users/12036,http://superuser.com/questions/10024,TECHNOLOGY,superuser.com,0.6666666666666666,0.4444444444444444,0.0,1.0,1.0,1.0,0.4444444444444444,0.4444444444444444,0.6666666666666666,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.0,0.0,0.8888888888888888,0.7777777777777778,0.5555555555555556,0.8888888888888888,0.8888888888888888,0.6666666666666667,0.6666666666666666,0.0,1.0,0.8888888888888888,How do I install an unsaved NTFS USB hard disk removed from windows to Mac OS X?,"I have a hard drive that gets plugged into several machines. One MacBook Pro running Mac OS X, some Ubuntu and Fedora Installations and sometimes Windows XP or Vista. Therefore, I formatted it NTFS to be able to read and write on it no matter which machine is used. On Mac OS I installed MacFUSE to do this. 

The Problem is, when the USB device is removed from a Windows box, without using the ""remove hardware"" function from the task bar, the drive is locked. When I wnat to mount it in Mac OS, I get an error message and have to connect it to back to Windows and cleanly unmount it.

So, my question is: Is there an easy way to use the drive on every computer / OS without mounting problems? 
","You should really unmount your drive properly.

The reason why you need to do that is Windows write-caches for that USB stick, so it may say it's done writing files to yoru app, to make it more responsive, but it could still be hard at work finishing the job.

If you remove the stick before that's done, you lose data, and it's for your data's protection that it is doing that.
"
5815,5815,9209,Mark: outstanding (as in: not yet known),"I’m updating my tabular CV for an application and I’d like to include my master thesis even though it’s not yet finished (soon!) and marked. So I’d like to write that the mark is still outstanding but I fear that if I simply write


  Master thesis: ‹topic›
  Supervisor: ‹supervisor›
  Mark: outstanding


this could be misconstrued to mean that the result is in, and that it’s outstanding (as in: spectacular). What can I say here instead? It should be as salient as possible, single word preferred. I specifically want to avoid writing half a sentence.
",Konrad Rudolph,https://english.stackexchange.com/users/1637,"I agree, using outstanding here is quite ambiguous.

I would use Awaiting mark or Pending mark - they are both clear and direct. (You can alternatively substitute mark with grade.)
",Noldorin,https://english.stackexchange.com/users/184,http://english.stackexchange.com/questions/9077/mark-outstanding-as-in-not-yet-known,CULTURE,english.stackexchange.com,1.0,0.4444444444444444,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.4444444444444444,0.4444444444444444,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,0.3333333333333333,0.8888888888888888,Mark: outstanding (i.e. unknown),"I’m updating my tabular CV for an application and I’d like to include my master thesis even though it’s not yet finished (soon!) and marked. So I’d like to write that the mark is still outstanding but I fear that if I simply write


  Master thesis: ‹topic›
  Supervisor: ‹supervisor›
  Mark: outstanding


this could be misconstrued to mean that the result is in, and that it’s outstanding (as in: spectacular). What can I say here instead? It should be as salient as possible, single word preferred. I specifically want to avoid writing half a sentence.
","I agree, using outstanding here is quite ambiguous.

I would use Awaiting mark or Pending mark - they are both clear and direct. (You can alternatively substitute mark with grade.)
"
2585,2585,4112,Voltage ratings of capacitors: ceramic vs electrolytic,"Now I know when it comes to electrolytic capacitors it's usually good practice to use a voltage rating 1.5x - 2.5x the maximum rating you ever expect the capacitor to be exposed to, as the lifetime can be significantly reduced by running it near its limits.

But does the same protocol apply to ceramic capacitors? For example, assume a 25V ceramic capacitor - will running it at 24V reduce its lifespan significantly?

I'm currently designing a PSU which needs to be reliable, so at the moment I'm using 50V caps for a maximum 20V input (35V caps aren't available), but I'd like to switch to 25V caps if possible.
",Thomas O,https://electronics.stackexchange.com/users/1225,"ceramic caps are really durable, MLCC's are often tested at rated to 200% rated voltage for ~1000 hours before failure.

That being said, I often find that higher voltage MLCC's can actually be cheaper than the lower voltage for a given capacitance due to higher industry volume for the higher voltage ratings.  For instance finding 16v 0.1uf MLCC is never a problem, but something like 100pF may be cheaper at 50V than it is at 16V
",Mark,https://electronics.stackexchange.com/users/1438,http://electronics.stackexchange.com/questions/5274/voltage-ratings-of-capacitors-ceramic-vs-electrolytic,TECHNOLOGY,electronics.stackexchange.com,0.7777777777777778,0.4444444444444444,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.0,1.0,0.8888888888888888,Rated voltage of capacitor: ceramics and electrolysis,"Now I know when it comes to electrolytic capacitors it's usually good practice to use a voltage rating 1.5x - 2.5x the maximum rating you ever expect the capacitor to be exposed to, as the lifetime can be significantly reduced by running it near its limits.

But does the same protocol apply to ceramic capacitors? For example, assume a 25V ceramic capacitor - will running it at 24V reduce its lifespan significantly?

I'm currently designing a PSU which needs to be reliable, so at the moment I'm using 50V caps for a maximum 20V input (35V caps aren't available), but I'd like to switch to 25V caps if possible.
","ceramic caps are really durable, MLCC's are often tested at rated to 200% rated voltage for ~1000 hours before failure.

That being said, I often find that higher voltage MLCC's can actually be cheaper than the lower voltage for a given capacitance due to higher industry volume for the higher voltage ratings.  For instance finding 16v 0.1uf MLCC is never a problem, but something like 100pF may be cheaper at 50V than it is at 16V
"
3917,3917,6247,Dynamic Programming: find the minimal route with ten nodes from a set of 100 nodes,"You are given 100 stations and distance between each adjacent stations. Now you have to select 10 stations(means 10 hops) among those 100 stations in such a way that maximum of distance between any 2 hops will be minimised. By default 1 and 100 stations are selected , so you need to choose only 8 more stations.
",John Smith,https://stackoverflow.com/users/1263492,"Since you haven't told us:


I'll assume time isn't an issue
I'll assume memory isn't an issue.
I'll assume the answer isn't programming language specific
I'll assume you are aiming to get from one station (1) to a destination station (100)



//Iterate through all possible paths to destination

//If you take more than 8 steps, stop and go back

//Note the total length of each path

//Select the shortest path



You're question is impossible difficult to answer, as such, my answer is rather impossible to understand. You will need to learn how to ask questions to get decent answers.

While you're at it, learn to accept answers
",James Webster,https://stackoverflow.com/users/916299,http://stackoverflow.com/questions/10953545,STACKOVERFLOW,stackoverflow.com,0.6666666666666666,0.6666666666666666,0.0,0.5,1.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.5,0.0,1.0,0.0,0.8333333333333334,0.6666666666666666,0.5,0.8333333333333334,0.8333333333333334,0.2,0.5,0.0,0.0,0.8333333333333334,Dynamic planning: finding the minimum path of 10 nodes from a group of 100 nodes,"Give you 100 sites and the distance between each adjacent site. Now, you have to choose 10 of the 100 stations (which means 10 hops) to minimize the distance between any two hops. By default, 1 and 100 stations are selected, so you only need to select an additional 8 stations.","Since you haven't told us:


I'll assume time isn't an issue
I'll assume memory isn't an issue.
I'll assume the answer isn't programming language specific
I'll assume you are aiming to get from one station (1) to a destination station (100)



//Iterate through all possible paths to destination

//If you take more than 8 steps, stop and go back

//Note the total length of each path

//Select the shortest path



You're question is impossible difficult to answer, as such, my answer is rather impossible to understand. You will need to learn how to ask questions to get decent answers.

While you're at it, learn to accept answers
"
1908,1908,3040,100% Rye Pizza Base Recipes?,"I'm looking for a 100% rye pizza base recipe. The recipes I can find all combine the rye with other flours (typically wheat based). I know it is possible to create 100% rye based pizza bases as I know of one pizza place in town that sells them. 

I understand that they had to do something special to keep the pizza base from falling apart. I don't mind experimenting a bit to find a recipe that works, but I could use some ideas on where to start - what sort of ingredients might bind the rye so that it doesn't crumble as a thin pizza base and maintains a low glycemic index for my diabetic wife.

The only dietary requirements would be that the various ingredients maintain a low glycemic index or a specific ingredient with a high glycemic index can be counteracted by some other ingredient. And only using rye flour.
",Stephen Perelson,https://cooking.stackexchange.com/users/1892,"
  I don't mind experimenting a bit to find a recipe that works, but I could use some ideas on where to start - what sort of ingredients might bind the rye so that it doesn't crumble as a thin pizza base and maintains a low glycemic index for my diabetic wife.


Psyllium husk is the general go-to binder for low-carb bread, but I have not seen a recipe using it in rye pizza dough. Another alternative is to give up on substituting bread and use the same toppings with something else. A frittata does not add much extra work and works well with standard pizza toppings.
",Krister Olsson,https://cooking.stackexchange.com/users/1220,http://cooking.stackexchange.com/questions/4979/100-rye-pizza-base-recipes,LIFE_ARTS,cooking.stackexchange.com,1.0,0.8888888888888888,0.0,0.6666666666666666,1.0,0.6666666666666666,0.8888888888888888,0.7777777777777778,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8,0.0,0.5,1.0,1.0,100% rye pizza formula?,"I'm looking for a 100% rye pizza base recipe. The recipes I can find all combine the rye with other flours (typically wheat based). I know it is possible to create 100% rye based pizza bases as I know of one pizza place in town that sells them. 

I understand that they had to do something special to keep the pizza base from falling apart. I don't mind experimenting a bit to find a recipe that works, but I could use some ideas on where to start - what sort of ingredients might bind the rye so that it doesn't crumble as a thin pizza base and maintains a low glycemic index for my diabetic wife.

The only dietary requirements would be that the various ingredients maintain a low glycemic index or a specific ingredient with a high glycemic index can be counteracted by some other ingredient. And only using rye flour.
","
  I don't mind experimenting a bit to find a recipe that works, but I could use some ideas on where to start - what sort of ingredients might bind the rye so that it doesn't crumble as a thin pizza base and maintains a low glycemic index for my diabetic wife.


Psyllium husk is the general go-to binder for low-carb bread, but I have not seen a recipe using it in rye pizza dough. Another alternative is to give up on substituting bread and use the same toppings with something else. A frittata does not add much extra work and works well with standard pizza toppings.
"
5554,5554,8822,Is there any performance difference between ++i and i++ in C#?,"Is there any performance difference between using something like

for(int i = 0; i &lt; 10; i++) { ... }


and

for(int i = 0; i &lt; 10; ++i) { ... }


or is the compiler able to optimize in such a way that they are equally fast in the case where they are functionally equivalent?

Edit:
This was asked because I had a discussion with a co-worker about it, not because I think its a useful optimization in any practical sense. It is largely academic. 
",Anton,https://stackoverflow.com/users/341413,"Have a concrete piece of code and CLR release in mind? If so, benchmark it. If not, forget about it. Micro-optimization, and all that... Besides, you can't even be sure different CLR release will produce the same result.
",Michael Borgwardt,https://stackoverflow.com/users/16883,http://stackoverflow.com/questions/467322/is-there-any-performance-difference-between-i-and-i-in-c,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.8888888888888888,0.0,1.0,1.0,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.3333333333333333,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8888888888888888,0.5,0.3333333333333333,0.6666666666666666,0.8333333333333334,0.5,0.0,0.0,0.0,0.6666666666666666,Is there any performance difference between + + I and I + + in C + +?,"Is there any performance difference between using something like

for(int i = 0; i &lt; 10; i++) { ... }


and

for(int i = 0; i &lt; 10; ++i) { ... }


or is the compiler able to optimize in such a way that they are equally fast in the case where they are functionally equivalent?

Edit:
This was asked because I had a discussion with a co-worker about it, not because I think its a useful optimization in any practical sense. It is largely academic. 
","Is there a specific code and CLR version? If so, benchmark. If not, forget it. Micro optimization, and all of this... In addition, you can't even be sure that different versions of CLR will produce the same results."
1817,1817,2883,Control 8V H-Bridge with microcontroller,"Good afternoon.

I've been trying to control an 8V H-Bridge (PMOS+NMOS) with a 4V microcontroller output signal. I thouth it would work but then i read that the PMOS source voltage had to be equal or smaller than the control voltage in the PMOS/NMOS gates. Does somebody know how to deal with this problem (without adding much more electronics)?


",Electronics_Guy,https://electronics.stackexchange.com/users/43113,"You can't drive the PMOS transistor directly like that. Remember that the gate voltage is always referenced to the source terminal, so if you apply 8V to the source and 0-4V to the gate, the gate-source voltage varies between -8V and -4V. In other words, the PMOS can never shut off, because it's gats-source voltage never goes to zero.

To fix this, you need to create a ""level shifter"" for the PMOS gate signal. There are many ways to do this; one of the easiest is to purchase a driver chip designed specifically for the task.
",Dave Tweed,https://electronics.stackexchange.com/users/11683,http://electronics.stackexchange.com/questions/111090/control-8v-h-bridge-with-microcontroller,SCIENCE,electronics.stackexchange.com,1.0,0.4444444444444444,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.3333333333333333,0.3333333333333333,1.0,Control 8V H bridge with single chip microcomputer,"Good afternoon.

I've been trying to control an 8V H-Bridge (PMOS+NMOS) with a 4V microcontroller output signal. I thouth it would work but then i read that the PMOS source voltage had to be equal or smaller than the control voltage in the PMOS/NMOS gates. Does somebody know how to deal with this problem (without adding much more electronics)?


","You can't drive the PMOS transistor directly like that. Remember that the gate voltage is always referenced to the source terminal, so if you apply 8V to the source and 0-4V to the gate, the gate-source voltage varies between -8V and -4V. In other words, the PMOS can never shut off, because it's gats-source voltage never goes to zero.

To fix this, you need to create a ""level shifter"" for the PMOS gate signal. There are many ways to do this; one of the easiest is to purchase a driver chip designed specifically for the task.
"
1668,1668,2637,Why does WPF toggle button pulse once unchecked,"Within a Desktop app I have a toggle button: 

&lt;ToggleButton x:Name=""CFStglBtn"" Checked=""cfsCBox_Checked""
              Unchecked=""cfsCBox_Unchecked""
              IsChecked=""True"" HorizontalAlignment=""Left"" Margin=""5,0,0,0""&gt;
    &lt;StackPanel Orientation=""Horizontal""&gt;
        &lt;Image Source=""assets\telephone.png"" Margin=""3,0,0,0"" /&gt;
        &lt;TextBlock Text=""CFS"" FontSize=""10"" Margin=""5,5,5,0""
                   Foreground=""DarkSlateGray""/&gt;
    &lt;/StackPanel&gt;
&lt;/ToggleButton&gt;


For the Checked event I am setting a value and then executing a method FilterView(); 
//ommitting code 

Unchecked state is just the opposite. resets a variable and executed the method again

The question I have is I noticed when I uncheck the toggle button the button continues to pulse or flash ( going from blue to chrome) as if it still has focus. The button will stay like this until another button is clicked.

Is there a way to remove this focus so that when the button is unchecked the button goes back to a unchecked state without the flashing / pulsing color. 


As you can see from above this is a standard toggle button no styles or custom 
I tested this on just a regular button and I found the same occured when clicked the button will continue to pulse / flash until another button is clicked. 


How do you work around this or prevent this effect from happening.

Thank you
",rlcrews,https://stackoverflow.com/users/290645,"Set the Button Focusable=""False"".
",MarnBeast,https://stackoverflow.com/users/858986,http://stackoverflow.com/questions/3048140/why-does-wpf-toggle-button-pulse-once-unchecked,STACKOVERFLOW,stackoverflow.com,1.0,0.7777777777777778,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.6666666666666666,0.0,0.7777777777777778,0.8888888888888888,0.4444444444444444,1.0,1.0,0.6666666666666667,1.0,0.0,0.0,0.8888888888888888,Why WPF toggle button pulse is unchecked,"Within a Desktop app I have a toggle button: 

&lt;ToggleButton x:Name=""CFStglBtn"" Checked=""cfsCBox_Checked""
              Unchecked=""cfsCBox_Unchecked""
              IsChecked=""True"" HorizontalAlignment=""Left"" Margin=""5,0,0,0""&gt;
    &lt;StackPanel Orientation=""Horizontal""&gt;
        &lt;Image Source=""assets\telephone.png"" Margin=""3,0,0,0"" /&gt;
        &lt;TextBlock Text=""CFS"" FontSize=""10"" Margin=""5,5,5,0""
                   Foreground=""DarkSlateGray""/&gt;
    &lt;/StackPanel&gt;
&lt;/ToggleButton&gt;


For the Checked event I am setting a value and then executing a method FilterView(); 
//ommitting code 

Unchecked state is just the opposite. resets a variable and executed the method again

The question I have is I noticed when I uncheck the toggle button the button continues to pulse or flash ( going from blue to chrome) as if it still has focus. The button will stay like this until another button is clicked.

Is there a way to remove this focus so that when the button is unchecked the button goes back to a unchecked state without the flashing / pulsing color. 


As you can see from above this is a standard toggle button no styles or custom 
I tested this on just a regular button and I found the same occured when clicked the button will continue to pulse / flash until another button is clicked. 


How do you work around this or prevent this effect from happening.

Thank you
","Set the Button Focusable=""False"".
"
5488,5488,8708,How can I get to view the North Face of the Eiger in Switzerland?,"I can't seem to find information online about trains, buses, to take to get there etc. I would be travelling in from Stainach in Austria.

Is there a mountain station or similar that I can view it from?

e: I see from VMA's comment that I can go there via Grindelwald. What is the best way to get there from Stainach?

I'm thinking the train in the way of Stainach - Salzburg - Zurich - Bern - Grindelwald, but I can't get fares online for the Salzburg-Zurich-Bern portion. Anyone have an idea of the rough estimate of the fare?
",victoriah,https://travel.stackexchange.com/users/30,"You can also view the North face of the Eiger from the inside. The Jungfraubahn takes you from Kleine Scheidegg to the Jungfraujoch via a stop in the Eigerwall complete with panoramic windows. Looks like you can connect with mainline services from Grindelwald or Lauterbrunnen.

See also http://en.wikipedia.org/wiki/Jungfraubahn
",e100,https://travel.stackexchange.com/users/1058,http://travel.stackexchange.com/questions/539/how-can-i-get-to-view-the-north-face-of-the-eiger-in-switzerland,CULTURE,travel.stackexchange.com,1.0,0.5555555555555556,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.6666666666666666,1.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,1.0,How can I see the north of the egger River in Switzerland?,"I can't seem to find information online about trains, buses, to take to get there etc. I would be travelling in from Stainach in Austria.

Is there a mountain station or similar that I can view it from?

e: I see from VMA's comment that I can go there via Grindelwald. What is the best way to get there from Stainach?

I'm thinking the train in the way of Stainach - Salzburg - Zurich - Bern - Grindelwald, but I can't get fares online for the Salzburg-Zurich-Bern portion. Anyone have an idea of the rough estimate of the fare?
",You can also see North of egger from inside. Girls street takes you from Kleine Scheidegg to Jungfraujoch via a station in eigerwall with panoramic windows. It looks like you can connect to Greenwald or Laut Brennan's trunk service.
5460,5460,8669,Mark: outstanding (as in: not yet known),"I’m updating my tabular CV for an application and I’d like to include my master thesis even though it’s not yet finished (soon!) and marked. So I’d like to write that the mark is still outstanding but I fear that if I simply write


  Master thesis: ‹topic›
  Supervisor: ‹supervisor›
  Mark: outstanding


this could be misconstrued to mean that the result is in, and that it’s outstanding (as in: spectacular). What can I say here instead? It should be as salient as possible, single word preferred. I specifically want to avoid writing half a sentence.
",Konrad Rudolph,https://english.stackexchange.com/users/1637,"To be received, or to be decided?

This fits into a pattern of common phrases: to be confirmed, to be announced, to be decided, which are standard enough that in many institutions they are given just as tbc, tba, tbd.  To be received is less standard than these, but should be well-understood since it clearly invokes this well-known template.
",PLL,https://english.stackexchange.com/users/2587,http://english.stackexchange.com/questions/9077/mark-outstanding-as-in-not-yet-known,CULTURE,english.stackexchange.com,0.8888888888888888,0.3333333333333333,0.3333333333333333,1.0,0.6666666666666666,0.6666666666666666,0.7777777777777778,0.5555555555555556,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,1.0,0.8888888888888888,0.8666666666666666,0.0,0.0,0.6666666666666666,0.8888888888888888,Mark: outstanding (i.e. unknown),"I’m updating my tabular CV for an application and I’d like to include my master thesis even though it’s not yet finished (soon!) and marked. So I’d like to write that the mark is still outstanding but I fear that if I simply write


  Master thesis: ‹topic›
  Supervisor: ‹supervisor›
  Mark: outstanding


this could be misconstrued to mean that the result is in, and that it’s outstanding (as in: spectacular). What can I say here instead? It should be as salient as possible, single word preferred. I specifically want to avoid writing half a sentence.
","To be received, or to be decided?

This fits into a pattern of common phrases: to be confirmed, to be announced, to be decided, which are standard enough that in many institutions they are given just as tbc, tba, tbd.  To be received is less standard than these, but should be well-understood since it clearly invokes this well-known template.
"
2933,2933,4671,Should we allow or avoid non-standard pronouns?,"This question brings up an important question:

Do we want to allow or avoid the use of non-standard English such as the words zie and zir as non gender specific pronouns on this site?
",Flimzy,https://meta.christianity.stackexchange.com/users/20,"Sure, let them. Who cares about ""zis""?  If someone is fond of their own pet thing, let them do it.  They'll have confused people make edits all the time and they'll roll them back and there's no need to have more scuffling than that over it.  I've seen it with ""colour vs color"" edits, and that's such a waste of time. If someone rejects BC/AD/BCE/CE dates and only puts in years from whatever other frame of reference - fine, let them.

What will happen is that if people insist on making question in their own pet mindframe, few people will answer their question.  As long as people are asking questions they want to know the answer to, this will be self correcting - if you use a language or date system or whatever that people don't understand, you won't get answers. If they are not asking questions they want to know the answer to, crush them, because that's not what we need here.
",mxyzplk,https://meta.christianity.stackexchange.com/users/232,http://meta.christianity.stackexchange.com/questions/514/should-we-allow-or-avoid-non-standard-pronouns,CULTURE,meta.christianity.stackexchange.com,1.0,0.7777777777777778,1.0,1.0,0.0,0.0,0.6666666666666666,0.7777777777777778,0.0,0.0,1.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,0.8888888888888888,1.0,0.8666666666666666,0.0,0.0,0.6666666666666666,0.8888888888888888,Should we allow or avoid the use of non-standard pronouns?,"This question brings up an important question:

Do we want to allow or avoid the use of non-standard English such as the words zie and zir as non gender specific pronouns on this site?
","Sure, let them. Who cares about ""zis""?  If someone is fond of their own pet thing, let them do it.  They'll have confused people make edits all the time and they'll roll them back and there's no need to have more scuffling than that over it.  I've seen it with ""colour vs color"" edits, and that's such a waste of time. If someone rejects BC/AD/BCE/CE dates and only puts in years from whatever other frame of reference - fine, let them.

What will happen is that if people insist on making question in their own pet mindframe, few people will answer their question.  As long as people are asking questions they want to know the answer to, this will be self correcting - if you use a language or date system or whatever that people don't understand, you won't get answers. If they are not asking questions they want to know the answer to, crush them, because that's not what we need here.
"
4820,4820,7660,display tag and c choose tag,"I use the following code. But it is always go to the otherwise condition. I checked the value , and those are correctly passed from java to the jsp. Any missing points?

&lt;c:when test=""${pCount &gt; 0}""&gt;
    &lt;display:column class=""colPCount"" property=""pCount "" title=""${titlePCount}"" sortable=""true"" headerClass=""sortable"" /&gt;
&lt;/c:when&gt;
&lt;c:otherwise&gt;
    &lt;display:column class=""colPCount"" title=""${titlePCount}""&gt;&amp;nbsp;-&amp;nbsp;&lt;/display:column&gt;
&lt;/c:otherwise&gt;


For the pcount>0 items, still displaying as  '-' in the display tag. Even I reverse the checking condition like pCount&lt;0 in the first condition checking, the display tag always show the otherwise condition. It always pointing to the otherwise condition for every value.

Edited: Full Code

    &lt;display:table class=""displayTable"" id=""itemList""
        name=""${sessionScope.itemList}"" requestURI=""listItem.action""
        pagesize=""15"" defaultsort=""2"" defaultorder=""ascending"" sort=""list""&gt;
        &lt;display:column class=""colItemName"" property=""name""
            title=""${titleItemName}"" sortable=""true"" headerClass=""sortable""/&gt;
        ...
        &lt;c:choose&gt;
        &lt;c:when test=""${pCount &gt; 0}""&gt;
            &lt;display:column class=""colPCount"" property=""pCount "" title=""${titlePCount}"" sortable=""true"" headerClass=""sortable"" /&gt;
        &lt;/c:when&gt;
        &lt;c:otherwise&gt;
            &lt;display:column class=""colPCount"" title=""${titlePCount}""&gt;&amp;nbsp;-&amp;nbsp;&lt;/display:column&gt;
        &lt;/c:otherwise&gt;
        &lt;/c:choose&gt;
    &lt;/display:table&gt;

",kitokid,https://stackoverflow.com/users/751689,"I guess that the variable pCount = null. Try to check ${not empty pCount and pCount&gt;0}.
",Alex,https://stackoverflow.com/users/1599479,http://stackoverflow.com/questions/12831136/display-tag-and-c-choose-tag,STACKOVERFLOW,stackoverflow.com,0.6666666666666666,0.4444444444444444,0.0,1.0,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.6666666666666666,0.0,0.3333333333333333,0.8888888888888888,0.6666666666666666,1.0,1.0,0.7333333333333333,1.0,0.0,0.6666666666666666,0.7777777777777778,Show tags and select Tags,"I use the following code. But it is always go to the otherwise condition. I checked the value , and those are correctly passed from java to the jsp. Any missing points?

&lt;c:when test=""${pCount &gt; 0}""&gt;
    &lt;display:column class=""colPCount"" property=""pCount "" title=""${titlePCount}"" sortable=""true"" headerClass=""sortable"" /&gt;
&lt;/c:when&gt;
&lt;c:otherwise&gt;
    &lt;display:column class=""colPCount"" title=""${titlePCount}""&gt;&amp;nbsp;-&amp;nbsp;&lt;/display:column&gt;
&lt;/c:otherwise&gt;


For the pcount>0 items, still displaying as  '-' in the display tag. Even I reverse the checking condition like pCount&lt;0 in the first condition checking, the display tag always show the otherwise condition. It always pointing to the otherwise condition for every value.

Edited: Full Code

    &lt;display:table class=""displayTable"" id=""itemList""
        name=""${sessionScope.itemList}"" requestURI=""listItem.action""
        pagesize=""15"" defaultsort=""2"" defaultorder=""ascending"" sort=""list""&gt;
        &lt;display:column class=""colItemName"" property=""name""
            title=""${titleItemName}"" sortable=""true"" headerClass=""sortable""/&gt;
        ...
        &lt;c:choose&gt;
        &lt;c:when test=""${pCount &gt; 0}""&gt;
            &lt;display:column class=""colPCount"" property=""pCount "" title=""${titlePCount}"" sortable=""true"" headerClass=""sortable"" /&gt;
        &lt;/c:when&gt;
        &lt;c:otherwise&gt;
            &lt;display:column class=""colPCount"" title=""${titlePCount}""&gt;&amp;nbsp;-&amp;nbsp;&lt;/display:column&gt;
        &lt;/c:otherwise&gt;
        &lt;/c:choose&gt;
    &lt;/display:table&gt;

",I guess the variable pcount = null. Try checking ${not empty pcount and pcount & gt; 0}.
1416,1416,2225,CSS: Dropdown menu not displaying,"I have this website: http://dev.gratefulhearttherapy.org/
with a dropdown menu, it's supposed to unfold when you hover a category like ""Our Services"" or ""Abous Us"". But it doesn't.

I know it's a CSS issue because I use 2 different stylesheets, and one works while the other doesn't. However I've spent two hours on it and I don't find what's wrong.

I tried to play with z-index but it doesn't work. I took over someone else's work and CSS file is messy, and the website calls several stylesheets. In any case, the stylesheet I'm working with is here: http://dev.gratefulhearttherapy.org/index.php/tools/css/themes/gratefulheart/typography-new2.css

The relevant part of the CSS begins line 287, the ""Mega Menu"" section. Here it is:

Can anyone give me a tip at what might be the issue?

/* Mega Menu */

.top-level-nav a.nav-path-selected {
    color: #EA5603 !important;


    ul.mega-menu {
    height: 44px;
    width: 96%;
    text-align: left;
    margin: 10px 0 0 20px;
    padding: 0 60px;
    text-indent: 0;
    list-style-type: none;
    margin-left: -1px;
    }
    ul li.mega-menu {
    padding: 0;
    margin: 0;
    text-indent: 0;
    display: inline;
    line-height: 44px;
    }
    ul li a.mega-menu {
    text-decoration: none;
    color: #DE573C;
    font-size: 138.5%;
    }
    .nav  li a:hover {
        color: #8e4c0f;  
    }

.custom {line-height: 1.6;}
.custom ul.mega-menu, .custom ul.mega-menu, .custom ul.mega-menu li {margin: 0; padding: 0; border: none;}
.custom ul.mega-menu {
    background: #D6CEB4; 
    width: 100%; 
    height: 44px; 
    border-top: solid 2px #CCC2A5; 
    border-bottom: solid 2px #CCC2A5; 
    -webkit-border-radius: 4px;
    -moz-border-radius: 4px;
    border-radius: 4px;; position: relative;
    }
.custom ul.mega-menu li {float: left; margin: 0; padding: 0; }
.custom ul.mega-menu li a {float: left; display: block; padding: 12px 38px 12px 25px; ; text-decoration: none; color: #3B3B3B; font-size: 138.5%; text-decoration: none;}
.custom ul.mega-menu li a.dc-mega {position: relative;}
.custom ul.mega-menu li a .dc-mega-icon {display: block; position: absolute; top: 18px; right: 15px; width: 8px; height: 6px; background: url(images/arrow.png) no-repeat 0 0;}
.custom ul.mega-menu li.mega-hover a, .custom ul.mega-menu li a:hover {background-position: 100% -40px; color: #8e4c0f;}
.custom ul.mega-menu li.mega-hover a .dc-mega-icon {background-position: 0 100%;}
.custom ul.mega-menu li .sub-container { /* block container of dropdown submenu when it's closed (I think) */
    position: absolute; 
    background:  url(images/bg_sub_left.png) no-repeat 0 100%; 
    padding: 10px 10px 0 10px;  
    margin-left: -3px;
    } 
.custom ul.mega-menu li .sub {  /* dropdown submenu itself */
    margin: -8px 0 0 -8px; 
    background: #E3DDD3 
    url(images/bg_sub.png) no-repeat 100% 100%;
    padding: 00px 20px 20px 10px;
    border: 1px #D1C6B4;
    border-style: none solid solid solid;
    /* rounded corners */
    -webkit-border-bottom-right-radius: 3px;
    -webkit-border-bottom-left-radius: 3px;
    -moz-border-radius-bottomright: 3px;
    -moz-border-radius-bottomleft: 3px;
    border-bottom-right-radius: 3px;
    border-bottom-left-radius: 3px;
    /* dropshadow effect */
    -webkit-box-shadow: 0px 4px 6px rgba(50, 50, 50, 0.6);
    -moz-box-shadow:    0px 4px 6px rgba(50, 50, 50, 0.6);
    box-shadow:         0px 4px 6px rgba(50, 50, 50, 0.6);
    } 
.custom ul.mega-menu li .sub-container.mega .sub {padding: 20px 20px 10px 0;}
.custom ul.mega-menu li .sub .row {width: 100%; overflow: hidden; clear: both;}
.custom ul.mega-menu li .sub li {list-style: none; float: none; width: 170px; font-size: 120%; line-height: 2;} /* li of dropdown submenu */
.custom ul.mega-menu li .sub li.mega-hdr {margin: 0 10px 10px 0; float: left;}
.custom ul.mega-menu li .sub li.mega-hdr.last {margin-right: 0;}
.custom ul.mega-menu li .sub a, .custom ul.mega-menu li .sub span {background: none; border: none; text-shadow: none; color: #111; padding: 7px 10px; display: block; float: none; text-decoration: none; font-size: 0.9em;}
.custom ul.mega-menu li .sub li.mega-hdr .mega-hdr-a {padding: 5px 5px 5px 15px; margin-bottom: 5px; background: #6B6B6B url(images/bg_mega_hdr.png) no-repeat 0 0; text-transform: uppercase; font-weight: bold; color: #fff; text-shadow: 1px 1px 1px #333;}
.custom ul.mega-menu li .sub li.mega-hdr a.mega-hdr-a:hover {color: #000; text-shadow: none;}
.custom ul.mega-menu .sub li.mega-hdr li a {padding: 4px 5px 4px 20px; background: url(images/arrow_off.png) no-repeat 5px 8px; font-weight: normal;}
.custom ul.mega-menu .sub li.mega-hdr li a:hover {color: #a32403; background: #efefef url(images/arrow_on.png) no-repeat 5px 8px;}
.custom ul.mega-menu .sub ul li {padding-right: 0;}
.custom ul.mega-menu li .sub-container.non-mega .sub {padding: 20px 20px 20px 0;}
.custom ul.mega-menu li .sub-container.non-mega li {padding: 0; width: 190px; margin: 0;}
.custom ul.mega-menu li .sub-container.non-mega li a {padding: 7px 5px 7px 22px; background: url(images/arrow_off.png) no-repeat 7px 10px;}
.custom ul.mega-menu li .sub-container.non-mega li a:hover {color: #a32403; background: #efefef url(images/arrow_on.png) no-repeat 7px 10px;}

",Olivier Compagne,https://stackoverflow.com/users/953527,"It's because your #headerNav is set to overflow:hidden. Just remove this line of css:

#headerNav {
    …
    overflow: hidden;
    …    
}

",gearsdigital,https://stackoverflow.com/users/294076,http://stackoverflow.com/questions/7477385/css-dropdown-menu-not-displaying,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.4444444444444444,0.0,0.5,1.0,1.0,0.5555555555555556,0.5555555555555556,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,1.0,0.8888888888888888,CSS: drop down menu does not display,"I have this website: http://dev.gratefulhearttherapy.org/
with a dropdown menu, it's supposed to unfold when you hover a category like ""Our Services"" or ""Abous Us"". But it doesn't.

I know it's a CSS issue because I use 2 different stylesheets, and one works while the other doesn't. However I've spent two hours on it and I don't find what's wrong.

I tried to play with z-index but it doesn't work. I took over someone else's work and CSS file is messy, and the website calls several stylesheets. In any case, the stylesheet I'm working with is here: http://dev.gratefulhearttherapy.org/index.php/tools/css/themes/gratefulheart/typography-new2.css

The relevant part of the CSS begins line 287, the ""Mega Menu"" section. Here it is:

Can anyone give me a tip at what might be the issue?

/* Mega Menu */

.top-level-nav a.nav-path-selected {
    color: #EA5603 !important;


    ul.mega-menu {
    height: 44px;
    width: 96%;
    text-align: left;
    margin: 10px 0 0 20px;
    padding: 0 60px;
    text-indent: 0;
    list-style-type: none;
    margin-left: -1px;
    }
    ul li.mega-menu {
    padding: 0;
    margin: 0;
    text-indent: 0;
    display: inline;
    line-height: 44px;
    }
    ul li a.mega-menu {
    text-decoration: none;
    color: #DE573C;
    font-size: 138.5%;
    }
    .nav  li a:hover {
        color: #8e4c0f;  
    }

.custom {line-height: 1.6;}
.custom ul.mega-menu, .custom ul.mega-menu, .custom ul.mega-menu li {margin: 0; padding: 0; border: none;}
.custom ul.mega-menu {
    background: #D6CEB4; 
    width: 100%; 
    height: 44px; 
    border-top: solid 2px #CCC2A5; 
    border-bottom: solid 2px #CCC2A5; 
    -webkit-border-radius: 4px;
    -moz-border-radius: 4px;
    border-radius: 4px;; position: relative;
    }
.custom ul.mega-menu li {float: left; margin: 0; padding: 0; }
.custom ul.mega-menu li a {float: left; display: block; padding: 12px 38px 12px 25px; ; text-decoration: none; color: #3B3B3B; font-size: 138.5%; text-decoration: none;}
.custom ul.mega-menu li a.dc-mega {position: relative;}
.custom ul.mega-menu li a .dc-mega-icon {display: block; position: absolute; top: 18px; right: 15px; width: 8px; height: 6px; background: url(images/arrow.png) no-repeat 0 0;}
.custom ul.mega-menu li.mega-hover a, .custom ul.mega-menu li a:hover {background-position: 100% -40px; color: #8e4c0f;}
.custom ul.mega-menu li.mega-hover a .dc-mega-icon {background-position: 0 100%;}
.custom ul.mega-menu li .sub-container { /* block container of dropdown submenu when it's closed (I think) */
    position: absolute; 
    background:  url(images/bg_sub_left.png) no-repeat 0 100%; 
    padding: 10px 10px 0 10px;  
    margin-left: -3px;
    } 
.custom ul.mega-menu li .sub {  /* dropdown submenu itself */
    margin: -8px 0 0 -8px; 
    background: #E3DDD3 
    url(images/bg_sub.png) no-repeat 100% 100%;
    padding: 00px 20px 20px 10px;
    border: 1px #D1C6B4;
    border-style: none solid solid solid;
    /* rounded corners */
    -webkit-border-bottom-right-radius: 3px;
    -webkit-border-bottom-left-radius: 3px;
    -moz-border-radius-bottomright: 3px;
    -moz-border-radius-bottomleft: 3px;
    border-bottom-right-radius: 3px;
    border-bottom-left-radius: 3px;
    /* dropshadow effect */
    -webkit-box-shadow: 0px 4px 6px rgba(50, 50, 50, 0.6);
    -moz-box-shadow:    0px 4px 6px rgba(50, 50, 50, 0.6);
    box-shadow:         0px 4px 6px rgba(50, 50, 50, 0.6);
    } 
.custom ul.mega-menu li .sub-container.mega .sub {padding: 20px 20px 10px 0;}
.custom ul.mega-menu li .sub .row {width: 100%; overflow: hidden; clear: both;}
.custom ul.mega-menu li .sub li {list-style: none; float: none; width: 170px; font-size: 120%; line-height: 2;} /* li of dropdown submenu */
.custom ul.mega-menu li .sub li.mega-hdr {margin: 0 10px 10px 0; float: left;}
.custom ul.mega-menu li .sub li.mega-hdr.last {margin-right: 0;}
.custom ul.mega-menu li .sub a, .custom ul.mega-menu li .sub span {background: none; border: none; text-shadow: none; color: #111; padding: 7px 10px; display: block; float: none; text-decoration: none; font-size: 0.9em;}
.custom ul.mega-menu li .sub li.mega-hdr .mega-hdr-a {padding: 5px 5px 5px 15px; margin-bottom: 5px; background: #6B6B6B url(images/bg_mega_hdr.png) no-repeat 0 0; text-transform: uppercase; font-weight: bold; color: #fff; text-shadow: 1px 1px 1px #333;}
.custom ul.mega-menu li .sub li.mega-hdr a.mega-hdr-a:hover {color: #000; text-shadow: none;}
.custom ul.mega-menu .sub li.mega-hdr li a {padding: 4px 5px 4px 20px; background: url(images/arrow_off.png) no-repeat 5px 8px; font-weight: normal;}
.custom ul.mega-menu .sub li.mega-hdr li a:hover {color: #a32403; background: #efefef url(images/arrow_on.png) no-repeat 5px 8px;}
.custom ul.mega-menu .sub ul li {padding-right: 0;}
.custom ul.mega-menu li .sub-container.non-mega .sub {padding: 20px 20px 20px 0;}
.custom ul.mega-menu li .sub-container.non-mega li {padding: 0; width: 190px; margin: 0;}
.custom ul.mega-menu li .sub-container.non-mega li a {padding: 7px 5px 7px 22px; background: url(images/arrow_off.png) no-repeat 7px 10px;}
.custom ul.mega-menu li .sub-container.non-mega li a:hover {color: #a32403; background: #efefef url(images/arrow_on.png) no-repeat 7px 10px;}

","It's because your #headerNav is set to overflow:hidden. Just remove this line of css:

#headerNav {
    …
    overflow: hidden;
    …    
}

"
3782,3782,6017,how to pass value from visual force page (InputField) to controller?,"I have created a Vf page from which i need to fetch the value of new owner and need to save the value in property defined in controller:

Following is my vf page code:

&lt;apex:pageBlockSection&gt;
    &lt;apex:InputField label=""user"" value=""{!a.ownerid}""/&gt;
&lt;/apex:pageBlockSection&gt;


here a is object of opportunity

Controller code:

used one property to store the value:

public string ownername {get;set;}


Note: user will input the value through lookup field.

Any suggestions on this?
",jack,https://salesforce.stackexchange.com/users/8706,"The inputfield will have a direct binding to the a.ownerid.

This binding is two-directional, so that means two things:


When the page loads, the input field will be filled with a.ownerid.
The reverse is also true: the value of the input field will be saved to a.ownerid. If you had a commandButton with an action that is executed on the controller, the a.ownerid will by then have the value that the user entered on the Visualforce page before the user clicked the commandButton.


Update your Visualforce code like so to include that commandButton

&lt;apex:pageBlockSection&gt;
    &lt;apex:InputField label=""user"" value=""{!a.ownerid}""/&gt;
    &lt;apex:commandButton action=""{!someAction}"" value=""Save""/&gt;
&lt;/apex:pageBlockSection&gt;


Now you can reference a.owernid anywhere in that someAction method on the controller, and use code like this to store it to owername:

public PageReferene someAction() {
    ownername = a.ownerid;
}

",Willem Mulder,https://salesforce.stackexchange.com/users/4989,http://salesforce.stackexchange.com/questions/38651/how-to-pass-value-from-visual-force-page-inputfield-to-controller,TECHNOLOGY,salesforce.stackexchange.com,0.8888888888888888,0.7777777777777778,0.0,0.6666666666666666,0.3333333333333333,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.0,0.3333333333333333,0.8888888888888888,How do I pass values from the visual force page (inputfield) to the controller?,"I have created a Vf page from which i need to fetch the value of new owner and need to save the value in property defined in controller:

Following is my vf page code:

&lt;apex:pageBlockSection&gt;
    &lt;apex:InputField label=""user"" value=""{!a.ownerid}""/&gt;
&lt;/apex:pageBlockSection&gt;


here a is object of opportunity

Controller code:

used one property to store the value:

public string ownername {get;set;}


Note: user will input the value through lookup field.

Any suggestions on this?
","The inputfield will have a direct binding to the a.ownerid.

This binding is two-directional, so that means two things:


When the page loads, the input field will be filled with a.ownerid.
The reverse is also true: the value of the input field will be saved to a.ownerid. If you had a commandButton with an action that is executed on the controller, the a.ownerid will by then have the value that the user entered on the Visualforce page before the user clicked the commandButton.


Update your Visualforce code like so to include that commandButton

&lt;apex:pageBlockSection&gt;
    &lt;apex:InputField label=""user"" value=""{!a.ownerid}""/&gt;
    &lt;apex:commandButton action=""{!someAction}"" value=""Save""/&gt;
&lt;/apex:pageBlockSection&gt;


Now you can reference a.owernid anywhere in that someAction method on the controller, and use code like this to store it to owername:

public PageReferene someAction() {
    ownername = a.ownerid;
}

"
2099,2099,3341,Is there any performance difference between ++i and i++ in C#?,"Is there any performance difference between using something like

for(int i = 0; i &lt; 10; i++) { ... }


and

for(int i = 0; i &lt; 10; ++i) { ... }


or is the compiler able to optimize in such a way that they are equally fast in the case where they are functionally equivalent?

Edit:
This was asked because I had a discussion with a co-worker about it, not because I think its a useful optimization in any practical sense. It is largely academic. 
",Anton,https://stackoverflow.com/users/341413,"As Jim Mischel has shown, the compiler will generate identical MSIL for the two ways of writing the for-loop.

But that is it then: there is no reason to speculate about the JIT or perform speed-measurements. If the two lines of code generate identical MSIL, not only will they perform identically, they are effectively identical.

No possible JIT would be able to distinguish between the loops, so the generated machine code must necessarily be identical, too.
",Rasmus Faber,https://stackoverflow.com/users/5542,http://stackoverflow.com/questions/467322/is-there-any-performance-difference-between-i-and-i-in-c,STACKOVERFLOW,stackoverflow.com,1.0,0.8888888888888888,0.0,0.6666666666666666,1.0,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,1.0,Is there any performance difference between + + I and I + + in C + +?,"Is there any performance difference between using something like

for(int i = 0; i &lt; 10; i++) { ... }


and

for(int i = 0; i &lt; 10; ++i) { ... }


or is the compiler able to optimize in such a way that they are equally fast in the case where they are functionally equivalent?

Edit:
This was asked because I had a discussion with a co-worker about it, not because I think its a useful optimization in any practical sense. It is largely academic. 
","As Jim Mischel has shown, the compiler will generate identical MSIL for the two ways of writing the for-loop.

But that is it then: there is no reason to speculate about the JIT or perform speed-measurements. If the two lines of code generate identical MSIL, not only will they perform identically, they are effectively identical.

No possible JIT would be able to distinguish between the loops, so the generated machine code must necessarily be identical, too.
"
6053,6053,9608,How can I write HTML and send as an email?,"I want to send HTML email from my Outlook or Yahoo, Gmail, Hotmail. I wasn't able to find any such option where I could write HTML which will then be rendered at the receiver's end. How can I do that?
",Umair Jabbar,https://webapps.stackexchange.com/users/2676,"For Outlook, you can use Bells &amp; Whistles for Outlook
",KuroNeko,https://webapps.stackexchange.com/users/74581,http://webapps.stackexchange.com/questions/7932/how-can-i-write-html-and-send-as-an-email,TECHNOLOGY,webapps.stackexchange.com,0.7777777777777778,0.7777777777777778,0.0,0.0,0.3333333333333333,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.7777777777777778,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.7777777777777778,0.6,0.3333333333333333,0.6666666666666666,0.0,0.7777777777777778,How do I write HTML and send it as an email?,"I want to send HTML messages from my outlook or Yahoo, Gmail, hotmail. I can't find any of these options, I can write HTML and then render it at the end of the receiver. What shall I do?","For outlook, you can use bells & walls for Outlook"
3993,3993,6373,How to show the integers have same cardinality as the natural numbers?,"How would I show the following have a bijection. Which is one to one and onto ofcourse.

$\mathbb{Z}\rightarrow \mathbb{N}$

I know I need to find a function. But I do not see the pattern that makes integer go to natural. I already did this problem from natural to integer but now I want to see it done this way.

I have listed some numbers

$,..,-4,-3,-2,-1,0,1,2,3,4,5,6,7,8,9,..$

$1,2,3,4,5,6,7,8,9,10,11,12,13,14,.$
",Fernando Martinez,https://math.stackexchange.com/users/37244,"For example
$$f:\mathbb Z\rightarrow\mathbb N$$
$$ f(n)=\begin{cases} 2n+1 \text{ if } n\geq0 \\ -2n \text{ if } n&lt;0\end{cases}$$
",nitzpo,https://math.stackexchange.com/users/114964,http://math.stackexchange.com/questions/873927/how-to-show-the-integers-have-same-cardinality-as-the-natural-numbers,SCIENCE,math.stackexchange.com,0.6666666666666666,0.6666666666666666,0.0,0.3333333333333333,1.0,0.6666666666666666,0.6666666666666666,0.4444444444444444,0.3333333333333333,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,0.7777777777777778,0.4444444444444444,0.7777777777777778,0.7777777777777778,0.6666666666666667,0.6666666666666666,0.0,0.0,0.6666666666666666,How to show that integers have the same cardinality as natural numbers?,"How would I show the following have a bijection. Which is one to one and onto ofcourse.

$\mathbb{Z}\rightarrow \mathbb{N}$

I know I need to find a function. But I do not see the pattern that makes integer go to natural. I already did this problem from natural to integer but now I want to see it done this way.

I have listed some numbers

$,..,-4,-3,-2,-1,0,1,2,3,4,5,6,7,8,9,..$

$1,2,3,4,5,6,7,8,9,10,11,12,13,14,.$
","For example
$$f:\mathbb Z\rightarrow\mathbb N$$
$$ f(n)=\begin{cases} 2n+1 \text{ if } n\geq0 \\ -2n \text{ if } n&lt;0\end{cases}$$
"
5154,5154,8194,What are the variable costs for an information company?,"For a company like GoodGuide, who make their money not by selling a hard product (with investment costs etc) but by selling product placement and business intelligence, what are their variable costs?

I understand what variable costs are for a pizza shop, where the costs vary based on the number of pizzas made and sold. More product = higher costs.

But in general, how do you talk about variable costs for a company that provides information?
",CodyBugstein,https://money.stackexchange.com/users/9863,"Marketing, namely advertising (Facebook, Google ads, maybe magazines, etc.)

Despite all the nice words about ""healthy, green, and socially responsible"", the business of this company (and many, many similar ones) is not ""providing information"". It's affiliate marketing - getting people to click through to retail sites and buy stuff, on which the company earns commissions (often they also get paid for registrations).

In a very real sense, their product is customers. They sell paying customers to the retail sites, and before that, they basically have to buy ""raw customers"" through advertising. The times when you could rely on getting enough people to visit your website for free are largely over - there is too much competition for peoples' attention. They can only be profitable if they can get the raw customers cheap enough, and can convert enough of them to paying customers. 

And this is really how it's talked about internally, in what is by now a highly organized industry: key performance measures are CPC (how much does it cost to get someone to come to your website), conversion rate (what percentage of visitors register) and ARPU (average revenue per user).
",Michael Borgwardt,https://money.stackexchange.com/users/9729,http://money.stackexchange.com/questions/30705/what-are-the-variable-costs-for-an-information-company,LIFE_ARTS,money.stackexchange.com,0.8888888888888888,0.8888888888888888,0.0,0.6666666666666666,1.0,0.6666666666666666,0.6666666666666666,0.7777777777777778,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.8,0.0,0.3333333333333333,1.0,1.0,What is the variable cost of an information company?,"For a company like GoodGuide, who make their money not by selling a hard product (with investment costs etc) but by selling product placement and business intelligence, what are their variable costs?

I understand what variable costs are for a pizza shop, where the costs vary based on the number of pizzas made and sold. More product = higher costs.

But in general, how do you talk about variable costs for a company that provides information?
","Marketing, namely advertising (Facebook, Google ads, maybe magazines, etc.)

Despite all the nice words about ""healthy, green, and socially responsible"", the business of this company (and many, many similar ones) is not ""providing information"". It's affiliate marketing - getting people to click through to retail sites and buy stuff, on which the company earns commissions (often they also get paid for registrations).

In a very real sense, their product is customers. They sell paying customers to the retail sites, and before that, they basically have to buy ""raw customers"" through advertising. The times when you could rely on getting enough people to visit your website for free are largely over - there is too much competition for peoples' attention. They can only be profitable if they can get the raw customers cheap enough, and can convert enough of them to paying customers. 

And this is really how it's talked about internally, in what is by now a highly organized industry: key performance measures are CPC (how much does it cost to get someone to come to your website), conversion rate (what percentage of visitors register) and ARPU (average revenue per user).
"
3598,3598,5743,Why did OCP build Robocop?,"It seems like building the Robocop was a really stupid business approach:


You can't build them on industrial scale (to put it somewhat insensitively, OCP didn't have a ready supply of highly trained and freshly killed police officers)

So, Robocop seemed like a prototype that could never have entered production. Total waste of R&amp;D money.
And having a police brain (because he already know police procedure) seems not necessary since at the same time OCP could build fully AI robots (from robot chicken, flawed as it was, in Robocop 1, to Ninja Androids in Robocop 3).

",DVK-on-Ahch-To,https://scifi.stackexchange.com/users/976,"Robocop was their ""Plan B"". ""Plan A"" was ED-209. As explained by Johnson (in the script):


  When ED209 ran into serious delays the old man ordered a backup plan. Probably to light a fire under Jones' ass. Old Bob here gets the assignment. Nobody in Security Concepts takes it seriously.


Note that part at the end which agrees with your question - initially the Robocop program was not taken seriously.

However, when the ED-209 spectacularly failed during a boardroom meeting, Bob Morton took the initiative:


  Old Man: Dick, I'm very disappointed.
  
  Dick Jones: I'm sure it's only a glitch, a temporary setback.
  
  Old Man: You call this a glitch? We're scheduled to begin construction in six months. This ""temporary setback"" could cost us millions in interest costs alone.
  
  Bob Morton: Not necessarily, sir. You may be aware of the Robocop program designed by myself at Security Concepts as a contingency against just this sort of thing.
  
  Dick Jones: Thank you for your concern. This is something we could...
  
  Old Man: Wait a minute. Dick! Maybe what we need here is a fresh perspective. Tell me about your plan. How long will it take?
  
  Bob Jones: We've restructured the police department and placed prime candidates according to risk factor. I'm confident we can go to prototype within 90 days.
  
  Old Man: Very good. Get your staff together. I'll expect a full presentation in my office in 20  minutes.
  
  Bob Morton: Thank you, sir.


Nevertheless, after only one month on the streets, Bob Morton predicted:


  Here at Security Concepts, we're predicting the end of crime in Old Detroit within 40 days. There's a new guy in town. His name's RoboCop.


So, even though he couldn't be mass produced, that wasn't necessary. On his own, Robocop dramatically reduced crime, not least by killing the crime lord Clarence Boddicker and drug baron Sal and shutting down their respective operations.

This also matches one of the themes of the film - American corporations' big, mass-produced machines (the ED-209 and 6000 SUX) versus the underdogs, most notably Alex Murphy / Robocop.

The script link has some errors. I've tried to patch it from memory but there might be a few words wrong.
",Wikis,https://scifi.stackexchange.com/users/143,http://scifi.stackexchange.com/questions/46596/why-did-ocp-build-robocop,LIFE_ARTS,scifi.stackexchange.com,1.0,1.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.0,0.6666666666666666,0.4444444444444444,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,0.8888888888888888,Why does OCP build Robocop?,"It seems like building the Robocop was a really stupid business approach:


You can't build them on industrial scale (to put it somewhat insensitively, OCP didn't have a ready supply of highly trained and freshly killed police officers)

So, Robocop seemed like a prototype that could never have entered production. Total waste of R&amp;D money.
And having a police brain (because he already know police procedure) seems not necessary since at the same time OCP could build fully AI robots (from robot chicken, flawed as it was, in Robocop 1, to Ninja Androids in Robocop 3).

","Robocop was their ""Plan B"". ""Plan A"" was ED-209. As explained by Johnson (in the script):


  When ED209 ran into serious delays the old man ordered a backup plan. Probably to light a fire under Jones' ass. Old Bob here gets the assignment. Nobody in Security Concepts takes it seriously.


Note that part at the end which agrees with your question - initially the Robocop program was not taken seriously.

However, when the ED-209 spectacularly failed during a boardroom meeting, Bob Morton took the initiative:


  Old Man: Dick, I'm very disappointed.
  
  Dick Jones: I'm sure it's only a glitch, a temporary setback.
  
  Old Man: You call this a glitch? We're scheduled to begin construction in six months. This ""temporary setback"" could cost us millions in interest costs alone.
  
  Bob Morton: Not necessarily, sir. You may be aware of the Robocop program designed by myself at Security Concepts as a contingency against just this sort of thing.
  
  Dick Jones: Thank you for your concern. This is something we could...
  
  Old Man: Wait a minute. Dick! Maybe what we need here is a fresh perspective. Tell me about your plan. How long will it take?
  
  Bob Jones: We've restructured the police department and placed prime candidates according to risk factor. I'm confident we can go to prototype within 90 days.
  
  Old Man: Very good. Get your staff together. I'll expect a full presentation in my office in 20  minutes.
  
  Bob Morton: Thank you, sir.


Nevertheless, after only one month on the streets, Bob Morton predicted:


  Here at Security Concepts, we're predicting the end of crime in Old Detroit within 40 days. There's a new guy in town. His name's RoboCop.


So, even though he couldn't be mass produced, that wasn't necessary. On his own, Robocop dramatically reduced crime, not least by killing the crime lord Clarence Boddicker and drug baron Sal and shutting down their respective operations.

This also matches one of the themes of the film - American corporations' big, mass-produced machines (the ED-209 and 6000 SUX) versus the underdogs, most notably Alex Murphy / Robocop.

The script link has some errors. I've tried to patch it from memory but there might be a few words wrong.
"
4641,4641,7360,How to get <img> src from CDATA in RSS?,"I am fetching data from RSS feed with Magpie.
$rss[description]  contains CDATA with html elements:  

&lt;![CDATA[  
&lt;div&gt;  
 &lt;a href='url'&gt;  
  &lt;img src='img_url' alt='aaa' title='bbb' border='0' width='116' height='116'&gt;  
 &lt;/a&gt;  
&lt;/div&gt;]]&gt;  
Some other text  


How can I fetch ""img_url"" from this?  Is preg_match() the only way? Maybe I can use simpleXML?
",lvil,https://stackoverflow.com/users/533861,"CDATA you have is a string containing HTML. So first treat it as text, but since this text is meant to contain HTML, parse this text using solution appropriate for parsing HTML.

In other words: use appropriate tool (HTML parser) for the job (parsing HTML).

There are already existing solutions for parsing HTML in PHP - eg. see answers to this questions:


How to parse and process HTML with PHP?
Robust, Mature HTML Parser for PHP.


So, basically, you already are able to get the HTML string from your XML. Now parse the HTML and get source of the image using some of the solutions mentioned above.

Using preg_match() for parsing HTML is not a good idea, as it would need to be very complex to do a simple thing HTML parser is suitable for.
",Tadeck,https://stackoverflow.com/users/548696,http://stackoverflow.com/questions/8838742/how-to-get-img-src-from-cdata-in-rss,STACKOVERFLOW,stackoverflow.com,1.0,0.7777777777777778,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.6666666666666666,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.3333333333333333,0.3333333333333333,1.0,How to get SRC from CDATA in RSS?,"I am fetching data from RSS feed with Magpie.
$rss[description]  contains CDATA with html elements:  

&lt;![CDATA[  
&lt;div&gt;  
 &lt;a href='url'&gt;  
  &lt;img src='img_url' alt='aaa' title='bbb' border='0' width='116' height='116'&gt;  
 &lt;/a&gt;  
&lt;/div&gt;]]&gt;  
Some other text  


How can I fetch ""img_url"" from this?  Is preg_match() the only way? Maybe I can use simpleXML?
","CDATA you have is a string containing HTML. So first treat it as text, but since this text is meant to contain HTML, parse this text using solution appropriate for parsing HTML.

In other words: use appropriate tool (HTML parser) for the job (parsing HTML).

There are already existing solutions for parsing HTML in PHP - eg. see answers to this questions:


How to parse and process HTML with PHP?
Robust, Mature HTML Parser for PHP.


So, basically, you already are able to get the HTML string from your XML. Now parse the HTML and get source of the image using some of the solutions mentioned above.

Using preg_match() for parsing HTML is not a good idea, as it would need to be very complex to do a simple thing HTML parser is suitable for.
"
796,796,1262,passing data from javascript to php using Jquery,"Maybe this question has been asked before but I am struggling in doing this. I have got a php  file which does not include any piece of php code (might be in the future),it includes just javascript and some html. What I want to do is clicking a button in this php file to send some amount of data to another php file.
put it this way..

1-I have got a saveProfile function in a.php and a button is calling this function

  function  saveProfile (){  
      var variableD = 'sample data';
      $.post(""dbConn.php"", { js: variableD});
  }


2-I have got another php which is called dbConn.php that receives data and stores in a database table.

I have found so many examples. I have applied them but it still does not work and is driving  me nuts. I am a java programmer but new in php.
Any help is appreciated.give me some clean sample code or if you see any mistake please kindly warn me. Thanks to all in advance...

Regards.
Ozlem.
",Ozlem,https://stackoverflow.com/users/485941,"Thanks for all the answers. I have solved the problem. The data had being passes but I was not able to handle it properly. I just add a dummy code to test it.It worked. I will upload the code after I have finished.Thanks to all. 
",Ozlem,https://stackoverflow.com/users/485941,http://stackoverflow.com/questions/4011160/passing-data-from-javascript-to-php-using-jquery,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.3333333333333333,0.0,0.0,1.0,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.7777777777777778,1.0,0.3333333333333333,1.0,0.6666666666666666,0.6,0.0,0.0,1.0,0.6666666666666666,Using jQuery to transfer data from JavaScript to PHP,"Maybe this question has been asked before but I am struggling in doing this. I have got a php  file which does not include any piece of php code (might be in the future),it includes just javascript and some html. What I want to do is clicking a button in this php file to send some amount of data to another php file.
put it this way..

1-I have got a saveProfile function in a.php and a button is calling this function

  function  saveProfile (){  
      var variableD = 'sample data';
      $.post(""dbConn.php"", { js: variableD});
  }


2-I have got another php which is called dbConn.php that receives data and stores in a database table.

I have found so many examples. I have applied them but it still does not work and is driving  me nuts. I am a java programmer but new in php.
Any help is appreciated.give me some clean sample code or if you see any mistake please kindly warn me. Thanks to all in advance...

Regards.
Ozlem.
","Thanks for all the answers. I have solved the problem. The data had being passes but I was not able to handle it properly. I just add a dummy code to test it.It worked. I will upload the code after I have finished.Thanks to all. 
"
2447,2447,3906,Can EE handle Millions of Users?,"I’m new to the expression engine project at our business. We are being acquired by a large company and they’re worried that expression engine cannot handle traffic for a exp_members table of 10M, and concurrent connections at about 10k.

I know that most people will naturally ask “It all depends on server resources, and how big is your database…”, and we can always have bigger boxes, I’m not really interested in theoretical limits, my question is a bit more practical than that. 

Has anyone had experience with using EE for 5+ millions of users and approx 10k concurrent users, and what has been your experience been with it?

Please help me understand your experience.

It’s a classic “Executive Decision makers (and what they think they understand from a sales slick”
versus Coders and EE fans.

Thank you.
",titicus james,https://expressionengine.stackexchange.com/users/3809,"There's an old post (from 2012) here which might go some way to answer the question. You'll note that there are some major sites there.

Ultimately, as you've acknowledged, the matter is one of resources and network infrastructure and not one of software. No system will cope with 10K concurrent connections unless the network is built in such a way as to allow it.
",foamcow,https://expressionengine.stackexchange.com/users/159,http://expressionengine.stackexchange.com/questions/26842/can-ee-handle-millions-of-users,TECHNOLOGY,expressionengine.stackexchange.com,0.7777777777777778,0.5555555555555556,0.0,0.3333333333333333,0.6666666666666666,0.0,0.6666666666666666,0.5555555555555556,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.8888888888888888,0.6666666666666666,0.3333333333333333,0.8888888888888888,0.6666666666666666,0.4666666666666667,0.0,0.0,0.6666666666666666,1.0,Can EE handle millions of users?,"I’m new to the expression engine project at our business. We are being acquired by a large company and they’re worried that expression engine cannot handle traffic for a exp_members table of 10M, and concurrent connections at about 10k.

I know that most people will naturally ask “It all depends on server resources, and how big is your database…”, and we can always have bigger boxes, I’m not really interested in theoretical limits, my question is a bit more practical than that. 

Has anyone had experience with using EE for 5+ millions of users and approx 10k concurrent users, and what has been your experience been with it?

Please help me understand your experience.

It’s a classic “Executive Decision makers (and what they think they understand from a sales slick”
versus Coders and EE fans.

Thank you.
","There's an old post (from 2012) here which might go some way to answer the question. You'll note that there are some major sites there.

Ultimately, as you've acknowledged, the matter is one of resources and network infrastructure and not one of software. No system will cope with 10K concurrent connections unless the network is built in such a way as to allow it.
"
5414,5414,8598,Why is Senketsu the only Kamui that can talk?,"There are three Kamui in the show: Senketsu, Junketsu and Shinra-Kōketsu (Omnisilk Kōketsu). 



Shinra-Kōketsu is on another level in comparison to other Kamui, but Junketsu is the same with Senketsu, but he never talk. Is Senketsu different from other Kamui?
",Darjeeling,https://anime.stackexchange.com/users/2869,"There might be many reasons:

First, Senketsu was created specially for Ryuuko. This might have created link, that allows them to understand each other. It is clear that Senketsu doesn't really ""talk"" using his mouth. It is more like telepathy. This telepathic link might have been created either intentionally or accidentaly when Senketsu was made.

Second, there is question of relationships. Ryuuko and Senketsu are partners or friends. For them, it is symbiotic relationship. Satsuki on the other hand uses her willpower to dominate Junketsu so it can be used as a tool. And as such, there was no reason for her to listen to it, so even if Junketsu did talk, Satsuki would simply make it shut up, because Junketsu talking isn't what she need. Ryuuko and Senketsu were partners so it was obvious they would talk to each other.

And last is simply about production: The creators simply didn't think of Junketsu as character. And as such, they didn't give it any voice. Senketsu was individual character from early start and as such it made sense to make him talk. And as such, he helped character development of Ryuuko. Junketsu on the other side was just something used by Satsuki.
",Euphoric,https://anime.stackexchange.com/users/115,http://anime.stackexchange.com/questions/10047/why-is-senketsu-the-only-kamui-that-can-talk,CULTURE,anime.stackexchange.com,1.0,0.8888888888888888,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.4444444444444444,0.6666666666666666,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,0.8888888888888888,Why is senktu the only talking turtle well?,"There are three Kamui in the show: Senketsu, Junketsu and Shinra-Kōketsu (Omnisilk Kōketsu). 



Shinra-Kōketsu is on another level in comparison to other Kamui, but Junketsu is the same with Senketsu, but he never talk. Is Senketsu different from other Kamui?
","There might be many reasons:

First, Senketsu was created specially for Ryuuko. This might have created link, that allows them to understand each other. It is clear that Senketsu doesn't really ""talk"" using his mouth. It is more like telepathy. This telepathic link might have been created either intentionally or accidentaly when Senketsu was made.

Second, there is question of relationships. Ryuuko and Senketsu are partners or friends. For them, it is symbiotic relationship. Satsuki on the other hand uses her willpower to dominate Junketsu so it can be used as a tool. And as such, there was no reason for her to listen to it, so even if Junketsu did talk, Satsuki would simply make it shut up, because Junketsu talking isn't what she need. Ryuuko and Senketsu were partners so it was obvious they would talk to each other.

And last is simply about production: The creators simply didn't think of Junketsu as character. And as such, they didn't give it any voice. Senketsu was individual character from early start and as such it made sense to make him talk. And as such, he helped character development of Ryuuko. Junketsu on the other side was just something used by Satsuki.
"
1849,1849,2933,Solspace Calendar ICS for single event,"Is it possible to have an .ics file to download a single event in a calendar?  right now downloading the .ics downloads the entire calendar

{exp:calendar:icalendar
event_id=""{segment_3}"" dynamic=""on""
{/exp:calendar:icalendar}


I figured something like the above would only export the one event using the dynamic on and event id but it downloads the entire calendar
",Peter Eastwood,https://expressionengine.stackexchange.com/users/451,"Well..

https://solspace.com/docs/calendar/icalendar/


  All of the parameters listed in Calendar:Events are available for use here.


and then..

https://solspace.com/docs/calendar/events/#event_id

Have you tried hard coding a known (and open) event_id?
",jrothafer,https://expressionengine.stackexchange.com/users/3579,http://expressionengine.stackexchange.com/questions/32559/solspace-calendar-ics-for-single-event,TECHNOLOGY,expressionengine.stackexchange.com,1.0,0.3333333333333333,0.0,0.0,1.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.6,0.0,1.0,0.0,1.0,Solspace calendar IC for individual events,"Is it possible to have an .ics file to download a single event in a calendar?  right now downloading the .ics downloads the entire calendar

{exp:calendar:icalendar
event_id=""{segment_3}"" dynamic=""on""
{/exp:calendar:icalendar}


I figured something like the above would only export the one event using the dynamic on and event id but it downloads the entire calendar
","Well..

https://solspace.com/docs/calendar/icalendar/


  All of the parameters listed in Calendar:Events are available for use here.


and then..

https://solspace.com/docs/calendar/events/#event_id

Have you tried hard coding a known (and open) event_id?
"
3974,3974,6343,Swift project using PHP web service,"I was hoping for someone to review my current project, which was created in Swift and uses a PHP web service. I'm not worried about UI elements, as this is just a 'test' project, but I'm concerned about two things: using the best practices and security. I'm concerned that the SQL query is not safe, among other things.

user.swift

import Foundation

class User: NSObject {

    var firstName: String?
    var lastName: String?
    var username: String
    var password: String
    var email: String?

    var recievedJSON: NSMutableData = NSMutableData()
    var userData: [[String: String]]!

    var verified: Bool = false

    required init(username: String, password: String) {
        self.username = username
        self.password = password
    }

    init(firstName: String, lastName: String, username: String, password: String, email: String) {
        self.firstName = firstName
        self.lastName = lastName
        self.username = username
        self.password = password
        self.email = email
    }

    func attemptRegister() {
        var variables: [String] = [""firstname="" + self.firstName! + ""&amp;""]
        variables.append(""lastname="" + self.lastName! + ""&amp;"")
        variables.append(""username="" + self.username + ""&amp;"")
        variables.append(""password="" + self.password + ""&amp;"")
        variables.append(""email="" + self.email!)
        request(""https://codekaufman.com/register.php"", variables: variables)
    }

    func attemptSignIn() {
        var variables: [String] = [""username="" + self.username + ""&amp;""]
        variables.append(""password="" + self.password)
        request(""https://codekaufman.com/login.php"", variables: variables)
        println(""Attempting sign-in..."")
    }

    private func request(urlPath: String, variables: [String]?) {
        var url: NSURL = NSURL(string: urlPath)!
        var request: NSMutableURLRequest = NSMutableURLRequest(URL: url)

        if(variables != nil) {
            request.HTTPMethod = ""POST""

            var bodyData: NSString = """"
            for item in variables! {
                bodyData = bodyData + NSString(string: item)
            }

            request.HTTPBody = bodyData.dataUsingEncoding(NSUTF8StringEncoding)
        }

        var connection: NSURLConnection = NSURLConnection(request: request, delegate: self, startImmediately: false)!
        connection.start()
        println(""Connection started."")
    }

    func connection(connection: NSURLConnection!, didReceiveData data: NSData!){
        self.recievedJSON.appendData(data)
        println(""Data recieved."")
    }

    func connectionDidFinishLoading(connection: NSURLConnection!) {
        userData = parseJSON(recievedJSON)

        if(userData != nil) {
            println(""Data recieved:"")
            println(userData[0])
        } else {
            println(""No data recieved."")
        }

    }

    func parseJSON(inputData: NSData) -&gt; [[String: String]]? {
        var error: NSError?
        var userData: [[String: String]]!
        userData = NSJSONSerialization.JSONObjectWithData(inputData, options: NSJSONReadingOptions.MutableContainers, error: &amp;error) as? [[String: String]]

        if (userData != nil) {
            println(""NSData had data, printing and returning."")
            println(userData)
            return userData
        } else {
            println(""NSData empty, returning nil."")
            return nil
        }
    }

}


register.php

&lt;?php

error_reporting(E_ALL);
ini_set('display errors', 1);

// Don't worry about this, I'm aware of the security issue. :)
$username = '';
$password = '';

try {
    $dbh = new PDO('mysql:host=localhost; dbname=codeggdj_users', $username, $password);
    $dbh-&gt;setAttribute(PDO::ATTR_ERRMODE, PDO::ERRMODE_EXCEPTION);

    $recievedUsername = $_POST['username'];
    $recievedPassword = password_hash($_POST['password'], PASSWORD_BCRYPT);
    $recievedFirstName = $_POST['firstname'];
    $recievedLastName = $_POST['lastname'];

    $sth = $dbh-&gt;prepare(""INSERT INTO users (username, password, first_name, last_name) VALUES (?, ?, ?, ?)"");
    $sth-&gt;execute([$recievedUsername, $recievedPassword, $recievedFirstName, $recievedLastName]);
} catch(PDOException $e) {
    echo $e-&gt;getMessage();
}

?&gt;


login.php

&lt;?php

error_reporting(E_ALL);
ini_set('display errors', 1);

// Don't worry about this, I'm aware of the security issue. :)
$username = '';
$password = '';

try {
    $dbh = new PDO('mysql:host=localhost; dbname=codeggdj_users', $username, $password);
    $dbh-&gt;setAttribute(PDO::ATTR_ERRMODE, PDO::ERRMODE_EXCEPTION);

    $recievedUsername = $_POST['username'];
    $recievedPassword = $_POST['password'];

    $sth = $dbh-&gt;prepare('SELECT password FROM users WHERE username = ?');
    $sth-&gt;execute([$recievedUsername]);

    if($sth-&gt;rowCount()) {
       $row = $sth-&gt;fetch(PDO::FETCH_OBJ);

       if(password_verify($recievedPassword, $row-&gt;password)) {
           $sth = $dbh-&gt;prepare('SELECT id, username, first_name, last_name FROM users WHERE username = ?');
           $sth-&gt;execute([$recievedUsername]);

           echo json_encode($row = $sth-&gt;fetchAll(PDO::FETCH_ASSOC));
       } else {
           echo 'Incorrect Password';
       }
    } else {
       echo 'Incorrect Username';
    }

} catch(PDOException $e) {
    echo $e-&gt;getMessage();
}

?&gt;

",Jeffrey,https://codereview.stackexchange.com/users/61707,"
  I'm concerned that the SQL query is not safe, among other things.


Well, you're right to be concerned.  I don't know much about PHP (basically nothing), so I'll let someone who does know about PHP comment about that half of your code.

But from the Swift end, we're passing the password as plaintext.  We really shouldn't be doing this.  When we send passwords over any sort of networking request, the password should be encrypted in some way.  MD5 is a common approach.  I'm not a safety expert and couldn't say one way or the other whether or not MD5 is still appropriate or not, but anything is better than passing completely unencrypted passwords.



func attemptRegister() {
    var variables: [String] = [""firstname="" + self.firstName! + ""&amp;""]
    variables.append(""lastname="" + self.lastName! + ""&amp;"")
    variables.append(""username="" + self.username + ""&amp;"")
    variables.append(""password="" + self.password + ""&amp;"")
    variables.append(""email="" + self.email!)
    request(""https://codekaufman.com/register.php"", variables: variables)
}


This method will crash every time it's call and one of your optional properties is nil.

If these properties truly are optional, then we need to optionally unwrap them:

if let email = self.email {
    variables.append(""email="" + email)
}


And moreover, appending the &amp; to the end of each of these variables here seems really contrived.

Moreover, why do we need to build the array here and pass it into another method... when the array is built of nothing more than instance variables that the other method has access to?

To be honest, if this is me, I think I completely rethink and restructure this class.  You call this class User, but it's nothing more than a utility for signing in or registering with your service.  How usable is this object after the user has either signed in or registered?  And should we REALLY be storing a password for as long as this object is kept around?

Realistically, our username/password (and in the case of registering, the other information) should be passed to a function, even if it's a class function of the user class.  As soon as we send the information to the web service, we should forget about it within the app.  

And then, assuming a successful response from the web service, our User class should be instantiated with the information about this user that our app actually needs to use.  A userid?  Display name, profile picture, etc?  These are the things our User class should keep as instance variables--the information that our application needs AFTER the user has successfully signed in or registered.  And we definitely should not be hanging on to information we need for signing in or registering (except any of this information that is also information that our app needs to function).



This bit of code by the way is a little redundant:

if (userData != nil) {
    println(""NSData had data, printing and returning."")
    println(userData)
    return userData
} else {
    println(""NSData empty, returning nil."")
    return nil
}


The only reason to actually split this into an if/else is because you want to print this stuff out for diagnostic reasons.  But realistically, in the final version of your app, you won't want to print this stuff out... and as such, the if/else could be eliminated.

As such, I'd rewrite this section as:

#if DEBUG
    if (userData != nil) {
        println(""NSData had data, printing and returning."")
        println(userData)
    } else {
        println(""NSData empty, returning nil."")
    }
#endif

return userData


We don't need to return a literal nil when userData is nil.  If userData is nil, then the statement return userData will already return nil for us!
",nhgrif,https://codereview.stackexchange.com/users/36366,http://codereview.stackexchange.com/questions/74732/swift-project-using-php-web-service,TECHNOLOGY,codereview.stackexchange.com,1.0,0.3333333333333333,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.5555555555555556,0.8888888888888888,0.6666666666666666,0.8888888888888888,0.8888888888888888,0.6666666666666667,1.0,0.0,0.0,0.8888888888888888,Swift project using PHP Web Services,"I was hoping for someone to review my current project, which was created in Swift and uses a PHP web service. I'm not worried about UI elements, as this is just a 'test' project, but I'm concerned about two things: using the best practices and security. I'm concerned that the SQL query is not safe, among other things.

user.swift

import Foundation

class User: NSObject {

    var firstName: String?
    var lastName: String?
    var username: String
    var password: String
    var email: String?

    var recievedJSON: NSMutableData = NSMutableData()
    var userData: [[String: String]]!

    var verified: Bool = false

    required init(username: String, password: String) {
        self.username = username
        self.password = password
    }

    init(firstName: String, lastName: String, username: String, password: String, email: String) {
        self.firstName = firstName
        self.lastName = lastName
        self.username = username
        self.password = password
        self.email = email
    }

    func attemptRegister() {
        var variables: [String] = [""firstname="" + self.firstName! + ""&amp;""]
        variables.append(""lastname="" + self.lastName! + ""&amp;"")
        variables.append(""username="" + self.username + ""&amp;"")
        variables.append(""password="" + self.password + ""&amp;"")
        variables.append(""email="" + self.email!)
        request(""https://codekaufman.com/register.php"", variables: variables)
    }

    func attemptSignIn() {
        var variables: [String] = [""username="" + self.username + ""&amp;""]
        variables.append(""password="" + self.password)
        request(""https://codekaufman.com/login.php"", variables: variables)
        println(""Attempting sign-in..."")
    }

    private func request(urlPath: String, variables: [String]?) {
        var url: NSURL = NSURL(string: urlPath)!
        var request: NSMutableURLRequest = NSMutableURLRequest(URL: url)

        if(variables != nil) {
            request.HTTPMethod = ""POST""

            var bodyData: NSString = """"
            for item in variables! {
                bodyData = bodyData + NSString(string: item)
            }

            request.HTTPBody = bodyData.dataUsingEncoding(NSUTF8StringEncoding)
        }

        var connection: NSURLConnection = NSURLConnection(request: request, delegate: self, startImmediately: false)!
        connection.start()
        println(""Connection started."")
    }

    func connection(connection: NSURLConnection!, didReceiveData data: NSData!){
        self.recievedJSON.appendData(data)
        println(""Data recieved."")
    }

    func connectionDidFinishLoading(connection: NSURLConnection!) {
        userData = parseJSON(recievedJSON)

        if(userData != nil) {
            println(""Data recieved:"")
            println(userData[0])
        } else {
            println(""No data recieved."")
        }

    }

    func parseJSON(inputData: NSData) -&gt; [[String: String]]? {
        var error: NSError?
        var userData: [[String: String]]!
        userData = NSJSONSerialization.JSONObjectWithData(inputData, options: NSJSONReadingOptions.MutableContainers, error: &amp;error) as? [[String: String]]

        if (userData != nil) {
            println(""NSData had data, printing and returning."")
            println(userData)
            return userData
        } else {
            println(""NSData empty, returning nil."")
            return nil
        }
    }

}


register.php

&lt;?php

error_reporting(E_ALL);
ini_set('display errors', 1);

// Don't worry about this, I'm aware of the security issue. :)
$username = '';
$password = '';

try {
    $dbh = new PDO('mysql:host=localhost; dbname=codeggdj_users', $username, $password);
    $dbh-&gt;setAttribute(PDO::ATTR_ERRMODE, PDO::ERRMODE_EXCEPTION);

    $recievedUsername = $_POST['username'];
    $recievedPassword = password_hash($_POST['password'], PASSWORD_BCRYPT);
    $recievedFirstName = $_POST['firstname'];
    $recievedLastName = $_POST['lastname'];

    $sth = $dbh-&gt;prepare(""INSERT INTO users (username, password, first_name, last_name) VALUES (?, ?, ?, ?)"");
    $sth-&gt;execute([$recievedUsername, $recievedPassword, $recievedFirstName, $recievedLastName]);
} catch(PDOException $e) {
    echo $e-&gt;getMessage();
}

?&gt;


login.php

&lt;?php

error_reporting(E_ALL);
ini_set('display errors', 1);

// Don't worry about this, I'm aware of the security issue. :)
$username = '';
$password = '';

try {
    $dbh = new PDO('mysql:host=localhost; dbname=codeggdj_users', $username, $password);
    $dbh-&gt;setAttribute(PDO::ATTR_ERRMODE, PDO::ERRMODE_EXCEPTION);

    $recievedUsername = $_POST['username'];
    $recievedPassword = $_POST['password'];

    $sth = $dbh-&gt;prepare('SELECT password FROM users WHERE username = ?');
    $sth-&gt;execute([$recievedUsername]);

    if($sth-&gt;rowCount()) {
       $row = $sth-&gt;fetch(PDO::FETCH_OBJ);

       if(password_verify($recievedPassword, $row-&gt;password)) {
           $sth = $dbh-&gt;prepare('SELECT id, username, first_name, last_name FROM users WHERE username = ?');
           $sth-&gt;execute([$recievedUsername]);

           echo json_encode($row = $sth-&gt;fetchAll(PDO::FETCH_ASSOC));
       } else {
           echo 'Incorrect Password';
       }
    } else {
       echo 'Incorrect Username';
    }

} catch(PDOException $e) {
    echo $e-&gt;getMessage();
}

?&gt;

","
  I'm concerned that the SQL query is not safe, among other things.


Well, you're right to be concerned.  I don't know much about PHP (basically nothing), so I'll let someone who does know about PHP comment about that half of your code.

But from the Swift end, we're passing the password as plaintext.  We really shouldn't be doing this.  When we send passwords over any sort of networking request, the password should be encrypted in some way.  MD5 is a common approach.  I'm not a safety expert and couldn't say one way or the other whether or not MD5 is still appropriate or not, but anything is better than passing completely unencrypted passwords.



func attemptRegister() {
    var variables: [String] = [""firstname="" + self.firstName! + ""&amp;""]
    variables.append(""lastname="" + self.lastName! + ""&amp;"")
    variables.append(""username="" + self.username + ""&amp;"")
    variables.append(""password="" + self.password + ""&amp;"")
    variables.append(""email="" + self.email!)
    request(""https://codekaufman.com/register.php"", variables: variables)
}


This method will crash every time it's call and one of your optional properties is nil.

If these properties truly are optional, then we need to optionally unwrap them:

if let email = self.email {
    variables.append(""email="" + email)
}


And moreover, appending the &amp; to the end of each of these variables here seems really contrived.

Moreover, why do we need to build the array here and pass it into another method... when the array is built of nothing more than instance variables that the other method has access to?

To be honest, if this is me, I think I completely rethink and restructure this class.  You call this class User, but it's nothing more than a utility for signing in or registering with your service.  How usable is this object after the user has either signed in or registered?  And should we REALLY be storing a password for as long as this object is kept around?

Realistically, our username/password (and in the case of registering, the other information) should be passed to a function, even if it's a class function of the user class.  As soon as we send the information to the web service, we should forget about it within the app.  

And then, assuming a successful response from the web service, our User class should be instantiated with the information about this user that our app actually needs to use.  A userid?  Display name, profile picture, etc?  These are the things our User class should keep as instance variables--the information that our application needs AFTER the user has successfully signed in or registered.  And we definitely should not be hanging on to information we need for signing in or registering (except any of this information that is also information that our app needs to function).



This bit of code by the way is a little redundant:

if (userData != nil) {
    println(""NSData had data, printing and returning."")
    println(userData)
    return userData
} else {
    println(""NSData empty, returning nil."")
    return nil
}


The only reason to actually split this into an if/else is because you want to print this stuff out for diagnostic reasons.  But realistically, in the final version of your app, you won't want to print this stuff out... and as such, the if/else could be eliminated.

As such, I'd rewrite this section as:

#if DEBUG
    if (userData != nil) {
        println(""NSData had data, printing and returning."")
        println(userData)
    } else {
        println(""NSData empty, returning nil."")
    }
#endif

return userData


We don't need to return a literal nil when userData is nil.  If userData is nil, then the statement return userData will already return nil for us!
"
1691,1691,2675,Is this a bug? Angular removes object params when corresponding input is not valid,"Please see this:

http://plnkr.co/edit/soubKCayeLAqgDOel8AL?p=preview

&lt;!DOCTYPE html&gt;
&lt;html ng-app=""testApp""&gt;
  &lt;head&gt;
    &lt;script data-require=""angular.js@1.4.1"" data-semver=""1.4.1"" src=""https://code.angularjs.org/1.4.1/angular.js""&gt;&lt;/script&gt;
    &lt;script src=""script.js""&gt;&lt;/script&gt;
  &lt;/head&gt;
  &lt;body ng-controller=""testCtlr""&gt;
    &lt;pre&gt;{{contacts | json}}&lt;/pre&gt;
    &lt;div ng-repeat=""contact in contacts""&gt;
      &lt;div ng-repeat=""email in contact.emails""&gt;
        &lt;input type=""email"" name=""email"" ng-model=""email.email""&gt;
        &lt;input type=""text"" name=""text"" ng-model=""email.text""&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/body&gt;
&lt;/html&gt;


var app = angular.module('testApp', []);
app.controller('testCtlr', [""$scope"", function ($scope) {
    $scope.contacts = [
        {
            id:'',
            name:'',
            emails:[
                {
                    email: 'e1',
                    text: 'fghfgh'
                },
                {
                    email: 'e2',
                    text: 'hjkhjk'
                }
            ],
        }
    ];
}]);


you see if you change the text in the email text box it is removed from the obj unless it is a valid email...
",user1804318,https://stackoverflow.com/users/1804318,"Its not bug, its desired behaviourof angular, when value is not valid , it is not binded to ngModelController , 

https://docs.angularjs.org/api/ng/type/ngModel.NgModelController

But there is possibility to attach custom email validator ($parsers)
https://docs.angularjs.org/api/ng/type/ngModel.NgModelController#$parsers

You can push parser to array of parser so it will be executed as last, and return modelValue so you will ""override"" angular validator and bind invalidValue to ngModel.
",Milos Mosovsky,https://stackoverflow.com/users/4530419,http://stackoverflow.com/questions/31062344/is-this-a-bug-angular-removes-object-params-when-corresponding-input-is-not-val,STACKOVERFLOW,stackoverflow.com,1.0,0.6666666666666666,0.0,1.0,1.0,1.0,0.5555555555555556,0.5555555555555556,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.3333333333333333,1.0,0.5555555555555556,"Is this a bug? When the corresponding input is invalid, angular deletes the object parameter","Please see this:

http://plnkr.co/edit/soubKCayeLAqgDOel8AL?p=preview

&lt;!DOCTYPE html&gt;
&lt;html ng-app=""testApp""&gt;
  &lt;head&gt;
    &lt;script data-require=""angular.js@1.4.1"" data-semver=""1.4.1"" src=""https://code.angularjs.org/1.4.1/angular.js""&gt;&lt;/script&gt;
    &lt;script src=""script.js""&gt;&lt;/script&gt;
  &lt;/head&gt;
  &lt;body ng-controller=""testCtlr""&gt;
    &lt;pre&gt;{{contacts | json}}&lt;/pre&gt;
    &lt;div ng-repeat=""contact in contacts""&gt;
      &lt;div ng-repeat=""email in contact.emails""&gt;
        &lt;input type=""email"" name=""email"" ng-model=""email.email""&gt;
        &lt;input type=""text"" name=""text"" ng-model=""email.text""&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/body&gt;
&lt;/html&gt;


var app = angular.module('testApp', []);
app.controller('testCtlr', [""$scope"", function ($scope) {
    $scope.contacts = [
        {
            id:'',
            name:'',
            emails:[
                {
                    email: 'e1',
                    text: 'fghfgh'
                },
                {
                    email: 'e2',
                    text: 'hjkhjk'
                }
            ],
        }
    ];
}]);


you see if you change the text in the email text box it is removed from the obj unless it is a valid email...
","Its not bug, its desired behaviourof angular, when value is not valid , it is not binded to ngModelController , 

https://docs.angularjs.org/api/ng/type/ngModel.NgModelController

But there is possibility to attach custom email validator ($parsers)
https://docs.angularjs.org/api/ng/type/ngModel.NgModelController#$parsers

You can push parser to array of parser so it will be executed as last, and return modelValue so you will ""override"" angular validator and bind invalidValue to ngModel.
"
5580,5580,8860,Does the <h1> tag get more SEO value if there is no usable keyword in the URL?,"I'm looking at a site for which the domain name and URL do not impart any meaningful data to a search engine.  It does have:


&lt;h1&gt; (eBook name)
&lt;h2&gt; (author - cannot be changed) 
&lt;p&gt; (description)


Do the &lt;h1&gt; and &lt;p&gt; elements provide SEO value?  Those are the only elements in that page that really provide any relevant information to search engines.   I see other sites that use keywords in their URL.

In theory, can the &lt;h1&gt; element be compared to a domain name in terms of SEO value?
",Marek Andreansky,https://webmasters.stackexchange.com/users/35439,"If I understand your question right, no. It is a numbers game. Simple math really. Keyword in link + keyword in URL + keyword in path + keyword in resource name + keyword in &lt;h1&gt; + keyword in content = ?? There is no adjusting the weight of a keyword in &lt;h1&gt; because keywords are not found in the URL or path. However, having said that, search engines will use the keywords they find. If there are no keywords in some elements, then the keywords found become more important for search matches. Not more weight. Just what is available.

I hope I got your question right.
",closetnoc,https://webmasters.stackexchange.com/users/36029,http://webmasters.stackexchange.com/questions/58569/does-the-h1-tag-get-more-seo-value-if-there-is-no-usable-keyword-in-the-url,TECHNOLOGY,webmasters.stackexchange.com,1.0,0.8888888888888888,0.0,0.6666666666666666,1.0,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.6666666666666666,0.0,0.3333333333333333,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.3333333333333333,0.0,1.0,1.0,"If no keywords are available in the URL, will the < H1 > tag get more SEO values?","I'm looking at a site for which the domain name and URL do not impart any meaningful data to a search engine.  It does have:


&lt;h1&gt; (eBook name)
&lt;h2&gt; (author - cannot be changed) 
&lt;p&gt; (description)


Do the &lt;h1&gt; and &lt;p&gt; elements provide SEO value?  Those are the only elements in that page that really provide any relevant information to search engines.   I see other sites that use keywords in their URL.

In theory, can the &lt;h1&gt; element be compared to a domain name in terms of SEO value?
","If I understand your question correctly, No. It's a number game. Simple mathematics really. Keywords in link + keywords in URL + keywords in path + keywords in resource name + keywords in content =?? The weight of the key was not adjusted in & lt; H1 & gt; because the key was not found in the URL or path. Still, search engines use the keywords they find. If there are no keywords in some elements, the keywords found become more important for search matching. It's not heavier. Only available."
315,315,507,How to enable or disable services?,"I read about how to enable and disable services in Ubuntu and it seems that there are different possibilities to manage them.

The first method I found is update-rc.d to add new services to startup, which aims on the /etc/init.d folder and its contents.

The other one I found is to edit .conf files in the /etc/init folder.

What's the recommended way to enable / disable / add services and why?

Could you please give a short bulletproof step by step example on how to add a service in Ubuntu and enable and disable it?
",NES,https://askubuntu.com/users/7155,"Currently there are actually 2 different ways for software to be started as a service in Ubuntu. A service is defined here as a program run by the system in the background, as opposed to one started and run directly by the user.

The traditional way to start services in Linux was to place a script in /etc/init.d, and then use the update-rc.d command (or in RedHat based distros, chkconfig) to enable/disable it. This command, btw, uses some mildly complicated logic to create symlinks in /etc/rc#.d, that control the order of starting services. If you run ls /etc/rc2.d you can see the order that services will be killed (K##xxxx) and started (S##xxxx).

The issue with that was that when booting the system, everything had to be done in serial, one thing after another, making system boot times really slow. Attempts were made to parallelize this, but they were haphazard and hard to take full advantage of. This was the main reason that Upstart was created.

Upstart uses job definition files in /etc/init to define on what events a service should be started. So, while the system is booting, upstart processes various events, and then can start multiple services in parallel. This allows them to fully utilize the resources of the system, for instance, by starting a disk-bound service up while another CPU-bound service runs, or while the network is waiting for a dynamic IP address to be assigned.

You can see all of the upstart job files by running ls /etc/init/*.conf

Let me just stop here and say that if you don't know what a service is, or what it does, DO NOT disable it!

Not all services have been converted to upstart. While working on the server team at Canonical for the past few months, I've worked on a number of converted job files, and the nicest part is that it allows one to get rid of all the script ""magic"" and just put in a few commands here and there to define exactly how to start the service, and nothing more. But for now, only a handful of traditional network services, like squid and samba, have been converted.

In order to figure out if a service is upstart based, you can run the status command:

status servicename


If its an upstart job, it will show this:

$ status statd
statd start/running, process 942


But if its not, you'll see something more like this:

$ status apache2
status: Unknown job: apache2


In this case, apache2 has not been converted to upstart. So, to disable apache2 you just run

sudo update-rc.d apache2 disable
sudo service apache2 stop


Upstart job definitions do not have an update-rc.d command. To disable the job, you need to edit the job file directly to disable it. There are two ways to do this.

If you want to still be able to manually start it, then you need to comment out the 'start on' condition. Say you want to install samba, but not have it start automatically.. here is its job file (in natty):

description ""SMB/CIFS File Server""
author      ""Steve Langasek &lt;steve.langasek@ubuntu.com&gt;""

start on local-filesystems
stop on runlevel [!2345]

respawn

pre-start script
    RUN_MODE=""daemons""

    [ -r /etc/default/samba ] &amp;&amp; . /etc/default/samba

    [ ""$RUN_MODE"" = inetd ] &amp;&amp; { stop; exit 0; }

    install -o root -g root -m 755 -d /var/run/samba
end script

exec smbd -F


To disable it, you can just put a # in front of the 'start on local-filesystems'. Note that while it won't start back up on boot, you still need to stop it this time with

sudo service smbd stop


If, however, you never want it to start, I'd suggest actually removing the package. If, however, you want it installed, but not startable, you can also do:

mv /etc/init/smbd.conf /etc/init/smbd.conf.disabled


Starting with the version of upstart that will be in 11.04, there is a new keyword that disables the 'start on' and 'stop on' stanzas, it is 'manual'. So another way to disable the service as of 11.04 is to do:

command using sudo
echo 'manual' | sudo tee /etc/init/mysql.override

command from root shell
echo manual &gt;&gt; /etc/init/mysql.override


And, hopefully real soon, you will be able to create an ""override"" file to disable a service without editing the job definition at all, by just putting the 'manual' keyword in it.
",SpamapS,https://askubuntu.com/users/813,http://askubuntu.com/questions/19320/how-to-enable-or-disable-services,TECHNOLOGY,askubuntu.com,0.7777777777777778,0.5555555555555556,0.0,0.6666666666666666,1.0,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,0.0,0.8888888888888888,0.8888888888888888,0.8333333333333334,0.8888888888888888,0.8888888888888888,1.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.8888888888888888,How do I enable or disable services?,"I read about how to enable and disable services in Ubuntu and it seems that there are different possibilities to manage them.

The first method I found is update-rc.d to add new services to startup, which aims on the /etc/init.d folder and its contents.

The other one I found is to edit .conf files in the /etc/init folder.

What's the recommended way to enable / disable / add services and why?

Could you please give a short bulletproof step by step example on how to add a service in Ubuntu and enable and disable it?
","Currently there are actually 2 different ways for software to be started as a service in Ubuntu. A service is defined here as a program run by the system in the background, as opposed to one started and run directly by the user.

The traditional way to start services in Linux was to place a script in /etc/init.d, and then use the update-rc.d command (or in RedHat based distros, chkconfig) to enable/disable it. This command, btw, uses some mildly complicated logic to create symlinks in /etc/rc#.d, that control the order of starting services. If you run ls /etc/rc2.d you can see the order that services will be killed (K##xxxx) and started (S##xxxx).

The issue with that was that when booting the system, everything had to be done in serial, one thing after another, making system boot times really slow. Attempts were made to parallelize this, but they were haphazard and hard to take full advantage of. This was the main reason that Upstart was created.

Upstart uses job definition files in /etc/init to define on what events a service should be started. So, while the system is booting, upstart processes various events, and then can start multiple services in parallel. This allows them to fully utilize the resources of the system, for instance, by starting a disk-bound service up while another CPU-bound service runs, or while the network is waiting for a dynamic IP address to be assigned.

You can see all of the upstart job files by running ls /etc/init/*.conf

Let me just stop here and say that if you don't know what a service is, or what it does, DO NOT disable it!

Not all services have been converted to upstart. While working on the server team at Canonical for the past few months, I've worked on a number of converted job files, and the nicest part is that it allows one to get rid of all the script ""magic"" and just put in a few commands here and there to define exactly how to start the service, and nothing more. But for now, only a handful of traditional network services, like squid and samba, have been converted.

In order to figure out if a service is upstart based, you can run the status command:

status servicename


If its an upstart job, it will show this:

$ status statd
statd start/running, process 942


But if its not, you'll see something more like this:

$ status apache2
status: Unknown job: apache2


In this case, apache2 has not been converted to upstart. So, to disable apache2 you just run

sudo update-rc.d apache2 disable
sudo service apache2 stop


Upstart job definitions do not have an update-rc.d command. To disable the job, you need to edit the job file directly to disable it. There are two ways to do this.

If you want to still be able to manually start it, then you need to comment out the 'start on' condition. Say you want to install samba, but not have it start automatically.. here is its job file (in natty):

description ""SMB/CIFS File Server""
author      ""Steve Langasek &lt;steve.langasek@ubuntu.com&gt;""

start on local-filesystems
stop on runlevel [!2345]

respawn

pre-start script
    RUN_MODE=""daemons""

    [ -r /etc/default/samba ] &amp;&amp; . /etc/default/samba

    [ ""$RUN_MODE"" = inetd ] &amp;&amp; { stop; exit 0; }

    install -o root -g root -m 755 -d /var/run/samba
end script

exec smbd -F


To disable it, you can just put a # in front of the 'start on local-filesystems'. Note that while it won't start back up on boot, you still need to stop it this time with

sudo service smbd stop


If, however, you never want it to start, I'd suggest actually removing the package. If, however, you want it installed, but not startable, you can also do:

mv /etc/init/smbd.conf /etc/init/smbd.conf.disabled


Starting with the version of upstart that will be in 11.04, there is a new keyword that disables the 'start on' and 'stop on' stanzas, it is 'manual'. So another way to disable the service as of 11.04 is to do:

command using sudo
echo 'manual' | sudo tee /etc/init/mysql.override

command from root shell
echo manual &gt;&gt; /etc/init/mysql.override


And, hopefully real soon, you will be able to create an ""override"" file to disable a service without editing the job definition at all, by just putting the 'manual' keyword in it.
"
966,966,1532,Wordpress - Custom taxonomy page of custom post type listing by terms,"I have a taxonomy-taxonomy.php page that needs to look like so:

CUSTOM POST TYPE TITLE (RESOURCES)

Custom Taxonomy 1 (Resource Types)

Resource Type Term 1 (White Papers)


White Paper post 1

White Paper post 2

White Paper post 3


Resource Type Term 2 (Videos)


Videos post 1

Videos post 2

Videos post 3


Tried to make sense of all the new documentation for Wordpress 3.0, but it only made me more confused as it seems to be mixed up with 2.8.
",manon1165,https://stackoverflow.com/users/405094,"Hey manon1165 , I actually just accomplished this. Was a huge pain, hopefully my code snippet will help!

I made a custom page template. And did something along the lines of

&lt;?php $categories = get_terms('taxonomy-name', 'orderby=name&amp;hide_empty=0'); $cats = object_to_array($categories); ?&gt;


Now, just print_r($cats) and you will see the array of the categories.

You will need to convert the object to an array, I did so with.

function object_to_array($data) 
{
  if(is_array($data) || is_object($data))
  {
    $result = array(); 
    foreach($data as $key =&gt; $value)
    { 
      $result[$key] = object_to_array($value); 
    }
    return $result;
  }
  return $data;
}


I did

&lt;ul id=""cat-list""&gt;
&lt;?php foreach($cats as $cat) { ?&gt;
  &lt;li&gt;&lt;a href=""/taxonomy-name/&lt;?php echo $cat['slug']; ?&gt;""&gt;&lt;?php echo $cat['name']; ?&gt; (&lt;?php echo $cat['count']; ?&gt;)&lt;/a&gt;&lt;br&gt;&lt;?php echo $cat['description']; ?&gt;&lt;/li&gt;
&lt;?php } ?&gt;
&lt;/ul&gt;


Hope that helps!
",LostInQuery,https://stackoverflow.com/users/399742,http://stackoverflow.com/questions/3358049/wordpress-custom-taxonomy-page-of-custom-post-type-listing-by-terms,STACKOVERFLOW,stackoverflow.com,1.0,0.5,0.0,0.5,0.5,1.0,0.3333333333333333,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.5,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,0.8888888888888888,WordPress - a custom category page that lists custom article types by term,"I have a taxonomy-taxonomy.php page that needs to look like so:

CUSTOM POST TYPE TITLE (RESOURCES)

Custom Taxonomy 1 (Resource Types)

Resource Type Term 1 (White Papers)


White Paper post 1

White Paper post 2

White Paper post 3


Resource Type Term 2 (Videos)


Videos post 1

Videos post 2

Videos post 3


Tried to make sense of all the new documentation for Wordpress 3.0, but it only made me more confused as it seems to be mixed up with 2.8.
","Hey manon1165 , I actually just accomplished this. Was a huge pain, hopefully my code snippet will help!

I made a custom page template. And did something along the lines of

&lt;?php $categories = get_terms('taxonomy-name', 'orderby=name&amp;hide_empty=0'); $cats = object_to_array($categories); ?&gt;


Now, just print_r($cats) and you will see the array of the categories.

You will need to convert the object to an array, I did so with.

function object_to_array($data) 
{
  if(is_array($data) || is_object($data))
  {
    $result = array(); 
    foreach($data as $key =&gt; $value)
    { 
      $result[$key] = object_to_array($value); 
    }
    return $result;
  }
  return $data;
}


I did

&lt;ul id=""cat-list""&gt;
&lt;?php foreach($cats as $cat) { ?&gt;
  &lt;li&gt;&lt;a href=""/taxonomy-name/&lt;?php echo $cat['slug']; ?&gt;""&gt;&lt;?php echo $cat['name']; ?&gt; (&lt;?php echo $cat['count']; ?&gt;)&lt;/a&gt;&lt;br&gt;&lt;?php echo $cat['description']; ?&gt;&lt;/li&gt;
&lt;?php } ?&gt;
&lt;/ul&gt;


Hope that helps!
"
2651,2651,4210,How do I burn a DVD with more than 3.8 GB data?,"I use Kubuntu 12.04 with KDE 4.8.3 and wodim / genisoimage 1.1.11, but the problem is on Ubuntu (with Brasero) and occurred in Oneiric as well.

Whenever I try to burn more than 3.8GB (approaching the 4 GB limit) of data onto a DVD, burning fails, aborts, or gives an ""error 254.""

I have lost more than 50 DVDs this way until I learned about the 3.8GB limit. Anything under 3.8GB burns fine, and DVDs burned with more than 3.8GB have usable data up to 3.8 GB, but then the remaining data is garbled, unaccessible, or the disk is just not recognized.

I'm pretty certain this is related to the replacement of cdrecord / mkisofs with wodim /genioimage (which is a problem that has been described for years). Is there another answer or fix? Re-installing cdrtools/cdrecord/mkisofs in Oneiric and Precise has become a herculean task.  
",Perspectoff,https://askubuntu.com/users/70130,"
Try other programs, i.e. gnomebaker or simpleburn:

http://simpleburn.tuxfamily.org/ -- https://launchpad.net/~simpleburn/+archive/ppa

http://sourceforge.net/projects/gnomebaker/ -- https://launchpad.net/~gnomebaker/+archive/stable
There are different types of DVDs that support different capacities. According to the wikipedia article (Capacity and nomenclature of (re)writable discs), there are two versions of DVD-R discs, ~3.68 GiB and ~4.37GiB (Don't look at GB, but GiB, that's the actual data capacity).

Always look at what's printed on the DVD, they usually mention if they're DVD-R or DVD+R. If they don't mention anything (i.e. no-named), don't buy them, unless you're up for the risk.

Prefer DVD+R (no specific reason, but if you need one, they don't have 2 versions and are 4.37 GiB in capacity).

You could also try the dual layered dvds, which provide ~8 GiB in capacity.

For testing purposes buy 2-3 DVD+RW discs.
Burn at low speeds, 4x recommended.
Devices such as dvd burners die eventually (at least in my case), after 2-3 years they become faulty. For example, burning worked in my case, except that I couldn't boot using any cd/dvd media. I bought a new CD/DVD burner and recycled the old one. Now the new one after 2 years burns only at speeds lower than 10x. Go figure. :)

",Savvas Radevic,https://askubuntu.com/users/5538,http://askubuntu.com/questions/149839/how-do-i-burn-a-dvd-with-more-than-3-8-gb-data,TECHNOLOGY,askubuntu.com,0.8888888888888888,0.6666666666666666,0.0,0.0,1.0,1.0,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,1.0,1.0,0.9,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.7777777777777778,How to record DVDs with data over 3.8 GB?,"I use Kubuntu 12.04 with KDE 4.8.3 and wodim / genisoimage 1.1.11, but the problem is on Ubuntu (with Brasero) and occurred in Oneiric as well.

Whenever I try to burn more than 3.8GB (approaching the 4 GB limit) of data onto a DVD, burning fails, aborts, or gives an ""error 254.""

I have lost more than 50 DVDs this way until I learned about the 3.8GB limit. Anything under 3.8GB burns fine, and DVDs burned with more than 3.8GB have usable data up to 3.8 GB, but then the remaining data is garbled, unaccessible, or the disk is just not recognized.

I'm pretty certain this is related to the replacement of cdrecord / mkisofs with wodim /genioimage (which is a problem that has been described for years). Is there another answer or fix? Re-installing cdrtools/cdrecord/mkisofs in Oneiric and Precise has become a herculean task.  
","
Try other programs, i.e. gnomebaker or simpleburn:

http://simpleburn.tuxfamily.org/ -- https://launchpad.net/~simpleburn/+archive/ppa

http://sourceforge.net/projects/gnomebaker/ -- https://launchpad.net/~gnomebaker/+archive/stable
There are different types of DVDs that support different capacities. According to the wikipedia article (Capacity and nomenclature of (re)writable discs), there are two versions of DVD-R discs, ~3.68 GiB and ~4.37GiB (Don't look at GB, but GiB, that's the actual data capacity).

Always look at what's printed on the DVD, they usually mention if they're DVD-R or DVD+R. If they don't mention anything (i.e. no-named), don't buy them, unless you're up for the risk.

Prefer DVD+R (no specific reason, but if you need one, they don't have 2 versions and are 4.37 GiB in capacity).

You could also try the dual layered dvds, which provide ~8 GiB in capacity.

For testing purposes buy 2-3 DVD+RW discs.
Burn at low speeds, 4x recommended.
Devices such as dvd burners die eventually (at least in my case), after 2-3 years they become faulty. For example, burning worked in my case, except that I couldn't boot using any cd/dvd media. I bought a new CD/DVD burner and recycled the old one. Now the new one after 2 years burns only at speeds lower than 10x. Go figure. :)

"
1926,1926,3072,Modifying Local Within Function Changes Global Passed to Function in Python,"I am trying to understand why the global copy of an object passed to a function is modified by the function. I understand that if I assign an object mylist to a second variable name, it does not make a copy and modifying the second object changes the first because they are one in the same. For example:

mylist = []
s = mylist
s.append(2)
print(mylist)
[2]


However, I did not think this occurred within a function unless made explicit with global varname. As this answer puts it, ""If you want to simply access a global variable you just use its name. However to change its value you need to use the global keyword."" This is how the function mult below behaves (though I am not modifying x but assigning a new value to it). However, when I pass a global variable to either app or noreturn, in both instances the global variable is modified by the function without a declaration that I want to modify the global variable with a global keyword.

import pandas as pd

def mult(x):
    x = x * x
    return x

def app(mylist):
    mylist.append(4)
    return mylist


def noreturn(df):
    df['indexcol'] = list(df.index)

df = pd.DataFrame({""A"": [10,20,30,40,50], ""B"": [20, 30, 10, 40, 50], ""C"": [32, 234, 23, 23, 42523]})
print(df)

    A   B      C
0  10  20     32
1  20  30    234
2  30  10     23
3  40  40     23
4  50  50  42523



noreturn(df)
print(df)

    A   B      C  indexcol
0  10  20     32         0
1  20  30    234         1
2  30  10     23         2
3  40  40     23         3
4  50  50  42523         4



x = 3
mylist = []

y = mult(x)
newlist = app(mylist)
print(x, y)
(3, 9)
print(mylist, newlist)
([4], [4])


If I want a function that does not modify global variables do I need to use copy.deepcopy on every variable passed to the function?
",Michael,https://stackoverflow.com/users/2327821,"Your quote says:


  If you want to simply access a global variable you just use its name. However to change its value you need to use the global keyword.


I would modify that to:


  If you want to simply access the object a global variable refers to, you just use its name. However to change what object it refers to, you need to use the global keyword.


Accessing a global object can include changing things about the object (such as appending a new object to an existing global list). However, if your function tried to do:

def app(mylist):
    mylist = mylist + [4]
    return mylist


which attempts to change the global mylist reference (by creating a new object and assigning the result to mylist), then you would need to use the global keyword.
",Greg Hewgill,https://stackoverflow.com/users/893,http://stackoverflow.com/questions/25434512/modifying-local-within-function-changes-global-passed-to-function-in-python,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.5555555555555556,0.0,1.0,1.0,1.0,0.4444444444444444,0.4444444444444444,0.6666666666666666,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.9,1.0,0.6666666666666666,0.3333333333333333,0.8888888888888888,Modifying local changes within a function in Python and passing them to the global of the function,"I am trying to understand why the global copy of an object passed to a function is modified by the function. I understand that if I assign an object mylist to a second variable name, it does not make a copy and modifying the second object changes the first because they are one in the same. For example:

mylist = []
s = mylist
s.append(2)
print(mylist)
[2]


However, I did not think this occurred within a function unless made explicit with global varname. As this answer puts it, ""If you want to simply access a global variable you just use its name. However to change its value you need to use the global keyword."" This is how the function mult below behaves (though I am not modifying x but assigning a new value to it). However, when I pass a global variable to either app or noreturn, in both instances the global variable is modified by the function without a declaration that I want to modify the global variable with a global keyword.

import pandas as pd

def mult(x):
    x = x * x
    return x

def app(mylist):
    mylist.append(4)
    return mylist


def noreturn(df):
    df['indexcol'] = list(df.index)

df = pd.DataFrame({""A"": [10,20,30,40,50], ""B"": [20, 30, 10, 40, 50], ""C"": [32, 234, 23, 23, 42523]})
print(df)

    A   B      C
0  10  20     32
1  20  30    234
2  30  10     23
3  40  40     23
4  50  50  42523



noreturn(df)
print(df)

    A   B      C  indexcol
0  10  20     32         0
1  20  30    234         1
2  30  10     23         2
3  40  40     23         3
4  50  50  42523         4



x = 3
mylist = []

y = mult(x)
newlist = app(mylist)
print(x, y)
(3, 9)
print(mylist, newlist)
([4], [4])


If I want a function that does not modify global variables do I need to use copy.deepcopy on every variable passed to the function?
","Your quote says:


  If you want to simply access a global variable you just use its name. However to change its value you need to use the global keyword.


I would modify that to:


  If you want to simply access the object a global variable refers to, you just use its name. However to change what object it refers to, you need to use the global keyword.


Accessing a global object can include changing things about the object (such as appending a new object to an existing global list). However, if your function tried to do:

def app(mylist):
    mylist = mylist + [4]
    return mylist


which attempts to change the global mylist reference (by creating a new object and assigning the result to mylist), then you would need to use the global keyword.
"
1760,1760,2790,Are prime lenses sharp across the whole frame while zoom lenses are soft in the corners?,"Somebody told me that there is a difference in sharpness between a zoom lens vs. prime lens. A  58-200mm will give sharp focus in the center of the frame but blurry performance at the corners,  while in the meantime a prime 200mm will give a sharp definition to the whole frame of the photograph. Is this true? 
",Reynol Cobreiro,https://photo.stackexchange.com/users/41380,"Performance in terms of acutance of any lens varies in a lot of ways, but throwing in the variable focal lengths a zoom lens is capable of adds to the complexity of things. Even a prime lens with a fixed focal length can vary in terms of center sharpness from one aperture setting to the next. How much that sharpness is degraded from the center to the edges can also change at different apertures. Adding the extra variables of a zoom lens creates an even more complex comparison.

In general the gist of what you have been told is basically true, especially when comparing prime and zoom lenses that are both in the same or similar price ranges. If you compare cheaper prime lenses with high end zoom lenses, though, all bets are off in terms of this generalization. And there are some very high end prime lenses that are specifically designed to soften up on the edges and in the corners. The unique look of the Canon EF 85mm f/1.2 L is due to uncorrected spherical aberration that makes the edges of a flat target soft when the center is correctly in focus.

With consumer grade telephoto zoom lenses, the longest focal lengths typically tend to be the least sharp, even at the center of the frame. As the lens is zoomed to the maximum focal length all of the aberrations of the lens are magnified. So if the center sharpness decreases a little as the focal length is lengthened, then the edges will usually soften up even more.
",Michael Clark,https://photo.stackexchange.com/users/15871,http://photo.stackexchange.com/questions/65562/are-prime-lenses-sharp-across-the-whole-frame-while-zoom-lenses-are-soft-in-the,LIFE_ARTS,photo.stackexchange.com,1.0,0.7777777777777778,0.0,0.3333333333333333,1.0,1.0,0.4444444444444444,0.3333333333333333,0.6666666666666666,0.0,0.0,1.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,1.0,"When the zoom lens becomes soft in the corner, is the main lens clear in the whole picture?","I was told that the sharpness of a zoom lens is different from that of a prime lens. The focal length of 58-200 mm will form a clear focus in the center of the picture, but the performance in the corner will be blurred. At the same time, the background color of 200 mm will bring a clear definition to the whole picture. But is it really the case?","Performance in terms of acutance of any lens varies in a lot of ways, but throwing in the variable focal lengths a zoom lens is capable of adds to the complexity of things. Even a prime lens with a fixed focal length can vary in terms of center sharpness from one aperture setting to the next. How much that sharpness is degraded from the center to the edges can also change at different apertures. Adding the extra variables of a zoom lens creates an even more complex comparison.

In general the gist of what you have been told is basically true, especially when comparing prime and zoom lenses that are both in the same or similar price ranges. If you compare cheaper prime lenses with high end zoom lenses, though, all bets are off in terms of this generalization. And there are some very high end prime lenses that are specifically designed to soften up on the edges and in the corners. The unique look of the Canon EF 85mm f/1.2 L is due to uncorrected spherical aberration that makes the edges of a flat target soft when the center is correctly in focus.

With consumer grade telephoto zoom lenses, the longest focal lengths typically tend to be the least sharp, even at the center of the frame. As the lens is zoomed to the maximum focal length all of the aberrations of the lens are magnified. So if the center sharpness decreases a little as the focal length is lengthened, then the edges will usually soften up even more.
"
89,89,148,How to fix a Macbook Pro trackpad where the mouse pointer is randomly moving?,"The trackpad on my Macbook Pro just started acting oddly. It's randomly clicking (which might cause me to switch programs), right-clicking and even once my screen even showed the swiping animation as if I was trying to switch to a different desktop.    

Part of me fears that this is some sort of joke hacking attempt (I know of a USB device you plug into someones computer and it randomly moves their mouse and types on their keyboard), but there is nothing plugged into my machine and I just turned off the Wi-Fi and watched as this web page tried to close, the mouse right clicked twice, highlighted a word and clicked ""Paste and Match Style"" in the Chrome right-click menu.
Also as I've been typing (with my Wi-Fi turned off) the mouse has randomly been clicking inside this question and changing where I am typing.  

I just plugged in a USB mouse which seems to work fine but the trackpad is now nearly useless. I can't even move the mouse cursor more than a few centimeters with it.

Is this a common issue?
EDIT
I think it is dying actually. I can now click but not move at all with the trackpad, while a regular mouse works fine.
EDIT 2
And now it seems to be working again. I turned on the option for ""Ignore Trackpad when Mouse is plugged in"" under Universal Access. I cleaned the trackpad with rubbing alcohol, I whined and complained for a few minutes to my dog, turned off the ""Ignore Trackpad"" setting, unplugged the USB mouse, and the Trackpad appears to be working mostly normally.
If I run my finger across it at the top or bottom portion of the mouse, it works, but there is a line horizontally across it (almost exactly where a physical trackpad button would end on the old trackpads) that is ""dead"".  The mouse stops moving, or moves sluggishly when hitting that spot and that ""spot"" goes across the whole trackpad.
",James P. Wright,https://apple.stackexchange.com/users/4049,"Today I had a horizontal line not working on the touchpad. I fixed it by removing the touchpad from the laptop (which is very annoying and requires a miniature screwdriver) and cleaned it with a lot of ethanol (ethyl alcohol) and a piece of cotton. I put it back in and it now works perfectly.

I have had a similar problem a couple of years ago and I didn't have a special screwdriver (that I do have now) and I fixed a similar problem with a syringe with ethanol and squirted the ethanol in the crack around the touchpad.

I have seen many people suggest to change the touchpad, but you can try with a cloth and ethanol (remove the battery and charger if possible and wait for 30 min for the ethanol to evaporate).
",mist,https://apple.stackexchange.com/users/4971,http://apple.stackexchange.com/questions/62146/how-to-fix-a-macbook-pro-trackpad-where-the-mouse-pointer-is-randomly-moving,TECHNOLOGY,apple.stackexchange.com,1.0,1.0,0.0,1.0,1.0,1.0,0.7777777777777778,0.8888888888888888,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.3333333333333333,0.0,1.0,0.6666666666666666,0.6666666666666666,1.0,0.8888888888888888,0.8666666666666666,0.6666666666666666,0.0,0.3333333333333333,1.0,How to repair the MacBook Pro touchpad with randomly moving mouse pointer?,"The trackpad on my Macbook Pro just started acting oddly. It's randomly clicking (which might cause me to switch programs), right-clicking and even once my screen even showed the swiping animation as if I was trying to switch to a different desktop.    

Part of me fears that this is some sort of joke hacking attempt (I know of a USB device you plug into someones computer and it randomly moves their mouse and types on their keyboard), but there is nothing plugged into my machine and I just turned off the Wi-Fi and watched as this web page tried to close, the mouse right clicked twice, highlighted a word and clicked ""Paste and Match Style"" in the Chrome right-click menu.
Also as I've been typing (with my Wi-Fi turned off) the mouse has randomly been clicking inside this question and changing where I am typing.  

I just plugged in a USB mouse which seems to work fine but the trackpad is now nearly useless. I can't even move the mouse cursor more than a few centimeters with it.

Is this a common issue?
EDIT
I think it is dying actually. I can now click but not move at all with the trackpad, while a regular mouse works fine.
EDIT 2
And now it seems to be working again. I turned on the option for ""Ignore Trackpad when Mouse is plugged in"" under Universal Access. I cleaned the trackpad with rubbing alcohol, I whined and complained for a few minutes to my dog, turned off the ""Ignore Trackpad"" setting, unplugged the USB mouse, and the Trackpad appears to be working mostly normally.
If I run my finger across it at the top or bottom portion of the mouse, it works, but there is a line horizontally across it (almost exactly where a physical trackpad button would end on the old trackpads) that is ""dead"".  The mouse stops moving, or moves sluggishly when hitting that spot and that ""spot"" goes across the whole trackpad.
","Today I had a horizontal line not working on the touchpad. I fixed it by removing the touchpad from the laptop (which is very annoying and requires a miniature screwdriver) and cleaned it with a lot of ethanol (ethyl alcohol) and a piece of cotton. I put it back in and it now works perfectly.

I have had a similar problem a couple of years ago and I didn't have a special screwdriver (that I do have now) and I fixed a similar problem with a syringe with ethanol and squirted the ethanol in the crack around the touchpad.

I have seen many people suggest to change the touchpad, but you can try with a cloth and ethanol (remove the battery and charger if possible and wait for 30 min for the ethanol to evaporate).
"
2919,2919,4646,WPF Validation Control Template overlapping,"I've got a user control with a control template to show validation errors, validation template:

&lt;ControlTemplate x:Key=""TextBoxPropertyValidationTemplate""&gt;
        &lt;StackPanel&gt;
            &lt;Border BorderBrush=""Red"" BorderThickness=""1""&gt;
                &lt;AdornedElementPlaceholder x:Name=""MyAdorner"" /&gt;
            &lt;/Border&gt;

            &lt;Grid&gt;
                &lt;Grid.ColumnDefinitions&gt;
                    &lt;ColumnDefinition Width=""Auto"" /&gt;
                    &lt;ColumnDefinition Width=""*"" /&gt;
                &lt;/Grid.ColumnDefinitions&gt;
                &lt;Image Grid.Column=""0"" MaxHeight=""16"" MaxWidth=""16""
                       Source=""{Binding Source={StaticResource ValidationIcon}, Converter={StaticResource UriConverter}}"" 
                       Margin=""1"" RenderOptions.BitmapScalingMode=""HighQuality""
                       VerticalAlignment=""Center"" HorizontalAlignment=""Center"" /&gt;
                &lt;TextBlock VerticalAlignment=""Center"" HorizontalAlignment=""Left""
                           Text=""{Binding ElementName=MyAdorner, Path=AdornedElement.(Validation.Errors)[0].ErrorContent}""
                           TextWrapping=""Wrap"" Grid.Column=""1"" FontSize=""10"" Foreground=""Red"" /&gt;
            &lt;/Grid&gt;

        &lt;/StackPanel&gt;
    &lt;/ControlTemplate&gt;


And I can't seem to get around a rather irritating problem which looks like this:



I've been trying to play around with margins on the user control and on the template also some Height=Auto etc but all these don't really help. Any ideas anyone?

If that helps the main user control (which nests the ones with validation) is in a TabItem with a AdornerDecorator.

Any help appreciated.
",hyp,https://stackoverflow.com/users/674581,"I'd say this is because your error message is on the AdornerLayer, which doesn't participate in the same layout as your control. MSDN says ""rendering of an adorner is independent from rendering of the UIElement that the adorner is bound to."" and that is why the message is just put on top of everything.   

You could put the error text into the original template, hide it based on Validation.HasError and include it in the layout process that way.  

But changing the layout of the control might not be the best way to go if a validation error occurs. You might consider providing additional information in a ToolTip.
",Botz3000,https://stackoverflow.com/users/93652,http://stackoverflow.com/questions/6516120/wpf-validation-control-template-overlapping,STACKOVERFLOW,stackoverflow.com,1.0,0.5555555555555556,0.0,0.6666666666666666,0.3333333333333333,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.5555555555555556,1.0,0.5555555555555556,1.0,1.0,0.9333333333333332,1.0,0.0,0.3333333333333333,0.8888888888888888,WPF validation control template overlap,"I've got a user control with a control template to show validation errors, validation template:

&lt;ControlTemplate x:Key=""TextBoxPropertyValidationTemplate""&gt;
        &lt;StackPanel&gt;
            &lt;Border BorderBrush=""Red"" BorderThickness=""1""&gt;
                &lt;AdornedElementPlaceholder x:Name=""MyAdorner"" /&gt;
            &lt;/Border&gt;

            &lt;Grid&gt;
                &lt;Grid.ColumnDefinitions&gt;
                    &lt;ColumnDefinition Width=""Auto"" /&gt;
                    &lt;ColumnDefinition Width=""*"" /&gt;
                &lt;/Grid.ColumnDefinitions&gt;
                &lt;Image Grid.Column=""0"" MaxHeight=""16"" MaxWidth=""16""
                       Source=""{Binding Source={StaticResource ValidationIcon}, Converter={StaticResource UriConverter}}"" 
                       Margin=""1"" RenderOptions.BitmapScalingMode=""HighQuality""
                       VerticalAlignment=""Center"" HorizontalAlignment=""Center"" /&gt;
                &lt;TextBlock VerticalAlignment=""Center"" HorizontalAlignment=""Left""
                           Text=""{Binding ElementName=MyAdorner, Path=AdornedElement.(Validation.Errors)[0].ErrorContent}""
                           TextWrapping=""Wrap"" Grid.Column=""1"" FontSize=""10"" Foreground=""Red"" /&gt;
            &lt;/Grid&gt;

        &lt;/StackPanel&gt;
    &lt;/ControlTemplate&gt;


And I can't seem to get around a rather irritating problem which looks like this:



I've been trying to play around with margins on the user control and on the template also some Height=Auto etc but all these don't really help. Any ideas anyone?

If that helps the main user control (which nests the ones with validation) is in a TabItem with a AdornerDecorator.

Any help appreciated.
","I'd say this is because your error message is on the AdornerLayer, which doesn't participate in the same layout as your control. MSDN says ""rendering of an adorner is independent from rendering of the UIElement that the adorner is bound to."" and that is why the message is just put on top of everything.   

You could put the error text into the original template, hide it based on Validation.HasError and include it in the layout process that way.  

But changing the layout of the control might not be the best way to go if a validation error occurs. You might consider providing additional information in a ToolTip.
"
5269,5269,8374,Which Windows 7 to install?,"I have 2GB of RAM on my laptop, which is the max.  

Should I install 32 bit version or 64 bit version?
",AngryHacker,https://superuser.com/users/2805,"For any PC with less than 3GB of RAM I would go for 32-bit Windows. If you plan on upgrading your RAM and you are sure you can get 64-bit drivers for all your hardware, go with 64-bit Windows. You probably won't find many Windows 7 drivers yet, but 64-bit Vista drivers should do fine. 

32-bit software usually runs fine on 64-bit Windows 7 (and Vista). Since I started using Vista 64-bit (around the time it got released), I've only experienced problems two times and only one was a complete failure. An average user should not have any problems using 32-bit software  when 64-bit is not available. 
",Tor-Erik,https://superuser.com/users/4498,http://superuser.com/questions/17917,TECHNOLOGY,superuser.com,1.0,0.3333333333333333,0.0,1.0,1.0,1.0,0.8333333333333334,0.3333333333333333,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0,1.0,1.0,0.9,1.0,0.0,1.0,1.0,Which Windows 7 do you want to install?,"I have 2GB of RAM on my laptop, which is the max.  

Should I install 32 bit version or 64 bit version?
","For any PC with less than 3GB of RAM I would go for 32-bit Windows. If you plan on upgrading your RAM and you are sure you can get 64-bit drivers for all your hardware, go with 64-bit Windows. You probably won't find many Windows 7 drivers yet, but 64-bit Vista drivers should do fine. 

32-bit software usually runs fine on 64-bit Windows 7 (and Vista). Since I started using Vista 64-bit (around the time it got released), I've only experienced problems two times and only one was a complete failure. An average user should not have any problems using 32-bit software  when 64-bit is not available. 
"
1211,1211,1902,.xlsx and xls(Latest Versions) to pdf using python,"With the help of this .doc to pdf using python
Link I am trying for excel (.xlsx and xls formats)

Following is modified Code for Excel:

import os
from win32com import client

folder = ""C:\\Oprance\\Excel\\XlsxWriter-0.5.1""
file_type = 'xlsx'
out_folder = folder + ""\\PDF_excel""

os.chdir(folder)

if not os.path.exists(out_folder):
    print 'Creating output folder...'
    os.makedirs(out_folder)
    print out_folder, 'created.'
else:
    print out_folder, 'already exists.\n'

for files in os.listdir("".""):
    if files.endswith("".xlsx""):
        print files

print '\n\n'

word = client.DispatchEx(""Excel.Application"")
for files in os.listdir("".""):
    if files.endswith("".xlsx"") or files.endswith('xls'):
        out_name = files.replace(file_type, r""pdf"")
        in_file = os.path.abspath(folder + ""\\"" + files)
        out_file = os.path.abspath(out_folder + ""\\"" + out_name)
        doc = word.Workbooks.Open(in_file)
        print 'Exporting', out_file
        doc.SaveAs(out_file, FileFormat=56)
        doc.Close()


It is showing following error : 

&gt;&gt;&gt; execfile('excel_to_pdf.py')
Creating output folder...
C:\Excel\XlsxWriter-0.5.1\PDF_excel created.
apms_trial.xlsx
~$apms_trial.xlsx

Exporting C:\Excel\XlsxWriter-0.5.1\PDF_excel\apms_trial.pdf
Traceback (most recent call last):
  File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
  File ""excel_to_pdf.py"", line 30, in &lt;module&gt;
    doc = word.Workbooks.Open(in_file)
  File ""&lt;COMObject &lt;unknown&gt;&gt;"", line 8, in Open
pywintypes.com_error: (-2147352567, 'Exception occurred.', (0, u'Microsoft Excel
', u""Excel cannot open the file '~$apms_trial.xlsx' because the file format or f
ile extension is not valid. Verify that the file has not been corrupted and that
 the file extension matches the format of the file."", u'xlmain11.chm', 0, -21468
27284), None)
&gt;&gt;&gt;


There is problem in

doc.SaveAs(out_file, FileFormat=56)

What should be FileFormat file format?
Please Help
",eegloo,https://stackoverflow.com/users/2621678,"You can print an excel sheet to pdf on linux using python.
Do need to run openoffice as a headless server and use unoconv, takes a bit of configuring but is doable

You run OO as a (service) daemon and use it for the conversions for xls, xlsx and doc, docx.

http://dag.wiee.rs/home-made/unoconv/
",lxx,https://stackoverflow.com/users/1493718,http://stackoverflow.com/questions/20854840/xlsx-and-xlslatest-versions-to-pdf-using-python,STACKOVERFLOW,stackoverflow.com,1.0,0.3333333333333333,0.0,1.0,1.0,1.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.3333333333333333,1.0,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,0.0,1.0,Convert. Xlsx and XLS (latest version) to PDF using Python,"With the help of this .doc to pdf using python
Link I am trying for excel (.xlsx and xls formats)

Following is modified Code for Excel:

import os
from win32com import client

folder = ""C:\\Oprance\\Excel\\XlsxWriter-0.5.1""
file_type = 'xlsx'
out_folder = folder + ""\\PDF_excel""

os.chdir(folder)

if not os.path.exists(out_folder):
    print 'Creating output folder...'
    os.makedirs(out_folder)
    print out_folder, 'created.'
else:
    print out_folder, 'already exists.\n'

for files in os.listdir("".""):
    if files.endswith("".xlsx""):
        print files

print '\n\n'

word = client.DispatchEx(""Excel.Application"")
for files in os.listdir("".""):
    if files.endswith("".xlsx"") or files.endswith('xls'):
        out_name = files.replace(file_type, r""pdf"")
        in_file = os.path.abspath(folder + ""\\"" + files)
        out_file = os.path.abspath(out_folder + ""\\"" + out_name)
        doc = word.Workbooks.Open(in_file)
        print 'Exporting', out_file
        doc.SaveAs(out_file, FileFormat=56)
        doc.Close()


It is showing following error : 

&gt;&gt;&gt; execfile('excel_to_pdf.py')
Creating output folder...
C:\Excel\XlsxWriter-0.5.1\PDF_excel created.
apms_trial.xlsx
~$apms_trial.xlsx

Exporting C:\Excel\XlsxWriter-0.5.1\PDF_excel\apms_trial.pdf
Traceback (most recent call last):
  File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
  File ""excel_to_pdf.py"", line 30, in &lt;module&gt;
    doc = word.Workbooks.Open(in_file)
  File ""&lt;COMObject &lt;unknown&gt;&gt;"", line 8, in Open
pywintypes.com_error: (-2147352567, 'Exception occurred.', (0, u'Microsoft Excel
', u""Excel cannot open the file '~$apms_trial.xlsx' because the file format or f
ile extension is not valid. Verify that the file has not been corrupted and that
 the file extension matches the format of the file."", u'xlmain11.chm', 0, -21468
27284), None)
&gt;&gt;&gt;


There is problem in

doc.SaveAs(out_file, FileFormat=56)

What should be FileFormat file format?
Please Help
","You can print an excel sheet to pdf on linux using python.
Do need to run openoffice as a headless server and use unoconv, takes a bit of configuring but is doable

You run OO as a (service) daemon and use it for the conversions for xls, xlsx and doc, docx.

http://dag.wiee.rs/home-made/unoconv/
"
4830,4830,7677,Does the original jutsu user feel anything when a shadow clone is dispersed forcefully?,"According to the wiki,


  While the technique can be extremely beneficial, attempting to use multiple clones for training purposes can be mentally harmful to the user, as not only is all the experience collected by the user, but so is all the mental stress from training each clone


Now, when a clone is destroyed, there must be some mental stress involved. So does Naruto (or anyone else) feel anything when their shadow clones are dispersed? 

Nothing has been shown to indicate this (at least in the anime). I was wondering why this would not be applicable.
",Chetter Hummin,https://anime.stackexchange.com/users/321,"I think mental knowledge and experiences are transferred to the original once disperesed, but not physical pain. If that were the case, using the shadow clone jutsu would only be too risky and only used for emergencies.

I was actually wondering about the opposite scenario. Do the shadow clones share injuries of the original. For example, when kabuto severed the muscle in naruto's leg out, did the shadow clone created afterwards also have a severed muscle in the leg.
",Chris,https://anime.stackexchange.com/users/2677,http://anime.stackexchange.com/questions/2193/does-the-original-jutsu-user-feel-anything-when-a-shadow-clone-is-dispersed-forc,CULTURE,anime.stackexchange.com,1.0,1.0,0.6666666666666666,1.0,0.3333333333333333,1.0,0.8888888888888888,0.8888888888888888,0.0,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.7777777777777778,1.0,1.0,0.8666666666666666,0.0,0.0,0.0,1.0,"When shadow clones are forced to disperse, how does the original jutsu user feel?","According to the wiki,


  While the technique can be extremely beneficial, attempting to use multiple clones for training purposes can be mentally harmful to the user, as not only is all the experience collected by the user, but so is all the mental stress from training each clone


Now, when a clone is destroyed, there must be some mental stress involved. So does Naruto (or anyone else) feel anything when their shadow clones are dispersed? 

Nothing has been shown to indicate this (at least in the anime). I was wondering why this would not be applicable.
","I think that once spiritual knowledge and experience are spread, they will be transferred to the original world, rather than physical pain. If that's the case, using shadow clones will only be too risky and will only be used in emergencies."
4485,4485,7111,How to Set GPO to Update Compatibility View List in IE9,"We recently started upgrading people in our organization to IE 9. One of the websites that our employees will be going to on a daily basis does not display the scroll bars correctly in IE 9. It does however display them correctly when the site is added to the compatibility view list in IE 9.

How can I set this through a group policy? Has this option been released yet?

In Windows Components\Internet Explorer\Compatibility View I only see options for IE7. Also in Preferences\Control Panel\Internet Settings it is only letting me create new group policy settings for IE 5-8.

The DC is running on W2K8R2 and is fully up to date.

Thanks for your help!
",adivis12,https://serverfault.com/users/63250,"From a Google search (which you should have done before posting your question) it appears that if you install IE9 on the computer where you have the GPMC installed (presumably your domain controllers) that the inetres.admx template will be updated with the IE9 settings.
",joeqwerty,https://serverfault.com/users/19152,http://serverfault.com/questions/420201,TECHNOLOGY,serverfault.com,0.8888888888888888,0.7777777777777778,0.0,1.0,1.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.7777777777777778,0.8888888888888888,0.5555555555555556,1.0,0.8888888888888888,0.8,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.8888888888888888,How to set up GPO to update compatibility view list in IE9,"We recently started upgrading people in our organization to IE 9. One of the websites that our employees will be going to on a daily basis does not display the scroll bars correctly in IE 9. It does however display them correctly when the site is added to the compatibility view list in IE 9.

How can I set this through a group policy? Has this option been released yet?

In Windows Components\Internet Explorer\Compatibility View I only see options for IE7. Also in Preferences\Control Panel\Internet Settings it is only letting me create new group policy settings for IE 5-8.

The DC is running on W2K8R2 and is fully up to date.

Thanks for your help!
","As you can see from Google search (which should be completed before the issue is published), if you install IE9 on a computer with GPMC (possibly a domain controller) installed, the inetres.admx template will be updated with IE9 settings."
3510,3510,5599,What kind of metrics should I collect for a website/web app,"I have a website that allows users to register for accounts, login, and renew an annual membership fee. They can also update their personal profile, their personal profile, look at a list of their employees, make bulk payments for their employees, view receipts and invoices, etc.

For non-members it's a regular website with a lot of pages, but for members, it has quite a few member only areas, with more to come (Such as forums). It also has a job listings page, course registrations, etc.

What are some useful ""metrics"" I can collect to give me meaningful information about the site, that I can share with my clients. I really don't know a lot about collecting data about this kind of thing, and would like to learn.

I already have a dashboard where the admins can view/export registrations this week and registrations by week for the past 30 weeks. I've been able to show them that registrations spiked after sending out an email about the new system.

I'm think I'll also be adding stats about how often users update their profiles and how many users have updated their profile that day/week. 

Thanks
",Brandon Wamboldt,https://programmers.stackexchange.com/users/3382,"What do your clients want to know?  Collect data on that.

That said, at a minimum I would collect (per web page):


Number of first-page views.
Number of pages viewed until abandonment (user leaves site).  This can be graphed to give an idea of how long people stay on the site.
Number of view per page.  Which pages are attracting more interest than others?


Stats will differ depending on whether it is a web app or web page.  Most sites are a combination of both; Amazon is a web page until you want to buy something, then it is a web app.

It wouldn't surprise me if it turned out that most websites have certain ""hot spots,"" i.e. pages that are overwhelmingly viewed more than others.  Your clients want to know things like that, so they can attempt to reproduce the attraction effect for other pages/products.
",Robert Harvey,https://programmers.stackexchange.com/users/1204,http://programmers.stackexchange.com/questions/115036/what-kind-of-metrics-should-i-collect-for-a-website-web-app,TECHNOLOGY,programmers.stackexchange.com,1.0,0.5555555555555556,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.3333333333333333,0.7777777777777778,0.6666666666666666,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.3333333333333333,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.3333333333333333,0.3333333333333333,1.0,What metrics should I collect for a website / Web Application,"I have a website that allows users to register for accounts, login, and renew an annual membership fee. They can also update their personal profile, their personal profile, look at a list of their employees, make bulk payments for their employees, view receipts and invoices, etc.

For non-members it's a regular website with a lot of pages, but for members, it has quite a few member only areas, with more to come (Such as forums). It also has a job listings page, course registrations, etc.

What are some useful ""metrics"" I can collect to give me meaningful information about the site, that I can share with my clients. I really don't know a lot about collecting data about this kind of thing, and would like to learn.

I already have a dashboard where the admins can view/export registrations this week and registrations by week for the past 30 weeks. I've been able to show them that registrations spiked after sending out an email about the new system.

I'm think I'll also be adding stats about how often users update their profiles and how many users have updated their profile that day/week. 

Thanks
","What do your clients want to know?  Collect data on that.

That said, at a minimum I would collect (per web page):


Number of first-page views.
Number of pages viewed until abandonment (user leaves site).  This can be graphed to give an idea of how long people stay on the site.
Number of view per page.  Which pages are attracting more interest than others?


Stats will differ depending on whether it is a web app or web page.  Most sites are a combination of both; Amazon is a web page until you want to buy something, then it is a web app.

It wouldn't surprise me if it turned out that most websites have certain ""hot spots,"" i.e. pages that are overwhelmingly viewed more than others.  Your clients want to know things like that, so they can attempt to reproduce the attraction effect for other pages/products.
"
4655,4655,7378,Why is the 't' in Hash Table(Hashtable) in Java not capitalized,"Everything in Java seems to follow capitalization rules except for Hashtable. 

Hashtable&lt;String, String&gt; ht = new Hashtable&lt;String, String&gt;();


as opposed to 

ArrayList&lt;String&gt; a = new ArrayList&lt;String&gt;();


or 

HashMap&lt;String,Integer&gt; a = new HashMap&lt;String,Integer&gt;(); 


Why is this ? Is Hash Table read as just one word (Hashtable) ?
",Slartibartfast,https://stackoverflow.com/users/1081340,"Hashtable was created in Java v1. The consistent naming conventions for collections were established later, in Java2, when the other classes were published as part of the brand new Java Collection Framework.

Which btw made Hashtable obsolete, so it should not be used in new code.

Hope that helps.
",Balkrishan Nagpal,https://stackoverflow.com/users/378214,http://stackoverflow.com/questions/12506706/why-is-the-t-in-hash-tablehashtable-in-java-not-capitalized,STACKOVERFLOW,stackoverflow.com,0.6666666666666666,1.0,0.0,0.5,1.0,1.0,0.8333333333333334,0.6666666666666666,0.5,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.8333333333333334,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,1.0,Why is t in hash table not capitalized in Java,"Everything in Java seems to follow capitalization rules except for Hashtable. 

Hashtable&lt;String, String&gt; ht = new Hashtable&lt;String, String&gt;();


as opposed to 

ArrayList&lt;String&gt; a = new ArrayList&lt;String&gt;();


or 

HashMap&lt;String,Integer&gt; a = new HashMap&lt;String,Integer&gt;(); 


Why is this ? Is Hash Table read as just one word (Hashtable) ?
","The hash table was created in Java v1. Later, in Java 2, when other classes were published as part of the new Java collection framework, a consistent naming convention was established for collections."
1734,1734,2742,God the Father's possession of a body of flesh and bones,"There is a belief out there that God the Father has always possessed a body of flesh and bones. Some of the proponents of this belief don't find it contradictory to John 4:24 (""God is a Spirit"") as the verse may be referring only to one part of God without limiting God to being only that one part - just like, for example, in 1 Pet 3:20 (""eight souls were saved by water"") Peter called some humans ""souls"", but he didn't mean by that that they didn't posses bodies.

The example of Jesus after His resurrection, Who, while possessing a body of flesh and bones, still retains all the qualities that are usually ascribed only to God, for example, His omnipresence, could go along with this belief. 

I wonder if Biblical hermeneutics, namely the hermeneutics of the Old Testament, allows for this belief. If not, please, point out those places that speak against the validity of this belief.
",brilliant,https://christianity.stackexchange.com/users/234,"How could the Creator of the universe have a body of flesh and bones which are products of that universe?  Only by later humbling himself into that form and taking on the nature of the creation.  The OT never states that God the Father did this, and the NT quite consistently reaffirms that only Jesus has ever done this, and that the Father is invisible eternal spirit only.
",kurosch,https://christianity.stackexchange.com/users/1729,http://christianity.stackexchange.com/questions/13648/god-the-fathers-possession-of-a-body-of-flesh-and-bones,CULTURE,christianity.stackexchange.com,1.0,0.3333333333333333,0.0,0.3333333333333333,0.3333333333333333,0.0,0.5555555555555556,0.5555555555555556,0.3333333333333333,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.6666666666666667,0.0,0.0,1.0,0.8888888888888888,God the Father's possession of a body of flesh and bones,"There is a belief out there that God the Father has always possessed a body of flesh and bones. Some of the proponents of this belief don't find it contradictory to John 4:24 (""God is a Spirit"") as the verse may be referring only to one part of God without limiting God to being only that one part - just like, for example, in 1 Pet 3:20 (""eight souls were saved by water"") Peter called some humans ""souls"", but he didn't mean by that that they didn't posses bodies.

The example of Jesus after His resurrection, Who, while possessing a body of flesh and bones, still retains all the qualities that are usually ascribed only to God, for example, His omnipresence, could go along with this belief. 

I wonder if Biblical hermeneutics, namely the hermeneutics of the Old Testament, allows for this belief. If not, please, point out those places that speak against the validity of this belief.
","How could the Creator of the universe have a body of flesh and bones which are products of that universe?  Only by later humbling himself into that form and taking on the nature of the creation.  The OT never states that God the Father did this, and the NT quite consistently reaffirms that only Jesus has ever done this, and that the Father is invisible eternal spirit only.
"
3253,3253,5185,Python Condensing Code,"My code is pretty long and I need help condensing it to make it more convenient. The code I have is suppose to do the set of instructions I commanded it to do on a fluke robot. I am using python. The robot is suppose to do the following code using it sensors. I need help condensing it.

EDIT:

My code: 

from Myro import *
from Graphics import *
init('/dev/tty.IPRE6-366079-DevB')

def markYellow(pic):
    for pix in getPixels(pic):
        r = getRed(pix)
        g = getGreen(pix)
        b = getBlue(pix)
        if r &gt; 200 and b &lt; 90 and g &gt; 150:
            setRed(pix,255)
            setGreen(pix,255)
            setBlue(pix,255)
        else:
            setRed(pix,0)
            setGreen(pix,0)
            setBlue(pix,0)

def pctMarked(pic):
    totalPixels = 0
    whitePixels = 0
    for pix in getPixels(pic):
        if getRed(pix) == 255:
            whitePixels = whitePixels + 1
        totalPixels = totalPixels + 1
    result = whitePixels / float(totalPixels)
    return result


def findAvgX(pic):
    pixelCount  = 0
    totalXCount = 0
    for pix in getPixels(pic):
        if getRed(pix) == 255:
            x = getX(pix)
            totalXCount = totalXCount + x
            pixelCount = pixelCount + 1
    avgX = totalXCount / float( pixelCount)
    return avgX


def turn():
    findAvgX(pic)
    if wallLocation &lt;= 85:
        turnLeft(1,0.25)
    elif ballLocation &gt;= 170:
        turnRight(1,0.25)


def celebrate():
    move(0.25,1)
    beep(1,800)
    beep(1,1600)
    beep(1,800)
    stop()

def main():
    p = takePicture()
    markYellow(p)
    pctMarked(p)
    while pctMarked(pic) &lt; 0.2: 
        rotate(1,1)
        p = takePicture()
        markYellow(p)
        pctMarked(p)
    turn()
    while getObstacle('center')&gt; 1000: # I'm not sure about the number. We can test it tomorrow
        forward(1,1)
    celebrate()

",Q.matin,https://stackoverflow.com/users/1670186,"This implementation works on the idea that you have an ARGB pixel, if you have an RGB pixel replace:

0xFFFFFFFF with 0xFFFFFF

What I am doing is this:  

pixel = A R G B
A = 2 bytes
R = 2 bytes
G = 2 bytes
B = 2 bytes


so in hex that is:

pixel = 0xFF000000; # black
pixel = 0xFFFFFFFF; # white


A has to be FF (255) to have no transparency.

I should mention that I make an assumption with this code, that is, a pixel is in the form of a 32bit Integer.  



def markYellow(pic):
    for pix in getPixels(pic):
        if getRed(pix) &gt; 200 and getBlue(pix) &lt; 90 and getGreen(pix) &gt; 150:
            pix = 0xFFFFFFFF;
        else:
            pix = 0xFF000000;

def pctMarked(pic):
    totalPixels = 0
    whitePixels = 0
    for pix in getPixels(pic):
        if pix == 0xFFFFFFFF:
            whitePixels += 1
        totalPixels += 1
    return whitePixels / float(totalPixels)




couple of comments:
your pcMarked was only looking at red to find white, this meant it will pick up ALL fully red colours.
your markyellow function is making the pixel white instead of yellow.
",Serdalis,https://stackoverflow.com/users/958051,http://stackoverflow.com/questions/13169971/python-condensing-code,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.3333333333333333,0.0,1.0,1.0,1.0,0.4444444444444444,0.4444444444444444,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.8888888888888888,Python compressed code,"My code is pretty long and I need help condensing it to make it more convenient. The code I have is suppose to do the set of instructions I commanded it to do on a fluke robot. I am using python. The robot is suppose to do the following code using it sensors. I need help condensing it.

EDIT:

My code: 

from Myro import *
from Graphics import *
init('/dev/tty.IPRE6-366079-DevB')

def markYellow(pic):
    for pix in getPixels(pic):
        r = getRed(pix)
        g = getGreen(pix)
        b = getBlue(pix)
        if r &gt; 200 and b &lt; 90 and g &gt; 150:
            setRed(pix,255)
            setGreen(pix,255)
            setBlue(pix,255)
        else:
            setRed(pix,0)
            setGreen(pix,0)
            setBlue(pix,0)

def pctMarked(pic):
    totalPixels = 0
    whitePixels = 0
    for pix in getPixels(pic):
        if getRed(pix) == 255:
            whitePixels = whitePixels + 1
        totalPixels = totalPixels + 1
    result = whitePixels / float(totalPixels)
    return result


def findAvgX(pic):
    pixelCount  = 0
    totalXCount = 0
    for pix in getPixels(pic):
        if getRed(pix) == 255:
            x = getX(pix)
            totalXCount = totalXCount + x
            pixelCount = pixelCount + 1
    avgX = totalXCount / float( pixelCount)
    return avgX


def turn():
    findAvgX(pic)
    if wallLocation &lt;= 85:
        turnLeft(1,0.25)
    elif ballLocation &gt;= 170:
        turnRight(1,0.25)


def celebrate():
    move(0.25,1)
    beep(1,800)
    beep(1,1600)
    beep(1,800)
    stop()

def main():
    p = takePicture()
    markYellow(p)
    pctMarked(p)
    while pctMarked(pic) &lt; 0.2: 
        rotate(1,1)
        p = takePicture()
        markYellow(p)
        pctMarked(p)
    turn()
    while getObstacle('center')&gt; 1000: # I'm not sure about the number. We can test it tomorrow
        forward(1,1)
    celebrate()

","This implementation works on the idea that you have an ARGB pixel, if you have an RGB pixel replace:

0xFFFFFFFF with 0xFFFFFF

What I am doing is this:  

pixel = A R G B
A = 2 bytes
R = 2 bytes
G = 2 bytes
B = 2 bytes


so in hex that is:

pixel = 0xFF000000; # black
pixel = 0xFFFFFFFF; # white


A has to be FF (255) to have no transparency.

I should mention that I make an assumption with this code, that is, a pixel is in the form of a 32bit Integer.  



def markYellow(pic):
    for pix in getPixels(pic):
        if getRed(pix) &gt; 200 and getBlue(pix) &lt; 90 and getGreen(pix) &gt; 150:
            pix = 0xFFFFFFFF;
        else:
            pix = 0xFF000000;

def pctMarked(pic):
    totalPixels = 0
    whitePixels = 0
    for pix in getPixels(pic):
        if pix == 0xFFFFFFFF:
            whitePixels += 1
        totalPixels += 1
    return whitePixels / float(totalPixels)




couple of comments:
your pcMarked was only looking at red to find white, this meant it will pick up ALL fully red colours.
your markyellow function is making the pixel white instead of yellow.
"
4334,4334,6901,Brute force login attempt from spoofed IP's,"I see that many of my WordPress installs are being hit with 1000+ failed login attempts using non-existing 'admin' account name. The requests come from different IP's every time, and I see IP's such as 8.8.8.8 (google's public dns) as the origin of some of the login attempts.

I use WordFence to detect and block these attempts, but the block is based on IP, so it's not so efficient.

My question is:


Is it 'normal' for low profile WordPress sites to get these 'attacks'? I've notices an increase in the logs during the first days of 2013.
Is it something to worry about, and is it possible to detect/verify if a login request is coming from a spoofed IP?

",mikkelbreum,https://security.stackexchange.com/users/18625,"Its impossible to spoof your ip address of a TCP connection due to the 3 way handshake....  Unless of course the application is vulnerable to CWE-291: Trusting a Self Reported IP address

Sure enough in ./wordfence/lib/wfUtils.php on line 77:

public static function getIP(){
    $IP = 0;
    if(isset($_SERVER['HTTP_X_FORWARDED_FOR'])){
        $IP = $_SERVER['HTTP_X_FORWARDED_FOR'];


So yes,  the reason why you are seeing brute force attempts from 8.8.8.8 is because WordFence is vulnerable to CWE-291.  I am reporting this vulnerability to WordFence,  but to be honest this vulnerability is so painfully obvious.  If the developer doesn't understand even the most basic flaws of trusting attacker input, then they have probably made other serious mistakes that impact security, I smell blood.

Its possible that a security system can make your system as a whole less secure.  This is nothing new, remote code execution vulnerabilities have been found in anti-virus software. Complexity is the worst enemy of security.
",rook,https://security.stackexchange.com/users/975,http://security.stackexchange.com/questions/27958/brute-force-login-attempt-from-spoofed-ips,TECHNOLOGY,security.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.4444444444444444,0.3333333333333333,1.0,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.8888888888888888,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,0.8888888888888888,Violent login attempts from spoofing IP,"I see that many of my WordPress installs are being hit with 1000+ failed login attempts using non-existing 'admin' account name. The requests come from different IP's every time, and I see IP's such as 8.8.8.8 (google's public dns) as the origin of some of the login attempts.

I use WordFence to detect and block these attempts, but the block is based on IP, so it's not so efficient.

My question is:


Is it 'normal' for low profile WordPress sites to get these 'attacks'? I've notices an increase in the logs during the first days of 2013.
Is it something to worry about, and is it possible to detect/verify if a login request is coming from a spoofed IP?

","Its impossible to spoof your ip address of a TCP connection due to the 3 way handshake....  Unless of course the application is vulnerable to CWE-291: Trusting a Self Reported IP address

Sure enough in ./wordfence/lib/wfUtils.php on line 77:

public static function getIP(){
    $IP = 0;
    if(isset($_SERVER['HTTP_X_FORWARDED_FOR'])){
        $IP = $_SERVER['HTTP_X_FORWARDED_FOR'];


So yes,  the reason why you are seeing brute force attempts from 8.8.8.8 is because WordFence is vulnerable to CWE-291.  I am reporting this vulnerability to WordFence,  but to be honest this vulnerability is so painfully obvious.  If the developer doesn't understand even the most basic flaws of trusting attacker input, then they have probably made other serious mistakes that impact security, I smell blood.

Its possible that a security system can make your system as a whole less secure.  This is nothing new, remote code execution vulnerabilities have been found in anti-virus software. Complexity is the worst enemy of security.
"
1785,1785,2836,"Problem in blitting a clean, crisp sprite","I am having a bit of a tooling problem...and I am unsure of how to solve it.

I am currently using PyGame to try and write a simple Minesweeper clone, except my sprites that I made are hexagon based and therefore have diagonal lines.

I drew up a nice, clean, crisp vector sprite set which looks very nice in Inkscape, however once I export it everything goes to hell.  I'm going to outline what I've done below and hopefully somebody here can set me straight :D

Disclaimer: Unfortunately I'm behind a proxy and cannot provide screenshots at the moment..I'll do my best to describe.

If I attempt to use a color key (0xFF00FF), then when I set the color key in PyGame I get a bunch of jagged pink edges along my sprite.  I believe this could be an anti-aliasing issue with Inkscape, but unfortunately my Googling didn't turn up a way to disable it.

If I import my PNG into Photoshop or the Gimp and delete the background, then I run into an issue where the background appears to be black when running the game.  I have tried to follow the instructions I saw on SO, but to no avail.

I am open to suggestions, but at this point I'm debating importing another library which can handle SVG graphics, in order to keep my clean, crisp diagonal lines.
",espais,https://gamedev.stackexchange.com/users/1743,"For your pink halo-ing, the issue is exactly what you described: anti-aliasing. If you have Photoshop, just create the hexagon with two layers, one with all pink (0xFF00FF) and another with the hexagon. Make sure when you create the hexagon all feathering and anti-aliasing settings are set to zero for all the tools you use, and all brushes are set to 100% hardness. Save as a PNG.

For best results, stick to the pencil and paint bucket tools.
",Casey,https://gamedev.stackexchange.com/users/7367,http://gamedev.stackexchange.com/questions/15450/problem-in-blitting-a-clean-crisp-sprite,TECHNOLOGY,gamedev.stackexchange.com,0.6666666666666666,0.3333333333333333,0.0,0.0,1.0,0.0,0.6666666666666666,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,1.0,0.3333333333333333,1.0,1.0,0.6,1.0,0.0,0.0,1.0,"The problem of cutting a clean, crisp sprite into small pieces","I am having a bit of a tooling problem...and I am unsure of how to solve it.

I am currently using PyGame to try and write a simple Minesweeper clone, except my sprites that I made are hexagon based and therefore have diagonal lines.

I drew up a nice, clean, crisp vector sprite set which looks very nice in Inkscape, however once I export it everything goes to hell.  I'm going to outline what I've done below and hopefully somebody here can set me straight :D

Disclaimer: Unfortunately I'm behind a proxy and cannot provide screenshots at the moment..I'll do my best to describe.

If I attempt to use a color key (0xFF00FF), then when I set the color key in PyGame I get a bunch of jagged pink edges along my sprite.  I believe this could be an anti-aliasing issue with Inkscape, but unfortunately my Googling didn't turn up a way to disable it.

If I import my PNG into Photoshop or the Gimp and delete the background, then I run into an issue where the background appears to be black when running the game.  I have tried to follow the instructions I saw on SO, but to no avail.

I am open to suggestions, but at this point I'm debating importing another library which can handle SVG graphics, in order to keep my clean, crisp diagonal lines.
","For your pink halo-ing, the issue is exactly what you described: anti-aliasing. If you have Photoshop, just create the hexagon with two layers, one with all pink (0xFF00FF) and another with the hexagon. Make sure when you create the hexagon all feathering and anti-aliasing settings are set to zero for all the tools you use, and all brushes are set to 100% hardness. Save as a PNG.

For best results, stick to the pencil and paint bucket tools.
"
5599,5599,8885,"Hide ""Close Window"" option from taskbar","I want to make a window that has an icon on the taskbar, but does not have the option to be closed from there.  I could simply intercept WM_CLOSE, but then a non-functional option still remains on the window's taskbar menu.  There are other questions on stackoverflow pertaining to that method, but none that describe how to hide the option itself.  How can I accomplish this?
",NmdMystery,https://stackoverflow.com/users/2228070,"The Taskbar button uses the same menu that is assigned to the window itself.  There is no way to differentiate whether the menu is being invoked by clicking on the Taskbar versus clicking on the window (or even if it is being invoked by mouse or keyboard, for that matter).  If you disable the ""Close"" item, the user would not be able to close the window at all.  So just don't do it.
",Remy Lebeau,https://stackoverflow.com/users/65863,http://stackoverflow.com/questions/24520757/hide-close-window-option-from-taskbar,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.4444444444444444,0.0,0.3333333333333333,1.0,0.6666666666666666,0.6666666666666666,0.4444444444444444,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.0,0.8888888888888888,0.7777777777777778,0.5555555555555556,1.0,0.8888888888888888,0.6666666666666667,0.6666666666666666,0.0,0.6666666666666666,0.8888888888888888,Hide the close window option from the taskbar,"I want to create a window with an icon on the taskbar, but there is no option to close it from there. I can simply intercept WM? Close, but there is still a non functional option on the taskbar menu of the window. Stack overflow has other issues related to this method, but none describe how to hide the options themselves. How can I do that?","The taskbar button uses the same menu assigned to the window itself. There is no way to tell whether a menu is called by clicking the taskbar or by clicking the window (or even by clicking the mouse or keyboard). If the close item is disabled, the user cannot close the window at all. So don't do that."
4717,4717,7483,How do I burn a DVD with more than 3.8 GB data?,"I use Kubuntu 12.04 with KDE 4.8.3 and wodim / genisoimage 1.1.11, but the problem is on Ubuntu (with Brasero) and occurred in Oneiric as well.

Whenever I try to burn more than 3.8GB (approaching the 4 GB limit) of data onto a DVD, burning fails, aborts, or gives an ""error 254.""

I have lost more than 50 DVDs this way until I learned about the 3.8GB limit. Anything under 3.8GB burns fine, and DVDs burned with more than 3.8GB have usable data up to 3.8 GB, but then the remaining data is garbled, unaccessible, or the disk is just not recognized.

I'm pretty certain this is related to the replacement of cdrecord / mkisofs with wodim /genioimage (which is a problem that has been described for years). Is there another answer or fix? Re-installing cdrtools/cdrecord/mkisofs in Oneiric and Precise has become a herculean task.  
",Perspectoff,https://askubuntu.com/users/70130,"I have had numerous problems with the CD burning software on Ubuntu. Only one option eventually satisfied me (but unfortunately it is not open source): Nero Linux 4.  Nero offers a free 30 trial before you have to buy. I don't know if Nero will solve the problem you are experiencing or not. But it being propietary might bypass whatever is causing the problem on Ubuntu?

What I would recommend is to try K3B on Ubuntu. You will have to install the KDE libraries to install K3B though. If K3B does not work for you, I would try Nero. Nero for Linux did everything I asked and had all the options I was looking for.

I'm hoping that the poor quality and dearth of features of the open source CD burning options will be addressed at some point for Ubuntu because I don't like having to use closed source stuff. But, unfortunately, I have not found a better alternative for CD burning on Ubuntu.
",Chad--24216,https://askubuntu.com/users/24216,http://askubuntu.com/questions/149839/how-do-i-burn-a-dvd-with-more-than-3-8-gb-data,TECHNOLOGY,askubuntu.com,1.0,0.7777777777777778,0.0,0.6666666666666666,0.3333333333333333,1.0,0.4444444444444444,0.4444444444444444,0.3333333333333333,0.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.0,0.0,0.8888888888888888,How to record DVDs with data over 3.8 GB?,"I use Kubuntu 12.04 with KDE 4.8.3 and wodim / genisoimage 1.1.11, but the problem is on Ubuntu (with Brasero) and occurred in Oneiric as well.

Whenever I try to burn more than 3.8GB (approaching the 4 GB limit) of data onto a DVD, burning fails, aborts, or gives an ""error 254.""

I have lost more than 50 DVDs this way until I learned about the 3.8GB limit. Anything under 3.8GB burns fine, and DVDs burned with more than 3.8GB have usable data up to 3.8 GB, but then the remaining data is garbled, unaccessible, or the disk is just not recognized.

I'm pretty certain this is related to the replacement of cdrecord / mkisofs with wodim /genioimage (which is a problem that has been described for years). Is there another answer or fix? Re-installing cdrtools/cdrecord/mkisofs in Oneiric and Precise has become a herculean task.  
","I have had numerous problems with the CD burning software on Ubuntu. Only one option eventually satisfied me (but unfortunately it is not open source): Nero Linux 4.  Nero offers a free 30 trial before you have to buy. I don't know if Nero will solve the problem you are experiencing or not. But it being propietary might bypass whatever is causing the problem on Ubuntu?

What I would recommend is to try K3B on Ubuntu. You will have to install the KDE libraries to install K3B though. If K3B does not work for you, I would try Nero. Nero for Linux did everything I asked and had all the options I was looking for.

I'm hoping that the poor quality and dearth of features of the open source CD burning options will be addressed at some point for Ubuntu because I don't like having to use closed source stuff. But, unfortunately, I have not found a better alternative for CD burning on Ubuntu.
"
2582,2582,4108,"GIN/GiST Full Text searches through openlayers, geoserver and postgres","I have a a web app that automatically maps recent tweets and allows you to search for certain keywords. it uses Postgres for the database, geoserver as the server, and openlayers as the cartographic library. Right now tweet keywords are done using the ILIKE query.

This works pretty well if the keyword i'm looking for is a commonly used word, like 'love' , 'friend', 'OMG', etc. but less common words like ""geospatial"" need to search through a lot more data in order to find the last n instances of the word. This is dead slow.

To combat my slowness I'm building a GIN index on my tweet field in postgres. Two days later and i'm still waiting for the index to complete. Once it's built though, I'll try a few queries using SQL view parameters and hopefully this will dramatically speed things up.

Even if this approach works though, it's not going to be all that useful if the index takes so long to create -- the maintenance of it will not be able to keep up will the incoming flood of data. I think I will try out the GiST index next and see how long it takes as I understand it is much faster to this build index. 

Beyond this, what can I do next? Do options like Solr work with Geoserver?? Are there any common approaches to this type of problem and data size/rate?
",mikedotonline,https://gis.stackexchange.com/users/24616,"You could use GeoAlchemy + Full Text Search (FTS). It can probably increase the speed of your queries. However, it seems that FTS needs to be adapted to do such work in GA. I put below some links that may give you some more insights on both tools:

GeoAlchemy:


http://frankpurcell.com/code/tutorial
http://www.geoalchemy.org/_sources/tutorial.txt
https://github.com/geoalchemy/geoalchemy/tree/master/examples
https://geoalchemy-2.readthedocs.org/en/latest/orm_tutorial.html


FTS (with SqlAlchemy, but it's already adapted to SA as a patch):


http://nibrahim.net.in/2013/11/29/sqlalchemy_and_full_text_searching_in_postgresql.html

",Gery,https://gis.stackexchange.com/users/10596,http://gis.stackexchange.com/questions/82627/gin-gist-full-text-searches-through-openlayers-geoserver-and-postgres,TECHNOLOGY,gis.stackexchange.com,1.0,0.3333333333333333,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.5555555555555556,0.4444444444444444,1.0,0.0,1.0,0.6666666666666666,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.3333333333333333,0.0,1.0,"Gin / gist full text search openlayers, GeoServer and Postgres","I have a a web app that automatically maps recent tweets and allows you to search for certain keywords. it uses Postgres for the database, geoserver as the server, and openlayers as the cartographic library. Right now tweet keywords are done using the ILIKE query.

This works pretty well if the keyword i'm looking for is a commonly used word, like 'love' , 'friend', 'OMG', etc. but less common words like ""geospatial"" need to search through a lot more data in order to find the last n instances of the word. This is dead slow.

To combat my slowness I'm building a GIN index on my tweet field in postgres. Two days later and i'm still waiting for the index to complete. Once it's built though, I'll try a few queries using SQL view parameters and hopefully this will dramatically speed things up.

Even if this approach works though, it's not going to be all that useful if the index takes so long to create -- the maintenance of it will not be able to keep up will the incoming flood of data. I think I will try out the GiST index next and see how long it takes as I understand it is much faster to this build index. 

Beyond this, what can I do next? Do options like Solr work with Geoserver?? Are there any common approaches to this type of problem and data size/rate?
","You could use GeoAlchemy + Full Text Search (FTS). It can probably increase the speed of your queries. However, it seems that FTS needs to be adapted to do such work in GA. I put below some links that may give you some more insights on both tools:

GeoAlchemy:


http://frankpurcell.com/code/tutorial
http://www.geoalchemy.org/_sources/tutorial.txt
https://github.com/geoalchemy/geoalchemy/tree/master/examples
https://geoalchemy-2.readthedocs.org/en/latest/orm_tutorial.html


FTS (with SqlAlchemy, but it's already adapted to SA as a patch):


http://nibrahim.net.in/2013/11/29/sqlalchemy_and_full_text_searching_in_postgresql.html

"
367,367,580,Why is the pixel count of RAW images from the Panasonic LX5 slightly larger than the generated JPEGs?,"I'm new to working with RAW images, and I'm capturing simultaneous RAW+JPGs with my new Lumix LX5, and using Bibble to view/process the results.

I'm very surprised that the RAW images taken at 24mm wide 16x9 seem to capture a different (and larger) sensor area compared to the JPGs. The RAW images seem to contain the equivalent of about 100 extra pixels on left and right sides, and a smaller number top and bottom. I say ""equivalent"", because the actual pixel counts of RAW and JPG are only slightly different, which implies some resizing must be going on...?

JPG: 3968 x 2232
RAW: 3976 x 2238

I guess this small difference is because JPG images must be 16x16 multiples>

The raw image displays noticeable vignetting in the extra pixels, and there's a fair bit of chromatic aberration. I can crop off the 'extra' pixels, but then my RAW image has fewer pixels in it than the JPG, which doesn't feel right. 

I'll try and add samples shortly.
",Roddy,https://photo.stackexchange.com/users/562,"Firstly there are a couple of general reasons raw and JPEG images differ in size, and raw differs from the actual number of pixels on the sensor:

Whilst JPEG image dimensions don't have to be multiples of 16 (or 8 if not using chroma subsampling) it is more efficient to do so, as it allows you to rotate the images without re-encoding (lossless rotation). So that can account for a small image size difference, as you say.

Even raw image sizes typically differ from the actual number of pixels as most sensors have strips masked pixels (that receive no light) down each side in order to detect banding issues with uneven amplification. Further, the size you see in your raw viewer will differ from the actual raw data as some image processing operations use a form of averaging which doesn't work at extreme edges (because there's no data beyond the image to use when averaging) so they get cropped off when the image is viewed/converted.

Secondly the Panasonic Lumix LX3 and LX5 have a different sensor design to most cameras, which is partially responsible for the difference in coverage between raw and jpeg you are experiencing:

The maximum 16:9 image size is actually wider than the maximum 4:3 image size. You would expect them to be the same width but different heights.

This is because they've made the sensor a bit wider for 16:9, employing a non rectangular design and it's pushing the very edges of the lens image circle, this explains the vignetting and CA you observe with the raw. This diagram shows the irregular design: 



As John Cavan suggests, the JPEG image pipeline is doing some correction, including barrel distortion correction, given that 24mm equiv. is very wide for a compact, and the sensor is pushing to the very edge of the image circle. 

Barrel distortion correction makes straight lines straight again, but will cause the image edges to bend in response. In response to this the correcting transformation enlarges the image slightly and crops to get straight edges again. 

Can you see any differences in the appearance of straight lines between the raw and JPEG? It might be quite subtle but get revealed if you overlay them. 
",Matt Grum,https://photo.stackexchange.com/users/1375,http://photo.stackexchange.com/questions/4242/why-is-the-pixel-count-of-raw-images-from-the-panasonic-lx5-slightly-larger-than,LIFE_ARTS,photo.stackexchange.com,1.0,0.8888888888888888,0.0,1.0,0.6666666666666666,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,1.0,Why is the original image pixel number of Panasonic LX5 slightly larger than the generated JPEG?,"I'm new to working with RAW images, and I'm capturing simultaneous RAW+JPGs with my new Lumix LX5, and using Bibble to view/process the results.

I'm very surprised that the RAW images taken at 24mm wide 16x9 seem to capture a different (and larger) sensor area compared to the JPGs. The RAW images seem to contain the equivalent of about 100 extra pixels on left and right sides, and a smaller number top and bottom. I say ""equivalent"", because the actual pixel counts of RAW and JPG are only slightly different, which implies some resizing must be going on...?

JPG: 3968 x 2232
RAW: 3976 x 2238

I guess this small difference is because JPG images must be 16x16 multiples>

The raw image displays noticeable vignetting in the extra pixels, and there's a fair bit of chromatic aberration. I can crop off the 'extra' pixels, but then my RAW image has fewer pixels in it than the JPG, which doesn't feel right. 

I'll try and add samples shortly.
","Firstly there are a couple of general reasons raw and JPEG images differ in size, and raw differs from the actual number of pixels on the sensor:

Whilst JPEG image dimensions don't have to be multiples of 16 (or 8 if not using chroma subsampling) it is more efficient to do so, as it allows you to rotate the images without re-encoding (lossless rotation). So that can account for a small image size difference, as you say.

Even raw image sizes typically differ from the actual number of pixels as most sensors have strips masked pixels (that receive no light) down each side in order to detect banding issues with uneven amplification. Further, the size you see in your raw viewer will differ from the actual raw data as some image processing operations use a form of averaging which doesn't work at extreme edges (because there's no data beyond the image to use when averaging) so they get cropped off when the image is viewed/converted.

Secondly the Panasonic Lumix LX3 and LX5 have a different sensor design to most cameras, which is partially responsible for the difference in coverage between raw and jpeg you are experiencing:

The maximum 16:9 image size is actually wider than the maximum 4:3 image size. You would expect them to be the same width but different heights.

This is because they've made the sensor a bit wider for 16:9, employing a non rectangular design and it's pushing the very edges of the lens image circle, this explains the vignetting and CA you observe with the raw. This diagram shows the irregular design: 



As John Cavan suggests, the JPEG image pipeline is doing some correction, including barrel distortion correction, given that 24mm equiv. is very wide for a compact, and the sensor is pushing to the very edge of the image circle. 

Barrel distortion correction makes straight lines straight again, but will cause the image edges to bend in response. In response to this the correcting transformation enlarges the image slightly and crops to get straight edges again. 

Can you see any differences in the appearance of straight lines between the raw and JPEG? It might be quite subtle but get revealed if you overlay them. 
"
298,298,480,How should I design a table with nested categories for users?,"I am really confused with user interface design of the website.
I want to design the Detailed view of the student.

So on the page there will be information about the students like name , class roll number etc.

Then i will have many rows for his smemesters , then each semester will have many subjects , then each subject will have many assignments.

Now i am not able to figure out how can i design the layout of the page.

can anyone give me idea or show me something on , how should i go
",user2082226,https://ux.stackexchange.com/users/27595,"From your description, I've taken the liberty to make a mockup to give you something to work on. It is a simple suggestion on how you can organize elements in groups and subgroups regarding a students life (at the university).

On the Semesters tab I suggest an accordion control to interact with the different courses in terms of assignments, reports, project and of course a link to course info.







download bmml source &ndash; Wireframes created with Balsamiq Mockups

Feel free to make comments and suggestions and I'll do my best to get your project moving forward.
",Benny Skogberg,https://ux.stackexchange.com/users/4679,http://ux.stackexchange.com/questions/35391/how-should-i-design-a-table-with-nested-categories-for-users,TECHNOLOGY,ux.stackexchange.com,0.7777777777777778,0.7777777777777778,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,0.5555555555555556,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.4444444444444444,1.0,0.6666666666666666,0.8888888888888888,1.0,0.9,0.3333333333333333,0.3333333333333333,0.0,0.8888888888888888,How to design tables with nested categories for users?,"I am really confused with user interface design of the website.
I want to design the Detailed view of the student.

So on the page there will be information about the students like name , class roll number etc.

Then i will have many rows for his smemesters , then each semester will have many subjects , then each subject will have many assignments.

Now i am not able to figure out how can i design the layout of the page.

can anyone give me idea or show me something on , how should i go
","From your description, I've taken the liberty to make a mockup to give you something to work on. It is a simple suggestion on how you can organize elements in groups and subgroups regarding a students life (at the university).

On the Semesters tab I suggest an accordion control to interact with the different courses in terms of assignments, reports, project and of course a link to course info.







download bmml source &ndash; Wireframes created with Balsamiq Mockups

Feel free to make comments and suggestions and I'll do my best to get your project moving forward.
"
811,811,1284,I need help! PopUp with only OK button,"I need help!  I have an Ipad.  A pop up came on my  screen giving an htpp : ip adress and a nasty sexual message.  There is only an OK button and I cannot close it.  It seems to be have frozen my web browser .  I'm using Safari.  I read some examples on this site.  I tried to download AVAST but finally I unstalled it.  I cannot find ClamXAV.  Should I click the ok button and then close all the Windows?  Since I have no access to internet can I download G-Whizz Apps Browser?  Can I have two browsers on the same Ipad, or will I loose all my favorites and stuff from Safari?

I'm 61, not very familiar with all this computer language, but willing to learn even if I find this very difficult!  

p.s.  Now I seem unable to send this message because I need a tag.... now what is a tag.  I can see many suggestions so I will chose ipad, because this is what I have, but why I'm doing it, is a mystery???
",Suzanne,https://superuser.com/users/230037,"Mobile Safari will disable the browser controls (new tab, back, etc.) when a JavaScript popup is opened. Unfortunately, this locks the browser until you press ""OK"" or ""Cancel"" (if available).

To get rid of the popup without clicking ""OK"" or ""Cancel"":


If you are in Mobile Safari, close it by pressing the home button.
Kill Mobile Safari by double-tapping the home button to bring up the bottom panel, tapping and holding the Mobile Safari icon, and then tapping the minus sign (-) at the top left of the icon.
Open the Settings app.
Click on ""Safari"".
Click on ""Advanced""
Uncheck/Turn off ""Java Script""
Go into Flight mode or turn the Wlan off
Open Safari and close the tab (of the former bugging popup - it wont open this time, because JavaScript is disabled :-) )
Turn Wlan and Java Script on again
enjoy the lack of the stupid popup in your Browser. ;-)


So this way you dont have to clean your cache.
",iglvzx,https://superuser.com/users/100787,http://superuser.com/questions/605463,TECHNOLOGY,superuser.com,1.0,0.3333333333333333,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.3333333333333333,0.6666666666666666,0.0,0.6666666666666666,0.0,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.0,0.3333333333333333,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.6666666666666666,1.0,I need help! Pop up menu with OK button only,"I need help! I have an iPad. A pop-up window appears on my screen with an HTPP: IP address and a nasty sexual message. There is only one ""OK"" button, I can't close it. It seems to freeze my web browser. I'm using the wildlife park. I read some examples on this website. I tried to download avast, but it didn't work. I can't find clamxav. Should I click OK and close all windows? Because I can't get online, can I download the g-whizz app browser? Can I have two browsers on the same iPad? Or will I delete everything I like from safari?","Mobile Safari will disable the browser controls (new tab, back, etc.) when a JavaScript popup is opened. Unfortunately, this locks the browser until you press ""OK"" or ""Cancel"" (if available).

To get rid of the popup without clicking ""OK"" or ""Cancel"":


If you are in Mobile Safari, close it by pressing the home button.
Kill Mobile Safari by double-tapping the home button to bring up the bottom panel, tapping and holding the Mobile Safari icon, and then tapping the minus sign (-) at the top left of the icon.
Open the Settings app.
Click on ""Safari"".
Click on ""Advanced""
Uncheck/Turn off ""Java Script""
Go into Flight mode or turn the Wlan off
Open Safari and close the tab (of the former bugging popup - it wont open this time, because JavaScript is disabled :-) )
Turn Wlan and Java Script on again
enjoy the lack of the stupid popup in your Browser. ;-)


So this way you dont have to clean your cache.
"
4943,4943,7871,The mechanics of Aspects on weapons/armor?,"Fate Core suggests one way to differentiate weapons and armor is by giving each one an Aspect. Daggers could be Quick, for instance, and maces could be Armor Piercing. I really like this idea. My question is, how would this actually work mechanically? I'm trying to picture how this would tie into ""Creating an Advantage"" or how it would modify attack rolls or shifts. 

A few examples to help fuel thinking caps:


Quick Dagger vs. Heavy Greatsword?
Long Spear vs. Balanced Longsword?


Any thoughts? 
",kevlar1818,https://rpg.stackexchange.com/users/6051,"It would simply give you excuses for invokes and compels, based on the aspect text. Nothing less, nothing more.


  — Wesroth attacks Quadron using his longsword, with Fighting 3
  
  — Ok but Quadron has a Long Spear, here's a compel for you, this fate point says Wesroth spends this exchange trying to close in with Quadron, struggling to find an opening.
  
  — Good call, but no, I refuse your compel. Here's a fate point, Wesroth does manage to attack despite the long spear
  
  Wesroth:Attack: [Roll + + - ·] + [Fighting 3] = +4(Great)
  
  Quadron:Defend: [Roll + - · ·] + [Fighting 2] = +2(Fair)
  
  — Whoops, that's physical stress box #2 for me …err… Quadron. Fortunately Quadron can take it and live.
  
  — Not so fast, Wesroth has a Balanced longsword, and I invoke it. He feints an attack but flips the sword and uses the pommel to push Quadron's spear aside, easily getting inside his guard. That brings my roll into a fantastic +6. I guess that's a #4 stress box, which Quadron doesn't have
  
  — Oh cr*p! …


… and it goes on like this
",edgerunner,https://rpg.stackexchange.com/users/554,http://rpg.stackexchange.com/questions/19783/the-mechanics-of-aspects-on-weapons-armor,CULTURE,rpg.stackexchange.com,1.0,0.3333333333333333,0.3333333333333333,0.0,1.0,0.0,0.6666666666666666,0.7777777777777778,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.0,1.0,0.6666666666666666,0.6666666666666666,0.7777777777777778,1.0,0.9333333333333332,0.0,0.3333333333333333,0.6666666666666666,0.8888888888888888,Weapons / armor mechanisms?,"The core of destiny has put forward a way to distinguish weapons and armor, that is, to give each weapon an aspect. For example, a dagger can be fast, while a mace can wear armor. I really like the idea. My question is, how does this work mechanically? I try to imagine how this will be combined with ""create advantage,"" or how it will modify attack roll or move.","It would simply give you excuses for invokes and compels, based on the aspect text. Nothing less, nothing more.


  — Wesroth attacks Quadron using his longsword, with Fighting 3
  
  — Ok but Quadron has a Long Spear, here's a compel for you, this fate point says Wesroth spends this exchange trying to close in with Quadron, struggling to find an opening.
  
  — Good call, but no, I refuse your compel. Here's a fate point, Wesroth does manage to attack despite the long spear
  
  Wesroth:Attack: [Roll + + - ·] + [Fighting 3] = +4(Great)
  
  Quadron:Defend: [Roll + - · ·] + [Fighting 2] = +2(Fair)
  
  — Whoops, that's physical stress box #2 for me …err… Quadron. Fortunately Quadron can take it and live.
  
  — Not so fast, Wesroth has a Balanced longsword, and I invoke it. He feints an attack but flips the sword and uses the pommel to push Quadron's spear aside, easily getting inside his guard. That brings my roll into a fantastic +6. I guess that's a #4 stress box, which Quadron doesn't have
  
  — Oh cr*p! …


… and it goes on like this
"
1430,1430,2247,Set proxy in nightwatch.js,"I'm writing Integration Tests using nightwatch.js in a Node.js application. For a particular test case, I want nightwatch to connect via a proxy. What would be the right way to do this? I can't find anything from its official documentation, or from its Google Group.

The Selenium documentation suggests setting it on the webdriver instance as described here. I'm not sure how to do this via nightwatch.
",kodeninja,https://stackoverflow.com/users/408626,"In the nightwatch.json configuration file, you should be able to set a proxy parameter in the desiredCapabilities:

""chrome"" : {
  ""desiredCapabilities"": {
    ""browserName"": ""chrome"",
    ""javascriptEnabled"": true,
    ""acceptSslCerts"": true,
    ""chromeOptions"" : {
      ""args"" : [
        ""disable-extensions"",
        ""start-maximized""
      ]
    },
    ""proxy"": {
      ""proxyType"": ""manual"",
      ""httpProxy"": ""your_proxy:8080""
    }
  }
},


Check this doc: https://code.google.com/p/selenium/wiki/JsonWireProtocol#Proxy_JSON_Object
",Nicolas Pennec,https://stackoverflow.com/users/4328275,http://stackoverflow.com/questions/30384818/set-proxy-in-nightwatch-js,STACKOVERFLOW,stackoverflow.com,1.0,0.3333333333333333,0.0,1.0,1.0,1.0,0.5,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.5,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.5,0.5,0.0,0.8333333333333334,Setting up the proxy in nightwatch.js,"I am writing integration tests in the node.js application using nightwatch.js. For specific test cases, I want nightwatch to connect through a proxy. What's the right way to do it? I can't find its official documents or its Google Group.","In the nightwatch.json configuration file, you should be able to set a proxy parameter in the desiredCapabilities:

""chrome"" : {
  ""desiredCapabilities"": {
    ""browserName"": ""chrome"",
    ""javascriptEnabled"": true,
    ""acceptSslCerts"": true,
    ""chromeOptions"" : {
      ""args"" : [
        ""disable-extensions"",
        ""start-maximized""
      ]
    },
    ""proxy"": {
      ""proxyType"": ""manual"",
      ""httpProxy"": ""your_proxy:8080""
    }
  }
},


Check this doc: https://code.google.com/p/selenium/wiki/JsonWireProtocol#Proxy_JSON_Object
"
4335,4335,6902,Thunderbird 2.0: Inbox size is 4GB on disk: how do I reduce it?,"Mozilla Thunderbird 2.0: I have set Thunderbird never to delete a message that is on disk...Thus, after four short years, I have a 4GB Inbox file. Thunderbird needs about 10 minutes to read it, and even then I can't compact it. Anyone have some suggestions?
",Eric,https://superuser.com/users/15673,"When you say you can't compact the file, what are you actually doing?  By this, I mean that ""compacting"" in Thunderbird is not like running your inbox through a compression algorithm like you would to create a .zip file.

The ""compact"" option in Thunderbird is there because deleting a message does not remove the message from your disk, it is just hidden - therefore, you use ""compact"" to remove these ""deleted"" messages from the data file.

You will need to clean out your mailbox by saving and deleting messages that are no longer needed and then running the ""compact"" option.
",Nick,https://superuser.com/users/51218,http://superuser.com/questions/198503,TECHNOLOGY,superuser.com,0.8888888888888888,0.6666666666666666,0.0,0.0,1.0,0.0,0.5555555555555556,0.5555555555555556,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,1.0,1.0,0.4,0.3333333333333333,0.6666666666666666,0.3333333333333333,0.8333333333333334,Thunderbird 2.0: the inbox size is 4GB disk: how to reduce it?,"Mozilla Thunderbird 2.0: I have set Thunderbird to never delete messages on disk So, in just four years, I have a 4GB inbox file. Thunderbird takes 10 minutes to read, and even then I can't compress it. Is there any suggestion?","When you say you can't compact the file, what are you actually doing?  By this, I mean that ""compacting"" in Thunderbird is not like running your inbox through a compression algorithm like you would to create a .zip file.

The ""compact"" option in Thunderbird is there because deleting a message does not remove the message from your disk, it is just hidden - therefore, you use ""compact"" to remove these ""deleted"" messages from the data file.

You will need to clean out your mailbox by saving and deleting messages that are no longer needed and then running the ""compact"" option.
"
2669,2669,4253,display tag and c choose tag,"I use the following code. But it is always go to the otherwise condition. I checked the value , and those are correctly passed from java to the jsp. Any missing points?

&lt;c:when test=""${pCount &gt; 0}""&gt;
    &lt;display:column class=""colPCount"" property=""pCount "" title=""${titlePCount}"" sortable=""true"" headerClass=""sortable"" /&gt;
&lt;/c:when&gt;
&lt;c:otherwise&gt;
    &lt;display:column class=""colPCount"" title=""${titlePCount}""&gt;&amp;nbsp;-&amp;nbsp;&lt;/display:column&gt;
&lt;/c:otherwise&gt;


For the pcount>0 items, still displaying as  '-' in the display tag. Even I reverse the checking condition like pCount&lt;0 in the first condition checking, the display tag always show the otherwise condition. It always pointing to the otherwise condition for every value.

Edited: Full Code

    &lt;display:table class=""displayTable"" id=""itemList""
        name=""${sessionScope.itemList}"" requestURI=""listItem.action""
        pagesize=""15"" defaultsort=""2"" defaultorder=""ascending"" sort=""list""&gt;
        &lt;display:column class=""colItemName"" property=""name""
            title=""${titleItemName}"" sortable=""true"" headerClass=""sortable""/&gt;
        ...
        &lt;c:choose&gt;
        &lt;c:when test=""${pCount &gt; 0}""&gt;
            &lt;display:column class=""colPCount"" property=""pCount "" title=""${titlePCount}"" sortable=""true"" headerClass=""sortable"" /&gt;
        &lt;/c:when&gt;
        &lt;c:otherwise&gt;
            &lt;display:column class=""colPCount"" title=""${titlePCount}""&gt;&amp;nbsp;-&amp;nbsp;&lt;/display:column&gt;
        &lt;/c:otherwise&gt;
        &lt;/c:choose&gt;
    &lt;/display:table&gt;

",kitokid,https://stackoverflow.com/users/751689,"Try this way: ${itemList.pCount&gt;0}
",Alex,https://stackoverflow.com/users/1599479,http://stackoverflow.com/questions/12831136/display-tag-and-c-choose-tag,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.3333333333333333,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.0,0.3333333333333333,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.0,0.0,1.0,Show tags and select Tags,"I use the following code. But it is always go to the otherwise condition. I checked the value , and those are correctly passed from java to the jsp. Any missing points?

&lt;c:when test=""${pCount &gt; 0}""&gt;
    &lt;display:column class=""colPCount"" property=""pCount "" title=""${titlePCount}"" sortable=""true"" headerClass=""sortable"" /&gt;
&lt;/c:when&gt;
&lt;c:otherwise&gt;
    &lt;display:column class=""colPCount"" title=""${titlePCount}""&gt;&amp;nbsp;-&amp;nbsp;&lt;/display:column&gt;
&lt;/c:otherwise&gt;


For the pcount>0 items, still displaying as  '-' in the display tag. Even I reverse the checking condition like pCount&lt;0 in the first condition checking, the display tag always show the otherwise condition. It always pointing to the otherwise condition for every value.

Edited: Full Code

    &lt;display:table class=""displayTable"" id=""itemList""
        name=""${sessionScope.itemList}"" requestURI=""listItem.action""
        pagesize=""15"" defaultsort=""2"" defaultorder=""ascending"" sort=""list""&gt;
        &lt;display:column class=""colItemName"" property=""name""
            title=""${titleItemName}"" sortable=""true"" headerClass=""sortable""/&gt;
        ...
        &lt;c:choose&gt;
        &lt;c:when test=""${pCount &gt; 0}""&gt;
            &lt;display:column class=""colPCount"" property=""pCount "" title=""${titlePCount}"" sortable=""true"" headerClass=""sortable"" /&gt;
        &lt;/c:when&gt;
        &lt;c:otherwise&gt;
            &lt;display:column class=""colPCount"" title=""${titlePCount}""&gt;&amp;nbsp;-&amp;nbsp;&lt;/display:column&gt;
        &lt;/c:otherwise&gt;
        &lt;/c:choose&gt;
    &lt;/display:table&gt;

","Try this way: ${itemList.pCount&gt;0}
"
3858,3858,6140,Converting string to NSDate,"I am trying to use NSDateFormatter to convert the following string to an NSDate: 2013-08-19 7:00 AM.

However, the following NSDate is created: 2013-08-19 04:00:00 +0000. The hour is wrong.

My code is below. I don't know what I am doing incorrectly.

NSDateFormatter *dateFormatter = [NSDateFormatter new];
[dateFormatter setTimeZone:[NSTimeZone systemTimeZone]];
[dateFormatter setDateFormat:@""yyyy-MM-dd HH:mm a""];
NSString *string = @""2013-08-19 7:00 AM"";
NSDate *dateFromString = [dateFormatter dateFromString:string];

",Jack Humphries,https://stackoverflow.com/users/775624,"The reason why you see ""+0000"" means that the OS is converting your time string to UTC. To solve this you just have to set your local time-zone.

dateFormatter.timeZone = YOUR_LOCAL_TIMEZONE;


Also, to print your date in your local settings you can use NSDateFormatter's:

localizedStringFromDate:dateStyle:timeStyle:


Hope this helps!
",LuisCien,https://stackoverflow.com/users/1202615,http://stackoverflow.com/questions/18320930/converting-string-to-nsdate,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.4444444444444444,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.6666666666666666,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.3333333333333333,1.0,1.0,Convert string to nsdate,"I am trying to use NSDateFormatter to convert the following string to an NSDate: 2013-08-19 7:00 AM.

However, the following NSDate is created: 2013-08-19 04:00:00 +0000. The hour is wrong.

My code is below. I don't know what I am doing incorrectly.

NSDateFormatter *dateFormatter = [NSDateFormatter new];
[dateFormatter setTimeZone:[NSTimeZone systemTimeZone]];
[dateFormatter setDateFormat:@""yyyy-MM-dd HH:mm a""];
NSString *string = @""2013-08-19 7:00 AM"";
NSDate *dateFromString = [dateFormatter dateFromString:string];

","The reason why you see ""+0000"" means that the OS is converting your time string to UTC. To solve this you just have to set your local time-zone.

dateFormatter.timeZone = YOUR_LOCAL_TIMEZONE;


Also, to print your date in your local settings you can use NSDateFormatter's:

localizedStringFromDate:dateStyle:timeStyle:


Hope this helps!
"
2323,2323,3705,"Netbook screen display is garbled (has black/white & horizontal line patterns, screen freezes, and/or wrong display position)","Upon powering my netbook on, its screen turns into a garbled display (has black/white patterns, horizontal line patterns, screen freezes and/or wrong display position). This distortion happens even at BIOS startup, continuing to Windows startup. Occasionally, the issue starts around 3 minutes after the Windows desktop appears.

Pictures of the monitor (click on image to enlarge):



  

More pictures at: http://imgur.com/a/ArME1

Details:   


This happens even in safe mode (the last picture above is of the
netbook screen in safe mode).  
I  connected the netbook to an external monitor (through VGA) and the display in the external monitor shows up just fine. I have been able to use the netbook without any issues with an external monitor.    
Aside from the monitor, the netbook still works (I can shut it down with keyboard shortcuts) and the files that it has shared through LAN can be accessed fine. The torrent client's web interface on the netbook can also still be accessed on another computer.  
The issue sometimes happens even at BIOS startup.  
The variations of the distortion will sometimes change randomly.   
Occasionally, the non-distorted screen display will simply freeze.
The netbook didn't fall in the ground or get hit by an object.  
The netbook is mostly used as a torrent seeder and downloader. Its lid is opened and closed around 2 times a day only, but the netbook is powered on almost 24/7 (its lid is closed most of the time). It is mostly accessed through another computer through LAN and is not often used directly.  
The netbook was bought around 2 years ago.  


What are the possible causes of this? Any possible fixes or methods of repair I can look into? The netbook is now out of warranty.

Netbook details:  


Model: Samsung NP-N150
OS:  Windows 7 Starter  
Graphics Chip: Intel GMA3150  
Monitor: Screen Size 10.1"", LED Backlit
Other specs here: http://www.samsung.com/us/computer/laptops/NP-N150-JA01US-specs

",galacticninja,https://superuser.com/users/10259,"Possible causes:


Overheating as @Dan Neely says
Physical issue with cable connecting LCD to motherboard
BIOS not initializing GPU correctly, try BIOS update (this is a long shot)
Motherboard needs to be replaced (bad chipset, or bad something else that would cost more than replacing the motherboard to fix)

",LawrenceC,https://superuser.com/users/51705,http://superuser.com/questions/421513,TECHNOLOGY,superuser.com,1.0,0.4444444444444444,0.3333333333333333,0.3333333333333333,1.0,0.3333333333333333,0.5555555555555556,0.5555555555555556,1.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,1.0,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.9,0.3333333333333333,0.3333333333333333,1.0,0.8888888888888888,"Netbook screen display is garbled (has black/white & horizontal line patterns, screen freezes, and/or wrong display position)","Upon powering my netbook on, its screen turns into a garbled display (has black/white patterns, horizontal line patterns, screen freezes and/or wrong display position). This distortion happens even at BIOS startup, continuing to Windows startup. Occasionally, the issue starts around 3 minutes after the Windows desktop appears.

Pictures of the monitor (click on image to enlarge):



  

More pictures at: http://imgur.com/a/ArME1

Details:   


This happens even in safe mode (the last picture above is of the
netbook screen in safe mode).  
I  connected the netbook to an external monitor (through VGA) and the display in the external monitor shows up just fine. I have been able to use the netbook without any issues with an external monitor.    
Aside from the monitor, the netbook still works (I can shut it down with keyboard shortcuts) and the files that it has shared through LAN can be accessed fine. The torrent client's web interface on the netbook can also still be accessed on another computer.  
The issue sometimes happens even at BIOS startup.  
The variations of the distortion will sometimes change randomly.   
Occasionally, the non-distorted screen display will simply freeze.
The netbook didn't fall in the ground or get hit by an object.  
The netbook is mostly used as a torrent seeder and downloader. Its lid is opened and closed around 2 times a day only, but the netbook is powered on almost 24/7 (its lid is closed most of the time). It is mostly accessed through another computer through LAN and is not often used directly.  
The netbook was bought around 2 years ago.  


What are the possible causes of this? Any possible fixes or methods of repair I can look into? The netbook is now out of warranty.

Netbook details:  


Model: Samsung NP-N150
OS:  Windows 7 Starter  
Graphics Chip: Intel GMA3150  
Monitor: Screen Size 10.1"", LED Backlit
Other specs here: http://www.samsung.com/us/computer/laptops/NP-N150-JA01US-specs

","Possible causes:


Overheating as @Dan Neely says
Physical issue with cable connecting LCD to motherboard
BIOS not initializing GPU correctly, try BIOS update (this is a long shot)
Motherboard needs to be replaced (bad chipset, or bad something else that would cost more than replacing the motherboard to fix)

"
3429,3429,5454,Windows Software to Mount Volume/Partition Image File,"Last night I had a BSOD a couple of minutes after moving a file. After a reboot, I found that the file was gone (it was deleted from the source partition and not present on the destination).

I took an image of the source volume (ie from the Boot Sector to the last cluster of the partition). Then I wrote a program to extract the unused clusters from a disk and save them as files.

Some of the free clusters on the original volume have now been overwritten so I need to use the image to do my final extraction. That means I need some software that can mount a volume/partition image, but all of the image mounting software I can find can only mount disk images (ie from the MBR—the master partition table—on).

Does anyone know of (hopefully free) Windows software that can do this?

I’ve already tried (without success): VirtualCloneDrive, DaemonTools, VirtualFloppyDrive (and probably a couple of others I can’t think of). They all either nag that the file is no good, or try to mount it, resulting in a disk that Windows complains has an unknown/corrupt filesystem.

Thanks.
",Synetech,https://superuser.com/users/3279,"OSFMount is a free program that can mount disk images containing just a single partition or entire drives with multiple partitions. Unlike most of the other programs I have tried, this one is aware of disk-structures, so it can detect the contents of image and lets your select what you want mounted.

If the image contains a partition table, it will display the contained partitions and let you mount either the whole drive, or select a partition. If it contains just a single partition, it mounts it as is.

It also lets you decide what type the mounted drive will be (hard-drive, optical, floppy, auto).


",Synetech,https://superuser.com/users/3279,http://superuser.com/questions/172184,TECHNOLOGY,superuser.com,0.8888888888888888,0.4444444444444444,0.0,1.0,0.6666666666666666,1.0,0.6666666666666666,0.4444444444444444,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.6666666666666666,0.0,0.6666666666666666,0.8888888888888888,Install windows software for volume / partition image files,"Last night I had a BSOD a couple of minutes after moving a file. After a reboot, I found that the file was gone (it was deleted from the source partition and not present on the destination).

I took an image of the source volume (ie from the Boot Sector to the last cluster of the partition). Then I wrote a program to extract the unused clusters from a disk and save them as files.

Some of the free clusters on the original volume have now been overwritten so I need to use the image to do my final extraction. That means I need some software that can mount a volume/partition image, but all of the image mounting software I can find can only mount disk images (ie from the MBR—the master partition table—on).

Does anyone know of (hopefully free) Windows software that can do this?

I’ve already tried (without success): VirtualCloneDrive, DaemonTools, VirtualFloppyDrive (and probably a couple of others I can’t think of). They all either nag that the file is no good, or try to mount it, resulting in a disk that Windows complains has an unknown/corrupt filesystem.

Thanks.
","OSFMount is a free program that can mount disk images containing just a single partition or entire drives with multiple partitions. Unlike most of the other programs I have tried, this one is aware of disk-structures, so it can detect the contents of image and lets your select what you want mounted.

If the image contains a partition table, it will display the contained partitions and let you mount either the whole drive, or select a partition. If it contains just a single partition, it mounts it as is.

It also lets you decide what type the mounted drive will be (hard-drive, optical, floppy, auto).


"
4806,4806,7636,Blender game engine camera,"My problem is setting up a camera in the game engine.
I wanted 4 camera views instead of one.
Front, Back, eyes view and side view; Something like minecraft game.
It will be very helpful if you can give me a tutorial of it.
Please include how to change camera view; for example, pressing f1 = front view , f2 = eyes view.

When I try to set my camera on eyes view I want the camera to see my hand when I walk or run, but the character body is blocking the view. Is there anyway to solve this or make the camera look through the body?
",Xavier Choo,https://blender.stackexchange.com/users/5638,"Your question covers a lot of ground.
For starters, I recommend you set up 4 separate cameras. This is easier than having your camera move to the different desired positions.

switching between cameras requires a spot of code (at least the way I've done it.)
however if you wish to display your separate views simultaneously, a tutorial to check into is https://www.youtube.com/watch?v=-TtTBGSOii4.

as far as seeing through your own head: make sure your render settings are set to 'Blender Game' and turn to the material properties of your object. Click the check mark next to Backface culling. This should allow you to view the world though your own head.
",Scalia,https://blender.stackexchange.com/users/6385,http://blender.stackexchange.com/questions/16389/blender-game-engine-camera,TECHNOLOGY,blender.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,1.0,0.6666666666666666,1.0,0.5555555555555556,0.5555555555555556,0.6666666666666666,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.3333333333333333,1.0,0.0,0.3333333333333333,0.0,0.7777777777777778,1.0,0.5555555555555556,1.0,1.0,0.8666666666666666,0.6666666666666666,0.0,1.0,0.8888888888888888,Blender game engine camera,"My problem is setting up a camera in the game engine.
I wanted 4 camera views instead of one.
Front, Back, eyes view and side view; Something like minecraft game.
It will be very helpful if you can give me a tutorial of it.
Please include how to change camera view; for example, pressing f1 = front view , f2 = eyes view.

When I try to set my camera on eyes view I want the camera to see my hand when I walk or run, but the character body is blocking the view. Is there anyway to solve this or make the camera look through the body?
","Your question covers a lot of ground.
For starters, I recommend you set up 4 separate cameras. This is easier than having your camera move to the different desired positions.

switching between cameras requires a spot of code (at least the way I've done it.)
however if you wish to display your separate views simultaneously, a tutorial to check into is https://www.youtube.com/watch?v=-TtTBGSOii4.

as far as seeing through your own head: make sure your render settings are set to 'Blender Game' and turn to the material properties of your object. Click the check mark next to Backface culling. This should allow you to view the world though your own head.
"
4781,4781,7593,Java method called twice from C++ JNI NDK function,"I have some C++ NDK code calling a Java method via JNI.  The problem I have is that my Java method is getting called twice.  It seems once I get a handle to the method using GetMethodID and then call env->NewObject w/ that method ID, my java function is called. 

It is again, obviously called when I call env->CallVoidMethod(obj, mid) which is expected.  I just am not sure why it is called when I create a NewObject?

C++ Code: 
---------
JNIEXPORT jint JNICALL JNI_OnLoad(JavaVM* vm, void* reserved)
{
    jvm = vm;
    start();
    return JNI_VERSION_1_6;
}

void start() {    
    JNIEnv *env = NULL;
    jvm-&gt;GetEnv((void**)&amp;env, JNI_VERSION_1_6);
    jclass cls = env-&gt;FindClass(""com/test/Test"");
    jmethodID mid = env-&gt;GetMethodID(cls, ""StartApp"", ""()V"");
    jobject obj = env-&gt;NewObject(cls, mid);

    if (mid != 0){
       env-&gt;CallVoidMethod(obj, mid);
    }
}       

Java Code:
----------
 public void StartApp(){
     android.util.Log.e(""Test"", ""Java Method Called from Native"");
 }

",Sofia Clover,https://stackoverflow.com/users/3838233,"NewObject take the constructor as parameter, so

jobject obj = env-&gt;NewObject(cls, mid);


This will invoke the first StartApp(), but note that since it's not a proper constructor, this will cause you trouble.

For the constructor, according to the manual, This ID must be obtained by calling GetMethodID() with &lt; init > as the method name and void (V) as the return type.
",Non-maskable Interrupt,https://stackoverflow.com/users/1094101,http://stackoverflow.com/questions/25123942/java-method-called-twice-from-c-jni-ndk-function,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.5555555555555556,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,0.8888888888888888,0.8,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.8888888888888888,Calling Java methods twice from C + + JNI NDK function,"I have some C++ NDK code calling a Java method via JNI.  The problem I have is that my Java method is getting called twice.  It seems once I get a handle to the method using GetMethodID and then call env->NewObject w/ that method ID, my java function is called. 

It is again, obviously called when I call env->CallVoidMethod(obj, mid) which is expected.  I just am not sure why it is called when I create a NewObject?

C++ Code: 
---------
JNIEXPORT jint JNICALL JNI_OnLoad(JavaVM* vm, void* reserved)
{
    jvm = vm;
    start();
    return JNI_VERSION_1_6;
}

void start() {    
    JNIEnv *env = NULL;
    jvm-&gt;GetEnv((void**)&amp;env, JNI_VERSION_1_6);
    jclass cls = env-&gt;FindClass(""com/test/Test"");
    jmethodID mid = env-&gt;GetMethodID(cls, ""StartApp"", ""()V"");
    jobject obj = env-&gt;NewObject(cls, mid);

    if (mid != 0){
       env-&gt;CallVoidMethod(obj, mid);
    }
}       

Java Code:
----------
 public void StartApp(){
     android.util.Log.e(""Test"", ""Java Method Called from Native"");
 }

","NewObject take the constructor as parameter, so

jobject obj = env-&gt;NewObject(cls, mid);


This will invoke the first StartApp(), but note that since it's not a proper constructor, this will cause you trouble.

For the constructor, according to the manual, This ID must be obtained by calling GetMethodID() with &lt; init > as the method name and void (V) as the return type.
"
963,963,1524,Is there any performance difference between ++i and i++ in C#?,"Is there any performance difference between using something like

for(int i = 0; i &lt; 10; i++) { ... }


and

for(int i = 0; i &lt; 10; ++i) { ... }


or is the compiler able to optimize in such a way that they are equally fast in the case where they are functionally equivalent?

Edit:
This was asked because I had a discussion with a co-worker about it, not because I think its a useful optimization in any practical sense. It is largely academic. 
",Anton,https://stackoverflow.com/users/341413,"Guys, guys, the ""answers"" are for C and C++.

C# is a different animal.

Use ILDASM to look at the compiled output to verify if there is an MSIL difference.
",dan,https://stackoverflow.com/users/56869,http://stackoverflow.com/questions/467322/is-there-any-performance-difference-between-i-and-i-in-c,STACKOVERFLOW,stackoverflow.com,1.0,0.8888888888888888,0.0,1.0,1.0,1.0,0.5555555555555556,0.5555555555555556,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,1.0,0.7777777777777778,0.3333333333333333,0.7777777777777778,0.7777777777777778,0.6,0.6666666666666666,0.0,0.3333333333333333,0.7777777777777778,Is there any performance difference between + + I and I + + in C + +?,"Is there any performance difference between using something like

for(int i = 0; i &lt; 10; i++) { ... }


and

for(int i = 0; i &lt; 10; ++i) { ... }


or is the compiler able to optimize in such a way that they are equally fast in the case where they are functionally equivalent?

Edit:
This was asked because I had a discussion with a co-worker about it, not because I think its a useful optimization in any practical sense. It is largely academic. 
","Guys, guys, the ""answers"" are for C and C++.

C# is a different animal.

Use ILDASM to look at the compiled output to verify if there is an MSIL difference.
"
5994,5994,9505,What package managers do popular Unix Distributions Use?,"I am creating a Script and I need to know what package manager each Popular Unix Distribution Uses (especially those distros that are commonly-used for Servers)...

I mean:
Debian uses apt-get
Fedora uses yum
",ant0nisk,https://unix.stackexchange.com/users/19942,"Its different for different unix-systems. But the common thing in all those is the tar.gz file . It is the source code of your program. Then you can make either .deb files for Debian systems or .rpm file for Red Hat Systems. The .deb and .rpm are both binary files while tar.gz is mostly ASCII file but it can also contain binaries. You can convert .rpm file to .deb file in debian systems by this command:

To install :


  sudo apt-get install alien


To convert to .deb from .rpm :


  sudo alien ""packagename.rpm""


Replace the ""packagename.rpm"" with your original name of the file.

Then a .deb file will be created and to install that use :


  sudo dpkg -i ""filename.deb""


Replace the ""filename.deb"" with your original name of the file.

If you want that users can install your application by apt-get or yum then you will have to upload your app to the repository of your distribution. Only then the user will be able to use apt-get or yum to install the application directly.
",Pranit Bauva,https://unix.stackexchange.com/users/19803,http://unix.stackexchange.com/questions/40989/what-package-managers-do-popular-unix-distributions-use,TECHNOLOGY,unix.stackexchange.com,1.0,1.0,0.0,1.0,1.0,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.9,0.6666666666666666,0.0,0.6666666666666666,0.8888888888888888,What package managers do popular UNIX distributions use?,"I'm creating a script, and I need to know what package managers are used for each popular UNIX distribution (especially those that are commonly used for servers)...","Its different for different unix-systems. But the common thing in all those is the tar.gz file . It is the source code of your program. Then you can make either .deb files for Debian systems or .rpm file for Red Hat Systems. The .deb and .rpm are both binary files while tar.gz is mostly ASCII file but it can also contain binaries. You can convert .rpm file to .deb file in debian systems by this command:

To install :


  sudo apt-get install alien


To convert to .deb from .rpm :


  sudo alien ""packagename.rpm""


Replace the ""packagename.rpm"" with your original name of the file.

Then a .deb file will be created and to install that use :


  sudo dpkg -i ""filename.deb""


Replace the ""filename.deb"" with your original name of the file.

If you want that users can install your application by apt-get or yum then you will have to upload your app to the repository of your distribution. Only then the user will be able to use apt-get or yum to install the application directly.
"
1236,1236,1937,Nexus 4 does not wake up from Sleep randomly,"I have a Nexus 4 running stock rom kit kat 4.4.2. There were few instances, in which when the phone goes to sleep, I see the notification light blinking indicating a new email/message, but it doesn't wake up when I press the power button. I have to soft reboot the phone {press the power button for 5 seconds to turn it off, then turn on}to use it again. This happens more frequently on some days, and some times it doesn't happen for weeks.I tried calling the phone from my land line when it is in this state, I could hear it ringing on the landline, but the phone doesn't actually ring. After rebooting, it doesn't even show a missed call. When I reboot it, the phone's battery is substantially less (down by about 10%). It started happening only since 4.3 JB update, it was fine till then.

I tried a full factory reset, and minimal apps, it worked fine. Once I installed all my apps back, this started happening again. I am thinking one of my apps is causing this and it could be an application or a bug in Kit kat/JB itself.


Is there any known bug in kitkat 4.4.2 (or >= 4.3 ) or is there any application known to cause this?
Is there any way I can look at the logs to see if any specific application is causing this.
Force wake up the phone without having to reboot it ?

",Dinesh,https://android.stackexchange.com/users/34183,"You might wish to run adb logcat for investigation. But that might only be helpful if you know how to trigger the issue.

Another approach would be, as you already indicated:


start with a factory reset. You know that with a ""fresh device"" the issue does not happen, as described by your question
install back only a part of your apps (the ones you feel most essential), but not more than ~50%. See if the issue still happens.

Yes: the problematic app was in this batch
No: the problematic app was not in this batch

start over at 1., this time with the other half. Does the issue show up again?


If 2. + 3. are answered ""No"", it might as well be a combination of apps. If the issue shows up only in either 2. or 3. (but not in both cases), start narrowing down. I will assume here it was part of 3., switch items if it was the other way around:


starting over with factory-reset and installing the first half of your apps.
split the other half in two again, and repeat as above


This procedure should help you finding the culprit, while still being able to use your device and as much of your apps as possible. Of course, you could also start with factory-reset and then install each app one-by-one (which might be the safer approach) – but as the issue might not show up immediately (may even take a day or more), the above might be more practical.
",Izzy,https://android.stackexchange.com/users/16575,http://android.stackexchange.com/questions/69297/nexus-4-does-not-wake-up-from-sleep-randomly,TECHNOLOGY,android.stackexchange.com,1.0,0.5555555555555556,0.0,0.6666666666666666,1.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,1.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,0.6666666666666666,1.0,Nexus 4 does not wake up randomly from sleep,"I have a nexus 4 running stock romkitkat 4.4.2. Rarely do I see a notification light blinking to indicate a new email / message when the phone goes to sleep, but it doesn't wake up when I press the power button. I have to soft restart my phone {press the power button for 5 seconds to turn it off, then turn it on} and use it again. Sometimes it's more frequent, sometimes not for a few weeks. I tried to call from my landline in this state. I could hear the landline ringing, but the phone didn't. When restarted, it will not even show missed calls. When I restart it, the battery power of the phone is greatly reduced (by about 10%). It didn't happen until 4.3jb was updated, which was good until then.","You might wish to run adb logcat for investigation. But that might only be helpful if you know how to trigger the issue.

Another approach would be, as you already indicated:


start with a factory reset. You know that with a ""fresh device"" the issue does not happen, as described by your question
install back only a part of your apps (the ones you feel most essential), but not more than ~50%. See if the issue still happens.

Yes: the problematic app was in this batch
No: the problematic app was not in this batch

start over at 1., this time with the other half. Does the issue show up again?


If 2. + 3. are answered ""No"", it might as well be a combination of apps. If the issue shows up only in either 2. or 3. (but not in both cases), start narrowing down. I will assume here it was part of 3., switch items if it was the other way around:


starting over with factory-reset and installing the first half of your apps.
split the other half in two again, and repeat as above


This procedure should help you finding the culprit, while still being able to use your device and as much of your apps as possible. Of course, you could also start with factory-reset and then install each app one-by-one (which might be the safer approach) – but as the issue might not show up immediately (may even take a day or more), the above might be more practical.
"
4033,4033,6441,Is it possible to get a popup to ignore MenuDropAlignment in a WPF / Touch app?,"As a bit of background - Windows has a facility for Touch/TabletPCs whereby it shifts the position of popups/menus depending on your ""handedness"" (to prevent the menu appearing under your hand). 

Essentially what this does is if you are set to ""right handed"" (which it seems to default to once you've connected a touch device), every popup you open is artificially kicked to the left - this causes massive layout issues where we try and line up a popup with the item it ""popped up from"" :

Tablet PC Settings set to Left handed - no artificial correction from Windows


Tablet PC Settings set to Right handed - Windows artificially adjusts our positioning


We can detect what this setting is set to with SystemParameters.MenuDropAlignment, and for trivial popups we can adjust this using the actual width of the popup - but for dynamic popups and when we throw right to left support into the mix, this just doesn't work.

Currently it's looking more likely that we are going to have to go through every popup, manually work out a value to adjust the kick, and add something like this to every one:

&lt;MultiDataTrigger&gt;
    &lt;MultiDataTrigger.Conditions&gt;
        &lt;Condition Binding=""{Binding Source={x:Static SystemParameters.MenuDropAlignment}}"" Value=""True""/&gt;
        &lt;Condition Binding=""{Binding RelativeSource={RelativeSource Mode=Self}, Path=FlowDirection}"" Value=""RightToLeft""/&gt;
    &lt;/MultiDataTrigger.Conditions&gt;
    &lt;MultiDataTrigger.Setters&gt;
        &lt;Setter Property=""HorizontalOffset"" Value=""-50""/&gt; &lt;!-- Set to arbitrary value to test --&gt;
    &lt;/MultiDataTrigger.Setters&gt;
&lt;/MultiDataTrigger&gt;


So.. back to the question :-) Does anyone know of a way to stop a WPF popup looking at this setting at all? 

For those that don't have a touch device you can access the Tablet PC settings by running:

C:\Windows\explorer.exe shell:::{80F3F1D5-FECA-45F3-BC32-752C152E456E}

And see the mess it makes for yourself :-)
",Steven Robbins,https://stackoverflow.com/users/26507,"Set it to regular mode for your whole application:

        FieldInfo fi = typeof(SystemParameters).GetField(""_menuDropAlignment"",
           BindingFlags.NonPublic | BindingFlags.Static);

        fi.SetValue(null, false);

",skimania,https://stackoverflow.com/users/270317,http://stackoverflow.com/questions/5027204/is-it-possible-to-get-a-popup-to-ignore-menudropalignment-in-a-wpf-touch-app,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.3333333333333333,0.0,0.0,1.0,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,1.0,Can I get a pop-up window in the WPF / touch application that ignores menudropalignment?,"As a bit of background - Windows has a facility for Touch/TabletPCs whereby it shifts the position of popups/menus depending on your ""handedness"" (to prevent the menu appearing under your hand). 

Essentially what this does is if you are set to ""right handed"" (which it seems to default to once you've connected a touch device), every popup you open is artificially kicked to the left - this causes massive layout issues where we try and line up a popup with the item it ""popped up from"" :

Tablet PC Settings set to Left handed - no artificial correction from Windows


Tablet PC Settings set to Right handed - Windows artificially adjusts our positioning


We can detect what this setting is set to with SystemParameters.MenuDropAlignment, and for trivial popups we can adjust this using the actual width of the popup - but for dynamic popups and when we throw right to left support into the mix, this just doesn't work.

Currently it's looking more likely that we are going to have to go through every popup, manually work out a value to adjust the kick, and add something like this to every one:

&lt;MultiDataTrigger&gt;
    &lt;MultiDataTrigger.Conditions&gt;
        &lt;Condition Binding=""{Binding Source={x:Static SystemParameters.MenuDropAlignment}}"" Value=""True""/&gt;
        &lt;Condition Binding=""{Binding RelativeSource={RelativeSource Mode=Self}, Path=FlowDirection}"" Value=""RightToLeft""/&gt;
    &lt;/MultiDataTrigger.Conditions&gt;
    &lt;MultiDataTrigger.Setters&gt;
        &lt;Setter Property=""HorizontalOffset"" Value=""-50""/&gt; &lt;!-- Set to arbitrary value to test --&gt;
    &lt;/MultiDataTrigger.Setters&gt;
&lt;/MultiDataTrigger&gt;


So.. back to the question :-) Does anyone know of a way to stop a WPF popup looking at this setting at all? 

For those that don't have a touch device you can access the Tablet PC settings by running:

C:\Windows\explorer.exe shell:::{80F3F1D5-FECA-45F3-BC32-752C152E456E}

And see the mess it makes for yourself :-)
","Set it to regular mode for your whole application:

        FieldInfo fi = typeof(SystemParameters).GetField(""_menuDropAlignment"",
           BindingFlags.NonPublic | BindingFlags.Static);

        fi.SetValue(null, false);

"
3546,3546,5656,get_option function,"I'm currently trying to make my own theme, but i'm not quite sure how the get_option() function works, because how come this..

echo get_option('show_header', 'sultenhest_theme_display_options');
echo get_option('sultenhest_theme_display_options')['show_header'];


..both returns 1 (but Dreamweaver doesnt like the second option). While

echo get_option('twitter', 'sultenhest_theme_social_options');


..simply returns 'sultenhest_theme_social_options', which is incorrect.

An option would be to define the array as such

$social_options = get_option( 'sultenhest_theme_social_options' );


and call it like this

echo $social_options['twitter'];


It returns the correct string, but it only works in the header.php (if the array is defined there) file and not in, e.g. footer.php.



UPDATE:
Following partly ialocin and Brad Dalton i came up with this solution, which works like a charm:

function sultenhest($option, $arg){
  $the_array = array();
  foreach( get_option('sultenhest_theme_'.$option) as $key =&gt; $item ){
    $the_array[$key] = $item;
  }
  return $the_array[$arg];
}


and echoing it out like this:

echo sultenhest('social_options', 'twitter') ? '&lt;a href=""' . sultenhest('social_options', 'twitter') . '""&gt;Twitter&lt;/a&gt;' : '';

",Sultenhest,https://wordpress.stackexchange.com/users/67261,"You are using get_option() wrong, first variant, so take another look at the get_option() documentation. Basically you can't directly access an array element with the function, it just doesn't support it.

The second variant should be possible, but you need at least PHP 5.4 - if I'm not totally mistaken; I don't know anything about dreamweaver.

The reason why you can't access the variable everywhere you want is the variable scope, read up on it at the PHP Manual: Variable scope.

The easiest thing I imagine is to do it the old fashion way, just make a function you can use. Exemplary like this:

function wpse_179693_echo_my_options_array_value() {
    $social_options = get_option( 'sultenhest_theme_social_options' );
    if ( isset( $social_options['twitter'] ) ) {
        echo $social_options['twitter'];
    } else {
        return FALSE;
    }
}

",Nicolai,https://wordpress.stackexchange.com/users/22534,http://wordpress.stackexchange.com/questions/179693/get-option-function,TECHNOLOGY,wordpress.stackexchange.com,0.6666666666666666,0.3333333333333333,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.3333333333333333,0.0,0.3333333333333333,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.0,0.6666666666666666,1.0,Get option function,"I'm currently trying to make my own theme, but i'm not quite sure how the get_option() function works, because how come this..

echo get_option('show_header', 'sultenhest_theme_display_options');
echo get_option('sultenhest_theme_display_options')['show_header'];


..both returns 1 (but Dreamweaver doesnt like the second option). While

echo get_option('twitter', 'sultenhest_theme_social_options');


..simply returns 'sultenhest_theme_social_options', which is incorrect.

An option would be to define the array as such

$social_options = get_option( 'sultenhest_theme_social_options' );


and call it like this

echo $social_options['twitter'];


It returns the correct string, but it only works in the header.php (if the array is defined there) file and not in, e.g. footer.php.



UPDATE:
Following partly ialocin and Brad Dalton i came up with this solution, which works like a charm:

function sultenhest($option, $arg){
  $the_array = array();
  foreach( get_option('sultenhest_theme_'.$option) as $key =&gt; $item ){
    $the_array[$key] = $item;
  }
  return $the_array[$arg];
}


and echoing it out like this:

echo sultenhest('social_options', 'twitter') ? '&lt;a href=""' . sultenhest('social_options', 'twitter') . '""&gt;Twitter&lt;/a&gt;' : '';

","You are using get_option() wrong, first variant, so take another look at the get_option() documentation. Basically you can't directly access an array element with the function, it just doesn't support it.

The second variant should be possible, but you need at least PHP 5.4 - if I'm not totally mistaken; I don't know anything about dreamweaver.

The reason why you can't access the variable everywhere you want is the variable scope, read up on it at the PHP Manual: Variable scope.

The easiest thing I imagine is to do it the old fashion way, just make a function you can use. Exemplary like this:

function wpse_179693_echo_my_options_array_value() {
    $social_options = get_option( 'sultenhest_theme_social_options' );
    if ( isset( $social_options['twitter'] ) ) {
        echo $social_options['twitter'];
    } else {
        return FALSE;
    }
}

"
3971,3971,6339,Should I block bots from my site and why?,"My logs are full of bot visitors, often from Eastern Europe and China.
The bots are identified as Ahrefs, Seznam, LSSRocketCrawler, Yandex, Sogou and so on.
Should I block these bots from my site and why?

Which ones have a legitimate purpose in increasing traffic to my site?
Many of them are SEO.

I have to say I see less traffic if anything since the bots have arrived in large numbers.

It would not be too hard to block these since they all admit in their User Agent that they are bots.
",Frank E,https://webmasters.stackexchange.com/users/21198,"While attempting to block bots can help in free up resources and clean up your logs it’s important to note that robots.txt and even using the meta tag on pages noindex does not actually stop bots visiting your site. They can still crawl your site occasionally to see if the denied from robots has been removed. A lot of bots don’t even use a user agent and will use a standard user agent. The bots I’m referring to are typically SEO harvesting bots that scan for backlinks and not the general ones you find from search engines. 

Rather than blocking the bots you should just factor in these bots when counting up your visitors, after a while of actively monitoring your site your establish a rough figure which are bots. Most people care about unique visits and this rules out the bots since they are constantly returning. In this day and age there are plenty of servers, shared hosting that can handle these bots so other than pages that you don’t want indexed I see no reason why to block these types of bots. Of course you have harmful bots as well but these certainly won’t use user agent ;).

Personally I believe blocking robots is a waste of time as they don’t use that much resources at all, SEO robots can help as they list your site on PR0 pages which of course increases your PageRank and there automated so you won’t get punished by them. 

Logs Issue

You should use a proper log viewer that enables you to filter out certain requests, this makes it easier when reviewing your logs. Good viewers can filter out lots of things like normal visits, 404s' and so forth.
",Simon Hayter,https://webmasters.stackexchange.com/users/20604,http://webmasters.stackexchange.com/questions/42169/should-i-block-bots-from-my-site-and-why,TECHNOLOGY,webmasters.stackexchange.com,1.0,1.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.4444444444444444,0.4444444444444444,1.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,1.0,I should stop the robots on my website. Why?,"My logs are full of bot visitors, often from Eastern Europe and China.
The bots are identified as Ahrefs, Seznam, LSSRocketCrawler, Yandex, Sogou and so on.
Should I block these bots from my site and why?

Which ones have a legitimate purpose in increasing traffic to my site?
Many of them are SEO.

I have to say I see less traffic if anything since the bots have arrived in large numbers.

It would not be too hard to block these since they all admit in their User Agent that they are bots.
","While attempting to block bots can help in free up resources and clean up your logs it’s important to note that robots.txt and even using the meta tag on pages noindex does not actually stop bots visiting your site. They can still crawl your site occasionally to see if the denied from robots has been removed. A lot of bots don’t even use a user agent and will use a standard user agent. The bots I’m referring to are typically SEO harvesting bots that scan for backlinks and not the general ones you find from search engines. 

Rather than blocking the bots you should just factor in these bots when counting up your visitors, after a while of actively monitoring your site your establish a rough figure which are bots. Most people care about unique visits and this rules out the bots since they are constantly returning. In this day and age there are plenty of servers, shared hosting that can handle these bots so other than pages that you don’t want indexed I see no reason why to block these types of bots. Of course you have harmful bots as well but these certainly won’t use user agent ;).

Personally I believe blocking robots is a waste of time as they don’t use that much resources at all, SEO robots can help as they list your site on PR0 pages which of course increases your PageRank and there automated so you won’t get punished by them. 

Logs Issue

You should use a proper log viewer that enables you to filter out certain requests, this makes it easier when reviewing your logs. Good viewers can filter out lots of things like normal visits, 404s' and so forth.
"
4234,4234,6750,How can I make a graph of a function?,"I'm trying to implement a function to LaTeX but i don't know how. I'm compiling using this  page: docs.latexlab.org
",Garmen1778,https://tex.stackexchange.com/users/12498,"Here's an option using pgfplots, which can be compiled with pdflatex



\documentclass{article}
\usepackage{pgfplots}

\begin{document}
\begin{tikzpicture}[&gt;=stealth]
    \begin{axis}[
        xmin=-4,xmax=4,
        ymin=-2,ymax=2,
        axis x line=middle,
        axis y line=middle,
        axis line style=&lt;-&gt;,
        xlabel={$x$},
        ylabel={$y$},
        ]
        \addplot[no marks,blue,&lt;-&gt;] expression[domain=-pi:pi,samples=100]{sin(deg(2*x))+1/2} 
                    node[pos=0.65,anchor=south west]{$y=\sin(2x)+\frac{1}{2}$}; 
    \end{axis}
\end{tikzpicture}
\end{document}


One of the main reasons I like this package, is that global styles can be specified easily in the preamble. So, if you're going to have more than one of these plots, it might be a good idea to use something like the following setup

\documentclass{article}
\usepackage{pgfplots}

% axis style
\pgfplotsset{every axis/.append style={
                    axis x line=middle,    % put the x axis in the middle
                    axis y line=middle,    % put the y axis in the middle
                    axis line style={&lt;-&gt;}, % arrows on the axis
                    xlabel={$x$},          % default put x on x-axis
                    ylabel={$y$},          % default put y on y-axis
                    }}

% line style
\pgfplotsset{mystyle/.style={color=blue,no marks,line width=1pt,&lt;-&gt;}} 

% arrow style: stealth stands for 'stealth fighter' 
\tikzset{&gt;=stealth}

\begin{document}
\begin{tikzpicture}
    \begin{axis}[
        xmin=-4,xmax=4,
        ymin=-2,ymax=2,
        ]
        \addplot[mystyle] expression[domain=-pi:pi,samples=100]{sin(deg(2*x))+1/2} 
                    node[pos=0.65,anchor=south west]{$y=\sin(2x)+\frac{1}{2}$}; 
    \end{axis}
\end{tikzpicture}
\end{document}

",cmhughes,https://tex.stackexchange.com/users/6621,http://tex.stackexchange.com/questions/47594/how-can-i-make-a-graph-of-a-function,TECHNOLOGY,tex.stackexchange.com,1.0,0.4444444444444444,0.0,1.0,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.6666666666666666,0.8888888888888888,How to draw the graph of function?,"I'm trying to implement a function to latex, but I don't know how. I am compiling using the following page: docs.latexlab.org","Here's an option using pgfplots, which can be compiled with pdflatex



\documentclass{article}
\usepackage{pgfplots}

\begin{document}
\begin{tikzpicture}[&gt;=stealth]
    \begin{axis}[
        xmin=-4,xmax=4,
        ymin=-2,ymax=2,
        axis x line=middle,
        axis y line=middle,
        axis line style=&lt;-&gt;,
        xlabel={$x$},
        ylabel={$y$},
        ]
        \addplot[no marks,blue,&lt;-&gt;] expression[domain=-pi:pi,samples=100]{sin(deg(2*x))+1/2} 
                    node[pos=0.65,anchor=south west]{$y=\sin(2x)+\frac{1}{2}$}; 
    \end{axis}
\end{tikzpicture}
\end{document}


One of the main reasons I like this package, is that global styles can be specified easily in the preamble. So, if you're going to have more than one of these plots, it might be a good idea to use something like the following setup

\documentclass{article}
\usepackage{pgfplots}

% axis style
\pgfplotsset{every axis/.append style={
                    axis x line=middle,    % put the x axis in the middle
                    axis y line=middle,    % put the y axis in the middle
                    axis line style={&lt;-&gt;}, % arrows on the axis
                    xlabel={$x$},          % default put x on x-axis
                    ylabel={$y$},          % default put y on y-axis
                    }}

% line style
\pgfplotsset{mystyle/.style={color=blue,no marks,line width=1pt,&lt;-&gt;}} 

% arrow style: stealth stands for 'stealth fighter' 
\tikzset{&gt;=stealth}

\begin{document}
\begin{tikzpicture}
    \begin{axis}[
        xmin=-4,xmax=4,
        ymin=-2,ymax=2,
        ]
        \addplot[mystyle] expression[domain=-pi:pi,samples=100]{sin(deg(2*x))+1/2} 
                    node[pos=0.65,anchor=south west]{$y=\sin(2x)+\frac{1}{2}$}; 
    \end{axis}
\end{tikzpicture}
\end{document}

"
4337,4337,6908,"How to prevent the ""Too awesome to use"" syndrome","When you give the player a rare but powerful item which can only be used once but is never really required to proceed, most players will not use it at all, because they are waiting for the perfect moment. But even when this moment comes, they will still be reluctant to use it, because there might be an even better moment later. So they keep hoarding it for a moment which will never come. 

In the end, they will carry the item around until it is outclassed by other, more readily available resources, or even until the very end of the game. That means that such one-shot items don't provide any gameplay-value at all. They are simply too awesome to use.

What can you do to encourage the player to make use of their one-shot items and not hoard them?
",Philipp,https://gamedev.stackexchange.com/users/21890,"A simple solution would be to make this special item available in-game for a limited time. 

For instance in 2012 Jagex (creator of Runescape) added a special item called the ""DeathTouched dart"" it could kill any opponent with just one hit. It has been said that it will be removed on some unspecified date.


  http://runescape.wikia.com/wiki/Deathtouched_dart


That way, most players used their darts and their purpose has been fulfilled.

Another example from my game experience comes from an old game called ""Star Wars Jedi Outcast Academy II"", I remember that I aquired some rare items like Seeker drone, which were supposed to help you fight your enemies. Due to their rarity I have kept them until the end of the game, hoping they can help me fight the final boss, but to my dissapointment it hasn't even left a scratch on him. In that case I would simply make them more common. 


",Mikolaj Marcisz,https://gamedev.stackexchange.com/users/23053,http://gamedev.stackexchange.com/questions/55558/how-to-prevent-the-too-awesome-to-use-syndrome,TECHNOLOGY,gamedev.stackexchange.com,1.0,0.5555555555555556,0.6666666666666666,1.0,0.0,0.0,0.7777777777777778,0.6666666666666666,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.3333333333333333,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.3333333333333333,0.0,0.3333333333333333,1.0,"How to prevent ""too good to use"" syndrome","When you give the player a rare but powerful item which can only be used once but is never really required to proceed, most players will not use it at all, because they are waiting for the perfect moment. But even when this moment comes, they will still be reluctant to use it, because there might be an even better moment later. So they keep hoarding it for a moment which will never come. 

In the end, they will carry the item around until it is outclassed by other, more readily available resources, or even until the very end of the game. That means that such one-shot items don't provide any gameplay-value at all. They are simply too awesome to use.

What can you do to encourage the player to make use of their one-shot items and not hoard them?
","A simple solution would be to make this special item available in-game for a limited time. 

For instance in 2012 Jagex (creator of Runescape) added a special item called the ""DeathTouched dart"" it could kill any opponent with just one hit. It has been said that it will be removed on some unspecified date.


  http://runescape.wikia.com/wiki/Deathtouched_dart


That way, most players used their darts and their purpose has been fulfilled.

Another example from my game experience comes from an old game called ""Star Wars Jedi Outcast Academy II"", I remember that I aquired some rare items like Seeker drone, which were supposed to help you fight your enemies. Due to their rarity I have kept them until the end of the game, hoping they can help me fight the final boss, but to my dissapointment it hasn't even left a scratch on him. In that case I would simply make them more common. 


"
828,828,1320,Search predictions broken in Chrome - reinstall didn't solve the problem,"I recently changed the default search engine to a custom google search URL (using baseUrl) with some additional parameters and removed all the rest of the search engines, and since then, the search predictions stopped working.

I even tried to reinstall Chrome but as soon as I resync, the problem is back!
Search predictions are just gone without option to fix!!

In IE changing the search provider allows specifying a prediction (suggestion) provider, In chrome, once you change the default search engine, you'll never be able to have predictions again!!
This is a terrible bug, I mean WTF!!!

Is there any workaround to that?

I posted a bug report a while ago but it seems no one looks at it. I'm about to give up on Chrome and go back to IE, the only good thing about Chrome is the Extension market and the AdBlocker (which I can find in IE as well). The perfrormance changes don't matter to me too much.

Thanks
",Shimmy,https://superuser.com/users/9825,"Goto:

Stop sync and remove all of your
    synced data.

After relaunching Chrome, the problem should be solved.
",Zac B,https://superuser.com/users/82976,http://superuser.com/questions/399796,TECHNOLOGY,superuser.com,0.8888888888888888,0.5555555555555556,0.0,0.0,0.3333333333333333,1.0,0.5555555555555556,0.5555555555555556,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.0,0.6666666666666666,0.8888888888888888,0.6666666666666666,0.8888888888888888,0.7777777777777778,1.0,1.0,0.0,0.6666666666666666,0.6666666666666666,Search prediction failed in chrome - reinstallation doesn't solve the problem,"I recently changed the default search engine to a custom google search URL (using baseUrl) with some additional parameters and removed all the rest of the search engines, and since then, the search predictions stopped working.

I even tried to reinstall Chrome but as soon as I resync, the problem is back!
Search predictions are just gone without option to fix!!

In IE changing the search provider allows specifying a prediction (suggestion) provider, In chrome, once you change the default search engine, you'll never be able to have predictions again!!
This is a terrible bug, I mean WTF!!!

Is there any workaround to that?

I posted a bug report a while ago but it seems no one looks at it. I'm about to give up on Chrome and go back to IE, the only good thing about Chrome is the Extension market and the AdBlocker (which I can find in IE as well). The perfrormance changes don't matter to me too much.

Thanks
","Goto:

Stop sync and remove all of your
    synced data.

After relaunching Chrome, the problem should be solved.
"
5795,5795,9181,Network database access - How do I connect to a remote database?,"I am able to connect to a specific MS Access Database when it is on the same Windows computer as Mathematica via the command

&lt;&lt; DatabaseLink`;
conn = OpenSQLConnection[JDBC[""odbc"", ""Databasename""]];


However, I cannot figure out how to connect to this database over a local area network -- disregarding trivial network problems (the computers can ping eachother), is this even possible?
",R.S.,https://mathematica.stackexchange.com/users/6704,"This is not really an answer yet, but definitely too long for a comment. 

Access databases are designed for single user access and store data, forms and code in a single file. It is possible to access such a file from a remote computer via e.g. a network drive. As there is no real database server involved, concurrent usage of the same database file with several processes/programs will only be possible within certain limits (which I don't know about).

It should be possible to access such a file from a network drive via the usual ODBC drivers, but you might need to configure those accordingly. You have mentioned that you want to access the database from a linux client: There are OBDC drivers for access databasefiles which work under linux, but I don't know if and how it is possible to use those from Mathematica, but would expect that should be possible. If the file lives on a windows server you could mount a network file with the samba client programs, but that might introduce additional restrictions on concurrent usage as there could be differences in how the file locking and other details are handled. I would be very careful when experimenting with such a setup. On the other hand I wouldn't expect insurmountable problems if only one program accesses the database file at a time.

Depending on how you are using that database converting the database is probably the best you can do, especially if you need concurrent access. As a first try you could try to use e.g. openoffice or kexi to convert the database, but of course you could also do that with Mathematica on a Windows machine. Depending on the target format there might be even better options, e.g. specialized import functions/scripts for certain database systems.

If you don't need concurrent access you could consider SQLite as a target format which like Access stores the data in plain files and also is ""serverless"", so using it might be simpler than setting up a database server. There is a JDBC driver for SQLite, which you should be able to use from Mathematica. There is also an undocumented more direct implementation to access a SQLite database from within Mathematica even without DatabaseLink, which you should find some notes about in the web.
",Albert Retey,https://mathematica.stackexchange.com/users/169,http://mathematica.stackexchange.com/questions/24215/network-database-access-how-do-i-connect-to-a-remote-database,TECHNOLOGY,mathematica.stackexchange.com,1.0,0.5555555555555556,0.0,1.0,0.3333333333333333,1.0,0.6666666666666666,0.4444444444444444,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,1.0,0.5555555555555556,1.0,1.0,0.7333333333333333,0.3333333333333333,0.0,1.0,1.0,Network database access - how do I connect to a remote database?,"I am able to connect to a specific MS Access Database when it is on the same Windows computer as Mathematica via the command

&lt;&lt; DatabaseLink`;
conn = OpenSQLConnection[JDBC[""odbc"", ""Databasename""]];


However, I cannot figure out how to connect to this database over a local area network -- disregarding trivial network problems (the computers can ping eachother), is this even possible?
","This is not really an answer yet, but definitely too long for a comment. 

Access databases are designed for single user access and store data, forms and code in a single file. It is possible to access such a file from a remote computer via e.g. a network drive. As there is no real database server involved, concurrent usage of the same database file with several processes/programs will only be possible within certain limits (which I don't know about).

It should be possible to access such a file from a network drive via the usual ODBC drivers, but you might need to configure those accordingly. You have mentioned that you want to access the database from a linux client: There are OBDC drivers for access databasefiles which work under linux, but I don't know if and how it is possible to use those from Mathematica, but would expect that should be possible. If the file lives on a windows server you could mount a network file with the samba client programs, but that might introduce additional restrictions on concurrent usage as there could be differences in how the file locking and other details are handled. I would be very careful when experimenting with such a setup. On the other hand I wouldn't expect insurmountable problems if only one program accesses the database file at a time.

Depending on how you are using that database converting the database is probably the best you can do, especially if you need concurrent access. As a first try you could try to use e.g. openoffice or kexi to convert the database, but of course you could also do that with Mathematica on a Windows machine. Depending on the target format there might be even better options, e.g. specialized import functions/scripts for certain database systems.

If you don't need concurrent access you could consider SQLite as a target format which like Access stores the data in plain files and also is ""serverless"", so using it might be simpler than setting up a database server. There is a JDBC driver for SQLite, which you should be able to use from Mathematica. There is also an undocumented more direct implementation to access a SQLite database from within Mathematica even without DatabaseLink, which you should find some notes about in the web.
"
5886,5886,9322,Voltage ratings of capacitors: ceramic vs electrolytic,"Now I know when it comes to electrolytic capacitors it's usually good practice to use a voltage rating 1.5x - 2.5x the maximum rating you ever expect the capacitor to be exposed to, as the lifetime can be significantly reduced by running it near its limits.

But does the same protocol apply to ceramic capacitors? For example, assume a 25V ceramic capacitor - will running it at 24V reduce its lifespan significantly?

I'm currently designing a PSU which needs to be reliable, so at the moment I'm using 50V caps for a maximum 20V input (35V caps aren't available), but I'd like to switch to 25V caps if possible.
",Thomas O,https://electronics.stackexchange.com/users/1225,"You should actually not be comparing ceramics to electrolytics in terms of lifespan at all, they are actually intended for totally different purposes. Most beginners (I did untill recently) think they are just higher values, but they are as different as inductors are to resistors. Mainly because electrolytic values are more approximate, and their value much more temperature dependant than ceramic, polycarbonates or tantalum. Note: Tantalum are very voltage sensitive.

You answer is that I would also use a 50V cap for a 20V supply, in fact if you glance at the charge curve for electrolytics you will notice that they work better (more farads) at about 1/3 of their rating anyway. As for being for different purpose, you will get heating in an electrolytic if you allow it to completely charge and discharge on a cycle, for instance using a 220uF to service a 10 amp load on a rectifier will tax the cap and cause heating in the leads, and as the other answers alread indicate, heating equals less farads.

I'm just an amateur, so no clever math, sorry.
",Conrad B,https://electronics.stackexchange.com/users/1357,http://electronics.stackexchange.com/questions/5274/voltage-ratings-of-capacitors-ceramic-vs-electrolytic,TECHNOLOGY,electronics.stackexchange.com,0.8888888888888888,0.6666666666666666,0.0,0.6666666666666666,1.0,1.0,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,0.8888888888888888,0.8666666666666666,0.3333333333333333,0.0,1.0,0.7777777777777778,Rated voltage of capacitor: ceramics and electrolysis,"Now I know when it comes to electrolytic capacitors it's usually good practice to use a voltage rating 1.5x - 2.5x the maximum rating you ever expect the capacitor to be exposed to, as the lifetime can be significantly reduced by running it near its limits.

But does the same protocol apply to ceramic capacitors? For example, assume a 25V ceramic capacitor - will running it at 24V reduce its lifespan significantly?

I'm currently designing a PSU which needs to be reliable, so at the moment I'm using 50V caps for a maximum 20V input (35V caps aren't available), but I'd like to switch to 25V caps if possible.
","You should actually not be comparing ceramics to electrolytics in terms of lifespan at all, they are actually intended for totally different purposes. Most beginners (I did untill recently) think they are just higher values, but they are as different as inductors are to resistors. Mainly because electrolytic values are more approximate, and their value much more temperature dependant than ceramic, polycarbonates or tantalum. Note: Tantalum are very voltage sensitive.

You answer is that I would also use a 50V cap for a 20V supply, in fact if you glance at the charge curve for electrolytics you will notice that they work better (more farads) at about 1/3 of their rating anyway. As for being for different purpose, you will get heating in an electrolytic if you allow it to completely charge and discharge on a cycle, for instance using a 220uF to service a 10 amp load on a rectifier will tax the cap and cause heating in the leads, and as the other answers alread indicate, heating equals less farads.

I'm just an amateur, so no clever math, sorry.
"
5655,5655,8967,"Is there such a thing as a circuit that outputs 1 if the input is high-impedance, and 0 otherwise?","I am trying to design a circuit that outputs a logical 1 if the input is high-impedance, and a 0 otherwise.  

Any idea how I might implement this?  I would prefer to use off-the-shelf parts (no programming).

Truth table:

I|O
---
X|1
0|0
1|0


I was thinking something along the lines of a pull up resistor with an NPN transistor.  Thoughts?
",Codeman,https://electronics.stackexchange.com/users/8239,"A simple window comparator will do what you want.

The input is tied to midvoltage by the two 1Mohm resistors.  The references are set at 1/3 and 2/3rds of the supply voltage.  LM339 is open-collector output, so can be OR'ed together to get the desired truth table.



Google for ""window comparator"" to get more detail about this circuit.

Please notice that this circuit will not detect a low-impedance connection to half the supply voltage, only low impedances to high or low levels.
",markrages,https://electronics.stackexchange.com/users/411,http://electronics.stackexchange.com/questions/71877/is-there-such-a-thing-as-a-circuit-that-outputs-1-if-the-input-is-high-impedance,TECHNOLOGY,electronics.stackexchange.com,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,1.0,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,1.0,"If the input is high impedance, is there a circuit output 1, otherwise output 0?","I am trying to design a circuit that outputs a logical 1 if the input is high-impedance, and a 0 otherwise.  

Any idea how I might implement this?  I would prefer to use off-the-shelf parts (no programming).

Truth table:

I|O
---
X|1
0|0
1|0


I was thinking something along the lines of a pull up resistor with an NPN transistor.  Thoughts?
","A simple window comparator will do what you want.

The input is tied to midvoltage by the two 1Mohm resistors.  The references are set at 1/3 and 2/3rds of the supply voltage.  LM339 is open-collector output, so can be OR'ed together to get the desired truth table.



Google for ""window comparator"" to get more detail about this circuit.

Please notice that this circuit will not detect a low-impedance connection to half the supply voltage, only low impedances to high or low levels.
"
1939,1939,3092,"How to prevent the ""Too awesome to use"" syndrome","When you give the player a rare but powerful item which can only be used once but is never really required to proceed, most players will not use it at all, because they are waiting for the perfect moment. But even when this moment comes, they will still be reluctant to use it, because there might be an even better moment later. So they keep hoarding it for a moment which will never come. 

In the end, they will carry the item around until it is outclassed by other, more readily available resources, or even until the very end of the game. That means that such one-shot items don't provide any gameplay-value at all. They are simply too awesome to use.

What can you do to encourage the player to make use of their one-shot items and not hoard them?
",Philipp,https://gamedev.stackexchange.com/users/21890,"Players should use an item when either (1) they can replace the item for a cost which is lower than the cost averted by using it, or (2) the cost of not having the item available later will be greater than the cost of using it immediately.  I don't like it when games punish the player for conserving resources in any fashion beyond the fact that players naturally don't benefit from things they don't use.  I also dislike it when games arbitrarily confiscate conserved items.  Instead of doing such things, games should try to convey to the player the idea that if an item will be needed, it will be possible to replace it, though perhaps at the cost of having to do some otherwise-unnecessary side missions.  If the player can, given time, earn an unbounded amount of in-game currency, an item might be sold in the ""arcana"" section of a shop where e.g. the first MagicWhatzit costs $1,000; the second costs $1,200; the third, $1,500, etc. rising at a rate which is noticeable but not overly frightening.  Such rules could encourage reasonable conservation without encouraging excessive hoarding, since players could have a sense that if they can avoid using a MagicWhatzit, they can avoid having to run a 10-minute side mission to get another one, but if running a ten-minute side mission would be easier than getting by without a MagicWhatzit, then they should use it.

This ties in with an economic principle, which has real-world consequences as well: if one wants people to perceive a resource as having a significant but not limitless cost, they must actually pay the cost if they use the resource.  If squandering a resource will mean that a players has to spend some of their real-world time running a not-terribly-exciting side mission to get it back, players will have an incentive not to squander it.  If the game were to let the player skip the busy-work, that incentive would vanish.  While it may seem that an ideal game should avoid giving the player busy-work, such busy-work may encouraging sensible resource management in a way that can improve a player's overall enjoyment and satisfaction.
",supercat,https://gamedev.stackexchange.com/users/20140,http://gamedev.stackexchange.com/questions/55558/how-to-prevent-the-too-awesome-to-use-syndrome,TECHNOLOGY,gamedev.stackexchange.com,1.0,0.7777777777777778,0.3333333333333333,1.0,0.0,0.0,1.0,0.7777777777777778,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.0,0.0,0.7777777777777778,0.8888888888888888,0.8888888888888888,1.0,1.0,0.8666666666666666,1.0,0.3333333333333333,0.0,1.0,"How to prevent ""too good to use"" syndrome","When you give the player a rare but powerful item which can only be used once but is never really required to proceed, most players will not use it at all, because they are waiting for the perfect moment. But even when this moment comes, they will still be reluctant to use it, because there might be an even better moment later. So they keep hoarding it for a moment which will never come. 

In the end, they will carry the item around until it is outclassed by other, more readily available resources, or even until the very end of the game. That means that such one-shot items don't provide any gameplay-value at all. They are simply too awesome to use.

What can you do to encourage the player to make use of their one-shot items and not hoard them?
","Players should use an item when either (1) they can replace the item for a cost which is lower than the cost averted by using it, or (2) the cost of not having the item available later will be greater than the cost of using it immediately.  I don't like it when games punish the player for conserving resources in any fashion beyond the fact that players naturally don't benefit from things they don't use.  I also dislike it when games arbitrarily confiscate conserved items.  Instead of doing such things, games should try to convey to the player the idea that if an item will be needed, it will be possible to replace it, though perhaps at the cost of having to do some otherwise-unnecessary side missions.  If the player can, given time, earn an unbounded amount of in-game currency, an item might be sold in the ""arcana"" section of a shop where e.g. the first MagicWhatzit costs $1,000; the second costs $1,200; the third, $1,500, etc. rising at a rate which is noticeable but not overly frightening.  Such rules could encourage reasonable conservation without encouraging excessive hoarding, since players could have a sense that if they can avoid using a MagicWhatzit, they can avoid having to run a 10-minute side mission to get another one, but if running a ten-minute side mission would be easier than getting by without a MagicWhatzit, then they should use it.

This ties in with an economic principle, which has real-world consequences as well: if one wants people to perceive a resource as having a significant but not limitless cost, they must actually pay the cost if they use the resource.  If squandering a resource will mean that a players has to spend some of their real-world time running a not-terribly-exciting side mission to get it back, players will have an incentive not to squander it.  If the game were to let the player skip the busy-work, that incentive would vanish.  While it may seem that an ideal game should avoid giving the player busy-work, such busy-work may encouraging sensible resource management in a way that can improve a player's overall enjoyment and satisfaction.
"
6003,6003,9524,Can I substitute a stainless steel pot for the traditional iron dutch oven?,"I have very limited options in my kitchen, and while the dutch oven is the preferred method for getting an 'oven spring' while baking sourdough, I do not have a cast iron pot to do it.

IF stainless steel is a good substitute, should I consider extra precautions?
",erasmortg,https://cooking.stackexchange.com/users/23068,"i have not tested this myself but I do have a thought.

I would tend to think that something a little less conductive would yield better results than a stainless steel stock pot. Cast Iron, Terracotta, earthenwear and other pots typically used for this are decent insulators, they take much longer to heat up. 

Just a stainless steel pot would probably transmit the heat too quickly resulting in and uneven baking of your bread.
",Rhapsody,https://cooking.stackexchange.com/users/33025,http://cooking.stackexchange.com/questions/47833/can-i-substitute-a-stainless-steel-pot-for-the-traditional-iron-dutch-oven,LIFE_ARTS,cooking.stackexchange.com,1.0,0.8888888888888888,0.0,1.0,0.3333333333333333,1.0,0.7777777777777778,0.7777777777777778,0.3333333333333333,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.3333333333333333,0.0,0.6666666666666666,1.0,Can I use a stainless steel pot instead of the traditional Dutch oven?,"My choice in the kitchen is very limited, although the Dutch oven is the preferred way to get ""oven spring"" when baking yogurt, but I don't have a cast iron pot to do it.","i have not tested this myself but I do have a thought.

I would tend to think that something a little less conductive would yield better results than a stainless steel stock pot. Cast Iron, Terracotta, earthenwear and other pots typically used for this are decent insulators, they take much longer to heat up. 

Just a stainless steel pot would probably transmit the heat too quickly resulting in and uneven baking of your bread.
"
5743,5743,9092,How to find first element of array matching a boolean condition in JavaScript?,"I'm wondering if there's a known, built-in/elegant way to find the first element of a JS array  matching a given condition. A C# equivalent would be List.Find.

So far I've been using a two-function combo like this:

// Returns the first element of an array that satisfies given predicate
Array.prototype.findFirst = function (predicateCallback) {
    if (typeof predicateCallback !== 'function') {
        return undefined;
    }

    for (var i = 0; i &lt; arr.length; i++) {
        if (i in this &amp;&amp; predicateCallback(this[i])) return this[i];
    }

    return undefined;
};

// Check if element is not undefined &amp;&amp; not null
isNotNullNorUndefined = function (o) {
    return (typeof (o) !== 'undefined' &amp;&amp; o !== null);
};


And then I can use:

var result = someArray.findFirst(isNotNullNorUndefined);


But since there are so many functional-style array methods in ECMAScript, perhaps there's something out there already like this? I imagine lots of people have to implement stuff like this all the time...
",Jakub P.,https://stackoverflow.com/users/397331,"It should be clear by now that JavaScript offers no such solution natively; here are the closest two derivatives, the most useful first:


Array.prototype.some(fn) offers the desired behaviour of stopping when a condition is met, but returns only whether an element is present; it's not hard to apply some trickery, such as the solution offered by Bergi's answer.
Array.prototype.filter(fn)[0] makes for a great one-liner but is the least efficient, because you throw away N - 1 elements just to get what you need.


Traditional search methods in JavaScript are characterized by returning the index of the found element instead of the element itself or -1. This avoids having to choose a return value from the domain of all possible types; an index can only be a number and negative values are invalid.

Both solutions above don't support offset searching either, so I've decided to write this:

(function(ns) {
  ns.search = function(array, callback, offset) {
    var size = array.length;

    offset = offset || 0;
    if (offset &gt;= size || offset &lt;= -size) {
      return -1;
    } else if (offset &lt; 0) {
      offset = size - offset;
    }

    while (offset &lt; size) {
      if (callback(array[offset], offset, array)) {
        return offset;
      }
      ++offset;
    }
    return -1;
  };
}(this));

search([1, 2, NaN, 4], Number.isNaN); // 2
search([1, 2, 3, 4], Number.isNaN); // -1
search([1, NaN, 3, NaN], Number.isNaN, 2); // 3

",Ja͢ck,https://stackoverflow.com/users/1338292,http://stackoverflow.com/questions/10457264/how-to-find-first-element-of-array-matching-a-boolean-condition-in-javascript,STACKOVERFLOW,stackoverflow.com,0.6666666666666666,0.3333333333333333,0.0,1.0,1.0,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,1.0,How to find the first element of an array that matches a Boolean condition in JavaScript?,"I'm wondering if there's a known, built-in/elegant way to find the first element of a JS array  matching a given condition. A C# equivalent would be List.Find.

So far I've been using a two-function combo like this:

// Returns the first element of an array that satisfies given predicate
Array.prototype.findFirst = function (predicateCallback) {
    if (typeof predicateCallback !== 'function') {
        return undefined;
    }

    for (var i = 0; i &lt; arr.length; i++) {
        if (i in this &amp;&amp; predicateCallback(this[i])) return this[i];
    }

    return undefined;
};

// Check if element is not undefined &amp;&amp; not null
isNotNullNorUndefined = function (o) {
    return (typeof (o) !== 'undefined' &amp;&amp; o !== null);
};


And then I can use:

var result = someArray.findFirst(isNotNullNorUndefined);


But since there are so many functional-style array methods in ECMAScript, perhaps there's something out there already like this? I imagine lots of people have to implement stuff like this all the time...
","It should be clear by now that JavaScript offers no such solution natively; here are the closest two derivatives, the most useful first:


Array.prototype.some(fn) offers the desired behaviour of stopping when a condition is met, but returns only whether an element is present; it's not hard to apply some trickery, such as the solution offered by Bergi's answer.
Array.prototype.filter(fn)[0] makes for a great one-liner but is the least efficient, because you throw away N - 1 elements just to get what you need.


Traditional search methods in JavaScript are characterized by returning the index of the found element instead of the element itself or -1. This avoids having to choose a return value from the domain of all possible types; an index can only be a number and negative values are invalid.

Both solutions above don't support offset searching either, so I've decided to write this:

(function(ns) {
  ns.search = function(array, callback, offset) {
    var size = array.length;

    offset = offset || 0;
    if (offset &gt;= size || offset &lt;= -size) {
      return -1;
    } else if (offset &lt; 0) {
      offset = size - offset;
    }

    while (offset &lt; size) {
      if (callback(array[offset], offset, array)) {
        return offset;
      }
      ++offset;
    }
    return -1;
  };
}(this));

search([1, 2, NaN, 4], Number.isNaN); // 2
search([1, 2, 3, 4], Number.isNaN); // -1
search([1, NaN, 3, NaN], Number.isNaN, 2); // 3

"
4966,4966,7911,100% Rye Pizza Base Recipes?,"I'm looking for a 100% rye pizza base recipe. The recipes I can find all combine the rye with other flours (typically wheat based). I know it is possible to create 100% rye based pizza bases as I know of one pizza place in town that sells them. 

I understand that they had to do something special to keep the pizza base from falling apart. I don't mind experimenting a bit to find a recipe that works, but I could use some ideas on where to start - what sort of ingredients might bind the rye so that it doesn't crumble as a thin pizza base and maintains a low glycemic index for my diabetic wife.

The only dietary requirements would be that the various ingredients maintain a low glycemic index or a specific ingredient with a high glycemic index can be counteracted by some other ingredient. And only using rye flour.
",Stephen Perelson,https://cooking.stackexchange.com/users/1892,"You need to work rye flour much longer than ordinary flour for the gluten to start binding the dough. I use a hand beater with dough hooks and start off with a very moist mix that includes olive oil and egg. Let it rise for a few hours then work more rye into the dough by hand kneading until it is nice and springy.
",Nick,https://cooking.stackexchange.com/users/6226,http://cooking.stackexchange.com/questions/4979/100-rye-pizza-base-recipes,LIFE_ARTS,cooking.stackexchange.com,1.0,0.5555555555555556,0.0,1.0,0.6666666666666666,1.0,0.7777777777777778,0.5555555555555556,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.6666666666666666,0.7777777777777778,0.4444444444444444,1.0,0.7777777777777778,0.6,0.6666666666666666,0.0,0.3333333333333333,0.8888888888888888,100% rye pizza formula?,"I'm looking for a 100% rye pizza base recipe. The recipes I can find all combine the rye with other flours (typically wheat based). I know it is possible to create 100% rye based pizza bases as I know of one pizza place in town that sells them. 

I understand that they had to do something special to keep the pizza base from falling apart. I don't mind experimenting a bit to find a recipe that works, but I could use some ideas on where to start - what sort of ingredients might bind the rye so that it doesn't crumble as a thin pizza base and maintains a low glycemic index for my diabetic wife.

The only dietary requirements would be that the various ingredients maintain a low glycemic index or a specific ingredient with a high glycemic index can be counteracted by some other ingredient. And only using rye flour.
","You need more rye flour than normal flour to make the gluten stick to the dough. I used a hand beater with a dough hook, starting with a very wet mixture, including olive oil and eggs. Let the dough rise for a few hours, then knead with your hands to put more rye into the dough until it becomes good and elastic."
5610,5610,8902,How to unbrick galaxy grand 2,"I want to unbrick my galaxy grand 2 but instead of flashing the stock rom through odin, is there any other way to flash a custom rom instead?
",Maaz,https://android.stackexchange.com/users/95836,"No.  Odin the stock ROM to get everything back to normal (you may need to use the appropriate PIT file to repartition), and then afterward you can flash a custom ROM as you would normally.
",Matthew Read,https://android.stackexchange.com/users/1465,http://android.stackexchange.com/questions/105352/how-to-unbrick-galaxy-grand-2,TECHNOLOGY,android.stackexchange.com,0.8888888888888888,0.6666666666666666,0.0,0.5,1.0,1.0,0.4444444444444444,0.5555555555555556,0.3333333333333333,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.8888888888888888,How to untie Galaxy 2,"I want to unlock my Galaxy grand 2, but not flash the stock ROM through Odin. Is there any other way to flash the custom Rom?","No Restore everything to normal in the storage ROM (you may need to repartition with the appropriate pit file), and then you can refresh a custom ROM as usual."
4759,4759,7553,Photoshop/Illustrator: generate vector graphic from bitmap,"
  Possible Duplicate:
  Vectorization graphics approach  




Folks,
Photoshop newbie here with what I think is a simple question, but clearly, I am not searching for the right keywords on Google.

I have a hand-sketched pattern that I have scanned into a (bitmap) image. It is a crisp black and white image. I would like for a way to get Photoshop (or Illustrator) to detect the edges and extract paths from it, thereby converting it into a vector graphic.

Is there a simple way to accomplish this?

Thanks.

-Raj
",user49692,https://superuser.com/users/49692,"Yes, by using the 'trace' function in Illustrator: there's a tutorial here.
",Andy Mikula,https://superuser.com/users/169,http://superuser.com/questions/188330,TECHNOLOGY,superuser.com,1.0,0.5555555555555556,0.0,0.3333333333333333,1.0,1.0,0.6666666666666666,0.5555555555555556,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,1.0,0.8888888888888888,0.5555555555555556,0.8888888888888888,1.0,0.9,0.3333333333333333,0.6666666666666666,0.0,0.8888888888888888,Photoshop / illustrator: generating vector graphics from bitmaps,"
  Possible Duplicate:
  Vectorization graphics approach  




Folks,
Photoshop newbie here with what I think is a simple question, but clearly, I am not searching for the right keywords on Google.

I have a hand-sketched pattern that I have scanned into a (bitmap) image. It is a crisp black and white image. I would like for a way to get Photoshop (or Illustrator) to detect the edges and extract paths from it, thereby converting it into a vector graphic.

Is there a simple way to accomplish this?

Thanks.

-Raj
","Yes, use the ""trace"" function in illustrator: Here's a tutorial."
4135,4135,6599,Apartment in Munich,"I'm a married man looking for an apartment to live with my wife from February 2014 until April 2014.  How can I find an apartment for this time period?
",user10034,https://travel.stackexchange.com/users/10034,"If you are searching for an unfurnished apartment, this is the most popular site in Germany:

http://www.immobilienscout24.de

Otherwise, you can check Craigslist Munich for apartment listings, almost all of which are furnished. Alternately run a simple search on Google for ""Furnished apartments Munich"" and you will see lots of different companies providing basically the same service.

Edit: I misread the original question, the OP is only staying for a very short amount of time.  My advice is best suited for people staying over a year.
",Ryan,https://travel.stackexchange.com/users/3765,http://travel.stackexchange.com/questions/23451/apartment-in-munich,CULTURE,travel.stackexchange.com,1.0,0.3333333333333333,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.7777777777777778,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.6666666666666666,0.7777777777777778,0.6666666666666666,1.0,0.7777777777777778,0.6,0.6666666666666666,0.0,0.3333333333333333,0.8888888888888888,Munich apartment,"I am a married man. From February 2014 to April 2014, I want to find an apartment to live with my wife. How can I find an apartment in this period of time?","If you are searching for an unfurnished apartment, this is the most popular site in Germany:

http://www.immobilienscout24.de

Otherwise, you can check Craigslist Munich for apartment listings, almost all of which are furnished. Alternately run a simple search on Google for ""Furnished apartments Munich"" and you will see lots of different companies providing basically the same service.

Edit: I misread the original question, the OP is only staying for a very short amount of time.  My advice is best suited for people staying over a year.
"
1389,1389,2187,How do I change the MySQL database directory?,"I am using CentOS with cPanel. On my server, all MySQL databases save at /var/lib/mysql. Now /var is 100% full and MySQL has stopped working. How can I move the databases to a new directory like /home/mysql especially considering that this server is managed with cPanel?
",user111175,https://serverfault.com/users/111175,"if you want to change mysql data directory, you should do edit the mysql config file and change datadir value.

datadir = /home/user/data


Your new data directory MUST be owned by mysql and has proper security context.

chown -R mysql.mysql /home/user/data
chcon -R -t mysqld_db_t /home/user/data


restart mysql server

/etc/init.d/mysqld restart

",wens,https://serverfault.com/users/98198,http://serverfault.com/questions/363958,TECHNOLOGY,serverfault.com,0.8888888888888888,0.7777777777777778,0.0,0.3333333333333333,1.0,0.6666666666666666,0.7777777777777778,0.4444444444444444,0.3333333333333333,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.3333333333333333,0.0,1.0,How to change MySQL database directory?,"I'm using CentOS and cPanel. On my server, all MySQL databases are stored in / var / lib / MySQL. Now / var is 100% full and MySQL has stopped working. How to move the database to a new directory (such as / home / MySQL), especially considering that this server is managed by cPanel?","if you want to change mysql data directory, you should do edit the mysql config file and change datadir value.

datadir = /home/user/data


Your new data directory MUST be owned by mysql and has proper security context.

chown -R mysql.mysql /home/user/data
chcon -R -t mysqld_db_t /home/user/data


restart mysql server

/etc/init.d/mysqld restart

"
5603,5603,8891,"How to prevent the ""Too awesome to use"" syndrome","When you give the player a rare but powerful item which can only be used once but is never really required to proceed, most players will not use it at all, because they are waiting for the perfect moment. But even when this moment comes, they will still be reluctant to use it, because there might be an even better moment later. So they keep hoarding it for a moment which will never come. 

In the end, they will carry the item around until it is outclassed by other, more readily available resources, or even until the very end of the game. That means that such one-shot items don't provide any gameplay-value at all. They are simply too awesome to use.

What can you do to encourage the player to make use of their one-shot items and not hoard them?
",Philipp,https://gamedev.stackexchange.com/users/21890,"Thank you all for your answers. There are some great ideas between them. I decided that instead of accepting one of them, I decided to collect all ideas from the posts above, summarize them in one answer, and accept this answer as reference for future readers.

Reasons why players hoard:


They develop a habit to solve certain situations using certain tools. When they have a tool which can only be used once, they will never develop a habit for using it. As a result they forget that they actually have this tool.
They don't know what the item is actually doing, so they aren't aware when they are in a situation where it could be useful.
They don't want to do a mistake and prevent further progress by using an item too early.


How to prevent it as a game designer:


Give the player a hint when in a situation where a certain one-shot item would be useful
Make it possible to re-obtain the items after use.
Give the player so many one-shot items, that each individual one doesn't seem that valuable and irreplaceable.
Add severe consequences to dying (more than having to reload the last savegame), so that the player will use one-shot items when desperate.
Don't make them single-use. Add a long cooldown to items instead or allow them to be recharged with another resource, so that the player can use them multiple times.
Make it impossible to hoard them. When the player is aware that they will lose the item anyway, they will use it sooner. This could be done by adding a time-limit, removing them after completing the level or severely limiting the number of items which can be carried at a time.
Punish the player for hoarding too many one-shot items, so that they will be motivated to get rid of them soon.

",Philipp,https://gamedev.stackexchange.com/users/21890,http://gamedev.stackexchange.com/questions/55558/how-to-prevent-the-too-awesome-to-use-syndrome,TECHNOLOGY,gamedev.stackexchange.com,1.0,1.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.8888888888888888,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9,1.0,0.0,1.0,1.0,"How to prevent ""too good to use"" syndrome","When you give the player a rare but powerful item which can only be used once but is never really required to proceed, most players will not use it at all, because they are waiting for the perfect moment. But even when this moment comes, they will still be reluctant to use it, because there might be an even better moment later. So they keep hoarding it for a moment which will never come. 

In the end, they will carry the item around until it is outclassed by other, more readily available resources, or even until the very end of the game. That means that such one-shot items don't provide any gameplay-value at all. They are simply too awesome to use.

What can you do to encourage the player to make use of their one-shot items and not hoard them?
","Thank you all for your answers. There are some great ideas between them. I decided that instead of accepting one of them, I decided to collect all ideas from the posts above, summarize them in one answer, and accept this answer as reference for future readers.

Reasons why players hoard:


They develop a habit to solve certain situations using certain tools. When they have a tool which can only be used once, they will never develop a habit for using it. As a result they forget that they actually have this tool.
They don't know what the item is actually doing, so they aren't aware when they are in a situation where it could be useful.
They don't want to do a mistake and prevent further progress by using an item too early.


How to prevent it as a game designer:


Give the player a hint when in a situation where a certain one-shot item would be useful
Make it possible to re-obtain the items after use.
Give the player so many one-shot items, that each individual one doesn't seem that valuable and irreplaceable.
Add severe consequences to dying (more than having to reload the last savegame), so that the player will use one-shot items when desperate.
Don't make them single-use. Add a long cooldown to items instead or allow them to be recharged with another resource, so that the player can use them multiple times.
Make it impossible to hoard them. When the player is aware that they will lose the item anyway, they will use it sooner. This could be done by adding a time-limit, removing them after completing the level or severely limiting the number of items which can be carried at a time.
Punish the player for hoarding too many one-shot items, so that they will be motivated to get rid of them soon.

"
1357,1357,2138,How to disable bash drivers in windows 8.1?,"I'm trying to follow these instructions to stop Bash Driver BHDrvx86 or BHDdrvx64, but device manager in Windows 8.1 no longer displays non plug and play drivers (such as the Bash drivers), even as a hidden option. I'm unsure how else to disable them.
",Erlja Jkdf.,https://superuser.com/users/446259,"Device Manager generally should be run elevated, it doesn't show many things otherwise.

However, the same can be done from an elevated command line:

sc config BHDrvx86 start= disabled
sc config BHDdrvx64 start= disabled


(A space only after the = sign, exactly as shown in the example.)
",grawity,https://superuser.com/users/1686,http://superuser.com/questions/913799,TECHNOLOGY,superuser.com,0.7777777777777778,1.0,0.0,1.0,1.0,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.8888888888888888,0.7777777777777778,0.4444444444444444,0.8888888888888888,0.7777777777777778,0.6666666666666667,1.0,0.0,0.0,1.0,How to disable bash driver in Windows 8.1?,"I'm trying to follow these instructions to stop the bash driver bhdrvx86 or bhdrvx64, but the device manager in Windows 8.1 no longer shows non plug and play drivers (such as bash drivers) or even hidden options. I don't know what else can make them fail.","Device Manager generally should be run elevated, it doesn't show many things otherwise.

However, the same can be done from an elevated command line:

sc config BHDrvx86 start= disabled
sc config BHDdrvx64 start= disabled


(A space only after the = sign, exactly as shown in the example.)
"
814,814,1290,Get Product Options for each Product in the Catalog,"I am trying to build a script that outputs all the product options for each product in the catalog into a CSV file.

I have tried using the code on this page: http://www.atwix.com/magento/configurable-product-attributes/

For this code:

$attribute = Mage::getModel('eav/config')-&gt;getAttribute('catalog_product', 'color');  
foreach ($attribute-&gt;getSource()-&gt;getAllOptions(true) as $option) {
    echo $option['value'] . ' ' . $option['label'] . ""\n"";
}


I get no output, what-so-ever.

For this code:

$productAttributeOptions = $product-&gt;getTypeInstance(true)-&gt;getConfigurableAttributesAsArray($product);
$attributeOptions = array();
foreach ($productAttributeOptions as $productAttribute) {
    foreach ($productAttribute['values'] as $attribute) {
        $attributeOptions[$productAttribute['label']][$attribute['value_index']] = $attribute['store_label'];
    }
}


I get this error:

Fatal error:  Call to undefined method Mage_Catalog_Model_Product_Type_Simple::getConfigurableAttributesAsArray() in /home/tws2/public_html/getopts.php on line 71

Ive been unable to find anything else on the internet for getting at the product options of a product with PHP code.

Can someone please explain to me how to use PHP to get at all the product options data for each product in the catalog, so I can output all this data into a CSV file.

The purpose of this is to transfer the product options data over to an identical Magento server that has the same catalog, just missing the product options data. Once I have all the CSV file of product options I was going to make another script to write them into the identical Magento server. This is how Ive been advised to do this task in-house, if you have a better suggestion please let me know.
",Jimmery,https://magento.stackexchange.com/users/26241,"No answer but another option. Use Avs_FastSimpleImport to update product data with the attribute values. In the FastSimpleImport settings you can define missing options should be created

Check out the module here
",Sander Mangel,https://magento.stackexchange.com/users/50,http://magento.stackexchange.com/questions/71853/get-product-options-for-each-product-in-the-catalog,TECHNOLOGY,magento.stackexchange.com,1.0,0.3333333333333333,0.0,1.0,1.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,0.0,0.6666666666666666,Get product options for each product in the catalog,"I am trying to build a script that outputs all the product options for each product in the catalog into a CSV file.

I have tried using the code on this page: http://www.atwix.com/magento/configurable-product-attributes/

For this code:

$attribute = Mage::getModel('eav/config')-&gt;getAttribute('catalog_product', 'color');  
foreach ($attribute-&gt;getSource()-&gt;getAllOptions(true) as $option) {
    echo $option['value'] . ' ' . $option['label'] . ""\n"";
}


I get no output, what-so-ever.

For this code:

$productAttributeOptions = $product-&gt;getTypeInstance(true)-&gt;getConfigurableAttributesAsArray($product);
$attributeOptions = array();
foreach ($productAttributeOptions as $productAttribute) {
    foreach ($productAttribute['values'] as $attribute) {
        $attributeOptions[$productAttribute['label']][$attribute['value_index']] = $attribute['store_label'];
    }
}


I get this error:

Fatal error:  Call to undefined method Mage_Catalog_Model_Product_Type_Simple::getConfigurableAttributesAsArray() in /home/tws2/public_html/getopts.php on line 71

Ive been unable to find anything else on the internet for getting at the product options of a product with PHP code.

Can someone please explain to me how to use PHP to get at all the product options data for each product in the catalog, so I can output all this data into a CSV file.

The purpose of this is to transfer the product options data over to an identical Magento server that has the same catalog, just missing the product options data. Once I have all the CSV file of product options I was going to make another script to write them into the identical Magento server. This is how Ive been advised to do this task in-house, if you have a better suggestion please let me know.
","No answer but another option. Use Avs_FastSimpleImport to update product data with the attribute values. In the FastSimpleImport settings you can define missing options should be created

Check out the module here
"
5724,5724,9066,"Do headset and frame metals need to match, or will a steel/aluminum headset get stuck on an aluminum/steel frame?","Will a steel headset get stuck on an aluminum frame bike?

Will an aluminum alloy headset get stuck on a steel frame bike?

I am not asking about carbon frames, by the way.

I ask because I have seen some questions about aluminum alloy seatposts getting stuck in steel frames, and I wonder if the same kind of ""galvanic pair"" issue would cause a steel / ""chromed steel"" threaded headset to get stuck into an aluminum frame.  

Would doing this make the headset impossible to replace?  Does it even matter if it is impossible to replace if the bike is not extraordinarily fancy?

I'm not worried about the  short term, but am wondering about best practices when assembling old bikes from scrap parts.
",PositiveK,https://bicycles.stackexchange.com/users/5202,"Seatposts have a relatively long length inside the tube, and no way to get a tool to the bottom of the post to hammer it. If you have a proper headset remover tool, I doubt a headset would ever get so stuck. (Even without the proper tool, it's unlikely to be a problem.)

Also, I don't believe there's such a thing as a headset with an alloy bearing race. So if it has alloy cups, they probably have replaceable bearings that fit inside it, so the cups shouldn't ever need replacing.
",armb,https://bicycles.stackexchange.com/users/1158,http://bicycles.stackexchange.com/questions/17212/do-headset-and-frame-metals-need-to-match-or-will-a-steel-aluminum-headset-get,CULTURE,bicycles.stackexchange.com,0.8888888888888888,0.6666666666666666,0.0,0.6666666666666666,1.0,0.6666666666666666,0.4444444444444444,0.4444444444444444,1.0,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.0,0.8888888888888888,1.0,0.8888888888888888,1.0,1.0,1.0,0.0,0.0,1.0,1.0,"Does the headset need to match the frame metal, or will the steel / aluminum headset stick to the aluminum / steel frame?","Will a steel headset get stuck on an aluminum frame bike?

Will an aluminum alloy headset get stuck on a steel frame bike?

I am not asking about carbon frames, by the way.

I ask because I have seen some questions about aluminum alloy seatposts getting stuck in steel frames, and I wonder if the same kind of ""galvanic pair"" issue would cause a steel / ""chromed steel"" threaded headset to get stuck into an aluminum frame.  

Would doing this make the headset impossible to replace?  Does it even matter if it is impossible to replace if the bike is not extraordinarily fancy?

I'm not worried about the  short term, but am wondering about best practices when assembling old bikes from scrap parts.
","The column has a relatively long length in the pipe, so there is no way to knock it at the bottom of the column with tools. If you have a suitable headset removal tool, I doubt if the headset will get stuck. (even without the right tools, it's unlikely to be a problem.)"
4727,4727,7501,How to change port number in vino?,"How to change port number in vino ubuntu 11.10?

Cannot find option to change from port 5900 on vino vnc 'remote desktop' window, nor can I find it via gconf-editor as was available in previous ubuntu version.

Please help
",Matt Perry,https://askubuntu.com/users/29396,"On Ubuntu 14.10, gconf-editor was required. dconf-editor set a value, but it was not used, and displayed as 0 (5900) in gconf-editor.

sudo apt-get install gconf-editor
gconf-editor



",rickfoosusa,https://askubuntu.com/users/106250,http://askubuntu.com/questions/69965/how-to-change-port-number-in-vino,TECHNOLOGY,askubuntu.com,0.8888888888888888,1.0,0.0,0.3333333333333333,1.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,0.6666666666666666,1.0,0.9,1.0,0.0,0.0,0.6666666666666666,How to change the port number in vino?,"How to change port number in vino ubuntu 11.10?

Cannot find option to change from port 5900 on vino vnc 'remote desktop' window, nor can I find it via gconf-editor as was available in previous ubuntu version.

Please help
","On Ubuntu 14.10, the gconf editor is required. The dconf editor sets a value, but does not use it, and displays it as 0 (5900) in the gconf editor."
2898,2898,4610,Send email when publish new post in certain categories,"I'm looking for php code that will allow me to do the following: when new post publish in categories which ids are 12 and 34, email will send to all users.
",Nguyen Duc Phuong,https://wordpress.stackexchange.com/users/60157,"You can use transition_post_status function, then fetch users and send an email to all users.

Here is a sample code, it's not tested. But it will get you started with this.

function wcs_send_mail_on_publish_category_posts( $new_status, $old_status, $post ) {

    global $post;

    if ( 'publish' !== $new_status or 'publish' === $old_status ) return;

    if ( in_category( array( '12', '34' ) ) ) {

        $subscribers = get_users( array ( 'role' =&gt; 'subscriber' ) );
        $emails      = array ();

        foreach ( $subscribers as $subscriber )
            $emails[] = $subscriber-&gt;user_email;

        $body = sprintf( 'Hey there is a new entry! See &lt;%s&gt;', get_permalink( $post )  );

        wp_mail( $emails, 'New entry!', $body );

    }

}

add_action( 'transition_post_status', 'wcs_send_mail_on_publish_category_posts', 10, 3 );

",Robert hue,https://wordpress.stackexchange.com/users/22461,http://wordpress.stackexchange.com/questions/162386/send-email-when-publish-new-post-in-certain-categories,TECHNOLOGY,wordpress.stackexchange.com,1.0,0.4444444444444444,0.0,0.0,1.0,1.0,1.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,1.0,Send email when publishing new articles in some categories,"The PHP code I'm looking for will allow me to do the following: when a new article is published in a category with IDS 12 and 34, the email will be sent to all users.","You can use transition_post_status function, then fetch users and send an email to all users.

Here is a sample code, it's not tested. But it will get you started with this.

function wcs_send_mail_on_publish_category_posts( $new_status, $old_status, $post ) {

    global $post;

    if ( 'publish' !== $new_status or 'publish' === $old_status ) return;

    if ( in_category( array( '12', '34' ) ) ) {

        $subscribers = get_users( array ( 'role' =&gt; 'subscriber' ) );
        $emails      = array ();

        foreach ( $subscribers as $subscriber )
            $emails[] = $subscriber-&gt;user_email;

        $body = sprintf( 'Hey there is a new entry! See &lt;%s&gt;', get_permalink( $post )  );

        wp_mail( $emails, 'New entry!', $body );

    }

}

add_action( 'transition_post_status', 'wcs_send_mail_on_publish_category_posts', 10, 3 );

"
5719,5719,9059,Populate column with number of substrings in another column,"I have two tables ""A"" and ""B"". Table ""A"" has two columns ""Body"" and ""Number."" The column ""Number"" is empty, the purpose is to populate it.

Table A: Body / Number

ABABCDEF /
IJKLMNOP /
QRSTUVWKYZ /


Table ""B"" only has one column:

Table B: Values

AB
CD
QR


Here is what I am looking for as a result:

ABABCDEF / 3
IJKLMNOP / 0
QRSTUVWKYZ / 1


In other words, I want to create a query that looks up, for each string in the ""Body"" column, how many times the substrings in the ""Values"" column appear.

How would you advise me to do that?
",user1029296,https://stackoverflow.com/users/1029296,"You want an update query:

update A
    set cnt = (select sum((length(a.body) - length(replace(a.body, b.value, '')) / length(b.value))
               from b
              )


This uses a little trick for counting the number of occurrence of b.value in a given string.  It replaces each occurrence with an empty string and counts the difference in length of the strings.  This is divided by the length of the string being replaced.

If you just wanted the number of matches (so the first value would be ""2"" instead of ""3""):

update A
    set cnt = (select count(*)
               from b
               where a.body like concat('%', b.value, '%')
              )

",Gordon Linoff,https://stackoverflow.com/users/1144035,http://stackoverflow.com/questions/16672046/populate-column-with-number-of-substrings-in-another-column,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.6666666666666666,0.0,0.0,1.0,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.3333333333333333,0.0,0.7777777777777778,Fill the column with the number of substrings in another column,"I have two tables ""A"" and ""B"". Table ""A"" has two columns ""Body"" and ""Number."" The column ""Number"" is empty, the purpose is to populate it.

Table A: Body / Number

ABABCDEF /
IJKLMNOP /
QRSTUVWKYZ /


Table ""B"" only has one column:

Table B: Values

AB
CD
QR


Here is what I am looking for as a result:

ABABCDEF / 3
IJKLMNOP / 0
QRSTUVWKYZ / 1


In other words, I want to create a query that looks up, for each string in the ""Body"" column, how many times the substrings in the ""Values"" column appear.

How would you advise me to do that?
","You want an update query:

update A
    set cnt = (select sum((length(a.body) - length(replace(a.body, b.value, '')) / length(b.value))
               from b
              )


This uses a little trick for counting the number of occurrence of b.value in a given string.  It replaces each occurrence with an empty string and counts the difference in length of the strings.  This is divided by the length of the string being replaced.

If you just wanted the number of matches (so the first value would be ""2"" instead of ""3""):

update A
    set cnt = (select count(*)
               from b
               where a.body like concat('%', b.value, '%')
              )

"
1466,1466,2309,Techniques for creating melodies,"I've posted this question:

Learning to create melodies

I've got a few ideas of techniques towards creating melodies but wanted to ask if there are any specific methods to help get better. I've read: The Complete's Idiot's Guide To Music Composition which explained a lot of details but I still find it difficult to create something 'good', whenever I play on my keyboard, it sounds rubbish. Is it something that comes with ample practice? What can I do to become better?
",MJohnson52,https://music.stackexchange.com/users/12211,"Melody in Songwriting, by Jack Perricone.  It's the first thing I've seen that makes explicit all the things I was (usually) doing unconsciously.
",Joel Derfner,https://music.stackexchange.com/users/12586,http://music.stackexchange.com/questions/23048/techniques-for-creating-melodies,LIFE_ARTS,music.stackexchange.com,1.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.7777777777777778,0.6666666666666666,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.0,0.0,1.0,0.8888888888888888,0.5555555555555556,1.0,1.0,0.7333333333333333,0.6666666666666666,0.0,0.0,0.8888888888888888,Techniques of creating melody,"I've posted this question:

Learning to create melodies

I've got a few ideas of techniques towards creating melodies but wanted to ask if there are any specific methods to help get better. I've read: The Complete's Idiot's Guide To Music Composition which explained a lot of details but I still find it difficult to create something 'good', whenever I play on my keyboard, it sounds rubbish. Is it something that comes with ample practice? What can I do to become better?
","Melody in Songwriting, by Jack Perricone.  It's the first thing I've seen that makes explicit all the things I was (usually) doing unconsciously.
"
2862,2862,4555,Is AES key length a size of the key or entropy?,"While educating my self I'm having hard time to understand what an 128 bit AES key actually means?
Is it a key length or entropy?

Please explain to me trough following example (assuming AES):


  Password length in characters (L) = 20 (characters) 
  
  Symbols used (N) = 95 (ASCII set)
  
  Entropy = log2 (N^L) = 128 (is this what is called 128bit AES key?)
  
  OR
  
  Key length = L * 8bits = 160 bit key length ? (is this supposed to
  be 160bit AES key?)


When somebody says that he's using 128bit AES key, I want to know to what is he referring to, a key length or entropy?
",codekiddy,https://crypto.stackexchange.com/users/13555,"When they say they are using a 128 bit AES key, they mean the length of the key is 128 bits. Technically a 128 bit AES key could have 0 bits of entropy, 128 bits of entropy, or anywhere in between.

To be secure, however, the 128 bit key should also have high entropy. Ideally, a 128 bit AES key would also have 128 bits of entropy.

A few side notes
Keep in mind that $\log_2N^L$ only computes the entropy in the key if the $L$ characters in the password were chosen randomly.

There is no such thing as a 160 bit AES key. AES supports key lengths of 128, 192, 256 bits. 
",mikeazo,https://crypto.stackexchange.com/users/706,http://crypto.stackexchange.com/questions/16166/is-aes-key-length-a-size-of-the-key-or-entropy,TECHNOLOGY,crypto.stackexchange.com,0.8888888888888888,0.7777777777777778,0.0,1.0,1.0,1.0,0.4444444444444444,0.4444444444444444,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,1.0,0.7777777777777778,1.0,1.0,1.0,0.3333333333333333,0.0,1.0,0.8888888888888888,Is AES key length the size of key or entropy?,"While educating my self I'm having hard time to understand what an 128 bit AES key actually means?
Is it a key length or entropy?

Please explain to me trough following example (assuming AES):


  Password length in characters (L) = 20 (characters) 
  
  Symbols used (N) = 95 (ASCII set)
  
  Entropy = log2 (N^L) = 128 (is this what is called 128bit AES key?)
  
  OR
  
  Key length = L * 8bits = 160 bit key length ? (is this supposed to
  be 160bit AES key?)


When somebody says that he's using 128bit AES key, I want to know to what is he referring to, a key length or entropy?
","When they say they are using a 128 bit AES key, they mean the length of the key is 128 bits. Technically a 128 bit AES key could have 0 bits of entropy, 128 bits of entropy, or anywhere in between.

To be secure, however, the 128 bit key should also have high entropy. Ideally, a 128 bit AES key would also have 128 bits of entropy.

A few side notes
Keep in mind that $\log_2N^L$ only computes the entropy in the key if the $L$ characters in the password were chosen randomly.

There is no such thing as a 160 bit AES key. AES supports key lengths of 128, 192, 256 bits. 
"
851,851,1357,"What is a layman's alternative to the IT word ""datetime""?","I have a spreadsheet with several columns. And one must contain the date and time. But I don't know what to write as the header.

In programming terms, it is a ""datetime"". But I suspect this would just look odd to a layman. What is the best alternative word or phrase to use.
",Urbycoz,https://english.stackexchange.com/users/7451,"I would go with simply date and time.  That is a phrase in common use, and would be commonly understood.

I think that in your situation, however, you might not need a variant of datetime; Rikon gives a couple example alternatives (Date Created or Date Modified) which describe the meaning of the date and time, rather than just saying date and time.  This is more user-friendly in a spreadsheet.
",Daniel,https://english.stackexchange.com/users/10041,http://english.stackexchange.com/questions/43564/what-is-a-laymans-alternative-to-the-it-word-datetime,CULTURE,english.stackexchange.com,1.0,1.0,0.0,1.0,0.3333333333333333,0.5,0.4444444444444444,0.4444444444444444,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,1.0,0.3333333333333333,0.0,0.0,1.0,"What is the layman's substitute for ""date time""?","I have a spreadsheet with several columns. And one must contain the date and time. But I don't know what to write as the header.

In programming terms, it is a ""datetime"". But I suspect this would just look odd to a layman. What is the best alternative word or phrase to use.
","I would go with simply date and time.  That is a phrase in common use, and would be commonly understood.

I think that in your situation, however, you might not need a variant of datetime; Rikon gives a couple example alternatives (Date Created or Date Modified) which describe the meaning of the date and time, rather than just saying date and time.  This is more user-friendly in a spreadsheet.
"
541,541,852,Thunderbird 2.0: Inbox size is 4GB on disk: how do I reduce it?,"Mozilla Thunderbird 2.0: I have set Thunderbird never to delete a message that is on disk...Thus, after four short years, I have a 4GB Inbox file. Thunderbird needs about 10 minutes to read it, and even then I can't compact it. Anyone have some suggestions?
",Eric,https://superuser.com/users/15673,"This may not be something you can or want to do, but Thunderbird 3.1 works well with large databases. My inbox is 7GB and it's plenty speedy.

The other thing I do is every couple of years, I search and find all bulk e-mail and delete them. 5000 e-mails from e.newegg.com can take up a bit of space. But I never delete any other type of message.
",emgee,https://superuser.com/users/7247,http://superuser.com/questions/198503,TECHNOLOGY,superuser.com,1.0,0.6666666666666666,0.0,1.0,0.6666666666666666,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.7777777777777778,0.6666666666666666,0.8888888888888888,0.8888888888888888,0.6,1.0,0.0,0.0,1.0,Thunderbird 2.0: the inbox size is 4GB disk: how to reduce it?,"Mozilla Thunderbird 2.0: I have set Thunderbird to never delete messages on disk So, in just four years, I have a 4GB inbox file. Thunderbird takes 10 minutes to read, and even then I can't compress it. Is there any suggestion?","This may not be something you can or want to do, but Thunderbird 3.1 works well with large databases. My inbox is 7GB and it's plenty speedy.

The other thing I do is every couple of years, I search and find all bulk e-mail and delete them. 5000 e-mails from e.newegg.com can take up a bit of space. But I never delete any other type of message.
"
1664,1664,2632,Scope and SQL query in Rails 4,"In app/controllers/ElementTypesController.rb, I have this:

l = params[:element_type_name]
@element_types = ElementType.by_name(l).page(params[:page])


and in the model app/models/ElementType.rb, I have this:

scope :by_name, (lambda do |name| { :conditions =&gt; ['name LIKE ?', ""%#{name}%""]} end )


However, this throws an error, complaining that pagination (Kaminari) can't happen on a hash. What is wrong with my scope?
",sploiber,https://stackoverflow.com/users/1379955,"I believe scope is just an alias, so its also possible to do it like this

def self.by_name (name)
   where('name LIKE ?', ""%#{name}"")
end

",natsumi,https://stackoverflow.com/users/884810,http://stackoverflow.com/questions/28931087/scope-and-sql-query-in-rails-4,STACKOVERFLOW,stackoverflow.com,1.0,0.3333333333333333,0.0,0.5,1.0,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.8888888888888888,0.8333333333333334,0.5,1.0,1.0,0.8,0.3333333333333333,0.3333333333333333,0.0,0.7777777777777778,Scope and SQL queries in rails 4,"In app/controllers/ElementTypesController.rb, I have this:

l = params[:element_type_name]
@element_types = ElementType.by_name(l).page(params[:page])


and in the model app/models/ElementType.rb, I have this:

scope :by_name, (lambda do |name| { :conditions =&gt; ['name LIKE ?', ""%#{name}%""]} end )


However, this throws an error, complaining that pagination (Kaminari) can't happen on a hash. What is wrong with my scope?
","I believe scope is just an alias, so its also possible to do it like this

def self.by_name (name)
   where('name LIKE ?', ""%#{name}"")
end

"
1261,1261,1987,Why are the ringwraiths fearful of coming in contact with water?,"At least twice in LoTR:FotR, ringwraiths cower away from bodies of water. The second time (the ford of Bruinen) can be explained away by their fear of some Elvish magical trap through the enchantment of the water; but what about the first time, at the ferry? One of the Nazgul could have easily made the jump onto the barge and quickly dispatched those pesky Hobitsses.
",einpoklum,https://scifi.stackexchange.com/users/16835,"It is common in folklore for evil or ""unnatural"" creatures to be unable to cross running water. For example, this is a traditional attribute of vampires: http://en.wikipedia.org/wiki/Vampire

Tolkien himself noted that this idea was difficult to sustain for the Ringwraiths. In particular, they would have had to cross the river Greyflood (which had no bridge or ferry) in order to travel from Mordor to the Shire. (I don't have the citation to hand, it may have been in Unfinished Tales.) He seems to have gone ahead with it anyway, in order to emphasise that the Ringwraiths were inhuman, undead creatures. 
",Royal Canadian Bandit,https://scifi.stackexchange.com/users/21600,http://scifi.stackexchange.com/questions/48656/why-are-the-ringwraiths-fearful-of-coming-into-contact-with-water,LIFE_ARTS,scifi.stackexchange.com,1.0,0.7777777777777778,0.3333333333333333,1.0,1.0,0.5,0.5555555555555556,0.6666666666666666,0.3333333333333333,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,1.0,Why is the ring ghost afraid of contact with water?,"At least two times in Lotte: Ford, the soul flinches out of the water. The second time (Ford of brunin) can be explained by their fear of some magical traps of elves through the magic of water; but the first time, on the ferry? One of the nazgules jumped on the barge easily, and soon drove away the nasty hobbits.","It is common in folklore for evil or ""unnatural"" creatures to be unable to cross running water. For example, this is a traditional attribute of vampires: http://en.wikipedia.org/wiki/Vampire

Tolkien himself noted that this idea was difficult to sustain for the Ringwraiths. In particular, they would have had to cross the river Greyflood (which had no bridge or ferry) in order to travel from Mordor to the Shire. (I don't have the citation to hand, it may have been in Unfinished Tales.) He seems to have gone ahead with it anyway, in order to emphasise that the Ringwraiths were inhuman, undead creatures. 
"
475,475,739,WKID matching EPSG,"Is there a way to matching the code of ESRI WKID with EPSG code? I'm trying to find the coordinate system of PCS Name = CGRS_1993_LTM. Which has WKID:102319 code. But I donn't know the EPSG code.
",Vassilis,https://gis.stackexchange.com/users/1242,"Up to now, the EPSG database has no CRS for Cyprus. There is an open ticket for it since November 2014 EPSG::2014.091.

The code you mention is from ESRI, and according to http://help.arcgis.com/en/arcims/10.0/mainhelp/mergedProjects/ArcXMLGuide/elements/pcs.htm#102319 the values are:

PROJCS[""CGRS_1993_LTM"",
GEOGCS[""GCS_CGRS_1993"",
DATUM[""D_Cyprus_Geodetic_Reference_System_1993"",
SPHEROID[""WGS_1984"",6378137.0,298.257223563]],
PRIMEM[""Greenwich"",0.0],
UNIT[""Degree"",0.0174532925199433]],
PROJECTION[""Transverse_Mercator""],
PARAMETER[""False_Easting"",200000.0],
PARAMETER[""False_Northing"",-3500000.0],
PARAMETER[""Central_Meridian"",33.0],
PARAMETER[""Scale_Factor"",0.99995],
PARAMETER[""Latitude_Of_Origin"",0.0],
UNIT[""Meter"",1.0]]


These have to get an official acknowledgment to be put into the EPSG database. Until then, you have to use a custom CRS if you are working outside of the ESRI world.

The equivalent Proj.4 string is

+proj=tmerc +lat_0=0 +lon_0=33 +k=0.99995 +x_0=200000 +y_0=-3500000 +ellps=WGS84 +units=m +no_defs.
",AndreJ,https://gis.stackexchange.com/users/9159,http://gis.stackexchange.com/questions/138228/wkid-matching-epsg,TECHNOLOGY,gis.stackexchange.com,0.5555555555555556,0.4444444444444444,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.6666666666666666,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,0.6666666666666666,0.8888888888888888,Wkid matches EPSG,Is there any way to match ESRI wkid code with EPSG code? I am trying to find the coordinate system of PCs name = cgrs_uuuuultm. Where wkid: 102319 code. But I don't know the EPSG code.,"Up to now, the EPSG database has no CRS for Cyprus. There is an open ticket for it since November 2014 EPSG::2014.091.

The code you mention is from ESRI, and according to http://help.arcgis.com/en/arcims/10.0/mainhelp/mergedProjects/ArcXMLGuide/elements/pcs.htm#102319 the values are:

PROJCS[""CGRS_1993_LTM"",
GEOGCS[""GCS_CGRS_1993"",
DATUM[""D_Cyprus_Geodetic_Reference_System_1993"",
SPHEROID[""WGS_1984"",6378137.0,298.257223563]],
PRIMEM[""Greenwich"",0.0],
UNIT[""Degree"",0.0174532925199433]],
PROJECTION[""Transverse_Mercator""],
PARAMETER[""False_Easting"",200000.0],
PARAMETER[""False_Northing"",-3500000.0],
PARAMETER[""Central_Meridian"",33.0],
PARAMETER[""Scale_Factor"",0.99995],
PARAMETER[""Latitude_Of_Origin"",0.0],
UNIT[""Meter"",1.0]]


These have to get an official acknowledgment to be put into the EPSG database. Until then, you have to use a custom CRS if you are working outside of the ESRI world.

The equivalent Proj.4 string is

+proj=tmerc +lat_0=0 +lon_0=33 +k=0.99995 +x_0=200000 +y_0=-3500000 +ellps=WGS84 +units=m +no_defs.
"
2576,2576,4100,"How to prevent the ""Too awesome to use"" syndrome","When you give the player a rare but powerful item which can only be used once but is never really required to proceed, most players will not use it at all, because they are waiting for the perfect moment. But even when this moment comes, they will still be reluctant to use it, because there might be an even better moment later. So they keep hoarding it for a moment which will never come. 

In the end, they will carry the item around until it is outclassed by other, more readily available resources, or even until the very end of the game. That means that such one-shot items don't provide any gameplay-value at all. They are simply too awesome to use.

What can you do to encourage the player to make use of their one-shot items and not hoard them?
",Philipp,https://gamedev.stackexchange.com/users/21890,"Short Answer: 

Have something more valuable than the item that the player can lose if they hesitate to use the item. EG You might use your single-use invincibility potion to save you from death in a game where death is permanent.

Long Answer:

I think the only games in which such an item can work are ones where there is some form of persistent punishment for failure: Things like permadeath, loss of money/exp/stats on death, limited lives before having to restart the game (that's pretty outdated, but whatever). So when the player gets stuck or comes up against a challenge that they are likely to fail, they have an incentive to skip part or all of this challenge using the super item.

You could look at a lot of old arcade shooters, where you where often given about 3 bombs to use per life and could not recover any more. Bombs where valuable, but not as valuable as lives. Players would never use them unless it was necessary, but they wouldn't hesitate if they thought it would prevent them from dying. The same principle can be applied to single-use items, as long as there is something more valuable that the use of such an item can protect.

In a lot of games, failure is not really penalized and therefore there is no reason to use rare resources. There is no reason to use limited resources to prevent the loss of a life when you have infinite lives. I suppose you could add a particular encounter to the game that forces the items use (like the Master Ball in pokemon), but that can fall into guide dang it territory. 

Making the game more difficult is not a solution, as players will not have the item for the vast majority of their playtime. ""If this is hard now, I should save the super-weapon for when it's even worse!""

EDIT: As zzzzBov points out below, you could also make the item itself disappear upon death. Which would certainly make players more likely to use it.
",Lewis Wakeford,https://gamedev.stackexchange.com/users/29308,http://gamedev.stackexchange.com/questions/55558/how-to-prevent-the-too-awesome-to-use-syndrome,TECHNOLOGY,gamedev.stackexchange.com,0.7777777777777778,0.6666666666666666,0.3333333333333333,0.5,0.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,1.0,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,1.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,1.0,"How to prevent ""too good to use"" syndrome","When you give the player a rare but powerful item which can only be used once but is never really required to proceed, most players will not use it at all, because they are waiting for the perfect moment. But even when this moment comes, they will still be reluctant to use it, because there might be an even better moment later. So they keep hoarding it for a moment which will never come. 

In the end, they will carry the item around until it is outclassed by other, more readily available resources, or even until the very end of the game. That means that such one-shot items don't provide any gameplay-value at all. They are simply too awesome to use.

What can you do to encourage the player to make use of their one-shot items and not hoard them?
","Short Answer: 

Have something more valuable than the item that the player can lose if they hesitate to use the item. EG You might use your single-use invincibility potion to save you from death in a game where death is permanent.

Long Answer:

I think the only games in which such an item can work are ones where there is some form of persistent punishment for failure: Things like permadeath, loss of money/exp/stats on death, limited lives before having to restart the game (that's pretty outdated, but whatever). So when the player gets stuck or comes up against a challenge that they are likely to fail, they have an incentive to skip part or all of this challenge using the super item.

You could look at a lot of old arcade shooters, where you where often given about 3 bombs to use per life and could not recover any more. Bombs where valuable, but not as valuable as lives. Players would never use them unless it was necessary, but they wouldn't hesitate if they thought it would prevent them from dying. The same principle can be applied to single-use items, as long as there is something more valuable that the use of such an item can protect.

In a lot of games, failure is not really penalized and therefore there is no reason to use rare resources. There is no reason to use limited resources to prevent the loss of a life when you have infinite lives. I suppose you could add a particular encounter to the game that forces the items use (like the Master Ball in pokemon), but that can fall into guide dang it territory. 

Making the game more difficult is not a solution, as players will not have the item for the vast majority of their playtime. ""If this is hard now, I should save the super-weapon for when it's even worse!""

EDIT: As zzzzBov points out below, you could also make the item itself disappear upon death. Which would certainly make players more likely to use it.
"
5620,5620,8913,How do I change the MySQL database directory?,"I am using CentOS with cPanel. On my server, all MySQL databases save at /var/lib/mysql. Now /var is 100% full and MySQL has stopped working. How can I move the databases to a new directory like /home/mysql especially considering that this server is managed with cPanel?
",user111175,https://serverfault.com/users/111175,"Stopping the Default Install/Instance

service mysqld stop


Clear Current Config

rm /etc/my.cnf


Uninstal the Default Install/Instance

yum remove mysql mysql-server -y


Clear Current Datadir

test -d /var/lib/mysql/ &amp;&amp; rm -rf /var/lib/mysql/


Clear the 'New' Datadir

test -d /mysql/mysql/ &amp;&amp; rm -rf /mysql/mysql/


Install it again

yum install mysql mysql-server -y


Check the service status

service mysqld status


Start it - just to create a first/default structure

service mysqld start


Check the service status

service mysqld status


Interrupt the current MySQL server installation

service mysqld stop


Ensure that you don´t have anymore instance/service running

ps axu | grep mysql


Move the mysql data directory to '/mysql' partition and create the symbolic link

test -d /var/lib/mysql/ &amp;&amp; mv /var/lib/mysql/ /mysql/ &amp;&amp; ln -s /mysql/mysql /var/lib/


Check symbolic link and the real path

ls -lrth /var/lib/ | grep mysql 


Set permission on new Datadir

chown -R mysql:mysql /mysql/mysql


Start it

service mysqld start


Try to connect (keep in mind that the default install of MySQL doesn´t set a 'pwd' for 'root' user and then you should connect with 'blank password'

mysql -u root -p --host 127.0.0.1


Once connected to MySQL, create a new db just to test if it´s working and where MySQL will create folder/file structure

create database DBTesteNew;
exit


Check if the new db is on the 'new datadir'

ls /mysql/mysql


Make sure the mysqld is set to start on boot time 

chkconfig mysqld on


restart

reboot

",Saji,https://serverfault.com/users/246548,http://serverfault.com/questions/363958,TECHNOLOGY,serverfault.com,1.0,0.7777777777777778,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.8888888888888888,0.8888888888888888,0.5555555555555556,1.0,0.8888888888888888,0.8,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.6666666666666666,How to change MySQL database directory?,"I'm using CentOS and cPanel. On my server, all MySQL databases are stored in / var / lib / MySQL. Now / var is 100% full and MySQL has stopped working. How to move the database to a new directory (such as / home / MySQL), especially considering that this server is managed by cPanel?","Stopping the Default Install/Instance

service mysqld stop


Clear Current Config

rm /etc/my.cnf


Uninstal the Default Install/Instance

yum remove mysql mysql-server -y


Clear Current Datadir

test -d /var/lib/mysql/ &amp;&amp; rm -rf /var/lib/mysql/


Clear the 'New' Datadir

test -d /mysql/mysql/ &amp;&amp; rm -rf /mysql/mysql/


Install it again

yum install mysql mysql-server -y


Check the service status

service mysqld status


Start it - just to create a first/default structure

service mysqld start


Check the service status

service mysqld status


Interrupt the current MySQL server installation

service mysqld stop


Ensure that you don´t have anymore instance/service running

ps axu | grep mysql


Move the mysql data directory to '/mysql' partition and create the symbolic link

test -d /var/lib/mysql/ &amp;&amp; mv /var/lib/mysql/ /mysql/ &amp;&amp; ln -s /mysql/mysql /var/lib/


Check symbolic link and the real path

ls -lrth /var/lib/ | grep mysql 


Set permission on new Datadir

chown -R mysql:mysql /mysql/mysql


Start it

service mysqld start


Try to connect (keep in mind that the default install of MySQL doesn´t set a 'pwd' for 'root' user and then you should connect with 'blank password'

mysql -u root -p --host 127.0.0.1


Once connected to MySQL, create a new db just to test if it´s working and where MySQL will create folder/file structure

create database DBTesteNew;
exit


Check if the new db is on the 'new datadir'

ls /mysql/mysql


Make sure the mysqld is set to start on boot time 

chkconfig mysqld on


restart

reboot

"
88,88,145,How are switches for two monitors called? Or can I use a monitor split?,"I have 2 monitors, 1 desktop and 1 laptop. I would like to switch the display between desktop and laptop and want to use 2 monitors as extended monitor sources.
I see  there are lot of solutions to switch between 1 monitor sharing 2 sources but not for 2 monitors.

How about this? I will go with a switch that facilitates 2 sources 1 monitor, but I will attach a split to the switch and connect to the 2 monitors... is that going to work?
",Krishna,https://superuser.com/users/45160,"You have to look for Dual Monitor KVM switches, which should get you what you want.

Don't use the term switch as it is way to broad and will also result in other type of products unrelated to what you are after. KVM stands for Keyboard, Video &amp; Mouse which is a specific property of the switch you are looking for. To denote that a KVM switch supports multiple monitors, use Dual Monitor.

Splitting could also work.
",Tom Wijsman,https://superuser.com/users/9666,http://superuser.com/questions/375145,TECHNOLOGY,superuser.com,1.0,0.7777777777777778,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.3333333333333333,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.6666666666666666,0.0,0.3333333333333333,0.8888888888888888,How to call the switches of two monitors? Or can I use the display split?,"I have 2 monitors, 1 desktop and 1 laptop. I would like to switch the display between desktop and laptop and want to use 2 monitors as extended monitor sources.
I see  there are lot of solutions to switch between 1 monitor sharing 2 sources but not for 2 monitors.

How about this? I will go with a switch that facilitates 2 sources 1 monitor, but I will attach a split to the switch and connect to the 2 monitors... is that going to work?
","You have to look for Dual Monitor KVM switches, which should get you what you want.

Don't use the term switch as it is way to broad and will also result in other type of products unrelated to what you are after. KVM stands for Keyboard, Video &amp; Mouse which is a specific property of the switch you are looking for. To denote that a KVM switch supports multiple monitors, use Dual Monitor.

Splitting could also work.
"
1205,1205,1894,Scipy Fast 1-D interpolation without any loop,"I have two 2D array, x(ni, nj) and y(ni,nj), that I need to interpolate over one axis. I want to interpolate along last axis for every ni.

I wrote

import numpy as np
from scipy.interpolate import interp1d

z = np.asarray([200,300,400,500,600])
out = []
for i in range(ni):
    f = interp1d(x[i,:], y[i,:], kind='linear')
    out.append(f(z))
out = np.asarray(out)


However, I think this method is inefficient and slow due to loop if array size is too large. What is the fastest way to interpolate multi-dimensional array like this? Is there any way to perform linear and cubic interpolation without loop? Thanks.
",Tetsuro,https://stackoverflow.com/users/1979961,"The method you propose does have a python loop, so for large values of ni it is going to get slow. That said, unless you are going to have large ni you shouldn't worry much.

I have created sample input data with the following code:

def sample_data(n_i, n_j, z_shape) :
    x = np.random.rand(n_i, n_j) * 1000
    x.sort()
    x[:,0] = 0
    x[:, -1] = 1000
    y = np.random.rand(n_i, n_j)
    z = np.random.rand(*z_shape) * 1000
    return x, y, z


And have tested them with this two versions of linear interpolation:

def interp_1(x, y, z) :
    rows, cols = x.shape
    out = np.empty((rows,) + z.shape, dtype=y.dtype)
    for j in xrange(rows) :
        out[j] =interp1d(x[j], y[j], kind='linear', copy=False)(z)
    return out

def interp_2(x, y, z) :
    rows, cols = x.shape
    row_idx = np.arange(rows).reshape((rows,) + (1,) * z.ndim)
    col_idx = np.argmax(x.reshape(x.shape + (1,) * z.ndim) &gt; z, axis=1) - 1
    ret = y[row_idx, col_idx + 1] - y[row_idx, col_idx]
    ret /= x[row_idx, col_idx + 1] - x[row_idx, col_idx]
    ret *= z - x[row_idx, col_idx]
    ret += y[row_idx, col_idx]
    return ret


interp_1 is an optimized version of your code, following Dave's answer. interp_2 is a vectorized implementation of linear interpolation that avoids any python loop whatsoever. Coding something like this requires a sound understanding of broadcasting and indexing in numpy, and some things are going to be less optimized than what interp1d does. A prime example being finding the bin in which to interpolate a value: interp1d will surely break out of loops early once it finds the bin, the above function is comparing the value to all bins.

So the result is going to be very dependent on what n_i and n_j are, and even how long your array z of values to interpolate is. If n_j is small and n_i is large, you should expect an advantage from interp_2, and from interp_1 if it is the other way around. Smaller z should be an advantage to interp_2, longer ones to interp_1.

I have actually timed both approaches with a variety of n_i and n_j, for z of shape (5,) and (50,), here are the graphs:





So it seems that for z of shape (5,) you should go with interp_2 whenever n_j &lt; 1000, and with interp_1 elsewhere. Not surprisingly, the threshold is different for z of shape (50,), now being around n_j &lt; 100. It seems tempting to conclude that you should stick with your code if n_j * len(z) &gt; 5000, but change it to something like interp_2 above if not, but there is a great deal of extrapolating in that statement! If you want to further experiment yourself, here's the code I used to produce the graphs.

n_s = np.logspace(1, 3.3, 25)
int_1 = np.empty((len(n_s),) * 2)
int_2 = np.empty((len(n_s),) * 2)
z_shape = (5,)

for i, n_i in enumerate(n_s) :
    print int(n_i)
    for j, n_j in enumerate(n_s) :
        x, y, z = sample_data(int(n_i), int(n_j), z_shape)
        int_1[i, j] = min(timeit.repeat('interp_1(x, y, z)',
                                        'from __main__ import interp_1, x, y, z',
                                        repeat=10, number=1))
        int_2[i, j] = min(timeit.repeat('interp_2(x, y, z)',
                                        'from __main__ import interp_2, x, y, z',
                                        repeat=10, number=1))

cs = plt.contour(n_s, n_s, np.transpose(int_1-int_2))
plt.clabel(cs, inline=1, fontsize=10)
plt.xlabel('n_i')
plt.ylabel('n_j')
plt.title('timeit(interp_2) - timeit(interp_1), z.shape=' + str(z_shape))
plt.show()

",Jaime,https://stackoverflow.com/users/110026,http://stackoverflow.com/questions/14559687/scipy-fast-1-d-interpolation-without-any-loop,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.3333333333333333,0.0,0.6666666666666666,1.0,1.0,0.5555555555555556,0.5555555555555556,1.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.6666666666666666,1.0,0.8,1.0,0.3333333333333333,0.0,1.0,SciPy fast one-dimensional interpolation without any loop,"I have two 2D array, x(ni, nj) and y(ni,nj), that I need to interpolate over one axis. I want to interpolate along last axis for every ni.

I wrote

import numpy as np
from scipy.interpolate import interp1d

z = np.asarray([200,300,400,500,600])
out = []
for i in range(ni):
    f = interp1d(x[i,:], y[i,:], kind='linear')
    out.append(f(z))
out = np.asarray(out)


However, I think this method is inefficient and slow due to loop if array size is too large. What is the fastest way to interpolate multi-dimensional array like this? Is there any way to perform linear and cubic interpolation without loop? Thanks.
","The method you propose does have a python loop, so for large values of ni it is going to get slow. That said, unless you are going to have large ni you shouldn't worry much.

I have created sample input data with the following code:

def sample_data(n_i, n_j, z_shape) :
    x = np.random.rand(n_i, n_j) * 1000
    x.sort()
    x[:,0] = 0
    x[:, -1] = 1000
    y = np.random.rand(n_i, n_j)
    z = np.random.rand(*z_shape) * 1000
    return x, y, z


And have tested them with this two versions of linear interpolation:

def interp_1(x, y, z) :
    rows, cols = x.shape
    out = np.empty((rows,) + z.shape, dtype=y.dtype)
    for j in xrange(rows) :
        out[j] =interp1d(x[j], y[j], kind='linear', copy=False)(z)
    return out

def interp_2(x, y, z) :
    rows, cols = x.shape
    row_idx = np.arange(rows).reshape((rows,) + (1,) * z.ndim)
    col_idx = np.argmax(x.reshape(x.shape + (1,) * z.ndim) &gt; z, axis=1) - 1
    ret = y[row_idx, col_idx + 1] - y[row_idx, col_idx]
    ret /= x[row_idx, col_idx + 1] - x[row_idx, col_idx]
    ret *= z - x[row_idx, col_idx]
    ret += y[row_idx, col_idx]
    return ret


interp_1 is an optimized version of your code, following Dave's answer. interp_2 is a vectorized implementation of linear interpolation that avoids any python loop whatsoever. Coding something like this requires a sound understanding of broadcasting and indexing in numpy, and some things are going to be less optimized than what interp1d does. A prime example being finding the bin in which to interpolate a value: interp1d will surely break out of loops early once it finds the bin, the above function is comparing the value to all bins.

So the result is going to be very dependent on what n_i and n_j are, and even how long your array z of values to interpolate is. If n_j is small and n_i is large, you should expect an advantage from interp_2, and from interp_1 if it is the other way around. Smaller z should be an advantage to interp_2, longer ones to interp_1.

I have actually timed both approaches with a variety of n_i and n_j, for z of shape (5,) and (50,), here are the graphs:





So it seems that for z of shape (5,) you should go with interp_2 whenever n_j &lt; 1000, and with interp_1 elsewhere. Not surprisingly, the threshold is different for z of shape (50,), now being around n_j &lt; 100. It seems tempting to conclude that you should stick with your code if n_j * len(z) &gt; 5000, but change it to something like interp_2 above if not, but there is a great deal of extrapolating in that statement! If you want to further experiment yourself, here's the code I used to produce the graphs.

n_s = np.logspace(1, 3.3, 25)
int_1 = np.empty((len(n_s),) * 2)
int_2 = np.empty((len(n_s),) * 2)
z_shape = (5,)

for i, n_i in enumerate(n_s) :
    print int(n_i)
    for j, n_j in enumerate(n_s) :
        x, y, z = sample_data(int(n_i), int(n_j), z_shape)
        int_1[i, j] = min(timeit.repeat('interp_1(x, y, z)',
                                        'from __main__ import interp_1, x, y, z',
                                        repeat=10, number=1))
        int_2[i, j] = min(timeit.repeat('interp_2(x, y, z)',
                                        'from __main__ import interp_2, x, y, z',
                                        repeat=10, number=1))

cs = plt.contour(n_s, n_s, np.transpose(int_1-int_2))
plt.clabel(cs, inline=1, fontsize=10)
plt.xlabel('n_i')
plt.ylabel('n_j')
plt.title('timeit(interp_2) - timeit(interp_1), z.shape=' + str(z_shape))
plt.show()

"
134,134,214,k-center algorithm in one-dimensional space,"I'm aware of the general k-center approximation algorithm, but my professor (this is a question from a CS class) says that in a one-dimensional space, the problem can be solved (optimal solution found, not an approximation) in O(n^2) polynomial time without depending on k or using dynamic programming.

A general description of the k-center problem: Given a set of nodes in an n-dimensional space, cluster them into k clusters such that the ""radius"" of each cluster (distance from furthest node to its center node) is minimized. A more formal and detailed description can be found at http://en.wikipedia.org/wiki/Metric_k-center

As you might expect, I can't figure out how this is possible. The part currently causing me problems is how the runtime can not rely on k.

The nature of the problem causes me to try to step through the nodes on a sort of number line and try to find points to put boundaries, marking off the edges of each cluster that way. But this would require a runtime based on k.

The O(n^2) runtime though makes me think it might involve filling out an nxn array with the distance between two nodes in each entry.

Any explanation on how this is works or tips on how to figure it out would be very helpful.
",philv,https://cs.stackexchange.com/users/22958,"First,


  There exist optimal solutions in which each cluster consists of a contiguous sequence of points in the real line.


Any other optimal solutions can be transformed into the cases above. In the following, we focus on the optimal solutions of the kind above.



The complexity of the following ""dynamic programming"" algorithm is $O(n^2 k) = O(n^3)$.

The case for $k=1$ is easy. Denote the optimal solution to $k=1$ in $n$ points by $R_{n,1}$.

Let $R(n,k)$ be the optimal solution for the problem of $k$-center in the first $n$ points. For convenience, define $R(n,k) = 0$ if $k \ge n$ (This is reasonable because we can choose each point as the center of the cluster consisting of only itself).

For general $k &gt; 1$, we consider all the cases according to the number (denoted $m$) of points that are assigned to the last cluster (that is, the last cluster contains a contiguous sequence of the rightmost $m$ points).

$$R(n,k) = \min_{0 \le m \le n} \{ R(n-m, k-1) + R_{m,1} \}$$

The complexity of the ""dynamic programming"" algorithm is $O(n^2 k) = O(n^3)$.



Note: This paper [1] gives an $O(n \log n)$ time algorithm.



[1] Efficient Algorithms for the One-Dimensional $k$-Center Problem. arXiv, 2014.
",hengxin,https://cs.stackexchange.com/users/4911,http://cs.stackexchange.com/questions/32218/k-center-algorithm-in-one-dimensional-space,SCIENCE,cs.stackexchange.com,0.6666666666666666,0.4444444444444444,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,1.0,0.0,0.5555555555555556,1.0,0.7777777777777778,1.0,1.0,0.8666666666666666,0.3333333333333333,0.3333333333333333,1.0,0.8888888888888888,K-center algorithm in one dimensional space,"I'm aware of the general k-center approximation algorithm, but my professor (this is a question from a CS class) says that in a one-dimensional space, the problem can be solved (optimal solution found, not an approximation) in O(n^2) polynomial time without depending on k or using dynamic programming.

A general description of the k-center problem: Given a set of nodes in an n-dimensional space, cluster them into k clusters such that the ""radius"" of each cluster (distance from furthest node to its center node) is minimized. A more formal and detailed description can be found at http://en.wikipedia.org/wiki/Metric_k-center

As you might expect, I can't figure out how this is possible. The part currently causing me problems is how the runtime can not rely on k.

The nature of the problem causes me to try to step through the nodes on a sort of number line and try to find points to put boundaries, marking off the edges of each cluster that way. But this would require a runtime based on k.

The O(n^2) runtime though makes me think it might involve filling out an nxn array with the distance between two nodes in each entry.

Any explanation on how this is works or tips on how to figure it out would be very helpful.
","First,


  There exist optimal solutions in which each cluster consists of a contiguous sequence of points in the real line.


Any other optimal solutions can be transformed into the cases above. In the following, we focus on the optimal solutions of the kind above.



The complexity of the following ""dynamic programming"" algorithm is $O(n^2 k) = O(n^3)$.

The case for $k=1$ is easy. Denote the optimal solution to $k=1$ in $n$ points by $R_{n,1}$.

Let $R(n,k)$ be the optimal solution for the problem of $k$-center in the first $n$ points. For convenience, define $R(n,k) = 0$ if $k \ge n$ (This is reasonable because we can choose each point as the center of the cluster consisting of only itself).

For general $k &gt; 1$, we consider all the cases according to the number (denoted $m$) of points that are assigned to the last cluster (that is, the last cluster contains a contiguous sequence of the rightmost $m$ points).

$$R(n,k) = \min_{0 \le m \le n} \{ R(n-m, k-1) + R_{m,1} \}$$

The complexity of the ""dynamic programming"" algorithm is $O(n^2 k) = O(n^3)$.



Note: This paper [1] gives an $O(n \log n)$ time algorithm.



[1] Efficient Algorithms for the One-Dimensional $k$-Center Problem. arXiv, 2014.
"
5198,5198,8256,"Variations in the pronunciation of ""the""","Although there are rather simple rules determining the pronunciation of ""the"", native speakers quite often deviate from these rules (including, e.g., TV shows). According to the Longman Pronunciation Dictionary,


  The EFL learner is advised to use [ðə] before a consonant sound (the
  boy, the house), [ði] before a vowel sound (the egg, the hour). Native
  speakers, however, sometimes ignore this distribution, in particular
  by using [ðə] before a vowel (which is in turn usually reinforced by a
  preceding ʔ), or by using [ði:] in any
  environment, though especially before a hesitation pause. Furthermore,
  some speakers use stressed [ðə] as a strong form, rather than the
  usual [ði:].


My question is: when native speakers use [ðə] instead of [ði] before a vowel sound, do they do it on purpose or accidentally? If it is on purpose, how do they (typically) decide which pronunciation to use? What is a valid reason to use [ðə] before a vowel sound?
",painfulenglish,https://english.stackexchange.com/users/71165,"For rather a lot of English there are ""rather simple rules"" that are flat out wrong (the order of the letters ""i"" and ""e"" when together is my favorite example). You just have to memorize them.

In the case of ""The"", it is often pronounced with the long E sound for emphasis, which means that the same phrase might use a different pronunciation depending on the point the speaker wants to get across. The point of emphasis is often if the speaker wants to draw attention to the fact that it is somehow unique. 

For example there's ""The Ohio State University"". If someone is just rattling off its official name, typically you'd hear the softer sound. However, many people are kind of annoyed at how insistent they are about the ""The"" at the front of the name (most US universities don't do that), so I often hear it pronounced with the harsher long E sound (and the entire word ""The"" louder than the rest of the name).
",T.E.D.,https://english.stackexchange.com/users/9186,http://english.stackexchange.com/questions/191979/variations-in-the-pronunciation-of-the,CULTURE,english.stackexchange.com,1.0,0.4444444444444444,0.3333333333333333,1.0,0.6666666666666666,1.0,0.5555555555555556,0.8888888888888888,1.0,0.0,1.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,1.0,0.0,1.0,1.0,0.6666666666666666,0.8888888888888888,1.0,0.9333333333333332,0.0,0.3333333333333333,1.0,1.0,"The pronunciation change of ""the""","Although there are rather simple rules determining the pronunciation of ""the"", native speakers quite often deviate from these rules (including, e.g., TV shows). According to the Longman Pronunciation Dictionary,


  The EFL learner is advised to use [ðə] before a consonant sound (the
  boy, the house), [ði] before a vowel sound (the egg, the hour). Native
  speakers, however, sometimes ignore this distribution, in particular
  by using [ðə] before a vowel (which is in turn usually reinforced by a
  preceding ʔ), or by using [ði:] in any
  environment, though especially before a hesitation pause. Furthermore,
  some speakers use stressed [ðə] as a strong form, rather than the
  usual [ði:].


My question is: when native speakers use [ðə] instead of [ði] before a vowel sound, do they do it on purpose or accidentally? If it is on purpose, how do they (typically) decide which pronunciation to use? What is a valid reason to use [ðə] before a vowel sound?
","For rather a lot of English there are ""rather simple rules"" that are flat out wrong (the order of the letters ""i"" and ""e"" when together is my favorite example). You just have to memorize them.

In the case of ""The"", it is often pronounced with the long E sound for emphasis, which means that the same phrase might use a different pronunciation depending on the point the speaker wants to get across. The point of emphasis is often if the speaker wants to draw attention to the fact that it is somehow unique. 

For example there's ""The Ohio State University"". If someone is just rattling off its official name, typically you'd hear the softer sound. However, many people are kind of annoyed at how insistent they are about the ""The"" at the front of the name (most US universities don't do that), so I often hear it pronounced with the harsher long E sound (and the entire word ""The"" louder than the rest of the name).
"
94,94,155,Detect user device and assign different jquery (desktop / mobile(ipad)) in js/ jquery?,"&lt;script src=""jsv3/jquery.js""&gt;&lt;/script&gt;
&lt;!--&lt;script src=""jsv3/jquery.mobile-1.2.0.min.js""&gt;&lt;/script&gt;--&gt;


Currently I have insert script for desktop version only because I found that declare two jquery will occur error. Are there any way to check the device type and select different jquery plugin for corresponding device? Thanks 
",Leo Chan,https://stackoverflow.com/users/1280996,"There are many ways to detect the client. Following example involves userAgent to detect the type of client device.

 $(document).ready(function(e) {

        if(navigator.userAgent.match(/Android/i)
             || navigator.userAgent.match(/webOS/i)
             || navigator.userAgent.match(/iPhone/i)
             || navigator.userAgent.match(/iPad/i)
             || navigator.userAgent.match(/iPod/i)
             || navigator.userAgent.match(/BlackBerry/i)
             || navigator.userAgent.match(/Windows Phone/i)) {


          var file=document.createElement(""link"");
          file.setAttribute(""rel"", ""stylesheet"");
          file.setAttribute(""type"", ""text/css"");
          file.setAttribute(""href"", ""css/alternate_css_file.css"");
          document.getElementsByTagName(""head"")[0].appendChild(file);

          var file_2= document.createElement(""script"");
          file_2.setAttribute(""type"", ""text/javascript"");
          file_2.setAttribute(""src"", ""js/alternate_js_file.js"");
          document.getElementsByTagName(""head"")[0].appendChild(file_2);

    }

    });


This is a general solution for detecting client devices. You may have to use different CSS for tablets clients like iPad.
",sohel khalifa,https://stackoverflow.com/users/1168493,http://stackoverflow.com/questions/13876411/detect-user-device-and-assign-different-jquery-desktop-mobileipad-in-js-j,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.6666666666666666,0.0,0.3333333333333333,1.0,0.6666666666666666,0.6666666666666666,0.4444444444444444,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.3333333333333333,0.3333333333333333,0.8888888888888888,Detect user devices in JS / jQuery and assign different jQuery (desktop / mobile device (iPad))?,"&lt;script src=""jsv3/jquery.js""&gt;&lt;/script&gt;
&lt;!--&lt;script src=""jsv3/jquery.mobile-1.2.0.min.js""&gt;&lt;/script&gt;--&gt;


Currently I have insert script for desktop version only because I found that declare two jquery will occur error. Are there any way to check the device type and select different jquery plugin for corresponding device? Thanks 
","There are many ways to detect the client. Following example involves userAgent to detect the type of client device.

 $(document).ready(function(e) {

        if(navigator.userAgent.match(/Android/i)
             || navigator.userAgent.match(/webOS/i)
             || navigator.userAgent.match(/iPhone/i)
             || navigator.userAgent.match(/iPad/i)
             || navigator.userAgent.match(/iPod/i)
             || navigator.userAgent.match(/BlackBerry/i)
             || navigator.userAgent.match(/Windows Phone/i)) {


          var file=document.createElement(""link"");
          file.setAttribute(""rel"", ""stylesheet"");
          file.setAttribute(""type"", ""text/css"");
          file.setAttribute(""href"", ""css/alternate_css_file.css"");
          document.getElementsByTagName(""head"")[0].appendChild(file);

          var file_2= document.createElement(""script"");
          file_2.setAttribute(""type"", ""text/javascript"");
          file_2.setAttribute(""src"", ""js/alternate_js_file.js"");
          document.getElementsByTagName(""head"")[0].appendChild(file_2);

    }

    });


This is a general solution for detecting client devices. You may have to use different CSS for tablets clients like iPad.
"
5591,5591,8877,Why do I get the wrong result from this program to compute gross pay?,"This is actually a homework. Here is the question.


  Write a program to prompt the user for hours and rate per hour using raw_input to compute gross pay. Pay the hourly rate for the hours up to 40 and 1.5 times the hourly rate for all hours worked above 40 hours. Use 45 hours and a rate of 10.50 per hour to test the program (the pay should be 498.75). You should use raw_input to read a string and float() to convert the string to a number. Do not worry about error checking the user input - assume the user types numbers properly.


I've tried this, but it doesn't work correctly.

hrs = raw_input(""Enter Hours:"")
h = float(hrs)
rate_hour = raw_input(""Enter rate:"")
r = float(rate_hour)
if h &lt;= 40:
    r = 1
else :
    r = 1.5
print h * r 

",coder123,https://stackoverflow.com/users/4776843,"There are a few problems with the way you've approached this.


The question specifies that the rate of pay only increases after 40 hours are worked, and so if 45 hours are worked, only 5 of those hours earn the overtime rate.

Look at the way you have written your if statement, and you should be able to see an incongruence between your code and the question. In particular, you'll need to look at the else: section.
When calculating pay using the standard or overtime rate, remember that the new rate will be a function of the old one. You should be able to see in your code that setting r = 1 or r = 1.5 will cause a problem. Assuming 10 hours have been worked, your code will produce 10 * 1 instead of 10 * rate_hour


To help you:


To modify a variable number such that it is doubled, variable = variable * 2
Calculating pay when more than 40 hours are worked will require 2 separate calculations, so you may want to create a variable pay under if: and else:, and then print that.

",Simon Horgan,https://stackoverflow.com/users/5038607,http://stackoverflow.com/questions/30993708/why-do-i-get-the-wrong-result-from-this-program-to-compute-gross-pay,STACKOVERFLOW,stackoverflow.com,1.0,0.3333333333333333,0.0,0.6666666666666666,1.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,0.6666666666666666,0.0,0.3333333333333333,1.0,Why do I get the wrong result from this program to calculate the payroll?,"This is actually a homework. Here is the question.


  Write a program to prompt the user for hours and rate per hour using raw_input to compute gross pay. Pay the hourly rate for the hours up to 40 and 1.5 times the hourly rate for all hours worked above 40 hours. Use 45 hours and a rate of 10.50 per hour to test the program (the pay should be 498.75). You should use raw_input to read a string and float() to convert the string to a number. Do not worry about error checking the user input - assume the user types numbers properly.


I've tried this, but it doesn't work correctly.

hrs = raw_input(""Enter Hours:"")
h = float(hrs)
rate_hour = raw_input(""Enter rate:"")
r = float(rate_hour)
if h &lt;= 40:
    r = 1
else :
    r = 1.5
print h * r 

","There are a few problems with the way you've approached this.


The question specifies that the rate of pay only increases after 40 hours are worked, and so if 45 hours are worked, only 5 of those hours earn the overtime rate.

Look at the way you have written your if statement, and you should be able to see an incongruence between your code and the question. In particular, you'll need to look at the else: section.
When calculating pay using the standard or overtime rate, remember that the new rate will be a function of the old one. You should be able to see in your code that setting r = 1 or r = 1.5 will cause a problem. Assuming 10 hours have been worked, your code will produce 10 * 1 instead of 10 * rate_hour


To help you:


To modify a variable number such that it is doubled, variable = variable * 2
Calculating pay when more than 40 hours are worked will require 2 separate calculations, so you may want to create a variable pay under if: and else:, and then print that.

"
2007,2007,3202,Administer block permission let the user to see admin theme name,"I gave the site admin role permission to administer blocks, but the problem is in admin/structure/block page, there is a tab that shows the admin theme name (Rubik).

he can click on Rubik but doesn't have permission to see the page.
what I want is to hide the tab.

other issue is in admin_menu module under structure > blocks there is a Rubik item too, which shouldn't be there too since the user doesn't have the permission to edit admin theme blocks.

So I'm wondering why does rubik block page link shows up!
",Sohail,https://drupal.stackexchange.com/users/6362,"In theory, you could write a module that uses hook_menu_alter(). It would modify the access callback element in the ""admin theme"" menu item (and maybe sub-menu items?). The callback function would check user_access('administer themes'). You could probably write this in 30 minutes or less.

That would cover both cases -- the block admin page and the admin menu.
",hargobind,https://drupal.stackexchange.com/users/11947,http://drupal.stackexchange.com/questions/79408/administer-block-permission-let-the-user-to-see-admin-theme-name,TECHNOLOGY,drupal.stackexchange.com,0.7777777777777778,0.4444444444444444,0.0,0.0,1.0,1.0,1.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.3333333333333333,0.0,0.6666666666666666,0.7777777777777778,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,1.0,Management block permission allows users to view management topic names,"I gave the site admin role permission to administer blocks, but the problem is in admin/structure/block page, there is a tab that shows the admin theme name (Rubik).

he can click on Rubik but doesn't have permission to see the page.
what I want is to hide the tab.

other issue is in admin_menu module under structure > blocks there is a Rubik item too, which shouldn't be there too since the user doesn't have the permission to edit admin theme blocks.

So I'm wondering why does rubik block page link shows up!
","In theory, you could write a module that uses hook_menu_alter(). It would modify the access callback element in the ""admin theme"" menu item (and maybe sub-menu items?). The callback function would check user_access('administer themes'). You could probably write this in 30 minutes or less.

That would cover both cases -- the block admin page and the admin menu.
"
2684,2684,4280,Verify guest order and set guest order state,"I'm trying to implement an order confirmation module for guest accounts. I researched now for a couple hours but it seems that I can't find any solution to my problem.

I need to verify if the email of a guest customer is actually valid. After the order is placed I observe the sales_order_place_after event and try to set the guest order to holded or a custom one like unconfirmed. Either way the state change gets overwritten by Magento.
After that I want to send an email with a verification link. And then change the state back to pending. I think I can overwrite the basic email template for a new guest order. Is this correct?

How can I set guest orders to a different state than the default ""pending""?

Thank you all very much in advance!
",user5668,https://magento.stackexchange.com/users/5668,"Just observe the sales_order_save_before event, find a correct condition (this is important) how to determine, you change the status for the correct orders (not every time, an order is saved) and set the status
",Fabian Blechschmidt,https://magento.stackexchange.com/users/217,http://magento.stackexchange.com/questions/16686/verify-guest-order-and-set-guest-order-state,TECHNOLOGY,magento.stackexchange.com,0.7777777777777778,0.4444444444444444,0.0,0.5,1.0,1.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9,1.0,0.0,0.3333333333333333,0.8888888888888888,Verify guest order and set guest order status,"I'm trying to implement an order confirmation module for guest accounts. I researched now for a couple hours but it seems that I can't find any solution to my problem.

I need to verify if the email of a guest customer is actually valid. After the order is placed I observe the sales_order_place_after event and try to set the guest order to holded or a custom one like unconfirmed. Either way the state change gets overwritten by Magento.
After that I want to send an email with a verification link. And then change the state back to pending. I think I can overwrite the basic email template for a new guest order. Is this correct?

How can I set guest orders to a different state than the default ""pending""?

Thank you all very much in advance!
","Just observe the sales_order_save_before event, find a correct condition (this is important) how to determine, you change the status for the correct orders (not every time, an order is saved) and set the status
"
161,161,254,Preventing Superscript from being interpreted as Power when using Ctrl+^ shortcut?,"I have very strong desire to use superscript as the index of the variable.

However, it looks like that the Mathematica automatically recognize the superscript as the power and I got message that my variable with superscript is 'protected'.

Could you help me to make the superscript used as the index of the variable instead of power?

UPDATE (16-June-2015):

This question is being reopened and a bounty is being awarded on this. Previous answers are very good, however the bounty is to be awarded on an answer which solve this specific problem: 


  How to change the behaviour of Ctrl+^ keybinding so that it produces Superscript instead of Power.

",Donggyu Jang,https://mathematica.stackexchange.com/users/9887,"When I asked people about this before, they wrote up: Displaying index as subscript on output: e.g. C[i] -&gt; C_i with Notation[...] or Interpretation[..]?  As with the other answers, this focuses on only output.  But uses an Interpretation instead of just changing the functions themselves.  You should just be able to copy/paste the code to try it out.  To change from subscripts to superscripts for your code, it should just be a copy/replace.

As for why you shouldn't use subscripts/superscripts, it took me a while to figure it out, but basically it is because $x_i$ is not a symbol.  Try to call FullForm on $x_i$ to get Subscript[x,i] which is tough to work with.
",jlperla,https://mathematica.stackexchange.com/users/9151,http://mathematica.stackexchange.com/questions/33672/preventing-superscript-from-being-interpreted-as-power-when-using-ctrl-shortcu,TECHNOLOGY,mathematica.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,0.5,1.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.7777777777777778,0.7777777777777778,0.4444444444444444,1.0,0.7777777777777778,0.9333333333333332,1.0,0.0,1.0,0.8888888888888888,Prevent superscripts from being interpreted as power when using the CTRL + ^shortcut?,"I have very strong desire to use superscript as the index of the variable.

However, it looks like that the Mathematica automatically recognize the superscript as the power and I got message that my variable with superscript is 'protected'.

Could you help me to make the superscript used as the index of the variable instead of power?

UPDATE (16-June-2015):

This question is being reopened and a bounty is being awarded on this. Previous answers are very good, however the bounty is to be awarded on an answer which solve this specific problem: 


  How to change the behaviour of Ctrl+^ keybinding so that it produces Superscript instead of Power.

","I asked people this question before, they wrote: Show index as subscript in output: for example, C [i] - & gt; c_i, signed [ ]Or interpretation [ ]? As with other answers, this only focuses on output. But use an explanation, not just the function itself. You should be able to copy / paste code to try. To change the subscript of the code to superscript, it should be just a copy / replacement."
3265,3265,5203,Preventing Superscript from being interpreted as Power when using Ctrl+^ shortcut?,"I have very strong desire to use superscript as the index of the variable.

However, it looks like that the Mathematica automatically recognize the superscript as the power and I got message that my variable with superscript is 'protected'.

Could you help me to make the superscript used as the index of the variable instead of power?

UPDATE (16-June-2015):

This question is being reopened and a bounty is being awarded on this. Previous answers are very good, however the bounty is to be awarded on an answer which solve this specific problem: 


  How to change the behaviour of Ctrl+^ keybinding so that it produces Superscript instead of Power.

",Donggyu Jang,https://mathematica.stackexchange.com/users/9887,"Superscript is not interpreted as Power:



Presumably you are referring to what happens when you enter a power in superscript notation using the key combination Ctrl+6.  Mathematica is capable of representing both this power notation and a formatted plain Superscript.  In my opinion it is a failing that the power notation appears in the Typesetting menu while the latter is missing; if anything it should be the other way around I think.  Since there is no key combination for raw Superscript I propose using a palette or input alias:

Palette

You may enter a formatting template using a palette button which may be created with:

CreatePalette @ PasteButton @ Superscript[\[SelectionPlaceholder], \[Placeholder]]




Click that palette button to insert a template for plain superscript in the current Notebook.  Use Tab to move between fields.

Input alias

Either open the Option Inspector, select Global Preferences, type ""InputAliases"" to find the appropriate entry, and add this to the list of rules:

""sps"" -&gt; TemplateBox[{""\[SelectionPlaceholder]"", ""\[Placeholder]""}, ""Superscript""]


Or add it programmatically (run this only once):

AppendTo[
 CurrentValue[$FrontEnd, ""InputAliases""],
 ""sps"" -&gt; TemplateBox[{""\[SelectionPlaceholder]"", ""\[Placeholder]""}, ""Superscript""]
]


Now type: EscspsEsc to enter a template for plain Superscript.

(In version 10.0.0 the first field will not be automatically selected due to a bug; see Input Aliases in Mathematica 10.)



Bounty

A bounty was added for:


  [A] solution to map the Ctrl+^ keybinding to produce superscript instead of power.


To accomplish this first copy MenuSetup.tr from the installation directory to the matching path in your user directory and open the user copy for editing:

os = $OperatingSystem /. ""Unix"" -&gt; ""X"";

CopyFile @@ (
  FileNameJoin[{#, ""SystemFiles"", ""FrontEnd"", ""TextResources"", os, ""MenuSetup.tr""}] &amp; /@
    {$InstallationDirectory, $UserBaseDirectory})

% // SystemOpen


Then within the user copy edit the appropriate MenuItem to read:

MenuItem[""&amp;Superscript"", 
 FrontEndExecute[{
   FrontEnd`SelectionMove[FrontEnd`InputNotebook[], All, Word], 
   FrontEnd`NotebookApply[FrontEnd`InputNotebook[], 
    TemplateBox[{""\[SelectionPlaceholder]"", ""\[Placeholder]""}, ""Superscript""], 
    Placeholder]
 }],
 MenuKey[""6"", Modifiers -&gt; {""Control""}]
]


Restart Mathematica.

You may now enter raw Superscript by using Ctrl+6 where 6 is the number-line six above the alphabetic keyboard.

You can still enter Power notation by using Ctrl+Shift+6 or Ctrl+Keypad-6, the latter assuming that Num Lock is on.



For those you prefer the reverse behavior you can instead copy and edit KeyEventTranslations.tr and change the Item:

Item[KeyEvent[""^"", Modifiers -&gt; {Control}], ""Superscript""]


to:

Item[KeyEvent[""^"", Modifiers -&gt; {Control}], 
  FrontEndExecute[{
     FrontEnd`SelectionMove[FrontEnd`InputNotebook[], All, Word], 
     FrontEnd`NotebookApply[FrontEnd`InputNotebook[], 
      TemplateBox[{""\[SelectionPlaceholder]"", ""\[Placeholder]""}, ""Superscript""], 
      Placeholder]
  }]
]


Now Ctrl+6 is Power and Ctrl+Shift+6 is raw Superscript.  However the Typesetting menu item remains misleadingly named Superscript so I would personally change that to Power if adopting this binding.

Also see:


Can I modify Ctrl-- to insert Indexed expressions?

",Mr.Wizard,https://mathematica.stackexchange.com/users/121,http://mathematica.stackexchange.com/questions/33672/preventing-superscript-from-being-interpreted-as-power-when-using-ctrl-shortcu,TECHNOLOGY,mathematica.stackexchange.com,0.6666666666666666,0.3333333333333333,0.0,0.0,1.0,1.0,1.0,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,0.0,1.0,Prevent superscripts from being interpreted as power when using the CTRL + ^shortcut?,"I have very strong desire to use superscript as the index of the variable.

However, it looks like that the Mathematica automatically recognize the superscript as the power and I got message that my variable with superscript is 'protected'.

Could you help me to make the superscript used as the index of the variable instead of power?

UPDATE (16-June-2015):

This question is being reopened and a bounty is being awarded on this. Previous answers are very good, however the bounty is to be awarded on an answer which solve this specific problem: 


  How to change the behaviour of Ctrl+^ keybinding so that it produces Superscript instead of Power.

","Superscript is not interpreted as Power:



Presumably you are referring to what happens when you enter a power in superscript notation using the key combination Ctrl+6.  Mathematica is capable of representing both this power notation and a formatted plain Superscript.  In my opinion it is a failing that the power notation appears in the Typesetting menu while the latter is missing; if anything it should be the other way around I think.  Since there is no key combination for raw Superscript I propose using a palette or input alias:

Palette

You may enter a formatting template using a palette button which may be created with:

CreatePalette @ PasteButton @ Superscript[\[SelectionPlaceholder], \[Placeholder]]




Click that palette button to insert a template for plain superscript in the current Notebook.  Use Tab to move between fields.

Input alias

Either open the Option Inspector, select Global Preferences, type ""InputAliases"" to find the appropriate entry, and add this to the list of rules:

""sps"" -&gt; TemplateBox[{""\[SelectionPlaceholder]"", ""\[Placeholder]""}, ""Superscript""]


Or add it programmatically (run this only once):

AppendTo[
 CurrentValue[$FrontEnd, ""InputAliases""],
 ""sps"" -&gt; TemplateBox[{""\[SelectionPlaceholder]"", ""\[Placeholder]""}, ""Superscript""]
]


Now type: EscspsEsc to enter a template for plain Superscript.

(In version 10.0.0 the first field will not be automatically selected due to a bug; see Input Aliases in Mathematica 10.)



Bounty

A bounty was added for:


  [A] solution to map the Ctrl+^ keybinding to produce superscript instead of power.


To accomplish this first copy MenuSetup.tr from the installation directory to the matching path in your user directory and open the user copy for editing:

os = $OperatingSystem /. ""Unix"" -&gt; ""X"";

CopyFile @@ (
  FileNameJoin[{#, ""SystemFiles"", ""FrontEnd"", ""TextResources"", os, ""MenuSetup.tr""}] &amp; /@
    {$InstallationDirectory, $UserBaseDirectory})

% // SystemOpen


Then within the user copy edit the appropriate MenuItem to read:

MenuItem[""&amp;Superscript"", 
 FrontEndExecute[{
   FrontEnd`SelectionMove[FrontEnd`InputNotebook[], All, Word], 
   FrontEnd`NotebookApply[FrontEnd`InputNotebook[], 
    TemplateBox[{""\[SelectionPlaceholder]"", ""\[Placeholder]""}, ""Superscript""], 
    Placeholder]
 }],
 MenuKey[""6"", Modifiers -&gt; {""Control""}]
]


Restart Mathematica.

You may now enter raw Superscript by using Ctrl+6 where 6 is the number-line six above the alphabetic keyboard.

You can still enter Power notation by using Ctrl+Shift+6 or Ctrl+Keypad-6, the latter assuming that Num Lock is on.



For those you prefer the reverse behavior you can instead copy and edit KeyEventTranslations.tr and change the Item:

Item[KeyEvent[""^"", Modifiers -&gt; {Control}], ""Superscript""]


to:

Item[KeyEvent[""^"", Modifiers -&gt; {Control}], 
  FrontEndExecute[{
     FrontEnd`SelectionMove[FrontEnd`InputNotebook[], All, Word], 
     FrontEnd`NotebookApply[FrontEnd`InputNotebook[], 
      TemplateBox[{""\[SelectionPlaceholder]"", ""\[Placeholder]""}, ""Superscript""], 
      Placeholder]
  }]
]


Now Ctrl+6 is Power and Ctrl+Shift+6 is raw Superscript.  However the Typesetting menu item remains misleadingly named Superscript so I would personally change that to Power if adopting this binding.

Also see:


Can I modify Ctrl-- to insert Indexed expressions?

"
4147,4147,6615,How to get <img> src from CDATA in RSS?,"I am fetching data from RSS feed with Magpie.
$rss[description]  contains CDATA with html elements:  

&lt;![CDATA[  
&lt;div&gt;  
 &lt;a href='url'&gt;  
  &lt;img src='img_url' alt='aaa' title='bbb' border='0' width='116' height='116'&gt;  
 &lt;/a&gt;  
&lt;/div&gt;]]&gt;  
Some other text  


How can I fetch ""img_url"" from this?  Is preg_match() the only way? Maybe I can use simpleXML?
",lvil,https://stackoverflow.com/users/533861,"You would better not to use regular expressions where you can use proper tools. Something which comes to my mind (although maybe it can be done easier):

$descr = $rss[description]; // String. You have extracted description part from your feed

$dom = new DOMDocument();
$dom-&gt;loadHTML($descr); // or you can use loadXML
if (!$dom) {
    die('Error loading HTML string.');
}

$xml = simplexml_import_dom($dom);
$imgSrc = (string)$xml-&gt;body-&gt;div-&gt;a-&gt;img['src'];


Here we go. Based on the your example CDATA $imgSrc will be equal to img_url.
",dfsq,https://stackoverflow.com/users/949476,http://stackoverflow.com/questions/8838742/how-to-get-img-src-from-cdata-in-rss,STACKOVERFLOW,stackoverflow.com,1.0,0.6666666666666666,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.3333333333333333,0.0,0.8888888888888888,How to get SRC from CDATA in RSS?,"I am fetching data from RSS feed with Magpie.
$rss[description]  contains CDATA with html elements:  

&lt;![CDATA[  
&lt;div&gt;  
 &lt;a href='url'&gt;  
  &lt;img src='img_url' alt='aaa' title='bbb' border='0' width='116' height='116'&gt;  
 &lt;/a&gt;  
&lt;/div&gt;]]&gt;  
Some other text  


How can I fetch ""img_url"" from this?  Is preg_match() the only way? Maybe I can use simpleXML?
","You would better not to use regular expressions where you can use proper tools. Something which comes to my mind (although maybe it can be done easier):

$descr = $rss[description]; // String. You have extracted description part from your feed

$dom = new DOMDocument();
$dom-&gt;loadHTML($descr); // or you can use loadXML
if (!$dom) {
    die('Error loading HTML string.');
}

$xml = simplexml_import_dom($dom);
$imgSrc = (string)$xml-&gt;body-&gt;div-&gt;a-&gt;img['src'];


Here we go. Based on the your example CDATA $imgSrc will be equal to img_url.
"
3103,3103,4942,Decompiler Bytecode and Obfuscators,"Can we completely reverse-engineer the source code from java bytecode ? Why this feature is allowed in Java and How successful are java decompilers against obfuscators.?
",Suraj Menon,https://stackoverflow.com/users/1662935,"I know this question is old but I kept looking for a reliable answer until I found nothing.
So in this post I summarize some of my effort to obfuscate a J2EE JAR.
It seems , that by year 2014 (time of writing) there are not many options out there.
If you read this review later then things may have changed or fixed.
When I think why , I start to sense that the whole obfuscation effort gives a false sense of security. Don't get me wrong. It does add a level of security, but not as much as I would hope.
I will try to give a preview of what I found to explain myself. My recommendation are personal ,  others may disagree with it.

So to begin with: obfuscation in Java is the process of taking bytecode and making it less readable (using a decompiler of course) while maintaining its original functionality.What can we do, Java ,working as an interperter, must keep its bytecode exposed. You run the obfuscator as a measure of security in case the class file falls into the wrong hands. The result of the obfuscation is a reverse-mapping files and a JAR with the obfuscated classes. The reverse mapping file is used of-course to perform stack trace reading (a.k.a re-trace) or to revert the bytecode to its original shape. The runtime performance hit of an obfuscated class should not pass the 10% (but this really depends on what you do in your code).

But there is a big “but” . Obfuscation will scramble your code but it won’t make it hacker-proof. Bare in mind you only buy time and a determined hacker will find a way to reverse engineer your bytecode into its pure algorithm.

IMHO: the best way to hide a sensitive piece of code is to drown it in some huge pile of meaningless code.

Some of the hackers will try to modify your bytecode (by code injection) to help them achieve their goals. Some obfuscators offer additional level of JAR hardening , making it harder to modify.

De-obfuscators and de-compilers: my favourite Java decompiler is JD-GUI . However, when it comes to de-obfuscators I found the market pretty empty. Most of the tools ask you for a hint (what obfuscation tool was used to encrypt the source JAR) , yet none of them really deliver results (some of them even crash when trying to de-cipher the JAR). They are open source projects with low maintenance. I couldn’t even find a paid application to do a decent de-obfuscation. so enlighten me if you know something.

Free solutions

There are open source , free obfuscators which usually simply rename the classes/methods names, making it one letter method  (i.e. from printUsage(String params) to a(String p) ).
They might ,as hinted here , even strip debugging information to make it a bit more difficult. (debugging information is kept at the end of every Java method bytecode and contains: line numbers, variables names ,etc.).
Its a nice effort , but an experience Java developer with a debugger can very easily deduce the purpose of each parameter while doing few live runs.
One of the nice open source obfuscators is ProGuard but there are several more tools.
Nevertheless , if you truly security fanatic you will probably want something stronger. Stronger demands more features (and more money) which leads us to the next bullet:

Paid solutions

While free products may only change classes method names , paid product will usually offer more features:


code/flow obfuscation: this will change the method code and inject empty loops/dead code/confusing switch tables and alike. Some of them may even scramble the exception table content. the obfuscation strength usually determine the output size.
Note: regarding code obfuscation: I deliberately avoided the details in my review. Some of the bytecode I saw and analyzed expose their obfuscation methods, and I wish to protect their IP. I do have an opinion about who uses better algorithms. contact me if you wish to know.
classes/method renaming : well this is the obvious , we discussed it in the free obfuscation. Some of the product will rename the class name and then recursively search for reflection usage of that class and fix those too. Paid products may even rename Spring /Wink configuration files for the same purpose (renaming in reflection).
String encryption: for every string “like this” in the code, it will encrypt it to some level and keep the key somewhere (in the class constant table/static blocks/a new method or any other mean).
debug information : stripping parts or scrambling.many of them will remove the line numbers info. 
class 
hardening: all kinds of methods like injecting some signing scheme into the beginning of the class/method, making sure an outsider won’t be able to easily modify the JAR and run it. Less important for Android or applets as most of them are digitally signed anyhow. some will combine hardening with water-marking to track pirated copies. But we all know anti-pirating methods by software are doomed to be hacked. Game industry suffered from it for decades until network based subscriptions arrived.
Since most products here deal with Java , some of them provides Android integration. It means it will not only obfuscate the Java (dalvik) code , but also manipulates the Android's manifest file and resources. Some offer anti debugging: remove the debug flag in android apps.
Nice GUI app to configure the various options and maybe do a re-trance on a given log file. The UI is usually used to generate a config file. with such file you can later re-play the obfuscation many times, even from command line.
Incremental build support - this is useful for large groups who release product updates/fixes frequently. You can tell the obfuscator to preserve old “obfuscation” result and randomly obfuscate only “new” code flows. this way you can be sure minimal impact on your methods signature. Without this flag , each obfuscation cycle on a JAR would yield a different output as most good tools use some level of randomness in their algorithms.
CLI and distributed builds. When you work alone then running an obfuscator is not a big issue. you need to configure the obfuscator to your relevant options and run it.However, in enterprise , when integrating obfuscator into the the build script things are a bit different. There is another level of complexity: build engine tasks (like ant/maven) and license management. The good news that all obfuscator I tested have command line API. In distributed build environment there are cluster/pool of build machines to support concurrent demand of builds. The cluster is dynamic and virtual, machines are going up or down, depending on various conditions. Some obfuscation products are based on cpuID license file or hostname. This can create quite a challenge for the build teams to integrate. Some prefer a local floating license server. Some may require public license server (but then: not all build farms have access to the public internet). Some offer multi-site license (which in my opinion is the best).
Some offer code optimizations - algebric equivalence and dropping of dead code. Its nice, but I believe that today's JDK do good job in optimizing bytecode. Its true that dead code makes you downloadable bigger, but with today's bandwidth its less than a problem. I also want to believe that in software today 20:80 thumb rule still applies. in any application 20% is probably a dead code anyway.


So who are the players I tried ?


KlassMaster by Zelix.com  - one of the oldest in the industry. Yet they deliver a solid product with 3-4 releases per year. This been going for decades (since 1997).  Zelix provides good email support and answered all my emails in a timely manner. They have a nice GUI client to either obfuscate a JAR or create a config file for future obfuscation. It simple and slick. nothing special here. They provided simple to read on-line documentation for all their flags. they support both “exclude” and “include” regular expressions for what the engine should obfuscate. The thing I liked about their process most is that it also adds “noise” to the exception table. It makes it a bit more confusing regarding the method exception handling. Their flow obfuscator strength is quite good and can be configured between 3 possible levels (light,medium and aggressive). Another feature I liked is the fine tuning they provide for debug info stripping (online line numbers, or online local variables or both). Klass Master doesn’t provide any 
dedicated Android flags  or anti-tamper methods.  Their licensing model is quite simple: a text file to be placed near the KlassMaster main JAR. They also support incremental obfuscation.
JFuscator from secureTeam.net : While secureTeam also has a .Net tool , I focus on their Java tool capabilities. Their (Swing based) GUI tool seems nice but it crash when trying the simplest obfuscation task. the error was always the same: Error reading '/opt/sun-jdk1.7.0_55/jre\lib\rt.jar'. Reason: ''/opt/sun-jdk1.7.0_55/jre\lib\rt.jar': no such file or directory'  . Now of course I have my Java installed in /opt/sun-jdk1.7.0_55/jre. You can image that they simply didn’t expect linux back slash structure. I contacted secureTeam.net support by email with the minor “path” problem. They asked if I am a linux user and after I replied I am , they never answered my email. I also tried their web site on-line chat : no response. So there I stopped testing. Without further results, I couldn’t examine the obfuscated bytecode quality. From their web site it seems they have anti-tamper method , String manipulation, method renaming and few other features.
GuartIt4J (by Arxan.com) : Arxan is fairly solid player in the mobile environment and as such they offer Android obfuscator which of course works well for Java. They have one of the most flexible engines.They provide code obfuscation,string encryption and alike  You can define the complexity of code obfuscation. it is simply an integer. the higher - the longer your method turns out. ofcourse, you must be carefull not to exceed the JVM 64KB limit per class… As I said before one of the best strategies to hide a sensitive code is not to encrypt it , but to inject it into huge pile of garbage. This is exactly what GuardIt does. It can also explode in the same way the methods exception table. I managed to create a method with 100 exceptions in its exception table (pre-obfuscator it was 5). what they miss: their re-trace program is not part of the supplied main JAR. Nevertheless, they were kind enough to send me a sample Java program that performs re-trace given the reverse mapping file and the log. They don’t support incremental obfuscation and no flexibility regarding debug information. Debug information stripping is either all or nothing.  watching the output JAR you will tons of conditions and jumps that were injected. Bare in mind , exploding the class size has its performance hit. In some methods I measured almost 50% performance hit when applying long obfuscation (no I/O in those methods). so extrapolating the code comes with a price.(from a 400 opcodes - I went up to 2200 opcodes after obfuscation). JD-GUI , my de-compiler failed to open such classes and crashed (IndexOutOfBoundException). They also supply complete class encryption . Meaning the class is encrypted with some symetrical key which demands a special (or custom written) class loader to open it in memory.  This is an anti-tamper mechanism as well as hiding code. Just remember that a JVM can’t run that class without the class loader help. Its a nice feature, but the secret key and the bootstrap loader JAR are probably there. If he got the encrypted JAR the hacker  will eventually get his hands and decrypt the classes. Yet this another level of obstacle the common hacker will need to pass. What I didn’t like here is the license file  policy: is bounded to CPUid or need to install a floating license server.
SecureIt (by Allatori.com) : SecureIt offers all the general code obfuscation, string encryption ,renaming and such. On top of the standard obfuscation methods they also offer some kind of water-marking which is an anti-tamper/pirating method. They support Android and JavaME (who uses ME these days?!). They support incremental obfuscation. The one thing to note about configuring SecureIt: it is all command line. No GUI tool this time. Personally , I don’t mind command line tools as long as they come with good documentation. Luckily they have a very good documentation and a rich API with many flags to tune if you wish. you can re-trace with they tool (also a command line ) . They can’t obfuscate the exception table. I didn’t check their licensing mechanism.
DashO (by Preemptive.com) : DashO obfuscator will be remembered probably as the best UI tool you can get (to create your configuration). Like SecureIt they lake the exception table obfuscation but they have all the rest of the required features (as well as CLI, Spring framework and gradle/ant integration, and even an eclipse plugin) . Well, they do document a try-catch obfuscator (which is same as exception table obfuscator) , but it is only a recommendation to the engine. When I tried it , it had nil effect on the exception table.  As I said , the GUI tool is superb and has a re-trace embedded into it. they also offer some kind of application signing and water-marking as an anti-tamper/pirating mechanism. DashO provides superb Android integration and also combine in their product a door for analytics uploads. You can actually track your application. Injecting crash log uploaders and reporting code to your JAR. Nevertheless that’s not the scope of obfuscation - that’s a whole different code injection product. They have a very good support. both online and by phone. Their licensing scheme is based on monthly subscription or one time purchase payment. A bit different than others. They are using a floating license server to support large environments.


I hope this helps a bit..
",taitelman,https://stackoverflow.com/users/2132826,http://stackoverflow.com/questions/13098606/decompiler-bytecode-and-obfuscators,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.3333333333333333,0.0,1.0,0.6666666666666666,1.0,0.5555555555555556,0.3333333333333333,1.0,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,1.0,0.0,0.3333333333333333,1.0,0.8888888888888888,1.0,1.0,1.0,0.3333333333333333,0.0,1.0,0.8888888888888888,Decompiler bytecode and obfuscator,Can we completely reverse engineer the source code from Java bytecode? Why is this feature allowed in Java and how successful is java decompiler for obfuscator.?,"I know this question is old but I kept looking for a reliable answer until I found nothing.
So in this post I summarize some of my effort to obfuscate a J2EE JAR.
It seems , that by year 2014 (time of writing) there are not many options out there.
If you read this review later then things may have changed or fixed.
When I think why , I start to sense that the whole obfuscation effort gives a false sense of security. Don't get me wrong. It does add a level of security, but not as much as I would hope.
I will try to give a preview of what I found to explain myself. My recommendation are personal ,  others may disagree with it.

So to begin with: obfuscation in Java is the process of taking bytecode and making it less readable (using a decompiler of course) while maintaining its original functionality.What can we do, Java ,working as an interperter, must keep its bytecode exposed. You run the obfuscator as a measure of security in case the class file falls into the wrong hands. The result of the obfuscation is a reverse-mapping files and a JAR with the obfuscated classes. The reverse mapping file is used of-course to perform stack trace reading (a.k.a re-trace) or to revert the bytecode to its original shape. The runtime performance hit of an obfuscated class should not pass the 10% (but this really depends on what you do in your code).

But there is a big “but” . Obfuscation will scramble your code but it won’t make it hacker-proof. Bare in mind you only buy time and a determined hacker will find a way to reverse engineer your bytecode into its pure algorithm.

IMHO: the best way to hide a sensitive piece of code is to drown it in some huge pile of meaningless code.

Some of the hackers will try to modify your bytecode (by code injection) to help them achieve their goals. Some obfuscators offer additional level of JAR hardening , making it harder to modify.

De-obfuscators and de-compilers: my favourite Java decompiler is JD-GUI . However, when it comes to de-obfuscators I found the market pretty empty. Most of the tools ask you for a hint (what obfuscation tool was used to encrypt the source JAR) , yet none of them really deliver results (some of them even crash when trying to de-cipher the JAR). They are open source projects with low maintenance. I couldn’t even find a paid application to do a decent de-obfuscation. so enlighten me if you know something.

Free solutions

There are open source , free obfuscators which usually simply rename the classes/methods names, making it one letter method  (i.e. from printUsage(String params) to a(String p) ).
They might ,as hinted here , even strip debugging information to make it a bit more difficult. (debugging information is kept at the end of every Java method bytecode and contains: line numbers, variables names ,etc.).
Its a nice effort , but an experience Java developer with a debugger can very easily deduce the purpose of each parameter while doing few live runs.
One of the nice open source obfuscators is ProGuard but there are several more tools.
Nevertheless , if you truly security fanatic you will probably want something stronger. Stronger demands more features (and more money) which leads us to the next bullet:

Paid solutions

While free products may only change classes method names , paid product will usually offer more features:


code/flow obfuscation: this will change the method code and inject empty loops/dead code/confusing switch tables and alike. Some of them may even scramble the exception table content. the obfuscation strength usually determine the output size.
Note: regarding code obfuscation: I deliberately avoided the details in my review. Some of the bytecode I saw and analyzed expose their obfuscation methods, and I wish to protect their IP. I do have an opinion about who uses better algorithms. contact me if you wish to know.
classes/method renaming : well this is the obvious , we discussed it in the free obfuscation. Some of the product will rename the class name and then recursively search for reflection usage of that class and fix those too. Paid products may even rename Spring /Wink configuration files for the same purpose (renaming in reflection).
String encryption: for every string “like this” in the code, it will encrypt it to some level and keep the key somewhere (in the class constant table/static blocks/a new method or any other mean).
debug information : stripping parts or scrambling.many of them will remove the line numbers info. 
class 
hardening: all kinds of methods like injecting some signing scheme into the beginning of the class/method, making sure an outsider won’t be able to easily modify the JAR and run it. Less important for Android or applets as most of them are digitally signed anyhow. some will combine hardening with water-marking to track pirated copies. But we all know anti-pirating methods by software are doomed to be hacked. Game industry suffered from it for decades until network based subscriptions arrived.
Since most products here deal with Java , some of them provides Android integration. It means it will not only obfuscate the Java (dalvik) code , but also manipulates the Android's manifest file and resources. Some offer anti debugging: remove the debug flag in android apps.
Nice GUI app to configure the various options and maybe do a re-trance on a given log file. The UI is usually used to generate a config file. with such file you can later re-play the obfuscation many times, even from command line.
Incremental build support - this is useful for large groups who release product updates/fixes frequently. You can tell the obfuscator to preserve old “obfuscation” result and randomly obfuscate only “new” code flows. this way you can be sure minimal impact on your methods signature. Without this flag , each obfuscation cycle on a JAR would yield a different output as most good tools use some level of randomness in their algorithms.
CLI and distributed builds. When you work alone then running an obfuscator is not a big issue. you need to configure the obfuscator to your relevant options and run it.However, in enterprise , when integrating obfuscator into the the build script things are a bit different. There is another level of complexity: build engine tasks (like ant/maven) and license management. The good news that all obfuscator I tested have command line API. In distributed build environment there are cluster/pool of build machines to support concurrent demand of builds. The cluster is dynamic and virtual, machines are going up or down, depending on various conditions. Some obfuscation products are based on cpuID license file or hostname. This can create quite a challenge for the build teams to integrate. Some prefer a local floating license server. Some may require public license server (but then: not all build farms have access to the public internet). Some offer multi-site license (which in my opinion is the best).
Some offer code optimizations - algebric equivalence and dropping of dead code. Its nice, but I believe that today's JDK do good job in optimizing bytecode. Its true that dead code makes you downloadable bigger, but with today's bandwidth its less than a problem. I also want to believe that in software today 20:80 thumb rule still applies. in any application 20% is probably a dead code anyway.


So who are the players I tried ?


KlassMaster by Zelix.com  - one of the oldest in the industry. Yet they deliver a solid product with 3-4 releases per year. This been going for decades (since 1997).  Zelix provides good email support and answered all my emails in a timely manner. They have a nice GUI client to either obfuscate a JAR or create a config file for future obfuscation. It simple and slick. nothing special here. They provided simple to read on-line documentation for all their flags. they support both “exclude” and “include” regular expressions for what the engine should obfuscate. The thing I liked about their process most is that it also adds “noise” to the exception table. It makes it a bit more confusing regarding the method exception handling. Their flow obfuscator strength is quite good and can be configured between 3 possible levels (light,medium and aggressive). Another feature I liked is the fine tuning they provide for debug info stripping (online line numbers, or online local variables or both). Klass Master doesn’t provide any 
dedicated Android flags  or anti-tamper methods.  Their licensing model is quite simple: a text file to be placed near the KlassMaster main JAR. They also support incremental obfuscation.
JFuscator from secureTeam.net : While secureTeam also has a .Net tool , I focus on their Java tool capabilities. Their (Swing based) GUI tool seems nice but it crash when trying the simplest obfuscation task. the error was always the same: Error reading '/opt/sun-jdk1.7.0_55/jre\lib\rt.jar'. Reason: ''/opt/sun-jdk1.7.0_55/jre\lib\rt.jar': no such file or directory'  . Now of course I have my Java installed in /opt/sun-jdk1.7.0_55/jre. You can image that they simply didn’t expect linux back slash structure. I contacted secureTeam.net support by email with the minor “path” problem. They asked if I am a linux user and after I replied I am , they never answered my email. I also tried their web site on-line chat : no response. So there I stopped testing. Without further results, I couldn’t examine the obfuscated bytecode quality. From their web site it seems they have anti-tamper method , String manipulation, method renaming and few other features.
GuartIt4J (by Arxan.com) : Arxan is fairly solid player in the mobile environment and as such they offer Android obfuscator which of course works well for Java. They have one of the most flexible engines.They provide code obfuscation,string encryption and alike  You can define the complexity of code obfuscation. it is simply an integer. the higher - the longer your method turns out. ofcourse, you must be carefull not to exceed the JVM 64KB limit per class… As I said before one of the best strategies to hide a sensitive code is not to encrypt it , but to inject it into huge pile of garbage. This is exactly what GuardIt does. It can also explode in the same way the methods exception table. I managed to create a method with 100 exceptions in its exception table (pre-obfuscator it was 5). what they miss: their re-trace program is not part of the supplied main JAR. Nevertheless, they were kind enough to send me a sample Java program that performs re-trace given the reverse mapping file and the log. They don’t support incremental obfuscation and no flexibility regarding debug information. Debug information stripping is either all or nothing.  watching the output JAR you will tons of conditions and jumps that were injected. Bare in mind , exploding the class size has its performance hit. In some methods I measured almost 50% performance hit when applying long obfuscation (no I/O in those methods). so extrapolating the code comes with a price.(from a 400 opcodes - I went up to 2200 opcodes after obfuscation). JD-GUI , my de-compiler failed to open such classes and crashed (IndexOutOfBoundException). They also supply complete class encryption . Meaning the class is encrypted with some symetrical key which demands a special (or custom written) class loader to open it in memory.  This is an anti-tamper mechanism as well as hiding code. Just remember that a JVM can’t run that class without the class loader help. Its a nice feature, but the secret key and the bootstrap loader JAR are probably there. If he got the encrypted JAR the hacker  will eventually get his hands and decrypt the classes. Yet this another level of obstacle the common hacker will need to pass. What I didn’t like here is the license file  policy: is bounded to CPUid or need to install a floating license server.
SecureIt (by Allatori.com) : SecureIt offers all the general code obfuscation, string encryption ,renaming and such. On top of the standard obfuscation methods they also offer some kind of water-marking which is an anti-tamper/pirating method. They support Android and JavaME (who uses ME these days?!). They support incremental obfuscation. The one thing to note about configuring SecureIt: it is all command line. No GUI tool this time. Personally , I don’t mind command line tools as long as they come with good documentation. Luckily they have a very good documentation and a rich API with many flags to tune if you wish. you can re-trace with they tool (also a command line ) . They can’t obfuscate the exception table. I didn’t check their licensing mechanism.
DashO (by Preemptive.com) : DashO obfuscator will be remembered probably as the best UI tool you can get (to create your configuration). Like SecureIt they lake the exception table obfuscation but they have all the rest of the required features (as well as CLI, Spring framework and gradle/ant integration, and even an eclipse plugin) . Well, they do document a try-catch obfuscator (which is same as exception table obfuscator) , but it is only a recommendation to the engine. When I tried it , it had nil effect on the exception table.  As I said , the GUI tool is superb and has a re-trace embedded into it. they also offer some kind of application signing and water-marking as an anti-tamper/pirating mechanism. DashO provides superb Android integration and also combine in their product a door for analytics uploads. You can actually track your application. Injecting crash log uploaders and reporting code to your JAR. Nevertheless that’s not the scope of obfuscation - that’s a whole different code injection product. They have a very good support. both online and by phone. Their licensing scheme is based on monthly subscription or one time purchase payment. A bit different than others. They are using a floating license server to support large environments.


I hope this helps a bit..
"
4465,4465,7086,Lyx itemize returning to last number,"I would like to have the following output:


Text

(a) Text

Text
Text


That is, after a subitem, I want to return to the last number without creating a new one. Is there any way to do this without ERT?
",LuizMMB,https://tex.stackexchange.com/users/41960,"Insert a ""custom item"" for the oddly-placed entry



and leave the entry blank



This leaves you with:


",Werner,https://tex.stackexchange.com/users/5764,http://tex.stackexchange.com/questions/177214/lyx-itemize-returning-to-last-number,TECHNOLOGY,tex.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,0.5,1.0,1.0,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.0,0.0,0.8888888888888888,0.7777777777777778,0.5555555555555556,1.0,1.0,0.8,0.6666666666666666,0.3333333333333333,0.0,0.7777777777777778,Lyx returns to the last number one by one,"I would like to have the following output:


Text

(a) Text

Text
Text


That is, after a subitem, I want to return to the last number without creating a new one. Is there any way to do this without ERT?
","Insert a ""custom item"" for the oddly-placed entry



and leave the entry blank



This leaves you with:


"
5708,5708,9047,Windows Software to Mount Volume/Partition Image File,"Last night I had a BSOD a couple of minutes after moving a file. After a reboot, I found that the file was gone (it was deleted from the source partition and not present on the destination).

I took an image of the source volume (ie from the Boot Sector to the last cluster of the partition). Then I wrote a program to extract the unused clusters from a disk and save them as files.

Some of the free clusters on the original volume have now been overwritten so I need to use the image to do my final extraction. That means I need some software that can mount a volume/partition image, but all of the image mounting software I can find can only mount disk images (ie from the MBR—the master partition table—on).

Does anyone know of (hopefully free) Windows software that can do this?

I’ve already tried (without success): VirtualCloneDrive, DaemonTools, VirtualFloppyDrive (and probably a couple of others I can’t think of). They all either nag that the file is no good, or try to mount it, resulting in a disk that Windows complains has an unknown/corrupt filesystem.

Thanks.
",Synetech,https://superuser.com/users/3279,"Try alcohol 120  and magicDisc
",Houston we have a problem,https://superuser.com/users/56585,http://superuser.com/questions/172184,TECHNOLOGY,superuser.com,0.8888888888888888,0.4444444444444444,0.0,1.0,1.0,0.5,0.5555555555555556,0.5555555555555556,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.9,0.3333333333333333,0.0,0.0,0.7777777777777778,Install windows software for volume / partition image files,"Last night I had a BSOD a couple of minutes after moving a file. After a reboot, I found that the file was gone (it was deleted from the source partition and not present on the destination).

I took an image of the source volume (ie from the Boot Sector to the last cluster of the partition). Then I wrote a program to extract the unused clusters from a disk and save them as files.

Some of the free clusters on the original volume have now been overwritten so I need to use the image to do my final extraction. That means I need some software that can mount a volume/partition image, but all of the image mounting software I can find can only mount disk images (ie from the MBR—the master partition table—on).

Does anyone know of (hopefully free) Windows software that can do this?

I’ve already tried (without success): VirtualCloneDrive, DaemonTools, VirtualFloppyDrive (and probably a couple of others I can’t think of). They all either nag that the file is no good, or try to mount it, resulting in a disk that Windows complains has an unknown/corrupt filesystem.

Thanks.
",Try alcohol 120 and Magic
2066,2066,3294,"what does ""predict"", ""milestone"" and ""tie into"" mean here?","
  Some psychologists believe that 'while object permanence alone may not
  predict communicative achievement, object permanence along with several other sensorimotor milestones, plays a critical role in,
  and interacts with, the communicative development of children with
  severe disabilities'. This was observed in 2006, in a study
  recognizing where the full mastery of object permanence is one of the
  milestones that ties into a child's ability to engage in mental
  representation.


Source: http://en.wikipedia.org/wiki/Object_permanence#Recent_studies

Thank you very much.
",en.newbie21,https://ell.stackexchange.com/users/9369,"Predict means to say now what will happen later.

Milestones is jargon for ""age-appropriate achievements|mastery of function"".

Ties into  is just a sloppy|casual phrase for ""is associated with"".
",Tᴚoɯɐuo,https://ell.stackexchange.com/users/10264,http://ell.stackexchange.com/questions/38038/what-does-predict-milestone-and-tie-into-mean-here,CULTURE,ell.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,0.6666666666666666,1.0,1.0,0.5555555555555556,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.6666666666666666,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,0.6666666666666666,0.8888888888888888,"What do you mean by ""forecast"", ""milestone"" and ""connection""?","
  Some psychologists believe that 'while object permanence alone may not
  predict communicative achievement, object permanence along with several other sensorimotor milestones, plays a critical role in,
  and interacts with, the communicative development of children with
  severe disabilities'. This was observed in 2006, in a study
  recognizing where the full mastery of object permanence is one of the
  milestones that ties into a child's ability to engage in mental
  representation.


Source: http://en.wikipedia.org/wiki/Object_permanence#Recent_studies

Thank you very much.
","Predict means to say now what will happen later.

Milestones is jargon for ""age-appropriate achievements|mastery of function"".

Ties into  is just a sloppy|casual phrase for ""is associated with"".
"
4740,4740,7518,Trying to recreate graphic from image as a vector,"I am trying to recreate the rings from the following image into a vector graphic. I have made several attempts using various shapes and the pen tool with no luck. Any help on which steps I could take would be greatly appreciated!

Here is the image in question (on pinterest):


",Graham,https://graphicdesign.stackexchange.com/users/36238,"
You simply draw one ellipse.
Duplicate it.
Draw a rectangle for the sides.
Then use the Shape Builder Tool to combine specific pieces (Holding the Option/Alt key down with the Shape Builder Tool will remove parts.)
Then add color.



",Scott,https://graphicdesign.stackexchange.com/users/3270,http://graphicdesign.stackexchange.com/questions/45014/trying-to-recreate-graphic-from-image-as-a-vector,LIFE_ARTS,graphicdesign.stackexchange.com,0.8888888888888888,0.6666666666666666,0.0,0.5,1.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,0.8888888888888888,Try to reconstruct the image as a vector,"I'm trying to reconstruct a vector ring from the image below. I made several attempts with various shapes and pen tools, but none of them succeeded. Any measures I can take will be appreciated!","
You simply draw one ellipse.
Duplicate it.
Draw a rectangle for the sides.
Then use the Shape Builder Tool to combine specific pieces (Holding the Option/Alt key down with the Shape Builder Tool will remove parts.)
Then add color.



"
850,850,1356,"How to prevent the ""Too awesome to use"" syndrome","When you give the player a rare but powerful item which can only be used once but is never really required to proceed, most players will not use it at all, because they are waiting for the perfect moment. But even when this moment comes, they will still be reluctant to use it, because there might be an even better moment later. So they keep hoarding it for a moment which will never come. 

In the end, they will carry the item around until it is outclassed by other, more readily available resources, or even until the very end of the game. That means that such one-shot items don't provide any gameplay-value at all. They are simply too awesome to use.

What can you do to encourage the player to make use of their one-shot items and not hoard them?
",Philipp,https://gamedev.stackexchange.com/users/21890,"I think looking at it from the ""this item is too powerful"" point of view is missing the point a bit.  In my view, it's more about hoarding items because they're limited.  A good example of this problem happening is in a game like Skyrim where you can make potions.  Sure, 5% fire resist for 5 seconds isn't terribly powerful by almost anybody's standards, but it still accumulated to the point where I didn't want to get rid of them because 1) they were a limited amount and 2) I couldn't predict the future.

So that being said, I would look at the problem as a way to mitigate hoarding behavior.

One of the most successful approaches I've seen is to take the items away from the player at known intervals.  For example, make it so you get consumables inside dungeons, but once you leave the dungeon the consumables go away.  That way, the item can't be hoarded because it isn't permanent. Since you don't have persistent consumable inventory beyond the dungeon, the user doesn't feel that the item has as much value. 

Alternatively, you could also do things like dramatically limit the number of single use items the player can carry.  The logic being that if you don't use the items you're leaving a bunch of consumables behind.  It isn't as good an approach as forcing the items out of the user's inventory, but it might also encourage the user to churn through their items.
",Tetrad,https://gamedev.stackexchange.com/users/51,http://gamedev.stackexchange.com/questions/55558/how-to-prevent-the-too-awesome-to-use-syndrome,TECHNOLOGY,gamedev.stackexchange.com,1.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.6666666666666666,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.3333333333333333,1.0,"How to prevent ""too good to use"" syndrome","When you give the player a rare but powerful item which can only be used once but is never really required to proceed, most players will not use it at all, because they are waiting for the perfect moment. But even when this moment comes, they will still be reluctant to use it, because there might be an even better moment later. So they keep hoarding it for a moment which will never come. 

In the end, they will carry the item around until it is outclassed by other, more readily available resources, or even until the very end of the game. That means that such one-shot items don't provide any gameplay-value at all. They are simply too awesome to use.

What can you do to encourage the player to make use of their one-shot items and not hoard them?
","I think looking at it from the ""this item is too powerful"" point of view is missing the point a bit.  In my view, it's more about hoarding items because they're limited.  A good example of this problem happening is in a game like Skyrim where you can make potions.  Sure, 5% fire resist for 5 seconds isn't terribly powerful by almost anybody's standards, but it still accumulated to the point where I didn't want to get rid of them because 1) they were a limited amount and 2) I couldn't predict the future.

So that being said, I would look at the problem as a way to mitigate hoarding behavior.

One of the most successful approaches I've seen is to take the items away from the player at known intervals.  For example, make it so you get consumables inside dungeons, but once you leave the dungeon the consumables go away.  That way, the item can't be hoarded because it isn't permanent. Since you don't have persistent consumable inventory beyond the dungeon, the user doesn't feel that the item has as much value. 

Alternatively, you could also do things like dramatically limit the number of single use items the player can carry.  The logic being that if you don't use the items you're leaving a bunch of consumables behind.  It isn't as good an approach as forcing the items out of the user's inventory, but it might also encourage the user to churn through their items.
"
1921,1921,3058,How to create 2 or more than 2 button in Android,"I want to create 2 or more than 2 two button in android but I got the problem in this line 

View btnClick = findViewById(R.id.buttonClick);
    View btnscan = findViewById(R.id.btscanClick);
    //set event listener
    btnClick.setOnClickListener(this);
}

//override the OnClickListener interface method
@Override
public void onClick(View arg0) {
    if(arg0.getId() == R.id.buttonClick){
        //define a new Intent for the second Activity
        Intent intent = new Intent(this,SecondActivity.class);
        //start the second Activity
        this.startActivity(intent);

public void onClick1(View arg1) {
    if(arg1.getId() == R.id.btscanClick){
        //define a new Intent for the second Activity
        Intent intent = new Intent(this,ScanActivity.class);
        //start the second Activity
        this.startActivity(intent);

",user3640392,https://stackoverflow.com/users/3640392,"may be the problem would be with your design, I thing you are implementing it in surface view. if you do so make your layout with LinearLayout and RelativeLayout, it would be better if you also add your .manifestfile
",Bharadwaja Bapatla,https://stackoverflow.com/users/3640268,http://stackoverflow.com/questions/23675794,STACKOVERFLOW,stackoverflow.com,0.6666666666666666,0.5555555555555556,0.0,1.0,1.0,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.5555555555555556,0.7777777777777778,0.4444444444444444,0.7777777777777778,0.7777777777777778,0.6666666666666667,0.3333333333333333,0.0,1.0,0.7777777777777778,How to create two or more buttons in Android,"I want to create 2 or more than 2 two button in android but I got the problem in this line 

View btnClick = findViewById(R.id.buttonClick);
    View btnscan = findViewById(R.id.btscanClick);
    //set event listener
    btnClick.setOnClickListener(this);
}

//override the OnClickListener interface method
@Override
public void onClick(View arg0) {
    if(arg0.getId() == R.id.buttonClick){
        //define a new Intent for the second Activity
        Intent intent = new Intent(this,SecondActivity.class);
        //start the second Activity
        this.startActivity(intent);

public void onClick1(View arg1) {
    if(arg1.getId() == R.id.btscanClick){
        //define a new Intent for the second Activity
        Intent intent = new Intent(this,ScanActivity.class);
        //start the second Activity
        this.startActivity(intent);

","may be the problem would be with your design, I thing you are implementing it in surface view. if you do so make your layout with LinearLayout and RelativeLayout, it would be better if you also add your .manifestfile
"
5377,5377,8539,"App is unable to write to the registry, even though the user has administrative privileges","I am using Visual Studio 2010, and I'm writing a program that needs to set (and read) new registry values under HKLM\Software\myapp 

The program is .NET 2.0-based and as for now it runs on Windows 7 64-bit. Here is my ocde:

RegistryKey softwareKey = Registry.LocalMachine.OpenSubKey(""Software"", true);
RegistryKey MyKey = softwareKey.CreateSubKey(""MyApp"");
RegistryKey  = MyKey.CreateSubKey(""MyKey"");
selfPlacingWindowKey.SetValue(""instaldateperson"", datestr + usrname);     


The problem I have when running Visual Studio 2010, is that it will run the app but logged on as me, I am a user and member of local admin group.. however I cannot create the key (despite I am part of local admin group, who have rights to do so). Neither do I know how to do it as a logon as (but its also not what I want since then I would put Adminuser and password inside the code, and I already am admin ?? so why ??)

If this isn't possible at all, are there options for creating registry keys?

Somehow add them to the project or so ??.. I am a bit confused here.
",user613326,https://stackoverflow.com/users/613326,"The design of your application is probably wrong. Standard desktop apps are not supposed to write to HKEY_LOCAL_MACHINE. Because of UAC, you need to have administrator rights, and be running in an elevated process in order to be able to write to HKLM.

If your application does need to make changes to HKLM then consider doing so at installation time because the installer will be run elevated.

If a desktop application does need to write to HKLM then it should consider separating those parts of the application that need to run elevated into a separate process. Otherwise the users are going to be very fed up with having to go through a UAC dialog in order to run your application. Even if they aren't using the part of the application that writes to HKLM. And if you force the entire app to require elevation then standard users can never run it at all.
",David Heffernan,https://stackoverflow.com/users/505088,http://stackoverflow.com/questions/15729538/app-is-unable-to-write-to-the-registry-even-though-the-user-has-administrative,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.5555555555555556,0.0,0.5,1.0,1.0,0.5555555555555556,0.3333333333333333,0.3333333333333333,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.0,0.6666666666666666,0.8888888888888888,0.5,0.8888888888888888,0.8888888888888888,0.7,0.0,0.0,1.0,0.8888888888888888,"The application cannot write to the registry, even if the user has administrative rights","I am using Visual Studio 2010, and I'm writing a program that needs to set (and read) new registry values under HKLM\Software\myapp 

The program is .NET 2.0-based and as for now it runs on Windows 7 64-bit. Here is my ocde:

RegistryKey softwareKey = Registry.LocalMachine.OpenSubKey(""Software"", true);
RegistryKey MyKey = softwareKey.CreateSubKey(""MyApp"");
RegistryKey  = MyKey.CreateSubKey(""MyKey"");
selfPlacingWindowKey.SetValue(""instaldateperson"", datestr + usrname);     


The problem I have when running Visual Studio 2010, is that it will run the app but logged on as me, I am a user and member of local admin group.. however I cannot create the key (despite I am part of local admin group, who have rights to do so). Neither do I know how to do it as a logon as (but its also not what I want since then I would put Adminuser and password inside the code, and I already am admin ?? so why ??)

If this isn't possible at all, are there options for creating registry keys?

Somehow add them to the project or so ??.. I am a bit confused here.
","The design of your application is probably wrong. Standard desktop apps are not supposed to write to HKEY_LOCAL_MACHINE. Because of UAC, you need to have administrator rights, and be running in an elevated process in order to be able to write to HKLM.

If your application does need to make changes to HKLM then consider doing so at installation time because the installer will be run elevated.

If a desktop application does need to write to HKLM then it should consider separating those parts of the application that need to run elevated into a separate process. Otherwise the users are going to be very fed up with having to go through a UAC dialog in order to run your application. Even if they aren't using the part of the application that writes to HKLM. And if you force the entire app to require elevation then standard users can never run it at all.
"
1292,1292,2037,Can excited electrons fall back to their ground state without the emission of photons?,"In gas discharge lamps, for example, a current composed of ionized atoms excites the electrons of the atoms of the gas, and when they fall back to their ground state photons are emitted. Why is the reverse process (energy transfer of an excited electron to a free electron) never mentioned? Is it not possible or is the characteristic time involved too low for the electron to ""wait"" for an electron to pass? 

I have read about losing excitation energy as heat in chemistry oriented articles, but they don't go too deep. Here is an example.
",Ant,https://physics.stackexchange.com/users/36680,"You are wanting to know about the Auger process.  The answer is yes.  An excited electron can emit a photon when it falls to a lower orbital, or it can give its energy to another electron in the atom and eject it instead.  The chances of this occurring are dependent on which atom, which energy transition, and to a very small extent the chemical environment.  
",ZSG,https://physics.stackexchange.com/users/41503,http://physics.stackexchange.com/questions/145077/can-excited-electrons-fall-back-to-their-ground-state-without-the-emission-of-ph,SCIENCE,physics.stackexchange.com,1.0,1.0,0.0,0.0,1.0,1.0,0.8888888888888888,0.7777777777777778,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,1.0,Can excited electrons return to the ground state without photon emission?,"For example, in a gas discharge lamp, an electric current composed of ionized atoms excites the electrons of the gas atoms, and when they fall back to the ground state, they emit photons. Why is there no mention of the reverse process (energy transfer from the excited electron to the free electron)? Is this impossible, or is the characteristic time required for the electron to ""wait"" for the electron to pass too low?","You are wanting to know about the Auger process.  The answer is yes.  An excited electron can emit a photon when it falls to a lower orbital, or it can give its energy to another electron in the atom and eject it instead.  The chances of this occurring are dependent on which atom, which energy transition, and to a very small extent the chemical environment.  
"
5393,5393,8568,"Is there a difference between ""brainstorming"" and ""mindstorming""?","Some people use brainstorming, others use mindstorming. I could not find the difference between the two words. 
",Rami Al-Muhtaseb,https://english.stackexchange.com/users/24218,"""Brainstorming"" is a commonly used and commonly accepted word. ""Mindstorming"" is not. As far as I can tell it means the same as ""brainstorming"", and thus it is difficult to see why we need a new word to express an idea that we already have a word for. (IMHO it's just an effort by some people to sound like they're introducing a new idea when they're just recycling the same old ideas, but that may be getting off topic.)
",Jay,https://english.stackexchange.com/users/13140,http://english.stackexchange.com/questions/93575/is-there-a-difference-between-brainstorming-and-mindstorming,CULTURE,english.stackexchange.com,1.0,1.0,0.0,1.0,1.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.0,0.0,0.3333333333333333,0.6666666666666666,0.3333333333333333,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.8888888888888888,0.7777777777777778,0.6666666666666666,0.8888888888888888,1.0,0.8,0.0,0.0,0.6666666666666666,1.0,"Is there any difference between ""brainstorming"" and ""brainstorming""?","Some people use brainstorming, some people use brainstorming. I can't find the difference between the two words.","""Brainstorming"" is a commonly used and widely accepted word ""mind storm"" is not. As far as I know, it means the same as brainstorming, so it's hard to understand why we need a new word to express an idea that we already have a word. (although some people are just repeating old ideas, it may feel like they are introducing new ideas.)"
5759,5759,9127,FragmentTabHost in VS2013 - xamarin C#,"the code i used to create FragmentTabHost :( i am designing for android 2.2 to upper)
i have googled a lot but no use so
i have placed all of my code here.
I get error in :

   mTabHost.AddTab(spec);


please help how to solve ??

Activity 2.cs

using System;
using System.Collections.Generic;
using System.Linq;
using System.Text;


using Android.App;
using Android.Content;
using Android.OS;
using Android.Runtime;
using Android.Views;
using Android.Widget;
using Android.Content.PM;
using Android.Support.V4.App;


namespace ANRestaurant.Forms
{
[Activity(Label = ""ANRestaurant"", MainLauncher = true, Icon = ""@drawable/icon"", ScreenOrientation = ScreenOrientation.Portrait)]


public class Activity2 : FragmentActivity
{
    FragmentTabHost mTabHost;
    protected override void OnCreate(Bundle bundle)
    {
        base.OnCreate(bundle);


        SetContentView(Resource.Layout.activity_main);
        try
        {
            mTabHost = FindViewById&lt;FragmentTabHost&gt;(Resource.Id.tabhostN  );
            Intent intent;
            intent = new Intent(this, typeof(Fragment1));
            intent.AddFlags(ActivityFlags.NewTask);
            //mTabHost.Setup(this, SupportFragmentManager, Resource.Id.tabFrameLayout);


            TabHost.TabSpec spec;
            spec = mTabHost.NewTabSpec(""artists"");
            spec.SetIndicator(""Artists"", Resources.GetDrawable(Resource.Drawable.tab_icon1)  );
            spec.SetContent(intent);
            mTabHost.AddTab(spec);   ======&gt;Here is the error
            //mTabHost.AddTab(
            //        mTabHost.NewTabSpec(""tab2"").SetIndicator(""Tab 2"", null),
            //       intent, null);
            //mTabHost.addTab(
            //        mTabHost.newTabSpec(""tab2"").setIndicator(""Tab 2"", null),
            //        FragmentTab.class, null);
            //mTabHost.addTab(
            //        mTabHost.newTabSpec(""tab3"").setIndicator(""Tab 3"", null),
            //        FragmentTab.class, null);
        }
        catch (Exception ex)
        {


        }
    }
}
}


activity_main.axml

&lt;?xml version=""1.0"" encoding=""utf-8""?&gt;
&lt;android.support.v4.app.FragmentTabHost xmlns:android=""http://schemas.android.com/apk/res/android""
    android:id=""@+id/tabhostN""
    android:layout_width=""match_parent""
    android:layout_height=""match_parent""&gt;
    &lt;LinearLayout
        android:layout_width=""match_parent""
        android:layout_height=""match_parent""
        android:orientation=""vertical""&gt;
        &lt;TabWidget
            android:id=""@+id/tabs""
            android:layout_width=""match_parent""
            android:layout_height=""wrap_content""
            android:layout_weight=""0""
            android:orientation=""horizontal"" /&gt;
        &lt;FrameLayout
            android:id=""@+id/tabFrameLayout""
            android:layout_width=""match_parent""
            android:layout_height=""0dp""
            android:layout_weight=""1"" /&gt;
    &lt;/LinearLayout&gt;
&lt;/android.support.v4.app.FragmentTabHost&gt;

Fragment1.cs

using System;
using System.Collections.Generic;
using System.Linq;
using System.Text;


using Android.App;
using Android.Content;
using Android.OS;
using Android.Runtime;
using Android.Util;
using Android.Views;
using Android.Widget;


namespace ANRestaurant.Forms
{
public class Fragment1 : Fragment
{



    public override void OnCreate(Bundle savedInstanceState)
    {
        base.OnCreate(savedInstanceState);


        // Create your fragment here
    }
    public override View OnCreateView(LayoutInflater inflater, ViewGroup container, Bundle savedInstanceState)
    {
        View view = inflater.Inflate(Resource.Layout.fragment1, container, false);
       return view;
         //return base.OnCreateView(inflater, container, savedInstanceState);
    }
}
}


ٍError Is :
Java.Lang.NullPointerException: Exception of type  Java.Lang.NullPointerException  was thrown.
at Android.Runtime.JNIEnv.CallVoidMethod (IntPtr jobject, IntPtr jmethod, Android.Runtime.JValue[] parms) 
",Ali Naiemabadi,https://stackoverflow.com/users/4019504,"I have done that by :
changing :

mTabHost.AddTab(spec);

To :

mTabHost.Setup(this, SupportFragmentManager, Resource.Id.tabFrameLayout);
mTabHost.AddTab(spec, Java.Lang.Class.FromType(typeof(Fragment1)), null);

End!
",Ali Naiemabadi,https://stackoverflow.com/users/4019504,http://stackoverflow.com/questions/25726932/fragmenttabhost-in-vs2013-xamarin-c-sharp,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.3333333333333333,0.0,1.0,0.6666666666666666,1.0,0.6666666666666666,0.4444444444444444,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.3333333333333333,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,0.8888888888888888,Fragment host in vs2013 - xamarin C#,"the code i used to create FragmentTabHost :( i am designing for android 2.2 to upper)
i have googled a lot but no use so
i have placed all of my code here.
I get error in :

   mTabHost.AddTab(spec);


please help how to solve ??

Activity 2.cs

using System;
using System.Collections.Generic;
using System.Linq;
using System.Text;


using Android.App;
using Android.Content;
using Android.OS;
using Android.Runtime;
using Android.Views;
using Android.Widget;
using Android.Content.PM;
using Android.Support.V4.App;


namespace ANRestaurant.Forms
{
[Activity(Label = ""ANRestaurant"", MainLauncher = true, Icon = ""@drawable/icon"", ScreenOrientation = ScreenOrientation.Portrait)]


public class Activity2 : FragmentActivity
{
    FragmentTabHost mTabHost;
    protected override void OnCreate(Bundle bundle)
    {
        base.OnCreate(bundle);


        SetContentView(Resource.Layout.activity_main);
        try
        {
            mTabHost = FindViewById&lt;FragmentTabHost&gt;(Resource.Id.tabhostN  );
            Intent intent;
            intent = new Intent(this, typeof(Fragment1));
            intent.AddFlags(ActivityFlags.NewTask);
            //mTabHost.Setup(this, SupportFragmentManager, Resource.Id.tabFrameLayout);


            TabHost.TabSpec spec;
            spec = mTabHost.NewTabSpec(""artists"");
            spec.SetIndicator(""Artists"", Resources.GetDrawable(Resource.Drawable.tab_icon1)  );
            spec.SetContent(intent);
            mTabHost.AddTab(spec);   ======&gt;Here is the error
            //mTabHost.AddTab(
            //        mTabHost.NewTabSpec(""tab2"").SetIndicator(""Tab 2"", null),
            //       intent, null);
            //mTabHost.addTab(
            //        mTabHost.newTabSpec(""tab2"").setIndicator(""Tab 2"", null),
            //        FragmentTab.class, null);
            //mTabHost.addTab(
            //        mTabHost.newTabSpec(""tab3"").setIndicator(""Tab 3"", null),
            //        FragmentTab.class, null);
        }
        catch (Exception ex)
        {


        }
    }
}
}


activity_main.axml

&lt;?xml version=""1.0"" encoding=""utf-8""?&gt;
&lt;android.support.v4.app.FragmentTabHost xmlns:android=""http://schemas.android.com/apk/res/android""
    android:id=""@+id/tabhostN""
    android:layout_width=""match_parent""
    android:layout_height=""match_parent""&gt;
    &lt;LinearLayout
        android:layout_width=""match_parent""
        android:layout_height=""match_parent""
        android:orientation=""vertical""&gt;
        &lt;TabWidget
            android:id=""@+id/tabs""
            android:layout_width=""match_parent""
            android:layout_height=""wrap_content""
            android:layout_weight=""0""
            android:orientation=""horizontal"" /&gt;
        &lt;FrameLayout
            android:id=""@+id/tabFrameLayout""
            android:layout_width=""match_parent""
            android:layout_height=""0dp""
            android:layout_weight=""1"" /&gt;
    &lt;/LinearLayout&gt;
&lt;/android.support.v4.app.FragmentTabHost&gt;

Fragment1.cs

using System;
using System.Collections.Generic;
using System.Linq;
using System.Text;


using Android.App;
using Android.Content;
using Android.OS;
using Android.Runtime;
using Android.Util;
using Android.Views;
using Android.Widget;


namespace ANRestaurant.Forms
{
public class Fragment1 : Fragment
{



    public override void OnCreate(Bundle savedInstanceState)
    {
        base.OnCreate(savedInstanceState);


        // Create your fragment here
    }
    public override View OnCreateView(LayoutInflater inflater, ViewGroup container, Bundle savedInstanceState)
    {
        View view = inflater.Inflate(Resource.Layout.fragment1, container, false);
       return view;
         //return base.OnCreateView(inflater, container, savedInstanceState);
    }
}
}


ٍError Is :
Java.Lang.NullPointerException: Exception of type  Java.Lang.NullPointerException  was thrown.
at Android.Runtime.JNIEnv.CallVoidMethod (IntPtr jobject, IntPtr jmethod, Android.Runtime.JValue[] parms) 
","I have done that by :
changing :

mTabHost.AddTab(spec);

To :

mTabHost.Setup(this, SupportFragmentManager, Resource.Id.tabFrameLayout);
mTabHost.AddTab(spec, Java.Lang.Class.FromType(typeof(Fragment1)), null);

End!
"
1518,1518,2386,How does an embryo know where to grow limbs etc,"For example you have a cell or already a bunch of cells. Those cell(s) divide and after several week you have a grown organism, for example a human with limbs, several different organs etc. 
However, how do cells know where up, down, left, right etc. is?
I know left and right can be defined clearly in physics. However how do cells define those directions and what are mechanisms for them to grow into a certain direction? 
Is there a paper or a longer article dealing with that question/problem?

I don't think my knowledge on Biology goes far beyond high school level maybe 1. term at a university. If I have to, I would read and learn everything I need to know to understand the matter. 
",Imago,https://biology.stackexchange.com/users/9370,"yea the hox genes are essential for the the specification of the location but the actual growing of the limbs are determined by a series of protein and other factors. proximal limb contains fgf(fibroblast growth factors) wnt(look up wnt pathway) and high levels of retonic acid where distal limbs shows high fgf's high wnt and little to none RA. the sonic the hedgehog gene talked about in the other answer has to to do with the anteriorizing(up)/posteriozing(down) of the autopod(digits, carpals). as to dorsal ventral wnt would be the culprit
",Mario Diaz,https://biology.stackexchange.com/users/10513,http://biology.stackexchange.com/questions/21881/how-does-an-embryo-know-where-to-grow-limbs-etc,SCIENCE,biology.stackexchange.com,0.8888888888888888,0.6666666666666666,0.0,0.0,1.0,1.0,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.7777777777777778,0.8888888888888888,0.5555555555555556,1.0,1.0,0.8666666666666666,0.0,0.0,1.0,0.6666666666666666,"How do embryos know where to grow limbs, etc","For example you have a cell or already a bunch of cells. Those cell(s) divide and after several week you have a grown organism, for example a human with limbs, several different organs etc. 
However, how do cells know where up, down, left, right etc. is?
I know left and right can be defined clearly in physics. However how do cells define those directions and what are mechanisms for them to grow into a certain direction? 
Is there a paper or a longer article dealing with that question/problem?

I don't think my knowledge on Biology goes far beyond high school level maybe 1. term at a university. If I have to, I would read and learn everything I need to know to understand the matter. 
","yea the hox genes are essential for the the specification of the location but the actual growing of the limbs are determined by a series of protein and other factors. proximal limb contains fgf(fibroblast growth factors) wnt(look up wnt pathway) and high levels of retonic acid where distal limbs shows high fgf's high wnt and little to none RA. the sonic the hedgehog gene talked about in the other answer has to to do with the anteriorizing(up)/posteriozing(down) of the autopod(digits, carpals). as to dorsal ventral wnt would be the culprit
"
1297,1297,2044,Removing blanks from a column in Excel,"
",Mike,https://superuser.com/users/79906,"Could you sort the data in its existing location?
",Diem,https://superuser.com/users/66246,http://superuser.com/questions/271627,TECHNOLOGY,superuser.com,1.0,1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.6,1.0,0.0,0.0,0.6666666666666666,Remove blanks from columns in Excel,"
","Could you sort the data in its existing location?
"
2041,2041,3251,Translate C code to assembly code?,"I have to translate this C code to assembly code:

 #include &lt;stdio.h&gt;

 int main(){

 int a, b,c;
 scanf(""%d"",&amp;a);
 scanf(""%d"",&amp;b);
 if (a == b){
   b++;
 } 
 if (a &gt; b){
  c = a;
  a = b;
  b = c;    
 }
 printf(""%d\n"",b-a);
 return 0;
 }  


My code is below, and incomplete.

    rdint %eax        # reading a
    rdint %ebx        # reading b
    irmovl $1, %edi

    subl %eax,%ebx
    addl %ebx, %edi
    je Equal


    irmov1 %eax, %efx  #flagged as invalid line
    irmov1 %ebx, %egx
    irmov1 %ecx, %ehx
    irmovl $0, %eax
    irmovl $0, %ebx
    irmovl $0, %ecx

    addl %eax, %efx    #flagged as invalid line
    addl %ebx, %egx
    addl %ecx, %ehx



    halt


Basically I think it is mostly done, but I have commented next to two lines flagged as invalid when I try to run it, but I'm not sure why they are invalid.  I'm also not sure how to do an if statment for  a > b.  I could use any suggestions from people who know about y86 assembly language.
",user1261445,https://stackoverflow.com/users/1261445,"Jens,

First, Y86 does not have any efx, egx, and ehx registers, which is why you are getting the invalid lines when you pour the code through YAS.

Second, you make conditional branches by subtracting two registers using the subl instruction and jumping on the condition code set by the Y86 ALU by ways of the jxx instructions.

Check my blog at http://y86tutoring.wordpress.com for details.
",pajacobsen,https://stackoverflow.com/users/1804487,http://stackoverflow.com/questions/11422895/translate-c-code-to-assembly-code,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.4444444444444444,0.0,1.0,1.0,1.0,0.5555555555555556,0.5555555555555556,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.8888888888888888,Translate C code into assembly code?,"I have to translate this C code to assembly code:

 #include &lt;stdio.h&gt;

 int main(){

 int a, b,c;
 scanf(""%d"",&amp;a);
 scanf(""%d"",&amp;b);
 if (a == b){
   b++;
 } 
 if (a &gt; b){
  c = a;
  a = b;
  b = c;    
 }
 printf(""%d\n"",b-a);
 return 0;
 }  


My code is below, and incomplete.

    rdint %eax        # reading a
    rdint %ebx        # reading b
    irmovl $1, %edi

    subl %eax,%ebx
    addl %ebx, %edi
    je Equal


    irmov1 %eax, %efx  #flagged as invalid line
    irmov1 %ebx, %egx
    irmov1 %ecx, %ehx
    irmovl $0, %eax
    irmovl $0, %ebx
    irmovl $0, %ecx

    addl %eax, %efx    #flagged as invalid line
    addl %ebx, %egx
    addl %ecx, %ehx



    halt


Basically I think it is mostly done, but I have commented next to two lines flagged as invalid when I try to run it, but I'm not sure why they are invalid.  I'm also not sure how to do an if statment for  a > b.  I could use any suggestions from people who know about y86 assembly language.
","Jens,

First, Y86 does not have any efx, egx, and ehx registers, which is why you are getting the invalid lines when you pour the code through YAS.

Second, you make conditional branches by subtracting two registers using the subl instruction and jumping on the condition code set by the Y86 ALU by ways of the jxx instructions.

Check my blog at http://y86tutoring.wordpress.com for details.
"
5589,5589,8870,What does “sign the final flourish” mean?,"There was the following sentence in Time magazine’s a bit old  article (December 11, 2013) titled, “Pope Francis, the people’s Pope,” in which I was drawn to the phrase, “sign the final flourish”: 


  “He returned o Buenos Aires and looked to retirement. - - He handed
  his letter of resignation to the Pope when he turned 75 in 2011.”I’m
  starting to consider the fact that I have to leave everything behind,”
  he said in 2010. “It makes me want to be fair with everyone always, to
  sign the final flourish ... But death is my thought every day.” He
  insisted he was not sad, and he went on posing for pictures with the
  faithful.”
  
  http://poy.time.com/2013/12/11/person-of-the-year-pope-francis-the-peoples-pope/


I thought “sign the flourish” an idiom, but I don’t find the phrase in dictionaries I use to consult, or on Google.”  

I wondered if it’s similar with Japanese idiom, “一花咲かせる－hitohana sakaseru” meaning to bloom the last blossoms at the ending, at the last stage of one's career, or before retiring, like a baseball player who passed his peak hitting a streak of homeruns before retiring, but then, the word, “sign” seems to be incongruent.

Or, does “sign the flourish” mean “sign by using decorated-letters”?

What does the phrase, Pope wanted to “sign the final flourish” mean?
",Yoichi Oishi,https://english.stackexchange.com/users/3119,"When you sign something with a flourish you make a kind of bold dramatic motion of the pen. 

I think it's a metaphor to living the end of his life, and how he would like to deal with it, in style and displaying good character. 
",Spehro Pefhany,https://english.stackexchange.com/users/63274,http://english.stackexchange.com/questions/156325/what-does-sign-the-final-flourish-mean,CULTURE,english.stackexchange.com,1.0,0.8888888888888888,0.0,1.0,1.0,1.0,0.5555555555555556,0.6666666666666666,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,0.3333333333333333,1.0,What does it mean to sign the final boom?,"There was the following sentence in Time magazine’s a bit old  article (December 11, 2013) titled, “Pope Francis, the people’s Pope,” in which I was drawn to the phrase, “sign the final flourish”: 


  “He returned o Buenos Aires and looked to retirement. - - He handed
  his letter of resignation to the Pope when he turned 75 in 2011.”I’m
  starting to consider the fact that I have to leave everything behind,”
  he said in 2010. “It makes me want to be fair with everyone always, to
  sign the final flourish ... But death is my thought every day.” He
  insisted he was not sad, and he went on posing for pictures with the
  faithful.”
  
  http://poy.time.com/2013/12/11/person-of-the-year-pope-francis-the-peoples-pope/


I thought “sign the flourish” an idiom, but I don’t find the phrase in dictionaries I use to consult, or on Google.”  

I wondered if it’s similar with Japanese idiom, “一花咲かせる－hitohana sakaseru” meaning to bloom the last blossoms at the ending, at the last stage of one's career, or before retiring, like a baseball player who passed his peak hitting a streak of homeruns before retiring, but then, the word, “sign” seems to be incongruent.

Or, does “sign the flourish” mean “sign by using decorated-letters”?

What does the phrase, Pope wanted to “sign the final flourish” mean?
","When you sign something with a flourish you make a kind of bold dramatic motion of the pen. 

I think it's a metaphor to living the end of his life, and how he would like to deal with it, in style and displaying good character. 
"
748,748,1184,"Without using dowels, how do I join 2x4s edge to edge to be 1.5"" x 7""?","I am trying to join a 2x4 supporting a workbench tabletop to another to make a backsplash of sorts. Any ideas how to do this without dowels? (No, I can't use 2x8)


",Jens Turner,https://diy.stackexchange.com/users/15656,"Strapping

You could use some form of strapping on the back side.



With this option, you can extend the strapping and use it to attach the whole bit to the workbench.



Bored Holes

You could bore holes on the edge of the top or bottom piece to about half the width of the board, then use screws to fasten the two boards together.



You'll likely want to use a drill press to bore the holes.

Glue

Since it's not going to be structural, you could simply glue the two boards together using wood glue.



Sliding Dovetail

If you want to get real fancy, a sliding dovetail would work.



Though with this joint, you'll loose a bit of overall height.
",Tester101,https://diy.stackexchange.com/users/33,http://diy.stackexchange.com/questions/32868/without-using-dowels-how-do-i-join-2x4s-edge-to-edge-to-be-1-5-x-7,LIFE_ARTS,diy.stackexchange.com,1.0,0.7777777777777778,0.0,1.0,0.3333333333333333,1.0,0.6666666666666666,0.4444444444444444,0.3333333333333333,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,1.0,"How do I connect 2x4s edge to edge as 1.5 ""x 7"" without the use of dowels?","I'm trying to add a 2x4 support to one workbench desktop to another, to make one backward. Is there any way to do it without pins? (no, I can't use 2x8)","Strapping

You could use some form of strapping on the back side.



With this option, you can extend the strapping and use it to attach the whole bit to the workbench.



Bored Holes

You could bore holes on the edge of the top or bottom piece to about half the width of the board, then use screws to fasten the two boards together.



You'll likely want to use a drill press to bore the holes.

Glue

Since it's not going to be structural, you could simply glue the two boards together using wood glue.



Sliding Dovetail

If you want to get real fancy, a sliding dovetail would work.



Though with this joint, you'll loose a bit of overall height.
"
874,874,1387,Add class via command line,"Classes can be added to an Android project in Eclipse via New -> Class, and this will supposedly add it to the project somehow, but how can I do this via the command line? I set up the class in src/(reverse.dns.path)/CLASS.java, but I couldn't find anything in http://developer.android.com/tools/building/building-cmdline.html, but I would appreciate any guidance
",Marco Scannadinari,https://stackoverflow.com/users/1526894,"There are no tools to create java classes in an Android project. You can however create a new android project with the sdk tools and modify it to some extent. 

Well, if you really want to do it via the command line:

$ cd myapplication/
$ cd src/
$ cd main/java/my/package/name/


Create the java class:

$ touch SomeClass.java


Add package and the class declaration to the java file:

$ echo ""package my.package.name;"" &gt;&gt; SomeClass.java 
$ echo ""public class SomeClass {}"" &gt;&gt; SomeClass.java 


If you want to create another package:

$ mkdir somepackage
$ cd somepackage
$ touch AnotherClass.java


Now if you go into Eclipse everything should be updated.
",Ahmad,https://stackoverflow.com/users/1333975,http://stackoverflow.com/questions/27583357/add-class-via-command-line,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.4444444444444444,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,0.0,0.8888888888888888,Adding classes from the command line,"Classes can be added to Android projects in eclipse through new - > class, which may be added to projects in some way, but how can I do this from the command line? I set this class in Src / (reverse. DNS. Path) / class. Java, but I can't find anything in http://developer.android.com/tools/building/building-cmdline.html, but I want to get any guidance","There are no tools to create java classes in an Android project. You can however create a new android project with the sdk tools and modify it to some extent. 

Well, if you really want to do it via the command line:

$ cd myapplication/
$ cd src/
$ cd main/java/my/package/name/


Create the java class:

$ touch SomeClass.java


Add package and the class declaration to the java file:

$ echo ""package my.package.name;"" &gt;&gt; SomeClass.java 
$ echo ""public class SomeClass {}"" &gt;&gt; SomeClass.java 


If you want to create another package:

$ mkdir somepackage
$ cd somepackage
$ touch AnotherClass.java


Now if you go into Eclipse everything should be updated.
"
4705,4705,7459,How to mount a NTFS USB harddrive to Mac OS X that was unsave removed from Windows?,"I have a hard drive that gets plugged into several machines. One MacBook Pro running Mac OS X, some Ubuntu and Fedora Installations and sometimes Windows XP or Vista. Therefore, I formatted it NTFS to be able to read and write on it no matter which machine is used. On Mac OS I installed MacFUSE to do this. 

The Problem is, when the USB device is removed from a Windows box, without using the ""remove hardware"" function from the task bar, the drive is locked. When I wnat to mount it in Mac OS, I get an error message and have to connect it to back to Windows and cleanly unmount it.

So, my question is: Is there an easy way to use the drive on every computer / OS without mounting problems? 
",Tim Büthe,https://superuser.com/users/3124,"You'll have to have a Windows system handy to have unlocked.  That's the only way I've heard of fixing this issue.

On a related note, unsafely removing a drive from MacOS X can lead to locking, for which I could not find a Mac-native solution.  That was hell in a handbasket to fix.
",Andrew Scagnelli,https://superuser.com/users/3128,http://superuser.com/questions/10024,TECHNOLOGY,superuser.com,0.8888888888888888,0.7777777777777778,0.0,0.0,1.0,0.3333333333333333,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.8888888888888888,1.0,0.8888888888888888,1.0,1.0,0.8666666666666666,1.0,0.6666666666666666,0.3333333333333333,1.0,How do I install an unsaved NTFS USB hard disk removed from windows to Mac OS X?,"I have a hard drive that gets plugged into several machines. One MacBook Pro running Mac OS X, some Ubuntu and Fedora Installations and sometimes Windows XP or Vista. Therefore, I formatted it NTFS to be able to read and write on it no matter which machine is used. On Mac OS I installed MacFUSE to do this. 

The Problem is, when the USB device is removed from a Windows box, without using the ""remove hardware"" function from the task bar, the drive is locked. When I wnat to mount it in Mac OS, I get an error message and have to connect it to back to Windows and cleanly unmount it.

So, my question is: Is there an easy way to use the drive on every computer / OS without mounting problems? 
","You'll have to have a Windows system handy to have unlocked.  That's the only way I've heard of fixing this issue.

On a related note, unsafely removing a drive from MacOS X can lead to locking, for which I could not find a Mac-native solution.  That was hell in a handbasket to fix.
"
1284,1284,2026,Squid proxy: how to link inbound IPv4+port to outbound IPv6,"I'm trying to setup a squid proxy that will accept multiple inbound connections on one IPv4 across a range of ports, and for each port connection to connect out on a unique IPv6 address.

I've named each port connection, and designated an ACL based on the connection name, and then I've tried to define an outgoing IPv6 for each. The script below works, in that it accepts connections on the different ports and routes out via IPv6 however, all outbound connections use the same IPv6 (user5) even though there are different ipv6 defined per user - the wierd bit is that even if I comment-out that user5 IPv6 from squid.conf, it still gets used for outbound connections.

Can anyone see whats wrong here? (using Squid 3.1.1 on Centos 6 64bit)

## declare an acl that is true for all ipv6 destinations
acl to_ipv6 dst ipv6

##tell Squid to listen on sequential ports and to designate a name for each inbound     connection. 
http_port 241.xxx.xxx.101:3128 name=3128
http_port 241.xxx.xxx.101:3129 name=3129
http_port 241.xxx.xxx.101:3130 name=3130
http_port 241.xxx.xxx.101:3131 name=3131
http_port 241.xxx.xxx.101:3132 name=3132

## designate acl based on inbound connection name
acl user1 myportname 3128 
acl user2 myportname 3129 
acl user3 myportname 3130 
acl user4 myportname 3131 
acl user5 myportname 3132 

## define outgoing IPv6 per user
tcp_outgoing_address [2001:::::::ipv61] user1
tcp_outgoing_address [2001:::::::ipv62] user2
tcp_outgoing_address [2001:::::::ipv63] user3
tcp_outgoing_address [2001:::::::ipv64] user4
##tcp_outgoing_address [2001:::::ipv65] user5
##this last IPv6 always gets used for all outbound connections, even if commented out

",user2408290,https://serverfault.com/users/174755,"In Squid 3.1 you need the to_ipv6 directive after each tcp_outgoing_address line. If you upgrade to 3.2 you won't encounter this problem.

Reference: http://www.squid-cache.org/Doc/config/tcp_outgoing_address/
",Nathan C,https://serverfault.com/users/173547,http://serverfault.com/questions/509785,TECHNOLOGY,serverfault.com,1.0,0.4444444444444444,0.0,0.6666666666666666,0.3333333333333333,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,0.0,0.8888888888888888,Squid agent: how to link an inbound IPv4 + port to an outbound IPv6,"I'm trying to setup a squid proxy that will accept multiple inbound connections on one IPv4 across a range of ports, and for each port connection to connect out on a unique IPv6 address.

I've named each port connection, and designated an ACL based on the connection name, and then I've tried to define an outgoing IPv6 for each. The script below works, in that it accepts connections on the different ports and routes out via IPv6 however, all outbound connections use the same IPv6 (user5) even though there are different ipv6 defined per user - the wierd bit is that even if I comment-out that user5 IPv6 from squid.conf, it still gets used for outbound connections.

Can anyone see whats wrong here? (using Squid 3.1.1 on Centos 6 64bit)

## declare an acl that is true for all ipv6 destinations
acl to_ipv6 dst ipv6

##tell Squid to listen on sequential ports and to designate a name for each inbound     connection. 
http_port 241.xxx.xxx.101:3128 name=3128
http_port 241.xxx.xxx.101:3129 name=3129
http_port 241.xxx.xxx.101:3130 name=3130
http_port 241.xxx.xxx.101:3131 name=3131
http_port 241.xxx.xxx.101:3132 name=3132

## designate acl based on inbound connection name
acl user1 myportname 3128 
acl user2 myportname 3129 
acl user3 myportname 3130 
acl user4 myportname 3131 
acl user5 myportname 3132 

## define outgoing IPv6 per user
tcp_outgoing_address [2001:::::::ipv61] user1
tcp_outgoing_address [2001:::::::ipv62] user2
tcp_outgoing_address [2001:::::::ipv63] user3
tcp_outgoing_address [2001:::::::ipv64] user4
##tcp_outgoing_address [2001:::::ipv65] user5
##this last IPv6 always gets used for all outbound connections, even if commented out

","In Squid 3.1 you need the to_ipv6 directive after each tcp_outgoing_address line. If you upgrade to 3.2 you won't encounter this problem.

Reference: http://www.squid-cache.org/Doc/config/tcp_outgoing_address/
"
5035,5035,8012,How to get the posts published in last two days using WP_Query?,"I am trying to loop through all the post to get the top most shared posts on social network. I want to use the date_query parameter in the WP_query to get the posts of last two days , last 5 days, last 7 days and last 9 days. How can i implement it through using the date_query in WP_Query 
My WP_query is

&lt;?php
 $args = array(
  'post_type' =&gt; 'post',
  'order'=&gt;'DESC',
  'posts_per_page' =&gt; 1,
  'date_query' =&gt; array(
                     array(
        'after'     =&gt; '10 days ago',
        'inclusive' =&gt; true,
       ),
     ),
  'orderby'=&gt;'meta_value',
  'meta_key'=&gt;'esml_socialcount_TOTAL'
  );
 $the_query = new WP_Query($args);
 if($the_query-&gt;have_posts()) { 
 while ($the_query-&gt;have_posts()){$the_query-&gt;the_post();
?&gt;

",Harman Preet,https://wordpress.stackexchange.com/users/56650,"Here are two ideas for your date_query part:

1) After 2 days ago:

If you need posts published after current time, 2 days ago:

'date_query' =&gt; array(
     array(
         'after'     =&gt; '2 days ago',  // or '-2 days'
         'inclusive' =&gt; true,
     ),
 ),


then the corresponding SQL part is:

 post_date &gt;= '2014-09-09 17:57:15'


if the current date-time is 2014-09-11 17:57:15.

2) After midnight 2 days ago :

If you need posts published after midnight, 2 days ago:

'date_query' =&gt; array(
     array(
         'after'     =&gt; 'midnight 2 days ago',
         'inclusive' =&gt; true,
     ),
 ),


then the corresponding SQL part is:

 post_date &gt;= '2014-09-09 00:00:00'


if the current date-time is 2014-09-11 17:57:15.

You can than easily modify this to other day periods.
",birgire,https://wordpress.stackexchange.com/users/26350,http://wordpress.stackexchange.com/questions/161080/how-to-get-the-posts-published-in-last-two-days-using-wp-query,TECHNOLOGY,wordpress.stackexchange.com,0.6666666666666666,0.8333333333333334,0.0,1.0,0.5,0.5,0.8333333333333334,0.6666666666666666,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.5,0.5,0.0,0.0,0.6666666666666666,0.8333333333333334,0.6666666666666666,0.6666666666666666,1.0,0.9,1.0,0.0,0.0,0.6666666666666666,How to use WP? Query to get Posts published in the last two days?,"I am trying to loop through all the post to get the top most shared posts on social network. I want to use the date_query parameter in the WP_query to get the posts of last two days , last 5 days, last 7 days and last 9 days. How can i implement it through using the date_query in WP_Query 
My WP_query is

&lt;?php
 $args = array(
  'post_type' =&gt; 'post',
  'order'=&gt;'DESC',
  'posts_per_page' =&gt; 1,
  'date_query' =&gt; array(
                     array(
        'after'     =&gt; '10 days ago',
        'inclusive' =&gt; true,
       ),
     ),
  'orderby'=&gt;'meta_value',
  'meta_key'=&gt;'esml_socialcount_TOTAL'
  );
 $the_query = new WP_Query($args);
 if($the_query-&gt;have_posts()) { 
 while ($the_query-&gt;have_posts()){$the_query-&gt;the_post();
?&gt;

","Here are two ideas for your date_query part:

1) After 2 days ago:

If you need posts published after current time, 2 days ago:

'date_query' =&gt; array(
     array(
         'after'     =&gt; '2 days ago',  // or '-2 days'
         'inclusive' =&gt; true,
     ),
 ),


then the corresponding SQL part is:

 post_date &gt;= '2014-09-09 17:57:15'


if the current date-time is 2014-09-11 17:57:15.

2) After midnight 2 days ago :

If you need posts published after midnight, 2 days ago:

'date_query' =&gt; array(
     array(
         'after'     =&gt; 'midnight 2 days ago',
         'inclusive' =&gt; true,
     ),
 ),


then the corresponding SQL part is:

 post_date &gt;= '2014-09-09 00:00:00'


if the current date-time is 2014-09-11 17:57:15.

You can than easily modify this to other day periods.
"
4623,4623,7331,What platform can I use to establish a users support forum?,"I was asked to develop a users support community forum for a small and young hi-tech company. This kind of forums is very popular with companies these days and is a great alternative to the official product support lines. An example of what we look for is the Analog Devices' Engineer Zone forums.

I am totally noob to this area so any advice will be appreciated - how to start developing such a site, what platforms are available (preferably open-source/free) and what are the advantages and disadvantages of these platforms.

Is a stackexchange style forum appropriate for such site?

* If you think there is a better SE site to post this question, please let me know.
",ysap,https://webmasters.stackexchange.com/users/9535,"A stackexchange style forum would be appropriate for this site (although there are many many other support forums out there). For a list of clones see this meta.stackexchange.com answer. The stackexchange model is designed around users helping users, but if your staff can take part then that's even better. If I were you I'd tweak the code so that users that are staff are clearly identified as such.
",paulmorriss,https://webmasters.stackexchange.com/users/1643,http://webmasters.stackexchange.com/questions/18090/what-platform-can-i-use-to-establish-a-users-support-forum,TECHNOLOGY,webmasters.stackexchange.com,0.8888888888888888,0.4444444444444444,0.0,0.3333333333333333,1.0,0.3333333333333333,0.6666666666666666,0.4444444444444444,0.6666666666666666,0.0,0.6666666666666666,0.0,0.6666666666666666,0.0,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.0,0.7777777777777778,0.6666666666666666,0.4444444444444444,0.7777777777777778,0.7777777777777778,0.5333333333333333,0.0,0.3333333333333333,0.6666666666666666,0.7777777777777778,What platform can I use to set up user support forum?,"I was asked to develop a users support community forum for a small and young hi-tech company. This kind of forums is very popular with companies these days and is a great alternative to the official product support lines. An example of what we look for is the Analog Devices' Engineer Zone forums.

I am totally noob to this area so any advice will be appreciated - how to start developing such a site, what platforms are available (preferably open-source/free) and what are the advantages and disadvantages of these platforms.

Is a stackexchange style forum appropriate for such site?

* If you think there is a better SE site to post this question, please let me know.
","Stackexchange style forums are suitable for this site (although there are many other support forums). For a list of clones, see meta.stackexchange.com answers. The stackexchange model is designed to help users, but it's better if your employees can participate. If I were you, I would adjust the code so that users as employees can be clearly identified."
3852,3852,6123,Computer browsing not working,"We have multiple computers joined in domain. We also have domain controller (Windows server 2008 Enterprise). 

The problem is, that sometimes computer browsing (Windows Explorer: My Network Places/Entire Network/MS Windows Network) works and sometimes doesn't.

Restarting Computer browser on domain controller helps poorly - usually not.

If users type other computer's name like Start/run: 
\\computer1
computer is accessible.  

What seems to be the problem?



We already have WINS server installed. 


",user1452932,https://serverfault.com/users/124494,"DNS doesn't facilitate network browsing. NetBIOS facilitates network browsing.

Network browsing has never been ""reliable"" in the sense that the list of computers is always accurate and complete.

If you want to have an accurate and complete list of computers while browsing the network then you'll have to implement a WINS server.

Personally, I don't understand why this is an issue. Why is it important that users be able to browse an accurate and complete list of computers on the network? Do they not know where resources are (shared folders and printers) and need to browse the network to find them? If so, that's poor infrastructure design and management, IMO.
",joeqwerty,https://serverfault.com/users/19152,http://serverfault.com/questions/436362,TECHNOLOGY,serverfault.com,0.8888888888888888,0.4444444444444444,0.0,1.0,1.0,1.0,0.5555555555555556,0.5555555555555556,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,1.0,0.0,0.6666666666666666,0.8888888888888888,0.7777777777777778,1.0,1.0,0.8,0.3333333333333333,0.0,1.0,0.8888888888888888,Computer browsing does not work,"We have multiple computers joined in domain. We also have domain controller (Windows server 2008 Enterprise). 

The problem is, that sometimes computer browsing (Windows Explorer: My Network Places/Entire Network/MS Windows Network) works and sometimes doesn't.

Restarting Computer browser on domain controller helps poorly - usually not.

If users type other computer's name like Start/run: 
\\computer1
computer is accessible.  

What seems to be the problem?



We already have WINS server installed. 


","DNS doesn't facilitate network browsing. NetBIOS facilitates network browsing.

Network browsing has never been ""reliable"" in the sense that the list of computers is always accurate and complete.

If you want to have an accurate and complete list of computers while browsing the network then you'll have to implement a WINS server.

Personally, I don't understand why this is an issue. Why is it important that users be able to browse an accurate and complete list of computers on the network? Do they not know where resources are (shared folders and printers) and need to browse the network to find them? If so, that's poor infrastructure design and management, IMO.
"
5152,5152,8189,How to increase saturation or intensity of this printed pattern,"


The image on the left is what I see on my monitor ( CMYK Vector )
The image on the right was produced using flexography for a packaging design


The image on the right is dull and murky and doesn't 'pop' as much as it should. I think the yellow is the issue. Is it a possibility that my printer is at fault? Could I ask them to increase the % of yellow?

Would a matte or glossy finishing technique help?

OR is the design itself the issue with too many gradients making it hard to accurately reproduce through print?
",Cool Brian,https://graphicdesign.stackexchange.com/users/30296,"What you see on your monitor is RGB. Yes, it's a CMYK file, and it's likely trying to compensate, but it's still using an RGB model.

As such, what you see on screen is usually always more vibrant/saturated than what CMYK can produce. This is due to the reproducible colors being different in each color space: 



Using coated paper and/or applying a top-coat can certainly help your CMYK print look brighter, but ultimately, you are at the mercy of what CMYK can do. 

At this point, you need to talk to your printer and get their feedback. They may be able to tweak the file to accommodate. Alternatively, if it is yellow that is the issue, perhaps they can swap Y for a more vibrant Pantone Spot Yellow. 
",DA01,https://graphicdesign.stackexchange.com/users/306,http://graphicdesign.stackexchange.com/questions/56417/how-to-increase-saturation-or-intensity-of-this-printed-pattern,LIFE_ARTS,graphicdesign.stackexchange.com,0.7777777777777778,0.5555555555555556,0.6666666666666666,0.0,1.0,1.0,0.7777777777777778,0.6666666666666666,1.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.3333333333333333,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8666666666666666,0.6666666666666666,0.0,1.0,0.8888888888888888,How to increase the saturation or intensity of this pattern,"


The image on the left is what I see on my monitor ( CMYK Vector )
The image on the right was produced using flexography for a packaging design


The image on the right is dull and murky and doesn't 'pop' as much as it should. I think the yellow is the issue. Is it a possibility that my printer is at fault? Could I ask them to increase the % of yellow?

Would a matte or glossy finishing technique help?

OR is the design itself the issue with too many gradients making it hard to accurately reproduce through print?
","What you see on your monitor is RGB. Yes, it's a CMYK file, and it's likely trying to compensate, but it's still using an RGB model.

As such, what you see on screen is usually always more vibrant/saturated than what CMYK can produce. This is due to the reproducible colors being different in each color space: 



Using coated paper and/or applying a top-coat can certainly help your CMYK print look brighter, but ultimately, you are at the mercy of what CMYK can do. 

At this point, you need to talk to your printer and get their feedback. They may be able to tweak the file to accommodate. Alternatively, if it is yellow that is the issue, perhaps they can swap Y for a more vibrant Pantone Spot Yellow. 
"
3504,3504,5590,"Clicking ""Add comment"" fails review audit","I just failed these review audits in First Post, I read the question and thought it seemed reasonable but the user was deleted so to be on the safe side I clicked add comment and I failed the audit.

I'm not sure why adding a comment would be considered a negative action, is the correct option to click No Action Needed or edit?

What was I supposed to do in this situation?  Adding a comment should not be a review audit fail.
",Aboutblank,https://meta.stackexchange.com/users/214833,"I understand the purpose of positive audits but I think the system is flawed. The good way to review is take time, read the post and understand it. When doing that, I find myself having all sorts off thoughts around the topic mentioned in the post. Sometimes I would like to add something. Sometimes I know a good link that would add to the post. Sometimes I would like to see clarification of some point which I believe could be expanded on. Comments are all suitable for that. I still think the post is good and I just want to comment on it so that it can become better.

Yet the system tries to stop me from doing that. It encourages me to only post comments on bad posts. My understanding is that comments don't work this way outside of the review system. We end up having to follow 2 sets of rules: one when reviewing and one outside of the review queue.

The same applies to edits in much lesser extend - edits of good posts are less warranted then comments (of the type mentioned above).
",Szymon,https://meta.stackexchange.com/users/234348,http://meta.stackexchange.com/questions/188885/clicking-add-comment-fails-review-audit,TECHNOLOGY,meta.stackexchange.com,0.7777777777777778,0.4444444444444444,0.0,1.0,1.0,1.0,0.6666666666666666,0.4444444444444444,0.6666666666666666,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.6666666666666666,0.0,0.7777777777777778,0.8333333333333334,0.6666666666666666,1.0,1.0,0.8,0.0,0.0,1.0,0.8888888888888888,"Click ""add comment"" to review failed","I just failed to pass these reviews in the first article. I read this question and thought it seemed reasonable, but the user was deleted, so for the sake of security, I clicked to add comments, and I failed to pass the review.","I understand the purpose of positive audits but I think the system is flawed. The good way to review is take time, read the post and understand it. When doing that, I find myself having all sorts off thoughts around the topic mentioned in the post. Sometimes I would like to add something. Sometimes I know a good link that would add to the post. Sometimes I would like to see clarification of some point which I believe could be expanded on. Comments are all suitable for that. I still think the post is good and I just want to comment on it so that it can become better.

Yet the system tries to stop me from doing that. It encourages me to only post comments on bad posts. My understanding is that comments don't work this way outside of the review system. We end up having to follow 2 sets of rules: one when reviewing and one outside of the review queue.

The same applies to edits in much lesser extend - edits of good posts are less warranted then comments (of the type mentioned above).
"
2362,2362,3766,How did Naruto call Shikamaru and the others during Obito's fight?,"Alert: This post contains spoilers. If you are not up-to-date to Naruto's manga, don't read it.

At chapter 651 of Naruto's manga, during the fight against Obito, Naruto called Shikamaru, Lee, Ino, Kiba and the others to join the fight and help him:



But what kind of jutsu did Naruto use to call them? Is he using the abilities of Yamanaka's clan or his own Kyuubi's chakra has this kind of power too? 
",Rikkin,https://anime.stackexchange.com/users/2251,"Recall when Naruto's feelings were relayed to everyone that he was sharing chakra with? That is his method of communication. Sharing the kyuubi chakra and transferring it to other shinobi establishes a link that lets them share thoughts with each other.
",krikara,https://anime.stackexchange.com/users/2178,http://anime.stackexchange.com/questions/5573/how-did-naruto-call-shikamaru-and-the-others-during-obitos-fight,CULTURE,anime.stackexchange.com,0.8888888888888888,0.7777777777777778,0.0,0.0,0.6666666666666666,1.0,0.7777777777777778,0.6666666666666666,0.3333333333333333,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,1.0,How do Naruto call ISHINOMAKI and others in the battle of Obito?,"Alert: This post contains spoilers. If you are not up-to-date to Naruto's manga, don't read it.

At chapter 651 of Naruto's manga, during the fight against Obito, Naruto called Shikamaru, Lee, Ino, Kiba and the others to join the fight and help him:



But what kind of jutsu did Naruto use to call them? Is he using the abilities of Yamanaka's clan or his own Kyuubi's chakra has this kind of power too? 
","Recall when Naruto's feelings were relayed to everyone that he was sharing chakra with? That is his method of communication. Sharing the kyuubi chakra and transferring it to other shinobi establishes a link that lets them share thoughts with each other.
"
2872,2872,4570,Why is it that the product of first N prime numbers + 1 another prime?,"Recently I came across this proof for fact that primes are infinite.

It's a proof by contradiction. The proof assumes that primes are finite and there is a prime M which is larger than any prime out there. Then you basically take the product of all primes up to and including M and you add one to it, which the source where I read this proof claims is a prime obviously larger than M hence a contradiction to our assumption that primes are finite.

So why is it that product of first N primes + 1 another prime? 
",user2340452,https://math.stackexchange.com/users/102019,"It is not necessarily another prime, but it is most definitely divisible by another prime.

For example, take $2\cdot3\cdot5\cdot7\cdot11\cdot13+1=30031$, which is not prime but divisible by $59$.

It cannot be divisible by any one of those first $N$ primes, so it has to be divisible by some other prime (or possibly, a prime by itself, which also qualifies under the same definition).
",barak manos,https://math.stackexchange.com/users/131263,http://math.stackexchange.com/questions/1380543/why-is-it-that-the-product-of-first-n-prime-numbers-1-another-prime,SCIENCE,math.stackexchange.com,0.6666666666666666,0.6666666666666666,0.0,0.3333333333333333,1.0,0.3333333333333333,0.7777777777777778,0.5555555555555556,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,1.0,0.5555555555555556,1.0,1.0,0.8666666666666666,0.3333333333333333,0.0,1.0,0.8888888888888888,Why is the product of the first n prime numbers and another prime number?,"Recently I came across this proof for fact that primes are infinite.

It's a proof by contradiction. The proof assumes that primes are finite and there is a prime M which is larger than any prime out there. Then you basically take the product of all primes up to and including M and you add one to it, which the source where I read this proof claims is a prime obviously larger than M hence a contradiction to our assumption that primes are finite.

So why is it that product of first N primes + 1 another prime? 
","It is not necessarily another prime, but it is most definitely divisible by another prime.

For example, take $2\cdot3\cdot5\cdot7\cdot11\cdot13+1=30031$, which is not prime but divisible by $59$.

It cannot be divisible by any one of those first $N$ primes, so it has to be divisible by some other prime (or possibly, a prime by itself, which also qualifies under the same definition).
"
4266,4266,6800,Mark: outstanding (as in: not yet known),"I’m updating my tabular CV for an application and I’d like to include my master thesis even though it’s not yet finished (soon!) and marked. So I’d like to write that the mark is still outstanding but I fear that if I simply write


  Master thesis: ‹topic›
  Supervisor: ‹supervisor›
  Mark: outstanding


this could be misconstrued to mean that the result is in, and that it’s outstanding (as in: spectacular). What can I say here instead? It should be as salient as possible, single word preferred. I specifically want to avoid writing half a sentence.
",Konrad Rudolph,https://english.stackexchange.com/users/1637,"I would go for “pending” (or, longer, “still pending”).
",F'x,https://english.stackexchange.com/users/3479,http://english.stackexchange.com/questions/9077/mark-outstanding-as-in-not-yet-known,CULTURE,english.stackexchange.com,0.8888888888888888,0.4444444444444444,0.3333333333333333,1.0,0.6666666666666666,0.6666666666666666,0.4444444444444444,0.4444444444444444,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,1.0,0.6666666666666666,0.0,0.0,1.0,Mark: outstanding (i.e. unknown),"I’m updating my tabular CV for an application and I’d like to include my master thesis even though it’s not yet finished (soon!) and marked. So I’d like to write that the mark is still outstanding but I fear that if I simply write


  Master thesis: ‹topic›
  Supervisor: ‹supervisor›
  Mark: outstanding


this could be misconstrued to mean that the result is in, and that it’s outstanding (as in: spectacular). What can I say here instead? It should be as salient as possible, single word preferred. I specifically want to avoid writing half a sentence.
","I'll choose ""to be determined"" (or, for a longer time, ""to be determined"")."
5639,5639,8941,Hanging boot and cannot boot to disk,"I'm having a very puzzling problem with my PC. Recently I have not been able to boot very consistently. The boot will hang during the Windows 7 splash screen and will not go further. The same thing happens when trying to run Startup Repair. At this point in time, I cannot boot, period. 

I've tried booting in safe mode. Safe mode boot hangs after loading disk.sys and will not go further. I've tried using LKGC, which also had no affect.

Normally in this situation, I would do some hardware testing (memtest, chkdsk, windows recovery), but for some reason I cannot boot to any disks whatsoever. The DVD drive I'm trying to boot with is only a few weeks old (my old one died recently), and I've used these disks to boot with before, so I know they are good. 

At this point, I'm a bit stymied as to what I should do next. I'm downloading Ubuntu now to try and backup some stuff, but again, I doubt the boot will be successful. If anyone has any advice on what to try now, I would really appreciate the help.
",Elliot,https://superuser.com/users/135283,"Another option would be to boot from a usb stick, if your mobo supports it. Most major linux distributions support booting from usb. Also, several recovery tools are available and capable of usb booting.
",bottmint,https://superuser.com/users/161814,http://superuser.com/questions/426761,TECHNOLOGY,superuser.com,1.0,0.4444444444444444,0.0,0.3333333333333333,1.0,0.3333333333333333,0.5555555555555556,0.4444444444444444,0.6666666666666666,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.6666666666666666,0.0,1.0,0.7777777777777778,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.3333333333333333,0.0,1.0,"Pending boot, unable to boot to disk","I'm having a very puzzling problem with my PC. Recently I have not been able to boot very consistently. The boot will hang during the Windows 7 splash screen and will not go further. The same thing happens when trying to run Startup Repair. At this point in time, I cannot boot, period. 

I've tried booting in safe mode. Safe mode boot hangs after loading disk.sys and will not go further. I've tried using LKGC, which also had no affect.

Normally in this situation, I would do some hardware testing (memtest, chkdsk, windows recovery), but for some reason I cannot boot to any disks whatsoever. The DVD drive I'm trying to boot with is only a few weeks old (my old one died recently), and I've used these disks to boot with before, so I know they are good. 

At this point, I'm a bit stymied as to what I should do next. I'm downloading Ubuntu now to try and backup some stuff, but again, I doubt the boot will be successful. If anyone has any advice on what to try now, I would really appreciate the help.
","If your mobo supports it, another option is to boot from a USB disk. Most mainstream Linux distributions support booting from USB. In addition, there are several recovery tools available, and USB boot can be performed."
1112,1112,1748,"Why isn't ""Column ordering"" available in my list settings?","I want to change the column order visible when viewing or editing a list item. I have accessed the ""Column ordering"" interface via the list settings page on other lists in the past, but it isn't visible in this list's settings.



Cheers!
",Pete,https://sharepoint.stackexchange.com/users/6300,"If you have Content Type management enabled for the list (if you see a list of content type with the option to add more), the display order of columns is set for each content type. Drill down into one of them and you'll see the option under the list of columns for that content type.
",Louis,https://sharepoint.stackexchange.com/users/6551,http://sharepoint.stackexchange.com/questions/29643/why-isnt-column-ordering-available-in-my-list-settings,TECHNOLOGY,sharepoint.stackexchange.com,1.0,0.8888888888888888,0.0,1.0,0.6666666666666666,1.0,0.7777777777777778,0.4444444444444444,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.6666666666666666,0.0,0.3333333333333333,0.8888888888888888,Why is column sorting not available in my list settings?,"I want to change the order of columns that are visible when I view or edit list items. I have previously accessed the column sorting interface through the list settings page of other lists, but I can't see it in the list settings.","If you have Content Type management enabled for the list (if you see a list of content type with the option to add more), the display order of columns is set for each content type. Drill down into one of them and you'll see the option under the list of columns for that content type.
"
2856,2856,4548,Can I substitute a stainless steel pot for the traditional iron dutch oven?,"I have very limited options in my kitchen, and while the dutch oven is the preferred method for getting an 'oven spring' while baking sourdough, I do not have a cast iron pot to do it.

IF stainless steel is a good substitute, should I consider extra precautions?
",erasmortg,https://cooking.stackexchange.com/users/23068,"I have been using a Tramontina Triply DO (stainless/aluminum/stainless sandwich).  This is a fairly substantial construction but no where near cast iron thickness.  The lid is single layer stainless and the handles are solid stainless.  Plastic handles will suffer in a 450 to 500 oven. I always preheat the oven, but have tried both a hot and a cold start for the DO.   Both methods work very nicely with similar oven spring.  The cold start allows the dough to spread to the edges of the DO, producing a round, domed loaf with nice crust.  The hot start ""freezes"" the dough in ""rustic"" irregular shapes and the crust seems a bit crispier.  I adjust lid-off bake time to achieve 200-210F on an instant read thermometer.
",A Hale,https://cooking.stackexchange.com/users/33966,http://cooking.stackexchange.com/questions/47833/can-i-substitute-a-stainless-steel-pot-for-the-traditional-iron-dutch-oven,LIFE_ARTS,cooking.stackexchange.com,1.0,0.7777777777777778,0.0,0.6666666666666666,1.0,0.6666666666666666,0.8888888888888888,0.8888888888888888,0.6666666666666666,0.0,0.3333333333333333,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,1.0,0.8888888888888888,0.7777777777777778,1.0,1.0,0.8666666666666666,0.3333333333333333,0.6666666666666666,1.0,1.0,Can I use a stainless steel pot instead of the traditional Dutch oven?,"My choice in the kitchen is very limited, although the Dutch oven is the preferred way to get ""oven spring"" when baking yogurt, but I don't have a cast iron pot to do it.","I have been using a Tramontina Triply DO (stainless/aluminum/stainless sandwich).  This is a fairly substantial construction but no where near cast iron thickness.  The lid is single layer stainless and the handles are solid stainless.  Plastic handles will suffer in a 450 to 500 oven. I always preheat the oven, but have tried both a hot and a cold start for the DO.   Both methods work very nicely with similar oven spring.  The cold start allows the dough to spread to the edges of the DO, producing a round, domed loaf with nice crust.  The hot start ""freezes"" the dough in ""rustic"" irregular shapes and the crust seems a bit crispier.  I adjust lid-off bake time to achieve 200-210F on an instant read thermometer.
"
4957,4957,7893,Java and JVM license,"Does Java license allow other companies to create their own versions of Java language or just implement it accurately? Same question about JVM.

I heard about Sun suing Microsoft for changing their .NET version of Java implementation and Java for Google Android, but I just can't grasp the whole concept as a totality.
",Sergey,https://programmers.stackexchange.com/users/9437,"Well, as I understand it, you can implement the specification all you like - to be able to legitimately call it ""Java"" you have to license and pass the compatibility kit, which apparently isn't trivial.

Android is not ""java"" although it uses the java language. It doesn't even attempt to pass the TCK.
",Joseph Ottinger,https://programmers.stackexchange.com/users/26589,http://programmers.stackexchange.com/questions/71561/java-and-jvm-license,TECHNOLOGY,programmers.stackexchange.com,0.6666666666666666,0.3333333333333333,0.0,0.3333333333333333,1.0,1.0,0.5555555555555556,0.4444444444444444,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,1.0,1.0,0.5555555555555556,1.0,1.0,0.8,0.0,0.0,1.0,1.0,Java and JVM licenses,"Does Java license allow other companies to create their own versions of Java language or just implement it accurately? Same question about JVM.

I heard about Sun suing Microsoft for changing their .NET version of Java implementation and Java for Google Android, but I just can't grasp the whole concept as a totality.
","Well, as far as I know, you can implement all the specifications you like - in order to be able to legitimately call it ""Java,"" you have to license and pass the compatibility toolkit, which is obviously not a small thing."
2045,2045,3259,Left align equation description,"I have a short description for each of my equations. I want to have them flushleft (similar to the equation numbers which are flushright). How can I do that?

Here is a MWE:

\documentclass{article}
\usepackage{amsmath}
\begin{document}
\begin{equation}
\text{this is my first equation: } z = x
\end{equation}
\begin{equation}
\text{this is my second equation: } z = x+y
\end{equation}
\end{document}


And my desired output is like this:

",Salman,https://tex.stackexchange.com/users/26272,"The following example uses environment tabular* to simulate the equations and to achieve the alignment requests:

\documentclass{article}
\usepackage{amsmath}
\usepackage{array}
\begin{document}
\noindent A\hfill Z

\begin{center}
\begin{tabular*}{\linewidth}{%
  @{}l% description
  @{\extracolsep{\fill}}%
  &gt;{$\displaystyle}c&lt;{$}% simulate displayed equation
  &gt;{\refstepcounter{equation}\thetag\theequation}r@{}% equation number
}
this is my first equation:&amp; z = x &amp;\\
this is my second equation:&amp; z = x + y &amp;\\
\end{tabular*}
\end{center}

\noindent A\hfill Z
\end{document}



  

",Heiko Oberdiek,https://tex.stackexchange.com/users/16967,http://tex.stackexchange.com/questions/119621/left-align-equation-description,TECHNOLOGY,tex.stackexchange.com,0.7777777777777778,0.5555555555555556,0.0,1.0,0.6666666666666666,1.0,0.6666666666666666,0.4444444444444444,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,0.8888888888888888,Left justification formula description,"I have a short description for each of my equations. I want to have them flushleft (similar to the equation numbers which are flushright). How can I do that?

Here is a MWE:

\documentclass{article}
\usepackage{amsmath}
\begin{document}
\begin{equation}
\text{this is my first equation: } z = x
\end{equation}
\begin{equation}
\text{this is my second equation: } z = x+y
\end{equation}
\end{document}


And my desired output is like this:

","The following example uses environment tabular* to simulate the equations and to achieve the alignment requests:

\documentclass{article}
\usepackage{amsmath}
\usepackage{array}
\begin{document}
\noindent A\hfill Z

\begin{center}
\begin{tabular*}{\linewidth}{%
  @{}l% description
  @{\extracolsep{\fill}}%
  &gt;{$\displaystyle}c&lt;{$}% simulate displayed equation
  &gt;{\refstepcounter{equation}\thetag\theequation}r@{}% equation number
}
this is my first equation:&amp; z = x &amp;\\
this is my second equation:&amp; z = x + y &amp;\\
\end{tabular*}
\end{center}

\noindent A\hfill Z
\end{document}



  

"
1144,1144,1797,Correctly debugging switching (DC-DC) boost converter with Oscilloscope,"I have an LED driver (LM3410) that adjusts it's voltage based upon how many LEDs you place in series to it and I'm curious to see what voltage it is actually outputting. To test it I connected my oscilloscope probe on the v+ output and ground and after getting a little smoke I'm a little worried about trying again. I'm pretty sure I put the thing into over-drive as it tried to ""power"" my oscilloscope. My over-voltage protection seems to have saved it since it still seems to work (miraculously).

So my question is: what is the proper way to measure voltage output from a DC-DC boost converter that changes it's voltage based on load?
",Aureis,https://electronics.stackexchange.com/users/15684,"From the problem description, two possible hypotheses come to mind:


There is a ground level mismatch: The DC-DC boost output has a ground that is different from your oscilloscope's ground
The probing was done with no LED load, so the boost circuit is attempting to generate the highest voltage it can. How high this can be depends on the circuit design, of course.


With some additional detail on the boost conversion design, additional hypotheses, or a definitive answer, might be possible. 
",Anindo Ghosh,https://electronics.stackexchange.com/users/14004,http://electronics.stackexchange.com/questions/56493/correctly-debugging-switching-dc-dc-boost-converter-with-oscilloscope,SCIENCE,electronics.stackexchange.com,1.0,0.5,0.0,1.0,1.0,1.0,0.5,0.5,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.5,0.0,1.0,0.8333333333333334,0.5,1.0,0.8333333333333334,0.7,0.0,0.0,1.0,1.0,Correct debugging of switch (DC-DC) boost converter with oscilloscope,"I have an LED driver (lm3410), which can adjust its voltage according to how many LEDs you connect in series. I'm curious about the output voltage. To test it, I connected the probe of the oscilloscope to the V + output and the ground. After a little smoke, I was a little worried about trying again. I'm sure I put it on the drive because it tries to ""power"" my oscilloscope. My over-voltage protection seems to have saved it because it still seems to work (miraculously).","From the problem description, two possible hypotheses come to mind:


There is a ground level mismatch: The DC-DC boost output has a ground that is different from your oscilloscope's ground
The probing was done with no LED load, so the boost circuit is attempting to generate the highest voltage it can. How high this can be depends on the circuit design, of course.


With some additional detail on the boost conversion design, additional hypotheses, or a definitive answer, might be possible. 
"
2060,2060,3282,Wordpress - Custom taxonomy page of custom post type listing by terms,"I have a taxonomy-taxonomy.php page that needs to look like so:

CUSTOM POST TYPE TITLE (RESOURCES)

Custom Taxonomy 1 (Resource Types)

Resource Type Term 1 (White Papers)


White Paper post 1

White Paper post 2

White Paper post 3


Resource Type Term 2 (Videos)


Videos post 1

Videos post 2

Videos post 3


Tried to make sense of all the new documentation for Wordpress 3.0, but it only made me more confused as it seems to be mixed up with 2.8.
",manon1165,https://stackoverflow.com/users/405094,"It's not necessary to transform the object to an array, you can perfectly work with the object without too much hassle. What is curious (at least for me), is that you get something like this:

  Array
  (
      [0] =&gt; stdClass Object
          (
              [term_id] =&gt; 7
              [name] =&gt; Magister comunicaciones aplicadas
              [slug] =&gt; magister-comunicaciones-aplicadas
              [term_group] =&gt; 0
              [term_taxonomy_id] =&gt; 7
              [taxonomy] =&gt; linea-de-estudio
              [description] =&gt; 
              [parent] =&gt; 0
              [count] =&gt; 4
          )

      [1] =&gt; stdClass Object
          (
               [term_id] =&gt; 8
               [name] =&gt; Engagement marketing
               [slug] =&gt; engagement-marketing
               [term_group] =&gt; 0
               [term_taxonomy_id] =&gt; 8
               [taxonomy] =&gt; linea-de-estudio
               [description] =&gt; 
               [parent] =&gt; 0
               [count] =&gt; 5
          )
  )


It's basically, an array of objects, so you've to treat them that way. For example if I want the name of the the first one:

$myterms = get_terms('taxonomy-name', 'orderby=none&amp;hide_empty');    
echo  $myterms[0]-&gt;name;


If you need to iterate through the elements, you still can use foreach();.

foreach ($myterms as $term) { ?&gt;
    &lt;li&gt;&lt;a href=""&lt;?php echo $term-&gt;slug; ?&gt;""&gt;&lt;?php echo $term-&gt;name; ?&gt;&lt;/a&gt;&lt;/li&gt; &lt;?php
} ?&gt;


That way you can post the articles from your taxonomy.

For the custom post types, you'll have to create a loop like this:

$args = array(
    'post_type' =&gt; 'post-type-name',
    'taxonomy' =&gt; 'term'
    //for example
    //'resources' =&gt; 'videos'
);

//  assigning variables to the loop
global $wp_query;
$wp_query = new WP_Query($args);

// starting loop
while ($wp_query-&gt;have_posts()) : $wp_query-&gt;the_post();

the_title();
blabla....

endwhile;


Then you can create multiple loops each of one for each taxonomy/term :).

If you want to get even more fancy (don't want to repeat yourself a hundred times) you can include the second loop inside the first one and assign variables to the taxonomy (resources ie) and the terms it has (videos) (from your example only the last one). The idea is that you would have a normal (typical) wordpress loop restricted to the custom post-type and each one of the terms.

foreach ($myterms as $term) : ?&gt;
    &lt;li&gt;&lt;a href=""&lt;?php echo $term-&gt;slug; ?&gt;""&gt;&lt;?php echo $term-&gt;name; ?&gt;&lt;/a&gt;&lt;/li&gt; &lt;?php

        $term_name = $term-&gt;slug;

        $args = array(
        'post_type' =&gt; 'post-type-name',
        'taxonomy' =&gt; ""$term_name""
        );

   //  assigning variables to the loop
   global $wp_query;
   $wp_query = new WP_Query($args);

   // starting loop posting only
   while ($wp_query-&gt;have_posts()) : $wp_query-&gt;the_post();

   the_title();
   blabla....

   endwhile;

endforeach; ?&gt;


Obviously you can do the inverse thing too, create the normal loop for a single-template custom type (it's looks like you have only one), and inside includes all the custom terms.

Not very elegant, but that's the best way I can came up with it :P. Hope that someone can understand this, sounds confusing. 

Maybe could it be possible with some callback function?.
",Pablo Olmos de Aguilera C.,https://stackoverflow.com/users/417527,http://stackoverflow.com/questions/3358049/wordpress-custom-taxonomy-page-of-custom-post-type-listing-by-terms,STACKOVERFLOW,stackoverflow.com,0.4444444444444444,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,0.0,0.5555555555555556,0.8888888888888888,0.6666666666666666,1.0,0.8888888888888888,0.8,1.0,0.0,0.6666666666666666,0.8888888888888888,WordPress - a custom category page that lists custom article types by term,"I have a taxonomy-taxonomy.php page that needs to look like so:

CUSTOM POST TYPE TITLE (RESOURCES)

Custom Taxonomy 1 (Resource Types)

Resource Type Term 1 (White Papers)


White Paper post 1

White Paper post 2

White Paper post 3


Resource Type Term 2 (Videos)


Videos post 1

Videos post 2

Videos post 3


Tried to make sense of all the new documentation for Wordpress 3.0, but it only made me more confused as it seems to be mixed up with 2.8.
","It's not necessary to transform the object to an array, you can perfectly work with the object without too much hassle. What is curious (at least for me), is that you get something like this:

  Array
  (
      [0] =&gt; stdClass Object
          (
              [term_id] =&gt; 7
              [name] =&gt; Magister comunicaciones aplicadas
              [slug] =&gt; magister-comunicaciones-aplicadas
              [term_group] =&gt; 0
              [term_taxonomy_id] =&gt; 7
              [taxonomy] =&gt; linea-de-estudio
              [description] =&gt; 
              [parent] =&gt; 0
              [count] =&gt; 4
          )

      [1] =&gt; stdClass Object
          (
               [term_id] =&gt; 8
               [name] =&gt; Engagement marketing
               [slug] =&gt; engagement-marketing
               [term_group] =&gt; 0
               [term_taxonomy_id] =&gt; 8
               [taxonomy] =&gt; linea-de-estudio
               [description] =&gt; 
               [parent] =&gt; 0
               [count] =&gt; 5
          )
  )


It's basically, an array of objects, so you've to treat them that way. For example if I want the name of the the first one:

$myterms = get_terms('taxonomy-name', 'orderby=none&amp;hide_empty');    
echo  $myterms[0]-&gt;name;


If you need to iterate through the elements, you still can use foreach();.

foreach ($myterms as $term) { ?&gt;
    &lt;li&gt;&lt;a href=""&lt;?php echo $term-&gt;slug; ?&gt;""&gt;&lt;?php echo $term-&gt;name; ?&gt;&lt;/a&gt;&lt;/li&gt; &lt;?php
} ?&gt;


That way you can post the articles from your taxonomy.

For the custom post types, you'll have to create a loop like this:

$args = array(
    'post_type' =&gt; 'post-type-name',
    'taxonomy' =&gt; 'term'
    //for example
    //'resources' =&gt; 'videos'
);

//  assigning variables to the loop
global $wp_query;
$wp_query = new WP_Query($args);

// starting loop
while ($wp_query-&gt;have_posts()) : $wp_query-&gt;the_post();

the_title();
blabla....

endwhile;


Then you can create multiple loops each of one for each taxonomy/term :).

If you want to get even more fancy (don't want to repeat yourself a hundred times) you can include the second loop inside the first one and assign variables to the taxonomy (resources ie) and the terms it has (videos) (from your example only the last one). The idea is that you would have a normal (typical) wordpress loop restricted to the custom post-type and each one of the terms.

foreach ($myterms as $term) : ?&gt;
    &lt;li&gt;&lt;a href=""&lt;?php echo $term-&gt;slug; ?&gt;""&gt;&lt;?php echo $term-&gt;name; ?&gt;&lt;/a&gt;&lt;/li&gt; &lt;?php

        $term_name = $term-&gt;slug;

        $args = array(
        'post_type' =&gt; 'post-type-name',
        'taxonomy' =&gt; ""$term_name""
        );

   //  assigning variables to the loop
   global $wp_query;
   $wp_query = new WP_Query($args);

   // starting loop posting only
   while ($wp_query-&gt;have_posts()) : $wp_query-&gt;the_post();

   the_title();
   blabla....

   endwhile;

endforeach; ?&gt;


Obviously you can do the inverse thing too, create the normal loop for a single-template custom type (it's looks like you have only one), and inside includes all the custom terms.

Not very elegant, but that's the best way I can came up with it :P. Hope that someone can understand this, sounds confusing. 

Maybe could it be possible with some callback function?.
"
2292,2292,3652,What is the variance of a Polya Gamma distribution?,"I have a simple application that needs the variance of a Polya Gamma distribution (I know the mean since I found it here- http://arxiv.org/abs/1205.0310). 

This paper says that there is a closed form solution for the variance, but I am not really a mathematician and cannot calculate it.

In short, does anyone know the closed form solution for the variance of the Polya Gamma distribution.

I would be very grateful.
",Roland Baddeley,https://stats.stackexchange.com/users/60155,"In equation (6), the paper obtains the Laplace transform of these distributions as

$$\phi(t) = \prod_{k=1}^\infty \left(1 + \frac{t}{d_k}
\right)^{-b};\ d_k = 2\left(k-\frac{1}{2}\right)^2 \pi^2 + c^2/2$$

where $b\gt 0$ and $c\in \mathbb R$ are the parameters.  Taking logarithms yields 

$$\psi(t) = \frac{d}{dt}\phi(t) = \sum_{k=1}^\infty -b \log\left(1 + \frac{t}{d_k}\right).$$

This is a cumulant generating function (for imaginary values of $t$, at any rate) whose Taylor series around $t=0$ begins

$$\psi(t) = -\mu_1^\prime t + \frac{1}{2!} \left( \mu_2^\prime - \mu_1^{\prime \,2} \right)t^2 + \cdots$$

with $\mu_j^\prime$ representing the raw moment of order $j$: thus, the negative of the coefficient of $t$ is the mean and twice ($=2!$) the coefficient of $t^2$ is the variance.  The summation formula for $\psi$ can be expanded term-by-term and collected in common powers of $t$ to produce

$$\psi(t) = \sum_{k=1}^\infty -b \left(\frac{t}{d_k} + \frac{t^2}{2 d_k^2} + \cdots\right) = -b\sum_{k=1}^\infty \frac{1}{d_k} t - b\sum_{k=1}^\infty \frac{1}{2d_k^2} t^2 + \cdots.$$

Such sums, whose terms are the reciprocals of quadratic (and higher) functions of the integral index $k$, are straightforward to evaluate using the Weierstrass Factorization Theorem and yield

$$\mu_1^\prime = \frac{b }{2 c}\tanh \left(c/2\right);\ \mu_2^\prime - \mu_1^{\prime\,2} = \frac{b }{4 c^3}(\sinh (c) - c) \text{sech}^2\left(c/2\right).$$

The former agrees with the mean reported in the paper (adding some confidence to the overall correctness of this approach) while the latter answers the question: it is a closed form expression for the variance.  (These series can be continued in higher powers of $t$ to develop closed formulas for any cumulants, from which higher moments can be extracted.)

Partial contour plots show that the signs of the results (at least) are correct.



Nothing is shown along the $b$ axis (where $c=0$) because these formulas are not defined for $c=0$.  However, the plots make it clear that the formulas can be extended to continuous functions along that axis by taking the limits as $c\to 0$.  They give $b/4$ for the mean and $b/24$ for the variance.
",whuber,https://stats.stackexchange.com/users/919,http://stats.stackexchange.com/questions/122957/what-is-the-variance-of-a-polya-gamma-distribution,SCIENCE,stats.stackexchange.com,0.8888888888888888,0.7777777777777778,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.0,0.6666666666666666,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,0.6666666666666666,0.0,1.0,1.0,What is the variance of multivariate gamma distribution?,"I have a simple application that needs the variance of a Polya Gamma distribution (I know the mean since I found it here- http://arxiv.org/abs/1205.0310). 

This paper says that there is a closed form solution for the variance, but I am not really a mathematician and cannot calculate it.

In short, does anyone know the closed form solution for the variance of the Polya Gamma distribution.

I would be very grateful.
","In equation (6), the paper obtains the Laplace transform of these distributions as

$$\phi(t) = \prod_{k=1}^\infty \left(1 + \frac{t}{d_k}
\right)^{-b};\ d_k = 2\left(k-\frac{1}{2}\right)^2 \pi^2 + c^2/2$$

where $b\gt 0$ and $c\in \mathbb R$ are the parameters.  Taking logarithms yields 

$$\psi(t) = \frac{d}{dt}\phi(t) = \sum_{k=1}^\infty -b \log\left(1 + \frac{t}{d_k}\right).$$

This is a cumulant generating function (for imaginary values of $t$, at any rate) whose Taylor series around $t=0$ begins

$$\psi(t) = -\mu_1^\prime t + \frac{1}{2!} \left( \mu_2^\prime - \mu_1^{\prime \,2} \right)t^2 + \cdots$$

with $\mu_j^\prime$ representing the raw moment of order $j$: thus, the negative of the coefficient of $t$ is the mean and twice ($=2!$) the coefficient of $t^2$ is the variance.  The summation formula for $\psi$ can be expanded term-by-term and collected in common powers of $t$ to produce

$$\psi(t) = \sum_{k=1}^\infty -b \left(\frac{t}{d_k} + \frac{t^2}{2 d_k^2} + \cdots\right) = -b\sum_{k=1}^\infty \frac{1}{d_k} t - b\sum_{k=1}^\infty \frac{1}{2d_k^2} t^2 + \cdots.$$

Such sums, whose terms are the reciprocals of quadratic (and higher) functions of the integral index $k$, are straightforward to evaluate using the Weierstrass Factorization Theorem and yield

$$\mu_1^\prime = \frac{b }{2 c}\tanh \left(c/2\right);\ \mu_2^\prime - \mu_1^{\prime\,2} = \frac{b }{4 c^3}(\sinh (c) - c) \text{sech}^2\left(c/2\right).$$

The former agrees with the mean reported in the paper (adding some confidence to the overall correctness of this approach) while the latter answers the question: it is a closed form expression for the variance.  (These series can be continued in higher powers of $t$ to develop closed formulas for any cumulants, from which higher moments can be extracted.)

Partial contour plots show that the signs of the results (at least) are correct.



Nothing is shown along the $b$ axis (where $c=0$) because these formulas are not defined for $c=0$.  However, the plots make it clear that the formulas can be extended to continuous functions along that axis by taking the limits as $c\to 0$.  They give $b/4$ for the mean and $b/24$ for the variance.
"
1855,1855,2947,"Usage of ""might"" and ""would"" to indicate doubt","Do the sentences 


  She might be only 28, but Jodie
  Whittaker....


and


  My parents would have walked along the
  Barrow


wrongly suggest doubt, or are they normal usage? Are there names for these constructions?
Taken from Irish Times .



I googled ""would have spent their time"". 
Many cases were counterfactuals (""... otherwise they would have spent their time...”)
But plenty simply describe past events, as the in the usage sited above.
I couldn't detect a regional bias.
As an Irish-English speaker this usage is unremarkable for example I might say


  This is the exact spot where Caesar
  would have crossed the Rubicon


I think the intention is to evoke the event rather than just record it.
",cindi,https://english.stackexchange.com/users/122,"Let's take them one at a time. The first,


  She might be only 28


is an example of great understatement, similar to when we say, 


  You know you might have helped us. 


The person is actually making a dig at the person by using might to imply ""it's the least you could have done."" 

I think that this is another example of understatement. The person is saying something like ""yeah, she's only 28 but wow... "" 



In one possible scenario, I can see that there could be some doubt but in the other I envision I don't see any doubt. In the first scenario, a child, maybe an orphan who found out who their parents were, makes a judgement that the parents, who, having lived close to the Barrow [a river?] must have walked along that __.

The second, it's a child who grew up with his parents and is describing a routine that the parents were seen to have engaged in. This is the would of reminiscing. 

Examples: 


  I remember when I was sick, my mother would stroke my head and sing softly to me.
  
  When I was a young lad, my father would take me fishing every Saturday morning after chores. 

",Dan,https://english.stackexchange.com/users/2015,http://english.stackexchange.com/questions/3541/usage-of-might-and-would-to-indicate-doubt,CULTURE,english.stackexchange.com,0.6666666666666666,0.3333333333333333,0.0,1.0,1.0,1.0,0.5555555555555556,0.5555555555555556,0.0,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,0.7777777777777778,0.4444444444444444,0.7777777777777778,1.0,0.9333333333333332,0.0,0.0,1.0,0.7777777777777778,"Use ""may"" and ""will"" to express doubt","Do the sentences 


  She might be only 28, but Jodie
  Whittaker....


and


  My parents would have walked along the
  Barrow


wrongly suggest doubt, or are they normal usage? Are there names for these constructions?
Taken from Irish Times .



I googled ""would have spent their time"". 
Many cases were counterfactuals (""... otherwise they would have spent their time...”)
But plenty simply describe past events, as the in the usage sited above.
I couldn't detect a regional bias.
As an Irish-English speaker this usage is unremarkable for example I might say


  This is the exact spot where Caesar
  would have crossed the Rubicon


I think the intention is to evoke the event rather than just record it.
","Let's take them one at a time. The first,


  She might be only 28


is an example of great understatement, similar to when we say, 


  You know you might have helped us. 


The person is actually making a dig at the person by using might to imply ""it's the least you could have done."" 

I think that this is another example of understatement. The person is saying something like ""yeah, she's only 28 but wow... "" 



In one possible scenario, I can see that there could be some doubt but in the other I envision I don't see any doubt. In the first scenario, a child, maybe an orphan who found out who their parents were, makes a judgement that the parents, who, having lived close to the Barrow [a river?] must have walked along that __.

The second, it's a child who grew up with his parents and is describing a routine that the parents were seen to have engaged in. This is the would of reminiscing. 

Examples: 


  I remember when I was sick, my mother would stroke my head and sing softly to me.
  
  When I was a young lad, my father would take me fishing every Saturday morning after chores. 

"
4627,4627,7341,Lyx itemize returning to last number,"I would like to have the following output:


Text

(a) Text

Text
Text


That is, after a subitem, I want to return to the last number without creating a new one. Is there any way to do this without ERT?
",LuizMMB,https://tex.stackexchange.com/users/41960,"This is supported natively in LyX; there's no need for the tricks in the other answers.

In the following:


First item

(a) Subitem

More of the first item
Second item


Make a separate paragraph for each, including the ""more of the first item"" one. Set its paragraph style to normal (like if it were not part of any list), and press tab to indent it (like you already did to subitem). It should all now look correct both in LyX and in the PDF output.
",Jim Oldfield,https://tex.stackexchange.com/users/32681,http://tex.stackexchange.com/questions/177214/lyx-itemize-returning-to-last-number,TECHNOLOGY,tex.stackexchange.com,0.7777777777777778,0.5555555555555556,0.0,0.3333333333333333,1.0,0.6666666666666666,0.6666666666666666,0.4444444444444444,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,0.8888888888888888,0.8,1.0,0.3333333333333333,0.3333333333333333,0.7777777777777778,Lyx returns to the last number one by one,"I would like to have the following output:


Text

(a) Text

Text
Text


That is, after a subitem, I want to return to the last number without creating a new one. Is there any way to do this without ERT?
","This is supported natively in LyX; there's no need for the tricks in the other answers.

In the following:


First item

(a) Subitem

More of the first item
Second item


Make a separate paragraph for each, including the ""more of the first item"" one. Set its paragraph style to normal (like if it were not part of any list), and press tab to indent it (like you already did to subitem). It should all now look correct both in LyX and in the PDF output.
"
3744,3744,5965,Is there any performance difference between ++i and i++ in C#?,"Is there any performance difference between using something like

for(int i = 0; i &lt; 10; i++) { ... }


and

for(int i = 0; i &lt; 10; ++i) { ... }


or is the compiler able to optimize in such a way that they are equally fast in the case where they are functionally equivalent?

Edit:
This was asked because I had a discussion with a co-worker about it, not because I think its a useful optimization in any practical sense. It is largely academic. 
",Anton,https://stackoverflow.com/users/341413,"If you're asking this question, you're either trolling for reputation or trying to solve the wrong problem.  

The first question to ask is ""how to I improve customer satisfaction with my software by making it run faster?"" and the answer is almost never ""use ++i instead of i++"" or vice versa.

From Coding Horror's post ""Hardware is Cheap, Programmers are Expensive"":


  Rules of Optimization:
  Rule 1: Don't do it.
  Rule 2 (for experts only): Don't do it yet.
  -- M.A. Jackson  


I read rule 2 to mean ""first write clean, clear code that meets your customer's needs, then speed it up where it's too slow"".  It's highly unlikely that ++i vs. i++ is going to be the solution.
",Jay Bazuzi,https://stackoverflow.com/users/5314,http://stackoverflow.com/questions/467322/is-there-any-performance-difference-between-i-and-i-in-c,STACKOVERFLOW,stackoverflow.com,1.0,0.6666666666666666,0.0,1.0,1.0,1.0,0.6666666666666666,0.6666666666666666,1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,1.0,Is there any performance difference between + + I and I + + in C + +?,"Is there any performance difference between using something like

for(int i = 0; i &lt; 10; i++) { ... }


and

for(int i = 0; i &lt; 10; ++i) { ... }


or is the compiler able to optimize in such a way that they are equally fast in the case where they are functionally equivalent?

Edit:
This was asked because I had a discussion with a co-worker about it, not because I think its a useful optimization in any practical sense. It is largely academic. 
","If you're asking this question, you're either trolling for reputation or trying to solve the wrong problem.  

The first question to ask is ""how to I improve customer satisfaction with my software by making it run faster?"" and the answer is almost never ""use ++i instead of i++"" or vice versa.

From Coding Horror's post ""Hardware is Cheap, Programmers are Expensive"":


  Rules of Optimization:
  Rule 1: Don't do it.
  Rule 2 (for experts only): Don't do it yet.
  -- M.A. Jackson  


I read rule 2 to mean ""first write clean, clear code that meets your customer's needs, then speed it up where it's too slow"".  It's highly unlikely that ++i vs. i++ is going to be the solution.
"
1028,1028,1619,What table tools/packages do you use?,"Making tables in LaTeX can be painful. All you need is a semi complex table with cells that have to span multiple rows/columns. What tools do you use to get around this complexity? Tabular? Tabularx? Are there others?
",levesque,https://tex.stackexchange.com/users/10,"I really like booktabs, it creates great, high quality tables (when I say quality I mean that they are really easy to read and look very clean). I feel weird when seeing a table with a lot of cluttered \hlines and \clines everywhere...
",YuppieNetworking,https://tex.stackexchange.com/users/146,http://tex.stackexchange.com/questions/214/what-table-tools-packages-do-you-use,TECHNOLOGY,tex.stackexchange.com,0.8888888888888888,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.0,0.0,0.5555555555555556,0.3333333333333333,0.0,0.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.0,0.3333333333333333,0.8888888888888888,What table tools / bags do you use?,Making tables out of latex can be painful. You only need a semi complex table in which cells must span multiple rows / columns. What tools do you use to circumvent this complexity? Form? Form? Anything else?,"I really like booktabs, it creates great, high quality tables (when I say quality I mean that they are really easy to read and look very clean). I feel weird when seeing a table with a lot of cluttered \hlines and \clines everywhere...
"
2001,2001,3195,Examples of two different descriptions of a set that are not obviously equivalent?,"I am teaching a course in enumerative combinatorics this semester and one of my students asked for deeper clarification regarding the difference between a ""combinatorial"" and a ""bijective"" proof.  Specifically, they pointed out that when one is proving the validity of a combinatorial identity by counting a set in two different ways, this is a different activity than giving an explicit bijection between two different sets.  However, in combinatorics we often use the phrases ""combinatorial proof"" and ""bijective proof"" as synonyms, and I have often heard people use the phrase ""bijective proof"" regarding a ""count in two different ways"" proof of an identity.

It seems to me that often a combinatorial proof arises from describing one set in two different ways; implicit in a proof of the equality of the two descriptions of this set is the identity bijection from the set to itself.  In this sense, one might regard all ""combinatorial"" proofs as ""bijective,"" but I feel that I am on quite shaky ground with this.  These thoughts have led me to the following questions:

Question 1: What are some examples of combinatorial situations where the same set can be described in two different ways but it is not at all clear that the two descriptions yield the same object?

Question 2: What are some examples of situations where two bijective proofs have been given for a theorem or identity where the bijections turned out to be the same, but proving their equivalence was non-trivial?

I would also appreciate opinions regarding the distinction, if any, between combinatorial arguments where one proves identities by describing a set in two different ways and combinatorial arguments where one sets up bijections between genuinely different sets of objects.

EDIT

Thanks for the answers and comments so far.  Here are two examples that will hopefully clarify what I am asking.  One example of a bijective proof between two different sets are showing that Dyck paths and nonnesting partitions are both Catalan-enumerated objects (even preserving the Narayana statistic with a good bijection).  On the other hand, the identity $\sum_{k=0}^nk{n\choose k}=n2^{n-1}$ is usually proved by describing $k$-subsets of $n$ with a distinguished element in two different ways: in the first way, pick the set then specify the element; in the second way, pick the element then specify the rest of the set.  These are both referred to as bijective or combinatorial proofs, yet somehow they each have a different feel to them.  In the second case, it is pretty easy to see that the two descriptions of these objects yield the same set of objects, but surely there must be more situations where the same set is described in two different ways and the equivalence of their descriptions is difficult to ascertain.  Similarly, there must be times where there are several bijections between different sets, like the first example, where the bijections are the same but not obviously so.  What I am wondering about are examples of these two situations.

A non-combinatorial example of an answer to Q1 is the compact-group vs reflection group definition of the Weyl group of a semi-simple Lie Algebra, where it isn't immediately clear that the same group is obtained.  However, I am looking for more combinatorial examples.
",Ben Braun,https://mathoverflow.net/users/10602,"Here is an example where the question of whether the two countings are the same is independent of the axioms of set theory. 

Namely, if the Continuum Hypothesis holds, then the number of real numbers is the same as the number of countable ordinals. But if CH fails, then it is not.
",Joel David Hamkins,https://mathoverflow.net/users/1946,http://mathoverflow.net/questions/52899,SCIENCE,mathoverflow.net,0.7777777777777778,0.5555555555555556,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.3333333333333333,1.0,0.0,0.6666666666666666,0.0,0.3333333333333333,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.8888888888888888,0.8333333333333334,0.4444444444444444,0.8333333333333334,0.8333333333333334,0.6,0.0,0.0,0.6666666666666666,0.8888888888888888,Two examples of different descriptions of a set are obviously not equivalent?,"I am teaching a course in enumerative combinatorics this semester and one of my students asked for deeper clarification regarding the difference between a ""combinatorial"" and a ""bijective"" proof.  Specifically, they pointed out that when one is proving the validity of a combinatorial identity by counting a set in two different ways, this is a different activity than giving an explicit bijection between two different sets.  However, in combinatorics we often use the phrases ""combinatorial proof"" and ""bijective proof"" as synonyms, and I have often heard people use the phrase ""bijective proof"" regarding a ""count in two different ways"" proof of an identity.

It seems to me that often a combinatorial proof arises from describing one set in two different ways; implicit in a proof of the equality of the two descriptions of this set is the identity bijection from the set to itself.  In this sense, one might regard all ""combinatorial"" proofs as ""bijective,"" but I feel that I am on quite shaky ground with this.  These thoughts have led me to the following questions:

Question 1: What are some examples of combinatorial situations where the same set can be described in two different ways but it is not at all clear that the two descriptions yield the same object?

Question 2: What are some examples of situations where two bijective proofs have been given for a theorem or identity where the bijections turned out to be the same, but proving their equivalence was non-trivial?

I would also appreciate opinions regarding the distinction, if any, between combinatorial arguments where one proves identities by describing a set in two different ways and combinatorial arguments where one sets up bijections between genuinely different sets of objects.

EDIT

Thanks for the answers and comments so far.  Here are two examples that will hopefully clarify what I am asking.  One example of a bijective proof between two different sets are showing that Dyck paths and nonnesting partitions are both Catalan-enumerated objects (even preserving the Narayana statistic with a good bijection).  On the other hand, the identity $\sum_{k=0}^nk{n\choose k}=n2^{n-1}$ is usually proved by describing $k$-subsets of $n$ with a distinguished element in two different ways: in the first way, pick the set then specify the element; in the second way, pick the element then specify the rest of the set.  These are both referred to as bijective or combinatorial proofs, yet somehow they each have a different feel to them.  In the second case, it is pretty easy to see that the two descriptions of these objects yield the same set of objects, but surely there must be more situations where the same set is described in two different ways and the equivalence of their descriptions is difficult to ascertain.  Similarly, there must be times where there are several bijections between different sets, like the first example, where the bijections are the same but not obviously so.  What I am wondering about are examples of these two situations.

A non-combinatorial example of an answer to Q1 is the compact-group vs reflection group definition of the Weyl group of a semi-simple Lie Algebra, where it isn't immediately clear that the same group is obtained.  However, I am looking for more combinatorial examples.
","Here is an example where the question of whether the two countings are the same is independent of the axioms of set theory. 

Namely, if the Continuum Hypothesis holds, then the number of real numbers is the same as the number of countable ordinals. But if CH fails, then it is not.
"
2151,2151,3429,Search predictions broken in Chrome - reinstall didn't solve the problem,"I recently changed the default search engine to a custom google search URL (using baseUrl) with some additional parameters and removed all the rest of the search engines, and since then, the search predictions stopped working.

I even tried to reinstall Chrome but as soon as I resync, the problem is back!
Search predictions are just gone without option to fix!!

In IE changing the search provider allows specifying a prediction (suggestion) provider, In chrome, once you change the default search engine, you'll never be able to have predictions again!!
This is a terrible bug, I mean WTF!!!

Is there any workaround to that?

I posted a bug report a while ago but it seems no one looks at it. I'm about to give up on Chrome and go back to IE, the only good thing about Chrome is the Extension market and the AdBlocker (which I can find in IE as well). The perfrormance changes don't matter to me too much.

Thanks
",Shimmy,https://superuser.com/users/9825,"After trying @ZacB's suggestion, it still didn't work. Removing all Chromium's settings and rebooting the computer also didn't work, so I concluded that the Chromium version I was running must be buggy.

Updating Chromium fixed it for me.
",Frank Kusters,https://superuser.com/users/124252,http://superuser.com/questions/399796,TECHNOLOGY,superuser.com,0.7777777777777778,0.4444444444444444,0.0,1.0,1.0,0.6666666666666666,0.4444444444444444,0.4444444444444444,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,0.0,0.7777777777777778,Search prediction failed in chrome - reinstallation doesn't solve the problem,"I recently changed the default search engine to a custom google search URL (using baseUrl) with some additional parameters and removed all the rest of the search engines, and since then, the search predictions stopped working.

I even tried to reinstall Chrome but as soon as I resync, the problem is back!
Search predictions are just gone without option to fix!!

In IE changing the search provider allows specifying a prediction (suggestion) provider, In chrome, once you change the default search engine, you'll never be able to have predictions again!!
This is a terrible bug, I mean WTF!!!

Is there any workaround to that?

I posted a bug report a while ago but it seems no one looks at it. I'm about to give up on Chrome and go back to IE, the only good thing about Chrome is the Extension market and the AdBlocker (which I can find in IE as well). The perfrormance changes don't matter to me too much.

Thanks
","After trying @ZacB's suggestion, it still didn't work. Removing all Chromium's settings and rebooting the computer also didn't work, so I concluded that the Chromium version I was running must be buggy.

Updating Chromium fixed it for me.
"
3261,3261,5199,God the Father's possession of a body of flesh and bones,"There is a belief out there that God the Father has always possessed a body of flesh and bones. Some of the proponents of this belief don't find it contradictory to John 4:24 (""God is a Spirit"") as the verse may be referring only to one part of God without limiting God to being only that one part - just like, for example, in 1 Pet 3:20 (""eight souls were saved by water"") Peter called some humans ""souls"", but he didn't mean by that that they didn't posses bodies.

The example of Jesus after His resurrection, Who, while possessing a body of flesh and bones, still retains all the qualities that are usually ascribed only to God, for example, His omnipresence, could go along with this belief. 

I wonder if Biblical hermeneutics, namely the hermeneutics of the Old Testament, allows for this belief. If not, please, point out those places that speak against the validity of this belief.
",brilliant,https://christianity.stackexchange.com/users/234,"Your question is worded a little tricky, but I think you're saying: John 4:24 says that God is a spirit, and you are saying that Mormons respond by saying that it only refers to one part of God (one part is the spirit and the other part is the body), since Mormons believe God has a body. Then you cite 1 Peter as an example.

Not to throw your example a little bit, but Mormons believe that


  15 ... the spirit and the body are the soul of man.(Doctrine and Covenants 88:15)


So, to answer your question:


  How do / Do Mormons reconcile God the Father's omnipresence with his corporeal / fleshy form?


Yes, Mormon doctrine does reconcile it, and it's quite simple:


The body houses the spirit.
God has a perfect, immortal, and glorified body which houses His spirit.
God is not, as an actual being, omnipresent. For example, Jesus couldn't visit the Nephites and other of God's children at the same time:



  1 And verily, verily, I say unto you that I have aother sheep, which
  are not of this land, neither of the land of Jerusalem, neither in any
  parts of that land round about whither I have been to minister.
  
  2 For they of whom I speak are they who have not as yet heard my
  voice; neither have I at any time manifested myself unto them.
  
  3 But I have received a commandment of the Father that I shall go
  unto them, and that they shall hear my voice, and shall be numbered
  among my sheep, that there may be one fold and one shepherd; therefore
  I go to show myself unto them.
  
  4 And I command you that ye shall write these sayings after I am
  gone ...



Since the Holy Ghost is both a spirit (no body) and also a god, His influence can be felt anywhere at once. The Holy Ghost is a separate, distinct being from God Himself, but is nonetheless a member of the godhead. In this sense, perhaps, God is ""omnipresent.""

",Matt,https://christianity.stackexchange.com/users/1003,http://christianity.stackexchange.com/questions/13648/god-the-fathers-possession-of-a-body-of-flesh-and-bones,CULTURE,christianity.stackexchange.com,0.8888888888888888,0.4444444444444444,0.0,0.5,0.6666666666666666,1.0,0.4444444444444444,0.4444444444444444,0.6666666666666666,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,1.0,0.7777777777777778,1.0,1.0,0.9,0.0,0.0,1.0,0.8888888888888888,God the Father's possession of a body of flesh and bones,"There is a belief out there that God the Father has always possessed a body of flesh and bones. Some of the proponents of this belief don't find it contradictory to John 4:24 (""God is a Spirit"") as the verse may be referring only to one part of God without limiting God to being only that one part - just like, for example, in 1 Pet 3:20 (""eight souls were saved by water"") Peter called some humans ""souls"", but he didn't mean by that that they didn't posses bodies.

The example of Jesus after His resurrection, Who, while possessing a body of flesh and bones, still retains all the qualities that are usually ascribed only to God, for example, His omnipresence, could go along with this belief. 

I wonder if Biblical hermeneutics, namely the hermeneutics of the Old Testament, allows for this belief. If not, please, point out those places that speak against the validity of this belief.
","Your question is worded a little tricky, but I think you're saying: John 4:24 says that God is a spirit, and you are saying that Mormons respond by saying that it only refers to one part of God (one part is the spirit and the other part is the body), since Mormons believe God has a body. Then you cite 1 Peter as an example.

Not to throw your example a little bit, but Mormons believe that


  15 ... the spirit and the body are the soul of man.(Doctrine and Covenants 88:15)


So, to answer your question:


  How do / Do Mormons reconcile God the Father's omnipresence with his corporeal / fleshy form?


Yes, Mormon doctrine does reconcile it, and it's quite simple:


The body houses the spirit.
God has a perfect, immortal, and glorified body which houses His spirit.
God is not, as an actual being, omnipresent. For example, Jesus couldn't visit the Nephites and other of God's children at the same time:



  1 And verily, verily, I say unto you that I have aother sheep, which
  are not of this land, neither of the land of Jerusalem, neither in any
  parts of that land round about whither I have been to minister.
  
  2 For they of whom I speak are they who have not as yet heard my
  voice; neither have I at any time manifested myself unto them.
  
  3 But I have received a commandment of the Father that I shall go
  unto them, and that they shall hear my voice, and shall be numbered
  among my sheep, that there may be one fold and one shepherd; therefore
  I go to show myself unto them.
  
  4 And I command you that ye shall write these sayings after I am
  gone ...



Since the Holy Ghost is both a spirit (no body) and also a god, His influence can be felt anywhere at once. The Holy Ghost is a separate, distinct being from God Himself, but is nonetheless a member of the godhead. In this sense, perhaps, God is ""omnipresent.""

"
2774,2774,4419,Mixed number fractions class,"I'm looking for bugs.  I tried to test all functionality in a variety of ways.

#by JB0x2D1

from decimal import Decimal
import math
import numbers
import operator
from fractions import Fraction

class Mixed(Fraction):
    """"""This class implements Fraction, which implements rational numbers.""""""
        # We're immutable, so use __new__ not __init__
    def __new__(cls, whole=0, numerator=None, denominator=None):
        """"""Constructs a Rational.

        Takes a string like '-1 2/3' or '1.5', another Rational instance, a
        numerator/denominator pair, a float, or a whole number/numerator/
        denominator set.  If one or more non-zero arguments is negative,
        all are treated as negative and the result is negative.

        General behavior:  whole number + (numerator / denominator)

        Examples
        --------

        &gt;&gt;&gt; Mixed(Mixed(-1,1,2), Mixed(0,1,2), Mixed(0,1,2))
        Mixed(-2, 1, 2)
        Note: The above call is similar to:
        &gt;&gt;&gt; Fraction(-3,2) + Fraction(Fraction(-1,2), Fraction(1,2))
        Fraction(-5, 2)
        &gt;&gt;&gt; Mixed('-1 2/3')
        Mixed(-1, 2, 3)
        &gt;&gt;&gt; Mixed(10,-8)
        Mixed(-1, 1, 4)
        &gt;&gt;&gt; Mixed(Fraction(1,7), 5)
        Mixed(0, 1, 35)
        &gt;&gt;&gt; Mixed(Mixed(1, 7), Fraction(2, 3))
        Mixed(0, 3, 14)
        &gt;&gt;&gt; Mixed(Mixed(0, 3, 2), Fraction(2, 3), 2)
        Mixed(1, 5, 6)
        &gt;&gt;&gt; Mixed('314')
        Mixed(314, 0, 1)
        &gt;&gt;&gt; Mixed('-35/4')
        Mixed(-8, 3, 4)
        &gt;&gt;&gt; Mixed('3.1415')
        Mixed(3, 283, 2000)
        &gt;&gt;&gt; Mixed('-47e-2')
        Mixed(0, -47, 100)
        &gt;&gt;&gt; Mixed(1.47)
        Mixed(1, 2116691824864133, 4503599627370496)
        &gt;&gt;&gt; Mixed(2.25)
        Mixed(2, 1, 4)
        &gt;&gt;&gt; Mixed(Decimal('1.47'))
        Mixed(1, 47, 100)

        """"""
        self = super(Fraction, cls).__new__(cls)

        if (numerator is None) and (denominator is None): #single argument
            if isinstance(whole, numbers.Rational) or \
               isinstance(whole, float) or \
               isinstance(whole, Decimal):
                if type(whole) == Mixed:
                    return whole
                f = Fraction(whole)
                whole = 0
            elif isinstance(whole, str):
                # Handle construction from strings.
                arg = whole
                fail = False
                try:
                    f = Fraction(whole)
                    whole = 0
                except ValueError:
                    n = whole.split()
                    if (len(n) == 2):
                        try:
                            whole = Fraction(n[0])
                            f = Fraction(n[1])
                        except ValueError:
                            fail = True
                    else:
                        fail = True
                if fail:
                    raise ValueError('Invalid literal for Mixed: %r' %
                                         arg)
            else:
                raise TypeError(""argument should be a string ""
                                ""or a Rational instance"")
        elif (isinstance(numerator, numbers.Rational) and #two arguments
            isinstance(whole, numbers.Rational) and (denominator is None)):
            #here whole is treated as numerator and numerator as denominator
            if numerator == 0:
                raise ZeroDivisionError('Mixed(%s, 0)' % whole)
            f = Fraction(whole, numerator)
            whole = 0
        elif (isinstance(whole, numbers.Rational) and #three arguments
              isinstance(numerator, numbers.Rational) and
              isinstance(denominator, numbers.Rational)):
            if denominator == 0:
                raise ZeroDivisionError('Mixed(%s, %s, 0)' % whole, numerator)
            whole = Fraction(whole)
            f = Fraction(numerator, denominator)
        else:
            raise TypeError(""all three arguments should be ""
                            ""Rational instances"")
        #handle negative values and convert improper to mixed number fraction
        if (whole &lt; 0) and (f &gt; 0):
            f = -f + whole
        elif (whole &gt; 0) and (f &lt; 0):
            f += -whole
        else:
            f += whole
        numerator = f.numerator
        denominator = f.denominator
        if numerator &lt; 0:
            whole = -(-numerator // denominator)
            numerator = -numerator % denominator
        else:
            whole = numerator // denominator
            numerator %= denominator
        self._whole = whole
        self._numerator = numerator
        self._denominator = denominator
        return self

    def __repr__(self):
        """"""repr(self)""""""
        return ('Mixed(%s, %s, %s)' % (self._whole, self._numerator,
                                       self._denominator))

    def __str__(self):
        """"""str(self)""""""
        if self._numerator == 0:
            return str(self._whole)
        elif self._whole != 0:
            return '%s %s/%s' % (self._whole, self._numerator,
                                 self._denominator)
        else:
            return '%s/%s' % (self._numerator, self._denominator)

    def to_fraction(self):
        n = self._numerator
        if self._whole != 0:
            if self._whole &lt; 0:
                n *= -1
            n += self._whole * self._denominator
        return Fraction(n, self._denominator)

    def limit_denominator(self, max_denominator=1000000):
        """"""Closest Fraction to self with denominator at most max_denominator.

        &gt;&gt;&gt; Mixed('3.141592653589793').limit_denominator(10)
        Mixed(3, 1, 7)
        &gt;&gt;&gt; Mixed('3.141592653589793').limit_denominator(100)
        Mixed(3, 14, 99)
        &gt;&gt;&gt; Mixed(4321, 8765).limit_denominator(10000)
        Mixed(0, 4321, 8765)
        """"""
        return Mixed(self.to_fraction().limit_denominator(max_denominator))

    @property
    def numerator(a):
        return a.to_fraction().numerator

    @property
    def denominator(a):
        return a._denominator

    @property
    def whole(a):
        """"""returns the whole number only (a % 1)

        &gt;&gt;&gt; Mixed(10,3).whole
        3
        """"""
        return a._whole

    @property
    def fnumerator(a):
        """""" returns the fractional portion's numerator.

        &gt;&gt;&gt; Mixed('1 3/4').fnumerator
        3
        """"""
        return a._numerator

    def _add(a, b):
        """"""a + b""""""
        return Mixed(a.numerator * b.denominator +
                     b.numerator * a.denominator,
                     a.denominator * b.denominator)
    __add__, __radd__ = Fraction._operator_fallbacks(_add, operator.add)

    def _sub(a, b):
        """"""a - b""""""
        return Mixed(a.numerator * b.denominator -
                        b.numerator * a.denominator,
                        a.denominator * b.denominator)

    __sub__, __rsub__ = Fraction._operator_fallbacks(_sub, operator.sub)

    def _mul(a, b):
        """"""a * b""""""
        return Mixed(a.numerator * b.numerator, a.denominator * b.denominator)

    __mul__, __rmul__ = Fraction._operator_fallbacks(_mul, operator.mul)


    def _div(a, b):
        """"""a / b""""""
        return Mixed(a.numerator * b.denominator,
                        a.denominator * b.numerator)

    __truediv__, __rtruediv__ = Fraction._operator_fallbacks(_div, operator.truediv)

    def __pow__(a, b):
        """"""a ** b

        If b is not an integer, the result will be a float or complex
        since roots are generally irrational. If b is an integer, the
        result will be rational.

        """"""
        if isinstance(b, numbers.Rational):
            if b.denominator == 1:
                return Mixed(Fraction(a) ** b)
            else:
                # A fractional power will generally produce an
                # irrational number.
                return float(a) ** float(b)
        else:
            return float(a) ** b

    def __rpow__(b, a):
        """"""a ** b""""""
        if b._denominator == 1 and b._numerator &gt;= 0:
            # If a is an int, keep it that way if possible.
            return a ** b.numerator

        if isinstance(a, numbers.Rational):
            return Mixed(a.numerator, a.denominator) ** b

        if b._denominator == 1:
            return a ** b.numerator

        return a ** float(b)

    def __pos__(a):
        """"""+a: Coerces a subclass instance to Fraction""""""
        return Mixed(a.numerator, a.denominator)

    def __neg__(a):
        """"""-a""""""
        return Mixed(-a.numerator, a.denominator)

    def __abs__(a):
        """"""abs(a)""""""
        return Mixed(abs(a.numerator), a.denominator)

    def __trunc__(a):
        """"""trunc(a)""""""
        if a.numerator &lt; 0:
            return -(-a.numerator // a.denominator)
        else:
            return a.numerator // a.denominator

    def __hash__(self):
        """"""hash(self)""""""
        return self.to_fraction().__hash__()

    def __eq__(a, b):
        """"""a == b""""""
        return Fraction(a) == b

    def _richcmp(self, other, op):
        """"""Helper for comparison operators, for internal use only.

        Implement comparison between a Rational instance `self`, and
        either another Rational instance or a float `other`.  If
        `other` is not a Rational instance or a float, return
        NotImplemented. `op` should be one of the six standard
        comparison operators.

        """"""
        return self.to_fraction()._richcmp(other, op)

    def __reduce__(self):
        return (self.__class__, (str(self),))

    def __copy__(self):
        if type(self) == Mixed:
            return self     # I'm immutable; therefore I am my own clone
        return self.__class__(self.numerator, self.denominator)

    def __deepcopy__(self, memo):
        if type(self) == Mixed:
            return self     # My components are also immutable
        return self.__class__(self.numerator, self.denominator)


Latest version download here.
",JB0x2D1,https://codereview.stackexchange.com/users/31982,"1. Bugs

Your doctests do not pass:

$ python3.3 -mdoctest cr35274.py
**********************************************************************
File ""./cr35274.py"", line 76, in cr35274.Mixed.__new__
Failed example:
    Mixed(Mixed(-1,1,2), Mixed(0,1,2), Mixed(0,1,2))
Expected:
    Mixed(-2, 1, 2)
    Note: The above call is similar to:
Got:
    Mixed(-2, 1, 2)
**********************************************************************
File ""./cr35274.py"", line 97, in cr35274.Mixed.__new__
Failed example:
    Mixed('-47e-2')
Expected:
    Mixed(0, -47, 100)
Got:
    Mixed(0, 47, 100)
**********************************************************************
1 items had failures:
   2 of  14 in cr35274.Mixed.__new__
***Test Failed*** 2 failures.


2. Commentary

As far as I can see, there are really only two things that you are trying to achieve:


To create the mixed fraction a b/c from the string ""a b/c"". But instead of implementing a whole new class, why not just write a function to parse the string and return a Fraction?

import re
from fractions import Fraction

_MIXED_FORMAT = re.compile(r""""""
    \A\s*                      # optional whitespace at the start, then
    (?P&lt;sign&gt;[-+]?)            # an optional sign, then
    (?P&lt;whole&gt;\d+)             # integer part
    \s+                        # whitespace
    (?P&lt;num&gt;\d+)               # numerator
    /(?P&lt;denom&gt;\d+)            # denominator
    \s*\Z                      # and optional whitespace to finish
"""""", re.VERBOSE)

def mixed(s):
    """"""Parse the string s as a (possibly mixed) fraction.

        &gt;&gt;&gt; mixed('1 2/3')
        Fraction(5, 3)
        &gt;&gt;&gt; mixed(' -1 2/3 ')
        Fraction(-5, 3)
        &gt;&gt;&gt; mixed('-0  12/15')
        Fraction(-4, 5)
        &gt;&gt;&gt; mixed('+45/15')
        Fraction(3, 1)

    """"""
    m = _MIXED_FORMAT.match(s)
    if not m:
        return Fraction(s)
    d = m.groupdict()
    result = int(d['whole']) + Fraction(int(d['num']), int(d['denom']))
    if d['sign'] == '-':
        return -result
    else:
        return result

To format a fraction in mixed notation. But why not just write this as a function:

def format_mixed(f):
    """"""Format the fraction f as a (possibly) mixed fraction.

        &gt;&gt;&gt; all(format_mixed(mixed(f)) == f for f in ['1 2/3', '-3 4/5', '7/8'])
        True

    """"""
    if abs(f) &lt;= 1 or f.denominator == 1:
        return str(f)
    return '{0} {1.numerator}/{1.denominator}'.format(int(f), abs(f - int(f)))



The rest of your code seems unnecessary and complicated.
",Gareth Rees,https://codereview.stackexchange.com/users/11728,http://codereview.stackexchange.com/questions/35274/mixed-number-fractions-class,TECHNOLOGY,codereview.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,1.0,1.0,1.0,0.5555555555555556,0.5555555555555556,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.6666666666666666,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.6666666666666666,0.0,0.6666666666666666,0.8888888888888888,Mixed number fraction class,"I'm looking for bugs.  I tried to test all functionality in a variety of ways.

#by JB0x2D1

from decimal import Decimal
import math
import numbers
import operator
from fractions import Fraction

class Mixed(Fraction):
    """"""This class implements Fraction, which implements rational numbers.""""""
        # We're immutable, so use __new__ not __init__
    def __new__(cls, whole=0, numerator=None, denominator=None):
        """"""Constructs a Rational.

        Takes a string like '-1 2/3' or '1.5', another Rational instance, a
        numerator/denominator pair, a float, or a whole number/numerator/
        denominator set.  If one or more non-zero arguments is negative,
        all are treated as negative and the result is negative.

        General behavior:  whole number + (numerator / denominator)

        Examples
        --------

        &gt;&gt;&gt; Mixed(Mixed(-1,1,2), Mixed(0,1,2), Mixed(0,1,2))
        Mixed(-2, 1, 2)
        Note: The above call is similar to:
        &gt;&gt;&gt; Fraction(-3,2) + Fraction(Fraction(-1,2), Fraction(1,2))
        Fraction(-5, 2)
        &gt;&gt;&gt; Mixed('-1 2/3')
        Mixed(-1, 2, 3)
        &gt;&gt;&gt; Mixed(10,-8)
        Mixed(-1, 1, 4)
        &gt;&gt;&gt; Mixed(Fraction(1,7), 5)
        Mixed(0, 1, 35)
        &gt;&gt;&gt; Mixed(Mixed(1, 7), Fraction(2, 3))
        Mixed(0, 3, 14)
        &gt;&gt;&gt; Mixed(Mixed(0, 3, 2), Fraction(2, 3), 2)
        Mixed(1, 5, 6)
        &gt;&gt;&gt; Mixed('314')
        Mixed(314, 0, 1)
        &gt;&gt;&gt; Mixed('-35/4')
        Mixed(-8, 3, 4)
        &gt;&gt;&gt; Mixed('3.1415')
        Mixed(3, 283, 2000)
        &gt;&gt;&gt; Mixed('-47e-2')
        Mixed(0, -47, 100)
        &gt;&gt;&gt; Mixed(1.47)
        Mixed(1, 2116691824864133, 4503599627370496)
        &gt;&gt;&gt; Mixed(2.25)
        Mixed(2, 1, 4)
        &gt;&gt;&gt; Mixed(Decimal('1.47'))
        Mixed(1, 47, 100)

        """"""
        self = super(Fraction, cls).__new__(cls)

        if (numerator is None) and (denominator is None): #single argument
            if isinstance(whole, numbers.Rational) or \
               isinstance(whole, float) or \
               isinstance(whole, Decimal):
                if type(whole) == Mixed:
                    return whole
                f = Fraction(whole)
                whole = 0
            elif isinstance(whole, str):
                # Handle construction from strings.
                arg = whole
                fail = False
                try:
                    f = Fraction(whole)
                    whole = 0
                except ValueError:
                    n = whole.split()
                    if (len(n) == 2):
                        try:
                            whole = Fraction(n[0])
                            f = Fraction(n[1])
                        except ValueError:
                            fail = True
                    else:
                        fail = True
                if fail:
                    raise ValueError('Invalid literal for Mixed: %r' %
                                         arg)
            else:
                raise TypeError(""argument should be a string ""
                                ""or a Rational instance"")
        elif (isinstance(numerator, numbers.Rational) and #two arguments
            isinstance(whole, numbers.Rational) and (denominator is None)):
            #here whole is treated as numerator and numerator as denominator
            if numerator == 0:
                raise ZeroDivisionError('Mixed(%s, 0)' % whole)
            f = Fraction(whole, numerator)
            whole = 0
        elif (isinstance(whole, numbers.Rational) and #three arguments
              isinstance(numerator, numbers.Rational) and
              isinstance(denominator, numbers.Rational)):
            if denominator == 0:
                raise ZeroDivisionError('Mixed(%s, %s, 0)' % whole, numerator)
            whole = Fraction(whole)
            f = Fraction(numerator, denominator)
        else:
            raise TypeError(""all three arguments should be ""
                            ""Rational instances"")
        #handle negative values and convert improper to mixed number fraction
        if (whole &lt; 0) and (f &gt; 0):
            f = -f + whole
        elif (whole &gt; 0) and (f &lt; 0):
            f += -whole
        else:
            f += whole
        numerator = f.numerator
        denominator = f.denominator
        if numerator &lt; 0:
            whole = -(-numerator // denominator)
            numerator = -numerator % denominator
        else:
            whole = numerator // denominator
            numerator %= denominator
        self._whole = whole
        self._numerator = numerator
        self._denominator = denominator
        return self

    def __repr__(self):
        """"""repr(self)""""""
        return ('Mixed(%s, %s, %s)' % (self._whole, self._numerator,
                                       self._denominator))

    def __str__(self):
        """"""str(self)""""""
        if self._numerator == 0:
            return str(self._whole)
        elif self._whole != 0:
            return '%s %s/%s' % (self._whole, self._numerator,
                                 self._denominator)
        else:
            return '%s/%s' % (self._numerator, self._denominator)

    def to_fraction(self):
        n = self._numerator
        if self._whole != 0:
            if self._whole &lt; 0:
                n *= -1
            n += self._whole * self._denominator
        return Fraction(n, self._denominator)

    def limit_denominator(self, max_denominator=1000000):
        """"""Closest Fraction to self with denominator at most max_denominator.

        &gt;&gt;&gt; Mixed('3.141592653589793').limit_denominator(10)
        Mixed(3, 1, 7)
        &gt;&gt;&gt; Mixed('3.141592653589793').limit_denominator(100)
        Mixed(3, 14, 99)
        &gt;&gt;&gt; Mixed(4321, 8765).limit_denominator(10000)
        Mixed(0, 4321, 8765)
        """"""
        return Mixed(self.to_fraction().limit_denominator(max_denominator))

    @property
    def numerator(a):
        return a.to_fraction().numerator

    @property
    def denominator(a):
        return a._denominator

    @property
    def whole(a):
        """"""returns the whole number only (a % 1)

        &gt;&gt;&gt; Mixed(10,3).whole
        3
        """"""
        return a._whole

    @property
    def fnumerator(a):
        """""" returns the fractional portion's numerator.

        &gt;&gt;&gt; Mixed('1 3/4').fnumerator
        3
        """"""
        return a._numerator

    def _add(a, b):
        """"""a + b""""""
        return Mixed(a.numerator * b.denominator +
                     b.numerator * a.denominator,
                     a.denominator * b.denominator)
    __add__, __radd__ = Fraction._operator_fallbacks(_add, operator.add)

    def _sub(a, b):
        """"""a - b""""""
        return Mixed(a.numerator * b.denominator -
                        b.numerator * a.denominator,
                        a.denominator * b.denominator)

    __sub__, __rsub__ = Fraction._operator_fallbacks(_sub, operator.sub)

    def _mul(a, b):
        """"""a * b""""""
        return Mixed(a.numerator * b.numerator, a.denominator * b.denominator)

    __mul__, __rmul__ = Fraction._operator_fallbacks(_mul, operator.mul)


    def _div(a, b):
        """"""a / b""""""
        return Mixed(a.numerator * b.denominator,
                        a.denominator * b.numerator)

    __truediv__, __rtruediv__ = Fraction._operator_fallbacks(_div, operator.truediv)

    def __pow__(a, b):
        """"""a ** b

        If b is not an integer, the result will be a float or complex
        since roots are generally irrational. If b is an integer, the
        result will be rational.

        """"""
        if isinstance(b, numbers.Rational):
            if b.denominator == 1:
                return Mixed(Fraction(a) ** b)
            else:
                # A fractional power will generally produce an
                # irrational number.
                return float(a) ** float(b)
        else:
            return float(a) ** b

    def __rpow__(b, a):
        """"""a ** b""""""
        if b._denominator == 1 and b._numerator &gt;= 0:
            # If a is an int, keep it that way if possible.
            return a ** b.numerator

        if isinstance(a, numbers.Rational):
            return Mixed(a.numerator, a.denominator) ** b

        if b._denominator == 1:
            return a ** b.numerator

        return a ** float(b)

    def __pos__(a):
        """"""+a: Coerces a subclass instance to Fraction""""""
        return Mixed(a.numerator, a.denominator)

    def __neg__(a):
        """"""-a""""""
        return Mixed(-a.numerator, a.denominator)

    def __abs__(a):
        """"""abs(a)""""""
        return Mixed(abs(a.numerator), a.denominator)

    def __trunc__(a):
        """"""trunc(a)""""""
        if a.numerator &lt; 0:
            return -(-a.numerator // a.denominator)
        else:
            return a.numerator // a.denominator

    def __hash__(self):
        """"""hash(self)""""""
        return self.to_fraction().__hash__()

    def __eq__(a, b):
        """"""a == b""""""
        return Fraction(a) == b

    def _richcmp(self, other, op):
        """"""Helper for comparison operators, for internal use only.

        Implement comparison between a Rational instance `self`, and
        either another Rational instance or a float `other`.  If
        `other` is not a Rational instance or a float, return
        NotImplemented. `op` should be one of the six standard
        comparison operators.

        """"""
        return self.to_fraction()._richcmp(other, op)

    def __reduce__(self):
        return (self.__class__, (str(self),))

    def __copy__(self):
        if type(self) == Mixed:
            return self     # I'm immutable; therefore I am my own clone
        return self.__class__(self.numerator, self.denominator)

    def __deepcopy__(self, memo):
        if type(self) == Mixed:
            return self     # My components are also immutable
        return self.__class__(self.numerator, self.denominator)


Latest version download here.
","1. Bugs

Your doctests do not pass:

$ python3.3 -mdoctest cr35274.py
**********************************************************************
File ""./cr35274.py"", line 76, in cr35274.Mixed.__new__
Failed example:
    Mixed(Mixed(-1,1,2), Mixed(0,1,2), Mixed(0,1,2))
Expected:
    Mixed(-2, 1, 2)
    Note: The above call is similar to:
Got:
    Mixed(-2, 1, 2)
**********************************************************************
File ""./cr35274.py"", line 97, in cr35274.Mixed.__new__
Failed example:
    Mixed('-47e-2')
Expected:
    Mixed(0, -47, 100)
Got:
    Mixed(0, 47, 100)
**********************************************************************
1 items had failures:
   2 of  14 in cr35274.Mixed.__new__
***Test Failed*** 2 failures.


2. Commentary

As far as I can see, there are really only two things that you are trying to achieve:


To create the mixed fraction a b/c from the string ""a b/c"". But instead of implementing a whole new class, why not just write a function to parse the string and return a Fraction?

import re
from fractions import Fraction

_MIXED_FORMAT = re.compile(r""""""
    \A\s*                      # optional whitespace at the start, then
    (?P&lt;sign&gt;[-+]?)            # an optional sign, then
    (?P&lt;whole&gt;\d+)             # integer part
    \s+                        # whitespace
    (?P&lt;num&gt;\d+)               # numerator
    /(?P&lt;denom&gt;\d+)            # denominator
    \s*\Z                      # and optional whitespace to finish
"""""", re.VERBOSE)

def mixed(s):
    """"""Parse the string s as a (possibly mixed) fraction.

        &gt;&gt;&gt; mixed('1 2/3')
        Fraction(5, 3)
        &gt;&gt;&gt; mixed(' -1 2/3 ')
        Fraction(-5, 3)
        &gt;&gt;&gt; mixed('-0  12/15')
        Fraction(-4, 5)
        &gt;&gt;&gt; mixed('+45/15')
        Fraction(3, 1)

    """"""
    m = _MIXED_FORMAT.match(s)
    if not m:
        return Fraction(s)
    d = m.groupdict()
    result = int(d['whole']) + Fraction(int(d['num']), int(d['denom']))
    if d['sign'] == '-':
        return -result
    else:
        return result

To format a fraction in mixed notation. But why not just write this as a function:

def format_mixed(f):
    """"""Format the fraction f as a (possibly) mixed fraction.

        &gt;&gt;&gt; all(format_mixed(mixed(f)) == f for f in ['1 2/3', '-3 4/5', '7/8'])
        True

    """"""
    if abs(f) &lt;= 1 or f.denominator == 1:
        return str(f)
    return '{0} {1.numerator}/{1.denominator}'.format(int(f), abs(f - int(f)))



The rest of your code seems unnecessary and complicated.
"
1565,1565,2458,"If $f: \mathbb Q\to \mathbb Q$ is a homomorphism, prove that $f(x)=0$ for all $x\in\mathbb Q$ or $f(x)=x$ for all $x$ in $\mathbb Q$.","If $f: \mathbb Q\to \mathbb Q$ is a homomorphism, prove that $f(x)=0$ for all $x\in\mathbb Q$ or $f(x)=x$ for all $x$ in $\mathbb Q$.

I'm wondering if you can help me with this one? 
",Mirna,https://math.stackexchange.com/users/36579,"Any multiplicative homomorphism must send $1$ to an idempotent.

The only idempotents of $\mathbb{Q}$ are $0$ and $1$ (the roots of $x^2-x=x(x-1)$), so $\varphi(1)=0$ or $\varphi(1)=1$.

If $\varphi(1)=0$, then $\varphi(a) = \varphi(1a) = \varphi(1)\varphi(a)=0$, so $\varphi(x)=0$ for all $x$.

If $\varphi(1)=1$ and the map is additive, then prove inductively that $\varphi(n)=n$ for all positive integers, hence for all integers; deduce that $\varphi(q) = q$ for all $q$. 
",Arturo Magidin,https://math.stackexchange.com/users/742,http://math.stackexchange.com/questions/175477/if-f-mathbb-q-to-mathbb-q-is-a-homomorphism-prove-that-fx-0-for-all-x,SCIENCE,math.stackexchange.com,0.6666666666666666,0.6666666666666666,0.0,0.0,1.0,0.5,0.6666666666666666,0.4444444444444444,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.8888888888888888,"If $f: \ mathbb Q \ to \ mathbb q $is homomorphic, then prove that $f (x) = 0 $means all $X \ in \ mathbb q $, or $f (x) = x $means all $x $in $\ mathbb q $.","If $f: \ mathbb Q \ to \ mathbb q $is homomorphic, then prove that $f (x) = 0 $means all $X \ in \ mathbb q $, or $f (x) = x $means all $x $in $\ mathbb q $.","Any multiplicative homomorphism must send $1$ to an idempotent.

The only idempotents of $\mathbb{Q}$ are $0$ and $1$ (the roots of $x^2-x=x(x-1)$), so $\varphi(1)=0$ or $\varphi(1)=1$.

If $\varphi(1)=0$, then $\varphi(a) = \varphi(1a) = \varphi(1)\varphi(a)=0$, so $\varphi(x)=0$ for all $x$.

If $\varphi(1)=1$ and the map is additive, then prove inductively that $\varphi(n)=n$ for all positive integers, hence for all integers; deduce that $\varphi(q) = q$ for all $q$. 
"
4495,4495,7128,How to find inter-country buses in Europe?,"I was traveling from Zurich to Frankfurt, and when I asked a tourist information, the guy advised that the best way is train. I took the train, and when arrived in Frankfurt, I found that there is a German company having bus from Zurich to Frankfurt with 1/3 of the train price.

The problem is that bus companies are small and not-connected. On the other hand, such small companies have website mainly in their local languages (not English). As a result, it is difficult for a foreigner to find the best option for bus from a country to another; particularly, as they operate from small stations rather than a big united terminal (as one can go and ask for options).

Are there resources (e.g., websites) for searching all bus routes around Europe?
",Googlebot,https://travel.stackexchange.com/users/2118,"Busbud is quickly becoming the go to site for bus tickets around the world, as it's adding more inventory to its database. Currently there are many routes in Europe that you can search, compare and book bus tickets directly on the busbud site, otherwise you can view schedules and prices and get redirected to the bus companies website to purchase your ticket.

Very soon, there will be some new bus routes added for Spain and Turkey as well as some other countries around Europe and the world.

Also another thing to keep in mind is that there is no additional fees for booking on busbud, the price you will pay is the same as on the website of the bus company.
",Doa,https://travel.stackexchange.com/users/16955,http://travel.stackexchange.com/questions/33896/how-to-find-inter-country-buses-in-europe,CULTURE,travel.stackexchange.com,1.0,0.8888888888888888,0.0,1.0,0.6666666666666666,0.6666666666666666,0.7777777777777778,1.0,0.3333333333333333,0.0,1.0,0.3333333333333333,0.0,0.0,0.0,1.0,1.0,0.3333333333333333,0.0,0.0,1.0,1.0,0.7777777777777778,1.0,1.0,0.8666666666666666,0.3333333333333333,0.0,0.6666666666666666,1.0,How to find transnational buses in Europe?,"I was traveling from Zurich to Frankfurt, and when I asked a tourist information, the guy advised that the best way is train. I took the train, and when arrived in Frankfurt, I found that there is a German company having bus from Zurich to Frankfurt with 1/3 of the train price.

The problem is that bus companies are small and not-connected. On the other hand, such small companies have website mainly in their local languages (not English). As a result, it is difficult for a foreigner to find the best option for bus from a country to another; particularly, as they operate from small stations rather than a big united terminal (as one can go and ask for options).

Are there resources (e.g., websites) for searching all bus routes around Europe?
","Busbud is quickly becoming the go to site for bus tickets around the world, as it's adding more inventory to its database. Currently there are many routes in Europe that you can search, compare and book bus tickets directly on the busbud site, otherwise you can view schedules and prices and get redirected to the bus companies website to purchase your ticket.

Very soon, there will be some new bus routes added for Spain and Turkey as well as some other countries around Europe and the world.

Also another thing to keep in mind is that there is no additional fees for booking on busbud, the price you will pay is the same as on the website of the bus company.
"
2554,2554,4066,How do I set up multiple printing defaults for one printer?,"I have a printer capable of printing high res photos on photo paper, and duplex documents on plain A4.

I have set the printer up twice (i.e. two separate printers pointing to the same URI) using the CUPS interface at http://localhost:631, once called Documents, once called Photos. For each of these instances I have set up the appropriate defaults (media type, size, print quality, duplex...). CUPS seems to remember these fine but applications (e.g. LibreOffice, EOG, firefox ... under Gnome Shell FWIW) seem to have some weird other default that bears no resemblance to either the defaults I set up, nor the last settings I used with any particular application.

It's a problem because there are so many settings to change that it adds a couple of minutes to each and every print job. Inevitably I forget one or two and end up having to reprint the job.

Seems there must be somewhere that these defaults get stored? Anyone shed any light on it?
",artfulrobot,https://askubuntu.com/users/28930,"I have three CUPS print queues configured with the same printer URI. Queue ""deskjet"" is configured with my local standard paper, queue ""Legal"" is configured with ""Legal"" size paper, and queue ""Envelopes"" is configured for #10 Envelopes. ""Legal"" and ""Envelopes"" queues are stopped (via cupsdisable). 

First, add the queue in CUPS  (http://localhost:631), then use Administration->Modify Printer to change the paper type and other characteristics.

I use my setup like this:

# print to the Envelope queue ( select Envelope queue in your app)
envelope .envelope/addresses/Friend4 | lpr -PEnvelope 
cupsdisable deskjet
# remove regular paper, load envelopes
cupsenable Envelope
# wait until envelope is printed, then
cupsdisable Envelope
cupsenable deskjet

",waltinator,https://askubuntu.com/users/25618,http://askubuntu.com/questions/252143/how-do-i-set-up-multiple-printing-defaults-for-one-printer,TECHNOLOGY,askubuntu.com,1.0,0.6666666666666666,0.0,1.0,1.0,1.0,0.5555555555555556,0.5555555555555556,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,0.8888888888888888,How to set multiple print defaults for a printer?,"I have a printer capable of printing high res photos on photo paper, and duplex documents on plain A4.

I have set the printer up twice (i.e. two separate printers pointing to the same URI) using the CUPS interface at http://localhost:631, once called Documents, once called Photos. For each of these instances I have set up the appropriate defaults (media type, size, print quality, duplex...). CUPS seems to remember these fine but applications (e.g. LibreOffice, EOG, firefox ... under Gnome Shell FWIW) seem to have some weird other default that bears no resemblance to either the defaults I set up, nor the last settings I used with any particular application.

It's a problem because there are so many settings to change that it adds a couple of minutes to each and every print job. Inevitably I forget one or two and end up having to reprint the job.

Seems there must be somewhere that these defaults get stored? Anyone shed any light on it?
","I have three CUPS print queues configured with the same printer URI. Queue ""deskjet"" is configured with my local standard paper, queue ""Legal"" is configured with ""Legal"" size paper, and queue ""Envelopes"" is configured for #10 Envelopes. ""Legal"" and ""Envelopes"" queues are stopped (via cupsdisable). 

First, add the queue in CUPS  (http://localhost:631), then use Administration->Modify Printer to change the paper type and other characteristics.

I use my setup like this:

# print to the Envelope queue ( select Envelope queue in your app)
envelope .envelope/addresses/Friend4 | lpr -PEnvelope 
cupsdisable deskjet
# remove regular paper, load envelopes
cupsenable Envelope
# wait until envelope is printed, then
cupsdisable Envelope
cupsenable deskjet

"
346,346,552,"Where are the fishing spots surrounded by rocks etc, and do they actually increase the chances of catching fish?","While talking to the fisher guy in the fishing hut he told me the best place to fish was in small places surrounded be rocks or wall. 

Is this true? If so, where are theses places in the game? Is there anything else that helps to catch more fish? 

For example, I have noticed that fishing next to a fisherman seems to have a higher chance of catching something. is this correct, and what else helps with fishing?
",Qwertie,https://gaming.stackexchange.com/users/57500,"Yes, fishing in a small tile of water walled off by shore and/or rocks on three of the 4 sides decreases the chance of ""Nothing seems to be biting..."" message. This does not reduce the chances of not catching anything to 0, but it is considerably better than it is otherwise.

However, if you are chain-fishing for shiny Pokemon, your best bet is is to have your lead Pokemon have the ability Suction Cups or Sticky Hold. If the Pokemon you've chosen for the task is under-leveled compared to what you are fishing, having it hold something like a smoke ball will allow you to flee from the hordes of non-shinies without fail.

For more information on how chain-fishing works (specifically what will and will not break the chain) see this question/answer; How does chain fishing work?
",Trent Hawkins,https://gaming.stackexchange.com/users/30115,http://gaming.stackexchange.com/questions/153619/where-are-the-fishing-spots-surrounded-by-rocks-etc-and-do-they-actually-increa,CULTURE,gaming.stackexchange.com,0.8888888888888888,0.6666666666666666,0.0,0.0,0.3333333333333333,0.6666666666666666,0.7777777777777778,0.6666666666666666,1.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.0,0.6666666666666666,0.8333333333333334,0.6666666666666666,0.8333333333333334,0.6666666666666666,0.6,0.0,0.0,1.0,0.7777777777777778,"Where are the fishing spots around the rocks, and do they really increase the chances of fishing?","While talking to the fisher guy in the fishing hut he told me the best place to fish was in small places surrounded be rocks or wall. 

Is this true? If so, where are theses places in the game? Is there anything else that helps to catch more fish? 

For example, I have noticed that fishing next to a fisherman seems to have a higher chance of catching something. is this correct, and what else helps with fishing?
","Yes, fishing in a small tile of water walled off by shore and/or rocks on three of the 4 sides decreases the chance of ""Nothing seems to be biting..."" message. This does not reduce the chances of not catching anything to 0, but it is considerably better than it is otherwise.

However, if you are chain-fishing for shiny Pokemon, your best bet is is to have your lead Pokemon have the ability Suction Cups or Sticky Hold. If the Pokemon you've chosen for the task is under-leveled compared to what you are fishing, having it hold something like a smoke ball will allow you to flee from the hordes of non-shinies without fail.

For more information on how chain-fishing works (specifically what will and will not break the chain) see this question/answer; How does chain fishing work?
"
1578,1578,2482,How to restore function attributes to default,"Adding an attribute to a function is easy and clearing attribute is easy also. But I don't know really how to restore the attributes of a function to its defaults. All I do is quit the kernel or close Mathematica and open again.

any idea?

Update

For example :

Log // Attributes
(* {Listable, NumericFunction, Protected} *)

ClearAttributes[Log, Listable]
Log // Attributes
(* {NumericFunction, Protected} *)


Now is there any way to restore the attributes of Log to its defaults other than SetAttributes or quitting Mathematica?

Thanks.
",Algohi,https://mathematica.stackexchange.com/users/13548,"If you have not saved the attributes before changing them, and also can't quit the Kernel, then you could launch a Subkernel and get the original attributes that way:

ClearAttributes[Log, Listable]

Attributes[Log]



  {NumericFunction, Protected}


First@ParallelEvaluate[Attributes[Log]]



  {Listable,NumericFunction,Protected}

",Jens,https://mathematica.stackexchange.com/users/245,http://mathematica.stackexchange.com/questions/60382/how-to-restore-function-attributes-to-default,TECHNOLOGY,mathematica.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.7777777777777778,0.8888888888888888,0.5555555555555556,1.0,0.8888888888888888,0.8,1.0,0.0,0.0,0.8888888888888888,How to restore function properties to default values,"Adding an attribute to a function is easy and clearing attribute is easy also. But I don't know really how to restore the attributes of a function to its defaults. All I do is quit the kernel or close Mathematica and open again.

any idea?

Update

For example :

Log // Attributes
(* {Listable, NumericFunction, Protected} *)

ClearAttributes[Log, Listable]
Log // Attributes
(* {NumericFunction, Protected} *)


Now is there any way to restore the attributes of Log to its defaults other than SetAttributes or quitting Mathematica?

Thanks.
","If you have not saved the attributes before changing them, and also can't quit the Kernel, then you could launch a Subkernel and get the original attributes that way:

ClearAttributes[Log, Listable]

Attributes[Log]



  {NumericFunction, Protected}


First@ParallelEvaluate[Attributes[Log]]



  {Listable,NumericFunction,Protected}

"
612,612,958,Left align equation description,"I have a short description for each of my equations. I want to have them flushleft (similar to the equation numbers which are flushright). How can I do that?

Here is a MWE:

\documentclass{article}
\usepackage{amsmath}
\begin{document}
\begin{equation}
\text{this is my first equation: } z = x
\end{equation}
\begin{equation}
\text{this is my second equation: } z = x+y
\end{equation}
\end{document}


And my desired output is like this:

",Salman,https://tex.stackexchange.com/users/26272,"A regular align with some macro-involvement would obtain the desired result:



\documentclass{article}
\usepackage{amsmath}% http://ctan.org/pkg/amsmath
\newcommand{\alignmath}[2]{\makebox[0pt][#1]{$\displaystyle#2$}}
\newcommand{\lmath}[1]{\alignmath{l}{#1}}
\newcommand{\rmath}[1]{\alignmath{r}{#1}}
\newcommand{\cmath}[1]{\alignmath{c}{#1}}
\begin{document}

\begin{align}
  &amp; \text{this is my first equation:}  &amp; \cmath{z=x}   &amp; \\
  &amp; \text{this is my second equation:} &amp; \cmath{z=x+y} &amp; \\
  &amp; \text{this is my third equation:} &amp; \lmath{z=x+y}  &amp; \\
  &amp; \text{this is my fourth equation:} &amp; \rmath{z=x+y} &amp; \\
  &amp; \text{this is my last equation:} &amp; z &amp;= x+y
\end{align}
\end{document}


\cmath inserts a zero-width box that is centred. The advantage here is that you maintain the align-like vertical spacing.

I've added \lmath and \rmath for completeness, since \makebox allows for left- and right-aligned boxes. Also, the vertical rule indicates the horizontal alignment with respect to the default align - also supported in the above syntax.
",Werner,https://tex.stackexchange.com/users/5764,http://tex.stackexchange.com/questions/119621/left-align-equation-description,TECHNOLOGY,tex.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.3333333333333333,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,1.0,Left justification formula description,"I have a short description for each of my equations. I want to have them flushleft (similar to the equation numbers which are flushright). How can I do that?

Here is a MWE:

\documentclass{article}
\usepackage{amsmath}
\begin{document}
\begin{equation}
\text{this is my first equation: } z = x
\end{equation}
\begin{equation}
\text{this is my second equation: } z = x+y
\end{equation}
\end{document}


And my desired output is like this:

","A regular align with some macro-involvement would obtain the desired result:



\documentclass{article}
\usepackage{amsmath}% http://ctan.org/pkg/amsmath
\newcommand{\alignmath}[2]{\makebox[0pt][#1]{$\displaystyle#2$}}
\newcommand{\lmath}[1]{\alignmath{l}{#1}}
\newcommand{\rmath}[1]{\alignmath{r}{#1}}
\newcommand{\cmath}[1]{\alignmath{c}{#1}}
\begin{document}

\begin{align}
  &amp; \text{this is my first equation:}  &amp; \cmath{z=x}   &amp; \\
  &amp; \text{this is my second equation:} &amp; \cmath{z=x+y} &amp; \\
  &amp; \text{this is my third equation:} &amp; \lmath{z=x+y}  &amp; \\
  &amp; \text{this is my fourth equation:} &amp; \rmath{z=x+y} &amp; \\
  &amp; \text{this is my last equation:} &amp; z &amp;= x+y
\end{align}
\end{document}


\cmath inserts a zero-width box that is centred. The advantage here is that you maintain the align-like vertical spacing.

I've added \lmath and \rmath for completeness, since \makebox allows for left- and right-aligned boxes. Also, the vertical rule indicates the horizontal alignment with respect to the default align - also supported in the above syntax.
"
1079,1079,1703,How to remember a trusted machine using two factor authentication (like Google's system),"We are developing a web application that will use two factor authentication. We are likely to try and emulate something similar to that used by google, where to login you enter a username and password, and then receive a token in an SMS message to be entered as well.

We would like to allow users to remember a client machine if they would like to so that they can login for 30 days without requiring the second authentication method. What information will we have access to (through headers of the web page requests etc.) which we can use to uniquely identify this trusted client machine? 

Obviously a user can have more than one trusted client machine, and I completely expect that if they use two different browsers on the same trusted machine machine, each browser will have to be trusted independently.

Setting a cookie on the machine with some GUID which means this is trusted simply would not be good enough, as someone else could just copy the cookie, and create it on their own browser circumventing the two factor authentication.
",Marryat,https://security.stackexchange.com/users/21071,"I don't think that it is entirely possible with just Javascript/PHP (or some other server side language) to uniquely imprint/identify a computer.

Remember, whatever you do, someone with malicious intent can just copy the Chrome/Firefox user data directory to a similar system (same OS, etc). Indeed, that's the easiest thing to do, since you don't have to hunt for the cookies. Javascript can't read anything outside these directories, so they have just duplicated the system.

However, you can use Flash/Java to fingerprint the browser. Unfortunately, the browser fingerprint can change if the user installs fonts/etc. Besides, your users will have to allow the Flash/Java to run -- nowadays quite a few people are disabling Java due to the recent 0 Day exploit. You don't want to force your users to have to use these. Anyway, one can easily replicate a fingerprint by replicating the system (which takes time, but isn't too hard).

In the end, two factor auth is all about (a) having a password, and (b) having physical access to a device. If you are giving someone unsupervised access to your computer while logged in as you, part (b) is compromised anyway, in a different manner.



To answer your question, though:


You can put a unique GUID in a cookie
You can put another GUID in localStorage
You can associate part of the browser User-Agent request header with the account. For example, my User Agent is User-Agent:Mozilla/5.0 (X11; Linux i686) AppleWebKit/536.11 (KHTML, like Gecko) Ubuntu/12.04 Chromium/20.0.1132.47 Chrome/20.0.1132.47 Safari/536.11. From here, you can extract my browser name (which won't change), OS name and version (which will change occasionally), whether or not my computer is 32 bit, etc.
navigator.plugins -- This is an array of all the plugins installed on the browser. Maybe not a good idea for 2 factor authentication, though, since this changes often.


Note that all of these can be easily spoofed. It's just extra hoops for a would-be hacker to jump through.

Again, you can try using fingerprinting techniques that deal with reading the list of installed fonts, etc. Again, this can be circumvented, but it's much harder. You can also use Java to store cookie-like files in random places on the computer (not sure if that's a good idea)

Edit: As Joel mentions in the comments, you should also have a way of revoking ""trusted computers"" (simply dissociate the GUID in your database). And this should apply when the password is changed as well.
",Manishearth,https://security.stackexchange.com/users/7497,http://security.stackexchange.com/questions/31327/how-to-remember-a-trusted-machine-using-two-factor-authentication-like-googles,TECHNOLOGY,security.stackexchange.com,1.0,0.5555555555555556,0.0,1.0,1.0,1.0,0.4444444444444444,0.4444444444444444,0.3333333333333333,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.6666666666666666,0.6666666666666666,1.0,0.8888888888888888,How to use two factor authentication to remember trusted machines (such as Google's system),"We are developing a web application that will use two factor authentication. We are likely to try and emulate something similar to that used by google, where to login you enter a username and password, and then receive a token in an SMS message to be entered as well.

We would like to allow users to remember a client machine if they would like to so that they can login for 30 days without requiring the second authentication method. What information will we have access to (through headers of the web page requests etc.) which we can use to uniquely identify this trusted client machine? 

Obviously a user can have more than one trusted client machine, and I completely expect that if they use two different browsers on the same trusted machine machine, each browser will have to be trusted independently.

Setting a cookie on the machine with some GUID which means this is trusted simply would not be good enough, as someone else could just copy the cookie, and create it on their own browser circumventing the two factor authentication.
","I don't think that it is entirely possible with just Javascript/PHP (or some other server side language) to uniquely imprint/identify a computer.

Remember, whatever you do, someone with malicious intent can just copy the Chrome/Firefox user data directory to a similar system (same OS, etc). Indeed, that's the easiest thing to do, since you don't have to hunt for the cookies. Javascript can't read anything outside these directories, so they have just duplicated the system.

However, you can use Flash/Java to fingerprint the browser. Unfortunately, the browser fingerprint can change if the user installs fonts/etc. Besides, your users will have to allow the Flash/Java to run -- nowadays quite a few people are disabling Java due to the recent 0 Day exploit. You don't want to force your users to have to use these. Anyway, one can easily replicate a fingerprint by replicating the system (which takes time, but isn't too hard).

In the end, two factor auth is all about (a) having a password, and (b) having physical access to a device. If you are giving someone unsupervised access to your computer while logged in as you, part (b) is compromised anyway, in a different manner.



To answer your question, though:


You can put a unique GUID in a cookie
You can put another GUID in localStorage
You can associate part of the browser User-Agent request header with the account. For example, my User Agent is User-Agent:Mozilla/5.0 (X11; Linux i686) AppleWebKit/536.11 (KHTML, like Gecko) Ubuntu/12.04 Chromium/20.0.1132.47 Chrome/20.0.1132.47 Safari/536.11. From here, you can extract my browser name (which won't change), OS name and version (which will change occasionally), whether or not my computer is 32 bit, etc.
navigator.plugins -- This is an array of all the plugins installed on the browser. Maybe not a good idea for 2 factor authentication, though, since this changes often.


Note that all of these can be easily spoofed. It's just extra hoops for a would-be hacker to jump through.

Again, you can try using fingerprinting techniques that deal with reading the list of installed fonts, etc. Again, this can be circumvented, but it's much harder. You can also use Java to store cookie-like files in random places on the computer (not sure if that's a good idea)

Edit: As Joel mentions in the comments, you should also have a way of revoking ""trusted computers"" (simply dissociate the GUID in your database). And this should apply when the password is changed as well.
"
4336,4336,6904,Decompiler Bytecode and Obfuscators,"Can we completely reverse-engineer the source code from java bytecode ? Why this feature is allowed in Java and How successful are java decompilers against obfuscators.?
",Suraj Menon,https://stackoverflow.com/users/1662935,"you can get source code from binary these days. Although the source code obtained by Java's bytecode is more readable, obfuscating will make it slightly unreadable. Its not that only Java can be reverse engineered to code. Even C/C++ these days (with Hexrays plugin for IDA Pro) can be decompiled to source. Obfuscaters will make it hard to read but not impossible. There is nothing that can save your program from an intelligent and capable reverse engineer. :).

Good luck.
",Aniket Inge,https://stackoverflow.com/users/1680957,http://stackoverflow.com/questions/13098606/decompiler-bytecode-and-obfuscators,STACKOVERFLOW,stackoverflow.com,1.0,0.3333333333333333,0.0,0.6666666666666666,0.3333333333333333,1.0,0.4444444444444444,0.3333333333333333,1.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.3333333333333333,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.3333333333333333,0.0,1.0,1.0,Decompiler bytecode and obfuscator,Can we completely reverse engineer the source code from Java bytecode? Why is this feature allowed in Java and how successful is java decompiler for obfuscator.?,"Now you can get the source code from the binary. Although Java bytecode gets more readable source code, obfuscation makes it slightly unreadable. This is not to say that only Java can reverse engineer code. Even with C / C + +, these days (the hixengl plug-in with IDA Pro) can be decompiled to source code. Obfuscators can make reading difficult, but not impossible. Nothing can save your program from intelligent and capable reverse engineering. ()."
3197,3197,5096,97 Honda Civic dies in neutral,"I have a 97 Honda Civic that will occasionally die in neutral. This is what I have done so far:


Replace both O2 sensors
Replace MAP sensor
Replace Air filter
Added Lucas treatment to fuel tank 


Even after the above changes, occasionally when coasting in neutral the rpm's will eventually drop to 0 and the engine will die. It starts back up just fine. My engine and fuel mileage have definitively improved with all the changes, especially after using Lucas.
",BrandonG,https://mechanics.stackexchange.com/users/4549,"Fix the oil leak then replace the distributor assembly. Oil covers the cam sensor eye inside the distributor causing the ecm to lose its position and stall out. Pull the distributor cap and see if any oil has gotten inside the housing.
",user4546,https://mechanics.stackexchange.com/users/4546,http://mechanics.stackexchange.com/questions/8856/97-honda-civic-dies-in-neutral,CULTURE,mechanics.stackexchange.com,0.7777777777777778,0.6666666666666666,0.0,1.0,1.0,0.6666666666666666,0.7777777777777778,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,1.0,0.0,0.6666666666666666,0.7777777777777778,0.5555555555555556,0.7777777777777778,0.8888888888888888,0.7333333333333333,1.0,0.0,0.3333333333333333,0.7777777777777778,97 Honda Civic died in neutral,"I have a 97 Honda Civic that will occasionally die in neutral. This is what I have done so far:


Replace both O2 sensors
Replace MAP sensor
Replace Air filter
Added Lucas treatment to fuel tank 


Even after the above changes, occasionally when coasting in neutral the rpm's will eventually drop to 0 and the engine will die. It starts back up just fine. My engine and fuel mileage have definitively improved with all the changes, especially after using Lucas.
","Fix the oil leak then replace the distributor assembly. Oil covers the cam sensor eye inside the distributor causing the ecm to lose its position and stall out. Pull the distributor cap and see if any oil has gotten inside the housing.
"
151,151,239,Disabled buttons while long running task,"My application has a toolbar and a lot of buttons on it. Some buttons start a long running processes(tasks). At this moment every task executes asynchronously to allow user to do something else while task is executing. Thereby I have a problem: user can click the same button many times to start others same tasks. I have decided to disable button before start task and enable it after finish. Other problem, I should to protect other buttons from pressing (some of these would be disabled after done current tasks). In general, I have to disable all buttons (toolbar) to be sure that user cannot do something dangerous with buttons at transient. My questions are: 

Could someone recommend way to distract users from flickering (disable/enable buttons) or how to involve them in process, how to made them filling that task is not so long?

Maybe I should to execute tasks synchronously and disable all UI for time of execution? 

By the way:
Delay can vary from 1 to 10 sec. About progress bar: it is a difficult to calculate current progress, and it causes some performance degradation (task can be done faster without any additional UI iterations from other threads).  
",igor,https://ux.stackexchange.com/users/79,"A quick suggestion: can you make it a ""checkbox button"", having its ""Pressed""/""Checked"" state indicate that task is running. Then automatically ""un-press""/""un-check"" it when the task async finishes?
",Jeroen,https://ux.stackexchange.com/users/7242,http://ux.stackexchange.com/questions/10336/disabled-buttons-while-long-running-task,TECHNOLOGY,ux.stackexchange.com,0.3333333333333333,0.3333333333333333,0.0,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,0.3333333333333333,0.6666666666666666,0.3333333333333333,0.6666666666666666,1.0,0.6,1.0,0.0,1.0,0.6666666666666666,Disable button when running task for a long time,"My app has a toolbar and many buttons. Some buttons start long-running processes (tasks). At this point, each task is executed asynchronously to allow the user to perform other operations while the task is executing. So I ran into a problem: users can click the same button multiple times to start the same task for other users. I decided to disable the button before I started the task and enable it when I finished. Another problem is that I should protect other buttons from being pressed (some of them will be disabled after completing the current task). Generally speaking, I have to disable all buttons (toolbars) to make sure that users can't do dangerous things to buttons in an instant. My question is:","A simple suggestion: can you make it a ""check box"" button? Its press / select state indicates that the task is running. Then ""cancel pressing"" or ""cancel checking"" automatically when the task completes asynchronously?"
1992,1992,3180,Is netrender only useful for multiple frames?,"Trying to speed-up render times on a large single-frame Cycles image by using netrender and a spare machine. The spare is running (in separate terminals) a master and a slave, and the main computer is running a client and another slave.

Pressing F12 from the client works to render the image, however only the slave on the client machine is used. Killing that slave will then cause the slave on the spare to be used. It does not appear possible to have them work in concert. Is it correct to conclude that netrender only divvies frames to slaves, not tiles?
",Plenus Franckly,https://blender.stackexchange.com/users/621,"You cannot use Network Render to render a single frame out-of-the-box. However, it is possible with some tweaking and post-processing.

First, extend your timeline to however many slaves you are going to use. If different slaves have different hardware configurations, you may want to multiply this by two to render slightly faster.

Then, in the Properties &rarr; Render Settings &rarr; Sampling, select the Seed field and enter the text #frame. Press Enter. (If you see a message indicating that the driver will not be automatically run, either enable autorun for drivers or reload the file as trusted; don't forget to save.) This will tie the interpolator seed to the current frame.

Then, take the Render Samples value and divide it by the number of frames in your timeline.

You can now perform a network render of your file. When your ""video"" is finished, you can blend the files together to obtain the final image.
",wchargin,https://blender.stackexchange.com/users/372,http://blender.stackexchange.com/questions/2002/is-netrender-only-useful-for-multiple-frames,TECHNOLOGY,blender.stackexchange.com,0.7777777777777778,0.7777777777777778,0.0,0.6666666666666666,1.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.6666666666666666,1.0,Is netrender only useful for multiple frames?,"Trying to speed-up render times on a large single-frame Cycles image by using netrender and a spare machine. The spare is running (in separate terminals) a master and a slave, and the main computer is running a client and another slave.

Pressing F12 from the client works to render the image, however only the slave on the client machine is used. Killing that slave will then cause the slave on the spare to be used. It does not appear possible to have them work in concert. Is it correct to conclude that netrender only divvies frames to slaves, not tiles?
","You cannot use Network Render to render a single frame out-of-the-box. However, it is possible with some tweaking and post-processing.

First, extend your timeline to however many slaves you are going to use. If different slaves have different hardware configurations, you may want to multiply this by two to render slightly faster.

Then, in the Properties &rarr; Render Settings &rarr; Sampling, select the Seed field and enter the text #frame. Press Enter. (If you see a message indicating that the driver will not be automatically run, either enable autorun for drivers or reload the file as trusted; don't forget to save.) This will tie the interpolator seed to the current frame.

Then, take the Render Samples value and divide it by the number of frames in your timeline.

You can now perform a network render of your file. When your ""video"" is finished, you can blend the files together to obtain the final image.
"
39,39,59,Difference between busses,"I think I am confusing the difference between some of the of busses, such as IDE, SATA, USB, and PCI.  What is the relationship between all four, how are they connected to each other? From what I read it seems like PCI connects them together as well as to the CPU, but it's not clear.  Any help would be greatly appreciated. I am cross referencing this post with another I made about the Linux commands to browse them.  http://unix.stackexchange.com/questions/27414/ide-and-pci-bus-commands
",rubixibuc,https://electronics.stackexchange.com/users/7163,"The interrelationship of the different busses is roughly as follows:

                                               / SATA
CPU =&gt; Northbridge =&gt; PCI Bus =&gt; Southbridge =&gt;  IDE
                                               \ USB


Where the Northbridge and Southbridge are names given to the two main controller chips inside a PC.

IDE and SATA both perform the same job but through different physical media - they are for attaching hard drives etc.

IDE is ""Integrated Device Electronics"" - also known as ""ATA"" or ""ATAPI"" (ATA Peripheral Interface).

SATA is ""Serial ATA"" - the same ATA protocol but serial instead of parallel.

USB is a serial communications bus which can communicate with any number of devices, not just hard drives and other storage devices.  It speaks a completely different protocol to the ATA family.

PCI (and the derivatives PCIe, etc) are much closer to the CPU and generally provides much more direct access to the CPU.

Edit:

You can see how everything is connected together in Windows through the Device Manager set to View Devices by Connection:


",Majenko,https://electronics.stackexchange.com/users/4245,http://electronics.stackexchange.com/questions/24077/difference-between-busses,SCIENCE,electronics.stackexchange.com,1.0,0.5555555555555556,0.0,0.6666666666666666,1.0,0.6666666666666666,0.4444444444444444,0.4444444444444444,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,0.6666666666666666,0.8888888888888888,The difference between buses,"I think I've confused some bus differences, such as IDE, SATA, USB and PCI. What is the relationship between the four and how are they related to each other? From what I read, PCI connects them together and connects them to the CPU, but it's not clear. Any help will be appreciated. I'm cross referencing this article and another about Linux commands to browse through them. http://unix.stackexchange.com/questions/27414/ide-and-pci-bus-commands","The interrelationship of the different busses is roughly as follows:

                                               / SATA
CPU =&gt; Northbridge =&gt; PCI Bus =&gt; Southbridge =&gt;  IDE
                                               \ USB


Where the Northbridge and Southbridge are names given to the two main controller chips inside a PC.

IDE and SATA both perform the same job but through different physical media - they are for attaching hard drives etc.

IDE is ""Integrated Device Electronics"" - also known as ""ATA"" or ""ATAPI"" (ATA Peripheral Interface).

SATA is ""Serial ATA"" - the same ATA protocol but serial instead of parallel.

USB is a serial communications bus which can communicate with any number of devices, not just hard drives and other storage devices.  It speaks a completely different protocol to the ATA family.

PCI (and the derivatives PCIe, etc) are much closer to the CPU and generally provides much more direct access to the CPU.

Edit:

You can see how everything is connected together in Windows through the Device Manager set to View Devices by Connection:


"
1078,1078,1702,"Can you designate your craft, perform, or profession skill even if you have no ranks in it?","Could you, for example, have one of your craft skills filled in as carpenter, but have no ranks in it?  Being a very bad carpenter, but a carpenter nevertheless.
",Nerevar,https://rpg.stackexchange.com/users/11514,"You can Craft and Perform, but you can't use Profession;

As stated here, Craft and Perform can be used without training. This means that you don't need to have ranks to use any of the Craft Skills (not limited to Alchemy, Armors, Bows, Traps, Weapons, Varies) or Perform Skills (not limited to Act, Comedy, Dance, Keyboard Instruments, Oratory, Percussion Instruments, String Instruments, Wind Instruments, Sing).

Unfortunately, this does not apply for Profession, and you'll have to get at least 1 rank in a Profession to use it.

It's worth noticing that every failure in a Perform check will give you a -2 when trying to Perform in front of the same audience (because they were not impressed by you and now have prejudices). Be aware of that and use Perform wisely when you don't have ranks in it.



Misc Bonuses

If you don't want to get ranks in these skills, there is still something we can do to improve your checks.

Artisan's Tools: You may want to get these to get a +2 on every Craft check;

Gnome Racial Trait: Gnomes get +2 to a Crafting Skill of their choice.

Masterwork Musical Instrument: If used during the performance, it will grant a +2 on the Perform check.

Skill Focus (feat): Choose a Skill; Without any rank in it, this feat gives you +3 on every check for that Skill (you can get up to +6 when you have 10 ranks, but this is not the case).
",Vereos,https://rpg.stackexchange.com/users/9411,http://rpg.stackexchange.com/questions/37160/can-you-designate-your-craft-perform-or-profession-skill-even-if-you-have-no-r,CULTURE,rpg.stackexchange.com,0.8333333333333334,0.8333333333333334,0.0,1.0,0.5,1.0,0.8333333333333334,0.6666666666666666,0.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,1.0,0.8333333333333334,1.0,1.0,0.9,0.0,0.0,1.0,0.8333333333333334,"Even if you don't have a level, can you specify your skills, acting or professional skills?","For example, can you fill in one of your crafts as a carpenter, but there is no grade? Be a bad carpenter, but still a carpenter.","You can Craft and Perform, but you can't use Profession;

As stated here, Craft and Perform can be used without training. This means that you don't need to have ranks to use any of the Craft Skills (not limited to Alchemy, Armors, Bows, Traps, Weapons, Varies) or Perform Skills (not limited to Act, Comedy, Dance, Keyboard Instruments, Oratory, Percussion Instruments, String Instruments, Wind Instruments, Sing).

Unfortunately, this does not apply for Profession, and you'll have to get at least 1 rank in a Profession to use it.

It's worth noticing that every failure in a Perform check will give you a -2 when trying to Perform in front of the same audience (because they were not impressed by you and now have prejudices). Be aware of that and use Perform wisely when you don't have ranks in it.



Misc Bonuses

If you don't want to get ranks in these skills, there is still something we can do to improve your checks.

Artisan's Tools: You may want to get these to get a +2 on every Craft check;

Gnome Racial Trait: Gnomes get +2 to a Crafting Skill of their choice.

Masterwork Musical Instrument: If used during the performance, it will grant a +2 on the Perform check.

Skill Focus (feat): Choose a Skill; Without any rank in it, this feat gives you +3 on every check for that Skill (you can get up to +6 when you have 10 ranks, but this is not the case).
"
5432,5432,8623,Sneak attack advancement feat,"One of my players is trying to play as a rogue/druid (mostly for sneak attacking). Unfortunately, these classes don't have a lot of synergy. Are there any feats or items, ideally for pathfinder, that allow a character to increase sneak attack dice while taking levels in a class like druid? I'm hoping for something similar to Monastic Legacy (a feat which lets you advance unarmed damage dice like a monk while leveling another class), but for the sneak attack mechanic.
",Lawton,https://rpg.stackexchange.com/users/9163,"Complete Adventurer had a prestige class for 3.5 called the daggerspell shaper, which advanced Sneak Attack, Spells, and Wild Shape. 

As for feats, I am not aware of any, but in the same vein as Daring Outlaw etc. from Complete Scoundrel, this feat seems quite reasonable:


  Natural Ambusher
  
  Requirements:
  
  
  Sneak Attack +2d6
  Trackless Step
  
  
  Benefit:
  
  Your druid levels stack with your rogue levels for the purposes of how much bonus damage you add on a Sneak Attack. For instance, a druid 4/rogue 3 with this feat would deal 4d6 extra damage on a Sneak Attack, as a rogue 7 would.
  
  Your rogue levels stack with your druid levels for the purposes of Nature Bond as well as your daily uses and options for Wild Shape. For example, a druid 4/rogue 3 with this feat could have an Animal Companion with the Devotion feature, and could use Wild Shape twice per day, since the druid&rsquo;s effective level would be 7 and these features are available at druid 6. 

",KRyan,https://rpg.stackexchange.com/users/4563,http://rpg.stackexchange.com/questions/46195/sneak-attack-advancement-feat,CULTURE,rpg.stackexchange.com,0.7777777777777778,0.4444444444444444,0.0,1.0,0.6666666666666666,1.0,0.6666666666666666,0.5555555555555556,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.0,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,1.0,1.0,0.9333333333333332,0.6666666666666666,0.0,0.3333333333333333,1.0,Sneak attack promotion expertise,"One of my players tried to play a rogue / Druid (mainly for sneak attacks). Unfortunately, these classes don't have a lot of synergy. What specialty or item, the ideal Pathfinder, allows a character to add sneak dice while taking a class like Druid? I would like to have something similar to a monk's legacy (a feat that allows you to push unarmed damage dice like a monk while leveling another class), but for a sneak attack mechanic.","Complete Adventurer had a prestige class for 3.5 called the daggerspell shaper, which advanced Sneak Attack, Spells, and Wild Shape. 

As for feats, I am not aware of any, but in the same vein as Daring Outlaw etc. from Complete Scoundrel, this feat seems quite reasonable:


  Natural Ambusher
  
  Requirements:
  
  
  Sneak Attack +2d6
  Trackless Step
  
  
  Benefit:
  
  Your druid levels stack with your rogue levels for the purposes of how much bonus damage you add on a Sneak Attack. For instance, a druid 4/rogue 3 with this feat would deal 4d6 extra damage on a Sneak Attack, as a rogue 7 would.
  
  Your rogue levels stack with your druid levels for the purposes of Nature Bond as well as your daily uses and options for Wild Shape. For example, a druid 4/rogue 3 with this feat could have an Animal Companion with the Devotion feature, and could use Wild Shape twice per day, since the druid&rsquo;s effective level would be 7 and these features are available at druid 6. 

"
3707,3707,5912,"How to prevent the ""Too awesome to use"" syndrome","When you give the player a rare but powerful item which can only be used once but is never really required to proceed, most players will not use it at all, because they are waiting for the perfect moment. But even when this moment comes, they will still be reluctant to use it, because there might be an even better moment later. So they keep hoarding it for a moment which will never come. 

In the end, they will carry the item around until it is outclassed by other, more readily available resources, or even until the very end of the game. That means that such one-shot items don't provide any gameplay-value at all. They are simply too awesome to use.

What can you do to encourage the player to make use of their one-shot items and not hoard them?
",Philipp,https://gamedev.stackexchange.com/users/21890,"If you, as a game designer, know when the opportune moment arises (eg. boss battle), I would give a cue to the player. This could be a character saying ""Sure could use that BFG right about now"", or even a tool-tip reminding you that the weapon is awesome. Sometimes, players will just forget that the weapon is there, so a little reminder at the right time can help.
",John McDonald,https://gamedev.stackexchange.com/users/9366,http://gamedev.stackexchange.com/questions/55558/how-to-prevent-the-too-awesome-to-use-syndrome,TECHNOLOGY,gamedev.stackexchange.com,0.8333333333333334,0.5,1.0,1.0,0.0,0.5,0.6666666666666666,0.6666666666666666,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9,0.0,0.0,0.5,1.0,"How to prevent ""too good to use"" syndrome","When you give the player a rare but powerful item which can only be used once but is never really required to proceed, most players will not use it at all, because they are waiting for the perfect moment. But even when this moment comes, they will still be reluctant to use it, because there might be an even better moment later. So they keep hoarding it for a moment which will never come. 

In the end, they will carry the item around until it is outclassed by other, more readily available resources, or even until the very end of the game. That means that such one-shot items don't provide any gameplay-value at all. They are simply too awesome to use.

What can you do to encourage the player to make use of their one-shot items and not hoard them?
","If you, as a game designer, know when the opportune moment arises (eg. boss battle), I would give a cue to the player. This could be a character saying ""Sure could use that BFG right about now"", or even a tool-tip reminding you that the weapon is awesome. Sometimes, players will just forget that the weapon is there, so a little reminder at the right time can help.
"
1470,1470,2314,Saturated Density Plots,"I am making some density and contour plots in Mathematica. These plots have very high peaks which saturate with color and prevent me from seeing differences in the peaks. Is there a way I can tone down the color scale so my peaks are not just white blobs?

Trying other color schemes has not worked out, and playing with the range of color data has not been very useful. Is there some way to have the colors on a log scale???

Here is my code.

ListDensityPlot[photo, PlotLegends -&gt; Automatic, Frame -&gt; {True}, 
FrameLabel -&gt; {""Electron Bunch Energy (MeV)"", ""Photon Energy (keV)"", 
"""", ""Yield (Photons/Sr e-KeV)"" }, LabelStyle -&gt; {15}, 
InterpolationOrder -&gt; 10]




Cheers, Ben
",user1558881,https://mathematica.stackexchange.com/users/9185,"It's difficult to help without photo data, but I'm almost sure that PlotRange can solve your problem.
Try to control Z coordinate in PlotRange as in this example, to find a better range to your plot.

pSaturated=DensityPlot[Exp[-10(x^2+y^2)],{x,-1,1},{y,-1,1},ImageSize-&gt;400];
pOK=DensityPlot[Exp[-10(x^2+y^2)],{x,-1,1},{y,-1,1},PlotRange-&gt;{All,All,{0,1}},ImageSize-&gt;400];
Row[{pSaturated,pOK}]



",Murta,https://mathematica.stackexchange.com/users/2266,http://mathematica.stackexchange.com/questions/30934/saturated-density-plots,TECHNOLOGY,mathematica.stackexchange.com,1.0,0.3333333333333333,0.0,0.0,1.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.5,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8,0.0,1.0,0.0,1.0,Saturation density diagram,"I am making some density and contour plots in Mathematica. These plots have very high peaks which saturate with color and prevent me from seeing differences in the peaks. Is there a way I can tone down the color scale so my peaks are not just white blobs?

Trying other color schemes has not worked out, and playing with the range of color data has not been very useful. Is there some way to have the colors on a log scale???

Here is my code.

ListDensityPlot[photo, PlotLegends -&gt; Automatic, Frame -&gt; {True}, 
FrameLabel -&gt; {""Electron Bunch Energy (MeV)"", ""Photon Energy (keV)"", 
"""", ""Yield (Photons/Sr e-KeV)"" }, LabelStyle -&gt; {15}, 
InterpolationOrder -&gt; 10]




Cheers, Ben
","It's difficult to help without photo data, but I'm almost sure that PlotRange can solve your problem.
Try to control Z coordinate in PlotRange as in this example, to find a better range to your plot.

pSaturated=DensityPlot[Exp[-10(x^2+y^2)],{x,-1,1},{y,-1,1},ImageSize-&gt;400];
pOK=DensityPlot[Exp[-10(x^2+y^2)],{x,-1,1},{y,-1,1},PlotRange-&gt;{All,All,{0,1}},ImageSize-&gt;400];
Row[{pSaturated,pOK}]



"
2305,2305,3674,Downloading specific yeast genes in an automated manner?,"I have 6 genes of Candida albicans yeast namely orf19.723, orf19.5908, orf19.610, orf19.2119, orf19.4998 and orf19.4056. And I have found the corresponding ortholog genes from Broad Institute website of other 16 species of yeast. So I have all gene names. Now how would I specifically download these genes and from where can I do this, preferably in an automated manner?

Also is there any standard naming convention? Because the ORF names given have other names too like BCR1, EFG1 and NDT80.

The list of gene names I have :

The orthologs of C. Albicans with S. cerevisiae
orf19.2119  YHR124W 
orf19.4998  YBR033W YKL034W 
orf19.5908  YBR083W 
orf19.610   YMR016C YKL043W 
orf19.723   NONE
orf19.4056  YMR136W 

The orthologs of C. Albicans with S. paradoxus
orf19.2119  spar33-g1.1 
orf19.4998  spar197-g23.1   spar324-g3.1    
orf19.5908  spar200-g4.1    
orf19.610   spar184-g1.1    spar324-g10.1   
orf19.723   NONE
orf19.4056  spar165-g2.1

The orthologs of C. Albicans with S. mikatae
orf19.2119  NONE
orf19.4998  smik146-g12.1   smik109-g17.1   
orf19.5908  smik83-g2.1 
orf19.610   smik571-g2.1    smik109-g10.1   
orf19.723   NONE
orf19.4056  smik1535-g1.1   

The orthologs of C. Albicans with S. bayanus
orf19.2119  sbayc514-g9.1   
orf19.4998  sbayc611-g22.1  sbayc652-g20.1  
orf19.5908  sbayc678-g131.1 
orf19.610   sbayc638-g23.1  sbayc652-g27.1  
orf19.723   NONE
orf19.4056  sbayc657-g41.1

The orthologs of C. Albicans with S. castellii
orf19.2119  Scas697.24  
orf19.4998  Scas625.4   
orf19.5908  Scas718.27  Scas635.12  
orf19.610   Scas106.1   Scas709.52  Scas625.8   
orf19.723   NONE
orf19.4056  Scas680.22d 

The orthologs of C. Albicans with C. glabrata
orf19.2119  CAGL0L13090g    
orf19.4998  CAGL0L01947g    
orf19.5908  CAGL0M01716g    CAGL0F04081g    
orf19.610   CAGL0M07634g    CAGL0L01771g    
orf19.723   NONE
orf19.4056  CAGL0I00902g    CAGL0L06776g    

The orthologs of C. Albicans with S. kluyveri
orf19.2119  SAKL0E11330g    
orf19.4998  SAKL0A09812g    
orf19.5908  SAKL0B06578g    
orf19.610   SAKL0D13442g    
orf19.723   SAKL0A03476g    
orf19.4056  SAKL0E04862g    

The orthologs of C. Albicans with K. lactis
orf19.2119  KLLA0F24420g    
orf19.4998  KLLA0F25674g    
orf19.5908  KLLA0E12507g    
orf19.610   KLLA0F04840g    
orf19.723   NONE
orf19.4056  KLLA0F17116g    

The orthologs of C. Albicans with A. gossypii
orf19.2119  AGR347W 
orf19.4998  AFR275W 
orf19.5908  AER177W 
orf19.610   ABR055C 
orf19.723   NONE
orf19.4056  ADR249W 

The orthologs of C. Albicans with K. waltii
orf19.2119  Kwal33.14699    
orf19.4998  Kwal26.8099 
orf19.5908  Kwal27.12423    
orf19.610   Kwal26.8176 
orf19.723   NONE
orf19.4056  Kwal47.17849    

The orthologs of C. Albicans with C. tropicalis
orf19.2119  CTRG01097.3 
orf19.4998  CTRG03636.3 
orf19.5908  CTRG02294.3 
orf19.610   NONE
orf19.723   CTRG00608.3 
orf19.4056  CTRG04523.3 

The orthologs of C. Albicans with L. elongosporus
orf19.2119  LELG01178   
orf19.4998  NONE
orf19.5908  LELG02666   
orf19.610   LELG05390   
orf19.723   LELG03123   
orf19.4056  LELG01761   

The orthologs of C. Albicans with C. parapsilosis
orf19.2119  CPAG04608   
orf19.4998  NONE
orf19.5908  CPAG01691   
orf19.610   CPAG00178   
orf19.723   CPAG00564   
orf19.4056  CPAG05034   

The orthologs of C. Albicans with D. hansenii
orf19.2119  DEHA2A07282g    
orf19.4998  NONE
orf19.5908  DEHA2G13794g    
orf19.610   DEHA2E10978g    
orf19.723   DEHA2E05984g    
orf19.4056  DEHA2E07172g    DEHA2F25916g    

The orthologs of C. Albicans with C. guilliermondii
orf19.2119  PGUG02096.1 
orf19.4998  NONE
orf19.5908  PGUG04378.1 
orf19.610   PGUG03651.1 
orf19.723   PGUG05571.1 
orf19.4056  PGUG05533.1 

The orthologs of C. Albicans with C. lusitaniae
orf19.2119  CLUG00404   
orf19.4998  NONE
orf19.5908  CLUG04694   
orf19.610   CLUG02047   
orf19.723   CLUG00627   
orf19.4056  CLUG05535

",dexterdev,https://biology.stackexchange.com/users/5669,"These sequences do not have any standard i.d. The information in Saccharomyces Genome Database is also obsolete (2005) and does not have these identifiers.

These sequences can be found here (in the same site).

Each species has a short name:


ORGANISM        Short Name
S.cerevesiae    Scer
S. bayanus      Sbay
S. paradoxus    Spar
A. gossypii     Agos

.... and so on. 

First letter of genus name in uppercase + first 3 letters of species name in lowercase.

The fasta file (for all ORFs) is:
 www.broadinstitute.org/regev/orthogroups/nt/&lt;Shortname&gt;.fasta

From there you can use grep to retrieve the sequence.

So, if you have saved shortnames and gene names two separate files you can do something like this: 

for shortname in `cat shortname.txt`; do wget -O tmp.fa ""http://www.broadinstitute.org/regev/orthogroups/nt/""$shortname.fasta; grep -A 1 -f ids.txt tmp.fa &gt;&gt; $shortname""_Select.fa""; done

",WYSIWYG,https://biology.stackexchange.com/users/3340,http://biology.stackexchange.com/questions/26148/downloading-specific-yeast-genes-in-an-automated-manner,SCIENCE,biology.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.3333333333333333,0.6666666666666666,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.3333333333333333,0.3333333333333333,1.0,Download specific yeast genes automatically?,"I have 6 genes of Candida albicans yeast namely orf19.723, orf19.5908, orf19.610, orf19.2119, orf19.4998 and orf19.4056. And I have found the corresponding ortholog genes from Broad Institute website of other 16 species of yeast. So I have all gene names. Now how would I specifically download these genes and from where can I do this, preferably in an automated manner?

Also is there any standard naming convention? Because the ORF names given have other names too like BCR1, EFG1 and NDT80.

The list of gene names I have :

The orthologs of C. Albicans with S. cerevisiae
orf19.2119  YHR124W 
orf19.4998  YBR033W YKL034W 
orf19.5908  YBR083W 
orf19.610   YMR016C YKL043W 
orf19.723   NONE
orf19.4056  YMR136W 

The orthologs of C. Albicans with S. paradoxus
orf19.2119  spar33-g1.1 
orf19.4998  spar197-g23.1   spar324-g3.1    
orf19.5908  spar200-g4.1    
orf19.610   spar184-g1.1    spar324-g10.1   
orf19.723   NONE
orf19.4056  spar165-g2.1

The orthologs of C. Albicans with S. mikatae
orf19.2119  NONE
orf19.4998  smik146-g12.1   smik109-g17.1   
orf19.5908  smik83-g2.1 
orf19.610   smik571-g2.1    smik109-g10.1   
orf19.723   NONE
orf19.4056  smik1535-g1.1   

The orthologs of C. Albicans with S. bayanus
orf19.2119  sbayc514-g9.1   
orf19.4998  sbayc611-g22.1  sbayc652-g20.1  
orf19.5908  sbayc678-g131.1 
orf19.610   sbayc638-g23.1  sbayc652-g27.1  
orf19.723   NONE
orf19.4056  sbayc657-g41.1

The orthologs of C. Albicans with S. castellii
orf19.2119  Scas697.24  
orf19.4998  Scas625.4   
orf19.5908  Scas718.27  Scas635.12  
orf19.610   Scas106.1   Scas709.52  Scas625.8   
orf19.723   NONE
orf19.4056  Scas680.22d 

The orthologs of C. Albicans with C. glabrata
orf19.2119  CAGL0L13090g    
orf19.4998  CAGL0L01947g    
orf19.5908  CAGL0M01716g    CAGL0F04081g    
orf19.610   CAGL0M07634g    CAGL0L01771g    
orf19.723   NONE
orf19.4056  CAGL0I00902g    CAGL0L06776g    

The orthologs of C. Albicans with S. kluyveri
orf19.2119  SAKL0E11330g    
orf19.4998  SAKL0A09812g    
orf19.5908  SAKL0B06578g    
orf19.610   SAKL0D13442g    
orf19.723   SAKL0A03476g    
orf19.4056  SAKL0E04862g    

The orthologs of C. Albicans with K. lactis
orf19.2119  KLLA0F24420g    
orf19.4998  KLLA0F25674g    
orf19.5908  KLLA0E12507g    
orf19.610   KLLA0F04840g    
orf19.723   NONE
orf19.4056  KLLA0F17116g    

The orthologs of C. Albicans with A. gossypii
orf19.2119  AGR347W 
orf19.4998  AFR275W 
orf19.5908  AER177W 
orf19.610   ABR055C 
orf19.723   NONE
orf19.4056  ADR249W 

The orthologs of C. Albicans with K. waltii
orf19.2119  Kwal33.14699    
orf19.4998  Kwal26.8099 
orf19.5908  Kwal27.12423    
orf19.610   Kwal26.8176 
orf19.723   NONE
orf19.4056  Kwal47.17849    

The orthologs of C. Albicans with C. tropicalis
orf19.2119  CTRG01097.3 
orf19.4998  CTRG03636.3 
orf19.5908  CTRG02294.3 
orf19.610   NONE
orf19.723   CTRG00608.3 
orf19.4056  CTRG04523.3 

The orthologs of C. Albicans with L. elongosporus
orf19.2119  LELG01178   
orf19.4998  NONE
orf19.5908  LELG02666   
orf19.610   LELG05390   
orf19.723   LELG03123   
orf19.4056  LELG01761   

The orthologs of C. Albicans with C. parapsilosis
orf19.2119  CPAG04608   
orf19.4998  NONE
orf19.5908  CPAG01691   
orf19.610   CPAG00178   
orf19.723   CPAG00564   
orf19.4056  CPAG05034   

The orthologs of C. Albicans with D. hansenii
orf19.2119  DEHA2A07282g    
orf19.4998  NONE
orf19.5908  DEHA2G13794g    
orf19.610   DEHA2E10978g    
orf19.723   DEHA2E05984g    
orf19.4056  DEHA2E07172g    DEHA2F25916g    

The orthologs of C. Albicans with C. guilliermondii
orf19.2119  PGUG02096.1 
orf19.4998  NONE
orf19.5908  PGUG04378.1 
orf19.610   PGUG03651.1 
orf19.723   PGUG05571.1 
orf19.4056  PGUG05533.1 

The orthologs of C. Albicans with C. lusitaniae
orf19.2119  CLUG00404   
orf19.4998  NONE
orf19.5908  CLUG04694   
orf19.610   CLUG02047   
orf19.723   CLUG00627   
orf19.4056  CLUG05535

","These sequences do not have any standard i.d. The information in Saccharomyces Genome Database is also obsolete (2005) and does not have these identifiers.

These sequences can be found here (in the same site).

Each species has a short name:


ORGANISM        Short Name
S.cerevesiae    Scer
S. bayanus      Sbay
S. paradoxus    Spar
A. gossypii     Agos

.... and so on. 

First letter of genus name in uppercase + first 3 letters of species name in lowercase.

The fasta file (for all ORFs) is:
 www.broadinstitute.org/regev/orthogroups/nt/&lt;Shortname&gt;.fasta

From there you can use grep to retrieve the sequence.

So, if you have saved shortnames and gene names two separate files you can do something like this: 

for shortname in `cat shortname.txt`; do wget -O tmp.fa ""http://www.broadinstitute.org/regev/orthogroups/nt/""$shortname.fasta; grep -A 1 -f ids.txt tmp.fa &gt;&gt; $shortname""_Select.fa""; done

"
5717,5717,9057,Asterisk for Small Business - Where to Start?,"I have been in IT for a long time now doing software development and some system/server administration, but all mostly software-related services.  I would like to help set up a small business (~50 employees) with Asterisk, but I am not very familiar with how the whole T1, data/voice channels, etc work.  I have set up a personal Asterisk server (functional), but have not done so with a pipe like a T1 (which sounds more complex than residential cable/DSL).

Are there any resources out there to help me understand what may be needed of me to help set this business up with Asterisk and re-use their existing T1 pipe?

Any help would be greatly appreciated.
",Benny,https://serverfault.com/users/42248,"Solid answer by @Bittrance already.

My main highlights for a new to all this 'VoIP guy for a small office' would be:

Server setup:


Consider buying an appliance with a nice GUI. Several vendors make 'Asterix bundled with hardware' packages, like the ""Asterisk Appliance 50"" or ""Trixbox"".
If not an appliance, then at least consider a nice virtual machine / server software image (OS + Asterix + Addons + GUI) like AsteriskNOW, Trixbox, etc.


Upstream connection:


You can use an IP based telephony service provider, i.e. send SIP VoIP data over the T1 to your telephony service provider. This is where much of the business innovation, low telephony rates etc can be had. In a good design, you want QoS on the upstream (T1) line, to guarantee good voice quality in all conditions.
You can use a traditional telephony service provider, and use ISDN/2, ISDN/30, or multiple analog lines to connect to your upstream service provider. This is very reliable, time-proven, and doesn't have any QoS needs as you are not mixing data and voice on the same physical circuit.


QoS:


""Quality of Service (QoS) is the biggest design issue. QoS, at very high level, refers to the ability to prioritize data flows though shared pipes, i.e. make sure voice traffic gets priority over computer data.
How to best implement QoS in a given network is very dependent on what equipment is being used.
In a few cases, the simplest/cheapest QoS solution is to just use 2 physical circuits -- one for data, and another for voice. For example, some small offices use a new high-speed FiOS package for Internet connectivity/data, and an old T1 or something for voice uplink. The most cost-effective option will depend on what is being offered in your area, and the QoS capabilities of your existing firewall/router.
You should go for QoS on your internal network too. That's not so hard; the common solution is setting up dedicated VLANs for voice and data, and using the QoS implementations in your (managed Cisco) switch. Some really cheap installations use 2 switches, one dump ~30 USD switch for data/PCs, and another dumb switch for SIP phones exclusively. That works too, but is inelegant and can lead to lots of cable runs.


Phones:


Read some reviews, and get good SIP phones for your office. Sound quality differs substantially between models (mostly due to different microphones &amp; speakers).
A SIP phone is basically a micro-computer. It needs an IP address (DHCP), it must be registered with Asterix, from time to time you might want to update the phone firmware, etc. Plan how you will administrate this.

",Jesper Mortensen,https://serverfault.com/users/2874,http://serverfault.com/questions/275107,TECHNOLOGY,serverfault.com,1.0,0.5555555555555556,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,1.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.3333333333333333,0.6666666666666666,1.0,Small business asterisk - where to start?,"I have worked in IT industry for a long time, now I am engaged in software development and some system / server management, but most of them are software related services. I want to help build a small business with an asterisk (about 50 employees), but I'm not familiar with the whole T1, data / voice channels, etc. I've built a personal asterisk server (functional), but I haven't used a T1 like conduit (sounds more complex than a residential cable / DSL).","Solid answer by @Bittrance already.

My main highlights for a new to all this 'VoIP guy for a small office' would be:

Server setup:


Consider buying an appliance with a nice GUI. Several vendors make 'Asterix bundled with hardware' packages, like the ""Asterisk Appliance 50"" or ""Trixbox"".
If not an appliance, then at least consider a nice virtual machine / server software image (OS + Asterix + Addons + GUI) like AsteriskNOW, Trixbox, etc.


Upstream connection:


You can use an IP based telephony service provider, i.e. send SIP VoIP data over the T1 to your telephony service provider. This is where much of the business innovation, low telephony rates etc can be had. In a good design, you want QoS on the upstream (T1) line, to guarantee good voice quality in all conditions.
You can use a traditional telephony service provider, and use ISDN/2, ISDN/30, or multiple analog lines to connect to your upstream service provider. This is very reliable, time-proven, and doesn't have any QoS needs as you are not mixing data and voice on the same physical circuit.


QoS:


""Quality of Service (QoS) is the biggest design issue. QoS, at very high level, refers to the ability to prioritize data flows though shared pipes, i.e. make sure voice traffic gets priority over computer data.
How to best implement QoS in a given network is very dependent on what equipment is being used.
In a few cases, the simplest/cheapest QoS solution is to just use 2 physical circuits -- one for data, and another for voice. For example, some small offices use a new high-speed FiOS package for Internet connectivity/data, and an old T1 or something for voice uplink. The most cost-effective option will depend on what is being offered in your area, and the QoS capabilities of your existing firewall/router.
You should go for QoS on your internal network too. That's not so hard; the common solution is setting up dedicated VLANs for voice and data, and using the QoS implementations in your (managed Cisco) switch. Some really cheap installations use 2 switches, one dump ~30 USD switch for data/PCs, and another dumb switch for SIP phones exclusively. That works too, but is inelegant and can lead to lots of cable runs.


Phones:


Read some reviews, and get good SIP phones for your office. Sound quality differs substantially between models (mostly due to different microphones &amp; speakers).
A SIP phone is basically a micro-computer. It needs an IP address (DHCP), it must be registered with Asterix, from time to time you might want to update the phone firmware, etc. Plan how you will administrate this.

"
1137,1137,1781,How to find inter-country buses in Europe?,"I was traveling from Zurich to Frankfurt, and when I asked a tourist information, the guy advised that the best way is train. I took the train, and when arrived in Frankfurt, I found that there is a German company having bus from Zurich to Frankfurt with 1/3 of the train price.

The problem is that bus companies are small and not-connected. On the other hand, such small companies have website mainly in their local languages (not English). As a result, it is difficult for a foreigner to find the best option for bus from a country to another; particularly, as they operate from small stations rather than a big united terminal (as one can go and ask for options).

Are there resources (e.g., websites) for searching all bus routes around Europe?
",Googlebot,https://travel.stackexchange.com/users/2118,"In many countries, there are only one or two companies offering long-distance busses and Eurolines would be the only one with a regular network of international busses. So the first things to check is the national transport company and Eurolines.

But there are more and more alternatives and in my experience it seems especially true for Germany. I don't know how comprehensive their coverage is but Rome2rio does include several of them and has two different solutions for this particular journey.
",Relaxed,https://travel.stackexchange.com/users/6669,http://travel.stackexchange.com/questions/33896/how-to-find-inter-country-buses-in-europe,CULTURE,travel.stackexchange.com,0.8888888888888888,0.8888888888888888,0.0,1.0,1.0,0.6666666666666666,0.5555555555555556,0.7777777777777778,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.3333333333333333,0.3333333333333333,0.3333333333333333,1.0,How to find transnational buses in Europe?,"I was traveling from Zurich to Frankfurt, and when I asked a tourist information, the guy advised that the best way is train. I took the train, and when arrived in Frankfurt, I found that there is a German company having bus from Zurich to Frankfurt with 1/3 of the train price.

The problem is that bus companies are small and not-connected. On the other hand, such small companies have website mainly in their local languages (not English). As a result, it is difficult for a foreigner to find the best option for bus from a country to another; particularly, as they operate from small stations rather than a big united terminal (as one can go and ask for options).

Are there resources (e.g., websites) for searching all bus routes around Europe?
","In many countries, there are only one or two companies offering long-distance busses and Eurolines would be the only one with a regular network of international busses. So the first things to check is the national transport company and Eurolines.

But there are more and more alternatives and in my experience it seems especially true for Germany. I don't know how comprehensive their coverage is but Rome2rio does include several of them and has two different solutions for this particular journey.
"
4116,4116,6570,How to enable or disable services?,"I read about how to enable and disable services in Ubuntu and it seems that there are different possibilities to manage them.

The first method I found is update-rc.d to add new services to startup, which aims on the /etc/init.d folder and its contents.

The other one I found is to edit .conf files in the /etc/init folder.

What's the recommended way to enable / disable / add services and why?

Could you please give a short bulletproof step by step example on how to add a service in Ubuntu and enable and disable it?
",NES,https://askubuntu.com/users/7155,"Try using sysv-rc-conf

sudo apt-get install sysv-rc-conf


and to start managing the services, execute

sudo sysv-rc-conf


Which will bring up interactive window like this



You can further navigate through pages using Ctrl+n for next page and Ctrl+p for previous page .You can enable and disable services by selecting SPACE on desired runlevels.

Another alternate would be  Jobs-Admin by installing through 

sudo apt-get install jobs-admin


Which also provides GUI like this 



For showing more jobs , you have to tick the Show Protected Jobs from its menu.

And third option would be chkconfig,

sudo apt-get install chkconfig


It can be used via CLI chkconfig, showing list of On/Off jobs.
Also we can view system services using chkconfig –list

Services can be turned on using

chkconfig &lt;service&gt; on


Services can be turned off using

chkconfig &lt;service&gt; off


And we can even add our own service, using a proper init script with proper headings.

chkconfig --add &lt;service&gt;


And another option can be referred here update-rc.d , explained briefly here. 

Note that for Ubuntu Server 12.04, update-rc.d is used instead of chkconfig.
",atenz,https://askubuntu.com/users/63025,http://askubuntu.com/questions/19320/how-to-enable-or-disable-services,TECHNOLOGY,askubuntu.com,0.8888888888888888,0.4444444444444444,0.0,0.3333333333333333,1.0,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9,1.0,0.0,0.3333333333333333,0.8888888888888888,How do I enable or disable services?,"I read about how to enable and disable services in Ubuntu and it seems that there are different possibilities to manage them.

The first method I found is update-rc.d to add new services to startup, which aims on the /etc/init.d folder and its contents.

The other one I found is to edit .conf files in the /etc/init folder.

What's the recommended way to enable / disable / add services and why?

Could you please give a short bulletproof step by step example on how to add a service in Ubuntu and enable and disable it?
","Try using sysv-rc-conf

sudo apt-get install sysv-rc-conf


and to start managing the services, execute

sudo sysv-rc-conf


Which will bring up interactive window like this



You can further navigate through pages using Ctrl+n for next page and Ctrl+p for previous page .You can enable and disable services by selecting SPACE on desired runlevels.

Another alternate would be  Jobs-Admin by installing through 

sudo apt-get install jobs-admin


Which also provides GUI like this 



For showing more jobs , you have to tick the Show Protected Jobs from its menu.

And third option would be chkconfig,

sudo apt-get install chkconfig


It can be used via CLI chkconfig, showing list of On/Off jobs.
Also we can view system services using chkconfig –list

Services can be turned on using

chkconfig &lt;service&gt; on


Services can be turned off using

chkconfig &lt;service&gt; off


And we can even add our own service, using a proper init script with proper headings.

chkconfig --add &lt;service&gt;


And another option can be referred here update-rc.d , explained briefly here. 

Note that for Ubuntu Server 12.04, update-rc.d is used instead of chkconfig.
"
3874,3874,6168,Setting text of UITextField from caller view,"I have a barcode scanner on one view, and after the user has scanned the barcode, the app takes them to another view (BoilerDetails) where the barcode text field has been pre-filled.

I understand that the viewcontroller is null when it hasn't come into view and I can'tchange the UITextField text directly. This so far has given me an error.. How can I fix this?

BarcodeScannerViewController.m

BoilerDetailsViewController *viewCtrl = [[BoilerDetailsViewController alloc] initWithNibName:nil bundle:nil];
[viewCtrl setBarcode:strBarcode];
[self.navigationController pushViewController:viewCtrl animated:YES];


BoilerDetailsViewController.h

@interface BoilerDetailsViewController : SubViewControllerBase
@property (retain, nonatomic) NSString *barcode;
@property (retain, nonatomic) IBOutlet UITextField *barcodeField;
- (void)setBarcode:(NSString*)strBarcode;
@end


BoilerDetailsViewController.m

-(void)setBarcode:(NSString *)strBarcode
{
    self.barcode = strBarcode;
}

- (void)viewDidLoad
{
    [super viewDidLoad];
    [_barcodeField setText:self.barcode];
    // Do any additional setup after loading the view from its nib.
}

",Freeman Latif,https://stackoverflow.com/users/823152,"you just have to synthesize the barcode and in ViewDidload just write this code [_barcodeField setText:barcode]; and good to Go.
",Ahsan,https://stackoverflow.com/users/1570507,http://stackoverflow.com/questions/14960306/setting-text-of-uitextfield-from-caller-view,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.4444444444444444,0.0,0.6666666666666666,1.0,0.6666666666666666,0.4444444444444444,0.4444444444444444,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.7777777777777778,0.6666666666666666,0.6666666666666666,0.7777777777777778,1.0,0.8666666666666666,1.0,0.0,0.0,0.8888888888888888,Set the text of uitextfield from the caller view,"I have a barcode scanner on one view, and after the user has scanned the barcode, the app takes them to another view (BoilerDetails) where the barcode text field has been pre-filled.

I understand that the viewcontroller is null when it hasn't come into view and I can'tchange the UITextField text directly. This so far has given me an error.. How can I fix this?

BarcodeScannerViewController.m

BoilerDetailsViewController *viewCtrl = [[BoilerDetailsViewController alloc] initWithNibName:nil bundle:nil];
[viewCtrl setBarcode:strBarcode];
[self.navigationController pushViewController:viewCtrl animated:YES];


BoilerDetailsViewController.h

@interface BoilerDetailsViewController : SubViewControllerBase
@property (retain, nonatomic) NSString *barcode;
@property (retain, nonatomic) IBOutlet UITextField *barcodeField;
- (void)setBarcode:(NSString*)strBarcode;
@end


BoilerDetailsViewController.m

-(void)setBarcode:(NSString *)strBarcode
{
    self.barcode = strBarcode;
}

- (void)viewDidLoad
{
    [super viewDidLoad];
    [_barcodeField setText:self.barcode];
    // Do any additional setup after loading the view from its nib.
}

","you just have to synthesize the barcode and in ViewDidload just write this code [_barcodeField setText:barcode]; and good to Go.
"
4391,4391,6980,Why is the last line of text separated in MS Visio shapes,"In the image below, you can see two rectangles with some text inside. If you take a closer look you will notice a difference in spacing between lines. The spacing between the first and the second lines is smaller than the spacing between the second and the third.

The last line is always separated. If you have 10 lines of text, the spacing between all the lines will be OK except the spacing between the next to last and the last line of text.
The font is the same (in every aspect) accross the lines (except the title), and there are no custom paragraph properties set.

Why does this happen and how to solve this?


",Kornelije Petak,https://superuser.com/users/12849,"The last line is separated because their is a blank character at the end of the bottom line that is the default font size.  Highlight any blank spaces at the end of the bottom line and then change the font size to match the others and it will go away.
",Brian Williford,https://superuser.com/users/184277,http://superuser.com/questions/432770,TECHNOLOGY,superuser.com,1.0,0.5555555555555556,0.0,0.0,1.0,0.6666666666666666,0.6666666666666666,0.4444444444444444,0.6666666666666666,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,1.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.6666666666666666,0.0,1.0,0.8888888888888888,Why is the last line of text in MS Visio shapes separate,"In the image below, you can see two rectangles with some text inside. If you take a closer look you will notice a difference in spacing between lines. The spacing between the first and the second lines is smaller than the spacing between the second and the third.

The last line is always separated. If you have 10 lines of text, the spacing between all the lines will be OK except the spacing between the next to last and the last line of text.
The font is the same (in every aspect) accross the lines (except the title), and there are no custom paragraph properties set.

Why does this happen and how to solve this?


","The last lines are separate because they are white space characters on the last line of the default font size. Highlight any spaces on the last line, then change the font size to match the other spaces, and it disappears."
4077,4077,6509,Apartment in Munich,"I'm a married man looking for an apartment to live with my wife from February 2014 until April 2014.  How can I find an apartment for this time period?
",user10034,https://travel.stackexchange.com/users/10034,"I would also recommend HouseTrip.com. We used it to find apartments in Budapest, Prague and Vienna and had a great experience overall! I was impressed by how flexible the search feature was (i.e., we were able to search for centrally located apartments that can sleep 6 people and that include WiFi and laundry).
",Dfriedla,https://travel.stackexchange.com/users/10041,http://travel.stackexchange.com/questions/23451/apartment-in-munich,CULTURE,travel.stackexchange.com,1.0,0.4444444444444444,0.0,0.5,1.0,0.0,0.8888888888888888,0.6666666666666666,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.3333333333333333,0.3333333333333333,1.0,0.8888888888888888,Munich apartment,"I am a married man. From February 2014 to April 2014, I want to find an apartment to live with my wife. How can I find an apartment in this period of time?","I would also recommend HouseTrip.com. We used it to find apartments in Budapest, Prague and Vienna and had a great experience overall! I was impressed by how flexible the search feature was (i.e., we were able to search for centrally located apartments that can sleep 6 people and that include WiFi and laundry).
"
919,919,1456,Standards/recommendations for Drush make files included in contrib modules,"What are the standards/recommendations for Drush make files that are included in contrib modules? Specifically, should these make files be included by default (module_name.make) or not (module_name.make.example)?

If they should be included, what is the recommended/supported method of overriding/ignoring them? Is there any documentation to point module maintainers to when discussing this in their issue queues?

EDIT: Found this post by jhedstrom from June 2012 recommending naming make files with '.example' suffix. Is this still the recommendation, or have things changed since then?
https://drupal.org/comment/6160018#comment-6160018
",BWPanda,https://drupal.stackexchange.com/users/16537,"Adding an example .make file is the recommended practice, that way when drush make builds the site, the modules all end up in the same directory.  For example OpenAtrium puts its contrib modules in /profiles/openatrium/modules/contrib, not /sites/all/modules. This prevents module conflicts and makes site maintenance easier.
",nielsonm,https://drupal.stackexchange.com/users/9263,http://drupal.stackexchange.com/questions/103538/standards-recommendations-for-drush-make-files-included-in-contrib-modules,TECHNOLOGY,drupal.stackexchange.com,0.6666666666666666,0.3333333333333333,0.0,0.0,1.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,1.0,0.0,1.0,Standard / recommendations for the flush make file included in the contrib module,"What are the standards/recommendations for Drush make files that are included in contrib modules? Specifically, should these make files be included by default (module_name.make) or not (module_name.make.example)?

If they should be included, what is the recommended/supported method of overriding/ignoring them? Is there any documentation to point module maintainers to when discussing this in their issue queues?

EDIT: Found this post by jhedstrom from June 2012 recommending naming make files with '.example' suffix. Is this still the recommendation, or have things changed since then?
https://drupal.org/comment/6160018#comment-6160018
","Adding an example .make file is the recommended practice, that way when drush make builds the site, the modules all end up in the same directory.  For example OpenAtrium puts its contrib modules in /profiles/openatrium/modules/contrib, not /sites/all/modules. This prevents module conflicts and makes site maintenance easier.
"
2419,2419,3858,JavaScript Equivalent Of PHP __invoke,"I'm developing a small framework (in JS) and for esthetic reasons and simplicity I was wondering if there could be a way to implement something like PHP ""__invoke"".

For example:

var myClass = function(config) {
    this.config = config;
    this.method = function(){};
    this.execute = function() {
        return this.method.apply(this, arguments);
    }
}
var execCustom = new myClass({ wait: 100 });
execCustom.method = function() {
    console.log(""called method with ""+arguments.length+"" argument(s):"");
    for(var a in arguments) console.log(arguments[a]);
    return true;
};
execCustom.execute(""someval"",""other"");  


Desired way to execute:

execCustom(""someval"",""other"");


Any ideas? Thanks.
",lepe,https://stackoverflow.com/users/196507,"if you are ready to use JS pattern, you can do this in following way:

var myClass = function(opts) {
          return function(){
            this.config = opts.config;
            this.method = opts.method;
            return this.method.apply(this, arguments);
          };
        };


var execCustom = new myClass({
        config:{ wait: 100 }, 
        method:function() {
            console.log(""called method with ""+arguments.length+"" argument(s):"");
            for(var a in arguments) console.log(arguments[a]);
            return true;
        }});

execCustom(""someval"",""other"");


jsbin

this is the best way I can think of

UPDATED VERSION (by op)

var myClass = function(opts) {
      var x = function(){
          return x.method.apply(x, arguments);
      };
      x.config = opts.config;
      x.method = opts.method;
      return x; 
    };


var execCustom = new myClass({
    config:{ wait: 100 }, 
    method:function() {
        console.log(""called method with ""+arguments.length+"" argument(s):"");
        for(var a in arguments) console.log(arguments[a]);
        return true;
    }});

execCustom(""someval"",""other"");


jsbin
",caoglish,https://stackoverflow.com/users/2272581,http://stackoverflow.com/questions/19018912/javascript-equivalent-of-php-invoke,STACKOVERFLOW,stackoverflow.com,1.0,0.4444444444444444,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,0.8,1.0,0.3333333333333333,0.0,1.0,JavaScript equivalent to PHP \ UU invoke,"I'm developing a small framework (in JS) and for esthetic reasons and simplicity I was wondering if there could be a way to implement something like PHP ""__invoke"".

For example:

var myClass = function(config) {
    this.config = config;
    this.method = function(){};
    this.execute = function() {
        return this.method.apply(this, arguments);
    }
}
var execCustom = new myClass({ wait: 100 });
execCustom.method = function() {
    console.log(""called method with ""+arguments.length+"" argument(s):"");
    for(var a in arguments) console.log(arguments[a]);
    return true;
};
execCustom.execute(""someval"",""other"");  


Desired way to execute:

execCustom(""someval"",""other"");


Any ideas? Thanks.
","if you are ready to use JS pattern, you can do this in following way:

var myClass = function(opts) {
          return function(){
            this.config = opts.config;
            this.method = opts.method;
            return this.method.apply(this, arguments);
          };
        };


var execCustom = new myClass({
        config:{ wait: 100 }, 
        method:function() {
            console.log(""called method with ""+arguments.length+"" argument(s):"");
            for(var a in arguments) console.log(arguments[a]);
            return true;
        }});

execCustom(""someval"",""other"");


jsbin

this is the best way I can think of

UPDATED VERSION (by op)

var myClass = function(opts) {
      var x = function(){
          return x.method.apply(x, arguments);
      };
      x.config = opts.config;
      x.method = opts.method;
      return x; 
    };


var execCustom = new myClass({
    config:{ wait: 100 }, 
    method:function() {
        console.log(""called method with ""+arguments.length+"" argument(s):"");
        for(var a in arguments) console.log(arguments[a]);
        return true;
    }});

execCustom(""someval"",""other"");


jsbin
"
3593,3593,5738,Parsing a Text to only see specific data,"I have the following text lines:

.add 7971 [Player: Sunfire (Account: 11309) X: 5839.623047 Y: 600.437439 Z: 650.839722 Map: 571 Selected player: Llubia (GUID: 19369)]  
.add 43956 [Player: Sunfire (Account: 11309) X: 5277.887695 Y: 2862.181641 Z: 446.735931 Map: 571 Selected none:  (GUID: 0)]  
.add 43956 [Player: Sunfire (Account: 11309) X: 5281.407715 Y: 2864.844482 Z: 446.735931 Map: 571 Selected player: Staticbaby (GUID: 19826)]  
.add 43956 [Player: Sunfire (Account: 11309) X: 5231.464844 Y: 1437.029175 Z: 648.498535 Map: 571 Selected player: Sunfire (GUID: 15295)]  
.add 44077 [Player: Sunfire (Account: 11309) X: 5231.464844 Y: 1437.029175 Z: 648.498535 Map: 571 Selected player: Sunfire (GUID: 15295)]  
.add 49285 [Player: Sunfire (Account: 11309) X: 16225.323242 Y: 16252.759766 Z: 12.790466 Map: 1 Selected none:  (GUID: 0)]  
.add 44115 175 [Player: Elmasguapo (Account: 11309) X: 1659.845093 Y: -4198.589844 Z: 56.382870 Map: 1 Selected none:  (GUID: 0)]  
.add 34078 [Player: Sunfire (Account: 11309) X: 16227.969727 Y: 16280.081055 Z: 13.175169 Map: 1 Selected none:  (GUID: 0)]  
.add  |cffffffff|Hitem:41427:0:0:0:0:0:0:0:80|h[Fuego de Artificio de Dalaran]|h|r 50 [Player: Sunfire (Account: 11309) X: 16221.392578 Y: 16260.944336 Z: 13.255954 Map: 1 Selected none:  (GUID: 0)]  
.add  |cffffffff|Hitem:45932:0:0:0:0:0:0:0:80|h[Gelatina Negra]|h|r [Player: Sunfire (Account: 11309) X: 5874.347168 Y: 679.056763 Z: 167.483719 Map: 571 Selected player: Assasins (GUID: 19438)]  
.add  |cffffffff|Hitem:45932:0:0:0:0:0:0:0:80|h[Gelatina Negra]|h|r [Player: Sunfire (Account: 11309) X: 5873.767090 Y: 679.386841 Z: 167.435257 Map: 571 Selected player: Assasins (GUID: 19438)]  
.add  |cffffffff|Hitem:45932:0:0:0:0:0:0:0:80|h[Gelatina Negra]|h|r [Player: Sunfire (Account: 11309) X: 16226.880859 Y: 16247.247070 Z: 12.286857 Map: 1 Selected player: Irmtarget (GUID: 18521)]  
.add  |cffffffff|Hitem:45932:0:0:0:0:0:0:0:80|h[Gelatina Negra]|h|r [Player: Sunfire (Account: 11309) X: 16229.297852 Y: 16251.202148 Z: 13.081388 Map: 1 Selected player: Irmtarget (GUID: 18521)]  
.add 41600 2 [Player: Sunfire (Account: 11309) X: 16223.138672 Y: 16250.496094 Z: 12.431313 Map: 1 Selected player: Eifreen (GUID: 20341)]  
.add 41600 1 [Player: Sunfire (Account: 11309) X: 16223.138672 Y: 16250.496094 Z: 12.431313 Map: 1 Selected player: Eifreen (GUID: 20341)]  
.add 40516 [Player: Sunfire (Account: 11309) X: 16223.138672 Y: 16250.496094 Z: 12.431313 Map: 1 Selected player: Eifreen (GUID: 20341)]  
.add 44661 [Player: Sunfire (Account: 11309) X: 16223.138672 Y: 16250.496094 Z: 12.431313 Map: 1 Selected player: Eifreen (GUID: 20341)]  
.add 40518 [Player: Sunfire (Account: 11309) X: 16223.138672 Y: 16250.496094 Z: 12.431313 Map: 1 Selected player: Eifreen (GUID: 20341)]  
.add 44005 [Player: Sunfire (Account: 11309) X: 16223.138672 Y: 16250.496094 Z: 12.431313 Map: 1 Selected player: Eifreen (GUID: 20341)]  
.add 45867 [Player: Sunfire (Account: 11309) X: 16223.138672 Y: 16250.496094 Z: 12.431313 Map: 1 Selected player: Eifreen (GUID: 20341)]  
.add 45316 [Player: Sunfire (Account: 11309) X: 16223.138672 Y: 16250.496094 Z: 12.431313 Map: 1 Selected player: Eifreen (GUID: 20341)]  


And I want to parse it so it outputs something like this:

Line 1 For example - 7971 Llubia
Line 3 For example - 43956 Staticbaby
Line 9 For Example - 45932 Assassins

And so on.. This is done in the terminal with commands like cut, grep, cat, etc..

UPDATE: Here is the whole file: http://paste2.org/p/1744102 to parse in that way.

UPDATE2: Please forgive me if I do not accept an answer just yet. Am waiting for the bounty option to appear since for me, stuff like this deserve a bounty. So I will add a bounty and give it to the correct answer or answers.
",Luis Alvarado,https://askubuntu.com/users/7035,"This can be what you want?

grep -v 'Selected none' input-file | awk '$2+0 &gt; 0 { print $2, $(NF-2) }'

",enzotib,https://askubuntu.com/users/2647,http://askubuntu.com/questions/73311/parsing-a-text-to-only-see-specific-data,TECHNOLOGY,askubuntu.com,0.7777777777777778,0.3333333333333333,0.0,1.0,1.0,1.0,0.4444444444444444,0.4444444444444444,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,0.8333333333333334,0.5,0.8333333333333334,1.0,0.9,1.0,0.0,0.0,0.6666666666666666,Analyze text to view only specific data,"I have the following text lines:

.add 7971 [Player: Sunfire (Account: 11309) X: 5839.623047 Y: 600.437439 Z: 650.839722 Map: 571 Selected player: Llubia (GUID: 19369)]  
.add 43956 [Player: Sunfire (Account: 11309) X: 5277.887695 Y: 2862.181641 Z: 446.735931 Map: 571 Selected none:  (GUID: 0)]  
.add 43956 [Player: Sunfire (Account: 11309) X: 5281.407715 Y: 2864.844482 Z: 446.735931 Map: 571 Selected player: Staticbaby (GUID: 19826)]  
.add 43956 [Player: Sunfire (Account: 11309) X: 5231.464844 Y: 1437.029175 Z: 648.498535 Map: 571 Selected player: Sunfire (GUID: 15295)]  
.add 44077 [Player: Sunfire (Account: 11309) X: 5231.464844 Y: 1437.029175 Z: 648.498535 Map: 571 Selected player: Sunfire (GUID: 15295)]  
.add 49285 [Player: Sunfire (Account: 11309) X: 16225.323242 Y: 16252.759766 Z: 12.790466 Map: 1 Selected none:  (GUID: 0)]  
.add 44115 175 [Player: Elmasguapo (Account: 11309) X: 1659.845093 Y: -4198.589844 Z: 56.382870 Map: 1 Selected none:  (GUID: 0)]  
.add 34078 [Player: Sunfire (Account: 11309) X: 16227.969727 Y: 16280.081055 Z: 13.175169 Map: 1 Selected none:  (GUID: 0)]  
.add  |cffffffff|Hitem:41427:0:0:0:0:0:0:0:80|h[Fuego de Artificio de Dalaran]|h|r 50 [Player: Sunfire (Account: 11309) X: 16221.392578 Y: 16260.944336 Z: 13.255954 Map: 1 Selected none:  (GUID: 0)]  
.add  |cffffffff|Hitem:45932:0:0:0:0:0:0:0:80|h[Gelatina Negra]|h|r [Player: Sunfire (Account: 11309) X: 5874.347168 Y: 679.056763 Z: 167.483719 Map: 571 Selected player: Assasins (GUID: 19438)]  
.add  |cffffffff|Hitem:45932:0:0:0:0:0:0:0:80|h[Gelatina Negra]|h|r [Player: Sunfire (Account: 11309) X: 5873.767090 Y: 679.386841 Z: 167.435257 Map: 571 Selected player: Assasins (GUID: 19438)]  
.add  |cffffffff|Hitem:45932:0:0:0:0:0:0:0:80|h[Gelatina Negra]|h|r [Player: Sunfire (Account: 11309) X: 16226.880859 Y: 16247.247070 Z: 12.286857 Map: 1 Selected player: Irmtarget (GUID: 18521)]  
.add  |cffffffff|Hitem:45932:0:0:0:0:0:0:0:80|h[Gelatina Negra]|h|r [Player: Sunfire (Account: 11309) X: 16229.297852 Y: 16251.202148 Z: 13.081388 Map: 1 Selected player: Irmtarget (GUID: 18521)]  
.add 41600 2 [Player: Sunfire (Account: 11309) X: 16223.138672 Y: 16250.496094 Z: 12.431313 Map: 1 Selected player: Eifreen (GUID: 20341)]  
.add 41600 1 [Player: Sunfire (Account: 11309) X: 16223.138672 Y: 16250.496094 Z: 12.431313 Map: 1 Selected player: Eifreen (GUID: 20341)]  
.add 40516 [Player: Sunfire (Account: 11309) X: 16223.138672 Y: 16250.496094 Z: 12.431313 Map: 1 Selected player: Eifreen (GUID: 20341)]  
.add 44661 [Player: Sunfire (Account: 11309) X: 16223.138672 Y: 16250.496094 Z: 12.431313 Map: 1 Selected player: Eifreen (GUID: 20341)]  
.add 40518 [Player: Sunfire (Account: 11309) X: 16223.138672 Y: 16250.496094 Z: 12.431313 Map: 1 Selected player: Eifreen (GUID: 20341)]  
.add 44005 [Player: Sunfire (Account: 11309) X: 16223.138672 Y: 16250.496094 Z: 12.431313 Map: 1 Selected player: Eifreen (GUID: 20341)]  
.add 45867 [Player: Sunfire (Account: 11309) X: 16223.138672 Y: 16250.496094 Z: 12.431313 Map: 1 Selected player: Eifreen (GUID: 20341)]  
.add 45316 [Player: Sunfire (Account: 11309) X: 16223.138672 Y: 16250.496094 Z: 12.431313 Map: 1 Selected player: Eifreen (GUID: 20341)]  


And I want to parse it so it outputs something like this:

Line 1 For example - 7971 Llubia
Line 3 For example - 43956 Staticbaby
Line 9 For Example - 45932 Assassins

And so on.. This is done in the terminal with commands like cut, grep, cat, etc..

UPDATE: Here is the whole file: http://paste2.org/p/1744102 to parse in that way.

UPDATE2: Please forgive me if I do not accept an answer just yet. Am waiting for the bounty option to appear since for me, stuff like this deserve a bounty. So I will add a bounty and give it to the correct answer or answers.
","This can be what you want?

grep -v 'Selected none' input-file | awk '$2+0 &gt; 0 { print $2, $(NF-2) }'

"
5543,5543,8804,Culinary uses for juniper extract?,"I bought some juniper extract for making bath stuff, and it doesn't seem to be very effective for this purpose. I have used juniper berries before, so I thought I might be able to use the extract for cooking or baking. I have not been able to find any recipes online. 

Is juniper extract ok to eat? What types of applications would it be good for, I assume whole berries is much better choice for marinades. Would it have the same uses as orange or peppermint extract?
",Manako,https://cooking.stackexchange.com/users/1675,"I agree with nixy. Make sure it's food grade. If it's not the extract may have other stabilizers that you don't want to consume. Glycerin is an example where glycerin that you use in soap is different from the food grade glycerin one would use to make non-alcoholic vanilla extract. 
",Spice Sherpa,https://cooking.stackexchange.com/users/5027,http://cooking.stackexchange.com/questions/12950/culinary-uses-for-juniper-extract,LIFE_ARTS,cooking.stackexchange.com,1.0,0.7777777777777778,0.0,0.6666666666666666,1.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.6666666666666666,0.0,0.8888888888888888,1.0,0.4444444444444444,1.0,1.0,0.8,0.3333333333333333,0.0,1.0,0.7777777777777778,What is the cooking use of juniper extract?,"I bought some juniper extract for making bath stuff, and it doesn't seem to be very effective for this purpose. I have used juniper berries before, so I thought I might be able to use the extract for cooking or baking. I have not been able to find any recipes online. 

Is juniper extract ok to eat? What types of applications would it be good for, I assume whole berries is much better choice for marinades. Would it have the same uses as orange or peppermint extract?
","I agree with Nicky. Make sure it's food grade. If not, the extract may contain other stabilizers that you don't want to eat. Glycerin is an example. The glycerin you use in soap is different from food grade glycerin, a kind of glycerin used to make non-alcoholic vanilla essence."
3519,3519,5610,What technique/sensor can I use to recognized tagged objects thrown onto a surface?,"I am trying to implement a concept for somebody else. 

Basically, I want to create a smart surface. I want to create a surface I can throw one or more tagged objects on that should all be recognized. 

I am unsure how to this and what sensors I should use. I have been thinking about using one of the NFC ICs from NXP. However, designing a circuit board and buying this IC is too expensive for our idea. I'm also unsure of whether the surface area will cause problems, because it'll be quite large (think of a small coffee table). 

I've also been thinking about other ways to recognize objects, but I have not come up with anything yet. I am probably not using the correct term. 

Does anyone know of a type or sensor or technique to implement this? 

Note: I am a computer engineer, not an electrical engineer. I know the basics, but really not much more than that, so I prefer a solution that is available as a simple IC or a complete circuit board with the really complicated things done for me by the experts :) 
",Pascal Muller,https://electronics.stackexchange.com/users/16149,"A better solution might be to use printed tags and image recognition. There are open source solutions for this - for instance, trackmate. All you will need is a printer, a camera, and a transparent (or possibly frosted) surface.
",Nick Johnson,https://electronics.stackexchange.com/users/3707,http://electronics.stackexchange.com/questions/49015/what-technique-sensor-can-i-use-to-recognized-tagged-objects-thrown-onto-a-surfa,SCIENCE,electronics.stackexchange.com,1.0,0.8888888888888888,0.0,1.0,0.6666666666666666,1.0,0.7777777777777778,0.4444444444444444,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.3333333333333333,1.0,0.3333333333333333,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.3333333333333333,0.0,0.8888888888888888,What technology / sensor can I use to identify the marked object thrown on the surface?,"I am trying to implement a concept for somebody else. 

Basically, I want to create a smart surface. I want to create a surface I can throw one or more tagged objects on that should all be recognized. 

I am unsure how to this and what sensors I should use. I have been thinking about using one of the NFC ICs from NXP. However, designing a circuit board and buying this IC is too expensive for our idea. I'm also unsure of whether the surface area will cause problems, because it'll be quite large (think of a small coffee table). 

I've also been thinking about other ways to recognize objects, but I have not come up with anything yet. I am probably not using the correct term. 

Does anyone know of a type or sensor or technique to implement this? 

Note: I am a computer engineer, not an electrical engineer. I know the basics, but really not much more than that, so I prefer a solution that is available as a simple IC or a complete circuit board with the really complicated things done for me by the experts :) 
","A better solution might be to use printed tags and image recognition. There are open source solutions for this - for instance, trackmate. All you will need is a printer, a camera, and a transparent (or possibly frosted) surface.
"
3748,3748,5970,How to keep the same style of a OSM map converted to SHP file,"I saved a OSM file as a Shapefile, this is fixing my previous question how to handle bad layers.

My question is how to retain the original style from OSM plugin to SHP files, when I copy the style and try to paste it it says ""Unknown renderer"".

I mean, is it possible keep the same look I have from OpenStreetMap in the new SHP file?
",Giovassi,https://gis.stackexchange.com/users/19186,"Basically, OSM data files and shapefiles do not contain any style information.

The most common design for OpenStreetMap is the Mapnik renderer. It uses a PostgreSQL database (for perfomance reasons) and has a bunch of XML stylefiles to style the data. It's not only a question of how to render, but also the sequence of rendering, e.g. houses on top of landuses, and roads on top of that, but minor roads first and major roads last, and so on.

QGIS has a much simplier approach for rendering data. Data is rendered in the sequence it is stored in the datasource. So you won't get an easy 1:1 style adaption of the Mapnik style, even if you have the original Mapnik stylefiles.



EDIT

You did not tell us where you got the OSM data from. Reading this previous post, you are using the ""old"" Openstreetmap plugin. That did not allow to save the style in an easy way. A new version of the Openstreetmap plugin is on the way with QGIS 2.0. This will solve many current issues, but is not yet ready for productive use.
",AndreJ,https://gis.stackexchange.com/users/9159,http://gis.stackexchange.com/questions/63744/how-to-keep-the-same-style-of-a-osm-map-converted-to-shp-file,TECHNOLOGY,gis.stackexchange.com,1.0,0.7777777777777778,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,1.0,0.8888888888888888,0.6666666666666667,0.6666666666666666,0.0,0.6666666666666666,0.8888888888888888,How to keep the same style of OSM map converted to SHP file,"I saved a OSM file as a Shapefile, this is fixing my previous question how to handle bad layers.

My question is how to retain the original style from OSM plugin to SHP files, when I copy the style and try to paste it it says ""Unknown renderer"".

I mean, is it possible keep the same look I have from OpenStreetMap in the new SHP file?
","Basically, OSM data files and shapefiles do not contain any style information.

The most common design for OpenStreetMap is the Mapnik renderer. It uses a PostgreSQL database (for perfomance reasons) and has a bunch of XML stylefiles to style the data. It's not only a question of how to render, but also the sequence of rendering, e.g. houses on top of landuses, and roads on top of that, but minor roads first and major roads last, and so on.

QGIS has a much simplier approach for rendering data. Data is rendered in the sequence it is stored in the datasource. So you won't get an easy 1:1 style adaption of the Mapnik style, even if you have the original Mapnik stylefiles.



EDIT

You did not tell us where you got the OSM data from. Reading this previous post, you are using the ""old"" Openstreetmap plugin. That did not allow to save the style in an easy way. A new version of the Openstreetmap plugin is on the way with QGIS 2.0. This will solve many current issues, but is not yet ready for productive use.
"
3162,3162,5033,Tags to Post-ID mysql query. Tag Search,"Im trying to implement a tag-based search. When i specify certain tags, tagged posts will be searched and the post-id will be displayed that matches the searchcriteria.

Currently it only works for a single tag.

$query = ""SELECT DISTINCT $wpdb-&gt;posts.ID FROM $wpdb-&gt;terms
    LEFT JOIN $wpdb-&gt;term_taxonomy ON ($wpdb-&gt;terms.term_id = $wpdb-&gt;term_taxonomy.term_id)
    LEFT JOIN $wpdb-&gt;term_relationships ON ($wpdb-&gt;terms.term_id = $wpdb-&gt;term_relationships.term_taxonomy_id)
    LEFT JOIN $wpdb-&gt;posts ON ($wpdb-&gt;term_relationships.object_id = $wpdb-&gt;posts.ID)
        WHERE $wpdb-&gt;term_taxonomy.taxonomy = 'post_tag' "" . $substring;


Substring looks like following:

$substring = ""AND $wpdb-&gt;terms.slug IN ('tag1','tag2')""


And here is the problem. It does not look for single posts that match all criteria. Instead it 'collects' all posts with all tags searched.

For example:

// postid1 -&gt; tag1
// postid2 -&gt; tag2
// postid3 -&gt; tag1, tag2

$substring = ""AND $wpdb-&gt;terms.slug IN ('tag1')""
//Output: postid1, postid3 - - - CORRECT
$substring = ""AND $wpdb-&gt;terms.slug IN ('tag1','tag2')""
//Output: postid1, postid2, postid3 - - -WRONG!

//Expected: postid3


So far i have no idea howto solve it in a single mysql query. Maybe im missing something.
Thanks for your help in advance.
",proxylittle,https://wordpress.stackexchange.com/users/2669,"These are normal IN mechanics - it matches anything in set, not all of set combined.

Type of match you want is called tag_slug__and in WP query arguments. You can see code that generates SQL for it in source of WP_Query-&gt;&amp;get_posts() method.

Resulting SQL is like this:

SELECT p.ID 
FROM wp_posts p 
INNER JOIN wp_term_relationships tr ON (p.ID = tr.object_id) 
INNER JOIN wp_term_taxonomy tt ON (tr.term_taxonomy_id = tt.term_taxonomy_id) 
INNER JOIN wp_terms t ON (tt.term_id = t.term_id) 
WHERE tt.taxonomy = 'post_tag' 
AND t.slug IN ('is', 'filler') 
GROUP BY p.ID HAVING count(p.ID) = 2

",Rarst,https://wordpress.stackexchange.com/users/847,http://wordpress.stackexchange.com/questions/7509/tags-to-post-id-mysql-query-tag-search,TECHNOLOGY,wordpress.stackexchange.com,0.7777777777777778,0.4444444444444444,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,0.7333333333333333,0.6666666666666666,0.0,0.3333333333333333,0.8888888888888888,The tag used to publish the ID MySQL query. Tag search,"Im trying to implement a tag-based search. When i specify certain tags, tagged posts will be searched and the post-id will be displayed that matches the searchcriteria.

Currently it only works for a single tag.

$query = ""SELECT DISTINCT $wpdb-&gt;posts.ID FROM $wpdb-&gt;terms
    LEFT JOIN $wpdb-&gt;term_taxonomy ON ($wpdb-&gt;terms.term_id = $wpdb-&gt;term_taxonomy.term_id)
    LEFT JOIN $wpdb-&gt;term_relationships ON ($wpdb-&gt;terms.term_id = $wpdb-&gt;term_relationships.term_taxonomy_id)
    LEFT JOIN $wpdb-&gt;posts ON ($wpdb-&gt;term_relationships.object_id = $wpdb-&gt;posts.ID)
        WHERE $wpdb-&gt;term_taxonomy.taxonomy = 'post_tag' "" . $substring;


Substring looks like following:

$substring = ""AND $wpdb-&gt;terms.slug IN ('tag1','tag2')""


And here is the problem. It does not look for single posts that match all criteria. Instead it 'collects' all posts with all tags searched.

For example:

// postid1 -&gt; tag1
// postid2 -&gt; tag2
// postid3 -&gt; tag1, tag2

$substring = ""AND $wpdb-&gt;terms.slug IN ('tag1')""
//Output: postid1, postid3 - - - CORRECT
$substring = ""AND $wpdb-&gt;terms.slug IN ('tag1','tag2')""
//Output: postid1, postid2, postid3 - - -WRONG!

//Expected: postid3


So far i have no idea howto solve it in a single mysql query. Maybe im missing something.
Thanks for your help in advance.
","These are normal IN mechanics - it matches anything in set, not all of set combined.

Type of match you want is called tag_slug__and in WP query arguments. You can see code that generates SQL for it in source of WP_Query-&gt;&amp;get_posts() method.

Resulting SQL is like this:

SELECT p.ID 
FROM wp_posts p 
INNER JOIN wp_term_relationships tr ON (p.ID = tr.object_id) 
INNER JOIN wp_term_taxonomy tt ON (tr.term_taxonomy_id = tt.term_taxonomy_id) 
INNER JOIN wp_terms t ON (tt.term_id = t.term_id) 
WHERE tt.taxonomy = 'post_tag' 
AND t.slug IN ('is', 'filler') 
GROUP BY p.ID HAVING count(p.ID) = 2

"
2412,2412,3849,Should I turn the text on my poster to outlines before I print?,"What would be the best practice for printing text based work from Illustrator, such as a poster? This is aimed at the final print quality of my workk.

I am creating an advertisement which will be about A4 size to go into a newspaper. Would it be best to Create Outline all the text in the advert before I send the files off to be printed or will it not make much of a difference in terms of quality?
",SaturnsEye,https://graphicdesign.stackexchange.com/users/21355,"Customarily, you'd send a PDF/X-1a file with fonts embedded by simply saving that format (with crops and bleed), therefore outlining type would actually not always be a good thing. PDF/X-1a is often preferred because it is a self-contained format with fonts embedded and artwork flattened. This ensures the most accurate preproduction.

If you are sending a .eps or .ai file, then outlining type is the best practice.
",Scott,https://graphicdesign.stackexchange.com/users/3270,http://graphicdesign.stackexchange.com/questions/34936/should-i-turn-the-text-on-my-poster-to-outlines-before-i-print,LIFE_ARTS,graphicdesign.stackexchange.com,0.7777777777777778,0.4444444444444444,0.0,0.3333333333333333,1.0,0.3333333333333333,0.3333333333333333,1.0,1.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,1.0,Should I change the text on the poster to outline before printing?,"What would be the best practice for printing text based work from Illustrator, such as a poster? This is aimed at the final print quality of my workk.

I am creating an advertisement which will be about A4 size to go into a newspaper. Would it be best to Create Outline all the text in the advert before I send the files off to be printed or will it not make much of a difference in terms of quality?
","Customarily, you'd send a PDF/X-1a file with fonts embedded by simply saving that format (with crops and bleed), therefore outlining type would actually not always be a good thing. PDF/X-1a is often preferred because it is a self-contained format with fonts embedded and artwork flattened. This ensures the most accurate preproduction.

If you are sending a .eps or .ai file, then outlining type is the best practice.
"
1491,1491,2347,OCR software for handwritten notes,"I am looking for a way to recognize handwriting of scanned notes (in PDF format).

It doesn't have to be perfect, and it doesn't have to free, but before paying I would like to try it (even with just a single page).

It doesn't necessarily have to be a native Mac OS X application. I would be OK with an online application, or a Unix application to install or compile. In other words, anything that works somewhat decently would be OK.

I am also not necessarily looking for a perfect result. Even transforming my notes into a searchable PDF with just some of the text recognized would be better than nothing.
",Matteo,https://apple.stackexchange.com/users/10888,"If you're fammiliar with any programming language, take a look @ ocrsdk.com, it's a website that lets you upload images through web API and sends you back OCRed data. Here's the documentation artcile on handwriting recognition: http://ocrsdk.com/documentation/quick-start/text-fields/ and here are some codesamples @ github: https://github.com/abbyysdk/ocrsdk.com There's a nice 50 pages free trial without any upfront charges.
",Nikolay,https://apple.stackexchange.com/users/21713,http://apple.stackexchange.com/questions/48807/ocr-software-for-handwritten-notes,TECHNOLOGY,apple.stackexchange.com,1.0,0.7777777777777778,0.0,1.0,1.0,1.0,0.6666666666666666,0.5555555555555556,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,1.0,1.0,0.7333333333333333,0.0,0.3333333333333333,0.6666666666666666,0.8888888888888888,OCR software for handwritten notes,"I am looking for a way to recognize handwriting of scanned notes (in PDF format).

It doesn't have to be perfect, and it doesn't have to free, but before paying I would like to try it (even with just a single page).

It doesn't necessarily have to be a native Mac OS X application. I would be OK with an online application, or a Unix application to install or compile. In other words, anything that works somewhat decently would be OK.

I am also not necessarily looking for a perfect result. Even transforming my notes into a searchable PDF with just some of the text recognized would be better than nothing.
","If you're fammiliar with any programming language, take a look @ ocrsdk.com, it's a website that lets you upload images through web API and sends you back OCRed data. Here's the documentation artcile on handwriting recognition: http://ocrsdk.com/documentation/quick-start/text-fields/ and here are some codesamples @ github: https://github.com/abbyysdk/ocrsdk.com There's a nice 50 pages free trial without any upfront charges.
"
5646,5646,8951,Why is the last line of text separated in MS Visio shapes,"In the image below, you can see two rectangles with some text inside. If you take a closer look you will notice a difference in spacing between lines. The spacing between the first and the second lines is smaller than the spacing between the second and the third.

The last line is always separated. If you have 10 lines of text, the spacing between all the lines will be OK except the spacing between the next to last and the last line of text.
The font is the same (in every aspect) accross the lines (except the title), and there are no custom paragraph properties set.

Why does this happen and how to solve this?


",Kornelije Petak,https://superuser.com/users/12849,"I was able to highlight all the text (Control + A), right click on the highlighted text, select Format Text, select a size 12 font, even though it said it was already size 12, then click OK and it got rid of the space. 
",Michael J. Smith,https://superuser.com/users/282694,http://superuser.com/questions/432770,TECHNOLOGY,superuser.com,1.0,0.6666666666666666,0.0,1.0,0.3333333333333333,1.0,0.4444444444444444,0.3333333333333333,0.6666666666666666,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,1.0,0.0,1.0,1.0,0.5555555555555556,1.0,1.0,0.7333333333333333,1.0,0.0,0.0,1.0,Why is the last line of text in MS Visio shapes separate,"In the image below, you can see two rectangles with some text inside. If you take a closer look you will notice a difference in spacing between lines. The spacing between the first and the second lines is smaller than the spacing between the second and the third.

The last line is always separated. If you have 10 lines of text, the spacing between all the lines will be OK except the spacing between the next to last and the last line of text.
The font is the same (in every aspect) accross the lines (except the title), and there are no custom paragraph properties set.

Why does this happen and how to solve this?


","I can highlight all the text (control + a), right-click the highlighted text, select ""format text"", select a 12 point font, even if it says it's already 12 point font, and then click ""OK"" to remove the space."

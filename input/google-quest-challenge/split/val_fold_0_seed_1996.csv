,Unnamed: 0,qa_id,question_title,question_body,question_user_name,question_user_page,answer,answer_user_name,answer_user_page,url,category,host,question_asker_intent_understanding,question_body_critical,question_conversational,question_expect_short_answer,question_fact_seeking,question_has_commonly_accepted_answer,question_interestingness_others,question_interestingness_self,question_multi_intent,question_not_really_a_question,question_opinion_seeking,question_type_choice,question_type_compare,question_type_consequence,question_type_definition,question_type_entity,question_type_instructions,question_type_procedure,question_type_reason_explanation,question_type_spelling,question_well_written,answer_helpful,answer_level_of_information,answer_plausible,answer_relevance,answer_satisfaction,answer_type_instructions,answer_type_procedure,answer_type_reason_explanation,answer_well_written,t_aug,q_aug,a_aug
4320,4320,6878,Is apt-get upgrade a dangerous command?,"When I use apt-get update and apt-get upgrade,there are some packages should installed in newest version,like below:

The following packages will be upgraded:
  accountsservice apparmor apport apt apt-transport-https apt-utils binutils
  cloud-init cpp-4.8 dpkg fuse g++-4.8 gcc-4.8 gcc-4.8-base gdisk gnupg gpgv
  grub-common grub-legacy-ec2 grub-pc grub-pc-bin grub2-common initscripts
  isc-dhcp-client isc-dhcp-common libaccountsservice0 libapparmor-perl
  libapparmor1 libapt-inst1.5 libapt-pkg4.12 libasan0 libatomic1 libbsd0
  libcurl3-gnutls libdrm2 libedit2 libfuse2 libgcc-4.8-dev libgd3 libgomp1
  libitm1 libjson-c2 libjson0 libnuma1 libpam-systemd libpolkit-agent-1-0
  libpolkit-backend-1-0 libpolkit-gobject-1-0 libquadmath0 libstdc++-4.8-dev
  libstdc++6 libsystemd-daemon0 libsystemd-login0 libtsan0 libudev1 libxext6
  linux-libc-dev ntpdate openssl overlayroot patch policykit-1 ppp
  python-urllib3 python3-apport python3-problem-report python3-update-manager
  rsyslog systemd-services sysv-rc sysvinit-utils tcpdump tzdata udev
  update-manager-core
75 upgraded, 0 newly installed, 0 to remove and 4 not upgraded.


If I didn't know every one of there packages what will happen if there update in newest version.I shouldn't execute this command(apt-get upgrade).

For example:

This php version is before I upgrade

yzxu@ubuntu:/tmp/git-2.1.2$ php --version
PHP 5.6.6-1+deb.sury.org~precise+1 (cli) 
Copyright (c) 1997-2015 The PHP Group
Zend Engine v2.6.0, Copyright (c) 1998-2015 Zend Technologies
    with Zend OPcache v7.0.6-dev, Copyright (c) 1999-2015, by Zend Technologies


and after I upgrade:

yzxu@ubuntu:/tmp/git-2.1.2$ php --version
PHP 5.6.10-1+deb.sury.org~precise+1 (cli) 
Copyright (c) 1997-2015 The PHP Group
Zend Engine v2.6.0, Copyright (c) 1998-2015 Zend Technologies
    with Zend OPcache v7.0.6-dev, Copyright (c) 1999-2015, by Zend Technologies


The php version is changed.And if I didn't what what was change in two version,should I upgrade it?Is it will influence product?
",大易归真,https://askubuntu.com/users/422775,"When you run apt-get upgradeit updates all installed packages on your system.
It is perfectly safe (unless you cut it off before it finishes) as all packages are from the repos (you should only install one's you trust) and are (probably) well tested before uploading.

The only small risk is a risk of bugs within the packages there self, but this could happen to any thing on any OS that was upgraded as bugs are common in any software and come and go based on version.

Should you upgrade ? Well thats up to you, I would say yes, if you don't like upgrade use the application-updater app, same thing no output to make you worried.

Here is some documentation for apt so you can find out more
",Mark Kirby,https://askubuntu.com/users/75060,http://askubuntu.com/questions/639822/is-apt-get-upgrade-a-dangerous-command/639838,TECHNOLOGY,askubuntu.com,0.5555555555555556,0.5555555555555556,0.0,1.0,1.0,1.0,0.5555555555555556,0.5555555555555556,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.5555555555555556,0.6666666666666666,0.6666666666666666,0.6666666666666666,1.0,0.8666666666666666,0.0,0.0,1.0,1.0,Is apt get upgrade a dangerous command?,"When I use apt-get update and apt-get upgrade,there are some packages should installed in newest version,like below:

The following packages will be upgraded:
  accountsservice apparmor apport apt apt-transport-https apt-utils binutils
  cloud-init cpp-4.8 dpkg fuse g++-4.8 gcc-4.8 gcc-4.8-base gdisk gnupg gpgv
  grub-common grub-legacy-ec2 grub-pc grub-pc-bin grub2-common initscripts
  isc-dhcp-client isc-dhcp-common libaccountsservice0 libapparmor-perl
  libapparmor1 libapt-inst1.5 libapt-pkg4.12 libasan0 libatomic1 libbsd0
  libcurl3-gnutls libdrm2 libedit2 libfuse2 libgcc-4.8-dev libgd3 libgomp1
  libitm1 libjson-c2 libjson0 libnuma1 libpam-systemd libpolkit-agent-1-0
  libpolkit-backend-1-0 libpolkit-gobject-1-0 libquadmath0 libstdc++-4.8-dev
  libstdc++6 libsystemd-daemon0 libsystemd-login0 libtsan0 libudev1 libxext6
  linux-libc-dev ntpdate openssl overlayroot patch policykit-1 ppp
  python-urllib3 python3-apport python3-problem-report python3-update-manager
  rsyslog systemd-services sysv-rc sysvinit-utils tcpdump tzdata udev
  update-manager-core
75 upgraded, 0 newly installed, 0 to remove and 4 not upgraded.


If I didn't know every one of there packages what will happen if there update in newest version.I shouldn't execute this command(apt-get upgrade).

For example:

This php version is before I upgrade

yzxu@ubuntu:/tmp/git-2.1.2$ php --version
PHP 5.6.6-1+deb.sury.org~precise+1 (cli) 
Copyright (c) 1997-2015 The PHP Group
Zend Engine v2.6.0, Copyright (c) 1998-2015 Zend Technologies
    with Zend OPcache v7.0.6-dev, Copyright (c) 1999-2015, by Zend Technologies


and after I upgrade:

yzxu@ubuntu:/tmp/git-2.1.2$ php --version
PHP 5.6.10-1+deb.sury.org~precise+1 (cli) 
Copyright (c) 1997-2015 The PHP Group
Zend Engine v2.6.0, Copyright (c) 1998-2015 Zend Technologies
    with Zend OPcache v7.0.6-dev, Copyright (c) 1999-2015, by Zend Technologies


The php version is changed.And if I didn't what what was change in two version,should I upgrade it?Is it will influence product?
","When you run apt-get upgradeit updates all installed packages on your system.
It is perfectly safe (unless you cut it off before it finishes) as all packages are from the repos (you should only install one's you trust) and are (probably) well tested before uploading.

The only small risk is a risk of bugs within the packages there self, but this could happen to any thing on any OS that was upgraded as bugs are common in any software and come and go based on version.

Should you upgrade ? Well thats up to you, I would say yes, if you don't like upgrade use the application-updater app, same thing no output to make you worried.

Here is some documentation for apt so you can find out more
"
126,126,201,How to deploy OSGi bundle to Maven repo with deploy:deploy-file?,"I have an OSGi bundle that was built using Maven by another team. The POM file declares its packaging as ""bundle"" and uses the Apache Felix plugin.

I need to deploy this artifact to a local Maven repository (Nexus) so that it can be used by our internal projects.

I have used the deploy:deploy-file target to deploy the bundle to the repository, just as you would with a standard JAR file and this works without error. I extracted the embedded POM from the bundle and passed that on the command line, so the command line was:

mvn deploy:deploy-file -Dfile=3rdpartybundle.jar -DpomFile=pom.xml -DrepositoryId=internal -Durl=http://internalserver/nexus


The issue is that when I deploy it like this, the packaging is set to bundle and as a result the name of the artifact in the repository ends up with a .bundle extension, instead of a .jar extension.

Now, we cannot figure out how to declare it as a dependency. If we declare it like this:

        &lt;dependency&gt;
            &lt;groupId&gt;...&lt;/groupId&gt;
            &lt;artifactId&gt;...&lt;/artifactId&gt;
            &lt;version&gt;...&lt;/version&gt;
            &lt;type&gt;bundle&lt;/type&gt;
        &lt;/dependency&gt;


We get an error stating that the dependency cannot be resolved. The interesting thing is that the GAV coordinates in the error message actually has ""jar"" as the value for the type of the dependency even though we set it as ""bundle"".

If we change the dependency to:

        &lt;dependency&gt;
            &lt;groupId&gt;...&lt;/groupId&gt;
            &lt;artifactId&gt;...&lt;/artifactId&gt;
            &lt;version&gt;...&lt;/version&gt;
            &lt;type&gt;jar&lt;/type&gt;
        &lt;/dependency&gt;


We get the exact same unresolved dependency error.

So how are you supposed to deploy an artifact packaged as a bundle to a Maven repository, so that it can be used as a compile time dependency for another project?

Thanks
",Craig S. Dickson,https://stackoverflow.com/users/860117,"Thanks for the answers, I think I have a workaround (I wouldn't call it a solution though).

@earcar is on the right track, although that solution doesn't leverage all of the information available in the pom.xml that is available in the 3rd party bundle already (particularly the dependencies).

So what seems to work, even though the documentation for the deploy:deploy-file is a little vague, is that you can pass a pom.xml file AND also set the packaging parameter at the same time. So my command line now looks like this:

mvn deploy:deploy-file -Dfile=3rdpartybundle.jar -DpomFile=pom.xml -DrepositoryId=internal -Durl=http://internalserver/nexus -Dpackaging=jar


Doing it this way, the pom.xml in the repository still says that the packaging is of type ""bundle"", and includes all of the dependencies etc., but the artifact itself has a .jar file extension.

Then when we declare our dependency as type JAR, Maven is able to resolve it successfully:

    &lt;dependency&gt;
        &lt;groupId&gt;...&lt;/groupId&gt;
        &lt;artifactId&gt;...&lt;/artifactId&gt;
        &lt;version&gt;...&lt;/version&gt;
        &lt;type&gt;jar&lt;/type&gt;
    &lt;/dependency&gt;


This basically solves our problem. I am not sure how portable or reliable this is though. FWIW, we are running Maven 3.0.3

Thanks for the help.
",Craig S. Dickson,https://stackoverflow.com/users/860117,http://stackoverflow.com/questions/7406600/how-to-deploy-osgi-bundle-to-maven-repo-with-deploydeploy-file,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.5555555555555556,0.0,0.0,1.0,1.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.6666666666666666,0.0,0.3333333333333333,1.0,How to use the deploy: deploy file to deploy OSGi package to Maven repo?,"I have an OSGi bundle that was built using Maven by another team. The POM file declares its packaging as ""bundle"" and uses the Apache Felix plugin.

I need to deploy this artifact to a local Maven repository (Nexus) so that it can be used by our internal projects.

I have used the deploy:deploy-file target to deploy the bundle to the repository, just as you would with a standard JAR file and this works without error. I extracted the embedded POM from the bundle and passed that on the command line, so the command line was:

mvn deploy:deploy-file -Dfile=3rdpartybundle.jar -DpomFile=pom.xml -DrepositoryId=internal -Durl=http://internalserver/nexus


The issue is that when I deploy it like this, the packaging is set to bundle and as a result the name of the artifact in the repository ends up with a .bundle extension, instead of a .jar extension.

Now, we cannot figure out how to declare it as a dependency. If we declare it like this:

        &lt;dependency&gt;
            &lt;groupId&gt;...&lt;/groupId&gt;
            &lt;artifactId&gt;...&lt;/artifactId&gt;
            &lt;version&gt;...&lt;/version&gt;
            &lt;type&gt;bundle&lt;/type&gt;
        &lt;/dependency&gt;


We get an error stating that the dependency cannot be resolved. The interesting thing is that the GAV coordinates in the error message actually has ""jar"" as the value for the type of the dependency even though we set it as ""bundle"".

If we change the dependency to:

        &lt;dependency&gt;
            &lt;groupId&gt;...&lt;/groupId&gt;
            &lt;artifactId&gt;...&lt;/artifactId&gt;
            &lt;version&gt;...&lt;/version&gt;
            &lt;type&gt;jar&lt;/type&gt;
        &lt;/dependency&gt;


We get the exact same unresolved dependency error.

So how are you supposed to deploy an artifact packaged as a bundle to a Maven repository, so that it can be used as a compile time dependency for another project?

Thanks
","Thanks for the answers, I think I have a workaround (I wouldn't call it a solution though).

@earcar is on the right track, although that solution doesn't leverage all of the information available in the pom.xml that is available in the 3rd party bundle already (particularly the dependencies).

So what seems to work, even though the documentation for the deploy:deploy-file is a little vague, is that you can pass a pom.xml file AND also set the packaging parameter at the same time. So my command line now looks like this:

mvn deploy:deploy-file -Dfile=3rdpartybundle.jar -DpomFile=pom.xml -DrepositoryId=internal -Durl=http://internalserver/nexus -Dpackaging=jar


Doing it this way, the pom.xml in the repository still says that the packaging is of type ""bundle"", and includes all of the dependencies etc., but the artifact itself has a .jar file extension.

Then when we declare our dependency as type JAR, Maven is able to resolve it successfully:

    &lt;dependency&gt;
        &lt;groupId&gt;...&lt;/groupId&gt;
        &lt;artifactId&gt;...&lt;/artifactId&gt;
        &lt;version&gt;...&lt;/version&gt;
        &lt;type&gt;jar&lt;/type&gt;
    &lt;/dependency&gt;


This basically solves our problem. I am not sure how portable or reliable this is though. FWIW, we are running Maven 3.0.3

Thanks for the help.
"
5811,5811,9204,Is there an iOS SMS Texting app that allows parent to get a record of all texting messages?,"My son (pre-teen) received an iPod Touch for Christmas.  He has a friend that does not have an iOS device.  But his friend can text.  I am still at the stage and my son is still of the age that I would like to have a way to know when he is texting and what he is texting.  Is there an app for that?

[It could be something that allows me to setup an account and login to a website to see activity.]
",JeffJak,https://apple.stackexchange.com/users/11458,"I found this app.

SMS Touch that allows you to setup email address to send copy of SMS content.  SMS are purchased in app.

Net Nanny are also bringing out an iOS app to monitor and restrict iOS devices in young persons hands. details  here


  NET NANNY FOR IOS includes Filtering (18 categories), Age-based Profiles, Safe Search, Profanity Masking, and supports Wi-Fi/3G/4G.
  
  NET NANNY SUITE FOR IOS includes all the features of Net Nanny for iOS plus Remote Administration, Reports, Custom Categories, Whitelist/Blacklist. Future releases within the next few months will include Time Controls, Custom Alerts, Reports, and device management tools such as Device Locate and Forced Ring. All new features will be auto-updated for existing users.

",Stu Wilson,https://apple.stackexchange.com/users/16529,http://apple.stackexchange.com/questions/37481/is-there-an-ios-sms-texting-app-that-allows-parent-to-get-a-record-of-all-textin,TECHNOLOGY,apple.stackexchange.com,1.0,0.8888888888888888,0.0,1.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.5555555555555556,0.0,0.0,0.3333333333333333,0.6666666666666666,0.3333333333333333,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,0.3333333333333333,0.7777777777777778,Is there an IOS SMS app that allows parents to get records of all SMS messages?,"My son received an iPod touch on Christmas. He has a friend who doesn't have an IOS device. But his friends can text. I'm still in this stage, and my son is still the age when I want to know when he is texting and what he is texting. Is there any application in this field?","I found this app.

SMS Touch that allows you to setup email address to send copy of SMS content.  SMS are purchased in app.

Net Nanny are also bringing out an iOS app to monitor and restrict iOS devices in young persons hands. details  here


  NET NANNY FOR IOS includes Filtering (18 categories), Age-based Profiles, Safe Search, Profanity Masking, and supports Wi-Fi/3G/4G.
  
  NET NANNY SUITE FOR IOS includes all the features of Net Nanny for iOS plus Remote Administration, Reports, Custom Categories, Whitelist/Blacklist. Future releases within the next few months will include Time Controls, Custom Alerts, Reports, and device management tools such as Device Locate and Forced Ring. All new features will be auto-updated for existing users.

"
530,530,834,Using pstool with beamer,"I would like to use pstool with beamer to create a presentation in pdflatex with figures processed by psfrag. However, as the simple example below shows, the figures are processed using the beamer documentclass, so that they each have a full beamer ""frame"" around them. Is there a way around this?

\documentclass{beamer}

\usepackage{lmodern}
\usepackage{graphicx}
\usepackage[process=all,crop=pdfcrop]{pstool}

\begin{document}
\begin{frame}
    \frametitle{Circle}
    \begin{figure}
        \psfragfig[width=0.3\textwidth]{figures/circle}
        {
            \psfrag{1}{\(s\)}
        }
    \end{figure}
\end{frame}
\end{document}




I suspect that if it's possible to override the documentclass used by pstool to process the figures, that would be a solution, but I haven't found how to do this.

Thanks.
",mjr,https://tex.stackexchange.com/users/5238,"The key to solving this is to realise that a ""regular"" compilation process sends your document through pdfLaTeX in PDF mode, and in order to do the psfrag replacements the graphic is sent through pdfLaTeX in DVI mode.

Therefore, conditional commands for either the main document only or each graphic only can simply use \ifpdf:

\ifpdf
  % setup for the main document only
\else
  % setup for pstool images only
\fi


And so in your case:

\ifpdf\else
  \setbeamertemplate{navigation symbols}{}
\fi


This is entirely unmentioned in the documentation, so I'll go fix that up now.
",Will Robertson,https://tex.stackexchange.com/users/179,http://tex.stackexchange.com/questions/167489/using-pstool-with-beamer,TECHNOLOGY,tex.stackexchange.com,1.0,0.3333333333333333,0.0,0.6666666666666666,0.3333333333333333,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.4444444444444444,0.8888888888888888,0.5555555555555556,0.8888888888888888,1.0,0.8666666666666666,1.0,0.0,0.0,0.8888888888888888,Using pstool and beamer,"I would like to use pstool with beamer to create a presentation in pdflatex with figures processed by psfrag. However, as the simple example below shows, the figures are processed using the beamer documentclass, so that they each have a full beamer ""frame"" around them. Is there a way around this?

\documentclass{beamer}

\usepackage{lmodern}
\usepackage{graphicx}
\usepackage[process=all,crop=pdfcrop]{pstool}

\begin{document}
\begin{frame}
    \frametitle{Circle}
    \begin{figure}
        \psfragfig[width=0.3\textwidth]{figures/circle}
        {
            \psfrag{1}{\(s\)}
        }
    \end{figure}
\end{frame}
\end{document}




I suspect that if it's possible to override the documentclass used by pstool to process the figures, that would be a solution, but I haven't found how to do this.

Thanks.
","The key to solving this is to realise that a ""regular"" compilation process sends your document through pdfLaTeX in PDF mode, and in order to do the psfrag replacements the graphic is sent through pdfLaTeX in DVI mode.

Therefore, conditional commands for either the main document only or each graphic only can simply use \ifpdf:

\ifpdf
  % setup for the main document only
\else
  % setup for pstool images only
\fi


And so in your case:

\ifpdf\else
  \setbeamertemplate{navigation symbols}{}
\fi


This is entirely unmentioned in the documentation, so I'll go fix that up now.
"
2380,2380,3792,I am a Resident Alien for tax purposes. Can I claim exemptions from the India - US Tax Treaty (21)?,"I am an Indian citizen living in the US since 2008 with an F1 Visa. I am a resident for tax purposes. Can I claim exemption under the India US Tax Treaty (21) ""Students and Business Apprentices From India""? So Do I have to file the 1040NR in spite for being a resident alien for tax purposes?

Could anyone site me IRS publications which clarifies this? I am looking through p519 and am lost :-/
",Lord Loh.,https://money.stackexchange.com/users/13083,"I was able to find several references that claim that the Indo-US treaty provision is limited to five years:

Here it says this (on page 20):


  Generally the treaty exemption for students is limited to the first
  five calendar years that the international student is in the U.S.
  However there is no set time limit for students from Belgium,
  Bulgaria, China, The Netherlands, and Pakistan.


However, I couldn't find any specific time limit neither in the treaty nor in the technical explanation. The explanation says:


  Thus, for example, an Indian resident who visits the United States as
  a student and becomes a U.S. resident according to the Code, other
  than by virtue of acquiring a green card, would continue to be exempt
  from U.S. tax in accordance with this Article so long as he is not a
  U.S. citizen and does not acquire immigrant status in the United
  States. The saving clause does apply to U.S. citizens and immigrants.


However, the treaty explicitly says this:


  The benefits of this Article shall extend only for such period of time
  as may be reasonable or customarily required to complete the education
  or training undertaken.


The reason for this last paragraph is to ensure that you don't artificially prolong your student status, and the 5 year limit may come out of the interpretation of this specific paragraph.

Similar paragraph exists in the US-China treaty, and the explanation for that treaty says this:


  These exemptions may be claimed only for the period reasonably
  necessary to complete the education or training. In some cases, the
  course of study or training may last less than year. For most
  undergraduate college or university degrees the appropriate period
  will be four years. For some advanced degrees, such as in medicine,
  the required period may be longer, e.g., seven years.


Based on this, it is my personal impression that if you're an undergraduate student and studying the same degree (and not, for example, finished your BA, and started your MS) - you are no longer eligible for the treaty benefit.

But I suggest you ask a professional (EA/CPA licensed in your State) for a more reliable tax advice on the matter. I'm not a tax professional and this is not a tax advice.
",littleadv,https://money.stackexchange.com/users/2998,http://money.stackexchange.com/questions/28257/i-am-a-resident-alien-for-tax-purposes-can-i-claim-exemptions-from-the-india,LIFE_ARTS,money.stackexchange.com,1.0,0.7777777777777778,0.0,0.6666666666666666,0.6666666666666666,1.0,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,1.0,1.0,0.9333333333333332,0.6666666666666666,0.0,1.0,0.8888888888888888,I am a foreign tax resident. Can I apply for exemption from the India-U.S. tax treaty (21)?,"I am an Indian citizen who has lived in the United States since 2008 and holds an F1 visa. I am a tax resident. Can I apply for exemption under the Indian American tax treaty (21), ""Indian students and apprentices""? So do I have to file 1040NR even though I am a foreign resident for tax purposes?","I was able to find several references that claim that the Indo-US treaty provision is limited to five years:

Here it says this (on page 20):


  Generally the treaty exemption for students is limited to the first
  five calendar years that the international student is in the U.S.
  However there is no set time limit for students from Belgium,
  Bulgaria, China, The Netherlands, and Pakistan.


However, I couldn't find any specific time limit neither in the treaty nor in the technical explanation. The explanation says:


  Thus, for example, an Indian resident who visits the United States as
  a student and becomes a U.S. resident according to the Code, other
  than by virtue of acquiring a green card, would continue to be exempt
  from U.S. tax in accordance with this Article so long as he is not a
  U.S. citizen and does not acquire immigrant status in the United
  States. The saving clause does apply to U.S. citizens and immigrants.


However, the treaty explicitly says this:


  The benefits of this Article shall extend only for such period of time
  as may be reasonable or customarily required to complete the education
  or training undertaken.


The reason for this last paragraph is to ensure that you don't artificially prolong your student status, and the 5 year limit may come out of the interpretation of this specific paragraph.

Similar paragraph exists in the US-China treaty, and the explanation for that treaty says this:


  These exemptions may be claimed only for the period reasonably
  necessary to complete the education or training. In some cases, the
  course of study or training may last less than year. For most
  undergraduate college or university degrees the appropriate period
  will be four years. For some advanced degrees, such as in medicine,
  the required period may be longer, e.g., seven years.


Based on this, it is my personal impression that if you're an undergraduate student and studying the same degree (and not, for example, finished your BA, and started your MS) - you are no longer eligible for the treaty benefit.

But I suggest you ask a professional (EA/CPA licensed in your State) for a more reliable tax advice on the matter. I'm not a tax professional and this is not a tax advice.
"
4939,4939,7865,Upper Bound on Determinant of Matrix in terms of Trace,"For an $n\times n$ positive definite matrix $A$, I wish to prove that 


  $$\det(A) \leq \bigg(\frac{Trace(A)}{n}\bigg)^n$$


To me this seems some form of AM-GM Inequality (Arithmatic Mean-Geometric Mean Inequality). Therefore If I can show the following, above inequality follows : 


  $$\det(A) \leq \prod_{i=1}^{i=n} A_{ii}$$


Any idea how to prove the above.
Thanks
",damned,https://math.stackexchange.com/users/26171,"Your second inequality is a consequence  of the Hadamard inequality, see here:
http://en.wikipedia.org/wiki/Hadamard_inequality

Another way is to use the result that the eigenvalue vector of a Hermitian (hence real symmetric) matrix majorizes the vector of diagonal values, and then using that the product function $\prod_{i=1}^n x_i$ for $x_i&gt;0$ is Schur-convex:

One source for this results is the book by Bhatia: ""Matrix Analysis"". 
",kjetil b halvorsen,https://math.stackexchange.com/users/32967,http://math.stackexchange.com/questions/202248/upper-bound-on-determinant-of-matrix-in-terms-of-trace,SCIENCE,math.stackexchange.com,0.6666666666666666,0.3333333333333333,0.0,0.0,1.0,0.0,0.6666666666666666,0.4444444444444444,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.3333333333333333,0.0,0.7777777777777778,0.8333333333333334,0.6666666666666666,1.0,1.0,0.8,0.0,0.0,1.0,1.0,Trace upper bound of matrix determinant,"For an $n\times n$ positive definite matrix $A$, I wish to prove that 


  $$\det(A) \leq \bigg(\frac{Trace(A)}{n}\bigg)^n$$


To me this seems some form of AM-GM Inequality (Arithmatic Mean-Geometric Mean Inequality). Therefore If I can show the following, above inequality follows : 


  $$\det(A) \leq \prod_{i=1}^{i=n} A_{ii}$$


Any idea how to prove the above.
Thanks
","Your second inequality is a consequence  of the Hadamard inequality, see here:
http://en.wikipedia.org/wiki/Hadamard_inequality

Another way is to use the result that the eigenvalue vector of a Hermitian (hence real symmetric) matrix majorizes the vector of diagonal values, and then using that the product function $\prod_{i=1}^n x_i$ for $x_i&gt;0$ is Schur-convex:

One source for this results is the book by Bhatia: ""Matrix Analysis"". 
"
778,778,1239,What route do I use to refer to the path of the current user's profile? Devise,"Users of my application upload an avatar when they create their profiles. Here is how I display a small version of their profile picture in the navbar:

 &lt;li&gt;&lt;%= link_to image_tag current_user.avatar(:nav) %&gt;&lt;/li&gt;


I want that link to to go to the profile page of the current user. Here are my routes:

  Prefix Verb   URI Pattern                    Controller#Action
                  things GET    /things(.:format)              things#index
                         POST   /things(.:format)              things#create
               new_thing GET    /things/new(.:format)          things#new
              edit_thing GET    /things/:id/edit(.:format)     things#edit
                   thing GET    /things/:id(.:format)          things#show
                         PATCH  /things/:id(.:format)          things#update
                         PUT    /things/:id(.:format)          things#update
                         DELETE /things/:id(.:format)          things#destroy
        new_user_session GET    /users/sign_in(.:format)       devise/sessions#new
            user_session POST   /users/sign_in(.:format)       devise/sessions#create
    destroy_user_session DELETE /users/sign_out(.:format)      devise/sessions#destroy
           user_password POST   /users/password(.:format)      devise/passwords#create
       new_user_password GET    /users/password/new(.:format)  devise/passwords#new
      edit_user_password GET    /users/password/edit(.:format) devise/passwords#edit
                         PATCH  /users/password(.:format)      devise/passwords#update
                         PUT    /users/password(.:format)      devise/passwords#update
cancel_user_registration GET    /users/cancel(.:format)        devise/registrations#cancel
       user_registration POST   /users(.:format)               devise/registrations#create
   new_user_registration GET    /users/sign_up(.:format)       devise/registrations#new
  edit_user_registration GET    /users/edit(.:format)          devise/registrations#edit
                         PATCH  /users(.:format)               devise/registrations#update
                         PUT    /users(.:format)               devise/registrations#update
                         DELETE /users(.:format)               devise/registrations#destroy
                   users POST   /users(.:format)               users#create
                new_user GET    /users/new(.:format)           users#new
                    user GET    /users/:id(.:format)           users#show
                   about GET    /about(.:format)               pagess#about
                    root GET    /                              things#index


I am currently using Devise for authentication.

Here is my UsersController

class UsersController &lt; ApplicationController
  def show
    @user = User.find_by_username(params[:id])
  end

  def user_params
      params.require(:user).permit(:avatar)
  end
end

",Dylan Richards,https://stackoverflow.com/users/2966990,"Try:

&lt;li&gt;&lt;%= link_to (image_tag current_user.avatar(:nav)), user_path(current_user.id) %&gt;&lt;/li&gt;


You may also be able to get away with just 'current_user' and not 'current_user.id'
",Philip7899,https://stackoverflow.com/users/1959050,http://stackoverflow.com/questions/20305008/what-route-do-i-use-to-refer-to-the-path-of-the-current-users-profile-devise,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.5555555555555556,0.0,1.0,1.0,1.0,0.5555555555555556,0.5555555555555556,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,1.0,1.0,0.0,0.0,0.8888888888888888,What path do I use to refer to the path of the current user profile? Design,"Users of my application upload an avatar when they create their profiles. Here is how I display a small version of their profile picture in the navbar:

 &lt;li&gt;&lt;%= link_to image_tag current_user.avatar(:nav) %&gt;&lt;/li&gt;


I want that link to to go to the profile page of the current user. Here are my routes:

  Prefix Verb   URI Pattern                    Controller#Action
                  things GET    /things(.:format)              things#index
                         POST   /things(.:format)              things#create
               new_thing GET    /things/new(.:format)          things#new
              edit_thing GET    /things/:id/edit(.:format)     things#edit
                   thing GET    /things/:id(.:format)          things#show
                         PATCH  /things/:id(.:format)          things#update
                         PUT    /things/:id(.:format)          things#update
                         DELETE /things/:id(.:format)          things#destroy
        new_user_session GET    /users/sign_in(.:format)       devise/sessions#new
            user_session POST   /users/sign_in(.:format)       devise/sessions#create
    destroy_user_session DELETE /users/sign_out(.:format)      devise/sessions#destroy
           user_password POST   /users/password(.:format)      devise/passwords#create
       new_user_password GET    /users/password/new(.:format)  devise/passwords#new
      edit_user_password GET    /users/password/edit(.:format) devise/passwords#edit
                         PATCH  /users/password(.:format)      devise/passwords#update
                         PUT    /users/password(.:format)      devise/passwords#update
cancel_user_registration GET    /users/cancel(.:format)        devise/registrations#cancel
       user_registration POST   /users(.:format)               devise/registrations#create
   new_user_registration GET    /users/sign_up(.:format)       devise/registrations#new
  edit_user_registration GET    /users/edit(.:format)          devise/registrations#edit
                         PATCH  /users(.:format)               devise/registrations#update
                         PUT    /users(.:format)               devise/registrations#update
                         DELETE /users(.:format)               devise/registrations#destroy
                   users POST   /users(.:format)               users#create
                new_user GET    /users/new(.:format)           users#new
                    user GET    /users/:id(.:format)           users#show
                   about GET    /about(.:format)               pagess#about
                    root GET    /                              things#index


I am currently using Devise for authentication.

Here is my UsersController

class UsersController &lt; ApplicationController
  def show
    @user = User.find_by_username(params[:id])
  end

  def user_params
      params.require(:user).permit(:avatar)
  end
end

","Try:

&lt;li&gt;&lt;%= link_to (image_tag current_user.avatar(:nav)), user_path(current_user.id) %&gt;&lt;/li&gt;


You may also be able to get away with just 'current_user' and not 'current_user.id'
"
4001,4001,6390,What is the use of the unused Data pins of a LCD,"I've a 16 pin LCD. The whole display (16x2) can be driven just using only half of the data pins (D4 - D7) of the LCD. Other 4 data pins (D0 - D3) can be neglected.

I need to know why then the LCDs come with eight data pins. Of course, there should be some reason(achieve faster update rates etc...)

Can someone show me the reason..
(This is just for my knowledge)

Thanks!
",Anubis,https://electronics.stackexchange.com/users/11033,"It has 8 data pins. The 8-bit mode is the standard mode, because the data is 8-bit: the characters are ASCII, and the DDRAM addresses are also 7 bit wide. In 8-bit mode you write them in 1 instruction, in 4-bit mode you have to split a byte in 2 nibbles, shift one of them 4 bits to the right, and perform 2 write operations.  

8-bit mode is just more simple.

edit
The 4-bit mode is often used today to save I/O pins. When the HD44780 was released microprocessors were far more common than microcontrollers. Microprocessors have data and address buses, and since most microprocessors were at least 8-bit that was not a problem, pinning-wise. And 4-bit microprocessors used the 4-bit mode. The control signals like R/W were also available, and the register/data select was derived from an address decoder, so that the LCD became memory mapped.

Most of today's microcontrollers don't have an external databus, and access the LCD through I/O pins through which the databus and the control signals are emulated. Smaller microcontrollers often don't have I/O to spare, and for those the 4-bit mode is a good solution.
",stevenvh,https://electronics.stackexchange.com/users/2064,http://electronics.stackexchange.com/questions/38149/what-is-the-use-of-the-unused-data-pins-of-a-lcd,TECHNOLOGY,electronics.stackexchange.com,1.0,0.6666666666666666,0.3333333333333333,1.0,1.0,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.8888888888888888,0.7777777777777778,0.6666666666666666,1.0,0.8888888888888888,0.8,0.0,0.0,1.0,1.0,What is the use of unused data pins of LCD,"I've a 16 pin LCD. The whole display (16x2) can be driven just using only half of the data pins (D4 - D7) of the LCD. Other 4 data pins (D0 - D3) can be neglected.

I need to know why then the LCDs come with eight data pins. Of course, there should be some reason(achieve faster update rates etc...)

Can someone show me the reason..
(This is just for my knowledge)

Thanks!
","It has 8 data pins. The 8-bit mode is the standard mode, because the data is 8-bit: the characters are ASCII, and the DDRAM addresses are also 7 bit wide. In 8-bit mode you write them in 1 instruction, in 4-bit mode you have to split a byte in 2 nibbles, shift one of them 4 bits to the right, and perform 2 write operations.  

8-bit mode is just more simple.

edit
The 4-bit mode is often used today to save I/O pins. When the HD44780 was released microprocessors were far more common than microcontrollers. Microprocessors have data and address buses, and since most microprocessors were at least 8-bit that was not a problem, pinning-wise. And 4-bit microprocessors used the 4-bit mode. The control signals like R/W were also available, and the register/data select was derived from an address decoder, so that the LCD became memory mapped.

Most of today's microcontrollers don't have an external databus, and access the LCD through I/O pins through which the databus and the control signals are emulated. Smaller microcontrollers often don't have I/O to spare, and for those the 4-bit mode is a good solution.
"
844,844,1342,How to remove the “ .0” in Decimal format and convert 1.01 to 1 in java,"My application deals with prices, I am facing a small problem here. I will explain it clearly in steps.

Following are my inputs and OutPut should be.


  input  1.01  =  output 1 
  
  input 1.748  = output 1.75
  
  input 1.98  =output 2
  
  input 1.49 = output 1.5
  
  input 20.0 = output 2


0

I have used the following code but I can't achieve it

    double calc = 1.98;
            DecimalFormat df = new DecimalFormat(""#.##"");  
            calc = Double.valueOf(df.format(calc));
            System.out.println(String.valueOf(calc).replaceAll(""([0-9])\\.0+([^0-9]|$)"", ""$1$2""));

::&gt; output is 1.98 which should be 2

double calc = 20.0;
        DecimalFormat df = new DecimalFormat(""#.#"");  
        calc = Double.valueOf(df.format(calc));
        System.out.println(String.valueOf(calc).replaceAll(""([0-9])\\.0+([^0-9]|$)"", ""$1$2""));

 ::&gt; output is 20 this is correct for me.

double calc = 2.01;
        DecimalFormat df = new DecimalFormat(""#.##"");  
        calc = Double.valueOf(df.format(calc));
        System.out.println(String.valueOf(calc).replaceAll(""([0-9])\\.0+([^0-9]|$)"", ""$1$2""));

::&gt; output is 2.01  Which should be 2.


following code which I have tried.
",Nikhilreddy Gujjula,https://stackoverflow.com/users/1010854,"
  input 1.01 = output 1


That implies using zero or one decimal places.


  input 1.748 = output 1.75


That implies adding .05 or possibly .005 and then using two decimal places.


  input 1.98 = output 2


This output could be described by either of the rules above.


  input 1.49 = output 1.5


That implies adding .05 or possibly .005 and then using one decimal place.


  input 20.0 = output 20


That implies using zero or one decimal places.

Your examples therefore aren't all instances of the same consistent rule. The only sense I can make of it is that you are only interested in a granularity of 0.25, but that's just my guess. You need to refine your requirement before you can possibly implement it.
",EJP,https://stackoverflow.com/users/207421,http://stackoverflow.com/questions/19721584/how-to-remove-the-0-in-decimal-format-and-convert-1-01-to-1-in-java,STACKOVERFLOW,stackoverflow.com,1.0,0.5555555555555556,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.0,0.0,1.0,"How to delete "". 0"" in decimal format and convert 1.01 to 1 in Java","My application deals with prices, I am facing a small problem here. I will explain it clearly in steps.

Following are my inputs and OutPut should be.


  input  1.01  =  output 1 
  
  input 1.748  = output 1.75
  
  input 1.98  =output 2
  
  input 1.49 = output 1.5
  
  input 20.0 = output 2


0

I have used the following code but I can't achieve it

    double calc = 1.98;
            DecimalFormat df = new DecimalFormat(""#.##"");  
            calc = Double.valueOf(df.format(calc));
            System.out.println(String.valueOf(calc).replaceAll(""([0-9])\\.0+([^0-9]|$)"", ""$1$2""));

::&gt; output is 1.98 which should be 2

double calc = 20.0;
        DecimalFormat df = new DecimalFormat(""#.#"");  
        calc = Double.valueOf(df.format(calc));
        System.out.println(String.valueOf(calc).replaceAll(""([0-9])\\.0+([^0-9]|$)"", ""$1$2""));

 ::&gt; output is 20 this is correct for me.

double calc = 2.01;
        DecimalFormat df = new DecimalFormat(""#.##"");  
        calc = Double.valueOf(df.format(calc));
        System.out.println(String.valueOf(calc).replaceAll(""([0-9])\\.0+([^0-9]|$)"", ""$1$2""));

::&gt; output is 2.01  Which should be 2.


following code which I have tried.
","
  input 1.01 = output 1


That implies using zero or one decimal places.


  input 1.748 = output 1.75


That implies adding .05 or possibly .005 and then using two decimal places.


  input 1.98 = output 2


This output could be described by either of the rules above.


  input 1.49 = output 1.5


That implies adding .05 or possibly .005 and then using one decimal place.


  input 20.0 = output 20


That implies using zero or one decimal places.

Your examples therefore aren't all instances of the same consistent rule. The only sense I can make of it is that you are only interested in a granularity of 0.25, but that's just my guess. You need to refine your requirement before you can possibly implement it.
"
3009,3009,4795,SQL Server 2000 - 'Performance: Deadlock',"We had to restart our SQL Server today, we had made no changes to it.

When it came back up we immediately started getting this error from the server


  DATE/TIME:    2/27/2014 3:09:31 PM
  
  DESCRIPTION:  The SQL Server performance counter 'Number of
  Deadlocks/sec' (instance 'Database') of object 'SQLServer:Locks' is
  now above the threshold of 1.00 (the current value is 2.00).
  
  COMMENT:  (None)
  
  JOB RUN:  (None)


We ran the DBCC TRACEON (1204) command and have watched the log's but it's not reporting any deadlocks.

Any idea what could trigger this to just go off? We are getting the alert every minute yet can't find any actual deadlocks.

Edit: I should add that before this reboot we had never received this error

Edit 2: We used SQL Server Profiler as well to look for deadlocks, let it run for 5 minutes over which we received 5 error alerts and when we checked the details we had NO deadlocks found.

Edit 3: March 06/2014: Ran the query and it worked, but it reports what our other details have said that we have no locks we where still getting the error above the whole time.

Thanks again for all your help!



Edit 4: March 06/2014: I ran the query and here is a sampling of the result set, I will admit I am not exactly sure what I am looking at here, that is to say I am not sure if it shows me something that I can act on or not.



Edit 5: March 07/2014: Image below shows the Alert that generates this error all of a sudden.



Thanks
",Stephen Archbold,https://dba.stackexchange.com/users/35059,"While this counter says /sec, I believe it is a cumulative counter. If I'm right, this means you have had a TOTAL of 2 deadlocks since the service has been up.

I'm not at a machine where I can test this, but I suspect that if you simulate your own deadlock - once - you'll suddenly be getting 3.0 deadlocks ""per second"" until another deadlock occurs or you restart the service. 

There are many scripts out there that will help you force a deadlock, basically:

-- window 1

Create table dbo.x(a int); create table dbo.y(b int);

Insert dbo.x(a) select 1: insert dbo.y select 2;

Begin transaction;

Update dbo.x set a = a + 1; 

-- window 2

Begin transaction;
Update dbo.y set b = b + 1;
Update dbo.x set a = 5;

-- go back to window 1

Update dbo.y set b = 22;


Now, if the counter goes up to 3.0, you know what to do: go find that pesky alert and disable it, or keep getting the alert but become desensitized to it unless the number changes drastically.
",Aaron Bertrand,https://dba.stackexchange.com/users/1186,http://dba.stackexchange.com/questions/59843/sql-server-2000-performance-deadlock,TECHNOLOGY,dba.stackexchange.com,1.0,0.3333333333333333,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.5555555555555556,0.8888888888888888,0.8333333333333334,1.0,1.0,1.0,1.0,0.0,0.6666666666666666,0.8888888888888888,SQL Server 2000 - Performance: deadlock,"We had to restart our SQL Server today, we had made no changes to it.

When it came back up we immediately started getting this error from the server


  DATE/TIME:    2/27/2014 3:09:31 PM
  
  DESCRIPTION:  The SQL Server performance counter 'Number of
  Deadlocks/sec' (instance 'Database') of object 'SQLServer:Locks' is
  now above the threshold of 1.00 (the current value is 2.00).
  
  COMMENT:  (None)
  
  JOB RUN:  (None)


We ran the DBCC TRACEON (1204) command and have watched the log's but it's not reporting any deadlocks.

Any idea what could trigger this to just go off? We are getting the alert every minute yet can't find any actual deadlocks.

Edit: I should add that before this reboot we had never received this error

Edit 2: We used SQL Server Profiler as well to look for deadlocks, let it run for 5 minutes over which we received 5 error alerts and when we checked the details we had NO deadlocks found.

Edit 3: March 06/2014: Ran the query and it worked, but it reports what our other details have said that we have no locks we where still getting the error above the whole time.

Thanks again for all your help!



Edit 4: March 06/2014: I ran the query and here is a sampling of the result set, I will admit I am not exactly sure what I am looking at here, that is to say I am not sure if it shows me something that I can act on or not.



Edit 5: March 07/2014: Image below shows the Alert that generates this error all of a sudden.



Thanks
","While this counter says /sec, I believe it is a cumulative counter. If I'm right, this means you have had a TOTAL of 2 deadlocks since the service has been up.

I'm not at a machine where I can test this, but I suspect that if you simulate your own deadlock - once - you'll suddenly be getting 3.0 deadlocks ""per second"" until another deadlock occurs or you restart the service. 

There are many scripts out there that will help you force a deadlock, basically:

-- window 1

Create table dbo.x(a int); create table dbo.y(b int);

Insert dbo.x(a) select 1: insert dbo.y select 2;

Begin transaction;

Update dbo.x set a = a + 1; 

-- window 2

Begin transaction;
Update dbo.y set b = b + 1;
Update dbo.x set a = 5;

-- go back to window 1

Update dbo.y set b = 22;


Now, if the counter goes up to 3.0, you know what to do: go find that pesky alert and disable it, or keep getting the alert but become desensitized to it unless the number changes drastically.
"
17,17,23,Can you book hotels on a prepaid credit card worldwide?,"I tend to stay at smaller boutique hotels or local apartments when I visit a city but recently due to some credit card issues I will need to depend on prepaid Visa.  But I noticed when I try to shop online a lot of retailers don't accept prepaid credit cards so I'm thinking hotels would be even stricter.  Is there a list somewhere of countries or particular hotel chains than ban prepaid cards? If so, how does one book online or reserve a room without a card?  Do all hotels worldwide accept cash?
",verve,https://travel.stackexchange.com/users/2283,"TL;DR - Depends, on your pre-paid card, the hotel, and how you book the hotel.

There are a few different charges to consider here:


Pre-payment of the room at/shortly after booking
Holding the room on a flexible booking
Deposit at checkin
Room charge, meals, drinks, extras etc at checkout


With many OTAs and hotel websites, if you make a non flexible booking, or some kinds of flexible bookings, they will charge your card for the room rate during the booking process. With some others, they'll send your card details through to the hotel, who'll put it through their tills later. (Maybe that day, maybe during a weekly sweep). In order for this pre-payment to go through, your card will need to support offline / cardholder-not-present transactions. As long as your card advertises itself as ""suitable for online shopping"" or similar, and as long as the card issuer doesn't block travel booking, you should be fine. Speak to your card issuer to be sure.

Alternately, when reserving the room, you might opt for a flexible rate where you pay at checkout, with no pre-payment. This is typically offered on the hotel's own site, and some OTAs. They will normally ask for a credit card to ""hold"" the reservation, which would be charged in the event of a no-show, but as long as you turn up as planned the card won't be charged. These rates are normally a bit more expensive than non-flexible pre-paid ones, but this style of booking should be fine on any card.

At checkin, most hotels (but not all) will want to take some sort of deposit. Typically this covers any unpaid parts of the room rate, along with expected spend in the restaurant / bar / etc. The details taken would also be used in the event of damage. If you've pre-paid the room and don't plan to run up extras in the hotel, many hotels would let you not leave a deposit, but not all. Very small hotels may take a look at you, decide you look fine, and tell you to pay everything at checkout. Some hotels may want to take something no matter what.

For the deposit, this is normally done as a pre-authorisation. Not all pre-paid card support this, which would be a problem. Some pre-paid cards do support it, but badly, and might take a week or so to release the reserved funds, which could be a problem. Check with your card issuer about this. Alternately, many hotels which require a deposit will be willing to take a cash deposit, but they may well want a larger cash deposit than they'd normally authorise on a credit card. (They can't charge extras to the card later for example). Expect to leave a hefty chunk of cash as a deposit, expect checkin to take a while, expect several people to count the money, bills may be checked for counterfeits, and expect a receipt at the end. Speak with the hotel first to see if they need a deposit, and if they take cash ones. As a datapoint, I once got stuck in a checkin queue behind someone doing a cash deposit, he was asked to leave something like 4 nights room rate as a deposit on a 2 night stay.

Finally, we have settling up the bill at the end. If you pre-paid, and didn't eat there, you could well find there's nothing to pay, or just a few dollars / pounds / euros in city taxes. Alternately, if you didn't pre pay (or they didn't take it), ate in the restaurant lots etc, you could have a decent amount to pay here. You'll be present, so any card which supports in-person transactions will be fine for this. Well, as long as you have the money on it for the bill that is! If you did a cash deposit, you should get the choice between taking the bill off that and getting the remainder, or getting the whole deposit back in cash and paying on a card.

Oh, one more possibility - charges not noticed at checkout. Maybe you forgot to tell them about the minibar charges, maybe that morning's breakfast didn't go through, something like that. If you used a credit card for the deposit, expect them to charge it to that later when they notice. If you paid cash, expect to get a bill in the mail some time later.

Can it be done - sure! Can it be done at one specific hotel with one particular kind of pre-paid card on one specific rate booked one specific way? Depends...
",Gagravarr,https://travel.stackexchange.com/users/26,http://travel.stackexchange.com/questions/35395/can-you-book-hotels-on-a-prepaid-credit-card-worldwide,CULTURE,travel.stackexchange.com,0.7777777777777778,0.7777777777777778,0.0,1.0,0.6666666666666666,0.5,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.3333333333333333,0.0,0.8888888888888888,1.0,0.7777777777777778,1.0,0.8888888888888888,0.9333333333333332,0.0,0.0,1.0,0.8888888888888888,Can you book hotels around the world by prepaid credit card?,"When I visit a city, I tend to stay in smaller boutique hotels or local apartments, but recently due to some credit card problems, I need to rely on a prepaid Visa. But I've noticed that when I try to shop online, many retailers don't accept prepaid credit cards, so I think hotels will be more strict. In addition to banning prepaid cards, is there a list of other countries or specific chains of hotels? If so, how can I book a room online or without a card? Do hotels around the world receive cash?","TL;DR - Depends, on your pre-paid card, the hotel, and how you book the hotel.

There are a few different charges to consider here:


Pre-payment of the room at/shortly after booking
Holding the room on a flexible booking
Deposit at checkin
Room charge, meals, drinks, extras etc at checkout


With many OTAs and hotel websites, if you make a non flexible booking, or some kinds of flexible bookings, they will charge your card for the room rate during the booking process. With some others, they'll send your card details through to the hotel, who'll put it through their tills later. (Maybe that day, maybe during a weekly sweep). In order for this pre-payment to go through, your card will need to support offline / cardholder-not-present transactions. As long as your card advertises itself as ""suitable for online shopping"" or similar, and as long as the card issuer doesn't block travel booking, you should be fine. Speak to your card issuer to be sure.

Alternately, when reserving the room, you might opt for a flexible rate where you pay at checkout, with no pre-payment. This is typically offered on the hotel's own site, and some OTAs. They will normally ask for a credit card to ""hold"" the reservation, which would be charged in the event of a no-show, but as long as you turn up as planned the card won't be charged. These rates are normally a bit more expensive than non-flexible pre-paid ones, but this style of booking should be fine on any card.

At checkin, most hotels (but not all) will want to take some sort of deposit. Typically this covers any unpaid parts of the room rate, along with expected spend in the restaurant / bar / etc. The details taken would also be used in the event of damage. If you've pre-paid the room and don't plan to run up extras in the hotel, many hotels would let you not leave a deposit, but not all. Very small hotels may take a look at you, decide you look fine, and tell you to pay everything at checkout. Some hotels may want to take something no matter what.

For the deposit, this is normally done as a pre-authorisation. Not all pre-paid card support this, which would be a problem. Some pre-paid cards do support it, but badly, and might take a week or so to release the reserved funds, which could be a problem. Check with your card issuer about this. Alternately, many hotels which require a deposit will be willing to take a cash deposit, but they may well want a larger cash deposit than they'd normally authorise on a credit card. (They can't charge extras to the card later for example). Expect to leave a hefty chunk of cash as a deposit, expect checkin to take a while, expect several people to count the money, bills may be checked for counterfeits, and expect a receipt at the end. Speak with the hotel first to see if they need a deposit, and if they take cash ones. As a datapoint, I once got stuck in a checkin queue behind someone doing a cash deposit, he was asked to leave something like 4 nights room rate as a deposit on a 2 night stay.

Finally, we have settling up the bill at the end. If you pre-paid, and didn't eat there, you could well find there's nothing to pay, or just a few dollars / pounds / euros in city taxes. Alternately, if you didn't pre pay (or they didn't take it), ate in the restaurant lots etc, you could have a decent amount to pay here. You'll be present, so any card which supports in-person transactions will be fine for this. Well, as long as you have the money on it for the bill that is! If you did a cash deposit, you should get the choice between taking the bill off that and getting the remainder, or getting the whole deposit back in cash and paying on a card.

Oh, one more possibility - charges not noticed at checkout. Maybe you forgot to tell them about the minibar charges, maybe that morning's breakfast didn't go through, something like that. If you used a credit card for the deposit, expect them to charge it to that later when they notice. If you paid cash, expect to get a bill in the mail some time later.

Can it be done - sure! Can it be done at one specific hotel with one particular kind of pre-paid card on one specific rate booked one specific way? Depends...
"
465,465,721,Is a Photoshop EPS file a vector format?,"If I save my file from Photoshop as a Photoshop EPS is that going to be okay as a vector across the board (ie will it be resizeable in whatever it's opened in)? I know if you open a .psd in Photoshop and resize the image, it holds it's quality, so that's fine, but when people need an EPS file because they might want to print it on the side of a building one day (or whatever) is a Photoshop EPS going to be okay? Or is there something else I need to be doing? 

All my designs are always vectors within Photoshop, so text/shapes/designs done with the pen tool - I just need to know that they'll still be a vector for people who don't have Photoshop and can't open it in there to resize it.
",Willow,https://graphicdesign.stackexchange.com/users/3494,"It can be. It may also not be. And EPS file is really just a wrapper around whatever the image is itself. So an EPS an include raster images, vector images, or both. 

When places ask for 'EPS' files they often are asking for vector files, of which an EPS may or may not be.
",DA01,https://graphicdesign.stackexchange.com/users/306,http://graphicdesign.stackexchange.com/questions/7726/is-a-photoshop-eps-file-a-vector-format,LIFE_ARTS,graphicdesign.stackexchange.com,1.0,0.8888888888888888,0.0,0.6666666666666666,1.0,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.6666666666666666,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.0,1.0,1.0,0.5555555555555556,1.0,1.0,0.7333333333333333,0.0,0.0,1.0,1.0,Is Photoshop EPS file in vector format?,"If I save the files in Photoshop as Photoshop's EPS, then, as a vector, can it be resized in all open files? I know if you open a. PSD in Photoshop and resize the image, it will keep the quality of the image, so that's good, but when people need an EPS file, because they may want to print it one day on one side of the building (or somewhere else), will Photoshop EPS be good? Or do I have anything else to do?","It can be. It may also not be. And EPS file is really just a wrapper around whatever the image is itself. So an EPS an include raster images, vector images, or both. 

When places ask for 'EPS' files they often are asking for vector files, of which an EPS may or may not be.
"
3881,3881,6183,Can you match a Windows XP product key to a service pack release?,"I have a Windows XP product key on my PC, but I'm not sure which release of Windows XP it belongs to SP1, SP2, or SP3.

Is there a way I can tell without trying each one?

Note: 
In this case, I have an old PC which had an OEM XP Pro license. I don't have the media for it any more. However, I do have a media for XP Pro (off the shelf non-OEM). 

The Product Key on the case doesn't want to validate. So I'm presuming that there is something encoded in it as to the release it works with. I can get media, I just don't want to try each one.
",BIBD,https://superuser.com/users/815,"
For activating you dont need to know which service pack you are using 
If you just bought a new computer then chances are you  have SP3
To find out which Service pack you have already installed  (source from http://pcsupport.about.com/od/tipstricks/ht/servicepackxp.htm)



  1) Click on Start and then Control
  Panel.
  
  2) Click on the Performance and
  Maintenance link.
  
  Note: If you're viewing the Classic
  View of Control Panel, you won't see
  this link. Simply double-click on the
  System icon and proceed to Step 4.
  
  3) In the Performance and Maintenance
  window, click on the System Control
  Panel icon at the bottom of the
  window.
  
  4) When the System Properties window
  opens it should default to the General
  tab. If not, choose it manually.
  
  5) In the System: area of the General
  tab you'll find the operating system
  version and the service pack level.
  See the screen shot on this page for
  an idea of what you're looking for.



An Easier way would be



  1) Right click on My Computer
  
  2) Select Properties
  
  3) Under General Tab look for your service pack version

",subanki,https://superuser.com/users/46669,http://superuser.com/questions/186405,TECHNOLOGY,superuser.com,0.7777777777777778,0.8888888888888888,0.0,1.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.4444444444444444,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,0.8888888888888888,0.9333333333333332,1.0,0.0,0.0,0.8888888888888888,Can you match the Windows XP product key to the service pack version?,"I have a Windows XP product key on my PC, but I'm not sure which release of Windows XP it belongs to SP1, SP2, or SP3.

Is there a way I can tell without trying each one?

Note: 
In this case, I have an old PC which had an OEM XP Pro license. I don't have the media for it any more. However, I do have a media for XP Pro (off the shelf non-OEM). 

The Product Key on the case doesn't want to validate. So I'm presuming that there is something encoded in it as to the release it works with. I can get media, I just don't want to try each one.
","
For activating you dont need to know which service pack you are using 
If you just bought a new computer then chances are you  have SP3
To find out which Service pack you have already installed  (source from http://pcsupport.about.com/od/tipstricks/ht/servicepackxp.htm)



  1) Click on Start and then Control
  Panel.
  
  2) Click on the Performance and
  Maintenance link.
  
  Note: If you're viewing the Classic
  View of Control Panel, you won't see
  this link. Simply double-click on the
  System icon and proceed to Step 4.
  
  3) In the Performance and Maintenance
  window, click on the System Control
  Panel icon at the bottom of the
  window.
  
  4) When the System Properties window
  opens it should default to the General
  tab. If not, choose it manually.
  
  5) In the System: area of the General
  tab you'll find the operating system
  version and the service pack level.
  See the screen shot on this page for
  an idea of what you're looking for.



An Easier way would be



  1) Right click on My Computer
  
  2) Select Properties
  
  3) Under General Tab look for your service pack version

"
513,513,807,What should a DM do if a player wants to do something impossible?,"If a player wants to do something a little out of the ordinary such as punching down a wall with his bare fists, what should I do? Do I make a DC for it? Do I make it so that no matter how much he rolls, he won't destroy the wall? Should I simply tell him that it won't work?
",Luke Burgin,https://rpg.stackexchange.com/users/5914,"For things that are physically impossible, don't bother with dice. As DM, dice are for when the group needs to determine whether something happens that's probable but neither impossible nor guaranteed. For impossible things, you're allowed to just say so:


  Player: I fly to the moon!
  
  DM: …You can't. You don't have wings, a ship, a Instant Moon Travel power, or anything like that.
  
  Player: Can't I just roll against a really high DC?
  
  DM: No.


Perfectly acceptable.

When there isn't a rule allowing something to happen, it's the DM's prerogative to judge whether something is possible, and how difficult it is. Things that are very easy like ""I walk up the stairs"" don't need rolls for you to say ""OK"" to — neither do impossible things need rolls for you to say ""No"" to.

Nota bene, for truly ""out of the ordinary"" but not impossible things there is Difficulty Class and Damage by Level (DMG, p. 42), which gives you a framework for assigning DCs to tasks that aren't otherwise covered by another rule in the game. Punching down a whole masonry wall with bare fists shouldn't ever need a DC (because it's just not happening), but punching a hole in a wall while accidentally turned into a golem might call for a high DC, and that's where to find it.
",SevenSidedDie,https://rpg.stackexchange.com/users/321,http://rpg.stackexchange.com/questions/19285/what-should-a-dm-do-if-a-player-wants-to-do-something-impossible,CULTURE,rpg.stackexchange.com,0.7777777777777778,0.8888888888888888,0.0,0.6666666666666666,0.0,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.6666666666666666,0.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,1.0,0.3333333333333333,1.0,"If a player wants to do something impossible, what should he do?","What should I do if a player wants to do something unusual, such as knocking down a wall with his bare hands? Do I want to be a DC? Can I do this so that no matter how many laps he rolls, he will not destroy the wall? Should I simply tell him it doesn't work?","For things that are physically impossible, don't bother with dice. As DM, dice are for when the group needs to determine whether something happens that's probable but neither impossible nor guaranteed. For impossible things, you're allowed to just say so:


  Player: I fly to the moon!
  
  DM: …You can't. You don't have wings, a ship, a Instant Moon Travel power, or anything like that.
  
  Player: Can't I just roll against a really high DC?
  
  DM: No.


Perfectly acceptable.

When there isn't a rule allowing something to happen, it's the DM's prerogative to judge whether something is possible, and how difficult it is. Things that are very easy like ""I walk up the stairs"" don't need rolls for you to say ""OK"" to — neither do impossible things need rolls for you to say ""No"" to.

Nota bene, for truly ""out of the ordinary"" but not impossible things there is Difficulty Class and Damage by Level (DMG, p. 42), which gives you a framework for assigning DCs to tasks that aren't otherwise covered by another rule in the game. Punching down a whole masonry wall with bare fists shouldn't ever need a DC (because it's just not happening), but punching a hole in a wall while accidentally turned into a golem might call for a high DC, and that's where to find it.
"
5666,5666,8983,Current passing through me from Macbook to iMac?,"I recently bought a UPS for my iMac and it runs just fine.

However, sometimes I also run a MacBook Pro nearby and when I have my hand in contact with the MacBook and reach across to touch the aluminium keyboard attached to my iMac I can feel electricity running through my finger!

It doesn't happen when the MacBook is running on battery power, only when it's connected to the mains. It also doesn't happen when the UPS isn't connected.

The MacBook Pro is plugged into a standard wall outlet, the iMac is plugged into a UPS and that's in a similar wall outlet (not the same one).

I'm not very electrically minded, so am puzzled as I'd like to plug the MacBook into the mains again! Does anyone have any ideas as to why it's happening and how I can fix the problem?
",FiddleMeRagged,https://apple.stackexchange.com/users/17333,"Usually, ground loop current is experienced on portables where often no ground wire is connected - just the neutral and live (or hot) wires. 



If you are using a grounded plug and feel ground loop current you should either have the outlet serviced or the computer serviced.

It's normal (and safe) for ground loop current to exist and feel lightly tingly on Macs with magsafe connectors and only DC power going in to them. It's harder to be sure an iMac or other device that has 110/220 AC power directly into the case, so I would rather be too cautious and have you get an electrician to look at the outlet if your Mac works properly on other outlets or a technician to look at the Mac if it leaks current no matter which receptacle you plug it in to.

You might be able to find a grounding issue and solve this yourself, but if you have any doubts as to safety, I'd rather you chose to get expert help rather than trust our guesses based on how things should work.

See:


Is grounding important?
Electricity coming through screws, USB, and headphone jack on 2009 MacBook
How can I avoid my MacBook Pro giving me minor shocks?
Is it bad that my MacBook Air is passing me electricity?


And note that all the MacBook questions are low risk situations where any iMac one would be a little more danger (potentially).
",bmike,https://apple.stackexchange.com/users/5472,http://apple.stackexchange.com/questions/97531/current-passing-through-me-from-macbook-to-imac,TECHNOLOGY,apple.stackexchange.com,1.0,0.4444444444444444,0.0,0.3333333333333333,1.0,1.0,0.6666666666666666,0.7777777777777778,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.0,1.0,1.0,Current from MacBook to IMAC?,"I recently bought a UPS for my iMac and it runs just fine.

However, sometimes I also run a MacBook Pro nearby and when I have my hand in contact with the MacBook and reach across to touch the aluminium keyboard attached to my iMac I can feel electricity running through my finger!

It doesn't happen when the MacBook is running on battery power, only when it's connected to the mains. It also doesn't happen when the UPS isn't connected.

The MacBook Pro is plugged into a standard wall outlet, the iMac is plugged into a UPS and that's in a similar wall outlet (not the same one).

I'm not very electrically minded, so am puzzled as I'd like to plug the MacBook into the mains again! Does anyone have any ideas as to why it's happening and how I can fix the problem?
","Usually, ground loop current is experienced on portables where often no ground wire is connected - just the neutral and live (or hot) wires. 



If you are using a grounded plug and feel ground loop current you should either have the outlet serviced or the computer serviced.

It's normal (and safe) for ground loop current to exist and feel lightly tingly on Macs with magsafe connectors and only DC power going in to them. It's harder to be sure an iMac or other device that has 110/220 AC power directly into the case, so I would rather be too cautious and have you get an electrician to look at the outlet if your Mac works properly on other outlets or a technician to look at the Mac if it leaks current no matter which receptacle you plug it in to.

You might be able to find a grounding issue and solve this yourself, but if you have any doubts as to safety, I'd rather you chose to get expert help rather than trust our guesses based on how things should work.

See:


Is grounding important?
Electricity coming through screws, USB, and headphone jack on 2009 MacBook
How can I avoid my MacBook Pro giving me minor shocks?
Is it bad that my MacBook Air is passing me electricity?


And note that all the MacBook questions are low risk situations where any iMac one would be a little more danger (potentially).
"
3574,3574,5711,pdfpages breaks display of small caps,"I try to create proceedings with a uniform title page for individual pdfs that I get from the authors. I use pdfpages for this. The individual pdfs are included and I add title information (not shown in the example below). I have one paper that looks fine, but when I include it, the result does not contain the small caps letters in the attribute value matrices (see figures on page 7 and 8).

\documentclass{article}
\usepackage{pdfpages}
\usepackage[utf8]{inputenc}
        \usepackage{hyperref}
        \setcounter{page}{335}
        \begin{document}
\includepdf[pages=-,pagecommand=\thispagestyle{plain}]{Includes/yatabe.pdf}
        \end{document}


This is the paper: yatabe.pdf 

What I get from including is yatabe-broken.pdf
",Stefan Müller,https://tex.stackexchange.com/users/18561,"use in the preamble:

\pdfinclusioncopyfonts=1


otherwise the SmallCaps font is not included. From the pdftex manual:


  \pdfinclusioncopyfonts (integer)
  
  If positive, this parameter forces pdfTEX to include fonts from a pdf
  file loaded with \pdfximage, even if those fonts are available on
  disk. Bigger files might be created, but included pdf files are sure
  to be embedded with the adequate fonts; indeed, the fonts on disk
  might be different from the embedded ones, and glyphs might be
  missing.

",Herbert,https://tex.stackexchange.com/users/2478,http://tex.stackexchange.com/questions/140380/pdfpages-breaks-display-of-small-caps,TECHNOLOGY,tex.stackexchange.com,0.8888888888888888,0.4444444444444444,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.3333333333333333,0.7777777777777778,Pdfpages interrupt display small caps,"I try to create proceedings with a uniform title page for individual pdfs that I get from the authors. I use pdfpages for this. The individual pdfs are included and I add title information (not shown in the example below). I have one paper that looks fine, but when I include it, the result does not contain the small caps letters in the attribute value matrices (see figures on page 7 and 8).

\documentclass{article}
\usepackage{pdfpages}
\usepackage[utf8]{inputenc}
        \usepackage{hyperref}
        \setcounter{page}{335}
        \begin{document}
\includepdf[pages=-,pagecommand=\thispagestyle{plain}]{Includes/yatabe.pdf}
        \end{document}


This is the paper: yatabe.pdf 

What I get from including is yatabe-broken.pdf
","use in the preamble:

\pdfinclusioncopyfonts=1


otherwise the SmallCaps font is not included. From the pdftex manual:


  \pdfinclusioncopyfonts (integer)
  
  If positive, this parameter forces pdfTEX to include fonts from a pdf
  file loaded with \pdfximage, even if those fonts are available on
  disk. Bigger files might be created, but included pdf files are sure
  to be embedded with the adequate fonts; indeed, the fonts on disk
  might be different from the embedded ones, and glyphs might be
  missing.

"
2,2,2,Maximum protusion length for through-hole component pins,"I'm working on a PCB that has through-hole components on both sides of the board. The ""top"" side of the board is mounted flush to a Delrin plastic block (the only top-side component is a gas sensor that is fed air samples through hose fittings in the plastic block).

The flush mounting means that I have to add grooves to the plastic block to accommodate the soldered pins of the bottom-side components. Assuming a standard 0.062"" thickness FR4 board, how deep do I need to make the grooves in the plastic block? The only thing I could find is this NASA workmanship standard that states 0.5mm to 2.29mm, but I'm not sure if that will always hold true.
",Joe Baker,https://electronics.stackexchange.com/users/10157,"Do you even need grooves?  We make several products using through-hole components that are intended to mount using VHB double-sided foam tape.  The boards are 0.062"" thick double-sided with PTH and we use a table-top vertical belt sander to bring the component leads almost flush with the solder mask.  In other words, the solder mask isn't touched by the sand paper but the leads are all sanded flat and sitting just proud of the solder mask.

This works well for small boards.

For what it's worth, there are commercial machines available that use a rotary saw blade to do the same thing.  The board is held horizontal in a mounting / clamping system on the base and the saw motor is vertical on a sliding X-Y mechanism.  The saw blade simply cuts all of the leads almost flush with the board surface.  

This system is suited for boards of all sizes but especially for those boards larger than can be handled easily to be sanded with the belt sander.

Also note that these techniques are suitable only for PC boards with plated-through holes.  
",Dwayne Reid,https://electronics.stackexchange.com/users/64754,http://electronics.stackexchange.com/questions/154225/maximum-protusion-length-for-through-hole-component-pins,SCIENCE,electronics.stackexchange.com,0.8888888888888888,0.6666666666666666,0.0,1.0,1.0,1.0,0.6666666666666666,0.4444444444444444,0.3333333333333333,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.7777777777777778,0.7777777777777778,0.5555555555555556,1.0,1.0,0.6666666666666667,0.0,0.3333333333333333,1.0,0.8888888888888888,Maximum extended length of through hole assembly pin,"I'm working on a PCB that has through-hole components on both sides of the board. The ""top"" side of the board is mounted flush to a Delrin plastic block (the only top-side component is a gas sensor that is fed air samples through hose fittings in the plastic block).

The flush mounting means that I have to add grooves to the plastic block to accommodate the soldered pins of the bottom-side components. Assuming a standard 0.062"" thickness FR4 board, how deep do I need to make the grooves in the plastic block? The only thing I could find is this NASA workmanship standard that states 0.5mm to 2.29mm, but I'm not sure if that will always hold true.
","Do you even need grooves?  We make several products using through-hole components that are intended to mount using VHB double-sided foam tape.  The boards are 0.062"" thick double-sided with PTH and we use a table-top vertical belt sander to bring the component leads almost flush with the solder mask.  In other words, the solder mask isn't touched by the sand paper but the leads are all sanded flat and sitting just proud of the solder mask.

This works well for small boards.

For what it's worth, there are commercial machines available that use a rotary saw blade to do the same thing.  The board is held horizontal in a mounting / clamping system on the base and the saw motor is vertical on a sliding X-Y mechanism.  The saw blade simply cuts all of the leads almost flush with the board surface.  

This system is suited for boards of all sizes but especially for those boards larger than can be handled easily to be sanded with the belt sander.

Also note that these techniques are suitable only for PC boards with plated-through holes.  
"
3515,3515,5605,awk - Group by and sum column values,"I have command to list system process by memory usage:

ps -A --sort -rss -o comm,pmem


Which list a table like

COMMAND         %MEM
firefox         28.2
chrome           5.4
compiz           4.8
atom             2.5
chrome           2.3
Xorg             2.3
skype            2.2
chrome           2.0
chrome           1.9
atom             1.9
nautilus         1.8
hud-service      1.5
evince           1.3


I would like to get total memory share per programs instead of per process of same programs. So I could get output like

COMMAND         %MEM
firefox         28.2
chrome          11.6
compiz           4.8
atom             4.4
Xorg             2.3
skype            2.2
nautilus         1.8
hud-service      1.5
evince           1.3


I thought about using awk, which I don't know much. Ended up with something like:

ps -A --sort -rss -o comm,pmem | awk -F ""\t"" '
{processes[$0] += $1;}
{End
for(i in processes) {
  print i,""\t"",processes[i];
}
}'


But it didn't work.

How can I correct this?
",Junaid,https://unix.stackexchange.com/users/15519,"processes[$0] += $1; use the whole line as key in your associative array, which is not unique. You must use $1, which is command name as key.

Try:

$ ps -A --sort -rss -o comm,pmem | awk '
  NR == 1 { print; next }
  { a[$1] += $2 }
  END {
    for (i in a) {
      printf ""%-15s\t%s\n"", i, a[i];
    }
  }
'


If you want to sort the output by the second field, try:

$ ps -A --sort -rss -o comm,pmem | awk '
  NR == 1 { print; next }
  { a[$1] += $2 }
  END {
    for (i in a) {
      printf ""%-15s\t%s\n"", i, a[i] | ""sort -rnk2"";
    }
  }
'

",cuonglm,https://unix.stackexchange.com/users/38906,http://unix.stackexchange.com/questions/167280/awk-group-by-and-sum-column-values,TECHNOLOGY,unix.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.3333333333333333,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,1.0,Awk group and sum by column value,"I have command to list system process by memory usage:

ps -A --sort -rss -o comm,pmem


Which list a table like

COMMAND         %MEM
firefox         28.2
chrome           5.4
compiz           4.8
atom             2.5
chrome           2.3
Xorg             2.3
skype            2.2
chrome           2.0
chrome           1.9
atom             1.9
nautilus         1.8
hud-service      1.5
evince           1.3


I would like to get total memory share per programs instead of per process of same programs. So I could get output like

COMMAND         %MEM
firefox         28.2
chrome          11.6
compiz           4.8
atom             4.4
Xorg             2.3
skype            2.2
nautilus         1.8
hud-service      1.5
evince           1.3


I thought about using awk, which I don't know much. Ended up with something like:

ps -A --sort -rss -o comm,pmem | awk -F ""\t"" '
{processes[$0] += $1;}
{End
for(i in processes) {
  print i,""\t"",processes[i];
}
}'


But it didn't work.

How can I correct this?
","processes[$0] += $1; use the whole line as key in your associative array, which is not unique. You must use $1, which is command name as key.

Try:

$ ps -A --sort -rss -o comm,pmem | awk '
  NR == 1 { print; next }
  { a[$1] += $2 }
  END {
    for (i in a) {
      printf ""%-15s\t%s\n"", i, a[i];
    }
  }
'


If you want to sort the output by the second field, try:

$ ps -A --sort -rss -o comm,pmem | awk '
  NR == 1 { print; next }
  { a[$1] += $2 }
  END {
    for (i in a) {
      printf ""%-15s\t%s\n"", i, a[i] | ""sort -rnk2"";
    }
  }
'

"
5967,5967,9458,Get current Activity with Android,"I have a method that scans the position and gets called on every activity I have, everytime an actions trigger I need to show an alertDialog, this is the code:

AlertDialog.Builder builder = new AlertDialog.Builder(mMainActivity.this);
                        builder.setMessage(""test"")
                           .setCancelable(false)
                           .setPositiveButton(""go"", new DialogInterface.OnClickListener() {
                               public void onClick(DialogInterface dialog, int id) {
                                   Intent intent = new Intent(mMainActivity.this,LocationDetails.class);
                                    intent.putExtra(""placeId"",1);
                                    startActivity(intent);

                               }
                           })
                           .setNegativeButton(""cancel"", new DialogInterface.OnClickListener() {
                               public void onClick(DialogInterface dialog, int id) {

                                    dialog.cancel();
                               }
                           });
                        AlertDialog alert = builder.create();
                        alert.show();


But How can I create the alert on the current activity? Because now it only gets created on AlertDialog.Builder(mMainActivity.this);
",Signo,https://stackoverflow.com/users/3789527,"You have various options... what you have to know:


  You can show AlertDialogs from Activity only


You have various options 


Pass your activity instance as parameter in constructor of other classes... then you can call activity from everywhere
Use notifications (class does not need to be an Activity)
Check this question. otherwise

",Jordi Castilla,https://stackoverflow.com/users/3850595,http://stackoverflow.com/questions/30511271/get-current-activity-with-android,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.5555555555555556,0.0,0.5,1.0,1.0,0.6666666666666666,0.4444444444444444,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.7777777777777778,0.7777777777777778,0.6666666666666666,0.8888888888888888,0.7777777777777778,0.7333333333333333,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.7777777777777778,Get current activity using Android,"I have a method that scans the position and gets called on every activity I have, everytime an actions trigger I need to show an alertDialog, this is the code:

AlertDialog.Builder builder = new AlertDialog.Builder(mMainActivity.this);
                        builder.setMessage(""test"")
                           .setCancelable(false)
                           .setPositiveButton(""go"", new DialogInterface.OnClickListener() {
                               public void onClick(DialogInterface dialog, int id) {
                                   Intent intent = new Intent(mMainActivity.this,LocationDetails.class);
                                    intent.putExtra(""placeId"",1);
                                    startActivity(intent);

                               }
                           })
                           .setNegativeButton(""cancel"", new DialogInterface.OnClickListener() {
                               public void onClick(DialogInterface dialog, int id) {

                                    dialog.cancel();
                               }
                           });
                        AlertDialog alert = builder.create();
                        alert.show();


But How can I create the alert on the current activity? Because now it only gets created on AlertDialog.Builder(mMainActivity.this);
","You have various options... what you have to know:


  You can show AlertDialogs from Activity only


You have various options 


Pass your activity instance as parameter in constructor of other classes... then you can call activity from everywhere
Use notifications (class does not need to be an Activity)
Check this question. otherwise

"
3512,3512,5601,Using pstool with beamer,"I would like to use pstool with beamer to create a presentation in pdflatex with figures processed by psfrag. However, as the simple example below shows, the figures are processed using the beamer documentclass, so that they each have a full beamer ""frame"" around them. Is there a way around this?

\documentclass{beamer}

\usepackage{lmodern}
\usepackage{graphicx}
\usepackage[process=all,crop=pdfcrop]{pstool}

\begin{document}
\begin{frame}
    \frametitle{Circle}
    \begin{figure}
        \psfragfig[width=0.3\textwidth]{figures/circle}
        {
            \psfrag{1}{\(s\)}
        }
    \end{figure}
\end{frame}
\end{document}




I suspect that if it's possible to override the documentclass used by pstool to process the figures, that would be a solution, but I haven't found how to do this.

Thanks.
",mjr,https://tex.stackexchange.com/users/5238,"pstool package uses the preamble of main document class(in your Q it is beamer) to build the pdf figures during the underhood auxiliary processing (latex-dvips-ps2pdf) of  .eps figure and psfrag commands. So to get a circle.pdf figure without navigation bar add 

\setbeamertemplate{navigation symbols}{} 


in the preamble after \documentclass{beamer}as shown in
How to get rid of navigation symbols in beamer? and compile with pdflatex -shell-escape gives



Once you have all pdf figures are generated via auxiliary processing.  Set the option process=none instead of process=all and comment out the only line  like this 
%\setbeamertemplate{navigation symbols}{} to process beamer slides with figures (navigation bar less) and finally you will get navigation bar on main beamer slides.

Note: \EndPreamble can be used to limit the preamble used for auxiliary processing and thereby speed it up. More details refer pstool documentation
",texenthusiast,https://tex.stackexchange.com/users/15717,http://tex.stackexchange.com/questions/167489/using-pstool-with-beamer,TECHNOLOGY,tex.stackexchange.com,1.0,0.4444444444444444,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.3333333333333333,0.3333333333333333,1.0,Using pstool and beamer,"I would like to use pstool with beamer to create a presentation in pdflatex with figures processed by psfrag. However, as the simple example below shows, the figures are processed using the beamer documentclass, so that they each have a full beamer ""frame"" around them. Is there a way around this?

\documentclass{beamer}

\usepackage{lmodern}
\usepackage{graphicx}
\usepackage[process=all,crop=pdfcrop]{pstool}

\begin{document}
\begin{frame}
    \frametitle{Circle}
    \begin{figure}
        \psfragfig[width=0.3\textwidth]{figures/circle}
        {
            \psfrag{1}{\(s\)}
        }
    \end{figure}
\end{frame}
\end{document}




I suspect that if it's possible to override the documentclass used by pstool to process the figures, that would be a solution, but I haven't found how to do this.

Thanks.
","pstool package uses the preamble of main document class(in your Q it is beamer) to build the pdf figures during the underhood auxiliary processing (latex-dvips-ps2pdf) of  .eps figure and psfrag commands. So to get a circle.pdf figure without navigation bar add 

\setbeamertemplate{navigation symbols}{} 


in the preamble after \documentclass{beamer}as shown in
How to get rid of navigation symbols in beamer? and compile with pdflatex -shell-escape gives



Once you have all pdf figures are generated via auxiliary processing.  Set the option process=none instead of process=all and comment out the only line  like this 
%\setbeamertemplate{navigation symbols}{} to process beamer slides with figures (navigation bar less) and finally you will get navigation bar on main beamer slides.

Note: \EndPreamble can be used to limit the preamble used for auxiliary processing and thereby speed it up. More details refer pstool documentation
"
4138,4138,6602,"""Become acquainted"", ""be connected"" with the connotation of ""take the initiative""","Would the following sentence be idiomatic and correct?


  At the conference, she became acquainted with more than 20 scholars,
  exhibiting excellent networking skills.


I was thinking saying something like ""connected to more than X scholars"".  I'm just not sure which expression better conveys the meaning that she took the initiative to approach those scholars and got to know them.
",lessismore,https://english.stackexchange.com/users/32580,"Who exhibited the excellent networking skills, ‘she’ or the ‘more than 20 scholars’? Assuming the first, a clearer way of putting it might be:


  She has excellent networking skills. This was apparent in the way in
  which she became acquainted with more than 20 scholars at the
  conference.


Possible alternatives to became acquainted with are made contact with, exchanged contact details with, or simply met. 
",Barrie England,https://english.stackexchange.com/users/12952,http://english.stackexchange.com/questions/95039/become-acquainted-be-connected-with-the-connotation-of-take-the-initiative,CULTURE,english.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,1.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.7777777777777778,0.6666666666666666,0.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.4444444444444444,1.0,1.0,0.8,0.0,0.0,0.0,1.0,"The connotation of ""acquaintance"", ""communication"" and ""initiative""","Would the following sentence be idiomatic and correct?


  At the conference, she became acquainted with more than 20 scholars,
  exhibiting excellent networking skills.


I was thinking saying something like ""connected to more than X scholars"".  I'm just not sure which expression better conveys the meaning that she took the initiative to approach those scholars and got to know them.
","Who exhibited the excellent networking skills, ‘she’ or the ‘more than 20 scholars’? Assuming the first, a clearer way of putting it might be:


  She has excellent networking skills. This was apparent in the way in
  which she became acquainted with more than 20 scholars at the
  conference.


Possible alternatives to became acquainted with are made contact with, exchanged contact details with, or simply met. 
"
232,232,369,Where can I find the duration of a bus trip on Gran Canaria?,"On 21 December, I will travel by bus from Aeropuerto Gran Canaria via Las Palmas de Gran Canaria to Agaete/Puerto de Las Nieves. I found timetables for buses on Gran Canaria and I found out I need to take line 60 from the airport to Las Palmas and then line 103 from Las Palmas to Agaete. However, I can't find anywhere how long the bus ride takes. Since I'm going to take a ferry, it is important to know the arrival time at the bus stop closest to the ferry terminal at Agaete.

Where can I find more precise timetables for buses on Gran Canaria? Google Transit doesn't know. Is there any other search engine I may use to find arrival times, or, equivalently, the duration of the bus ride?
",gerrit,https://travel.stackexchange.com/users/2509,"One option appears to be a shuttle, if you would consider that.

It  runs from the airport to Agaete, and appears to take 1 hour and 20 minutes.  

At the very least, that should help give you an idea of the time it takes.
",Mark Mayo,https://travel.stackexchange.com/users/101,http://travel.stackexchange.com/questions/11084/where-can-i-find-the-duration-of-a-bus-trip-on-gran-canaria,CULTURE,travel.stackexchange.com,0.6666666666666666,0.3333333333333333,0.0,1.0,1.0,0.0,0.6666666666666666,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.6,0.0,0.6666666666666666,0.0,0.8888888888888888,Where can I find bus travel time in Grand Canaria?,"On December 21, I will take the bus from the Canary air port, via Las Palmas de Gran Canary, to the port of argate / LAS Neves. I found the bus schedule in grancanary, and I found that I needed to take line 60 from the airport to Las Palmas, then line 103 from Las Palmas to argate. But I can't find anywhere how long it will take by bus. Because I'm going to take a ferry, it's important to know the arrival time of the nearest bus stop to the argate ferry terminal.","One option appears to be a shuttle, if you would consider that.

It  runs from the airport to Agaete, and appears to take 1 hour and 20 minutes.  

At the very least, that should help give you an idea of the time it takes.
"
742,742,1177,How can I speed up the rate at which putty dries?,"We're (slowly) renovating the sash windows in our house and the current window is causing problems. What should have been a quick job (especially at this time of year!) has turned into a marathon because the putty won't dry.

We had to replace a couple of panes of glass (one was cracked and we broke another when using a heat gun to remove the paint) so we knew it would take a little while. On a previous window the putty took over three weeks to dry enough to paint partly because (as we thought) there was too much oil. So this time we rolled the putty on newspaper first to try to remove the excess oil. It seemed to work, but after two weeks the putty is still soft to the touch.

We've tried standing the windows next to a radiator but all that seemed to do was make it softer (which was obviously going to happen in hindsight).

So given that we don't want to reputty the windows what can we do to speed up the drying process.

We've had to seal off the room and cover the window as best we can in the meantime.

I've found this advice on DoItYourself.com which doesn't really help as it says use other materials!

The answers to this post on DIY-Forums are confusing at best and possibly contradictory as one recommends exposing the putty to moisture(!) to speed the drying process.
",ChrisF,https://diy.stackexchange.com/users/194,"Heat will make the putty softer, which is why you can heat it up to remove it.  Putty pretty much stays soft for years.  Initially, it doesn't really dry out so much as oxidize which forms a skin on it. 

If you absolutely must paint it right away, you'll probably has to use one of the latex based glazing compounds. If you want to use a traditional one, paint it as soon as it forms enough of a skin that the paint will stick to it.  Also, I think you probably should be using oil based paints, but check the instructions on the putty.

If you let use know specifically which putty you are using, that might help get better answers.
",Zach,https://diy.stackexchange.com/users/1141,http://diy.stackexchange.com/questions/3022/how-can-i-speed-up-the-rate-at-which-putty-dries,LIFE_ARTS,diy.stackexchange.com,1.0,0.7777777777777778,0.0,0.0,1.0,0.0,0.5555555555555556,0.5555555555555556,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.3333333333333333,0.6666666666666666,0.3333333333333333,1.0,How can I speed up the drying of putty?,"We're (slowly) renovating the sash windows in our house and the current window is causing problems. What should have been a quick job (especially at this time of year!) has turned into a marathon because the putty won't dry.

We had to replace a couple of panes of glass (one was cracked and we broke another when using a heat gun to remove the paint) so we knew it would take a little while. On a previous window the putty took over three weeks to dry enough to paint partly because (as we thought) there was too much oil. So this time we rolled the putty on newspaper first to try to remove the excess oil. It seemed to work, but after two weeks the putty is still soft to the touch.

We've tried standing the windows next to a radiator but all that seemed to do was make it softer (which was obviously going to happen in hindsight).

So given that we don't want to reputty the windows what can we do to speed up the drying process.

We've had to seal off the room and cover the window as best we can in the meantime.

I've found this advice on DoItYourself.com which doesn't really help as it says use other materials!

The answers to this post on DIY-Forums are confusing at best and possibly contradictory as one recommends exposing the putty to moisture(!) to speed the drying process.
","Heat will make the putty softer, which is why you can heat it up to remove it.  Putty pretty much stays soft for years.  Initially, it doesn't really dry out so much as oxidize which forms a skin on it. 

If you absolutely must paint it right away, you'll probably has to use one of the latex based glazing compounds. If you want to use a traditional one, paint it as soon as it forms enough of a skin that the paint will stick to it.  Also, I think you probably should be using oil based paints, but check the instructions on the putty.

If you let use know specifically which putty you are using, that might help get better answers.
"
4075,4075,6506,What is the cardinality of the family of unlabelled bipartite graphs on n vertices?,"I have attempted to calculate the number of unlabelled bipartite graphs as follows:


  Let $G = (V_1, V_2, E)$ be a bipartite graph on $n$ vertices with $|V_1| = m$ and $|V_2| = n-m$. Assume without loss of generality that $|V_1| \leq |V_2|$ so $m \leq \left\lfloor \frac{n}{2} \right\rfloor$. If $G$ is complete bipartite then it has $m(n-m)$ edges since each of the vertices in $V_1$ is connected to each in $V_2$. Thus, the total number of bipartite graphs with parts of size $m$ and $n-m$ is $2^{m(n-m)}$. In order to find the total number of possible bipartite graphs on $n$ vertices we sum over all possible $m$:
  \begin{align}
\sum^{\left\lfloor \frac{n}{2} \right\rfloor}_{m=1} 2^{m(n-m)}
\end{align}


However, I notice that I have counted labelled bipartite graphs where I need the number of unlabelled graphs. I'm struggling to see how to account for this.
",Andrew,https://mathoverflow.net/users/31128,"It seems that what Andrew wants to count are what are called in enumerative contexts
""bicolored graphs"". A bicolored graph is a graph in which the vertices have been colored black and white so that every edge joins two vertices of different colors. A bipartite (or bicolorable) graph is a graph that has a bicoloring. A bicolorable graph with $k$ connected components has $2^k$ bicolorings. (In nonenumerative contexts the distinction between bipartite and bicolored is usually unimportant.) In addition, in counting  bicolored graphs one might or might not consider switching the two colors to give an equivalent graph. All of the versions of the enumeration problem have been solved. Counting unlabeled bicolored graphs (with no color-switching equivalence) is a straightforward application of Burnside's lemma; counting unlabeled bipartite graphs is tricky. 

It's not too hard to find appropriate references by searching MathSciNet. (Hint: ""color"" is sometimes spelled ""colour"".)

Incidentally, the number of labeled bicolored graphs on $n$ vertices is 
$$\sum_{m=0}^n 2^{m(n-m)}\binom{n}{m}.$$
",Ira Gessel,https://mathoverflow.net/users/10744,http://mathoverflow.net/questions/120674,SCIENCE,mathoverflow.net,0.6666666666666666,0.6666666666666666,0.0,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,1.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.6666666666666666,0.0,1.0,0.8888888888888888,What is the cardinality of a family of unmarked bipartite graphs on n vertices?,"I have attempted to calculate the number of unlabelled bipartite graphs as follows:


  Let $G = (V_1, V_2, E)$ be a bipartite graph on $n$ vertices with $|V_1| = m$ and $|V_2| = n-m$. Assume without loss of generality that $|V_1| \leq |V_2|$ so $m \leq \left\lfloor \frac{n}{2} \right\rfloor$. If $G$ is complete bipartite then it has $m(n-m)$ edges since each of the vertices in $V_1$ is connected to each in $V_2$. Thus, the total number of bipartite graphs with parts of size $m$ and $n-m$ is $2^{m(n-m)}$. In order to find the total number of possible bipartite graphs on $n$ vertices we sum over all possible $m$:
  \begin{align}
\sum^{\left\lfloor \frac{n}{2} \right\rfloor}_{m=1} 2^{m(n-m)}
\end{align}


However, I notice that I have counted labelled bipartite graphs where I need the number of unlabelled graphs. I'm struggling to see how to account for this.
","It seems that what Andrew wants to count are what are called in enumerative contexts
""bicolored graphs"". A bicolored graph is a graph in which the vertices have been colored black and white so that every edge joins two vertices of different colors. A bipartite (or bicolorable) graph is a graph that has a bicoloring. A bicolorable graph with $k$ connected components has $2^k$ bicolorings. (In nonenumerative contexts the distinction between bipartite and bicolored is usually unimportant.) In addition, in counting  bicolored graphs one might or might not consider switching the two colors to give an equivalent graph. All of the versions of the enumeration problem have been solved. Counting unlabeled bicolored graphs (with no color-switching equivalence) is a straightforward application of Burnside's lemma; counting unlabeled bipartite graphs is tricky. 

It's not too hard to find appropriate references by searching MathSciNet. (Hint: ""color"" is sometimes spelled ""colour"".)

Incidentally, the number of labeled bicolored graphs on $n$ vertices is 
$$\sum_{m=0}^n 2^{m(n-m)}\binom{n}{m}.$$
"
2083,2083,3317,"Explain ""you can have functions that change other functions""","I was reading through Eloquent JavaScript, when I came across this in chapter 5. :


  you can have functions that create new functions.

function greaterThan(n) {
  return function(m) { return m &gt; n; };
}
var greaterThan10 = greaterThan(10);

  
  And you can have functions that change other functions.

function noisy(f) {
  return function(arg) {
    console.log(""calling with"", arg);
    var val = f(arg);
    console.log(""called with"", arg, ""- got"", val);
    return val;
  };
}
noisy(Boolean)(0);
//-&gt;calling with 0
//-&gt;called with 0 - got false



My questions are:


How are the above two examples different? 
How does noisy change Boolean?

",kchak,https://stackoverflow.com/users/3384193,"The difference is that the argument to noisy is meant to be another function, rather than a ""plain"" value like a number.  So, yes, it creates a new anonymous function just like greaterThan does, but it's a wrapper around an existing function that modifies its behavior.

In this case, the wrapper just logs some messages before and after calling the original function f.  But you could do other things, like modifying its arguments or its return value.  For example, you can implement partial function application, which lets you provide some of the arguments for a function call at one point in the program, and ""remember"" those arguments in a new function that takes just the remaining arguments later.
",Wyzard,https://stackoverflow.com/users/226975,http://stackoverflow.com/questions/31622584/explain-you-can-have-functions-that-change-other-functions,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.5555555555555556,0.0,0.5,1.0,1.0,0.6666666666666666,0.5555555555555556,1.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,0.8888888888888888,1.0,0.8,0.0,0.0,1.0,1.0,"Explain ""you can have the ability to change other functions""","I was reading through Eloquent JavaScript, when I came across this in chapter 5. :


  you can have functions that create new functions.

function greaterThan(n) {
  return function(m) { return m &gt; n; };
}
var greaterThan10 = greaterThan(10);

  
  And you can have functions that change other functions.

function noisy(f) {
  return function(arg) {
    console.log(""calling with"", arg);
    var val = f(arg);
    console.log(""called with"", arg, ""- got"", val);
    return val;
  };
}
noisy(Boolean)(0);
//-&gt;calling with 0
//-&gt;called with 0 - got false



My questions are:


How are the above two examples different? 
How does noisy change Boolean?

","The difference is that the argument to noisy is meant to be another function, rather than a ""plain"" value like a number.  So, yes, it creates a new anonymous function just like greaterThan does, but it's a wrapper around an existing function that modifies its behavior.

In this case, the wrapper just logs some messages before and after calling the original function f.  But you could do other things, like modifying its arguments or its return value.  For example, you can implement partial function application, which lets you provide some of the arguments for a function call at one point in the program, and ""remember"" those arguments in a new function that takes just the remaining arguments later.
"
893,893,1417,What is the Republic City Police Force (metalbender cops) insignia?,"What is the insignia worn by the metalbending cops?  The one that looks like a gold geometric ant's head (with mandibles):



Is it a spin on something from the previous series?
",Nick T,https://scifi.stackexchange.com/users/584,"If you look closely you see the shape resembles Toph's hair!

That's all it is.
",Shrimpy,https://scifi.stackexchange.com/users/11116,http://scifi.stackexchange.com/questions/19173/what-is-the-republic-city-police-force-metalbender-cops-insignia,LIFE_ARTS,scifi.stackexchange.com,0.8888888888888888,0.7777777777777778,0.6666666666666666,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.8888888888888888,0.8333333333333334,0.5555555555555556,1.0,1.0,1.0,0.0,0.0,0.6666666666666666,1.0,What is the badge of the city police force of the Republic?,What's the badge of the metal crooked police? The one that looks like the golden geometric ant's head (with jaws):,"If you look closely you see the shape resembles Toph's hair!

That's all it is.
"
5519,5519,8754,How to split a string between two character into sub groups in R,"I have a list of codes in the second column of a table and I want to extract some elements of each code then store them in new columns associated with each of the codes. 
Each code consists of letters followed by some numbers. The letters are P, F, I , R, C repeated with the same order in all codes but the number of digits are varying in each code. 

For example: consider the codes as below:

P1F2I235R15C145   P1   F2   I23   R15   C145
P24F1I12R124C96   P24  F1   I12   R124  C96


so in this way I can split each code into its constitutes sub-codes, and store these components into new columns in the same table.
thanks
",ashkan,https://stackoverflow.com/users/4227079,"Try this:

#simulate your data frame
df&lt;-data.frame(code=c(""P1F2I235R15C145"",""P24F1I12R124C96""),stringsAsFactors=FALSE)
#split the columns
cbind(df,do.call(rbind,regmatches(df$code,gregexpr(""[PFIRC][0-9]+"",df$code))))
#             code   1  2    3    4    5
#1 P1F2I235R15C145  P1 F2 I235  R15 C145
#2 P24F1I12R124C96 P24 F1  I12 R124  C96


What @AnandaMatho suggested in the comment was to let the letter in front of the code go away and name the columns accordingly. Something like that:

res&lt;-cbind(df,do.call(rbind,regmatches(df$code,gregexpr(""(?&lt;=[PFIRC])[0-9]+"",df$code,perl=TRUE))))
names(res)&lt;-c(""Code"",""P"",""F"",""I"",""R"",""C"")
#             Code  P F   I   R   C
#1 P1F2I235R15C145  1 2 235  15 145
#2 P24F1I12R124C96 24 1  12 124  96

",nicola,https://stackoverflow.com/users/3987294,http://stackoverflow.com/questions/30593693/how-to-split-a-string-between-two-character-into-sub-groups-in-r,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.5555555555555556,0.0,0.3333333333333333,1.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.7777777777777778,1.0,0.3333333333333333,1.0,0.7777777777777778,0.8,1.0,0.0,0.0,0.8888888888888888,How to split a string between two characters into subgroups in R,"I have a list of codes in the second column of a table and I want to extract some elements of each code then store them in new columns associated with each of the codes. 
Each code consists of letters followed by some numbers. The letters are P, F, I , R, C repeated with the same order in all codes but the number of digits are varying in each code. 

For example: consider the codes as below:

P1F2I235R15C145   P1   F2   I23   R15   C145
P24F1I12R124C96   P24  F1   I12   R124  C96


so in this way I can split each code into its constitutes sub-codes, and store these components into new columns in the same table.
thanks
","Try this:

#simulate your data frame
df&lt;-data.frame(code=c(""P1F2I235R15C145"",""P24F1I12R124C96""),stringsAsFactors=FALSE)
#split the columns
cbind(df,do.call(rbind,regmatches(df$code,gregexpr(""[PFIRC][0-9]+"",df$code))))
#             code   1  2    3    4    5
#1 P1F2I235R15C145  P1 F2 I235  R15 C145
#2 P24F1I12R124C96 P24 F1  I12 R124  C96


What @AnandaMatho suggested in the comment was to let the letter in front of the code go away and name the columns accordingly. Something like that:

res&lt;-cbind(df,do.call(rbind,regmatches(df$code,gregexpr(""(?&lt;=[PFIRC])[0-9]+"",df$code,perl=TRUE))))
names(res)&lt;-c(""Code"",""P"",""F"",""I"",""R"",""C"")
#             Code  P F   I   R   C
#1 P1F2I235R15C145  1 2 235  15 145
#2 P24F1I12R124C96 24 1  12 124  96

"
1513,1513,2380,How do they shoot long underwater scenes (especially the even longer stylistic ones)?,"How do they shoot the music videos where people are singing inside water? What confuses me if that is plain special effects is their clothes, they behave exactly how clothes behave in water. 

The motion of the cloth is slow, like it's supposed to be in a fluid, whereas the motion of the person is normal (or slow, but for stylistic reasons). I mean, it could be special effects, but that will really surprise me, because it will certainly take a lot of effort.

Example
",Man,https://movies.stackexchange.com/users/4982,"It really depends on the film, but the best example I can think of is the James Cameron's The Abyss, and I suspect they did the same thing in the music video you mentioned.

As detailed in this Time article about the film, there is a large tank of water for the scene to be filmed in, with all the crew using oxygen tanks. In between cuts, support divers with a spare oxygen tank will then swim up to the cast and give it to them. In the case of The Abyss, there was also an underwater oxygen refilling station so they didn't have to surface every time their Oxygen tank was empty (which would be once an hour), but in shorter and/or cheaper projects they would just swim up to the surface to do so.

Though in the music video, the angle of the light source seems to indicate that she isn't very deep underwater and could probably reach the surface with a single kick.
",Crow T Robot,https://movies.stackexchange.com/users/9682,http://movies.stackexchange.com/questions/23668/how-do-they-shoot-long-underwater-scenes-especially-the-even-longer-stylistic-o,LIFE_ARTS,movies.stackexchange.com,1.0,1.0,0.0,1.0,1.0,1.0,0.6666666666666666,0.7777777777777778,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.6666666666666666,0.3333333333333333,0.8888888888888888,How do they photograph long underwater scenes (especially longer style scenes)?,"How do they shoot the music videos where people are singing inside water? What confuses me if that is plain special effects is their clothes, they behave exactly how clothes behave in water. 

The motion of the cloth is slow, like it's supposed to be in a fluid, whereas the motion of the person is normal (or slow, but for stylistic reasons). I mean, it could be special effects, but that will really surprise me, because it will certainly take a lot of effort.

Example
","It really depends on the film, but the best example I can think of is the James Cameron's The Abyss, and I suspect they did the same thing in the music video you mentioned.

As detailed in this Time article about the film, there is a large tank of water for the scene to be filmed in, with all the crew using oxygen tanks. In between cuts, support divers with a spare oxygen tank will then swim up to the cast and give it to them. In the case of The Abyss, there was also an underwater oxygen refilling station so they didn't have to surface every time their Oxygen tank was empty (which would be once an hour), but in shorter and/or cheaper projects they would just swim up to the surface to do so.

Though in the music video, the angle of the light source seems to indicate that she isn't very deep underwater and could probably reach the surface with a single kick.
"
5457,5457,8664,Change published date to 12 hour time,"Right now my nodes say published by ""author name 19:02"". How can I change it to display 12 hour time 7:02?
",Matthew Hui,https://drupal.stackexchange.com/users/1170,"It uses the default date format of the site, which is medium. You can configure that at admin/settings/date-time and choose a format which uses am/pm.

You can also implement hook_preprocess_node() in your theme or module and then override the 'submitted' variable set by template_preprocess_node(). That allows you to use a different date format just there.
",Berdir,https://drupal.stackexchange.com/users/31,http://drupal.stackexchange.com/questions/6693/change-published-date-to-12-hour-time,TECHNOLOGY,drupal.stackexchange.com,0.8888888888888888,0.6666666666666666,0.0,1.0,1.0,0.6666666666666666,0.5555555555555556,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.3333333333333333,0.8888888888888888,Change release date to 12 hours,"Now my node is published by ""author name 19:02"". How do I change it to show 12 hours at 7:02?","It uses the default date format of the site, which is medium. You can configure that at admin/settings/date-time and choose a format which uses am/pm.

You can also implement hook_preprocess_node() in your theme or module and then override the 'submitted' variable set by template_preprocess_node(). That allows you to use a different date format just there.
"
2347,2347,3742,Setting up a food pantry/orphanage?,"I can't find much on how to set up any kind of establishments that are for charity. HOw would I go about this? Acquiring a building, a few volunteers, how much to run it per day, ect? Anyone have any experience in this? My character is a NG Druid, who had never been to a city and saw the poverty and lack of food and housing for people. He wants to help! But I have no idea on how to establish a continual act of help. Buying food for the town and stuff, one time is easy to figure out. How many people * ammount of food needed is the price. But for bigger acts of continual charity, who knows? 

EDIT:
So, it was suggested that I make an eco orphanage in a forest. I accidently doomed the continent with demons, so that won't work. (Wish spell to get rid of orcs, things went horribly wrong) NO one knows it was me though! :D 

I don't want the leadership feat cause I need my 6th level feat for a prestige class.

Also, I don't want to donate to the churches in this city, I'm finding a lot of corruption in some of these churches, especially this city, so I want something more controllable by me. 
",samuraiseoul,https://rpg.stackexchange.com/users/10381,"There isn't anything in the core rules about building ownership, but you (or your DM) can fake it in a good-enough way (at least, so long as nobody tries to break the game using such a ruling) by estimating off the equipment tables. You need three things: cost for building maintenance (or rent), cost for food, and (if not renting) initial price of the building.

In the equipment chapter under Food, Drink, And Lodging, a poor meal costs 1sp. I'm picking ""poor"" because no matter how much you have, you want to stretch it as far as you can to feed as many, right? So go with ""poor"". That price is assuming making a profit, so let's be conservative (on the ""more expensive for you"" side) and cut it in half: 5cp to feed an orphan. Maybe shave that down to 3cp, since they're kids and not grown adults eating at a poor inn. (This is really back-of-the-envelope stuff, not rigorous at all.)

We can do something similar for the rent/maintenance of the building: a night's stay in a poor inn is listed as 2sp. Let's cut it in half to 1sp to eliminate the profit normally involved. Since a normal poor inn can maintain the whole building on 2sp per room per night, we can be pretty sure that the 1sp per orphan per night will cover (sans profits) whatever costs are involved in paying rent or taxes, repairs, replacing bedding, laundering, upkeep of the non-sleeping quarters and so on.

Somewhere, between the price for meals and the price for rooms, a combined inn/tavern also pays for their kitchen, so we're probably safely in the black with our estimates. You probably don't need to maintain a stable like a normal inn, and you're not paying for the volunteer labour, so that makes the estimate even more likely to at least meet or exceed the costs of rooms and food.

Altogether, that makes it 1sp, 3cp to feed and house a single orphan per day, assuming one good meal every day (which is not far off the unfortunate reality of old orphanages). If you want to have them slightly healthier, but be able to take in fewer, make it two meals per day and double the meals costs to 6cp, for 1.6sp per orphan per day.

So, very roughly, you see how you can use the goods and services lists in the core book to get a gameable estimate of the costs per orphan per day. From there you can look at what money you've got stashed and what your incoming donations are, and estimate how many orphans you can house and feed at once on an ongoing basis.

As for the initial cost of acquiring the building, that the core rules don't provide anything even close to helpful for estimating. You don't have to worry about this if you find a willing landlord, but if you have to buy the building outright, this becomes a slightly sticky issue. If I was running this game I'd probably just play it out, maybe angling for the druid to find a donor with a vacant building. At worst I'd just name a price in gold and get on with it, while making sure that the players know that the price is particular to this building from this seller, and they shouldn't expect it to set a precedent. Maybe, like 100gp or something.
",SevenSidedDie,https://rpg.stackexchange.com/users/321,http://rpg.stackexchange.com/questions/32292/setting-up-a-food-pantry-orphanage,CULTURE,rpg.stackexchange.com,0.8888888888888888,0.5555555555555556,0.3333333333333333,1.0,0.6666666666666666,1.0,0.7777777777777778,0.5555555555555556,0.3333333333333333,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,0.8888888888888888,Food storage / orphanage?,"I can't find much on how to set up any kind of establishments that are for charity. HOw would I go about this? Acquiring a building, a few volunteers, how much to run it per day, ect? Anyone have any experience in this? My character is a NG Druid, who had never been to a city and saw the poverty and lack of food and housing for people. He wants to help! But I have no idea on how to establish a continual act of help. Buying food for the town and stuff, one time is easy to figure out. How many people * ammount of food needed is the price. But for bigger acts of continual charity, who knows? 

EDIT:
So, it was suggested that I make an eco orphanage in a forest. I accidently doomed the continent with demons, so that won't work. (Wish spell to get rid of orcs, things went horribly wrong) NO one knows it was me though! :D 

I don't want the leadership feat cause I need my 6th level feat for a prestige class.

Also, I don't want to donate to the churches in this city, I'm finding a lot of corruption in some of these churches, especially this city, so I want something more controllable by me. 
","There isn't anything in the core rules about building ownership, but you (or your DM) can fake it in a good-enough way (at least, so long as nobody tries to break the game using such a ruling) by estimating off the equipment tables. You need three things: cost for building maintenance (or rent), cost for food, and (if not renting) initial price of the building.

In the equipment chapter under Food, Drink, And Lodging, a poor meal costs 1sp. I'm picking ""poor"" because no matter how much you have, you want to stretch it as far as you can to feed as many, right? So go with ""poor"". That price is assuming making a profit, so let's be conservative (on the ""more expensive for you"" side) and cut it in half: 5cp to feed an orphan. Maybe shave that down to 3cp, since they're kids and not grown adults eating at a poor inn. (This is really back-of-the-envelope stuff, not rigorous at all.)

We can do something similar for the rent/maintenance of the building: a night's stay in a poor inn is listed as 2sp. Let's cut it in half to 1sp to eliminate the profit normally involved. Since a normal poor inn can maintain the whole building on 2sp per room per night, we can be pretty sure that the 1sp per orphan per night will cover (sans profits) whatever costs are involved in paying rent or taxes, repairs, replacing bedding, laundering, upkeep of the non-sleeping quarters and so on.

Somewhere, between the price for meals and the price for rooms, a combined inn/tavern also pays for their kitchen, so we're probably safely in the black with our estimates. You probably don't need to maintain a stable like a normal inn, and you're not paying for the volunteer labour, so that makes the estimate even more likely to at least meet or exceed the costs of rooms and food.

Altogether, that makes it 1sp, 3cp to feed and house a single orphan per day, assuming one good meal every day (which is not far off the unfortunate reality of old orphanages). If you want to have them slightly healthier, but be able to take in fewer, make it two meals per day and double the meals costs to 6cp, for 1.6sp per orphan per day.

So, very roughly, you see how you can use the goods and services lists in the core book to get a gameable estimate of the costs per orphan per day. From there you can look at what money you've got stashed and what your incoming donations are, and estimate how many orphans you can house and feed at once on an ongoing basis.

As for the initial cost of acquiring the building, that the core rules don't provide anything even close to helpful for estimating. You don't have to worry about this if you find a willing landlord, but if you have to buy the building outright, this becomes a slightly sticky issue. If I was running this game I'd probably just play it out, maybe angling for the druid to find a donor with a vacant building. At worst I'd just name a price in gold and get on with it, while making sure that the players know that the price is particular to this building from this seller, and they shouldn't expect it to set a precedent. Maybe, like 100gp or something.
"
3899,3899,6215,What is the best introductory Bayesian statistics textbook?,"Which is the best introductory textbook for Bayesian statistics?

One book per answer, please.
",Shane,https://stats.stackexchange.com/users/5,"I found an excellent introduction in Gelman and Hill (2006) Data Analysis Using Regression and Multilevel/Hierarchical Models. (Other comments mention it, but it deserves to get upvoted on its own.)
",Jack Tanner,https://stats.stackexchange.com/users/8207,http://stats.stackexchange.com/questions/125/what-is-the-best-introductory-bayesian-statistics-textbook,SCIENCE,stats.stackexchange.com,1.0,0.8888888888888888,0.3333333333333333,1.0,0.0,0.0,0.5555555555555556,0.5555555555555556,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.3333333333333333,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,0.3333333333333333,1.0,What is the best introduction to Bayesian statistics?,Which is the best introduction to Bayesian statistics?,"I found an excellent introduction in Gelman and Hill (2006) Data Analysis Using Regression and Multilevel/Hierarchical Models. (Other comments mention it, but it deserves to get upvoted on its own.)
"
1598,1598,2514,iPhone app - Persistent hamburger menu vs last page visited,"I'm wondering which option is best for an iPhone app using a hamburger menu (placed at the top left):


The menu is persistent on every single page even when the user goes
to a sub-level.
When the user goes to a sub-level, the hamburger menu is replaced by a back button or a button whose label is the name of last page visited.
Both. The menu is persistent on every page and a back button appears when needed.


Thanks for your help :)
",Leo,https://ux.stackexchange.com/users/25518,"I'd recommend iOS standards unless you really need to break from convention.  Standard iOS expectation is that you always have a back / up-level nav in the upper left corner. If you put 2 nav icons side-by-side in the upper left (Hamburger and Back Nav) that makes them both less usable and creates challenges - which is the one on the left most side?  Your #2 is the most common implementation.  Do users need to get back to the top most menu frequently enough to require having the hamburger nav on all screens? Then consider...

iOS standards also call for the use of the Tab Bar across the bottom - it is an option if you have a small (7) number of items in your nav (though it does persistently take up screen real-estate so isn't ideal unless the user needs to quickly access a few key screens).  

The big question for any use of Hamburger Menus is... what are you putting in there?  @Majo0od incorrectly states the reasons why hamburger menus are problematic.  Hamburger menus have been being maligned considerably lately and most of the critiques have zero to do with user experience.  List Menus (Hamburger Menus) work great when they provide a consistent list of items clearly delineated.  The majority of user testing with List Menus shows that users very easily understand what they are and often go there to find stuff if the thing they're looking for isn't obvious elsewhere on the screen.  This has led to some bad practice among designers who started tossing everything in there - this leads to a garbage pile of items which makes it difficult for users to find what they're looking for or to know what to expect on subsequent visits to that menu.  A similar List Menu metaphor used all over both iOS and Android is 3 dots on the right (doesn't look like a hamburger so it isn't as maligned but has identical problems when not used consistently).  This is usually used to show a contextual list based on where the user is rather than an omnipresent top left list menu. Going back to my point for this paragraph... what are you using it for? Is it a clearly delineated list of concise items that is contextually relevant to where the user is in the app? Could it be better implemented using a different design pattern? Use the right tool for the job.
",Oddible,https://ux.stackexchange.com/users/42867,http://ux.stackexchange.com/questions/74551/iphone-app-persistent-hamburger-menu-vs-last-page-visited,TECHNOLOGY,ux.stackexchange.com,0.8888888888888888,0.4444444444444444,0.3333333333333333,1.0,0.3333333333333333,1.0,0.6666666666666666,0.5555555555555556,0.3333333333333333,0.0,1.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.4444444444444444,1.0,0.7777777777777778,1.0,1.0,1.0,0.6666666666666666,0.0,0.3333333333333333,0.8888888888888888,IPhone app - persistent hamburger menu vs. last visited page,"I'm wondering which option is best for an iPhone app using a hamburger menu (placed at the top left):


The menu is persistent on every single page even when the user goes
to a sub-level.
When the user goes to a sub-level, the hamburger menu is replaced by a back button or a button whose label is the name of last page visited.
Both. The menu is persistent on every page and a back button appears when needed.


Thanks for your help :)
","I'd recommend iOS standards unless you really need to break from convention.  Standard iOS expectation is that you always have a back / up-level nav in the upper left corner. If you put 2 nav icons side-by-side in the upper left (Hamburger and Back Nav) that makes them both less usable and creates challenges - which is the one on the left most side?  Your #2 is the most common implementation.  Do users need to get back to the top most menu frequently enough to require having the hamburger nav on all screens? Then consider...

iOS standards also call for the use of the Tab Bar across the bottom - it is an option if you have a small (7) number of items in your nav (though it does persistently take up screen real-estate so isn't ideal unless the user needs to quickly access a few key screens).  

The big question for any use of Hamburger Menus is... what are you putting in there?  @Majo0od incorrectly states the reasons why hamburger menus are problematic.  Hamburger menus have been being maligned considerably lately and most of the critiques have zero to do with user experience.  List Menus (Hamburger Menus) work great when they provide a consistent list of items clearly delineated.  The majority of user testing with List Menus shows that users very easily understand what they are and often go there to find stuff if the thing they're looking for isn't obvious elsewhere on the screen.  This has led to some bad practice among designers who started tossing everything in there - this leads to a garbage pile of items which makes it difficult for users to find what they're looking for or to know what to expect on subsequent visits to that menu.  A similar List Menu metaphor used all over both iOS and Android is 3 dots on the right (doesn't look like a hamburger so it isn't as maligned but has identical problems when not used consistently).  This is usually used to show a contextual list based on where the user is rather than an omnipresent top left list menu. Going back to my point for this paragraph... what are you using it for? Is it a clearly delineated list of concise items that is contextually relevant to where the user is in the app? Could it be better implemented using a different design pattern? Use the right tool for the job.
"
2039,2039,3247,Difference in technique for cooking with non-stick and standard pans?,"Following up from my previous question, which I'd raised because I have concerns that my non-stick wok will need replacing very soon (again), and was having a think about ""standard"" pans.

I'm not currently interested in differences in care/cleaning/etc, I think those are quite well covered in other questions.

So, I'm wondering what's the difference in the required technique when using them to cook food?
",DMA57361,https://cooking.stackexchange.com/users/1181,"You can get the benefits of both non-stick and fond by prepping the stainless steel pan so it's more non-stick:

Use the ""water test"" to know when a stainless steel pan is hot enough to add oil. Besides being fascinating to watch, passing the water test ensures the pan becomes amazingly non-stick.

When the pan is hot enough, water will ball up like mercury and slide around the pan without evaporating. The temperature required is pretty high, but I've found the non-stick properties remain if I add the oil and let the pan cool to the cooking temperature I want.

Note: preheating the pan like this applies to non-stainless steel pans, but water only balls up like mercury on stainless steel.

Detailed explanation of how/why this works: On properly heating your pan
",Leftium,https://cooking.stackexchange.com/users/398,http://cooking.stackexchange.com/questions/3122/difference-in-technique-for-cooking-with-non-stick-and-standard-pans,LIFE_ARTS,cooking.stackexchange.com,1.0,0.8888888888888888,0.0,1.0,0.6666666666666666,0.5,0.7777777777777778,0.5555555555555556,0.0,0.0,0.6666666666666666,0.0,0.6666666666666666,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,0.8888888888888888,0.6666666666666666,1.0,0.8888888888888888,0.8666666666666666,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.8888888888888888,What's the difference between nonstick cooking and standard cooking?,"Following up from my previous question, which I'd raised because I have concerns that my non-stick wok will need replacing very soon (again), and was having a think about ""standard"" pans.

I'm not currently interested in differences in care/cleaning/etc, I think those are quite well covered in other questions.

So, I'm wondering what's the difference in the required technique when using them to cook food?
","You can get the benefits of both non-stick and fond by prepping the stainless steel pan so it's more non-stick:

Use the ""water test"" to know when a stainless steel pan is hot enough to add oil. Besides being fascinating to watch, passing the water test ensures the pan becomes amazingly non-stick.

When the pan is hot enough, water will ball up like mercury and slide around the pan without evaporating. The temperature required is pretty high, but I've found the non-stick properties remain if I add the oil and let the pan cool to the cooking temperature I want.

Note: preheating the pan like this applies to non-stainless steel pans, but water only balls up like mercury on stainless steel.

Detailed explanation of how/why this works: On properly heating your pan
"
2744,2744,4376,Help me identify this spider from my garden,"Found this in my garden today in Sydney, Australia (specifically Lane Cove). Can you tell me what it is?



",jacobsa,https://biology.stackexchange.com/users/15380,"It looks like Neoscona Crucifera to me, but I could be wrong.

Here is a picture of her: 



Another one, only this is more of the web: 


",CDB,https://biology.stackexchange.com/users/13496,http://biology.stackexchange.com/questions/31461/help-me-identify-this-spider-from-my-garden,SCIENCE,biology.stackexchange.com,1.0,0.3333333333333333,0.0,1.0,1.0,1.0,0.7777777777777778,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.9,0.0,0.0,0.0,0.8888888888888888,Help me identify the spider from the garden,"Today I found this in my garden in Sydney, Australia (especially Lane Bay). Can you tell me what it is?","It looks like Neoscona Crucifera to me, but I could be wrong.

Here is a picture of her: 



Another one, only this is more of the web: 


"
3038,3038,4846,How to upload to WebDAV using a web browser?,"I've setup and configured webdav on debian using the following tutorial:

http://www.unix-tutorials.com/go.php?id=3711

I want to be able to download and upload files to the webdav share using a web browser. I can download and upload files to the webdav share if I mount it to my file system but we don't want the other people accessing this to have to do that. We want people to be able to go to the URL in their web browser, authenticate, and do everything, download, upload in their browser. 

When I go to the webdav URL in my browser and authenticate I'm given a list of the webdav share's contents and I can download the files but I don't see any way to upload files? How can I upload files to the webdav share using a web browser? 

Thanks in advance.
",caleban,https://serverfault.com/users/37321,"You don't say which browser.  I thought it was built-in with Internet Explorer by simply using drag-and-drop.  I seem to recall a Firefox add-on.  I am looking for it now.

Edit: 


  Webfolders is a firefox extension that gives you the ability to view the contents of WebDAV
  servers in the browser and use the full functionality of the WebDAV protocol. 


webfolder add-on for Firefox
",Aaron Copley,https://serverfault.com/users/50647,http://serverfault.com/questions/197910,TECHNOLOGY,serverfault.com,0.7777777777777778,0.6666666666666666,0.0,0.3333333333333333,1.0,1.0,0.6666666666666666,0.4444444444444444,0.3333333333333333,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.7777777777777778,0.7777777777777778,0.5555555555555556,0.8888888888888888,0.8888888888888888,0.7333333333333333,0.3333333333333333,0.6666666666666666,0.6666666666666666,1.0,How do I upload to WebDAV using a web browser?,"I've setup and configured webdav on debian using the following tutorial:

http://www.unix-tutorials.com/go.php?id=3711

I want to be able to download and upload files to the webdav share using a web browser. I can download and upload files to the webdav share if I mount it to my file system but we don't want the other people accessing this to have to do that. We want people to be able to go to the URL in their web browser, authenticate, and do everything, download, upload in their browser. 

When I go to the webdav URL in my browser and authenticate I'm given a list of the webdav share's contents and I can download the files but I don't see any way to upload files? How can I upload files to the webdav share using a web browser? 

Thanks in advance.
","You don't say which browser.  I thought it was built-in with Internet Explorer by simply using drag-and-drop.  I seem to recall a Firefox add-on.  I am looking for it now.

Edit: 


  Webfolders is a firefox extension that gives you the ability to view the contents of WebDAV
  servers in the browser and use the full functionality of the WebDAV protocol. 


webfolder add-on for Firefox
"
3036,3036,4843,How to change rotation direction of 3-phase electrical machines?,"I was taught that if you want to change the direction of a three phase rotating machine that is rotating in forward direction, you interchange the phases. Since the phases has the same features (voltage and current), what is responsible for making the machine to rotate in reverse direction, when the phases are interchanged?
",Ezeatum Solomon,https://electronics.stackexchange.com/users/82333,"Each phase has the same voltage in a sinewave, but 120 degrees out of phase. The question then becomes which phase leads the other. This is what determines the direction of the motor. 
",DoxyLover,https://electronics.stackexchange.com/users/19489,http://electronics.stackexchange.com/questions/182800/how-to-change-rotation-direction-of-3-phase-electrical-machines,SCIENCE,electronics.stackexchange.com,1.0,0.7777777777777778,0.0,1.0,0.6666666666666666,1.0,0.5555555555555556,0.5555555555555556,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.0,0.8888888888888888,0.8888888888888888,0.5,1.0,0.8888888888888888,0.8666666666666666,0.0,0.0,1.0,1.0,How to change the rotation direction of three-phase motor?,"I have been taught that if you want to change the direction of a three-phase rotating machine that is rotating in a positive direction, you have to change the phase. Since the phases have the same characteristics (voltage and current), when the phases are interchanged, what causes the machine to rotate in reverse?","Each phase has the same voltage in a sinewave, but 120 degrees out of phase. The question then becomes which phase leads the other. This is what determines the direction of the motor. 
"
871,871,1381,Wildcard subdomain directory names,"I have the following in my Apache config:

&lt;VirtualHost *:80&gt;
  VirtualDocumentRoot /var/www/hosts/%0
  ServerAlias *.test.galapagos.office
&lt;/VirtualHost&gt;


In /var/www/hosts, I have a directory called jason.test.galapagos.office and one called bill.test.galapagos.office. If I go to jason.test.galapagos.office in a browser, I get what I expect to see. Same with bill. In other words, everything is working perfectly.

However, I'm not quite satisfied with what's going on. Instead of /var/www/hosts/jason.test.galapagos.office and /var/www/hosts/bill.test.galapagos.office/, I'd like /home/jason/web and /home/bill/web.

How can I tell Apache to map to those subdirectories instead?

Thanks,
Jason
",Jason Swett,https://serverfault.com/users/53516,"Try this:

&lt;VirtualHost *:80&gt;
  #VirtualDocumentRoot /var/www/hosts/%0
  VirtualDocumentRoot /home/%1/web
  ServerAlias *.test.galapagos.office
&lt;/VirtualHost&gt;


I believe that will sent requests to ""jason.test.galapagos.office"" to ""/home/jason/web""

The full list of VirtualDocumentRoot directives can be found here:

http://httpd.apache.org/docs/2.2/mod/mod_vhost_alias.html

0     the whole name
1     the first part
2     the second part
-1    the last part
-2    the penultimate part
2+    the second and all subsequent parts
-2+   the penultimate and all preceding parts
1+ and -1+     the same as 0
",sysadmin1138,https://serverfault.com/users/3038,http://serverfault.com/questions/182929,TECHNOLOGY,serverfault.com,0.8888888888888888,0.3333333333333333,0.0,0.0,1.0,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,1.0,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,1.0,Wildcard subdomain directory name,"I have the following in my Apache config:

&lt;VirtualHost *:80&gt;
  VirtualDocumentRoot /var/www/hosts/%0
  ServerAlias *.test.galapagos.office
&lt;/VirtualHost&gt;


In /var/www/hosts, I have a directory called jason.test.galapagos.office and one called bill.test.galapagos.office. If I go to jason.test.galapagos.office in a browser, I get what I expect to see. Same with bill. In other words, everything is working perfectly.

However, I'm not quite satisfied with what's going on. Instead of /var/www/hosts/jason.test.galapagos.office and /var/www/hosts/bill.test.galapagos.office/, I'd like /home/jason/web and /home/bill/web.

How can I tell Apache to map to those subdirectories instead?

Thanks,
Jason
","Try this:

&lt;VirtualHost *:80&gt;
  #VirtualDocumentRoot /var/www/hosts/%0
  VirtualDocumentRoot /home/%1/web
  ServerAlias *.test.galapagos.office
&lt;/VirtualHost&gt;


I believe that will sent requests to ""jason.test.galapagos.office"" to ""/home/jason/web""

The full list of VirtualDocumentRoot directives can be found here:

http://httpd.apache.org/docs/2.2/mod/mod_vhost_alias.html

0     the whole name
1     the first part
2     the second part
-1    the last part
-2    the penultimate part
2+    the second and all subsequent parts
-2+   the penultimate and all preceding parts
1+ and -1+     the same as 0
"
5102,5102,8113,Alternatives of 'a snowball's chance in hell',"I am looking for a different, common English idiom that expresses the same thing as a snowball's chance in hell.  My teacher says I use this expression too much, and that it is not appropriate for every essay. I need a same meaning like something very cold in a hot place to have a little chance.
",The Beefer Fan,https://english.stackexchange.com/users/83537,"Here are some alternatives you may consider:


chance in a million
next to impossible
poor prospect
ghost of a chance


Although I do agree these may not come across as colorful enough.
",Armen Ծիրունյան,https://english.stackexchange.com/users/11268,http://english.stackexchange.com/questions/184377/alternatives-of-a-snowballs-chance-in-hell,CULTURE,english.stackexchange.com,1.0,0.8888888888888888,0.3333333333333333,1.0,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.8888888888888888,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.6666666666666666,0.0,0.5555555555555556,0.8888888888888888,0.6666666666666666,1.0,0.8888888888888888,0.8,0.0,0.0,0.3333333333333333,0.6666666666666666,"Alternative to ""snowball opportunity in hell""","I am looking for a different, common English idiom that expresses the same thing as snowball opportunities in hell. My teacher said that I used the word too much, not suitable for every article. I need a bit of opportunity for something that means the same, like being cold in a hot place.","Here are some alternatives you may consider:


chance in a million
next to impossible
poor prospect
ghost of a chance


Although I do agree these may not come across as colorful enough.
"
5946,5946,9421,Can grep return true/false or are there alternative methods,"I'm trying to write this script for an assignment - it's only the second one I've written so bear with me. 

As a part of this script, I need to be able to check if the first argument given matches the first word of file. If it does, exit with an error message, if it doesn't, append the arguments to the file. I understand how to write the if statement, but not how to use grep within a script. I understand that grep will look something like this

grep ^$1 schemas.txt

I feel like this should be much easier than I am making it. Any help appreciated. 

Update:
I'm getting an error too many arguments on the if statement. I got rid of the space between grep-q and then got an error binary operator expected. I've been poking around at it, but I don't see what it sees.

if [ grep -q ^$1 schemas.txt ]
then
        echo ""Schema already exists. Please try again""
        exit 1
else
        echo ""$@"" &gt;&gt; schemas.txt
fi

",Lauren,https://unix.stackexchange.com/users/23551,"Another simple way is to use grep -c.  

That outputs (not return as exit code), the number of lines that match the pattern, so 0 if there's no match or 1 or more if there's a match.

So, if you wanted to check that the pattern is matched 3 or more times, you would do:

if [ ""$(grep -c ""^$1"" schemas.txt)"" -ge 3 ]; then
  ...

",amigal,https://unix.stackexchange.com/users/11876,http://unix.stackexchange.com/questions/48535/can-grep-return-true-false-or-are-there-alternative-methods,TECHNOLOGY,unix.stackexchange.com,1.0,0.5555555555555556,0.0,1.0,1.0,1.0,0.7777777777777778,0.5555555555555556,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,0.8333333333333334,"Whether grep can return true / false, or whether there are other methods","I'm trying to write this script for an assignment - it's only the second one I've written so bear with me. 

As a part of this script, I need to be able to check if the first argument given matches the first word of file. If it does, exit with an error message, if it doesn't, append the arguments to the file. I understand how to write the if statement, but not how to use grep within a script. I understand that grep will look something like this

grep ^$1 schemas.txt

I feel like this should be much easier than I am making it. Any help appreciated. 

Update:
I'm getting an error too many arguments on the if statement. I got rid of the space between grep-q and then got an error binary operator expected. I've been poking around at it, but I don't see what it sees.

if [ grep -q ^$1 schemas.txt ]
then
        echo ""Schema already exists. Please try again""
        exit 1
else
        echo ""$@"" &gt;&gt; schemas.txt
fi

","Another simple way is to use grep -c.  

That outputs (not return as exit code), the number of lines that match the pattern, so 0 if there's no match or 1 or more if there's a match.

So, if you wanted to check that the pattern is matched 3 or more times, you would do:

if [ ""$(grep -c ""^$1"" schemas.txt)"" -ge 3 ]; then
  ...

"
2700,2700,4306,Get public feeds of a Facebook Page in Node.js,"I'm developing a simple node/express/jade website that fetch all the public feeds of a Facebook Page.

I create an application from wich i get client_id (APP_ID) and client_secret (APP_SECRET).

My code works, and it's okay but i wonder if this is the correct way of handling this need.

Here is the code:

var https = require('https'),
    concat = require('concat-stream'),
    async = require('async');

function FacebookPage(pageId) {
    if (!(this instanceof FacebookPage))
        return new FacebookPage(pageId);

    this.pageId = pageId;
}

FacebookPage.prototype.getPublicFeeds = function (callback) {

var pageId = this.pageId;

async.waterfall([

  function (done) {
        var params = {
            hostname: 'graph.facebook.com',
            port: 443,
            path: '/oauth/access_token?client_id=MY_CLIENT_ID&amp;' +
                'client_secret=MY_CLIENT_SECRET&amp;grant_type=client_credentials',
            method: 'GET'
        };

        https.get(params, function (response) {
            //response is a stream so it is an EventEmitter
            response.setEncoding(""utf8"");

            //More compact
            response.pipe(concat(function (data) {
                done(null, data);
            }));

            response.on(""error"", done);
        });
  },

  function (access_token, done) {

        var params = {
            hostname: 'graph.facebook.com',
            port: 443,
            path: '/v2.0/' + pageId + '/feed?' + access_token,
            method: 'GET'
        };

        https.get(params, function (response) {
            //response is a stream so it is an EventEmitter
            response.setEncoding(""utf8"");

            //More compact
            response.pipe(concat(function (data) {
                callback(null, JSON.parse(data));
            }));

            response.on(""error"", callback);
        });

  }]);
};

module.exports = FacebookPage;


EDIT: thank to @Tobi I can delete the part of getting the access_token by putting access_token=app_id|app_secret as explained here:

",Axel92Dev,https://stackoverflow.com/users/1758494,"Not sure why you'd want to include to OAuth stuff (which I think can't work because you don't exchange the code for an actual access token if I understand this correctly)...

According to https://developers.facebook.com/docs/graph-api/reference/v2.0/page/feed/ you need an access token ... to view publicly shared posts., this means you can also use an app access token in the form of app_id|app_secret.

You can then use the

GET /{page_id}/feed


endpoint by passing the access_token paramenter with your app access token. I'd also recommend to use the NPM modules request or restler, these make the HTTP handling much easier.
",Tobi,https://stackoverflow.com/users/1603357,http://stackoverflow.com/questions/24821352/get-public-feeds-of-a-facebook-page-in-node-js,STACKOVERFLOW,stackoverflow.com,0.6666666666666666,0.5,0.5,1.0,0.5,1.0,0.5,0.6666666666666666,0.0,0.5,0.0,0.5,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.9,1.0,0.0,0.0,1.0,Get the public feed of Facebook page in node.js,"I'm developing a simple node/express/jade website that fetch all the public feeds of a Facebook Page.

I create an application from wich i get client_id (APP_ID) and client_secret (APP_SECRET).

My code works, and it's okay but i wonder if this is the correct way of handling this need.

Here is the code:

var https = require('https'),
    concat = require('concat-stream'),
    async = require('async');

function FacebookPage(pageId) {
    if (!(this instanceof FacebookPage))
        return new FacebookPage(pageId);

    this.pageId = pageId;
}

FacebookPage.prototype.getPublicFeeds = function (callback) {

var pageId = this.pageId;

async.waterfall([

  function (done) {
        var params = {
            hostname: 'graph.facebook.com',
            port: 443,
            path: '/oauth/access_token?client_id=MY_CLIENT_ID&amp;' +
                'client_secret=MY_CLIENT_SECRET&amp;grant_type=client_credentials',
            method: 'GET'
        };

        https.get(params, function (response) {
            //response is a stream so it is an EventEmitter
            response.setEncoding(""utf8"");

            //More compact
            response.pipe(concat(function (data) {
                done(null, data);
            }));

            response.on(""error"", done);
        });
  },

  function (access_token, done) {

        var params = {
            hostname: 'graph.facebook.com',
            port: 443,
            path: '/v2.0/' + pageId + '/feed?' + access_token,
            method: 'GET'
        };

        https.get(params, function (response) {
            //response is a stream so it is an EventEmitter
            response.setEncoding(""utf8"");

            //More compact
            response.pipe(concat(function (data) {
                callback(null, JSON.parse(data));
            }));

            response.on(""error"", callback);
        });

  }]);
};

module.exports = FacebookPage;


EDIT: thank to @Tobi I can delete the part of getting the access_token by putting access_token=app_id|app_secret as explained here:

","Not sure why you'd want to include to OAuth stuff (which I think can't work because you don't exchange the code for an actual access token if I understand this correctly)...

According to https://developers.facebook.com/docs/graph-api/reference/v2.0/page/feed/ you need an access token ... to view publicly shared posts., this means you can also use an app access token in the form of app_id|app_secret.

You can then use the

GET /{page_id}/feed


endpoint by passing the access_token paramenter with your app access token. I'd also recommend to use the NPM modules request or restler, these make the HTTP handling much easier.
"
1018,1018,1607,"iptables -P FORWARD DROP, good or bad?","Is dropping all FORWARD packets bad? What are they used for? Why would I want to block them or keep them open?

(I fully understand INPUT and OUTPUT)
",Luke,https://serverfault.com/users/95470,"The FORWARD chain is used to manage packets that are being routed through the machine. If the machine is a router then dropping all packets in the FORWARD chain would be bad. If it's not a router then you can drop packets in the FORWARD chain (if they ever get there).
",Iain,https://serverfault.com/users/9517,http://serverfault.com/questions/314086,TECHNOLOGY,serverfault.com,0.7777777777777778,0.4444444444444444,0.0,1.0,1.0,1.0,0.5555555555555556,0.5555555555555556,0.6666666666666666,0.0,0.0,0.3333333333333333,0.0,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,1.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.3333333333333333,0.0,1.0,0.8888888888888888,"Iptables-p forwarding down, good or bad?",Discard all forwarding packets bad? What are they used for? Why should I stop them or keep them open?,"The FORWARD chain is used to manage packets that are being routed through the machine. If the machine is a router then dropping all packets in the FORWARD chain would be bad. If it's not a router then you can drop packets in the FORWARD chain (if they ever get there).
"
1901,1901,3029,Can't ping host in OpenVPN Site-to-Site VPN,"My logs say that a connection has been established but I cant ping the host.

Here are my logs. 

Firewall 1 Logs:

May 24 10:42:57 openvpn[9163]: /etc/rc.filter_configure tun0 1500 1544 10.0.8.1 10.0.8.2 init  
May 24 10:42:57 openvpn[9163]: SIGTERM[hard,] received, process exiting  
May 24 10:42:59 openvpn[9742]: OpenVPN 2.0.6 i386-portbld-freebsd7.2 [SSL] [LZO] built on Dec 4 2009  
May 24 10:42:59 openvpn[9742]: WARNING: file '/var/etc/openvpn_server0.key' is group or others accessible  
May 24 10:42:59 openvpn[9742]: gw 112.202.0.1  
May 24 10:42:59 openvpn[9742]: TUN/TAP device /dev/tun0 opened  
May 24 10:42:59 openvpn[9742]: /sbin/ifconfig tun0 10.0.8.1 10.0.8.2 mtu 1500 netmask 255.255.255.255 up  
May 24 10:42:59 openvpn[9742]: /etc/rc.filter_configure tun0 1500 1544 10.0.8.1 10.0.8.2 init  
May 24 10:43:00 openvpn[9757]: Listening for incoming TCP connection on [undef]:1194  
May 24 10:43:00 openvpn[9757]: TCPv4_SERVER link local (bound): [undef]:1194  
May 24 10:43:00 openvpn[9757]: TCPv4_SERVER link remote: [undef]  
May 24 10:43:00 openvpn[9757]: Initialization Sequence Completed  
May 24 10:43:02 openvpn[9757]: Re-using SSL/TLS context  
May 24 10:43:02 openvpn[9757]: LZO compression initialized  
May 24 10:43:02 openvpn[9757]: TCP connection established with 119.93.150.4:47750  
May 24 10:43:02 openvpn[9757]: TCPv4_SERVER link local: [undef]  
May 24 10:43:02 openvpn[9757]: TCPv4_SERVER link remote: 119.93.150.4:47750  
May 24 10:43:06 openvpn[9757]: 119.93.150.4:47750 [client] Peer Connection Initiated with 119.93.150.4:47750  


Firewall 2 Logs:

May 24 10:42:57 openvpn[7489]: Connection reset, restarting [0]  
May 24 10:42:57 openvpn[7489]: SIGUSR1[soft,connection-reset] received, process restarting  
May 24 10:43:02 openvpn[7489]: WARNING: No server certificate verification method has been enabled. See http://openvpn.net/howto.html#mitm for more info.  
May 24 10:43:02 openvpn[7489]: Re-using SSL/TLS context  
May 24 10:43:02 openvpn[7489]: LZO compression initialized  
May 24 10:43:02 openvpn[7489]: Attempting to establish TCP connection with 112.202.103.45:1194  
May 24 10:43:02 openvpn[7489]: TCP connection established with 112.202.103.45:1194  
May 24 10:43:02 openvpn[7489]: TCPv4_CLIENT link local: [undef]  
May 24 10:43:02 openvpn[7489]: TCPv4_CLIENT link remote: 112.202.103.45:1194  
May 24 10:43:06 openvpn[7489]: [server] Peer Connection Initiated with 112.202.103.45:1194  
May 24 10:43:08 openvpn[7489]: Options error: Unrecognized option or missing parameter(s) in [PUSH-OPTIONS]:1: 112.202.103.45 (2.0.6)  
May 24 10:43:08 openvpn[7489]: Preserving previous TUN/TAP instance: tun0  
May 24 10:43:08 openvpn[7489]: Initialization Sequence Completed  


What could the problem be?
",vrynxzent,https://serverfault.com/users/82348,"It appears that even though you seem to have a ""push"" option in the config file for firewall2, there is a syntactical problem with it:

May 24 10:43:08 openvpn[7489]: Options error: Unrecognized option or missing parameter(s) in [PUSH-OPTIONS]:1: 112.202.103.45 (2.0.6)


Once this is fixed, you should have routing through the tunnel, which will give firewall2 access to machines on the other end of the tunnel.
",wolfgangsz,https://serverfault.com/users/17621,http://serverfault.com/questions/273101,TECHNOLOGY,serverfault.com,0.3333333333333333,0.6666666666666666,0.0,0.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,0.8333333333333334,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,1.0,Unable to Ping OpenVPN site to host in site VPN,"My logs say that a connection has been established but I cant ping the host.

Here are my logs. 

Firewall 1 Logs:

May 24 10:42:57 openvpn[9163]: /etc/rc.filter_configure tun0 1500 1544 10.0.8.1 10.0.8.2 init  
May 24 10:42:57 openvpn[9163]: SIGTERM[hard,] received, process exiting  
May 24 10:42:59 openvpn[9742]: OpenVPN 2.0.6 i386-portbld-freebsd7.2 [SSL] [LZO] built on Dec 4 2009  
May 24 10:42:59 openvpn[9742]: WARNING: file '/var/etc/openvpn_server0.key' is group or others accessible  
May 24 10:42:59 openvpn[9742]: gw 112.202.0.1  
May 24 10:42:59 openvpn[9742]: TUN/TAP device /dev/tun0 opened  
May 24 10:42:59 openvpn[9742]: /sbin/ifconfig tun0 10.0.8.1 10.0.8.2 mtu 1500 netmask 255.255.255.255 up  
May 24 10:42:59 openvpn[9742]: /etc/rc.filter_configure tun0 1500 1544 10.0.8.1 10.0.8.2 init  
May 24 10:43:00 openvpn[9757]: Listening for incoming TCP connection on [undef]:1194  
May 24 10:43:00 openvpn[9757]: TCPv4_SERVER link local (bound): [undef]:1194  
May 24 10:43:00 openvpn[9757]: TCPv4_SERVER link remote: [undef]  
May 24 10:43:00 openvpn[9757]: Initialization Sequence Completed  
May 24 10:43:02 openvpn[9757]: Re-using SSL/TLS context  
May 24 10:43:02 openvpn[9757]: LZO compression initialized  
May 24 10:43:02 openvpn[9757]: TCP connection established with 119.93.150.4:47750  
May 24 10:43:02 openvpn[9757]: TCPv4_SERVER link local: [undef]  
May 24 10:43:02 openvpn[9757]: TCPv4_SERVER link remote: 119.93.150.4:47750  
May 24 10:43:06 openvpn[9757]: 119.93.150.4:47750 [client] Peer Connection Initiated with 119.93.150.4:47750  


Firewall 2 Logs:

May 24 10:42:57 openvpn[7489]: Connection reset, restarting [0]  
May 24 10:42:57 openvpn[7489]: SIGUSR1[soft,connection-reset] received, process restarting  
May 24 10:43:02 openvpn[7489]: WARNING: No server certificate verification method has been enabled. See http://openvpn.net/howto.html#mitm for more info.  
May 24 10:43:02 openvpn[7489]: Re-using SSL/TLS context  
May 24 10:43:02 openvpn[7489]: LZO compression initialized  
May 24 10:43:02 openvpn[7489]: Attempting to establish TCP connection with 112.202.103.45:1194  
May 24 10:43:02 openvpn[7489]: TCP connection established with 112.202.103.45:1194  
May 24 10:43:02 openvpn[7489]: TCPv4_CLIENT link local: [undef]  
May 24 10:43:02 openvpn[7489]: TCPv4_CLIENT link remote: 112.202.103.45:1194  
May 24 10:43:06 openvpn[7489]: [server] Peer Connection Initiated with 112.202.103.45:1194  
May 24 10:43:08 openvpn[7489]: Options error: Unrecognized option or missing parameter(s) in [PUSH-OPTIONS]:1: 112.202.103.45 (2.0.6)  
May 24 10:43:08 openvpn[7489]: Preserving previous TUN/TAP instance: tun0  
May 24 10:43:08 openvpn[7489]: Initialization Sequence Completed  


What could the problem be?
","It appears that even though you seem to have a ""push"" option in the config file for firewall2, there is a syntactical problem with it:

May 24 10:43:08 openvpn[7489]: Options error: Unrecognized option or missing parameter(s) in [PUSH-OPTIONS]:1: 112.202.103.45 (2.0.6)


Once this is fixed, you should have routing through the tunnel, which will give firewall2 access to machines on the other end of the tunnel.
"
390,390,612,How to load a properties file in java without calling laod method separately,"How to load a properties file in java without calling laod method separately
i want to load the file while instantiation of the properties object itself. 
like i have pasted below but i am not able to succeed in it.

class test{
Properties configFile = new Properties(load(new FileInputStream(""config.properties""));
}

",sarsarahman,https://stackoverflow.com/users/1078960,"Just create a separate method to do that - potentially in a helper class you can use elsewhere:

public class PropertiesHelper {
    public static Properties loadFromFile(String file) throws IOException {
        Properties properties = new Properties();
        FileInputStream stream = new FileInputStream(file);
        try {
            properties.load(stream);
        } finally {
            stream.close();
        }
        return properties;
    }
}


Note that due to the possibility of an IOException, you'll still need to be careful where you call this from. If you want to use it in an instance initializer, you'll need to declare that all of your constructors can throw IOException.
",Jon Skeet,https://stackoverflow.com/users/22656,http://stackoverflow.com/questions/10269112/how-to-load-a-properties-file-in-java-without-calling-laod-method-separately,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.7777777777777778,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,1.0,How to load the property file in Java without calling the law method alone,"How to load a properties file in java without calling laod method separately
i want to load the file while instantiation of the properties object itself. 
like i have pasted below but i am not able to succeed in it.

class test{
Properties configFile = new Properties(load(new FileInputStream(""config.properties""));
}

","Just create a separate method to do that - potentially in a helper class you can use elsewhere:

public class PropertiesHelper {
    public static Properties loadFromFile(String file) throws IOException {
        Properties properties = new Properties();
        FileInputStream stream = new FileInputStream(file);
        try {
            properties.load(stream);
        } finally {
            stream.close();
        }
        return properties;
    }
}


Note that due to the possibility of an IOException, you'll still need to be careful where you call this from. If you want to use it in an instance initializer, you'll need to declare that all of your constructors can throw IOException.
"
5360,5360,8511,Determining sample size for a comparative study involving two unequal groups,"I will like to know the formula for calculating the minimum sample size required for a comparative study involving 2 groups with unequal size. Group 1 is 10 times greater than group 2.
",Ehizele,https://stats.stackexchange.com/users/30970,"The answer is 11.  Given that the size of the first group is 10 times the size of the second, 11 is the smallest possible sample size that includes at least one observation.  Now, you might say that this is ridiculous, but it turns out that a single observation is adequate for updating your prior beliefs, supposing that you are a Bayesian.

Given that you are almost certainly not a Bayesian, one might ask the following type of question:  What is the smallest sample size needed to reject the null hypothesis at least $x\%$ of the time if we assume that the true difference between groups is at least $y$ and we assume that the distribution of the response variable is $z$?

Specifying $x$, $y$, and $z$ is the first step towards getting the answer you seem to be seeking. 
",zkurtz,https://stats.stackexchange.com/users/27765,http://stats.stackexchange.com/questions/71690/determining-sample-size-for-a-comparative-study-involving-two-unequal-groups,SCIENCE,stats.stackexchange.com,0.8888888888888888,0.6666666666666666,0.0,0.6666666666666666,0.6666666666666666,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.3333333333333333,0.0,0.6666666666666666,0.8888888888888888,0.7777777777777778,1.0,0.8888888888888888,0.8,0.0,0.0,1.0,0.8888888888888888,Determination of sample size in comparative study of two unequal groups,I would like to know the formula for calculating the minimum sample size required for two groups of comparative studies of different sizes. The first group was 10 times larger than the second.,"The answer is 11.  Given that the size of the first group is 10 times the size of the second, 11 is the smallest possible sample size that includes at least one observation.  Now, you might say that this is ridiculous, but it turns out that a single observation is adequate for updating your prior beliefs, supposing that you are a Bayesian.

Given that you are almost certainly not a Bayesian, one might ask the following type of question:  What is the smallest sample size needed to reject the null hypothesis at least $x\%$ of the time if we assume that the true difference between groups is at least $y$ and we assume that the distribution of the response variable is $z$?

Specifying $x$, $y$, and $z$ is the first step towards getting the answer you seem to be seeking. 
"
910,910,1443,Is the Mechromancer's Little Big Trouble tree worthwhile in UVHM (72 level cap)?,"So far, the tree seems rather underwhelming, especially the low-tier skills like Myelin, More Pep, Strength of 5 gorillas, etc.

Evil Enchantress apparently doesn't affect shock, fire and acid direct damage; it only buffs the status effects which is pretty pointless when slagging an enemy does 3X damage.

Shock storm doesn't sound useful as most enemies won't be bunched up enough.

On the other hand, the damage buffs from Wires Don't Talk and Interspersed Outburst look very useful. Make it Sparkle also apparently gives Deathtrap massive additional damage of up to 3X.

Is it worthwhile to spec into this tree just for the end-tier perks?
",Twilight Sparkle,https://gaming.stackexchange.com/users/54882,"http://forums.gearboxsoftware.com/showthread.php?t=322489
I highly recommend that you read over this post on the official BL2 forums.  It's titled ""Gaige's skill tree and general deficiencies"" or something along those lines, and it's a well thought out post that provides examples and math for the skills.  Furthermore, it is written and discussed by people who are very experienced Mechromancer players.  The op is an active member of the Mechromancer section of the BL2 forums. 

I hope the link helps, but if you don't want to bother with it the short answer is that, excepting Evil Enchantress and Electrical Burn  (I think those are the right names), the LBT tree has lots of problems and can be a waste of skill points. 

I would also highly recommend using shotguns if you're specced into Anarchy.  Slow Hand (from Badassasaurus in the Toruge Campaign of Carnage DLC ), Is a Moxxie weapon, and will heal you for around 3% of ~ANY~ damage done while it's equipped.  That's a very good suggestion from  Ben Brocka.  I would further add that the Twister shotgun is also good with Anarchy, as the fixed firing pattern helps negate the accuracy debuff.   It's dropped in the Hammerlock's Hunt DLC.  By Rouge, a large crysalisk.  
",Lypreila,https://gaming.stackexchange.com/users/66045,http://gaming.stackexchange.com/questions/149664/is-the-mechromancers-little-big-trouble-tree-worthwhile-in-uvhm-72-level-cap,CULTURE,gaming.stackexchange.com,0.7777777777777778,0.6666666666666666,0.6666666666666666,0.0,0.3333333333333333,0.5,0.7777777777777778,0.5555555555555556,0.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.7777777777777778,0.8888888888888888,0.7777777777777778,0.8888888888888888,0.8888888888888888,0.8,0.3333333333333333,0.3333333333333333,1.0,0.8888888888888888,Is the machinist's little trouble tree worth it in the uvhm?,"So far, the tree seems rather underwhelming, especially the low-tier skills like Myelin, More Pep, Strength of 5 gorillas, etc.

Evil Enchantress apparently doesn't affect shock, fire and acid direct damage; it only buffs the status effects which is pretty pointless when slagging an enemy does 3X damage.

Shock storm doesn't sound useful as most enemies won't be bunched up enough.

On the other hand, the damage buffs from Wires Don't Talk and Interspersed Outburst look very useful. Make it Sparkle also apparently gives Deathtrap massive additional damage of up to 3X.

Is it worthwhile to spec into this tree just for the end-tier perks?
","http://forums.gearboxsoftware.com/showthread.php?t=322489
I highly recommend that you read over this post on the official BL2 forums.  It's titled ""Gaige's skill tree and general deficiencies"" or something along those lines, and it's a well thought out post that provides examples and math for the skills.  Furthermore, it is written and discussed by people who are very experienced Mechromancer players.  The op is an active member of the Mechromancer section of the BL2 forums. 

I hope the link helps, but if you don't want to bother with it the short answer is that, excepting Evil Enchantress and Electrical Burn  (I think those are the right names), the LBT tree has lots of problems and can be a waste of skill points. 

I would also highly recommend using shotguns if you're specced into Anarchy.  Slow Hand (from Badassasaurus in the Toruge Campaign of Carnage DLC ), Is a Moxxie weapon, and will heal you for around 3% of ~ANY~ damage done while it's equipped.  That's a very good suggestion from  Ben Brocka.  I would further add that the Twister shotgun is also good with Anarchy, as the fixed firing pattern helps negate the accuracy debuff.   It's dropped in the Hammerlock's Hunt DLC.  By Rouge, a large crysalisk.  
"
3366,3366,5371,How to load a properties file in java without calling laod method separately,"How to load a properties file in java without calling laod method separately
i want to load the file while instantiation of the properties object itself. 
like i have pasted below but i am not able to succeed in it.

class test{
Properties configFile = new Properties(load(new FileInputStream(""config.properties""));
}

",sarsarahman,https://stackoverflow.com/users/1078960,"Something along the lines of this:

class Test {
    Properties configFile = new Properties() {{ load(new FileInputStream(""config.properties"")); }};
}


You are actually sub classing Properties here and using its initialization section. 
load(..) might throw an Exception if so you would need to add a try { ... } catch () {}
",Mattias Isegran Bergander,https://stackoverflow.com/users/1007169,http://stackoverflow.com/questions/10269112/how-to-load-a-properties-file-in-java-without-calling-laod-method-separately,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.8888888888888888,0.0,1.0,0.6666666666666666,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.8,1.0,0.0,0.0,0.8888888888888888,How to load the property file in Java without calling the law method alone,"How to load a properties file in java without calling laod method separately
i want to load the file while instantiation of the properties object itself. 
like i have pasted below but i am not able to succeed in it.

class test{
Properties configFile = new Properties(load(new FileInputStream(""config.properties""));
}

","Something along the lines of this:

class Test {
    Properties configFile = new Properties() {{ load(new FileInputStream(""config.properties"")); }};
}


You are actually sub classing Properties here and using its initialization section. 
load(..) might throw an Exception if so you would need to add a try { ... } catch () {}
"
385,385,607,FIPS 140 compliance for encrypted files,"Does FIPS 140-2 require specific key sizes, or does it have specific requirements for the data?
In other words, if I encrypt a file, how I can check whether it is FIPS-compliant or not? Does only the key need to be checked, or does the encrypted file have to be checked too? If yes, is it possible to elaborate on how to check an encrypted file for FIPS compliance?
",user39576,https://crypto.stackexchange.com/users/2854,"FIPS 140-2 only certifies cryptographic modules, not entire systems. So, to tell if your system is 140-2 compliant, it must be using a 140-2 certified module. NIST publishes a list of all FIPS 140-2 certified cryptographic modules.

It is important to remember, though, that 140-2 certification does not certify that the module is used in a secure manner. From the FIPS 140-2 document:


  Similarly, the use of a validated cryptographic module in a computer or telecommunications system is not sufficient to ensure the security of the overall system.


Looking over the document, I don't see anything on specific key sizes. It discusses key management, including key storage. So you'd have to make sure keys are stored properly. I don't see anything in the document about requirements on the data which is to be encrypted. That makes sense though as you would want your module to be data agnostic.

So, there is no way to look at an encrypted file and tell if it is FIPS 140-2 compliant. You would have to look at the module that did the encrypting.
",mikeazo,https://crypto.stackexchange.com/users/706,http://crypto.stackexchange.com/questions/5743/fips-140-compliance-for-encrypted-files,TECHNOLOGY,crypto.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.4444444444444444,1.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8,0.6666666666666666,0.0,1.0,1.0,FIPS 140 compliant encrypted files,"Does FIPS 140-2 require specific key sizes, or does it have specific requirements for the data?
In other words, if I encrypt a file, how I can check whether it is FIPS-compliant or not? Does only the key need to be checked, or does the encrypted file have to be checked too? If yes, is it possible to elaborate on how to check an encrypted file for FIPS compliance?
","FIPS 140-2 only certifies cryptographic modules, not entire systems. So, to tell if your system is 140-2 compliant, it must be using a 140-2 certified module. NIST publishes a list of all FIPS 140-2 certified cryptographic modules.

It is important to remember, though, that 140-2 certification does not certify that the module is used in a secure manner. From the FIPS 140-2 document:


  Similarly, the use of a validated cryptographic module in a computer or telecommunications system is not sufficient to ensure the security of the overall system.


Looking over the document, I don't see anything on specific key sizes. It discusses key management, including key storage. So you'd have to make sure keys are stored properly. I don't see anything in the document about requirements on the data which is to be encrypted. That makes sense though as you would want your module to be data agnostic.

So, there is no way to look at an encrypted file and tell if it is FIPS 140-2 compliant. You would have to look at the module that did the encrypting.
"
433,433,673,Does Windows XP Mode require its separate serial/license?,"I just did a Windows Anytime Upgrade from Home to Ultimate. Which to my surprise was very quick and smooth. Anyways, I want to install Windows XP Mode to help with answering questions related to Windows XP on Super User and other Stack Exchange sites. 

Before I download the 500MB file from Microsoft's site, I want to know if it prompts for a serial number? If it does, do I need to buy a Windows XP license? If doesn't require a new license but still require a serial number, do I use the Windows 7 Anytime Update from Home to Ultimate key?
",SgtOJ,https://superuser.com/users/20433,"No serial prompt at all assuming you have a valid copy of Windows 7. You will be prompted for genuine Windows 7 license validation when downloading.
",John T,https://superuser.com/users/1931,http://superuser.com/questions/218237,TECHNOLOGY,superuser.com,0.8888888888888888,0.6666666666666666,0.0,1.0,1.0,1.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.5555555555555556,0.8888888888888888,0.8888888888888888,0.8666666666666666,0.0,0.3333333333333333,0.0,0.6666666666666666,Does Windows XP mode require a separate serial number / license?,"I just did a Windows Anytime Upgrade from Home to Ultimate. Which to my surprise was very quick and smooth. Anyways, I want to install Windows XP Mode to help with answering questions related to Windows XP on Super User and other Stack Exchange sites. 

Before I download the 500MB file from Microsoft's site, I want to know if it prompts for a serial number? If it does, do I need to buy a Windows XP license? If doesn't require a new license but still require a serial number, do I use the Windows 7 Anytime Update from Home to Ultimate key?
","No serial prompt at all assuming you have a valid copy of Windows 7. You will be prompted for genuine Windows 7 license validation when downloading.
"
2519,2519,4019,Elegant way of sending e-mails with Service Broker,"Is there an elegant way for sending e-mails using a Service Broker service/queue?

I want to setup an EVENT NOTIFICATION for SQL Server, and I'd like to send e-mails to operators for each message on the queue.

According to the book SQL Server 2005 DBA Street Smarts: A Real World Guide to SQL Server 2005 Certification Skills, Database Mail uses the Service Broker:


  Additionaly, Database Mail is scalable because it uses the Service Broker queue, which allows the requests to be handled asynchronously and even saves the request if the server goes down before it can be handled.


Maybe I'm too off base here, but, is there a way I can send messages directly to the Database Mail queue using Service Broker?

If I have to set up a stored procedure for sending an e-mail on behalf of Service Broker, I think it should be easier to just setup a job on the SQL Server Agent to check for the events I'm interested in inside the error log and send the operators an e-mail.

I'm open to suggestions.
",ivanmp,https://dba.stackexchange.com/users/3460,"
  is there a way I can send messages directly to the Database Mail queue using Service Broker


When you invoke sp_send_dbmail that is exactly what is happening.


  I want to setup an EVENT NOTIFICATION for SQL Server, and I'd like to
  send e-mails to operators for each message on the queue


Then do just that. Create an activated stored procedure on the queue of your service that receives the notifications and have it RECEIVE the message and invokes sp_send_dbmail. 

I think you are trying to 'cut out the middleman' and have the EVENT NOTIFICATION send the notification directly to the DB Mail queue. That is not possible because the code that handles the messages arriving in the DB Mail queue expects the messages to have a certain format (ie. the one created by sp_send_dbmail). The messages sent by Event Notifications would have a completely different format and the DB Mail processor would choke as it does not understand them. In order to prevent exactly such situation Service Broker services are bound to specific contracts and DB Mail service does not accept the http://schemas.microsoft.com/SQL/Notifications/PostEventNotification contract used by Event Notifications.
",Remus Rusanu,https://dba.stackexchange.com/users/708,http://dba.stackexchange.com/questions/15613/elegant-way-of-sending-e-mails-with-service-broker,TECHNOLOGY,dba.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,0.0,1.0,0.0,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.7777777777777778,0.6666666666666666,0.5555555555555556,0.6666666666666666,0.8888888888888888,0.6,0.6666666666666666,0.3333333333333333,1.0,0.6666666666666666,Elegant way to send email using service broker,"Is there an elegant way for sending e-mails using a Service Broker service/queue?

I want to setup an EVENT NOTIFICATION for SQL Server, and I'd like to send e-mails to operators for each message on the queue.

According to the book SQL Server 2005 DBA Street Smarts: A Real World Guide to SQL Server 2005 Certification Skills, Database Mail uses the Service Broker:


  Additionaly, Database Mail is scalable because it uses the Service Broker queue, which allows the requests to be handled asynchronously and even saves the request if the server goes down before it can be handled.


Maybe I'm too off base here, but, is there a way I can send messages directly to the Database Mail queue using Service Broker?

If I have to set up a stored procedure for sending an e-mail on behalf of Service Broker, I think it should be easier to just setup a job on the SQL Server Agent to check for the events I'm interested in inside the error log and send the operators an e-mail.

I'm open to suggestions.
","
  is there a way I can send messages directly to the Database Mail queue using Service Broker


When you invoke sp_send_dbmail that is exactly what is happening.


  I want to setup an EVENT NOTIFICATION for SQL Server, and I'd like to
  send e-mails to operators for each message on the queue


Then do just that. Create an activated stored procedure on the queue of your service that receives the notifications and have it RECEIVE the message and invokes sp_send_dbmail. 

I think you are trying to 'cut out the middleman' and have the EVENT NOTIFICATION send the notification directly to the DB Mail queue. That is not possible because the code that handles the messages arriving in the DB Mail queue expects the messages to have a certain format (ie. the one created by sp_send_dbmail). The messages sent by Event Notifications would have a completely different format and the DB Mail processor would choke as it does not understand them. In order to prevent exactly such situation Service Broker services are bound to specific contracts and DB Mail service does not accept the http://schemas.microsoft.com/SQL/Notifications/PostEventNotification contract used by Event Notifications.
"
2624,2624,4172,How do I reference (what is the syntax I have to use) to get the data of my Profile2 custom fields?,"I have used the Profile2 module (D7) and created some custom fields for my users. One of those fields (for example) is ""field_company"" with the label ""Company.""

Now I am using a computed field (Company) on a content type (Games). When user creates a Game, I want my computed field Company to be computed/populated automatically, based on the ""field_company"" field I have set in my profile2. 

I am trying to find how to get that information. This is as far I got, so far, but it doesn't work. 

$entity_field[0]['value'] = """";
$name=$profile2-&gt;field_onoma[LANGUAGE_NONE][0]['value']; 
$entity_field[0]['value'] = $name;

",Achilles,https://drupal.stackexchange.com/users/4296,"drupal_set_message('&lt;pre&gt;' . print_r($profile2,true) . '&lt;/pre&gt;');


or changing $profile2 to whatever variable is in your code you want described is a great way of seeing what's going on...
",Jimajamma,https://drupal.stackexchange.com/users/4255,http://drupal.stackexchange.com/questions/16582/how-do-i-reference-what-is-the-syntax-i-have-to-use-to-get-the-data-of-my-prof,TECHNOLOGY,drupal.stackexchange.com,1.0,0.5555555555555556,0.0,1.0,1.0,1.0,0.5555555555555556,0.5555555555555556,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.8,0.6666666666666666,0.3333333333333333,0.0,0.7777777777777778,How do I reference (what syntax do I need) to get the data for the profile2 custom field?,"I have used the Profile2 module (D7) and created some custom fields for my users. One of those fields (for example) is ""field_company"" with the label ""Company.""

Now I am using a computed field (Company) on a content type (Games). When user creates a Game, I want my computed field Company to be computed/populated automatically, based on the ""field_company"" field I have set in my profile2. 

I am trying to find how to get that information. This is as far I got, so far, but it doesn't work. 

$entity_field[0]['value'] = """";
$name=$profile2-&gt;field_onoma[LANGUAGE_NONE][0]['value']; 
$entity_field[0]['value'] = $name;

","drupal_set_message('&lt;pre&gt;' . print_r($profile2,true) . '&lt;/pre&gt;');


or changing $profile2 to whatever variable is in your code you want described is a great way of seeing what's going on...
"
2637,2637,4194,Using video ports 'backwards',"If I want to connect my laptop, which has a VGA output, to a monitor, I plug a VGA cable into both ends. The output being my laptop, and the input the monitor

VGA output sockets are the same as VGA input sockets however, so what if I want to use my laptop as the monitor, with the video being outputted from somewhere else?

As I said, VGA's output is the same as input, so in theory, I have the hardware in my laptop to do this. But presumably I need some software.

So can I use the VGA port on a laptop as a video input?

(And also, can this be done with HDMI?)
",ACarter,https://superuser.com/users/167983,"Your video adapter is an output device.  just because the ports are the same/similar doesn't automatically mean they are wired, or work the same.

If you want video in, you need a video capture adapter.
",Ƭᴇcʜιᴇ007,https://superuser.com/users/23133,http://superuser.com/questions/510358,TECHNOLOGY,superuser.com,1.0,0.3333333333333333,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,0.6666666666666666,1.0,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.3333333333333333,0.3333333333333333,1.0,0.8888888888888888,Use video port backward,"If I want to connect my laptop, which has a VGA output, to a monitor, I plug a VGA cable into both ends. The output being my laptop, and the input the monitor

VGA output sockets are the same as VGA input sockets however, so what if I want to use my laptop as the monitor, with the video being outputted from somewhere else?

As I said, VGA's output is the same as input, so in theory, I have the hardware in my laptop to do this. But presumably I need some software.

So can I use the VGA port on a laptop as a video input?

(And also, can this be done with HDMI?)
","Your video adapter is an output device.  just because the ports are the same/similar doesn't automatically mean they are wired, or work the same.

If you want video in, you need a video capture adapter.
"
5826,5826,9232,Why does Wizards of the Coast print terrible MTG cards?,"I understand that there needs to be a wide variety of power levels in Magic: The Gathering. Even bad cards will see play in limited formats, some because they fill a specific niche (flying removal, fat colorless flyer, providing a counter to certain decks), and others because those decks can't afford to be too picky. However, some cards are just unforgivably terrible. I'm talking about cards that you would only run in sealed if you had absolutely no other options:

Mindless Null: Black 2/2 for 3 with a big disadvantage

Defensive Stance: literally does nothing in exchange for you getting card disadvantage 

Merfolk of the Depths: Would still be bad if it only costed 5...

Archangel's Light: 8 mana just to gain some life and put cheap cards back into your deck. And it's a mythic rare....

There are many more examples, but I think these best illustrate my case. Obviously I'd rather have these cards in the game than not have them at all, but I feel like Wizards of the Coast could have made Magic a more enjoyable game just by keeping the flavor and making all of these cards a tiny bit better...yet they didn't. Why?
",Gordon Gustafson,https://boardgames.stackexchange.com/users/191,"Tom LaPille, When Cards Go Bad, Part 2, a followup to the first When Good Cards Go Bad article thesunneversets linked, has a few more points that haven't been fully explored yet.

Some cards aren't fun when they're good.

Here he uses the example of Scrambleverse, which has really cumbersome and complicated mechanics, explaining that it is costed very high so that it doesn't get played often. The only people that play it are the people that really want to.

Limited needs to be balanced.

I think Limited play is the biggest reason there are ""bad"" cards in modern MtG. From the article:


  …there was a meeting when both blue and black were doing much better than we wanted in our playtests. Lead developer Aaron Forsythe decreed that we needed a weak blue card and a weak black card. None of us came up with a blue card that was weak enough, so Aaron created Defensive Stance to fill the hole.


So while Defensive Stance does have some narrow infect-hosing mechanic, it was basically created just to keep blue drafters in New Phyrexia in check.

Draft needs to be human-processable.


  Drafting is a complex enough task already without every card being extremely close together in power, so we include plenty of cards of widely differing power levels so that the right answer can be a little bit less ambiguous. This doesn't simplify the task of correctly identifying those power levels—a challenging task in itself!—but it does make deciding between correctly-identified power levels a little bit easier.


Imagine if every card in a pack had the same power-level. I have a hard enough time deciding between two or three similar power-level cards in a draft. If all cards had a similar power level, each decision becomes stressful and agonizing. Drafts would slow to a crawl. If there are some ""last pick"" cards and definite common ""bombs"", it makes the draft a bit more smooth and manageable.  
",ghoppe,https://boardgames.stackexchange.com/users/632,http://boardgames.stackexchange.com/questions/11473/why-does-wizards-of-the-coast-print-terrible-mtg-cards,CULTURE,boardgames.stackexchange.com,0.7777777777777778,0.7777777777777778,0.3333333333333333,1.0,0.3333333333333333,1.0,0.8888888888888888,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.7777777777777778,1.0,0.8333333333333334,1.0,1.0,0.9333333333333332,0.3333333333333333,0.0,1.0,0.8888888888888888,Why do wizards along the coast print bad MTG cards?,"I understand that there needs to be a wide variety of power levels in Magic: The Gathering. Even bad cards will see play in limited formats, some because they fill a specific niche (flying removal, fat colorless flyer, providing a counter to certain decks), and others because those decks can't afford to be too picky. However, some cards are just unforgivably terrible. I'm talking about cards that you would only run in sealed if you had absolutely no other options:

Mindless Null: Black 2/2 for 3 with a big disadvantage

Defensive Stance: literally does nothing in exchange for you getting card disadvantage 

Merfolk of the Depths: Would still be bad if it only costed 5...

Archangel's Light: 8 mana just to gain some life and put cheap cards back into your deck. And it's a mythic rare....

There are many more examples, but I think these best illustrate my case. Obviously I'd rather have these cards in the game than not have them at all, but I feel like Wizards of the Coast could have made Magic a more enjoyable game just by keeping the flavor and making all of these cards a tiny bit better...yet they didn't. Why?
","Tom LaPille, When Cards Go Bad, Part 2, a followup to the first When Good Cards Go Bad article thesunneversets linked, has a few more points that haven't been fully explored yet.

Some cards aren't fun when they're good.

Here he uses the example of Scrambleverse, which has really cumbersome and complicated mechanics, explaining that it is costed very high so that it doesn't get played often. The only people that play it are the people that really want to.

Limited needs to be balanced.

I think Limited play is the biggest reason there are ""bad"" cards in modern MtG. From the article:


  …there was a meeting when both blue and black were doing much better than we wanted in our playtests. Lead developer Aaron Forsythe decreed that we needed a weak blue card and a weak black card. None of us came up with a blue card that was weak enough, so Aaron created Defensive Stance to fill the hole.


So while Defensive Stance does have some narrow infect-hosing mechanic, it was basically created just to keep blue drafters in New Phyrexia in check.

Draft needs to be human-processable.


  Drafting is a complex enough task already without every card being extremely close together in power, so we include plenty of cards of widely differing power levels so that the right answer can be a little bit less ambiguous. This doesn't simplify the task of correctly identifying those power levels—a challenging task in itself!—but it does make deciding between correctly-identified power levels a little bit easier.


Imagine if every card in a pack had the same power-level. I have a hard enough time deciding between two or three similar power-level cards in a draft. If all cards had a similar power level, each decision becomes stressful and agonizing. Drafts would slow to a crawl. If there are some ""last pick"" cards and definite common ""bombs"", it makes the draft a bit more smooth and manageable.  
"
6056,6056,9612,Alternatives of 'a snowball's chance in hell',"I am looking for a different, common English idiom that expresses the same thing as a snowball's chance in hell.  My teacher says I use this expression too much, and that it is not appropriate for every essay. I need a same meaning like something very cold in a hot place to have a little chance.
",The Beefer Fan,https://english.stackexchange.com/users/83537,"'You've got two chances--slim and none...and Slim left town'.
",user3847,https://english.stackexchange.com/users/77520,http://english.stackexchange.com/questions/184377/alternatives-of-a-snowballs-chance-in-hell,CULTURE,english.stackexchange.com,1.0,1.0,0.3333333333333333,0.6666666666666666,0.0,0.6666666666666666,0.5555555555555556,0.7777777777777778,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.0,0.0,0.8888888888888888,"Alternative to ""snowball opportunity in hell""","I am looking for a different, common English idiom that expresses the same thing as snowball opportunities in hell. My teacher said that I used the word too much, not suitable for every article. I need a bit of opportunity for something that means the same, like being cold in a hot place.","""You have two chances - slim and no chance Slim left town."
1695,1695,2683,linq sql where closest to number,"i have a table

Id Number
1   9
2   10
3   12
4   19
5   20


select Id where Number is closest to 18
it should return row 4 which is 19

how do i write this in linq and tsql? thanks
",scrippie,https://stackoverflow.com/users/204579,"(from q in table
 orderby Math.Abs(18 - q.Number)
 select q).FirstOrDefault()


and

SELECT TOP 1
    *
FROM
    table
ORDER BY
    ABS(10 - Number)


and for a datetime

var nearTo = new DateTime(1999, 12, 31);
(from q in table
 orderby Math.Abs((nearTo - q.Date).TotalSeconds)
 select q).FirstOrDefault()

",John Gietzen,https://stackoverflow.com/users/57986,http://stackoverflow.com/questions/1705799/linq-sql-where-closest-to-number,STACKOVERFLOW,stackoverflow.com,1.0,0.3333333333333333,0.0,0.6666666666666666,0.3333333333333333,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.5555555555555556,1.0,0.5555555555555556,1.0,1.0,0.8,1.0,0.0,0.0,0.7777777777777778,LINQ SQL closest to number,"i have a table

Id Number
1   9
2   10
3   12
4   19
5   20


select Id where Number is closest to 18
it should return row 4 which is 19

how do i write this in linq and tsql? thanks
","(from q in table
 orderby Math.Abs(18 - q.Number)
 select q).FirstOrDefault()


and

SELECT TOP 1
    *
FROM
    table
ORDER BY
    ABS(10 - Number)


and for a datetime

var nearTo = new DateTime(1999, 12, 31);
(from q in table
 orderby Math.Abs((nearTo - q.Date).TotalSeconds)
 select q).FirstOrDefault()

"
5606,5606,8896,Create a table that fills a page with empty rows,"I'm trying to create an inventory sheet for our lab, and as such I need a large blank table. Is there a better way to do this then copy and pasting \midrule&amp;&amp;&amp;\\ over and over again?

I'd like to look like this, but automatically repeat the blank cells until the page is full:

%Page layout here
\documentclass[letterpaper, 12pt,twocolumn]{article}
\usepackage[left= 2 cm, right=2 cm, top = 2 cm, bottom = 2 cm]{geometry}

%Font stuff here
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}

%Goddamn tables.
\usepackage{booktabs} %Makes the pretty table based on wikibooks example

\begin{document}

\centering
{\large
\begin{tabular}{c|c|c|c}
\toprule
Date &amp; User &amp; Amount Used &amp; Procedure\\
\phantom{2015-3-17} &amp; \phantom{NAME} &amp; (mg) &amp;  \phantom{XXX3-33}\\
\midrule
&amp;&amp;&amp;\\
\midrule
&amp;&amp;&amp;\\
\midrule&amp;&amp;&amp;\\
\midrule&amp;&amp;&amp;\\
\midrule&amp;&amp;&amp;\\
\bottomrule
\end{tabular}
}
\end{document}


Note: I'm just using Booktabs to add the midrule, that can be dropped. This is just going on a clipboard on the wall, it can be ugly as you want. I'm just sick of fighting with Word's hellish layout tools. 

Edit: There is this answer that places blank lines in the middle, but I don't understand the code nearly enough to modify it to fill to the end of the page. 
",Canageek,https://tex.stackexchange.com/users/7880,"David Carlisle has gotten me most of the way to a solution, so I thought I'd post it:

%Page layout here
\documentclass[letterpaper, 12pt,twocolumn]{article}
\usepackage[left= 1 cm, right=1 cm, top = 2 cm, bottom = 1 cm]{geometry}

\newlength\linefillheight % vertical distance between lines
\setlength\linefillheight{1cm}

\newlength\wcolone %first column width
\setlength\wcolone{\dimexpr.125\textwidth-4mm\relax}
\newlength\wcoltwo %second column width
\setlength\wcoltwo{\dimexpr.125\textwidth-4mm\relax}
\newlength\wcolthree % third column width
\setlength\wcolthree{\dimexpr.125\textwidth-4mm\relax}
\newlength\wcolfour % third column width
\setlength\wcolfour{\dimexpr.125\textwidth-4mm\relax}

\newcommand\linefill{\leavevmode
    \rule{\wcolone}{0.4pt}\hspace*{4mm}\rule{\wcoltwo}{0.4pt}\hspace*{4mm}\rule{\wcolthree}{0.4pt}\hspace*{4mm}\rule{\wcolfour}{0.4pt}}

\makeatletter
\def\fillwithlines#1{%
  \begingroup
  \ifhmode
    \par
  \fi
  \hrule height 0pt
  \nobreak
  \cleaders\hbox to \hsize{\hskip \@totalleftmargin
          \vrule height \linefillheight depth 0pt width 0pt
          \linefill} \vskip #1 \hbox{}%
  \endgroup}
\makeatother


\begin{document}

\noindent\begin{minipage}[c][1cm][t]{\textwidth}
\parbox{\dimexpr\wcolone+4mm\relax}{\textbf{\centering Date}}%
\parbox{\dimexpr\wcoltwo+4mm\relax}{\textbf{\centering User}}%
\parbox{\dimexpr\wcoltwo+4mm\relax}{\textbf{\centering Amount Used\\mg}}%
\parbox{\dimexpr\wcoltwo+4mm\relax}{\textbf{\centering Procedure}}%
\end{minipage}

\fillwithlines{\dimexpr\textheight-1cm\relax}

\noindent\begin{minipage}[c][1cm][t]{\textwidth}
\parbox{\dimexpr\wcolone+4mm\relax}{\textbf{\centering Date}}%
\parbox{\dimexpr\wcoltwo+4mm\relax}{\textbf{\centering User}}%
\parbox{\dimexpr\wcoltwo+4mm\relax}{\textbf{\centering Amount Used\\mg}}%
\parbox{\dimexpr\wcoltwo+4mm\relax}{\textbf{\centering Procedure}}%
\end{minipage}

\fillwithlines{\dimexpr\textheight-1cm\relax}
\end{document}


Based on this answer. However, I'd like to be able to centre the column headers and draw a line down the middle, if anyone could help with this. 

some minor tweaks:

\documentclass[letterpaper, 12pt,twocolumn]{article}
\usepackage[left= 1 cm, right=1 cm, top = 2 cm, bottom = 1 cm]{geometry}

\newlength\linefillheight % vertical distance between lines
\setlength\linefillheight{1cm}

\newlength\wcolone %first column width
\setlength\wcolone{\dimexpr.125\textwidth-4mm-1.25pt\relax}
\newlength\wcoltwo %second column width
\setlength\wcoltwo{\dimexpr.125\textwidth-4mm-1.25pt\relax}
\newlength\wcolthree % third column width
\setlength\wcolthree{\dimexpr.125\textwidth-4mm-1.25pt\relax}
\newlength\wcolfour % third column width
\setlength\wcolfour{\dimexpr.125\textwidth-4mm-1.25pt\relax}

\newcommand\linefill{\leavevmode
    \rule{\wcolone}{0.4pt}\hspace*{4mm}\rule{\wcoltwo}{0.4pt}\hspace*{4mm}\rule{\wcolthree}{0.4pt}\hspace*{4mm}\rule{\wcolfour}{0.4pt}}

\makeatletter
\def\fillwithlines#1{%
  \begingroup
    \par
  \hrule height 0pt
  \nobreak
  \cleaders\hbox to \hsize{%
          \vrule height \linefillheight depth 0pt width 0pt
          \hss\linefill\hss} \vskip #1 \hbox{}%
  \endgroup}
\makeatother\showoutput

\setlength\columnseprule{1pt}

\begin{document}


\noindent\begin{minipage}[c][1cm][t]{\linewidth}
\parbox{\dimexpr\wcolone+4mm\relax}{\centering\textbf{Date}}%
\parbox{\dimexpr\wcoltwo+4mm\relax}{\centering\textbf{User}}%
\parbox{\dimexpr\wcoltwo+4mm\relax}{\centering\textbf{Amount Used\\mg}}%
\parbox{\dimexpr\wcoltwo+4mm\relax}{\centering\textbf{Procedure}}%
\end{minipage}

\fillwithlines{\dimexpr\textheight-1cm\relax}

\noindent\begin{minipage}[c][1cm][t]{\linewidth}
\parbox{\dimexpr\wcolone+4mm\relax}{\centering\textbf{Date}}%
\parbox{\dimexpr\wcoltwo+4mm\relax}{\centering\textbf{User}}%
\parbox{\dimexpr\wcoltwo+4mm\relax}{\centering\textbf{Amount Used\\mg}}%
\parbox{\dimexpr\wcoltwo+4mm\relax}{\centering\textbf{Procedure}}%
\end{minipage}

\fillwithlines{\dimexpr\textheight-1cm\relax}
\end{document}




In chat you said you wanted single column with 7 headings...

\documentclass[letterpaper, 12pt]{article}
\usepackage[left= 1 cm, right=1 cm, top = 2 cm, bottom = 1 cm]{geometry}

\newlength\linefillheight % vertical distance between lines
\setlength\linefillheight{1cm}
\usepackage[T1]{fontenc}

\newcommand\linefill{\hspace{\stretch{.5}}%
    \rule{.1\textwidth}{0.4pt}\hfill
    \rule{.1\textwidth}{0.4pt}\hfill
    \rule{.1\textwidth}{0.4pt}\hfill
    \rule{.1\textwidth}{0.4pt}\hfill
    \rule{.1\textwidth}{0.4pt}\hfill
    \rule{.1\textwidth}{0.4pt}\hfill
    \rule{.1\textwidth}{0.4pt}\hspace{\stretch{.5}}%
}

\makeatletter
\def\fillwithlines#1{%
  \begingroup
    \par
  \hrule height 0pt
  \nobreak
  \cleaders\hbox to \hsize{%
          \vrule height \linefillheight depth 0pt width 0pt
          \linefill} \vskip #1 \hbox{}%
  \endgroup}
\makeatother

\setlength\columnseprule{1pt}

\begin{document}


\noindent\begin{minipage}[c][1cm][t]{\linewidth}
\parbox[t]{\dimexpr\linewidth/7\relax}{\centering\textbf{Date}}%
\parbox[t]{\dimexpr\linewidth/7\relax}{\centering\textbf{User}}%
\parbox[t]{\dimexpr\linewidth/7\relax}{\centering\textbf{Amount Used\\mg}}%
\parbox[t]{\dimexpr\linewidth/7\relax}{\centering\textbf{Procedure}}%
\parbox[t]{\dimexpr\linewidth/7\relax}{\centering\textbf{User}}%
\parbox[t]{\dimexpr\linewidth/7\relax}{\centering\textbf{Amount Used\\mg}}%
\parbox[t]{\dimexpr\linewidth/7\relax}{\centering\textbf{Procedure}}%
\end{minipage}

\fillwithlines{\dimexpr\textheight-1cm\relax}
\end{document}

",Canageek,https://tex.stackexchange.com/users/7880,http://tex.stackexchange.com/questions/233700/create-a-table-that-fills-a-page-with-empty-rows,TECHNOLOGY,tex.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,0.3333333333333333,0.0,0.3333333333333333,0.0,0.0,0.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,0.8333333333333334,0.8,1.0,0.0,0.0,0.8333333333333334,Create a table with blank rows to fill the page,"I'm trying to create an inventory sheet for our lab, and as such I need a large blank table. Is there a better way to do this then copy and pasting \midrule&amp;&amp;&amp;\\ over and over again?

I'd like to look like this, but automatically repeat the blank cells until the page is full:

%Page layout here
\documentclass[letterpaper, 12pt,twocolumn]{article}
\usepackage[left= 2 cm, right=2 cm, top = 2 cm, bottom = 2 cm]{geometry}

%Font stuff here
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}

%Goddamn tables.
\usepackage{booktabs} %Makes the pretty table based on wikibooks example

\begin{document}

\centering
{\large
\begin{tabular}{c|c|c|c}
\toprule
Date &amp; User &amp; Amount Used &amp; Procedure\\
\phantom{2015-3-17} &amp; \phantom{NAME} &amp; (mg) &amp;  \phantom{XXX3-33}\\
\midrule
&amp;&amp;&amp;\\
\midrule
&amp;&amp;&amp;\\
\midrule&amp;&amp;&amp;\\
\midrule&amp;&amp;&amp;\\
\midrule&amp;&amp;&amp;\\
\bottomrule
\end{tabular}
}
\end{document}


Note: I'm just using Booktabs to add the midrule, that can be dropped. This is just going on a clipboard on the wall, it can be ugly as you want. I'm just sick of fighting with Word's hellish layout tools. 

Edit: There is this answer that places blank lines in the middle, but I don't understand the code nearly enough to modify it to fill to the end of the page. 
","David Carlisle has gotten me most of the way to a solution, so I thought I'd post it:

%Page layout here
\documentclass[letterpaper, 12pt,twocolumn]{article}
\usepackage[left= 1 cm, right=1 cm, top = 2 cm, bottom = 1 cm]{geometry}

\newlength\linefillheight % vertical distance between lines
\setlength\linefillheight{1cm}

\newlength\wcolone %first column width
\setlength\wcolone{\dimexpr.125\textwidth-4mm\relax}
\newlength\wcoltwo %second column width
\setlength\wcoltwo{\dimexpr.125\textwidth-4mm\relax}
\newlength\wcolthree % third column width
\setlength\wcolthree{\dimexpr.125\textwidth-4mm\relax}
\newlength\wcolfour % third column width
\setlength\wcolfour{\dimexpr.125\textwidth-4mm\relax}

\newcommand\linefill{\leavevmode
    \rule{\wcolone}{0.4pt}\hspace*{4mm}\rule{\wcoltwo}{0.4pt}\hspace*{4mm}\rule{\wcolthree}{0.4pt}\hspace*{4mm}\rule{\wcolfour}{0.4pt}}

\makeatletter
\def\fillwithlines#1{%
  \begingroup
  \ifhmode
    \par
  \fi
  \hrule height 0pt
  \nobreak
  \cleaders\hbox to \hsize{\hskip \@totalleftmargin
          \vrule height \linefillheight depth 0pt width 0pt
          \linefill} \vskip #1 \hbox{}%
  \endgroup}
\makeatother


\begin{document}

\noindent\begin{minipage}[c][1cm][t]{\textwidth}
\parbox{\dimexpr\wcolone+4mm\relax}{\textbf{\centering Date}}%
\parbox{\dimexpr\wcoltwo+4mm\relax}{\textbf{\centering User}}%
\parbox{\dimexpr\wcoltwo+4mm\relax}{\textbf{\centering Amount Used\\mg}}%
\parbox{\dimexpr\wcoltwo+4mm\relax}{\textbf{\centering Procedure}}%
\end{minipage}

\fillwithlines{\dimexpr\textheight-1cm\relax}

\noindent\begin{minipage}[c][1cm][t]{\textwidth}
\parbox{\dimexpr\wcolone+4mm\relax}{\textbf{\centering Date}}%
\parbox{\dimexpr\wcoltwo+4mm\relax}{\textbf{\centering User}}%
\parbox{\dimexpr\wcoltwo+4mm\relax}{\textbf{\centering Amount Used\\mg}}%
\parbox{\dimexpr\wcoltwo+4mm\relax}{\textbf{\centering Procedure}}%
\end{minipage}

\fillwithlines{\dimexpr\textheight-1cm\relax}
\end{document}


Based on this answer. However, I'd like to be able to centre the column headers and draw a line down the middle, if anyone could help with this. 

some minor tweaks:

\documentclass[letterpaper, 12pt,twocolumn]{article}
\usepackage[left= 1 cm, right=1 cm, top = 2 cm, bottom = 1 cm]{geometry}

\newlength\linefillheight % vertical distance between lines
\setlength\linefillheight{1cm}

\newlength\wcolone %first column width
\setlength\wcolone{\dimexpr.125\textwidth-4mm-1.25pt\relax}
\newlength\wcoltwo %second column width
\setlength\wcoltwo{\dimexpr.125\textwidth-4mm-1.25pt\relax}
\newlength\wcolthree % third column width
\setlength\wcolthree{\dimexpr.125\textwidth-4mm-1.25pt\relax}
\newlength\wcolfour % third column width
\setlength\wcolfour{\dimexpr.125\textwidth-4mm-1.25pt\relax}

\newcommand\linefill{\leavevmode
    \rule{\wcolone}{0.4pt}\hspace*{4mm}\rule{\wcoltwo}{0.4pt}\hspace*{4mm}\rule{\wcolthree}{0.4pt}\hspace*{4mm}\rule{\wcolfour}{0.4pt}}

\makeatletter
\def\fillwithlines#1{%
  \begingroup
    \par
  \hrule height 0pt
  \nobreak
  \cleaders\hbox to \hsize{%
          \vrule height \linefillheight depth 0pt width 0pt
          \hss\linefill\hss} \vskip #1 \hbox{}%
  \endgroup}
\makeatother\showoutput

\setlength\columnseprule{1pt}

\begin{document}


\noindent\begin{minipage}[c][1cm][t]{\linewidth}
\parbox{\dimexpr\wcolone+4mm\relax}{\centering\textbf{Date}}%
\parbox{\dimexpr\wcoltwo+4mm\relax}{\centering\textbf{User}}%
\parbox{\dimexpr\wcoltwo+4mm\relax}{\centering\textbf{Amount Used\\mg}}%
\parbox{\dimexpr\wcoltwo+4mm\relax}{\centering\textbf{Procedure}}%
\end{minipage}

\fillwithlines{\dimexpr\textheight-1cm\relax}

\noindent\begin{minipage}[c][1cm][t]{\linewidth}
\parbox{\dimexpr\wcolone+4mm\relax}{\centering\textbf{Date}}%
\parbox{\dimexpr\wcoltwo+4mm\relax}{\centering\textbf{User}}%
\parbox{\dimexpr\wcoltwo+4mm\relax}{\centering\textbf{Amount Used\\mg}}%
\parbox{\dimexpr\wcoltwo+4mm\relax}{\centering\textbf{Procedure}}%
\end{minipage}

\fillwithlines{\dimexpr\textheight-1cm\relax}
\end{document}




In chat you said you wanted single column with 7 headings...

\documentclass[letterpaper, 12pt]{article}
\usepackage[left= 1 cm, right=1 cm, top = 2 cm, bottom = 1 cm]{geometry}

\newlength\linefillheight % vertical distance between lines
\setlength\linefillheight{1cm}
\usepackage[T1]{fontenc}

\newcommand\linefill{\hspace{\stretch{.5}}%
    \rule{.1\textwidth}{0.4pt}\hfill
    \rule{.1\textwidth}{0.4pt}\hfill
    \rule{.1\textwidth}{0.4pt}\hfill
    \rule{.1\textwidth}{0.4pt}\hfill
    \rule{.1\textwidth}{0.4pt}\hfill
    \rule{.1\textwidth}{0.4pt}\hfill
    \rule{.1\textwidth}{0.4pt}\hspace{\stretch{.5}}%
}

\makeatletter
\def\fillwithlines#1{%
  \begingroup
    \par
  \hrule height 0pt
  \nobreak
  \cleaders\hbox to \hsize{%
          \vrule height \linefillheight depth 0pt width 0pt
          \linefill} \vskip #1 \hbox{}%
  \endgroup}
\makeatother

\setlength\columnseprule{1pt}

\begin{document}


\noindent\begin{minipage}[c][1cm][t]{\linewidth}
\parbox[t]{\dimexpr\linewidth/7\relax}{\centering\textbf{Date}}%
\parbox[t]{\dimexpr\linewidth/7\relax}{\centering\textbf{User}}%
\parbox[t]{\dimexpr\linewidth/7\relax}{\centering\textbf{Amount Used\\mg}}%
\parbox[t]{\dimexpr\linewidth/7\relax}{\centering\textbf{Procedure}}%
\parbox[t]{\dimexpr\linewidth/7\relax}{\centering\textbf{User}}%
\parbox[t]{\dimexpr\linewidth/7\relax}{\centering\textbf{Amount Used\\mg}}%
\parbox[t]{\dimexpr\linewidth/7\relax}{\centering\textbf{Procedure}}%
\end{minipage}

\fillwithlines{\dimexpr\textheight-1cm\relax}
\end{document}

"
5080,5080,8084,How is this site different from Stack Overflow?,"I've decided to check this site out since it was tweeted by the great Jeff Atwood himself. The first question I saw was ""Advice on making ruby code more ruby-like"", which is the kind of question I see all the time on Stack Overflow.

So what is the difference between the questions on SO and the questions here? It seems to me there is enough overlap between the two that the difference is not clear, and I may not be alone in feeling this.  So far this site seems redundant.
",alimbada,https://meta.codereview.stackexchange.com/users/1037,"Did you not read the FAQ at all?


About page
What topics can I ask about here?


As I said on Twitter, this site is about asking


  Does this code make my ass look fat?


In other words, general broad-spectrum subjective feedback about blocks of code you've written.

Stated another way, on Stack Overflow it would be


  Why doesn't this code compile?


Whereas here it is 


  Why is my code so ugly?


I hope it is immediately obvious why the latter form would get closed instantly on Stack Overflow.
",Jeff Atwood,https://meta.codereview.stackexchange.com/users/136,http://meta.codereview.stackexchange.com/questions/138/how-is-this-site-different-from-stack-overflow,TECHNOLOGY,meta.codereview.stackexchange.com,1.0,1.0,1.0,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.5555555555555556,0.0,0.0,1.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,1.0,0.7777777777777778,1.0,1.0,0.8666666666666666,0.0,0.0,1.0,1.0,How is this site different from a stack overflow?,"I've decided to check this site out since it was tweeted by the great Jeff Atwood himself. The first question I saw was ""Advice on making ruby code more ruby-like"", which is the kind of question I see all the time on Stack Overflow.

So what is the difference between the questions on SO and the questions here? It seems to me there is enough overlap between the two that the difference is not clear, and I may not be alone in feeling this.  So far this site seems redundant.
","Did you not read the FAQ at all?


About page
What topics can I ask about here?


As I said on Twitter, this site is about asking


  Does this code make my ass look fat?


In other words, general broad-spectrum subjective feedback about blocks of code you've written.

Stated another way, on Stack Overflow it would be


  Why doesn't this code compile?


Whereas here it is 


  Why is my code so ugly?


I hope it is immediately obvious why the latter form would get closed instantly on Stack Overflow.
"
5110,5110,8128,SQL OUTPUT entire row after update,"With the following: 

UPDATE ITS2_UserNames  
SET AupIp = @AupIp  
OUTPUT INSERTED.PrimaryKeyID
WHERE @Customer_ID = TCID AND @Handle_ID = ID


I get the primary key, but how do I get all columns?
",SB2055,https://stackoverflow.com/users/899530,"Try this 
--TO get updated values of columns

 UPDATE ITS2_UserNames  
    SET AupIp = @AupIp  
    OUTPUT INSERTED.*
    WHERE @Customer_ID = TCID AND @Handle_ID = ID


--TO Get both new and old values 

UPDATE ITS2_UserNames  
    SET AupIp = @AupIp  
    OUTPUT INSERTED.*,Deleted.*
    WHERE @Customer_ID = TCID AND @Handle_ID = ID

",akhila vangala,https://stackoverflow.com/users/1133052,http://stackoverflow.com/questions/28533098/sql-output-entire-row-after-update,STACKOVERFLOW,stackoverflow.com,1.0,0.3333333333333333,0.0,1.0,1.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.8333333333333334,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,1.0,SQL output whole line after update,"With the following: 

UPDATE ITS2_UserNames  
SET AupIp = @AupIp  
OUTPUT INSERTED.PrimaryKeyID
WHERE @Customer_ID = TCID AND @Handle_ID = ID


I get the primary key, but how do I get all columns?
","Try this 
--TO get updated values of columns

 UPDATE ITS2_UserNames  
    SET AupIp = @AupIp  
    OUTPUT INSERTED.*
    WHERE @Customer_ID = TCID AND @Handle_ID = ID


--TO Get both new and old values 

UPDATE ITS2_UserNames  
    SET AupIp = @AupIp  
    OUTPUT INSERTED.*,Deleted.*
    WHERE @Customer_ID = TCID AND @Handle_ID = ID

"
2030,2030,3236,Do dice finish resolving before yielding Tokyo?,"When does yielding occur in relation to dice resolution? Simultaneously? After all dice have resolved? After attack dice are resolved?

For example (A for attack die, H for heart):

Alice is outside Tokyo, Bob is inside. It is now Alice's turn.
Alice rolls: 3, 3, 3, A, A, H
? Handle VP and hearts?
Alice attacks Bob
Bob chooses to yield


Now consider the possibility Alice has a single shrink ray token, so she only rolls 5 dice:

Alice is outside Tokyo, Bob is inside. It is now Alice's turn.
Alice rolls: 3, 3, 3, A, H
? Handle VP and hearts?
Alice attacks Bob
Bob chooses to yield


She must choose if the heart is applied to heal for one, or if it will remove the shrink ray token. In this case, order of resolution for the attack/yield and heart matters (more/less information for Alice &amp; Bob, inability to heal in Tokyo). Is there an order to the dice resolution (eg hearts then attacks), or is the yield not declared until after all dice have resolved?
",thegrinner,https://boardgames.stackexchange.com/users/3101,"It is my opinion that the dice indicate what happens to you at your current location. A heart dice would indicate that you healed, if your location permits it. 

This is partially supported by the fact that one must take all damage rolled even if one cedes Tokyo. You should similarly be able to use all hearts even if you are forced to take Tokyo. There's absolutely no mention or implication of any other possibility.

Everyone I've played with has naturally come to the same understanding. You could view podcasts of people playing KoT, but I'm sure they've come to the same conclusion.


  She must choose if the heart is applied to heal for one, or if it will remove the shrink ray token. In this case, order of resolution for the attack/yield and heart matters


No, it doesn't. According to the FAQ on BoardGameGeek, removing a bad counter counts as healing and is thus equally forbidden in Tokyo, so the order does not affect the choice.
",ikegami,https://boardgames.stackexchange.com/users/2880,http://boardgames.stackexchange.com/questions/13721/do-dice-finish-resolving-before-yielding-tokyo,CULTURE,boardgames.stackexchange.com,1.0,0.3333333333333333,0.0,1.0,1.0,1.0,0.5,0.3333333333333333,0.5,0.0,0.5,0.5,0.0,0.0,0.0,0.0,0.0,1.0,0.5,0.0,0.8333333333333334,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,1.0,0.5,1.0,Has dice solved the problem before giving up Tokyo?,"When does yielding occur in relation to dice resolution? Simultaneously? After all dice have resolved? After attack dice are resolved?

For example (A for attack die, H for heart):

Alice is outside Tokyo, Bob is inside. It is now Alice's turn.
Alice rolls: 3, 3, 3, A, A, H
? Handle VP and hearts?
Alice attacks Bob
Bob chooses to yield


Now consider the possibility Alice has a single shrink ray token, so she only rolls 5 dice:

Alice is outside Tokyo, Bob is inside. It is now Alice's turn.
Alice rolls: 3, 3, 3, A, H
? Handle VP and hearts?
Alice attacks Bob
Bob chooses to yield


She must choose if the heart is applied to heal for one, or if it will remove the shrink ray token. In this case, order of resolution for the attack/yield and heart matters (more/less information for Alice &amp; Bob, inability to heal in Tokyo). Is there an order to the dice resolution (eg hearts then attacks), or is the yield not declared until after all dice have resolved?
","It is my opinion that the dice indicate what happens to you at your current location. A heart dice would indicate that you healed, if your location permits it. 

This is partially supported by the fact that one must take all damage rolled even if one cedes Tokyo. You should similarly be able to use all hearts even if you are forced to take Tokyo. There's absolutely no mention or implication of any other possibility.

Everyone I've played with has naturally come to the same understanding. You could view podcasts of people playing KoT, but I'm sure they've come to the same conclusion.


  She must choose if the heart is applied to heal for one, or if it will remove the shrink ray token. In this case, order of resolution for the attack/yield and heart matters


No, it doesn't. According to the FAQ on BoardGameGeek, removing a bad counter counts as healing and is thus equally forbidden in Tokyo, so the order does not affect the choice.
"
2172,2172,3464,Upper Bound on Determinant of Matrix in terms of Trace,"For an $n\times n$ positive definite matrix $A$, I wish to prove that 


  $$\det(A) \leq \bigg(\frac{Trace(A)}{n}\bigg)^n$$


To me this seems some form of AM-GM Inequality (Arithmatic Mean-Geometric Mean Inequality). Therefore If I can show the following, above inequality follows : 


  $$\det(A) \leq \prod_{i=1}^{i=n} A_{ii}$$


Any idea how to prove the above.
Thanks
",damned,https://math.stackexchange.com/users/26171,"Let $\,\lambda_1,...,\lambda_n\,$ be the matrix's eigenvalues (perhaps in some field extension of the original one), which are all positive (of course, it is customary to consider only Hermitian, or symmetric, matrices when defining positive definite), then

$$\det A=\prod_{k=1}^n \lambda_k\,\,\,,\,\,\,\operatorname{tr.}A=\sum_{k=1}^n\lambda_k$$

Thus we're required to prove

$$\prod_{k=1}^n\lambda_k\leq\left(\frac{\sum_{k=1}^n\lambda_k}{n}\right)^n\Longleftrightarrow \sqrt[n]{\prod_{k=1}^n\lambda_k}\leq \,\frac{1}{n}\sum_{k=1}^n\lambda_k$$

which is precisely the AM-GM inequality, as you mentioned.
",DonAntonio,https://math.stackexchange.com/users/31254,http://math.stackexchange.com/questions/202248/upper-bound-on-determinant-of-matrix-in-terms-of-trace,SCIENCE,math.stackexchange.com,0.6666666666666666,0.4444444444444444,0.0,1.0,0.6666666666666666,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.0,0.8888888888888888,1.0,0.6666666666666666,0.8888888888888888,1.0,0.9333333333333332,0.6666666666666666,0.3333333333333333,0.3333333333333333,1.0,Trace upper bound of matrix determinant,"For an $n\times n$ positive definite matrix $A$, I wish to prove that 


  $$\det(A) \leq \bigg(\frac{Trace(A)}{n}\bigg)^n$$


To me this seems some form of AM-GM Inequality (Arithmatic Mean-Geometric Mean Inequality). Therefore If I can show the following, above inequality follows : 


  $$\det(A) \leq \prod_{i=1}^{i=n} A_{ii}$$


Any idea how to prove the above.
Thanks
","Let $\,\lambda_1,...,\lambda_n\,$ be the matrix's eigenvalues (perhaps in some field extension of the original one), which are all positive (of course, it is customary to consider only Hermitian, or symmetric, matrices when defining positive definite), then

$$\det A=\prod_{k=1}^n \lambda_k\,\,\,,\,\,\,\operatorname{tr.}A=\sum_{k=1}^n\lambda_k$$

Thus we're required to prove

$$\prod_{k=1}^n\lambda_k\leq\left(\frac{\sum_{k=1}^n\lambda_k}{n}\right)^n\Longleftrightarrow \sqrt[n]{\prod_{k=1}^n\lambda_k}\leq \,\frac{1}{n}\sum_{k=1}^n\lambda_k$$

which is precisely the AM-GM inequality, as you mentioned.
"
580,580,907,What is the distinction between a city and a sprawl/metroplex... between downtown and a commercial district?,"I am trying to understand what kinds of places the spam values on p 231 refer to in the 5th Edition main book for Shadowrun.

Per p 15, a sprawl is a plex, a plex is a ""metropolitan complex, short for metroplex"". Per Google a metroplex is "" a very large metropolitan area, especially one that is an aggregation of two or more cities"".  A city downtown and sprawl downtown would tend to have similar densities, but for some reason the sprawl (which includes suburbs?) has a higher spam zone noise rating (p 231).  Similarly, I'd think of a downtown as being more dense and noisy (e.g. Office buildings and street vendors) than a commercial district, e.g. an outdoor mall.  The noise ratings make me think that I am thinking about this incorrectly. What is a better way of thinking of them?
",russellpierce,https://rpg.stackexchange.com/users/8774,"When I interpret the Spam/Static Zone noise ratings, I see it as the following:

The City spam rating is one because that is where the more affluent people live. They pay for access to the city's grid, and typically these locations are going to be other businesses or higher-end residential areas, where they don't want the advertising, given that it will have a negative effect. The sprawl downtown has the same idea, but since they aren't throwing as much nuyen around, there's a bit more leeway on what advertising will do. There are going to be more people around, of course, adding to the chatter, even more so when you consider that since more will be on the public grid, both businesses and people.

For the commercial areas, even in an open air market, you're going to have everyone with a booth throwing out AROs and such to attract others. People are going to be doing searches for best prices, checking SINs, and all sorts of things. People are there to blow their nuyen, and marketers aren't going to miss out on the chance to grab your money before you have a chance to second-guess.
",Codeacula,https://rpg.stackexchange.com/users/8076,http://rpg.stackexchange.com/questions/47820/what-is-the-distinction-between-a-city-and-a-sprawl-metroplex-between-downtow,CULTURE,rpg.stackexchange.com,0.8888888888888888,1.0,0.0,0.3333333333333333,1.0,1.0,0.5555555555555556,0.5555555555555556,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.3333333333333333,0.0,0.0,0.0,1.0,0.0,0.8888888888888888,1.0,0.7777777777777778,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,0.8888888888888888,What's the difference between a city and an expanding metropolis... Between downtown and downtown?,"I am trying to understand what kinds of places the spam values on p 231 refer to in the 5th Edition main book for Shadowrun.

Per p 15, a sprawl is a plex, a plex is a ""metropolitan complex, short for metroplex"". Per Google a metroplex is "" a very large metropolitan area, especially one that is an aggregation of two or more cities"".  A city downtown and sprawl downtown would tend to have similar densities, but for some reason the sprawl (which includes suburbs?) has a higher spam zone noise rating (p 231).  Similarly, I'd think of a downtown as being more dense and noisy (e.g. Office buildings and street vendors) than a commercial district, e.g. an outdoor mall.  The noise ratings make me think that I am thinking about this incorrectly. What is a better way of thinking of them?
","When I interpret the Spam/Static Zone noise ratings, I see it as the following:

The City spam rating is one because that is where the more affluent people live. They pay for access to the city's grid, and typically these locations are going to be other businesses or higher-end residential areas, where they don't want the advertising, given that it will have a negative effect. The sprawl downtown has the same idea, but since they aren't throwing as much nuyen around, there's a bit more leeway on what advertising will do. There are going to be more people around, of course, adding to the chatter, even more so when you consider that since more will be on the public grid, both businesses and people.

For the commercial areas, even in an open air market, you're going to have everyone with a booth throwing out AROs and such to attract others. People are going to be doing searches for best prices, checking SINs, and all sorts of things. People are there to blow their nuyen, and marketers aren't going to miss out on the chance to grab your money before you have a chance to second-guess.
"
2038,2038,3246,Trigger to autopopulate a lookup field via related record,"I have a custom object in salesforce. Every record has many fields. One is a lookup field in which we select an opportunity from lookup. What we want is another lookup field: Account__c which has to be automatically populated with account name of that respective opportunity.

In the code below, ""After insert"" is working but before update is not working properly.

 trigger trigger_name on object__c (after insert, before update) {

    List&lt;object__c&gt; listOfSfdcRecords  =[SELECT Opportunity__r.AccountId,Opportunity__r.Account.Name FROM object__c WHERE ID IN :trigger.newMap.keySet()];
    Map&lt;String, Id&gt; myMap = new Map&lt;String, Id&gt;(); 
    for(object__c eachRec : listOfSfdcRecords){
        System.debug(listOfSfdcRecords);          
        myMap.put(eachRec.Id, eachRec.Opportunity__r.AccountId);
    }
    if(trigger.isAfter){
        List &lt;object__c&gt; updateList = new List &lt;object__c&gt;();
        for(object__c eachSfdc: listOfSfdcRecords){
            System.debug(eachSfdc.Opportunity__r.AccountId);
            object__c sfdc = new object__c(Id = eachSfdc.Id);
            sfdc.Test_Account__c = eachSfdc.Opportunity__r.AccountId;
            updateList.add(sfdc);
        }
        update updateList;
    }
    if(trigger.isBefore){
        for(object__c eachSfdc: trigger.new){
            //System.debug('before update'+eachSfdc.Opportunity__r.AccountId);
            System.debug('b4 update'+myMap.get(eachSfdc.id));
            eachSfdc.Test_Account__c = myMap.get(eachSfdc.id);
        }
    }

}

",James,https://salesforce.stackexchange.com/users/4659,"You can do something like this. Basically you would need to get the opportunities of all the records that you're inserting / updating, get the associated accounts and then set the account values in the customOject's account__c field. 

trigger autoPopulateTrigger on customObject__c (before insert, before update){

    //get the oppotyunity Id's and store it in a set.
    set&lt;Id&gt; opptyIdSet = new set&lt;Id&gt;();
    for(customObject__c co: trigger.new){
        if(co.opportuntiy__c != null){
            opptyIdSet.add(co.opportunity__c);
        }
    }

    //query the opportunity records and get the associated accounts.
    map&lt;id, opportunity&gt; opptyMap = new map&lt;id, opportunity&gt;{[SELECT id, accountid from opportunity where Id IN: opptyIdSet]};

    //update the account value based on the opportunity in the record.
    for(customObject__c co: trigger.new){
        if(opptyMap.containsKey(co.opportunity__c)){
            co.Account__c = opptyMap.get(co.opportunity__c).accountId;
        }       
    }

}

",Anamadeya,https://salesforce.stackexchange.com/users/2832,http://salesforce.stackexchange.com/questions/21530/trigger-to-autopopulate-a-lookup-field-via-related-record,TECHNOLOGY,salesforce.stackexchange.com,1.0,0.3333333333333333,0.0,0.0,0.3333333333333333,1.0,0.3333333333333333,1.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,1.0,Trigger to automatically fill the lookup field with related records,"I have a custom object in salesforce. Every record has many fields. One is a lookup field in which we select an opportunity from lookup. What we want is another lookup field: Account__c which has to be automatically populated with account name of that respective opportunity.

In the code below, ""After insert"" is working but before update is not working properly.

 trigger trigger_name on object__c (after insert, before update) {

    List&lt;object__c&gt; listOfSfdcRecords  =[SELECT Opportunity__r.AccountId,Opportunity__r.Account.Name FROM object__c WHERE ID IN :trigger.newMap.keySet()];
    Map&lt;String, Id&gt; myMap = new Map&lt;String, Id&gt;(); 
    for(object__c eachRec : listOfSfdcRecords){
        System.debug(listOfSfdcRecords);          
        myMap.put(eachRec.Id, eachRec.Opportunity__r.AccountId);
    }
    if(trigger.isAfter){
        List &lt;object__c&gt; updateList = new List &lt;object__c&gt;();
        for(object__c eachSfdc: listOfSfdcRecords){
            System.debug(eachSfdc.Opportunity__r.AccountId);
            object__c sfdc = new object__c(Id = eachSfdc.Id);
            sfdc.Test_Account__c = eachSfdc.Opportunity__r.AccountId;
            updateList.add(sfdc);
        }
        update updateList;
    }
    if(trigger.isBefore){
        for(object__c eachSfdc: trigger.new){
            //System.debug('before update'+eachSfdc.Opportunity__r.AccountId);
            System.debug('b4 update'+myMap.get(eachSfdc.id));
            eachSfdc.Test_Account__c = myMap.get(eachSfdc.id);
        }
    }

}

","You can do something like this. Basically you would need to get the opportunities of all the records that you're inserting / updating, get the associated accounts and then set the account values in the customOject's account__c field. 

trigger autoPopulateTrigger on customObject__c (before insert, before update){

    //get the oppotyunity Id's and store it in a set.
    set&lt;Id&gt; opptyIdSet = new set&lt;Id&gt;();
    for(customObject__c co: trigger.new){
        if(co.opportuntiy__c != null){
            opptyIdSet.add(co.opportunity__c);
        }
    }

    //query the opportunity records and get the associated accounts.
    map&lt;id, opportunity&gt; opptyMap = new map&lt;id, opportunity&gt;{[SELECT id, accountid from opportunity where Id IN: opptyIdSet]};

    //update the account value based on the opportunity in the record.
    for(customObject__c co: trigger.new){
        if(opptyMap.containsKey(co.opportunity__c)){
            co.Account__c = opptyMap.get(co.opportunity__c).accountId;
        }       
    }

}

"
3743,3743,5964,How to split a string between two character into sub groups in R,"I have a list of codes in the second column of a table and I want to extract some elements of each code then store them in new columns associated with each of the codes. 
Each code consists of letters followed by some numbers. The letters are P, F, I , R, C repeated with the same order in all codes but the number of digits are varying in each code. 

For example: consider the codes as below:

P1F2I235R15C145   P1   F2   I23   R15   C145
P24F1I12R124C96   P24  F1   I12   R124  C96


so in this way I can split each code into its constitutes sub-codes, and store these components into new columns in the same table.
thanks
",ashkan,https://stackoverflow.com/users/4227079,"Here's a possible stringi solution

library(stringi)
x &lt;- c(""P1F2I235R15C145"",""P24F1I12R124C96"")
res &lt;- stri_split_regex(x,""(?=([A-Za-z]=?))"",perl = TRUE,simplify = TRUE,omit_empty = TRUE)
cbind.data.frame(x, res)
#                 x   1  2    3    4    5
# 1 P1F2I235R15C145  P1 F2 I235  R15 C145
# 2 P24F1I12R124C96 P24 F1  I12 R124  C96

",David Arenburg,https://stackoverflow.com/users/3001626,http://stackoverflow.com/questions/30593693/how-to-split-a-string-between-two-character-into-sub-groups-in-r,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.5555555555555556,0.0,1.0,0.6666666666666666,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.3333333333333333,0.0,1.0,How to split a string between two characters into subgroups in R,"I have a list of codes in the second column of a table and I want to extract some elements of each code then store them in new columns associated with each of the codes. 
Each code consists of letters followed by some numbers. The letters are P, F, I , R, C repeated with the same order in all codes but the number of digits are varying in each code. 

For example: consider the codes as below:

P1F2I235R15C145   P1   F2   I23   R15   C145
P24F1I12R124C96   P24  F1   I12   R124  C96


so in this way I can split each code into its constitutes sub-codes, and store these components into new columns in the same table.
thanks
","Here's a possible stringi solution

library(stringi)
x &lt;- c(""P1F2I235R15C145"",""P24F1I12R124C96"")
res &lt;- stri_split_regex(x,""(?=([A-Za-z]=?))"",perl = TRUE,simplify = TRUE,omit_empty = TRUE)
cbind.data.frame(x, res)
#                 x   1  2    3    4    5
# 1 P1F2I235R15C145  P1 F2 I235  R15 C145
# 2 P24F1I12R124C96 P24 F1  I12 R124  C96

"
614,614,961,Take quick notes without interrupting current activity,"When I’m in the middle of something and get an idea, I want to note it down without interrupting what I’m doing.

Desired workflow: adding a note


I press a key (or a key combo).
(should work everywhere: while browsing, while writing, while watching a video, etc.)
A note window opens.
(just a single text field, no title/category/etc.)
(it must be empty)
(doesn’t have to be a GUI)
I enter my note.
I press, e.g. Enter to save the note.
(the window must close automatically)


Browsing notes


Just a simple list/table of all saved notes.

Especially not just text files which I’d have to open separately to read their content.

Should display the date/time when a note was saved.
Should offer a quick way to delete notes.
No need for editing notes.


Formal requirements

A solution must be FLOSS and run natively on GNU/Linux.
",unor,https://softwarerecs.stackexchange.com/users/60,"Sounds like a job for Emacs!

Install Emacs through your distribution's package manager.

Emacs comes with Remember Mode, which does pretty much what you want. (Note that there's a lot of complication in the Emacs Wiki that you don't care about, because it's for older versions of Emacs. Remember Mode is bundled since Emacs 23.)

To start taking a note, run the following shell command:

emacsclient -a """" -e ""(let ((pop-up-frame-alist \`((window-system . x) (display . \""$DISPLAY\"") ,@pop-up-frame-alist))) (remember-other-frame))""


(Having just -e ""(remember-other-frame)"" doesn't work if Emacs isn't already displaying a window due to a bad interaction between server mode and frame creation.)
You can add other frame parameters in that list, with the syntax (NAME . VALUE). For example, to set a smaller height:

emacsclient -a """" -e ""(let ((pop-up-frame-alist \`((window-system . x) (display . \""$DISPLAY\"") (height . 8) ,@pop-up-frame-alist))) (remember-other-frame))""


Bind that shell command to a key in your window manager or desktop environment; each has its own way of doing this, so I can't describe them all.

Emacs will start if it isn't already running, and a new Emacs window showing an empty file will pop up. When you've finished taking that note, press Ctrl+C twice. If you want to change that key binding, you can do it in your .emacs, for example to use Ctrl+Return, use this code:

(require 'remember)
(define-key remember-mode-map [C-return] 'remember-finalize)


If you want to save some text from another application, copy it to the clipboard and run this command (which you may want to bind to a key as well):

emacsclient -a """" -c -e ""(remember-clipboard)""


With this command, you need to press Ctrl+C twice, then close the window.

The notes are saved in the file ~/.notes (each new note is appended to that file). A header containing ** followed by the current time is automatically added at the beginning of the note.

To browse the notes, just open ~/.notes in your favorite text editor (such as Emacs).

If you want to save the notes to a different file, add a line like this to your ~/.emacs:

(setq remember-data-file ""/path/to/notes/file"")


What Remember mode lacks out of the box is a really convenient way of deleting a single note. You can of course select the text and delete it. Here's a function to delete the current note, plus a bit of infrastructure to bind it to a key when browsing the notes file. Put this code in your ~/.emacs.

(defun remember-current-note-extent ()
  (save-match-data
    (save-excursion
      (end-of-line)
      (let ((beg (search-backward (concat ""\n"" remember-leader-text))))
        (forward-char)
        (cons beg
              (if (search-forward (concat ""\n"" remember-leader-text) nil t)
                  (- (point) 1 (length remember-leader-text))
                (point-max)))))))
(defun remember-mark-current-note ()
  (interactive ""@"")
  (let ((bounds (remember-current-note-extent)))
    (set-mark (car bounds))
    (goto-char (cdr bounds))))
(defun remember-delete-current-note ()
  (interactive ""@*"")
  (let ((bounds (remember-current-note-extent)))
    (delete-region (car bounds) (cdr bounds))))

(defvar remember-notes-mode-map
  (let ((map (make-sparse-keymap)))
    (define-key map ""\C-c\C-d"" 'remember-delete-current-note)
    map)
  ""Keymap for Remember Notes mode."")

(define-derived-mode remember-notes-mode text-mode ""Notes""
  ""Major mode to browse Remember notes.

\\{remember-notes-mode-map}""
  (require 'remember))
(add-to-list 'auto-mode-alist '(""/\\.notes\\'"" . remember-notes-mode))

",Gilles,https://softwarerecs.stackexchange.com/users/64,http://softwarerecs.stackexchange.com/questions/2224/take-quick-notes-without-interrupting-current-activity,SCIENCE,softwarerecs.stackexchange.com,1.0,0.6666666666666666,0.0,0.5,1.0,0.5,0.7777777777777778,0.6666666666666666,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.5,0.5,0.5,0.0,0.0,0.7777777777777778,0.8888888888888888,0.7777777777777778,1.0,0.8888888888888888,0.9333333333333332,1.0,0.3333333333333333,0.3333333333333333,0.7777777777777778,Take notes quickly without interrupting the current activity,"When I’m in the middle of something and get an idea, I want to note it down without interrupting what I’m doing.

Desired workflow: adding a note


I press a key (or a key combo).
(should work everywhere: while browsing, while writing, while watching a video, etc.)
A note window opens.
(just a single text field, no title/category/etc.)
(it must be empty)
(doesn’t have to be a GUI)
I enter my note.
I press, e.g. Enter to save the note.
(the window must close automatically)


Browsing notes


Just a simple list/table of all saved notes.

Especially not just text files which I’d have to open separately to read their content.

Should display the date/time when a note was saved.
Should offer a quick way to delete notes.
No need for editing notes.


Formal requirements

A solution must be FLOSS and run natively on GNU/Linux.
","Sounds like a job for Emacs!

Install Emacs through your distribution's package manager.

Emacs comes with Remember Mode, which does pretty much what you want. (Note that there's a lot of complication in the Emacs Wiki that you don't care about, because it's for older versions of Emacs. Remember Mode is bundled since Emacs 23.)

To start taking a note, run the following shell command:

emacsclient -a """" -e ""(let ((pop-up-frame-alist \`((window-system . x) (display . \""$DISPLAY\"") ,@pop-up-frame-alist))) (remember-other-frame))""


(Having just -e ""(remember-other-frame)"" doesn't work if Emacs isn't already displaying a window due to a bad interaction between server mode and frame creation.)
You can add other frame parameters in that list, with the syntax (NAME . VALUE). For example, to set a smaller height:

emacsclient -a """" -e ""(let ((pop-up-frame-alist \`((window-system . x) (display . \""$DISPLAY\"") (height . 8) ,@pop-up-frame-alist))) (remember-other-frame))""


Bind that shell command to a key in your window manager or desktop environment; each has its own way of doing this, so I can't describe them all.

Emacs will start if it isn't already running, and a new Emacs window showing an empty file will pop up. When you've finished taking that note, press Ctrl+C twice. If you want to change that key binding, you can do it in your .emacs, for example to use Ctrl+Return, use this code:

(require 'remember)
(define-key remember-mode-map [C-return] 'remember-finalize)


If you want to save some text from another application, copy it to the clipboard and run this command (which you may want to bind to a key as well):

emacsclient -a """" -c -e ""(remember-clipboard)""


With this command, you need to press Ctrl+C twice, then close the window.

The notes are saved in the file ~/.notes (each new note is appended to that file). A header containing ** followed by the current time is automatically added at the beginning of the note.

To browse the notes, just open ~/.notes in your favorite text editor (such as Emacs).

If you want to save the notes to a different file, add a line like this to your ~/.emacs:

(setq remember-data-file ""/path/to/notes/file"")


What Remember mode lacks out of the box is a really convenient way of deleting a single note. You can of course select the text and delete it. Here's a function to delete the current note, plus a bit of infrastructure to bind it to a key when browsing the notes file. Put this code in your ~/.emacs.

(defun remember-current-note-extent ()
  (save-match-data
    (save-excursion
      (end-of-line)
      (let ((beg (search-backward (concat ""\n"" remember-leader-text))))
        (forward-char)
        (cons beg
              (if (search-forward (concat ""\n"" remember-leader-text) nil t)
                  (- (point) 1 (length remember-leader-text))
                (point-max)))))))
(defun remember-mark-current-note ()
  (interactive ""@"")
  (let ((bounds (remember-current-note-extent)))
    (set-mark (car bounds))
    (goto-char (cdr bounds))))
(defun remember-delete-current-note ()
  (interactive ""@*"")
  (let ((bounds (remember-current-note-extent)))
    (delete-region (car bounds) (cdr bounds))))

(defvar remember-notes-mode-map
  (let ((map (make-sparse-keymap)))
    (define-key map ""\C-c\C-d"" 'remember-delete-current-note)
    map)
  ""Keymap for Remember Notes mode."")

(define-derived-mode remember-notes-mode text-mode ""Notes""
  ""Major mode to browse Remember notes.

\\{remember-notes-mode-map}""
  (require 'remember))
(add-to-list 'auto-mode-alist '(""/\\.notes\\'"" . remember-notes-mode))

"
2984,2984,4758,What does the lpr -h command exactly mean from linux?,"I am new at Linux and in my school they asked me to give an example of this command

lpr -h


I already know that lpr its for printing and that the option -h disables banner printing.

What banner? As far as I am with Linux I only know to create banners from the banner command 

banner ""hello world""


Not how to save it or print it. Is that kind of banner what this -h option refers to?

Could you give me an example?
",elizabeth,https://superuser.com/users/162305,"man lpr --> -h --> -o job-sheets=none --> banner page --> Wikipedia &ndash; Banner Page.

The first page explains what the command does, the second explains the options -o takes and the third explains what the banner page actually is; thus we obtain this paragraph from Wikipedia:


  A banner page, also called a burst page, job sheet, or a printer separator, is used in computerized printing in order to separate documents (or ""print jobs"") from each other and to identify the originator of the print request by username. These pages are typically used in office environments where many people share a small number of printers. In some cases, print jobs are sent to a central processing area where messengers take the printouts back to the owner, but the usual practice in modern office environments is for the user to retrieve his or her own documents. The banner page makes it clear who printed each job.


You can find examples of what banner pages look like on Google Images.

Also, I should note that the Linux banner command is something completely different.

You are responsible for not doing your homework yourself, not me.
",Tom Wijsman,https://superuser.com/users/9666,http://superuser.com/questions/481644,TECHNOLOGY,superuser.com,1.0,0.4444444444444444,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.4444444444444444,0.6666666666666666,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,1.0,0.0,0.7777777777777778,0.7777777777777778,0.6666666666666666,0.7777777777777778,0.7777777777777778,0.7333333333333333,0.0,0.0,0.6666666666666666,1.0,What is the meaning of lpr-h command in Linux?,"I am new at Linux and in my school they asked me to give an example of this command

lpr -h


I already know that lpr its for printing and that the option -h disables banner printing.

What banner? As far as I am with Linux I only know to create banners from the banner command 

banner ""hello world""


Not how to save it or print it. Is that kind of banner what this -h option refers to?

Could you give me an example?
","man lpr --> -h --> -o job-sheets=none --> banner page --> Wikipedia &ndash; Banner Page.

The first page explains what the command does, the second explains the options -o takes and the third explains what the banner page actually is; thus we obtain this paragraph from Wikipedia:


  A banner page, also called a burst page, job sheet, or a printer separator, is used in computerized printing in order to separate documents (or ""print jobs"") from each other and to identify the originator of the print request by username. These pages are typically used in office environments where many people share a small number of printers. In some cases, print jobs are sent to a central processing area where messengers take the printouts back to the owner, but the usual practice in modern office environments is for the user to retrieve his or her own documents. The banner page makes it clear who printed each job.


You can find examples of what banner pages look like on Google Images.

Also, I should note that the Linux banner command is something completely different.

You are responsible for not doing your homework yourself, not me.
"
1384,1384,2181,Should I avoid credit card use to improve our debt-to-income ratio?,"We put all our expenses on a credit card and pay it off every month in order to get maximize our cash back.  We never charge more than we have in the checking account, so we always pay it off.  Should we reconsider doing this in order to improve our debt-to-income ratio?

Our goal is to be in the best position possible to get a mortgage in the next 3-12 months.
",JHFB,https://money.stackexchange.com/users/6182,"The answer depends on how much you spend every month. The DTI is calculated using the minimum payment on the balance owed on your card.  Credit card minimum payments are ridiculous, often being only $50 for balances of a couple thousand dollars.

In any case, when you get preapproved, the lender will tell you (based on your DTI) the maximum amount they will approve you for. If your minimum payment is $50, that's another $50 that could go towards your mortgage, which could mean an additional $10,000 financed.

It's up to you to decide if $10,000 will make enough of a difference in the houses you look at.
",Benjamin Chambers,https://money.stackexchange.com/users/1739,http://money.stackexchange.com/questions/30939/should-i-avoid-credit-card-use-to-improve-our-debt-to-income-ratio,LIFE_ARTS,money.stackexchange.com,0.6666666666666666,0.7777777777777778,0.0,0.6666666666666666,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.0,0.0,1.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.8888888888888888,0.6666666666666666,0.5555555555555556,1.0,1.0,0.8,0.6666666666666666,0.0,0.0,1.0,Should I avoid using credit cards to increase our debt to income ratio?,"We spend all our expenses on credit cards and pay them monthly to maximize our cash. We never charge more than a checking account, so we always pay it off. Should we reconsider this to improve our debt to income ratio?","The answer depends on how much you spend every month. The DTI is calculated using the minimum payment on the balance owed on your card.  Credit card minimum payments are ridiculous, often being only $50 for balances of a couple thousand dollars.

In any case, when you get preapproved, the lender will tell you (based on your DTI) the maximum amount they will approve you for. If your minimum payment is $50, that's another $50 that could go towards your mortgage, which could mean an additional $10,000 financed.

It's up to you to decide if $10,000 will make enough of a difference in the houses you look at.
"
4408,4408,7003,What is the best introductory Bayesian statistics textbook?,"Which is the best introductory textbook for Bayesian statistics?

One book per answer, please.
",Shane,https://stats.stackexchange.com/users/5,"Its focus isn't strictly on Bayesian statistics, so it lacks some methodology, but David MacKay's Information Theory, Inference, and Learning Algorithms made me intuitively grasp Bayesian statistics better than others - most do the how quite nicely, but I felt MacKay explained why better.
",Joe,https://stats.stackexchange.com/users/1119,http://stats.stackexchange.com/questions/125/what-is-the-best-introductory-bayesian-statistics-textbook,SCIENCE,stats.stackexchange.com,0.7777777777777778,1.0,1.0,1.0,0.0,0.0,0.5555555555555556,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.8888888888888888,0.7777777777777778,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,0.0,1.0,What is the best introduction to Bayesian statistics?,Which is the best introduction to Bayesian statistics?,"Its focus is not strictly on Bayesian statistics, so it lacks some methodology, but David Mackay's information theory, reasoning and learning algorithm make me intuitively master Bayesian statistics better than others - most people do well, but I think Mackay explains why it is better."
4439,4439,7048,Custom stackoverflow settings,"Is it possible to be able to set some default settings, such as the display format of dates of posts? (For example, I would much rather see 2011-13-01 than the current jan 13 '11)

In addition to an alternative datetime format one could also think of some other settings, perhaps some color blind settings, light/dark-theme or some other stuff I'm sure some clever people here can think of.
",Deruijter,https://meta.stackexchange.com/users/214628,"No, please do not overcomplicate things with endless little settings to suit each and every user.

You can style and tweak Stack Overflow endlessly in your own browser.


There are Stylish plugins for Firefox, Chrome, Safari and Opera, with several Stack Overflow themes to choose from already. It is easy to create your own styles.
For altering behaviour, you can add Greasemonkey to Firefox and Opera or NinjaKit to Safari; Chrome supports most such scripts out-of-the-box. Then head over to UserScripts.org to find yourself Stack Overflow tweaks.


Many of these styles and scripts are also (or only) featured on StackApps.com, the Stack Exchange Q&amp;A site for the SE API, SE applications and scripts.
",Martijn Pieters,https://meta.stackexchange.com/users/140890,http://meta.stackexchange.com/questions/172818/custom-stackoverflow-settings,TECHNOLOGY,meta.stackexchange.com,0.8888888888888888,0.4444444444444444,0.0,1.0,1.0,0.6666666666666666,0.7777777777777778,0.5555555555555556,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.6666666666666666,0.0,1.0,1.0,Custom stack overflow settings,"Is it possible to be able to set some default settings, such as the display format of dates of posts? (For example, I would much rather see 2011-13-01 than the current jan 13 '11)

In addition to an alternative datetime format one could also think of some other settings, perhaps some color blind settings, light/dark-theme or some other stuff I'm sure some clever people here can think of.
","No, please do not overcomplicate things with endless little settings to suit each and every user.

You can style and tweak Stack Overflow endlessly in your own browser.


There are Stylish plugins for Firefox, Chrome, Safari and Opera, with several Stack Overflow themes to choose from already. It is easy to create your own styles.
For altering behaviour, you can add Greasemonkey to Firefox and Opera or NinjaKit to Safari; Chrome supports most such scripts out-of-the-box. Then head over to UserScripts.org to find yourself Stack Overflow tweaks.


Many of these styles and scripts are also (or only) featured on StackApps.com, the Stack Exchange Q&amp;A site for the SE API, SE applications and scripts.
"
5613,5613,8906,Importance of dividend yield when evaluating a stock?,"Why is the dividend yield (Dividend divided by market price) of a stock a valuable parameter to consider when evaluating a stock? By looking at it, what can one infer about the stock?

edit: Thanks for the answers. But I wish to know why the parameter is dividend/market price rather than just 'dividend'? What 'extra' info you can uncover by looking at dividend/market price that you cannot get from 'dividend'?
",Victor123,https://money.stackexchange.com/users/2991,"
  But I wish to know why the parameter is dividend/market price rather than just 'dividend'? What 'extra' info you can uncover by looking at dividend/market price that you cannot get from 'dividend'?


Consider two stocks A and B. A offers a dividend of $1 per year. B offers a dividend of $2 per year. Let's remove all complications aside and assume that this trend continues. If you were to buy each of these stocks you will get the following amounts over its life (assumed infinity for simplicity):


  cash flows from A = $1/(0.04) = $25, assuming risk free is 4% per annum
  
  cash flows from B = $2/(0.04) = $50, assuming risk free is 4% per annum


The price you buy them at is an important factor to consider because let's say if A was trading for $10 and B for $60, then A would look like a profitable nvestment while B won't. Of course, this is a very simplistic view. Dividend rates are not constant and many companies pose a significant risk of going bust but this should help illustrate the general idea behind the D/P ratio.

P.S.:- The formula I have used is one for computing the NPV of a perpetuity. 
",Apoorv Khurasia,https://money.stackexchange.com/users/3743,http://money.stackexchange.com/questions/9192/importance-of-dividend-yield-when-evaluating-a-stock,LIFE_ARTS,money.stackexchange.com,1.0,0.4444444444444444,0.0,0.0,1.0,0.3333333333333333,0.8888888888888888,0.8888888888888888,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,1.0,How important is the dividend yield when evaluating stocks?,"Why is the dividend yield (Dividend divided by market price) of a stock a valuable parameter to consider when evaluating a stock? By looking at it, what can one infer about the stock?

edit: Thanks for the answers. But I wish to know why the parameter is dividend/market price rather than just 'dividend'? What 'extra' info you can uncover by looking at dividend/market price that you cannot get from 'dividend'?
","
  But I wish to know why the parameter is dividend/market price rather than just 'dividend'? What 'extra' info you can uncover by looking at dividend/market price that you cannot get from 'dividend'?


Consider two stocks A and B. A offers a dividend of $1 per year. B offers a dividend of $2 per year. Let's remove all complications aside and assume that this trend continues. If you were to buy each of these stocks you will get the following amounts over its life (assumed infinity for simplicity):


  cash flows from A = $1/(0.04) = $25, assuming risk free is 4% per annum
  
  cash flows from B = $2/(0.04) = $50, assuming risk free is 4% per annum


The price you buy them at is an important factor to consider because let's say if A was trading for $10 and B for $60, then A would look like a profitable nvestment while B won't. Of course, this is a very simplistic view. Dividend rates are not constant and many companies pose a significant risk of going bust but this should help illustrate the general idea behind the D/P ratio.

P.S.:- The formula I have used is one for computing the NPV of a perpetuity. 
"
1475,1475,2321,Google Mail Keyboard Shortcut for delete on Mac,"I use the Google Mail keyboard shortcuts a lot and I've just started working on a Mac. One shortcut I use a lot is delete, which Google Mail listens for the # key.

However, when I press the equivalent on the Mac keyboard (Alt+3) it doesn't work.  I've tried pressing backspace and Fn+Backspace but no luck.

Anyone out there know the solution?
",Sam Huggill,https://webapps.stackexchange.com/users/11487,"It is Shift+3 within a message for Mac.
It is the same in the inbox as well  


You must move to the message with j/k  
Select a message with x
Then press Shift+3


It could be that your keyboard layout is different.
Using a UK layout, it would be Option + 3 : ⌥ + 3, but this does not work (Not sure why).
You can also remap your keys with the Google Labs feature : Custom keyboard shortcuts
",phwd,https://webapps.stackexchange.com/users/40,http://webapps.stackexchange.com/questions/16198/google-mail-keyboard-shortcut-for-delete-on-mac,TECHNOLOGY,webapps.stackexchange.com,1.0,0.7777777777777778,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,0.8888888888888888,Google Mail keyboard shortcut for Mac removal,"I use the Google Mail keyboard shortcuts a lot and I've just started working on a Mac. One shortcut I use a lot is delete, which Google Mail listens for the # key.

However, when I press the equivalent on the Mac keyboard (Alt+3) it doesn't work.  I've tried pressing backspace and Fn+Backspace but no luck.

Anyone out there know the solution?
","It is Shift+3 within a message for Mac.
It is the same in the inbox as well  


You must move to the message with j/k  
Select a message with x
Then press Shift+3


It could be that your keyboard layout is different.
Using a UK layout, it would be Option + 3 : ⌥ + 3, but this does not work (Not sure why).
You can also remap your keys with the Google Labs feature : Custom keyboard shortcuts
"
4880,4880,7769,When to use layoutSubview in iOS,"I am writing iOS application for iPad that require custom layout.

The layout from portrait and landscape are totally difference, so it can't be solve by using UIAutoResizingMask.

I try to use the layoutSubview Method, but I detected that layout subview is called a lot (from UIScrollView).
How can i reduce the layoutSubview call to optimize the code , or I should call it by my self when ever the device is rotated. 

Thank.
",Isara Rungvitayakul,https://stackoverflow.com/users/475479,"For different landscape and portrait design use view controllers methods such as

-(void)willRotateToInterfaceOrientation:(UIInterfaceOrientation)toInterfaceOrientation duration:(NSTimeInterval)duration;
-(void)didRotateFromInterfaceOrientation:(UIInterfaceOrientation)fromInterfaceOrientation;
-(void)willAnimateRotationToInterfaceOrientation:(UIInterfaceOrientation)toInterfaceOrientation duration:(NSTimeInterval)duration;


If you create your custom view depending on current orientation, check this orientation by UIDeviceOrientationDidChangeNotification notification and write appropriate code.

in one of the init~ methods:

[[NSNotificationCenter defaultCenter] addObserver:self selector:@selector(didChangedOrientation:) name:UIDeviceOrientationDidChangeNotification object:nil];


And action

- (void) didChangedOrientation:(NSNotification *)sender{
UIDeviceOrientation orientation = [[UIDevice currentDevice] orientation];
if (UIDeviceOrientationIsPortrait(orientation)){}}

",beryllium,https://stackoverflow.com/users/194544,http://stackoverflow.com/questions/6953373/when-to-use-layoutsubview-in-ios,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.6666666666666666,0.0,0.6666666666666666,1.0,0.6666666666666666,0.6666666666666666,0.4444444444444444,0.3333333333333333,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.6666666666666666,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.8666666666666666,1.0,0.3333333333333333,0.0,1.0,When to use layoutsubview in IOS,"I am writing iOS application for iPad that require custom layout.

The layout from portrait and landscape are totally difference, so it can't be solve by using UIAutoResizingMask.

I try to use the layoutSubview Method, but I detected that layout subview is called a lot (from UIScrollView).
How can i reduce the layoutSubview call to optimize the code , or I should call it by my self when ever the device is rotated. 

Thank.
","For different landscape and portrait design use view controllers methods such as

-(void)willRotateToInterfaceOrientation:(UIInterfaceOrientation)toInterfaceOrientation duration:(NSTimeInterval)duration;
-(void)didRotateFromInterfaceOrientation:(UIInterfaceOrientation)fromInterfaceOrientation;
-(void)willAnimateRotationToInterfaceOrientation:(UIInterfaceOrientation)toInterfaceOrientation duration:(NSTimeInterval)duration;


If you create your custom view depending on current orientation, check this orientation by UIDeviceOrientationDidChangeNotification notification and write appropriate code.

in one of the init~ methods:

[[NSNotificationCenter defaultCenter] addObserver:self selector:@selector(didChangedOrientation:) name:UIDeviceOrientationDidChangeNotification object:nil];


And action

- (void) didChangedOrientation:(NSNotification *)sender{
UIDeviceOrientation orientation = [[UIDevice currentDevice] orientation];
if (UIDeviceOrientationIsPortrait(orientation)){}}

"
1138,1138,1782,Slowdown in large perl array,"I'm currently running a perl program where I have to take a 1 million line text file, break it down into chunks (anywhere between 50 and 50,000 lines per chunk), and run some calculations and such on them.  Right now, I load all of the data into array1.  I take array2 and use it to pull just the chunks of data I need.  I then do what I need to perform on array 2, and then go back and grab the next set.

example data

A, blah1, blah2

A, blah6, blah7

A, blah4, blah5

B, blah2, blah2

So I would grab the first three into array 2, sort them, then move on to the next set. My program works pretty well and efficiently to begin with, but it experiences a severe slowdown later on.

50K takes 50 seconds, 100k takes 184 seconds, 150k takes 360 seconds, 200k takes 581 seconds, and it only gets exponentially worse as the program continues (4500 seconds at line 500k)

No, I cannot use a database for this project, any suggestions?

my @Rows1=&lt;FILE&gt;;
my $temp = @Rows1;
for($k = 0; $k &lt; $temp; $k++)
{
    my @temp2array = ();
    my $temp2count = 0;
    my $thisrow = $Rows1[$k];
    my @thisarray = split(',', $thisrow);
    my $currcode = $thisarray[0];
    my $flag123 = 0;
    $temp2array[$temp2count] = $thisrow;
    $temp2count++;
    while ($flag123 == 0)
    {
        $nextrow = $tuRows1[$k + 1];
        @nextarray = split(',', $nextrow);
        if ($currcode eq $nextarray[0])
        {
            $temp2array[$temp2count] = $nextrow;
            $k++;
            $temp2count++;
        }
        else
        {
            $flag123 = 1;
        }
    }
}


I have edited my code to more resemble the answer below, and I've got these times:

50k = 42, 100k = 133, 150k = 280, 200k = 467, 250k = 699, 300k = 978, 350k = 1313

Its not exactly keeping linear, and by this trend, this prog will still take 14000+ seconds.  I'll investigate other parts of the code
",ThePirateSheep,https://stackoverflow.com/users/590982,"Loading an entire large file into memory will slow you down as your OS will need to start swapping pages of virtual memory. In such cases, it is best to deal with only the section of the file that you need.

In your case, you seem to be processing lines that have the same value in the first field together, so you could do something like:

my @lines = ();
my $current_key = '';

while (&lt;FILE&gt;) {
    my ($key) = split /,/;     # get first column
    if ($key ne $current_key) {
        # new key. Process all the lines from the previous key.
        if (@lines &gt; 0) {
            process(@lines);
        }
        @lines = ();
        $current_key = $key;
    }
    push @lines, $_
}
# don't forget the lines from the last key
if (@lines &gt; 0) {
    process(@lines);
}


This way, you are only storing in memory enough lines to make up one group.

(I am assuming that the input data is sorted or organized by the key. If that's not the case, you could make multiple passes through the file: a first pass to see what keys you will need to process, and subsequent passes to collect the lines associated with each key.)
",mob,https://stackoverflow.com/users/168657,http://stackoverflow.com/questions/4807740/slowdown-in-large-perl-array,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.4444444444444444,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,0.8888888888888888,0.9333333333333332,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.7777777777777778,Large Perl arrays slow down,"I'm currently running a perl program where I have to take a 1 million line text file, break it down into chunks (anywhere between 50 and 50,000 lines per chunk), and run some calculations and such on them.  Right now, I load all of the data into array1.  I take array2 and use it to pull just the chunks of data I need.  I then do what I need to perform on array 2, and then go back and grab the next set.

example data

A, blah1, blah2

A, blah6, blah7

A, blah4, blah5

B, blah2, blah2

So I would grab the first three into array 2, sort them, then move on to the next set. My program works pretty well and efficiently to begin with, but it experiences a severe slowdown later on.

50K takes 50 seconds, 100k takes 184 seconds, 150k takes 360 seconds, 200k takes 581 seconds, and it only gets exponentially worse as the program continues (4500 seconds at line 500k)

No, I cannot use a database for this project, any suggestions?

my @Rows1=&lt;FILE&gt;;
my $temp = @Rows1;
for($k = 0; $k &lt; $temp; $k++)
{
    my @temp2array = ();
    my $temp2count = 0;
    my $thisrow = $Rows1[$k];
    my @thisarray = split(',', $thisrow);
    my $currcode = $thisarray[0];
    my $flag123 = 0;
    $temp2array[$temp2count] = $thisrow;
    $temp2count++;
    while ($flag123 == 0)
    {
        $nextrow = $tuRows1[$k + 1];
        @nextarray = split(',', $nextrow);
        if ($currcode eq $nextarray[0])
        {
            $temp2array[$temp2count] = $nextrow;
            $k++;
            $temp2count++;
        }
        else
        {
            $flag123 = 1;
        }
    }
}


I have edited my code to more resemble the answer below, and I've got these times:

50k = 42, 100k = 133, 150k = 280, 200k = 467, 250k = 699, 300k = 978, 350k = 1313

Its not exactly keeping linear, and by this trend, this prog will still take 14000+ seconds.  I'll investigate other parts of the code
","Loading an entire large file into memory will slow you down as your OS will need to start swapping pages of virtual memory. In such cases, it is best to deal with only the section of the file that you need.

In your case, you seem to be processing lines that have the same value in the first field together, so you could do something like:

my @lines = ();
my $current_key = '';

while (&lt;FILE&gt;) {
    my ($key) = split /,/;     # get first column
    if ($key ne $current_key) {
        # new key. Process all the lines from the previous key.
        if (@lines &gt; 0) {
            process(@lines);
        }
        @lines = ();
        $current_key = $key;
    }
    push @lines, $_
}
# don't forget the lines from the last key
if (@lines &gt; 0) {
    process(@lines);
}


This way, you are only storing in memory enough lines to make up one group.

(I am assuming that the input data is sorted or organized by the key. If that's not the case, you could make multiple passes through the file: a first pass to see what keys you will need to process, and subsequent passes to collect the lines associated with each key.)
"
90,90,149,Refused visit a friend visa for Belgium,"I applied for a visa to visit a friend in Belgium last April 28, 2014 and I got the result recently (June 6, 2014) wherein it has been refused.

Reasons were:


The plan and the circumstances from the intend stay are insufficient.
Resolve to leave country before end of visa couldn't be determined.
No med-travel insurance.


I'm a Filipino citizen and applied from Manila. My boyfriend is sponsoring me. We were confident that I should be able to get the visa, because we both know that we have completed and submitted all the requirements that are needed for the visa. I wanted to appeal the refusal of my visa.

What are my options? I haven't yet received the official result of my refusal and will be going to the Belgium Embassy in Manila as per the schedule they have given me.

What sort of letter can I do to assist my situation?
",sha,https://travel.stackexchange.com/users/16434,"It's common for embassies to get nervous when your reason is to visit family / spouse / significant other, as sometimes this is what overstayers do - find a way in, and then just don't leave.  Therefore, your job is to assure them that:


You're not overstaying
You're just visiting your significant other
You have money to cover your time there
You have a return ticket booked
You have valid medical insurance to cover your time there, so that you won't be a medical problem for their country


To prove you're not trying to overstay and are just visiting, you simply print out your plane tickets showing your return.  If you have evidence that you're working or studying at home, a letter from your employer showing you're returning to work at a given date will help, or your uni showing the upcoming courses you're involved in.

You'll also need to print bank statements showing your current balance to show you've considered how to cover your time there.  If you've only got say, $200 and are planning to stay at the best hotels when asked, it'll raise flags. They're just making sure you don't get into financial difficulty while there.

Also make sure you get medical insurance, or show intent to get it (reserved funds) and print that out, showing that you're covered for the duration of the trip.

Finally if you have an itinerary (are travelling while there) write it out, so that you can clearly show what your intended journey is, how much it might cost, and so on.  A budget may even help! (Not normally required, but at this point, more documentation is good to help convince them).

You said you were confident you'd completed all requirements, but the letter clearly indicates you're missing a few things, so hopefully with the above items covered your next application will go more smoothly, and you can enjoy a trip to Belgium!
",Mark Mayo,https://travel.stackexchange.com/users/101,http://travel.stackexchange.com/questions/30314/refused-visit-a-friend-visa-for-belgium,CULTURE,travel.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,1.0,0.3333333333333333,1.0,0.6666666666666666,0.6666666666666666,1.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.3333333333333333,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.3333333333333333,0.3333333333333333,1.0,A friend visa denied to visit Belgium,"I applied for a visa to visit a friend in Belgium last April 28, 2014 and I got the result recently (June 6, 2014) wherein it has been refused.

Reasons were:


The plan and the circumstances from the intend stay are insufficient.
Resolve to leave country before end of visa couldn't be determined.
No med-travel insurance.


I'm a Filipino citizen and applied from Manila. My boyfriend is sponsoring me. We were confident that I should be able to get the visa, because we both know that we have completed and submitted all the requirements that are needed for the visa. I wanted to appeal the refusal of my visa.

What are my options? I haven't yet received the official result of my refusal and will be going to the Belgium Embassy in Manila as per the schedule they have given me.

What sort of letter can I do to assist my situation?
","It's common for embassies to get nervous when your reason is to visit family / spouse / significant other, as sometimes this is what overstayers do - find a way in, and then just don't leave.  Therefore, your job is to assure them that:


You're not overstaying
You're just visiting your significant other
You have money to cover your time there
You have a return ticket booked
You have valid medical insurance to cover your time there, so that you won't be a medical problem for their country


To prove you're not trying to overstay and are just visiting, you simply print out your plane tickets showing your return.  If you have evidence that you're working or studying at home, a letter from your employer showing you're returning to work at a given date will help, or your uni showing the upcoming courses you're involved in.

You'll also need to print bank statements showing your current balance to show you've considered how to cover your time there.  If you've only got say, $200 and are planning to stay at the best hotels when asked, it'll raise flags. They're just making sure you don't get into financial difficulty while there.

Also make sure you get medical insurance, or show intent to get it (reserved funds) and print that out, showing that you're covered for the duration of the trip.

Finally if you have an itinerary (are travelling while there) write it out, so that you can clearly show what your intended journey is, how much it might cost, and so on.  A budget may even help! (Not normally required, but at this point, more documentation is good to help convince them).

You said you were confident you'd completed all requirements, but the letter clearly indicates you're missing a few things, so hopefully with the above items covered your next application will go more smoothly, and you can enjoy a trip to Belgium!
"
2170,2170,3460,Bottom bracket bearing Issues,"Been having some bottom bracket (BB) woes. Noticed a click on the top of the left pedal stroke decided to re-grease the BB. Took it apart cleaned everything re-greased, put it back together. 
Roll forward a week.
Notice my cranks sticking here and there, gets progressively worse on the ride. Get it home and off the bike notice my bike has turned into a rain-stick (this provided no calming effect)
Que another strip down of the BB.
Upon inspection, I found all the bearing on the non lockring side of the where out of the cage, which now would no longer hold them. I pinched the cages with pilers to secure the ball bearings back in place. Re-greased repacked.
Lifted my bike out today for my cycle to work jingle-jingle; LOOSE BEARING!
Cycle to work was sub 3miles so risked it.
Want to take care of this ASAP, so my questions are:

1. I figure I am over-tighting the bottom bracket, causing the damage to the cage, however what else could cause?

BB info:


Campagnolo Italian threaded
plastic sleeve is in two parts, the smaller part pushes into the
other.
2 caged bearings from memory 8/9 bearings in each cage.
Two screw in cones one locking.


here is a pics of my spindle:


Brev whatever that means


2. What size bearing does an Italian threaded BB take?
",will,https://bicycles.stackexchange.com/users/3068,"Note that most bottom brackets don't use a cage.  Rather you get enough loose balls to fill the race, gob some grease into the race of the cup, press the balls into the grease, and install.  The cage should not be necessary to hold the balls in place.

In your case you may want to consider replacing the cups, bearings, and shaft with a cartridge -- much less to go wrong.
",Daniel R Hicks,https://bicycles.stackexchange.com/users/1584,http://bicycles.stackexchange.com/questions/9882/bottom-bracket-bearing-issues,CULTURE,bicycles.stackexchange.com,0.6666666666666666,0.6666666666666666,0.0,0.0,1.0,1.0,0.6666666666666666,0.3333333333333333,1.0,0.0,1.0,0.0,0.0,0.0,0.0,1.0,1.0,0.0,1.0,0.0,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.6666666666666666,1.0,0.8,1.0,0.0,1.0,1.0,Bearing problem of bottom bracket,"Been having some bottom bracket (BB) woes. Noticed a click on the top of the left pedal stroke decided to re-grease the BB. Took it apart cleaned everything re-greased, put it back together. 
Roll forward a week.
Notice my cranks sticking here and there, gets progressively worse on the ride. Get it home and off the bike notice my bike has turned into a rain-stick (this provided no calming effect)
Que another strip down of the BB.
Upon inspection, I found all the bearing on the non lockring side of the where out of the cage, which now would no longer hold them. I pinched the cages with pilers to secure the ball bearings back in place. Re-greased repacked.
Lifted my bike out today for my cycle to work jingle-jingle; LOOSE BEARING!
Cycle to work was sub 3miles so risked it.
Want to take care of this ASAP, so my questions are:

1. I figure I am over-tighting the bottom bracket, causing the damage to the cage, however what else could cause?

BB info:


Campagnolo Italian threaded
plastic sleeve is in two parts, the smaller part pushes into the
other.
2 caged bearings from memory 8/9 bearings in each cage.
Two screw in cones one locking.


here is a pics of my spindle:


Brev whatever that means


2. What size bearing does an Italian threaded BB take?
","Note that most bottom brackets don't use a cage.  Rather you get enough loose balls to fill the race, gob some grease into the race of the cup, press the balls into the grease, and install.  The cage should not be necessary to hold the balls in place.

In your case you may want to consider replacing the cups, bearings, and shaft with a cartridge -- much less to go wrong.
"
775,775,1227,awk - Group by and sum column values,"I have command to list system process by memory usage:

ps -A --sort -rss -o comm,pmem


Which list a table like

COMMAND         %MEM
firefox         28.2
chrome           5.4
compiz           4.8
atom             2.5
chrome           2.3
Xorg             2.3
skype            2.2
chrome           2.0
chrome           1.9
atom             1.9
nautilus         1.8
hud-service      1.5
evince           1.3


I would like to get total memory share per programs instead of per process of same programs. So I could get output like

COMMAND         %MEM
firefox         28.2
chrome          11.6
compiz           4.8
atom             4.4
Xorg             2.3
skype            2.2
nautilus         1.8
hud-service      1.5
evince           1.3


I thought about using awk, which I don't know much. Ended up with something like:

ps -A --sort -rss -o comm,pmem | awk -F ""\t"" '
{processes[$0] += $1;}
{End
for(i in processes) {
  print i,""\t"",processes[i];
}
}'


But it didn't work.

How can I correct this?
",Junaid,https://unix.stackexchange.com/users/15519,"cuonglm answer solves your typo, to get the values in ascending order (as asked in your comment), pipe the output through sort -n -k 2 (sort as numbers (-n, on second field (-k 2), after changing the print statement to output the floats as in your example:

$ ps -A --sort -rss -o comm,pmem | awk '
  NR == 1 { print; next }
  { a[$1] += $2 }
  END {
    for (i in a) {
      printf ""%-15s\t%.1f\n"", i, a[i];
    }
  }
' | sed 's/%MEM/-1MEM/' | sort -n -k 2 | sed 's/-1MEM/%MEM/'


Output (using your table as input instead of doing ps on my system):

COMMAND         %MEM
evince          1.3
hud-service     1.5
nautilus        1.8
skype           2.2
Xorg            2.3
atom            4.4
compiz          4.8
chrome          11.6
firefox         28.2


Alternatively you can pipe the output through this python program (if you want descending sort (as in your example), change the reverse=False into reverse=True:


#! /usr/bin/env python
# coding: utf-8

import sys
import operator

d = {}
for line in sys.stdin:
    try:
        name, val = line.split()
        val = float(val)
        d.setdefault(name, [0.0])[0] += val
    except ValueError:
        print line,

for x in sorted(d.items(), reverse=False, key=operator.itemgetter(1)):
    print ""{:16s}{:&gt;4}"".format(x[0], x[1][0])

",Anthon,https://unix.stackexchange.com/users/33055,http://unix.stackexchange.com/questions/167280/awk-group-by-and-sum-column-values,TECHNOLOGY,unix.stackexchange.com,0.8888888888888888,0.4444444444444444,0.0,0.5,1.0,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.5555555555555556,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.9333333333333332,1.0,0.3333333333333333,0.0,0.7777777777777778,Awk group and sum by column value,"I have command to list system process by memory usage:

ps -A --sort -rss -o comm,pmem


Which list a table like

COMMAND         %MEM
firefox         28.2
chrome           5.4
compiz           4.8
atom             2.5
chrome           2.3
Xorg             2.3
skype            2.2
chrome           2.0
chrome           1.9
atom             1.9
nautilus         1.8
hud-service      1.5
evince           1.3


I would like to get total memory share per programs instead of per process of same programs. So I could get output like

COMMAND         %MEM
firefox         28.2
chrome          11.6
compiz           4.8
atom             4.4
Xorg             2.3
skype            2.2
nautilus         1.8
hud-service      1.5
evince           1.3


I thought about using awk, which I don't know much. Ended up with something like:

ps -A --sort -rss -o comm,pmem | awk -F ""\t"" '
{processes[$0] += $1;}
{End
for(i in processes) {
  print i,""\t"",processes[i];
}
}'


But it didn't work.

How can I correct this?
","cuonglm answer solves your typo, to get the values in ascending order (as asked in your comment), pipe the output through sort -n -k 2 (sort as numbers (-n, on second field (-k 2), after changing the print statement to output the floats as in your example:

$ ps -A --sort -rss -o comm,pmem | awk '
  NR == 1 { print; next }
  { a[$1] += $2 }
  END {
    for (i in a) {
      printf ""%-15s\t%.1f\n"", i, a[i];
    }
  }
' | sed 's/%MEM/-1MEM/' | sort -n -k 2 | sed 's/-1MEM/%MEM/'


Output (using your table as input instead of doing ps on my system):

COMMAND         %MEM
evince          1.3
hud-service     1.5
nautilus        1.8
skype           2.2
Xorg            2.3
atom            4.4
compiz          4.8
chrome          11.6
firefox         28.2


Alternatively you can pipe the output through this python program (if you want descending sort (as in your example), change the reverse=False into reverse=True:


#! /usr/bin/env python
# coding: utf-8

import sys
import operator

d = {}
for line in sys.stdin:
    try:
        name, val = line.split()
        val = float(val)
        d.setdefault(name, [0.0])[0] += val
    except ValueError:
        print line,

for x in sorted(d.items(), reverse=False, key=operator.itemgetter(1)):
    print ""{:16s}{:&gt;4}"".format(x[0], x[1][0])

"
4560,4560,7227,What do I do wrong to get hip aches after biking?,"I ride about 17 miles each session. After the ride, the outside of my hips sore: only the parts near the outermost joints, most likely the tendon (although this is only a guess). My knees are fine, my ankles are fine, etc.

The only thing that might not fit perfectly for me is the seat height. I'd rather have a longer post so I can lift the seat up an inch or two. Do you think this might create the soreness in the area of the outer hips? 
",RJIGO,https://bicycles.stackexchange.com/users/3628,"I have the same problem at the moment... I am not too sure what causes it but I do notice the pain happens when I power up hills whilst seated in a high gears. I do a 3.5 mile commute everyday with a couple of short uphill bursts. I might try and use a lower gear in a standing position. I am also experimenting with different seats and seat post height, I think since I have lowered the seat height the pain is not as bad. I have also experienced some knee pain
",i-am-andy,https://bicycles.stackexchange.com/users/3578,http://bicycles.stackexchange.com/questions/8476/what-do-i-do-wrong-to-get-hip-aches-after-biking,CULTURE,bicycles.stackexchange.com,1.0,1.0,0.0,0.0,1.0,1.0,0.6666666666666666,0.8888888888888888,0.3333333333333333,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.5555555555555556,0.5555555555555556,1.0,0.7777777777777778,0.4666666666666667,0.0,0.0,1.0,1.0,How does buttock ache do after cycling?,"I ride about 17 miles at a time. After riding, my buttocks ache on the outside: only the part near the most lateral joint, most likely the tendon (although this is only a guess). My knees are good, my ankles are good, and so on.","I have the same problem now... I'm not sure what caused it, but I do notice that when I'm in a high gear, when I'm powering up the mountain, pain happens. I commute 3.5 miles a day, with a couple of short uphill sprints. I can try to stand in a lower gear. I'm also trying different seat and seat pillar heights. I think since I lowered the seat height, the pain is not so serious. I've also experienced knee pain"
2542,2542,4048,What should my credit limit be?,"I have two credit cards (through the same bank).  The first I got at age 18, and the 2nd I applied for while in grad school for better rewards.  I use credit cards (primarily the more recent one) for routine monthly expenses and I pay them off in full every month and reap the rewards.  The limits were pretty low while I was in school, but every 6 months or so they would notify me that they were raising my credit limit by a modest amount.  This continued for a while, but it stopped not long after I left school (which roughly coincided with banks becoming more reluctant to offer credit).

My income has increased several hundred percent over what it was while I was in grad school, and I feel my credit limits do not reflect that.  My combined credit limit between the two cards is a little over 12% of my yearly gross income.  I feel this is probably low, and I might like to increase it both to increase my credit score and to easier allow for multiple large purchases (computer, furniture, etc.) in the same month without using an excessively high portion of my available credit.  What guidelines should I use to determine how much of an increase, if any, to request?
",Michael McGowan,https://money.stackexchange.com/users/3360,"I think it would be hard to make the decision based on your credit score, b/c there are always different answers about what affects, and how much. If you don't make big mistakes, like defaulting, I'm sure your credit score will take care of itself.

If you feel like you want more flexibility in your limits, then call and see what you can get. I have around 6 cards, at least 2 have limits over 10k, and my credit score has been over 800 for years. I've opened and closed various cards, and had limits rise over the years and haven't been constrained in getting mortgage or refinancing. 
",Andy Wiesendanger,https://money.stackexchange.com/users/3010,http://money.stackexchange.com/questions/8024/what-should-my-credit-limit-be,LIFE_ARTS,money.stackexchange.com,0.6666666666666666,0.3333333333333333,0.0,0.3333333333333333,0.0,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.8888888888888888,0.7777777777777778,0.3333333333333333,1.0,1.0,0.6,0.0,0.0,0.0,1.0,What's my credit line?,"I have two credit cards (through the same bank). The first was when I was 18, and the second was when I applied for Graduate School in order to get better rewards. I use my credit card (mainly the latest one) to pay for my daily expenses every month. Every month, I will pay in full and get a return. When I went to school, the credit limit was very low, but every six months or so, they would inform me that they would increase my credit limit appropriately. This continued for a while, but stopped shortly after I left school (roughly in line with the growing reluctance of banks to provide credit).","I think it would be hard to make the decision based on your credit score, b/c there are always different answers about what affects, and how much. If you don't make big mistakes, like defaulting, I'm sure your credit score will take care of itself.

If you feel like you want more flexibility in your limits, then call and see what you can get. I have around 6 cards, at least 2 have limits over 10k, and my credit score has been over 800 for years. I've opened and closed various cards, and had limits rise over the years and haven't been constrained in getting mortgage or refinancing. 
"
3786,3786,6021,Would Esther really have kept silent?,"In Esther 7:4 we read


  וְאִלּוּ לַעֲבָדִים וְלִשְׁפָחוֹת נִמְכַּרְנוּ, הֶחֱרַשְׁתִּי--כִּי אֵין הַצָּר שֹׁוֶה, בְּנֵזֶק הַמֶּלֶךְ ...
  
  ... But if we had been sold for bondmen and bondwomen, I had held my peace, for the adversary is not worthy that the king be endamaged.


Is this true? Had, in fact, the entire Jewish population been sold as slaves Esther would not have said a word about it? Is this simply hyperbole? How do we understand this? 
",none,https://judaism.stackexchange.com/users/1255,"The Meam Loez says that she meant that Achashveirosh shouldn't kill the Jews, as he would thereby lose out. Had the Jews been sold as slaves, Achashveirosh could have always changed his mind later on (once realized how useful the Jews are). However, once they would be dead, he couldn't have done anything.
",Shmuel Brin,https://judaism.stackexchange.com/users/732,http://judaism.stackexchange.com/questions/14737/would-esther-really-have-kept-silent,CULTURE,judaism.stackexchange.com,0.8888888888888888,0.6666666666666666,0.3333333333333333,0.3333333333333333,1.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,1.0,0.0,0.6666666666666666,1.0,0.0,0.3333333333333333,0.0,0.3333333333333333,0.3333333333333333,0.0,1.0,0.0,0.8888888888888888,0.6666666666666666,0.5555555555555556,0.7777777777777778,1.0,0.8,0.0,0.0,1.0,1.0,Will Esther really remain silent?,"In Esther 7:4 we read


  וְאִלּוּ לַעֲבָדִים וְלִשְׁפָחוֹת נִמְכַּרְנוּ, הֶחֱרַשְׁתִּי--כִּי אֵין הַצָּר שֹׁוֶה, בְּנֵזֶק הַמֶּלֶךְ ...
  
  ... But if we had been sold for bondmen and bondwomen, I had held my peace, for the adversary is not worthy that the king be endamaged.


Is this true? Had, in fact, the entire Jewish population been sold as slaves Esther would not have said a word about it? Is this simply hyperbole? How do we understand this? 
","The Meam Loez says that she meant that Achashveirosh shouldn't kill the Jews, as he would thereby lose out. Had the Jews been sold as slaves, Achashveirosh could have always changed his mind later on (once realized how useful the Jews are). However, once they would be dead, he couldn't have done anything.
"
4420,4420,7022,Birthday paradox: meaning of random,"In the wikipedia page (http://en.wikipedia.org/wiki/Birthday_problem) on birthday paradox the following statement has been said : ""the probability that, in a set of $n$ ""randomly chosen"" people, some pair of them will have the same birthday. We assume that that each day of the year is equally probable for a birthday.""

My question is what is the meaning of ""randomly chosen"" here ? Is the assumption of equally probable for a birthday needed separately ? Does not the word ""randomly chosen"" imply the equal probability ? 
",RIchard Williams,https://math.stackexchange.com/users/21982,"The assumption is that each person's birthday is chosen randomly from the $365$ days of the year.
",Ross Millikan,https://math.stackexchange.com/users/1827,http://math.stackexchange.com/questions/370570/birthday-paradox-meaning-of-random,SCIENCE,math.stackexchange.com,0.7777777777777778,0.4444444444444444,0.0,0.0,1.0,0.3333333333333333,0.5555555555555556,0.4444444444444444,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,0.7777777777777778,0.5555555555555556,0.7777777777777778,1.0,0.7333333333333333,0.0,0.0,0.3333333333333333,0.8888888888888888,Birthday paradox: the significance of randomness,"In the wikipedia page (http://en.wikipedia.org/wiki/Birthday_problem) on birthday paradox the following statement has been said : ""the probability that, in a set of $n$ ""randomly chosen"" people, some pair of them will have the same birthday. We assume that that each day of the year is equally probable for a birthday.""

My question is what is the meaning of ""randomly chosen"" here ? Is the assumption of equally probable for a birthday needed separately ? Does not the word ""randomly chosen"" imply the equal probability ? 
",Suppose everyone's birthday is chosen at random from the number of days in a year of $365.
3301,3301,5266,.NET class library DLL refresh,"I'm using class library in .NET.

I'm generating DLL but it is being generated without the refresh file, so I can not update it automacatilly in my project.

How do you generate the refresh file with the DLL when compiling?
Or have a way to automatically update the DLL without refresh file?
",ozsenegal,https://stackoverflow.com/users/257234,"While adding references to a dll/library, You can add your library project as a Project reference. 

This way, it will automatically get compiled/refreshed when you compile the main project.

If you are asking about getting the latest files from Source Control, before compiling then you will have to write pre/post build events.
",Hps,https://stackoverflow.com/users/211633,http://stackoverflow.com/questions/4398484/net-class-library-dll-refresh,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.3333333333333333,0.0,0.0,1.0,0.6666666666666666,0.6666666666666666,0.4444444444444444,0.6666666666666666,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.3333333333333333,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.8888888888888888,. net class library DLL refresh,"I'm using class library in .NET.

I'm generating DLL but it is being generated without the refresh file, so I can not update it automacatilly in my project.

How do you generate the refresh file with the DLL when compiling?
Or have a way to automatically update the DLL without refresh file?
","While adding references to a dll/library, You can add your library project as a Project reference. 

This way, it will automatically get compiled/refreshed when you compile the main project.

If you are asking about getting the latest files from Source Control, before compiling then you will have to write pre/post build events.
"
1051,1051,1652,"Why is MapReduce in CouchDB called ""incremental""?","I am reading the O'Reilly CouchDB book. I am puzzled by the reduce/re-reduce/incremental-MapReduce part on page 64. Too much is left to rhetory in the O'Reilly book with the sentence


  If you're interested in pushing the ede of CouchDB's incremental reduce functionality, have a look at Google's paper on Sawzall, ...


If I understand the word ""incremental"" correctly, it refers to some sort of addition -operation in the B-tree data structure. I cannot yet see why it is somehow special over typical map-reduce, probably not yet understanding it. In CouchDB, it mentions that there is no side-effects with map function - does that hold true with reduce too?

Why is MapReduce in CouchDB is called ""incremental""?

Helper questions


Explain the quote about incremental MapReduce with Sawzall.
Why two terms for the same thing i.e. reduction? Reduce and re-reduce?


References


A Google paper about Sawzall.
Introduction to CouchDB views in the CouchDB wiki and a lot of blurry blog references.
CouchDB O'Reilly book

",hhh,https://stackoverflow.com/users/164148,"This page that you linked explained it.

The view (which is the whole point of map reduce in CouchDB) can be updated by re-indexing only the documents that have changed since the last index update. That's the incremental part.

This can be achieved by requiring the reduce function to be referentially transparent, which means that it always returns the same output for a given input.

The reduce function also must be commutative and associative for the array value input, which means that if you run the reducer on the output of that same reducer, you will receive the same result. In that wiki page it is expressed like:

f(Key, Values) == f(Key, [ f(Key, Values) ] )


Rereduce is where you take the output from several reducer calls and run that through the reducer again. This sometimes is required because CouchDB sends stuff through the reducer in batches, so sometimes not all keys that need to be reduced will be sent through in once shot.
",nickgroenke,https://stackoverflow.com/users/1087981,http://stackoverflow.com/questions/11236676/why-is-mapreduce-in-couchdb-called-incremental,STACKOVERFLOW,stackoverflow.com,1.0,0.5555555555555556,0.0,1.0,1.0,1.0,0.6666666666666666,0.4444444444444444,0.6666666666666666,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,0.8888888888888888,"Why is MapReduce in CouchDB called ""incremental""?","I am reading the O'Reilly CouchDB book. I am puzzled by the reduce/re-reduce/incremental-MapReduce part on page 64. Too much is left to rhetory in the O'Reilly book with the sentence


  If you're interested in pushing the ede of CouchDB's incremental reduce functionality, have a look at Google's paper on Sawzall, ...


If I understand the word ""incremental"" correctly, it refers to some sort of addition -operation in the B-tree data structure. I cannot yet see why it is somehow special over typical map-reduce, probably not yet understanding it. In CouchDB, it mentions that there is no side-effects with map function - does that hold true with reduce too?

Why is MapReduce in CouchDB is called ""incremental""?

Helper questions


Explain the quote about incremental MapReduce with Sawzall.
Why two terms for the same thing i.e. reduction? Reduce and re-reduce?


References


A Google paper about Sawzall.
Introduction to CouchDB views in the CouchDB wiki and a lot of blurry blog references.
CouchDB O'Reilly book

","This page that you linked explained it.

The view (which is the whole point of map reduce in CouchDB) can be updated by re-indexing only the documents that have changed since the last index update. That's the incremental part.

This can be achieved by requiring the reduce function to be referentially transparent, which means that it always returns the same output for a given input.

The reduce function also must be commutative and associative for the array value input, which means that if you run the reducer on the output of that same reducer, you will receive the same result. In that wiki page it is expressed like:

f(Key, Values) == f(Key, [ f(Key, Values) ] )


Rereduce is where you take the output from several reducer calls and run that through the reducer again. This sometimes is required because CouchDB sends stuff through the reducer in batches, so sometimes not all keys that need to be reduced will be sent through in once shot.
"
2603,2603,4142,Is it okay to vacuum a laptop keyboard?,"Is it okay to vacuum a laptop keyboard? Would it cause any damage?
",dsafdsf,https://superuser.com/users/97559,"You can use vacuum cleaner, but make sure your laptop's keyboard doesn't have ""pop off"" keys that could possibly be sucked up by the vacuum.

A can of compressed air will safely blow dust right out of the little crevices between your keys.

You may want to read this article from LifeHacker.
",Mehper C. Palavuzlar,https://superuser.com/users/13567,http://superuser.com/questions/334626,TECHNOLOGY,superuser.com,1.0,1.0,0.0,1.0,1.0,1.0,0.8888888888888888,0.7777777777777778,0.6666666666666666,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,1.0,1.0,0.7777777777777778,1.0,1.0,1.0,0.6666666666666666,0.0,1.0,0.8888888888888888,Can I vacuum my laptop keyboard?,Can I vacuum my laptop keyboard? Is there any damage?,"You can use vacuum cleaner, but make sure your laptop's keyboard doesn't have ""pop off"" keys that could possibly be sucked up by the vacuum.

A can of compressed air will safely blow dust right out of the little crevices between your keys.

You may want to read this article from LifeHacker.
"
5118,5118,8138,How much of the universe is observable at visible wavelengths?,"Knowing that:


The Zone of Avoidance (Looking towards the center of the Milky Way) blocks roughly 20%
Each Milky Way star has an angular size, depending on proximity, that obscures a certain percentage of our optical view.
Each Galaxy has an angular size, depending on proximity, that obscures a certain percentage of our optical view.


And so on through Galaxy Clusters, Superstructures, etc...

What percentage of our universe can we not see at visible wavelengths?
",PJL71,https://physics.stackexchange.com/users/16638,"Have a look at the Hubble Deep Field image.

I downloaded the 1024x1024 version of this and the Photoshop histogram reports that about 95% of the image is dark. From this (somewhat cavalier) measurement I deduce that about 5% of the sky is blocked out by galaxies up to 13 billion years old. I'm not sure what difference going back even further in time would make, though presumably if you go back far enough the surface of last scattering would block out 100% of the field.

Note that the deep field deliberately chose a direction in which there were few stars, however only the bigger closer stars show a visible disk through Hubble, so I'd guess that the stars make little difference. Dust clouds will make far more of a difference, but you've already accounted for that by taking the Milky Way into account.

Response to comment:

How about the picture in http://www.eso.org/public/images/eso1243c/ (there's nothing special about this - I just Googled for ""wide field view of sky"")? The Adobe histogram trick reports around 95% of the image is dark, though the cutoff isn't that sharp so it could be as little as 90%.

This image won't show faint galaxies, but on the other hand the limited resolution makes the stars look bigger than they should be (i.e. they cover more pixels). I'm not sure how you'd come up with a definitive answer since it depends on the resolution and sensitivity of your telescope. Still, I'd guess somewhere around 5% is not a bad estimate.

Later still:

Actually this is quite interesting in a Friday afternoon sort of way. Consider this:

The Milky way contains 100 billion stars and is about 100,000 light years across. The Sun is about 8.3 light minutes away. Suppose the average star is the same size as the Sun (probably an overestimate), and the average distance from the Sun to other stars is 25,000 light years (the distance to the centre of the galaxy), then the average star appears about 1.5 billion times smaller then the Sun. So altogether the 100 billion stars cover about 65 times as much sky as the Sun covers. The Sun subtends about half a degree, which is about 0.0005% of the sky, so all the stars in the Milky way cover about 0.03% of the sky. That backs up my claim that the area covered by the stars can be ignored.
",John Rennie,https://physics.stackexchange.com/users/1325,http://physics.stackexchange.com/questions/46189/how-much-of-the-universe-is-observable-at-visible-wavelengths,SCIENCE,physics.stackexchange.com,1.0,1.0,0.0,1.0,1.0,0.6666666666666666,0.6666666666666666,0.7777777777777778,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,1.0,1.0,0.8888888888888888,1.0,1.0,0.8666666666666666,0.3333333333333333,0.3333333333333333,1.0,1.0,How much of the universe can be observed in visible light?,"Knowing that:


The Zone of Avoidance (Looking towards the center of the Milky Way) blocks roughly 20%
Each Milky Way star has an angular size, depending on proximity, that obscures a certain percentage of our optical view.
Each Galaxy has an angular size, depending on proximity, that obscures a certain percentage of our optical view.


And so on through Galaxy Clusters, Superstructures, etc...

What percentage of our universe can we not see at visible wavelengths?
","Have a look at the Hubble Deep Field image.

I downloaded the 1024x1024 version of this and the Photoshop histogram reports that about 95% of the image is dark. From this (somewhat cavalier) measurement I deduce that about 5% of the sky is blocked out by galaxies up to 13 billion years old. I'm not sure what difference going back even further in time would make, though presumably if you go back far enough the surface of last scattering would block out 100% of the field.

Note that the deep field deliberately chose a direction in which there were few stars, however only the bigger closer stars show a visible disk through Hubble, so I'd guess that the stars make little difference. Dust clouds will make far more of a difference, but you've already accounted for that by taking the Milky Way into account.

Response to comment:

How about the picture in http://www.eso.org/public/images/eso1243c/ (there's nothing special about this - I just Googled for ""wide field view of sky"")? The Adobe histogram trick reports around 95% of the image is dark, though the cutoff isn't that sharp so it could be as little as 90%.

This image won't show faint galaxies, but on the other hand the limited resolution makes the stars look bigger than they should be (i.e. they cover more pixels). I'm not sure how you'd come up with a definitive answer since it depends on the resolution and sensitivity of your telescope. Still, I'd guess somewhere around 5% is not a bad estimate.

Later still:

Actually this is quite interesting in a Friday afternoon sort of way. Consider this:

The Milky way contains 100 billion stars and is about 100,000 light years across. The Sun is about 8.3 light minutes away. Suppose the average star is the same size as the Sun (probably an overestimate), and the average distance from the Sun to other stars is 25,000 light years (the distance to the centre of the galaxy), then the average star appears about 1.5 billion times smaller then the Sun. So altogether the 100 billion stars cover about 65 times as much sky as the Sun covers. The Sun subtends about half a degree, which is about 0.0005% of the sky, so all the stars in the Milky way cover about 0.03% of the sky. That backs up my claim that the area covered by the stars can be ignored.
"
4995,4995,7952,Intuition / Premonition / Precognition / Instinct / Gut feeling / Hunch,"What is the difference between them in terms of meaning and usage in daily life.

Can we say :


  I have a Intuition  / Premonition / Precognition / Instinct /  Gut
  feeling / Hunch you are going to pass
  driver test successfully.
  
  I have a  Intuition  / Premonition / Precognition / Instinct /  Gut
  feeling / Hunch that if I accept this job offer, it is not going to affect
  my career positively.
  
  I have a Intuition  / Premonition / Precognition / Instinct /  Gut
   feeling / Hunch that my son and your son are going to get along well even they have not met yet.

",Mrt,https://ell.stackexchange.com/users/11631,"In order of 'magnitude'

Precognition - you really actually knew, for an absolute immutable fact, that this would happen.

Premonition - something came to you in a dream &amp; told you it would happen.

Both the above, of course, in the real world - absolute tosh… yet sometimes used for extreme emphasis (or by raving lunatics;-).

Instinct - Instinct is the thing that puts your hands out in front of your face if you fall. It requires no conscious thought whatsoever.

Intuition - you can intuit from relatively sparse evidence, if you have sufficient background in the subject being considered. You almost 'know it without thinking'.

Gut feeling - uses a hint of both the above &amp; a pinch of the last one..

Hunch - mainly guesswork, based on little actual evidence.

Unless you are exaggerating for effect - dramatic or comedic - you ought to choose based on how 'big a deal' it really is &amp; how much evidence &amp;/or conscious thought went into your conclusion.
",Tetsujin,https://ell.stackexchange.com/users/11747,http://ell.stackexchange.com/questions/56681/intuition-premonition-precognition-instinct-gut-feeling-hunch,CULTURE,ell.stackexchange.com,1.0,1.0,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.0,0.6666666666666666,0.0,0.3333333333333333,0.0,0.6666666666666666,0.0,0.0,0.0,0.3333333333333333,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.3333333333333333,0.3333333333333333,1.0,Intuition / presentiment / presentiment / intuition / intuition / intuition,"What is the difference between them in terms of meaning and usage in daily life.

Can we say :


  I have a Intuition  / Premonition / Precognition / Instinct /  Gut
  feeling / Hunch you are going to pass
  driver test successfully.
  
  I have a  Intuition  / Premonition / Precognition / Instinct /  Gut
  feeling / Hunch that if I accept this job offer, it is not going to affect
  my career positively.
  
  I have a Intuition  / Premonition / Precognition / Instinct /  Gut
   feeling / Hunch that my son and your son are going to get along well even they have not met yet.

","In order of 'magnitude'

Precognition - you really actually knew, for an absolute immutable fact, that this would happen.

Premonition - something came to you in a dream &amp; told you it would happen.

Both the above, of course, in the real world - absolute tosh… yet sometimes used for extreme emphasis (or by raving lunatics;-).

Instinct - Instinct is the thing that puts your hands out in front of your face if you fall. It requires no conscious thought whatsoever.

Intuition - you can intuit from relatively sparse evidence, if you have sufficient background in the subject being considered. You almost 'know it without thinking'.

Gut feeling - uses a hint of both the above &amp; a pinch of the last one..

Hunch - mainly guesswork, based on little actual evidence.

Unless you are exaggerating for effect - dramatic or comedic - you ought to choose based on how 'big a deal' it really is &amp; how much evidence &amp;/or conscious thought went into your conclusion.
"
6045,6045,9592,SQL Help in Access – Looking for the Absence of Data,"I am trying to find the fastest way to find all of the records in a parent table that do not have certain records in a child table. For example, I want the query to return all of the family records where there are no male children or no children at all. 

Example 1

This is painfully slow:

SELECT * FROM Families
WHERE Families.FamilyID NOT IN(SELECT FamilyID FROM Children WHERE Children.Gender=""m"")

Example 2

This is faster:

SELECT * FROM Families
WHERE NOT EXISTS(SELECT * FROM Children WHERE Children.Gender=""m"" AND Children.FamilyID = Families.FamilyID)

Example 3

This is the fastest, but I'm worried about investing in it because I can't find any documentation on it. I don't even know what it's called. For want of a better term, we have been calling it an ""anonymous query"". 

SELECT * FROM Families
LEFT JOIN
[SELECT * FROM Children WHERE Gender=""m""]. AS AliasChildren
ON Families.FamilyID=AliasChildren.FamilyID
WHERE AliasChildren.FamilyID IS NULL

So my question is this:


What is this thing called in example 3?
Is it a ""mainstream"" feature of Access that
will be supported in the future?
Where can I find documentation on
it (this might be easier once I know what it's called)?


Thanks!
",Shane Miskin,https://stackoverflow.com/users/16415,"What is this thing called in example 3?
It is called a ""Derrived table""

Is it a ""mainstream"" feature of Access that will be supported in the future?
It is a standard feature of ANSI SQL as far as I know and is very commonly used.

Where can I find documentation on it (this might be easier once I know what it's called)? 
Here is a blog article about them

In any case the query posed by Mitch is your best bet:

SELECT *   
FROM Families   
LEFT JOIN Children  
  ON (Families.FamilyID = Children.FamilyID) AND (Children.Gender=""m"")  
WHERE (Children.FamilyID IS NULL)

",JohnFx,https://stackoverflow.com/users/30018,http://stackoverflow.com/questions/752048/sql-help-in-access-looking-for-the-absence-of-data,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.4444444444444444,0.0,0.6666666666666666,1.0,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.6666666666666666,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.0,0.3333333333333333,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.6666666666666666,0.3333333333333333,0.3333333333333333,1.0,SQL help in access - finding missing data,"I am trying to find the fastest way to find all of the records in a parent table that do not have certain records in a child table. For example, I want the query to return all of the family records where there are no male children or no children at all. 

Example 1

This is painfully slow:

SELECT * FROM Families
WHERE Families.FamilyID NOT IN(SELECT FamilyID FROM Children WHERE Children.Gender=""m"")

Example 2

This is faster:

SELECT * FROM Families
WHERE NOT EXISTS(SELECT * FROM Children WHERE Children.Gender=""m"" AND Children.FamilyID = Families.FamilyID)

Example 3

This is the fastest, but I'm worried about investing in it because I can't find any documentation on it. I don't even know what it's called. For want of a better term, we have been calling it an ""anonymous query"". 

SELECT * FROM Families
LEFT JOIN
[SELECT * FROM Children WHERE Gender=""m""]. AS AliasChildren
ON Families.FamilyID=AliasChildren.FamilyID
WHERE AliasChildren.FamilyID IS NULL

So my question is this:


What is this thing called in example 3?
Is it a ""mainstream"" feature of Access that
will be supported in the future?
Where can I find documentation on
it (this might be easier once I know what it's called)?


Thanks!
","What is this thing called in example 3?
It is called a ""Derrived table""

Is it a ""mainstream"" feature of Access that will be supported in the future?
It is a standard feature of ANSI SQL as far as I know and is very commonly used.

Where can I find documentation on it (this might be easier once I know what it's called)? 
Here is a blog article about them

In any case the query posed by Mitch is your best bet:

SELECT *   
FROM Families   
LEFT JOIN Children  
  ON (Families.FamilyID = Children.FamilyID) AND (Children.Gender=""m"")  
WHERE (Children.FamilyID IS NULL)

"
3325,3325,5308,how can i use regex to get a certain string of a file,"with linux bash shell , how can i use regex to get a certain string of a file

by example:

for filename *.tgz
do 

""get the certain string of filename (in my case, get 2010.04.12 of file 2010.01.12myfile.tgz)""

done  

or should I turn to perl

Merci

frank
",chun,https://stackoverflow.com/users/304910,"#!/bin/sh
a=""2010.04.18Myfile.tgz""
echo ${a%%+([a-zA-Z.])}


bash' regexp are quite powerful (at least compared to standard sh or command.com :-))
",topskip,https://stackoverflow.com/users/317915,http://stackoverflow.com/questions/2673919/how-can-i-use-regex-to-get-a-certain-string-of-a-file,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.6666666666666666,0.0,0.0,1.0,1.0,0.5555555555555556,0.4444444444444444,0.6666666666666666,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.4444444444444444,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.9,1.0,0.0,0.0,0.4444444444444444,How to use regex to get specific strings of files,"with linux bash shell , how can i use regex to get a certain string of a file

by example:

for filename *.tgz
do 

""get the certain string of filename (in my case, get 2010.04.12 of file 2010.01.12myfile.tgz)""

done  

or should I turn to perl

Merci

frank
","#!/bin/sh
a=""2010.04.18Myfile.tgz""
echo ${a%%+([a-zA-Z.])}


bash' regexp are quite powerful (at least compared to standard sh or command.com :-))
"
4429,4429,7035,"What is the difference between ""section"" and ""part""?","What is the difference between ""section"" and ""part""?  

The Longman Dictionary of Contemporary English says for ""section"":  


  one of the parts that something such as an object or place is divided into


and says for ""part"":  


  a piece or feature of something such as an object, area, event, or period of time


I know that ""section"" is smaller than ""part"" in size, but I'm totally confused about their usage in sentences. For example, is ""the front section of the car was damaged"" correct grammatically? Or is ""in sections of Canada, French is the first language""  correct?
",Vahid Damanafshan,https://english.stackexchange.com/users/31675,"These are general words that don't have concrete definitions in the sense that you seem to be driving at. Both are used when some large ""thing"" is divided into smaller ""things"". There's no rule that a section is 1/10 of the whole while a part is 1/20 of the whole or any such.

Note that while ""part"" can be used generally to mean a subdivision, it also has the more specific meaning of a discrete mechanical component within a larger assembly. Like we routinely refer to ""car parts"" meaning spark plugs, oil filters, alternators, etc. But then these parts can often be broken down into yet smaller parts. Like an alternator may have a rotor, a stator, an armature, mounting bolts, etc. So in the case of a mechanical device, I'd avoid using ""part"" in the more generic sense. Like I'd say ""the front section of a car"" rather than ""the front part of a car"".

It's not necessarily true that a section is smaller than a part. If you said, ""For this discussion, we will divide the nation into three major sections, and each of those sections into several parts"", I can't imagine that anyone would find that confusing on the grounds that parts should be divided into sections and not vice versa. Divide things up as is convenient in context.
",Jay,https://english.stackexchange.com/users/13140,http://english.stackexchange.com/questions/100285/what-is-the-difference-between-section-and-part,CULTURE,english.stackexchange.com,0.8888888888888888,0.8888888888888888,0.0,0.0,1.0,0.0,0.6666666666666666,0.8333333333333334,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.6666666666666666,0.0,0.8888888888888888,0.8888888888888888,0.7777777777777778,1.0,1.0,0.8666666666666666,0.0,0.0,1.0,0.8888888888888888,"What's the difference between ""part"" and ""part""?","What is the difference between ""section"" and ""part""?  

The Longman Dictionary of Contemporary English says for ""section"":  


  one of the parts that something such as an object or place is divided into


and says for ""part"":  


  a piece or feature of something such as an object, area, event, or period of time


I know that ""section"" is smaller than ""part"" in size, but I'm totally confused about their usage in sentences. For example, is ""the front section of the car was damaged"" correct grammatically? Or is ""in sections of Canada, French is the first language""  correct?
","These are general words that don't have concrete definitions in the sense that you seem to be driving at. Both are used when some large ""thing"" is divided into smaller ""things"". There's no rule that a section is 1/10 of the whole while a part is 1/20 of the whole or any such.

Note that while ""part"" can be used generally to mean a subdivision, it also has the more specific meaning of a discrete mechanical component within a larger assembly. Like we routinely refer to ""car parts"" meaning spark plugs, oil filters, alternators, etc. But then these parts can often be broken down into yet smaller parts. Like an alternator may have a rotor, a stator, an armature, mounting bolts, etc. So in the case of a mechanical device, I'd avoid using ""part"" in the more generic sense. Like I'd say ""the front section of a car"" rather than ""the front part of a car"".

It's not necessarily true that a section is smaller than a part. If you said, ""For this discussion, we will divide the nation into three major sections, and each of those sections into several parts"", I can't imagine that anyone would find that confusing on the grounds that parts should be divided into sections and not vice versa. Divide things up as is convenient in context.
"
4882,4882,7771,"Is there a iOS Configuration Profile Key for ""Find My iPhone?""","I've been looking at this page:

http://developer.apple.com/library/ios/#featuredarticles/iPhoneConfigurationProfileRef/Introduction/Introduction.html

for the configuration profile keys. I couldn't find one for the feature ""Find My iPhone."" Is there a key for that? If so what is it?
",Di Zou,https://stackoverflow.com/users/873268,"Sorry, but both Michael and titaniumdecoy are only partially correct. The ""Find My iPhone"" app is an app that helps you locate your iOS device if you have the settings set in your iCloud settings on the device.

I too would be interested in knowing if it is possible to push out a configuration profile (using IPCU) that has the ""Find My iPhone"" setting locked on even though it is technically an iCloud user settings.
",Joel Pratt,https://stackoverflow.com/users/1217092,http://stackoverflow.com/questions/8392213/is-there-a-ios-configuration-profile-key-for-find-my-iphone,STACKOVERFLOW,stackoverflow.com,1.0,0.3333333333333333,0.0,1.0,1.0,1.0,0.5,0.5,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.5,1.0,0.0,0.0,0.0,0.8333333333333334,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.8333333333333334,0.2,0.0,0.0,0.0,0.6666666666666666,Is there an IOS profile key for find my iPhone,"I've been looking at this page:

http://developer.apple.com/library/ios/#featuredarticles/iPhoneConfigurationProfileRef/Introduction/Introduction.html

for the configuration profile keys. I couldn't find one for the feature ""Find My iPhone."" Is there a key for that? If so what is it?
","Sorry, but both Michael and titaniumdecoy are only partially correct. The ""Find My iPhone"" app is an app that helps you locate your iOS device if you have the settings set in your iCloud settings on the device.

I too would be interested in knowing if it is possible to push out a configuration profile (using IPCU) that has the ""Find My iPhone"" setting locked on even though it is technically an iCloud user settings.
"
69,69,109,Who are the members of an early design of Luffy's crew?,"Browsing through One Piece wiki, there's a databook series called One Piece Green: Secret Pieces. I found a picture of Mugiwara Pirates early design. This is the picture.



I can see Zorro, Luffy, Nami, Sanji, and maybe Usopp, Brook, and Chopper. But who is the other two on the left? Did Robin and Franky replace them? Is there any official information about this picture?
",Darjeeling,https://anime.stackexchange.com/users/2869,"I have no good references but:

The mini character was supposed to be the shipwright and was replaced by Franky.

The other one was meant to be a plant obsessed character who was replaced by Robin and largely incorporated into the post time skip Ussop.
",kaine,https://anime.stackexchange.com/users/3561,http://anime.stackexchange.com/questions/8631/who-are-the-members-of-an-early-design-of-luffys-crew,CULTURE,anime.stackexchange.com,1.0,0.5555555555555556,0.0,0.3333333333333333,1.0,1.0,0.5555555555555556,0.4444444444444444,0.6666666666666666,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,1.0,0.0,0.0,0.3333333333333333,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,0.3333333333333333,0.8888888888888888,Who was a member of Luffy's early design team?,"Browsing through One Piece wiki, there's a databook series called One Piece Green: Secret Pieces. I found a picture of Mugiwara Pirates early design. This is the picture.



I can see Zorro, Luffy, Nami, Sanji, and maybe Usopp, Brook, and Chopper. But who is the other two on the left? Did Robin and Franky replace them? Is there any official information about this picture?
","I have no good references but:

The mini character was supposed to be the shipwright and was replaced by Franky.

The other one was meant to be a plant obsessed character who was replaced by Robin and largely incorporated into the post time skip Ussop.
"
4659,4659,7383,How do I create a simple yet complex business layer?,"I'm working with a fairly complex web application. It's split up into the following layers:


Presentation - HTML
Service layer - A REST and SOAP API communicating with the business layer
Business layer - Contains the business logic.
Data access - Provides access to the storage (SQL etc)


The business layers contains classes encapsulating specific areas, such as customer registration, user management and more. The problem we are seeing is that the business layer is starting to get a bit messy. We have a single class handling customer management but as this area of the application grows more and more complex, the class grows and grows and become messy.

For example, we may have the following classes


class CustomerManager


void CreateCustomer(...)
void DeleteCustomer(...)

class UserManager


void CreateUser(..)
void DeleteUser(...) 
void ActivateUser(...)
void InactivateUser(...)
void ResetPassword(...) 



Creating a customer involves creating users as well. So CustomerManager calls misc methods in the UserManager class. As the application has evolved, creating a new customer means roughly 10 different things needs to be done except for registring the customer in the database, such as informing sales, audit logging, configuring default user accounts, creating a default configuration for the customer, notifying end-users of their auto-generated passwords and more. So CustomerManager.CreateCustomer grows to ~100 lines of fairly hairy code.

I'm trying to think of a good way to handle this but am assuming that there's some common good way to do this which I'm simply not aware of.

I've considered creating ""Task""/""Command"" classes implementing small sub-processes and then let the CustomerCreation.CreateCustomer simply execute a set of tasks. I would have more classes but they would each do less things.

I've also considering implementing some kind of global application-level event/plug-in systems where CustomerManager.CreateCustomer just creates the customer in the database and then publishes an event that the customer is created. Plug-ins/something can then subscribe to these events and do stuff such as informing sales and logging the fact. Using this method, I wouldn't have to actually update CustomerManager.CreateCustomer when I want to do more stuff which is something which feels attractive to me.

What obvious design pattern am I missing?
",Nitra,https://programmers.stackexchange.com/users/90440,"Component architecture can provide good tools for fighting complexity of the business layer. For example, notifications can be done with registering subscribers (event handlers). A lot of logic can be done by adaptors, which will provide certain specific interfaces to your User and Customer interfaces. This way logic can be decoupled, making large monolithic classes unnecessary. Hopefully your platform already has some proven component architecture you can use, which is much better than implementing ""plugins"" from scratch.

Older answer (see first comment):


  My first impression of having CustomerRegistration and
  UserRegistration classes with the methods mentioned is that OO
  analysis has not been properly accomplished. I always thought that
  having sensible entities at business layer is the only way to prevent
  the mess. My advice would be to redesign (if it is not late yet) the
  business layer classes to better reflect business entities and not
  frontend processes. It may well be, that after such a redesign
  complexity will be a fraction of what you have now, and, more
  important, natural representation of the problem domain will answer
  your goals better than classes, combined with seemingly related
  functions.
  
  For example, even as such, UserRegistration should not have DeleteUser
  method! The task naturally belong to UsersManager class or maybe
  UserRegistry, if you wish.
  
  In short, I think the problem is that classes are formed around
  action-like entities, which requires much more interconnections
  (=mess) than class system around (say) User, Customer, and Managers of
  those two (managers are more like containers).
  
  There is little point of making User Management OOA from scratch. Good
  examples can be found from many frameworks, and sometimes they handle
  much more complex things, like fine-grained authorization,
  role/permission management, group management, etc.

",Roman Susi,https://programmers.stackexchange.com/users/44681,http://programmers.stackexchange.com/questions/211491/how-do-i-create-a-simple-yet-complex-business-layer,TECHNOLOGY,programmers.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,0.0,1.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.3333333333333333,0.6666666666666666,1.0,1.0,How to create a simple and complex business layer?,"I'm working with a fairly complex web application. It's split up into the following layers:


Presentation - HTML
Service layer - A REST and SOAP API communicating with the business layer
Business layer - Contains the business logic.
Data access - Provides access to the storage (SQL etc)


The business layers contains classes encapsulating specific areas, such as customer registration, user management and more. The problem we are seeing is that the business layer is starting to get a bit messy. We have a single class handling customer management but as this area of the application grows more and more complex, the class grows and grows and become messy.

For example, we may have the following classes


class CustomerManager


void CreateCustomer(...)
void DeleteCustomer(...)

class UserManager


void CreateUser(..)
void DeleteUser(...) 
void ActivateUser(...)
void InactivateUser(...)
void ResetPassword(...) 



Creating a customer involves creating users as well. So CustomerManager calls misc methods in the UserManager class. As the application has evolved, creating a new customer means roughly 10 different things needs to be done except for registring the customer in the database, such as informing sales, audit logging, configuring default user accounts, creating a default configuration for the customer, notifying end-users of their auto-generated passwords and more. So CustomerManager.CreateCustomer grows to ~100 lines of fairly hairy code.

I'm trying to think of a good way to handle this but am assuming that there's some common good way to do this which I'm simply not aware of.

I've considered creating ""Task""/""Command"" classes implementing small sub-processes and then let the CustomerCreation.CreateCustomer simply execute a set of tasks. I would have more classes but they would each do less things.

I've also considering implementing some kind of global application-level event/plug-in systems where CustomerManager.CreateCustomer just creates the customer in the database and then publishes an event that the customer is created. Plug-ins/something can then subscribe to these events and do stuff such as informing sales and logging the fact. Using this method, I wouldn't have to actually update CustomerManager.CreateCustomer when I want to do more stuff which is something which feels attractive to me.

What obvious design pattern am I missing?
","Component architecture can provide good tools for fighting complexity of the business layer. For example, notifications can be done with registering subscribers (event handlers). A lot of logic can be done by adaptors, which will provide certain specific interfaces to your User and Customer interfaces. This way logic can be decoupled, making large monolithic classes unnecessary. Hopefully your platform already has some proven component architecture you can use, which is much better than implementing ""plugins"" from scratch.

Older answer (see first comment):


  My first impression of having CustomerRegistration and
  UserRegistration classes with the methods mentioned is that OO
  analysis has not been properly accomplished. I always thought that
  having sensible entities at business layer is the only way to prevent
  the mess. My advice would be to redesign (if it is not late yet) the
  business layer classes to better reflect business entities and not
  frontend processes. It may well be, that after such a redesign
  complexity will be a fraction of what you have now, and, more
  important, natural representation of the problem domain will answer
  your goals better than classes, combined with seemingly related
  functions.
  
  For example, even as such, UserRegistration should not have DeleteUser
  method! The task naturally belong to UsersManager class or maybe
  UserRegistry, if you wish.
  
  In short, I think the problem is that classes are formed around
  action-like entities, which requires much more interconnections
  (=mess) than class system around (say) User, Customer, and Managers of
  those two (managers are more like containers).
  
  There is little point of making User Management OOA from scratch. Good
  examples can be found from many frameworks, and sometimes they handle
  much more complex things, like fine-grained authorization,
  role/permission management, group management, etc.

"
1290,1290,2033,Increasing the search query limit (Apache Solr),"We want to create a search page with Apache Solr with an increased query limit. I was reading that using hook_search_execute was not a recommended way to do this.

Is this statement correct? What would be the recommended way to go about this?

Apache Solr Views module?

Some other solution?

The page absolutely has to have more than 10 search results, and no pager.
",Andrew Alexander,https://drupal.stackexchange.com/users/6491,"To do that programatically, you can implement hook_apachesolr_query_alter() to play with the rows parameter :

function yourmodule_apachesolr_query_alter($query) {
  // Increase the number of results per query
  $query-&gt;replaceParam('rows', 50);
}


Note : To disable the pager you can set a very very large number of rows, but it may impact performance. In this case you may prefer to bypass the pager at another level (for example in a preprocess function) and go with a more reasonable rows value.
",EricLavault,https://drupal.stackexchange.com/users/26231,http://drupal.stackexchange.com/questions/102365/increasing-the-search-query-limit-apache-solr,TECHNOLOGY,drupal.stackexchange.com,1.0,0.4444444444444444,0.0,0.3333333333333333,1.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,1.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.6666666666666666,0.6666666666666666,0.8888888888888888,Add search query restrictions (APACHE Solr),"We want to create a search page with Apache Solr with an increased query limit. I was reading that using hook_search_execute was not a recommended way to do this.

Is this statement correct? What would be the recommended way to go about this?

Apache Solr Views module?

Some other solution?

The page absolutely has to have more than 10 search results, and no pager.
","To do that programatically, you can implement hook_apachesolr_query_alter() to play with the rows parameter :

function yourmodule_apachesolr_query_alter($query) {
  // Increase the number of results per query
  $query-&gt;replaceParam('rows', 50);
}


Note : To disable the pager you can set a very very large number of rows, but it may impact performance. In this case you may prefer to bypass the pager at another level (for example in a preprocess function) and go with a more reasonable rows value.
"
3817,3817,6068,Eclipse Java EE Indigo 's XML formatting is suddenly screwed up,"A few days ago it was just fine. I haven't made any change to the IDE or anything else in the preferences.

Looks like random instability, but I hope I'm wrong, I don't want to go through the IDE setup again.......

Here are two screenshots to tell the story:

Before Ctrl+Shift+F (format):


After (format results):


What can I do about it?

I've tried comparing settings in another Eclipse setup that I have which has XML formatting working properly. (Window -> Preferences -> XML -> XML Files -> Editor). Also (Structured Text Editors).
",Poni,https://stackoverflow.com/users/286260,"Solved.

It looks like ""Android Common XML Editor"" took over, and the above crappy formatting belongs to it.

All I had to do is right click on the XML file and choose Open With -> XML Editor.
",Poni,https://stackoverflow.com/users/286260,http://stackoverflow.com/questions/10941447/eclipse-java-ee-indigo-s-xml-formatting-is-suddenly-screwed-up,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.5555555555555556,0.0,1.0,1.0,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,1.0,0.6666666666666666,0.0,1.0,0.8888888888888888,The XML format of eclipse Java EE indigo was suddenly messed up,"A few days ago it was just fine. I haven't made any change to the IDE or anything else in the preferences.

Looks like random instability, but I hope I'm wrong, I don't want to go through the IDE setup again.......

Here are two screenshots to tell the story:

Before Ctrl+Shift+F (format):


After (format results):


What can I do about it?

I've tried comparing settings in another Eclipse setup that I have which has XML formatting working properly. (Window -> Preferences -> XML -> XML Files -> Editor). Also (Structured Text Editors).
","Solved.

It looks like ""Android Common XML Editor"" took over, and the above crappy formatting belongs to it.

All I had to do is right click on the XML file and choose Open With -> XML Editor.
"
5784,5784,9166,Why choose an 80-200mm over an 18-200mm lens?,"Being a beginner, I can't see why I must choose an 80-200 over an 18-200. Are there scenarios where an 80-200 would be preferable over an 18-200?

I will be buying a D7000 soon and am looking at these:


AF Zoom-NIKKOR 80-200mm f/2.8D ED
AF-S DX NIKKOR 18-200mm f/3.5-5.6G ED VR II


but similar considerations would apply to other brands as well.
",Ygam,https://photo.stackexchange.com/users/2362,"The biggest reason for difference in the two lenses is aperture. The 80-200mm is a constant f/2.8 throughout the focal range and the 18-200mm varies from f/3.5 to f/5.6, so substantially slower, especially at the far end. All this really means is that the 80-200 can let in more light at the same focal length over the other. 

Also, generally, zooms with constant apertures are higher grade lenses. I hesitate to make this statement a truism, but it pretty much is. Consumer grade lenses are often massive zoom ranges with variable aperture whereas more professional grade variants are smaller zoom ranges and constant apertures. The professional variants tend to be fast, sharper, and better built. There are exceptions, but this is generally the case regardless of brand.

So, that is why you might make the choice of the 80-200mm lens. I made such a choice with a Pentax variant not so long ago...

Edit

To answer your other question, I would probably recommend the super zoom (18-200) for a newcomer if you want a single, general purpose, lens. I would expect the 80-200 to be optically superior, but also more expensive, and it would probably mean a second, equally expensive, lens to fill in the range. Worth it to some of us, but not for everyone.
",John Cavan,https://photo.stackexchange.com/users/472,http://photo.stackexchange.com/questions/11247/why-choose-an-80-200mm-over-an-18-200mm-lens,LIFE_ARTS,photo.stackexchange.com,0.8888888888888888,0.8888888888888888,0.0,0.6666666666666666,1.0,0.6666666666666666,0.7777777777777778,0.5555555555555556,0.3333333333333333,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.7777777777777778,0.8888888888888888,0.7777777777777778,1.0,0.8888888888888888,0.8666666666666666,0.0,0.0,1.0,0.8888888888888888,Why 80-200mm instead of 18-200mm?,"Being a beginner, I can't see why I must choose an 80-200 over an 18-200. Are there scenarios where an 80-200 would be preferable over an 18-200?

I will be buying a D7000 soon and am looking at these:


AF Zoom-NIKKOR 80-200mm f/2.8D ED
AF-S DX NIKKOR 18-200mm f/3.5-5.6G ED VR II


but similar considerations would apply to other brands as well.
","The biggest reason for difference in the two lenses is aperture. The 80-200mm is a constant f/2.8 throughout the focal range and the 18-200mm varies from f/3.5 to f/5.6, so substantially slower, especially at the far end. All this really means is that the 80-200 can let in more light at the same focal length over the other. 

Also, generally, zooms with constant apertures are higher grade lenses. I hesitate to make this statement a truism, but it pretty much is. Consumer grade lenses are often massive zoom ranges with variable aperture whereas more professional grade variants are smaller zoom ranges and constant apertures. The professional variants tend to be fast, sharper, and better built. There are exceptions, but this is generally the case regardless of brand.

So, that is why you might make the choice of the 80-200mm lens. I made such a choice with a Pentax variant not so long ago...

Edit

To answer your other question, I would probably recommend the super zoom (18-200) for a newcomer if you want a single, general purpose, lens. I would expect the 80-200 to be optically superior, but also more expensive, and it would probably mean a second, equally expensive, lens to fill in the range. Worth it to some of us, but not for everyone.
"
1345,1345,2119,Resonance stabilization and size of ligand atoms,"I am told that for these two molecules, one of them is not as resonance stabilized as the other. Apparently it's the chlorine one, and it's because of the mismatch in the size of chlorine and carbon. This makes sense prima facie, but can someone confirm this is true? I can see how carbon and nitrogen have similarly sized p orbitals and thus have good overlap, and how chlorine and carbon might have poor p orbital overlap, like a BB pellet with a basketball. 


",Dissenter,https://chemistry.stackexchange.com/users/5084,"Yes, this is true. The $\pi$ overlap between a valence $\ce{p}$ orbital of a second row element and one of a higher row element is much smaller than the $\pi$ overlap between two second row elements. One reason is that the bond length is generally higher when higher row elements are involved (due to their size). Another reason is, that the $3 \ce{p}$ or $4 \ce{p}$ orbitals are much more diffuse than the $2 \ce{p}$ orbitals. If you want to read deeper into the topic have a look at:

[1] W. Kutzelnigg, Angew. Chem. Int. Ed. Engl., 23, 272 (1984).

[2] N. C. Norman, Polyhedron, 12, 2431 (1993).
",Philipp,https://chemistry.stackexchange.com/users/189,http://chemistry.stackexchange.com/questions/15920/resonance-stabilization-and-size-of-ligand-atoms,SCIENCE,chemistry.stackexchange.com,0.8888888888888888,0.6666666666666666,0.0,1.0,1.0,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.8888888888888888,1.0,0.7777777777777778,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,1.0,Resonance stability and size of ligand atom,"I've been told that one of these two molecules is less resonant stable than the other. It's obviously chlorine, because the size of chlorine and carbon don't match. On the surface, it makes sense, but can anyone confirm that it is true? I can see that the p orbital size of carbon and nitrogen is similar, so there is a good overlap. The p orbital overlap of chlorine and carbon is very poor, just like a BB ball with a basketball.","Yes, this is true. The $\pi$ overlap between a valence $\ce{p}$ orbital of a second row element and one of a higher row element is much smaller than the $\pi$ overlap between two second row elements. One reason is that the bond length is generally higher when higher row elements are involved (due to their size). Another reason is, that the $3 \ce{p}$ or $4 \ce{p}$ orbitals are much more diffuse than the $2 \ce{p}$ orbitals. If you want to read deeper into the topic have a look at:

[1] W. Kutzelnigg, Angew. Chem. Int. Ed. Engl., 23, 272 (1984).

[2] N. C. Norman, Polyhedron, 12, 2431 (1993).
"
4911,4911,7820,Understanding of Relays and associated circuitry,"I needed a simple understanding of how this circuit works.



I understand everything about this circuit apart from the diode. I also know the function of the diode is to protect the transistor but from what exactly? Is it something to do with back EMF from the coil? I'm not too sure. Also I needed to confirm if the relay will function correctly with a 9V supply (regulated or unregulated). The datasheet of the relay is attached here and the part I'm going to use is '40.61' on page 20 of the datasheet.

Also any tips for making this circuit work more efficiently. Note I am going to use the relay for no more than 16A at 230VAC at 50Hz.

Thanks
",David Norman,https://electronics.stackexchange.com/users/10082,"I remember from technician school that diodes are often placed on the coil of a relay or solenoid to prevent ""bounce"", which in the class, implied the coil might throw more than once when switched on. This is a subtle difference from what I'm reading in the other answers as voltage spikes. 

Given my lab and field experience, I would lean more towards the purpose of preventing voltage spikes with the intent of preserving the transistor.
",Chris K,https://electronics.stackexchange.com/users/10330,http://electronics.stackexchange.com/questions/33844/understanding-of-relays-and-associated-circuitry,TECHNOLOGY,electronics.stackexchange.com,0.3333333333333333,0.3333333333333333,0.0,0.0,1.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.8,0.0,0.0,1.0,1.0,Understand relays and related circuits,"I needed a simple understanding of how this circuit works.



I understand everything about this circuit apart from the diode. I also know the function of the diode is to protect the transistor but from what exactly? Is it something to do with back EMF from the coil? I'm not too sure. Also I needed to confirm if the relay will function correctly with a 9V supply (regulated or unregulated). The datasheet of the relay is attached here and the part I'm going to use is '40.61' on page 20 of the datasheet.

Also any tips for making this circuit work more efficiently. Note I am going to use the relay for no more than 16A at 230VAC at 50Hz.

Thanks
","I remember when I was in a technical school, diodes were often placed on the coils of relays or solenoids to prevent ""bounce,"" which in class meant that the coils might be thrown more than once when they were turned on. This is slightly different from the voltage peaks I see in other answers."
4591,4591,7275,Are scientifically detached professors referred to as ‘clinical’?,"I have come across this term fairly often, where full/associate/assistant professors are referred to by the term ‘clinical’. Given that their departments had nothing to do with medicine, I thought the term referred to the second meaning of clinical:


  scientifically detached; strictly objective


Is this interpretation correct? If yes, isn’t such a branding offensive?
",Sheeba,https://academia.stackexchange.com/users/37947,"Clinical Law Faculty usually supervise one or two law clinics where law students can get practical experience getting indigent or immigrant clients. In this case, ""clinical"" means that their responsibilities are mainly focused in the teaching and running of said clinics and that they are not full faculty in the law school in terms of voting and tenure rights. 

Clinical Writing Faculty is a term I've recently come across for some professional staff (with PhDs) who work in university writing/tutoring clinics. They help students with their essays and may also teach some composition courses. These people are also not full faculty in terms of voting and tenure rights.

Note: ""Adjunct"" is not appropriate for these faculty as they are often full time with renewing terms. ""Visiting"" is inappropriate as they are on renewing terms that could span decades of service.  ""Staff"" is inappropriate as they have terminal degrees and are teaching/supervising students. ""Professor of Practice"" is a mostly  equivalent term to ""clinical faculty,"" again with the emphasis on teaching rather than research.
",RoboKaren,https://academia.stackexchange.com/users/14885,http://academia.stackexchange.com/questions/49759/are-scientifically-detached-professors-referred-to-as-clinical,LIFE_ARTS,academia.stackexchange.com,0.6666666666666666,0.8888888888888888,0.3333333333333333,1.0,1.0,1.0,0.6666666666666666,0.4444444444444444,1.0,0.0,0.0,1.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.3333333333333333,0.0,0.8888888888888888,1.0,0.8888888888888888,0.8888888888888888,1.0,0.8666666666666666,0.0,0.0,0.0,0.7777777777777778,"Is an independent professor of science called ""clinical professor""?","I often come across this semester. The formal Professor / Associate Professor / Assistant Professor here is called ""clinical professor"". Since their department is not related to medicine, I think this word refers to the second meaning of clinical:","Clinical Law Faculty usually supervise one or two law clinics where law students can get practical experience getting indigent or immigrant clients. In this case, ""clinical"" means that their responsibilities are mainly focused in the teaching and running of said clinics and that they are not full faculty in the law school in terms of voting and tenure rights. 

Clinical Writing Faculty is a term I've recently come across for some professional staff (with PhDs) who work in university writing/tutoring clinics. They help students with their essays and may also teach some composition courses. These people are also not full faculty in terms of voting and tenure rights.

Note: ""Adjunct"" is not appropriate for these faculty as they are often full time with renewing terms. ""Visiting"" is inappropriate as they are on renewing terms that could span decades of service.  ""Staff"" is inappropriate as they have terminal degrees and are teaching/supervising students. ""Professor of Practice"" is a mostly  equivalent term to ""clinical faculty,"" again with the emphasis on teaching rather than research.
"
1199,1199,1883,Next & Previous (Pagination in this case) Not Appearing,"I am using a custom page template for my portfolio.  The code is calling the correct number of posts per page but for some reason the pagination links won't show up :-S

My query

&lt;?php 
    $loop = new WP_Query(array('post_type' =&gt; 'portfolio', 'posts_per_page' =&gt; 2)); 
?&gt;
&lt;?php while ( $loop-&gt;have_posts() ) : $loop-&gt;the_post(); ?&gt;
&lt;?php   
    $custom = get_post_custom($post-&gt;ID);
    $screenshot_url = $custom[""screenshot_url""][0];
    $website_url = $custom[""website_url""][0];
?&gt;


The entire markup

&lt;?php
/*
Template Name: Portfolio
*/
?&gt;

&lt;?php get_header(); ?&gt;

&lt;div id=""full_container""&gt;
&lt;div id=""portfolio_content""&gt;
&lt;div id=""portfolio_wrap""&gt;
&lt;div id=""content""&gt;

    &lt;?php 
        $loop = new WP_Query(array('post_type' =&gt; 'portfolio', 'posts_per_page' =&gt; 2)); 
    ?&gt;
    &lt;?php while ( $loop-&gt;have_posts() ) : $loop-&gt;the_post(); ?&gt;
    &lt;?php   
        $custom = get_post_custom($post-&gt;ID);
        $screenshot_url = $custom[""screenshot_url""][0];
        $website_url = $custom[""website_url""][0];
    ?&gt;


&lt;a href=""&lt;?php the_permalink() ?&gt;""&gt;

&lt;span class=""img""&gt;
&lt;?php if ( has_post_thumbnail() ) { the_post_thumbnail( 'thmb-portfolio' ); } ?&gt;

&lt;span class=""under""&gt;
&lt;!-- Excerpt title --&gt;
&lt;span class=""title""&gt;&lt;?php the_title(); ?&gt;&lt;/span&gt;

&lt;!-- Excerpt description --&gt;
&lt;span class=""desc""&gt;
    &lt;?php my_excerpt('short'); ?&gt;
&lt;/span&gt;
&lt;/span&gt;
&lt;/span&gt;
&lt;/a&gt;


        &lt;?php endwhile; ?&gt;  

&lt;!-- Next/Previous Posts --&gt;
&lt;?php if (function_exists(""pagination"")) {
    pagination($additional_loop-&gt;max_num_pages);
} ?&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;?php get_footer(); ?&gt;

",AndrettiMilas,https://wordpress.stackexchange.com/users/5205,"I don't see the variable $additional_loop being set anywhere in your code. If you're comfortable with WP-Pagenavi, install it and modify your code as follows:

&lt;?php
    //You need to handle the 'paged' query var for pagination!
    $paged = (get_query_var('paged'))?get_query_var('paged'):1;
    $loop = new WP_Query(array('post_type' =&gt; 'portfolio', 'posts_per_page' =&gt; 2, 'paged' =&gt; $paged)); 
?&gt;


Replace the following:

&lt;!-- Next/Previous Posts --&gt;
&lt;?php if (function_exists(""pagination"")) {
    pagination($additional_loop-&gt;max_num_pages);
} ?&gt;


With:

&lt;?php
    if(function_exists('wp_pagenavi'))
    { 
        wp_pagenavi(); 
    }
    else
    { ?&gt;
        &lt;div class=""navigation""&gt;
        &lt;div class=""alignleft""&gt;&lt;?php next_posts_link('Previous entries') ?&gt;&lt;/div&gt;
        &lt;div class=""alignright""&gt;&lt;?php previous_posts_link('Next entries') ?&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;?php }
?&gt;


Hope this helps!
",Rutwick Gangurde,https://wordpress.stackexchange.com/users/4740,http://wordpress.stackexchange.com/questions/30616/next-previous-pagination-in-this-case-not-appearing,TECHNOLOGY,wordpress.stackexchange.com,0.6666666666666666,0.3333333333333333,0.0,1.0,1.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,0.8333333333333334,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.5,1.0,Next and previous pages (pagination in this case) do not appear,"I am using a custom page template for my portfolio.  The code is calling the correct number of posts per page but for some reason the pagination links won't show up :-S

My query

&lt;?php 
    $loop = new WP_Query(array('post_type' =&gt; 'portfolio', 'posts_per_page' =&gt; 2)); 
?&gt;
&lt;?php while ( $loop-&gt;have_posts() ) : $loop-&gt;the_post(); ?&gt;
&lt;?php   
    $custom = get_post_custom($post-&gt;ID);
    $screenshot_url = $custom[""screenshot_url""][0];
    $website_url = $custom[""website_url""][0];
?&gt;


The entire markup

&lt;?php
/*
Template Name: Portfolio
*/
?&gt;

&lt;?php get_header(); ?&gt;

&lt;div id=""full_container""&gt;
&lt;div id=""portfolio_content""&gt;
&lt;div id=""portfolio_wrap""&gt;
&lt;div id=""content""&gt;

    &lt;?php 
        $loop = new WP_Query(array('post_type' =&gt; 'portfolio', 'posts_per_page' =&gt; 2)); 
    ?&gt;
    &lt;?php while ( $loop-&gt;have_posts() ) : $loop-&gt;the_post(); ?&gt;
    &lt;?php   
        $custom = get_post_custom($post-&gt;ID);
        $screenshot_url = $custom[""screenshot_url""][0];
        $website_url = $custom[""website_url""][0];
    ?&gt;


&lt;a href=""&lt;?php the_permalink() ?&gt;""&gt;

&lt;span class=""img""&gt;
&lt;?php if ( has_post_thumbnail() ) { the_post_thumbnail( 'thmb-portfolio' ); } ?&gt;

&lt;span class=""under""&gt;
&lt;!-- Excerpt title --&gt;
&lt;span class=""title""&gt;&lt;?php the_title(); ?&gt;&lt;/span&gt;

&lt;!-- Excerpt description --&gt;
&lt;span class=""desc""&gt;
    &lt;?php my_excerpt('short'); ?&gt;
&lt;/span&gt;
&lt;/span&gt;
&lt;/span&gt;
&lt;/a&gt;


        &lt;?php endwhile; ?&gt;  

&lt;!-- Next/Previous Posts --&gt;
&lt;?php if (function_exists(""pagination"")) {
    pagination($additional_loop-&gt;max_num_pages);
} ?&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;?php get_footer(); ?&gt;

","I don't see the variable $additional_loop being set anywhere in your code. If you're comfortable with WP-Pagenavi, install it and modify your code as follows:

&lt;?php
    //You need to handle the 'paged' query var for pagination!
    $paged = (get_query_var('paged'))?get_query_var('paged'):1;
    $loop = new WP_Query(array('post_type' =&gt; 'portfolio', 'posts_per_page' =&gt; 2, 'paged' =&gt; $paged)); 
?&gt;


Replace the following:

&lt;!-- Next/Previous Posts --&gt;
&lt;?php if (function_exists(""pagination"")) {
    pagination($additional_loop-&gt;max_num_pages);
} ?&gt;


With:

&lt;?php
    if(function_exists('wp_pagenavi'))
    { 
        wp_pagenavi(); 
    }
    else
    { ?&gt;
        &lt;div class=""navigation""&gt;
        &lt;div class=""alignleft""&gt;&lt;?php next_posts_link('Previous entries') ?&gt;&lt;/div&gt;
        &lt;div class=""alignright""&gt;&lt;?php previous_posts_link('Next entries') ?&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;?php }
?&gt;


Hope this helps!
"
5312,5312,8438,"Does the Canon *.CR2/CRW format contain ""truly RAW"" data?","In my work I am dealing with *.CR2 raw images taken by a Canon DSLR in raw mode.
When I read about the format here, I was surprised to find that it has 4 TIFF IFDs which contain a) Original Size JPEG Image b) Thumbnail JPEG image c) Uncompressed RGB data d) Lossless JPEG image.

My impression until now was any camera captured RAW image file would have Raw Bayer Data i.e. R,Gr,B,Gb kind of bayer data, and some EXIF data about camera capture settings etc.

But after reading this CR2 specification I am slightly confused as to how can it have a RGB data or even surprisingly JPEG data. This seems to be the data after demosaicing(obtaining the missing R/G/B pixel data for the original sensor Bayer pattern). If thats the case I would not consider *.CR2 as ""truly raw"" data. It has done demosaicing before dumping the socalled raw file.

Am I missing something?

Does any other Camera Raw formats(e.g. Nikon - *.NEF, Kodac - *.kdc, Pentax - *.ptx/pef,...) have real raw bayer data without any processing done?
",goldenmean,https://photo.stackexchange.com/users/2438,"The DNG contains Lossless grayscale JPG with resolution 4 times higher than ""normal"" color jpg file. Is it more clear now?

What is the problem in placing 3 types of black balls in a basked that is meant to hold 3 colored balls?

In the JPG file there are no colors, there are just numbers, as in any other file format. And they use JPG because it is easier to encode it in this way, because the camera processor is already made to create such files.

They would probably write the matrix data into zip, rar, flac, or any other lossless format pretty much the same way. But that would require a bunch of algorithms added into the software of the camera, that are not needed.
",user28170,https://photo.stackexchange.com/users/28170,http://photo.stackexchange.com/questions/10440/does-the-canon-cr2-crw-format-contain-truly-raw-data,LIFE_ARTS,photo.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,1.0,1.0,1.0,0.7777777777777778,0.3333333333333333,0.6666666666666666,0.0,0.0,1.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,0.8888888888888888,"Does Canon *. CR2 / CRW format contain ""real raw"" data?","In my work I am dealing with *.CR2 raw images taken by a Canon DSLR in raw mode.
When I read about the format here, I was surprised to find that it has 4 TIFF IFDs which contain a) Original Size JPEG Image b) Thumbnail JPEG image c) Uncompressed RGB data d) Lossless JPEG image.

My impression until now was any camera captured RAW image file would have Raw Bayer Data i.e. R,Gr,B,Gb kind of bayer data, and some EXIF data about camera capture settings etc.

But after reading this CR2 specification I am slightly confused as to how can it have a RGB data or even surprisingly JPEG data. This seems to be the data after demosaicing(obtaining the missing R/G/B pixel data for the original sensor Bayer pattern). If thats the case I would not consider *.CR2 as ""truly raw"" data. It has done demosaicing before dumping the socalled raw file.

Am I missing something?

Does any other Camera Raw formats(e.g. Nikon - *.NEF, Kodac - *.kdc, Pentax - *.ptx/pef,...) have real raw bayer data without any processing done?
","The DNG contains Lossless grayscale JPG with resolution 4 times higher than ""normal"" color jpg file. Is it more clear now?

What is the problem in placing 3 types of black balls in a basked that is meant to hold 3 colored balls?

In the JPG file there are no colors, there are just numbers, as in any other file format. And they use JPG because it is easier to encode it in this way, because the camera processor is already made to create such files.

They would probably write the matrix data into zip, rar, flac, or any other lossless format pretty much the same way. But that would require a bunch of algorithms added into the software of the camera, that are not needed.
"
1141,1141,1789,Replacing a PERC S300,"The PERC S300 card that came with our Dell PowerEdge T110 servers is Windows only (see here). As a result, we're looking for an alternative that works under Linux.

We had planned to use software RAID under Linux. However, the hard drives are SAS-only, that is, we can't just put SATA cables in and hook them up to the motherboard. 

Is the best solution here to buy SAS to SATA cables, hook them up to the motherboard and power, and use the drives that way?
",max,https://serverfault.com/users/95478,"If the motherboard ports are SATA-only, you won't be able to run SAS disks from them.

Your best bet is a dedicated HBA.  If you're looking for basic hardware RAID OR the ability to present raw disks to the OS for software RAID, try an LSI controller like the 9211-4i or 9211-8i. That's 4 or 8 internal ports, depending on what you need. You'd probably want to look at: http://store.lsi.com/store.cfm/Host_Bus_Adapters/9211_Adapters/LSI00191
",ewwhite,https://serverfault.com/users/13325,http://serverfault.com/questions/314101,TECHNOLOGY,serverfault.com,0.8888888888888888,0.3333333333333333,0.0,1.0,0.3333333333333333,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.3333333333333333,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.0,0.6666666666666666,1.0,Replace perc S300,"The PERC S300 card that came with our Dell PowerEdge T110 servers is Windows only (see here). As a result, we're looking for an alternative that works under Linux.

We had planned to use software RAID under Linux. However, the hard drives are SAS-only, that is, we can't just put SATA cables in and hook them up to the motherboard. 

Is the best solution here to buy SAS to SATA cables, hook them up to the motherboard and power, and use the drives that way?
","If the motherboard ports are SATA-only, you won't be able to run SAS disks from them.

Your best bet is a dedicated HBA.  If you're looking for basic hardware RAID OR the ability to present raw disks to the OS for software RAID, try an LSI controller like the 9211-4i or 9211-8i. That's 4 or 8 internal ports, depending on what you need. You'd probably want to look at: http://store.lsi.com/store.cfm/Host_Bus_Adapters/9211_Adapters/LSI00191
"
5806,5806,9199,"iptables -P FORWARD DROP, good or bad?","Is dropping all FORWARD packets bad? What are they used for? Why would I want to block them or keep them open?

(I fully understand INPUT and OUTPUT)
",Luke,https://serverfault.com/users/95470,"Is your machine a router?  Is it expected to do something with packets that it receives that are not destined for your machine?

You can safely drop packets if you are not expected to forward them, though it's probably a sign of a misconfigured network if you are receiving them.
",crb,https://serverfault.com/users/5724,http://serverfault.com/questions/314086,TECHNOLOGY,serverfault.com,0.8888888888888888,0.3333333333333333,0.0,0.6666666666666666,1.0,0.6666666666666666,0.4444444444444444,0.3333333333333333,1.0,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,1.0,0.8888888888888888,0.9,0.0,0.0,0.6666666666666666,1.0,"Iptables-p forwarding down, good or bad?",Discard all forwarding packets bad? What are they used for? Why should I stop them or keep them open?,"Is your machine a router?  Is it expected to do something with packets that it receives that are not destined for your machine?

You can safely drop packets if you are not expected to forward them, though it's probably a sign of a misconfigured network if you are receiving them.
"
1746,1746,2762,"How can I redirect what is shown on Terminal to a file, when using the 'less' command?","How do I redirect the Terminal content (the content that currently I'm looking not the entire file, when using the less command) into a outfile until I press the Q to exit from less?
",αғsнιη,https://askubuntu.com/users/283843,"To save just the section that is currently displayed in your terminal you can use the | command.

From man less:

| &lt;m&gt; shell-command
      &lt;m&gt;  represents any mark letter. Pipes a section of the input file to the given
  shell command. The section of the file to be piped is between the first line on the
  current screen and the position marked by the letter. &lt;m&gt; may also be '^' or '$' to
  indicate beginning or end of file respectively.
  If &lt;m&gt; is '.' or newline, the current screen is piped.



So first type | (the pipe symbol)
Then choose the . mark to select only what's visible on your terminal (or just hit Enter)
Use tee to save to a file e.g. tee /tmp/section_of_big_file.txt
Press Enter then q


The sequence with screenshots:






",Sylvain Pineau,https://askubuntu.com/users/32239,http://askubuntu.com/questions/589858/how-can-i-redirect-what-is-shown-on-terminal-to-a-file-when-using-the-less-co,TECHNOLOGY,askubuntu.com,0.8888888888888888,0.8888888888888888,0.0,1.0,1.0,1.0,0.6666666666666666,0.5555555555555556,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.3333333333333333,0.6666666666666666,1.0,"When using the ""less"" command, how to redirect the content displayed on the terminal to a file?","How can I redirect terminal content (what I see is not the content of the entire file at present, when using fewer commands) to an outfile until I press Q to exit fewer files?","To save just the section that is currently displayed in your terminal you can use the | command.

From man less:

| &lt;m&gt; shell-command
      &lt;m&gt;  represents any mark letter. Pipes a section of the input file to the given
  shell command. The section of the file to be piped is between the first line on the
  current screen and the position marked by the letter. &lt;m&gt; may also be '^' or '$' to
  indicate beginning or end of file respectively.
  If &lt;m&gt; is '.' or newline, the current screen is piped.



So first type | (the pipe symbol)
Then choose the . mark to select only what's visible on your terminal (or just hit Enter)
Use tee to save to a file e.g. tee /tmp/section_of_big_file.txt
Press Enter then q


The sequence with screenshots:






"
729,729,1161,Splicing tiny wire inside broken mouse cable,"I don't know a lot about electronics repairs, but I've got a relatively expensive laser mouse that got a frayed connection on the wire:



I'm wanting to repair it as it's out of warranty.  I've cut the cable on either side of the ""stopper"", isolated each of the individual wires, and stripped the ends off in preparation for splicing.



I've read some instructions that indicate I should do an inline wrap and then apply some solder.  

Is there a better way for wires this small?

Is there a particular type of heat shrink wrap I should put on this after it's spliced?  Or will electrical tape suffice?



Inside the mouse, the cable is connected to a little plug.  To me, it looks a lot like the fan plugs inside a PC.  It's got 5 pins each 1mm apart.  If there were a replacement plug I could buy and crimp the wires into, that'd be great!


",James Kolpack,https://electronics.stackexchange.com/users/7046,"As neat multi-wire splices are hard to make, I'd recommend that instead of splicing, you simply shorten the cable by discarding the inside piece and connect the outside end to the circuitry inside.  Try to replicate the function of the strain relief somehow.
",Chris Stratton,https://electronics.stackexchange.com/users/2246,http://electronics.stackexchange.com/questions/23760/splicing-tiny-wire-inside-broken-mouse-cable,SCIENCE,electronics.stackexchange.com,1.0,0.3333333333333333,0.0,0.3333333333333333,1.0,1.0,0.4444444444444444,0.4444444444444444,0.3333333333333333,0.0,1.0,0.0,0.0,0.0,0.0,0.3333333333333333,1.0,0.3333333333333333,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8,0.3333333333333333,0.6666666666666666,0.0,0.8888888888888888,Splicing thin wires in a disconnected mouse cable,"I don't know a lot about electronics repairs, but I've got a relatively expensive laser mouse that got a frayed connection on the wire:



I'm wanting to repair it as it's out of warranty.  I've cut the cable on either side of the ""stopper"", isolated each of the individual wires, and stripped the ends off in preparation for splicing.



I've read some instructions that indicate I should do an inline wrap and then apply some solder.  

Is there a better way for wires this small?

Is there a particular type of heat shrink wrap I should put on this after it's spliced?  Or will electrical tape suffice?



Inside the mouse, the cable is connected to a little plug.  To me, it looks a lot like the fan plugs inside a PC.  It's got 5 pins each 1mm apart.  If there were a replacement plug I could buy and crimp the wires into, that'd be great!


","As neat multi-wire splices are hard to make, I'd recommend that instead of splicing, you simply shorten the cable by discarding the inside piece and connect the outside end to the circuitry inside.  Try to replicate the function of the strain relief somehow.
"
2954,2954,4699,How to get angle bewteen two vectors in range -1 to 1 without using arc cosine?,"Given two normalized vectors in 3d space, how can I get a value from $-1$ to $1$ based on their angle without using arc cosine?

With use of arc cosine, I think this would give me the correct result. But since arc cosine is a computational expensive function in computer programming, I need to avoid it.

$$\frac{cos^{-1}(a * b)}{180^°}-1$$

It is acceptable that the solution doesn't return the same values as the formula above. It's just important that the output depends (not necessarily linear) on the angle and is in the range from $-1$ to $1$.
",danijar,https://math.stackexchange.com/users/67338,"You can consider the cross product of the vectors and take the arcsin of the magnitude of that cross product.  Specifically, for the case of 2D vectors $\vec{a}$ and $\vec{b}$, we have

$$\sin{\theta} = \frac{a_x\, b_y - a_y\,b_x}{\sqrt{a_x^2+a_y^2}\sqrt{b_x^2+b_y^2}}$$
",Ron Gordon,https://math.stackexchange.com/users/53268,http://math.stackexchange.com/questions/344922/how-to-get-angle-bewteen-two-vectors-in-range-1-to-1-without-using-arc-cosine,SCIENCE,math.stackexchange.com,0.8888888888888888,0.4444444444444444,0.0,0.6666666666666666,1.0,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.6666666666666666,0.0,1.0,How to get the angle between two vectors in the range of - 1 to 1 without cosine?,"Given two normalized vectors in 3d space, how can I get a value from $-1$ to $1$ based on their angle without using arc cosine?

With use of arc cosine, I think this would give me the correct result. But since arc cosine is a computational expensive function in computer programming, I need to avoid it.

$$\frac{cos^{-1}(a * b)}{180^°}-1$$

It is acceptable that the solution doesn't return the same values as the formula above. It's just important that the output depends (not necessarily linear) on the angle and is in the range from $-1$ to $1$.
","You can consider the cross product of the vectors and take the arcsin of the magnitude of that cross product.  Specifically, for the case of 2D vectors $\vec{a}$ and $\vec{b}$, we have

$$\sin{\theta} = \frac{a_x\, b_y - a_y\,b_x}{\sqrt{a_x^2+a_y^2}\sqrt{b_x^2+b_y^2}}$$
"
236,236,378,"Should it be an ""unlike"" or ""dislike"" button on Facebook?","I see an increasing demand for an unlike button on Facebook: 


http://www.facebook.com/pages/The-Unlike-Button/72641866357
Facebook Adds An Unlike Button For Pages
May 7, 2010
Facebook ""Unlike"" Button Comes to the News Feed
NOV 3, 2010


I have always used and understood unlike in the sense of dissimilar. Is it ever used in the sense of do not like?    
",rest_day,https://english.stackexchange.com/users/8887,"In the modern world, and particularly in the world of computers, the un- prefix is increasingly used to denote an opposite or reversing action.

As in install/uninstall, register/unregister, and delete/undelete. Not to mention the undo facility we rely on in many applications.

In short, people quite reasonably expect the Facebook functionality to be called unlike because that follows the pattern they're used to. There's no danger of confusing such terminology with the dissimilar meaning, so why not?
",FumbleFingers,https://english.stackexchange.com/users/2637,http://english.stackexchange.com/questions/30332/should-it-be-an-unlike-or-dislike-button-on-facebook,CULTURE,english.stackexchange.com,1.0,0.8888888888888888,0.6666666666666666,0.3333333333333333,1.0,0.6666666666666666,0.8888888888888888,1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,0.3333333333333333,1.0,"Should it be the ""don't like"" or ""don't like"" button on Facebook?","I see an increasing demand for an unlike button on Facebook: 


http://www.facebook.com/pages/The-Unlike-Button/72641866357
Facebook Adds An Unlike Button For Pages
May 7, 2010
Facebook ""Unlike"" Button Comes to the News Feed
NOV 3, 2010


I have always used and understood unlike in the sense of dissimilar. Is it ever used in the sense of do not like?    
","In the modern world, and particularly in the world of computers, the un- prefix is increasingly used to denote an opposite or reversing action.

As in install/uninstall, register/unregister, and delete/undelete. Not to mention the undo facility we rely on in many applications.

In short, people quite reasonably expect the Facebook functionality to be called unlike because that follows the pattern they're used to. There's no danger of confusing such terminology with the dissimilar meaning, so why not?
"
3409,3409,5431,Need help using vba to fill in blanks left by excel pivot table when using %difference from previous row,"So, I'm not very knowledgeable at all yet when it comes to VBA. I have experience with Java, so I understand the concepts of structure behind coding and can read/understand basic-intermediate code. But when it comes to writing it myself, I'm definitely still a 1.5 out of 10 in terms of writing VBA myself. So, any help would be greatly appreciated.

So I have the following example pivot table (my actual is about 10 years of data with a few more columns):


The red and yellow dots are my problem areas. The columns with blank titles are just %differences from the previous row. However, as you can see, using that leaves blank spaces for the first month of every year (those are the yellow dots). Also, for the year lines, it doesn't calculate the %difference from the previous year (the red dots).

So, what I'm needing is (most likely) a PivotTableUpdate or PivotTableChangeSync (I still don't understand the difference actually by the way) to fill in data in those cells with the red and yellow dots. Any thoughts?

Edit: As requested, here's the data powering the pivot table:



For formatting purposes I moved the bottom half of the set up and to the right to fit it all into one picture.
",dootcher,https://stackoverflow.com/users/407775,"Without VBA you could try this attempt, i might extend it, but not today - it might be a way to solve this without VBA, but I am missing something.



E2=SUMIFS(D:D,C:C,C2)

F2=IFERROR(E2/E1;1)-1


On the PivotTable you add NP and Test2 to the section of values, then you can use Max or Sum for Test2 and it will look like this:



ATTENION here is an error, because summing the differences does not add up, when looking at the YEAR! But however, you can use the given formulas to get to the sums and differnces between the years ;)
",Jook,https://stackoverflow.com/users/1370465,http://stackoverflow.com/questions/12374038/need-help-using-vba-to-fill-in-blanks-left-by-excel-pivot-table-when-using-diff,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.5555555555555556,0.0,1.0,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.6666666666666666,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,1.0,1.0,0.7333333333333333,1.0,0.0,0.3333333333333333,0.8888888888888888,"When using the% difference from the previous row, you need help filling in the blanks left by Excel PivotTable with VBA","So, I'm not very knowledgeable at all yet when it comes to VBA. I have experience with Java, so I understand the concepts of structure behind coding and can read/understand basic-intermediate code. But when it comes to writing it myself, I'm definitely still a 1.5 out of 10 in terms of writing VBA myself. So, any help would be greatly appreciated.

So I have the following example pivot table (my actual is about 10 years of data with a few more columns):


The red and yellow dots are my problem areas. The columns with blank titles are just %differences from the previous row. However, as you can see, using that leaves blank spaces for the first month of every year (those are the yellow dots). Also, for the year lines, it doesn't calculate the %difference from the previous year (the red dots).

So, what I'm needing is (most likely) a PivotTableUpdate or PivotTableChangeSync (I still don't understand the difference actually by the way) to fill in data in those cells with the red and yellow dots. Any thoughts?

Edit: As requested, here's the data powering the pivot table:



For formatting purposes I moved the bottom half of the set up and to the right to fit it all into one picture.
","Without VBA you could try this attempt, i might extend it, but not today - it might be a way to solve this without VBA, but I am missing something.



E2=SUMIFS(D:D,C:C,C2)

F2=IFERROR(E2/E1;1)-1


On the PivotTable you add NP and Test2 to the section of values, then you can use Max or Sum for Test2 and it will look like this:



ATTENION here is an error, because summing the differences does not add up, when looking at the YEAR! But however, you can use the given formulas to get to the sums and differnces between the years ;)
"
2670,2670,4254,Help me identify this spider from my garden,"Found this in my garden today in Sydney, Australia (specifically Lane Cove). Can you tell me what it is?



",jacobsa,https://biology.stackexchange.com/users/15380,"I believe it is a Garden Orb Weaver spider. The Australian garden orb weaver, Eriophora transmarina, has a strikingly similar body 




",dustin,https://biology.stackexchange.com/users/12909,http://biology.stackexchange.com/questions/31461/help-me-identify-this-spider-from-my-garden,SCIENCE,biology.stackexchange.com,1.0,0.4444444444444444,0.0,1.0,1.0,1.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,0.0,0.8888888888888888,Help me identify the spider from the garden,"Today I found this in my garden in Sydney, Australia (especially Lane Bay). Can you tell me what it is?","I believe it is a Garden Orb Weaver spider. The Australian garden orb weaver, Eriophora transmarina, has a strikingly similar body 




"
5699,5699,9031,Keyword not supported in SQL Server CE connection string,"I'm trying to connect to a SQL Server CE database in a C# web application (VB 2012) using this connection string:

using (SqlCeConnection conn = new SqlCeConnection(@""Data Source|DataDirectory|\MyData.sdf; Persist Security Info=False;""))


The problem is that I am getting an exception that the data source|datadirectory is not a supported keyword. I attempted to change this string to:

Data Source=MainDb.sdf;Persist Security Info=False;


But then I get an error that the Db cannot be found. The database is located in the App_Data folder. Any ideas?
",E Crux,https://stackoverflow.com/users/2407018,"I think you're just simply missing an = sign:

Data Source=|DataDirectory|\MyData.sdf; Persist Security Info=False;
           * 
          ***

",marc_s,https://stackoverflow.com/users/13302,http://stackoverflow.com/questions/16697086/keyword-not-supported-in-sql-server-ce-connection-string,STACKOVERFLOW,stackoverflow.com,1.0,0.3333333333333333,0.0,1.0,0.6666666666666666,1.0,0.6666666666666666,0.4444444444444444,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.6666666666666666,0.8888888888888888,Keyword is not supported in SQL Server CE connection string,"I'm trying to connect to a SQL Server CE database in a C# web application (VB 2012) using this connection string:

using (SqlCeConnection conn = new SqlCeConnection(@""Data Source|DataDirectory|\MyData.sdf; Persist Security Info=False;""))


The problem is that I am getting an exception that the data source|datadirectory is not a supported keyword. I attempted to change this string to:

Data Source=MainDb.sdf;Persist Security Info=False;


But then I get an error that the Db cannot be found. The database is located in the App_Data folder. Any ideas?
","I think you're just simply missing an = sign:

Data Source=|DataDirectory|\MyData.sdf; Persist Security Info=False;
           * 
          ***

"
4354,4354,6929,image processing,"This is an assignment, i have put good effort since i am new to python programming:

I am running the following function which takes in image and phrase (spaces will be removed so just text) as arguments, i have already been given all the import and preprocessing code, i just need to implement this function. I can only use getpixel, putpixel, load, and save. That is why coding this has been a hard task for me.

def InsertoImage(srcImage, phrase):  
    pix = srcImage.load()  
    for index,value in enumerate(phrase):  
        pix[10+index,15] = phrase[index]  
    srcImage.save()  
pass  


This code is giving ""system error"" which says that ""new style getargs format but argument is not tuple""

Edit:

C:\Users\Nave\Desktop\a1&gt;a1_template.py lolmini.jpg Hi  
Traceback (most recent call last):  
  File ""C:\Users\Nave\Desktop\a1\a1_template.py"", line 31, in &lt;module&gt;  
    doLOLImage(srcImage, phrase)  
  File ""C:\Users\Nave\Desktop\a1\a1_template.py"", line 23, in doLOLImage  
    pix[10+index,15] = phrase[index]  
SystemError: new style getargs format but argument is not a tuple  


Edit:

Ok Thanks, i understood and now posting code but i am getting error for the if statement not sure why the if statement is not working, here is full code sorry for not adding it entirely before: 

from future import division  

letters, numbers, and punctation are dictionaries mapping (uppercase)

characters to Images representing that character

NOTE: There is no space character stored!

from imageproc import letters, numbers, punctuation, preProcess  

This is the function to implement

def InserttoImage(srcImage, phrase):
    pix = srcImage.load()
    for index,value in enumerate(phrase):
        if value in letters:
           pix[10+index, 15]  = letters[value]
        elif value in numbers:
           pix[10+index, 15]  = numbers[value]
        elif value in punctuation: 
           pix[10+index, 15]  = punctuation[value]
    srcImage.save()
    pass  

This code is performed when this script is called from the command line via:

'python .py'

if name == 'main':
    srcImage, phrase = preProcess()
    InserttoImage(srcImage, phrase)  

Thanks, letter, numbers, and punctuation are dictionaries which see the key element and open the image (font).
But still there is an issue with pix[10+index, 15] as it is giving error:

pix[10+index, 15]  = letters[value]  


SystemError: new style getargs format but argument is not a tuple  
",nman84,https://stackoverflow.com/users/427886,"My suggestion to the general problem is to create an image that contains all of the characters, at known coordinates (top, bottom, left, right) and then transfer the appropriate parts of the character image into the new output image.
",rwong,https://stackoverflow.com/users/377657,http://stackoverflow.com/questions/3553088/image-processing,STACKOVERFLOW,stackoverflow.com,0.6666666666666666,0.3333333333333333,0.0,0.5,1.0,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,1.0,0.0,0.5555555555555556,0.8333333333333334,0.5,1.0,1.0,0.7,0.3333333333333333,0.3333333333333333,0.0,0.7777777777777778,image processing,"This is an assignment, i have put good effort since i am new to python programming:

I am running the following function which takes in image and phrase (spaces will be removed so just text) as arguments, i have already been given all the import and preprocessing code, i just need to implement this function. I can only use getpixel, putpixel, load, and save. That is why coding this has been a hard task for me.

def InsertoImage(srcImage, phrase):  
    pix = srcImage.load()  
    for index,value in enumerate(phrase):  
        pix[10+index,15] = phrase[index]  
    srcImage.save()  
pass  


This code is giving ""system error"" which says that ""new style getargs format but argument is not tuple""

Edit:

C:\Users\Nave\Desktop\a1&gt;a1_template.py lolmini.jpg Hi  
Traceback (most recent call last):  
  File ""C:\Users\Nave\Desktop\a1\a1_template.py"", line 31, in &lt;module&gt;  
    doLOLImage(srcImage, phrase)  
  File ""C:\Users\Nave\Desktop\a1\a1_template.py"", line 23, in doLOLImage  
    pix[10+index,15] = phrase[index]  
SystemError: new style getargs format but argument is not a tuple  


Edit:

Ok Thanks, i understood and now posting code but i am getting error for the if statement not sure why the if statement is not working, here is full code sorry for not adding it entirely before: 

from future import division  

letters, numbers, and punctation are dictionaries mapping (uppercase)

characters to Images representing that character

NOTE: There is no space character stored!

from imageproc import letters, numbers, punctuation, preProcess  

This is the function to implement

def InserttoImage(srcImage, phrase):
    pix = srcImage.load()
    for index,value in enumerate(phrase):
        if value in letters:
           pix[10+index, 15]  = letters[value]
        elif value in numbers:
           pix[10+index, 15]  = numbers[value]
        elif value in punctuation: 
           pix[10+index, 15]  = punctuation[value]
    srcImage.save()
    pass  

This code is performed when this script is called from the command line via:

'python .py'

if name == 'main':
    srcImage, phrase = preProcess()
    InserttoImage(srcImage, phrase)  

Thanks, letter, numbers, and punctuation are dictionaries which see the key element and open the image (font).
But still there is an issue with pix[10+index, 15] as it is giving error:

pix[10+index, 15]  = letters[value]  


SystemError: new style getargs format but argument is not a tuple  
","My general advice is to create an image with all the characters in the known coordinates (top, bottom, left, right), and then transfer the appropriate part of the character image to the new output image."
4288,4288,6831,Wrong spacing around guillemets,"I use UTF-8 encoding to type a document in French, with the following definitions for guillemets:

\DeclareUnicodeCharacter{AB}{\og}
\DeclareUnicodeCharacter{BB}{\fg\xspace}


and the Babel package:

\usepackage[francais]{babel}


However, when I type a text like ceci cela «~quoted~» ceci cela, the spacing is wrong around the opening guillemet:



Notice that the space before the opening guillemet is too small, and the spacing after is too large. The closing guillemet has correct spacing. How could I fix that?
",F'x,https://tex.stackexchange.com/users/3734,"The spacing is already inserted by \og and \fg, so you shouldn't type the ~. You can consider changing the definition of the Unicode character as

\DeclareUnicodeCharacter{AB}{\og\ignorespaces}
\DeclareUnicodeCharacter{BB}{\unskip\fg}


so that inputting

Ces simulations «directes» sont ainsi

Ces simulations « directes » sont ainsi


will be equivalent.



Notice that \xspace does nothing.

If you insist to type «~directes~», then the definition for the open guillemets character could be

\makeatletter
\DeclareUnicodeCharacter{AB}{%
  \og\@ifnextchar~{\@gobble}{}}
\makeatother


Say what you want, but I find this spacing awful. ;-)
",egreg,https://tex.stackexchange.com/users/4427,http://tex.stackexchange.com/questions/71035/wrong-spacing-around-guillemets,TECHNOLOGY,tex.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,0.6666666666666666,1.0,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.8,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.8888888888888888,Incorrect spacing near Guilin,"I use UTF-8 encoding to type a document in French, with the following definitions for guillemets:

\DeclareUnicodeCharacter{AB}{\og}
\DeclareUnicodeCharacter{BB}{\fg\xspace}


and the Babel package:

\usepackage[francais]{babel}


However, when I type a text like ceci cela «~quoted~» ceci cela, the spacing is wrong around the opening guillemet:



Notice that the space before the opening guillemet is too small, and the spacing after is too large. The closing guillemet has correct spacing. How could I fix that?
","The spacing is already inserted by \og and \fg, so you shouldn't type the ~. You can consider changing the definition of the Unicode character as

\DeclareUnicodeCharacter{AB}{\og\ignorespaces}
\DeclareUnicodeCharacter{BB}{\unskip\fg}


so that inputting

Ces simulations «directes» sont ainsi

Ces simulations « directes » sont ainsi


will be equivalent.



Notice that \xspace does nothing.

If you insist to type «~directes~», then the definition for the open guillemets character could be

\makeatletter
\DeclareUnicodeCharacter{AB}{%
  \og\@ifnextchar~{\@gobble}{}}
\makeatother


Say what you want, but I find this spacing awful. ;-)
"
544,544,857,How to tell a macmini to stop booting to Windows from a macbook pro?,"I need to be able to control a mac mini without a screen and I think using screensharing would be enough. I've enabled screensharing, setup a manual IP address and I have an ethernet cable. 

The problem is I don't have display to use on the mac mini and I currently borrowed a keyboard and a firewire cable to setup screensharing: 


booted mac mini in target mode (wish there was a way to do it without the keyboard)
booted the macbook holding the alt key and choosing the firewire drive


The problem is the mac mini has a bootcamp partition setup to which it boots by default. I googled a bit and tried the System Preferences &gt; Startup Disk option then the /etc/fstab route but no joy: the mac mini still boots to Windows.

How can I get the macmini to simply boot to it's osx all the time (given that I have to change the settings on a macbook with a firewire cable) ?
",George Profenza,https://apple.stackexchange.com/users/8542,"The system stores the boot choice in NVRAM, so you might reset it by powering off and then holding command-option-p-r while you hear the start chimes repeat 2 or 3 times.  At that point, it should choose the first bootable system on the internal drive. IF that doesn't work, you could post the filesystem layout - but a corrupt NVRAM settings file would explain why your choice of Startup Disk wasn't respected.
",bmike,https://apple.stackexchange.com/users/5472,http://apple.stackexchange.com/questions/84865/how-to-tell-a-macmini-to-stop-booting-to-windows-from-a-macbook-pro,TECHNOLOGY,apple.stackexchange.com,1.0,0.8888888888888888,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.8,0.6666666666666666,0.0,0.6666666666666666,0.8888888888888888,How do I tell macmini to stop booting from MacBook Pro to windows?,"I need to be able to control a mac mini without a screen and I think using screensharing would be enough. I've enabled screensharing, setup a manual IP address and I have an ethernet cable. 

The problem is I don't have display to use on the mac mini and I currently borrowed a keyboard and a firewire cable to setup screensharing: 


booted mac mini in target mode (wish there was a way to do it without the keyboard)
booted the macbook holding the alt key and choosing the firewire drive


The problem is the mac mini has a bootcamp partition setup to which it boots by default. I googled a bit and tried the System Preferences &gt; Startup Disk option then the /etc/fstab route but no joy: the mac mini still boots to Windows.

How can I get the macmini to simply boot to it's osx all the time (given that I have to change the settings on a macbook with a firewire cable) ?
","The system stores the boot choice in NVRAM, so you might reset it by powering off and then holding command-option-p-r while you hear the start chimes repeat 2 or 3 times.  At that point, it should choose the first bootable system on the internal drive. IF that doesn't work, you could post the filesystem layout - but a corrupt NVRAM settings file would explain why your choice of Startup Disk wasn't respected.
"
3681,3681,5870,"Given Ohm's law, how can current increase if voltage increases, given fixed resistance?","According to Ohm's law, V=IR (voltage equals current times resistance).

So if the voltage increases, then the current increases provided that the resistance remains constant.

I know that Voltage or potential difference means work done per unit positive charge in bringing that charge from one point to another.

So according to Ohm's law, if the work done per unit charge increases then current will increase. How can this be true? Point out my mistakes.
",Souhardya Mondal,https://physics.stackexchange.com/users/62308,"
  how can this be true?


If we connect 1.5V cell to a 10 ohm resistor, the current is, by Ohm's law, 0.15A and the power delivered to the resistor by the cell is 0.225W.

Now, connect a 9V battery in place of the 1.5V cell.  The current is now, by Ohm's law, 0.9A and the power delivered to the resistor is now 8.1W.

The 9V battery must deliver far more power to the resistor than the 1.5V cell does.

There's nothing mysterious here.  Why do you think the current should not increase if the voltage increases?
",Alfred Centauri,https://physics.stackexchange.com/users/9887,http://physics.stackexchange.com/questions/141786/given-ohms-law-how-can-current-increase-if-voltage-increases-given-fixed-resi,SCIENCE,physics.stackexchange.com,1.0,0.8888888888888888,0.0,1.0,1.0,1.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,0.8888888888888888,"Given Ohm's law, given a fixed resistance, if the voltage increases, how does the current increase?","According to Ohm's law, V=IR (voltage equals current times resistance).

So if the voltage increases, then the current increases provided that the resistance remains constant.

I know that Voltage or potential difference means work done per unit positive charge in bringing that charge from one point to another.

So according to Ohm's law, if the work done per unit charge increases then current will increase. How can this be true? Point out my mistakes.
","
  how can this be true?


If we connect 1.5V cell to a 10 ohm resistor, the current is, by Ohm's law, 0.15A and the power delivered to the resistor by the cell is 0.225W.

Now, connect a 9V battery in place of the 1.5V cell.  The current is now, by Ohm's law, 0.9A and the power delivered to the resistor is now 8.1W.

The 9V battery must deliver far more power to the resistor than the 1.5V cell does.

There's nothing mysterious here.  Why do you think the current should not increase if the voltage increases?
"
5740,5740,9089,Why is covalent bonding stronger than electrostatic attraction?,"I guess if we look at this problem from a ""conjugate"" perspective then the conjugate of a covalent bond is two elements with electrons lying around. On the other hand, with two electrostatically attracted things, the lack of a bond leaves two separate, charged particles. 

But that still doesn't answer the question; why are electrons less stable than ions? I guess in the case of an ion though there are still electrons but also a nucleus the stabilize the electrons. 
",Dissenter,https://chemistry.stackexchange.com/users/5084,"Short answer:

To quote Mehrdad: You're basically comparing an intermolecular force with an intramolecular force.

Ionic bonds are two charged atoms sitting next to each other with minimal overlap of their orbitals.

Covalents bonds are two atoms becoming one molecule with significant changes in orbital structure. 

It is not always clear cut: there are atoms with part-ionic and part-covalent character or two atoms sitting next to each other with moderate overlap of their orbitals. 

Here is a good explanation (for solids): Are metallic/ionic bonds weaker than covalent bonds? I was taught the opposite. Now I&#39;m confused

Long answer:

Electrostatic bonds by definition are incapable of any significant bond formation. Bond formation involves the formation of a lower energy ""bonding orbital(s)"" out of two (or more) higher energy ordinary orbitals on adjacent atoms within the molecule. The formation of bonding orbitals gives covalent bonding orbitals much lower energy (not smaller, see diagram) than non-bonding orbitals which exist in the unbound state. This energy difference is larger than is possible for merely electrostatic attractions. Why is this the case? Because the electrons in bonding orbital are better able to counteract the positive charges of the adjacent nuclei. This makes sense because the negative charge on one molecule in an electrostatic arrangement is only able to neutralize the positive charge from its own nuclei. Bonding orbitals that are only present in covalent bonds share those electrons between two nuclei and thereby better neutralize the charges of both nuclei, which results in a lower energy for the bonded system than is possible in an ionic system. 


Image Source
",Dale,https://chemistry.stackexchange.com/users/114,http://chemistry.stackexchange.com/questions/21774/why-is-covalent-bonding-stronger-than-electrostatic-attraction,SCIENCE,chemistry.stackexchange.com,1.0,0.7777777777777778,0.0,0.0,1.0,1.0,0.5,0.5,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.8888888888888888,1.0,0.7777777777777778,1.0,1.0,0.9,0.0,0.0,1.0,0.8888888888888888,Why is covalent bond stronger than electrostatic attraction?,"I think if we look at this problem from the perspective of ""conjugation"", then the conjugation of covalent bond is the element around two electrons. On the other hand, there are two electrostatic attraction, the lack of a bond leaves two independent charged particles.","Short answer:

To quote Mehrdad: You're basically comparing an intermolecular force with an intramolecular force.

Ionic bonds are two charged atoms sitting next to each other with minimal overlap of their orbitals.

Covalents bonds are two atoms becoming one molecule with significant changes in orbital structure. 

It is not always clear cut: there are atoms with part-ionic and part-covalent character or two atoms sitting next to each other with moderate overlap of their orbitals. 

Here is a good explanation (for solids): Are metallic/ionic bonds weaker than covalent bonds? I was taught the opposite. Now I&#39;m confused

Long answer:

Electrostatic bonds by definition are incapable of any significant bond formation. Bond formation involves the formation of a lower energy ""bonding orbital(s)"" out of two (or more) higher energy ordinary orbitals on adjacent atoms within the molecule. The formation of bonding orbitals gives covalent bonding orbitals much lower energy (not smaller, see diagram) than non-bonding orbitals which exist in the unbound state. This energy difference is larger than is possible for merely electrostatic attractions. Why is this the case? Because the electrons in bonding orbital are better able to counteract the positive charges of the adjacent nuclei. This makes sense because the negative charge on one molecule in an electrostatic arrangement is only able to neutralize the positive charge from its own nuclei. Bonding orbitals that are only present in covalent bonds share those electrons between two nuclei and thereby better neutralize the charges of both nuclei, which results in a lower energy for the bonded system than is possible in an ionic system. 


Image Source
"
1879,1879,2982,Make *Buffer List* always appear in horizontal split,"I know Emacs tries to be intellectual and opens its helper buffers depending on which dimension of the window is bigger, so it may appear in vertical split window if current width is bigger than height, and in horizontal split otherwise.

But I’d prefer it to open that list always in horizontal split, because there are long paths I can’t see when the buffer is placed in vertical split. How can I do this?
",tijagi,https://stackoverflow.com/users/685107,"You can remove (5) if you prefer not to select the window after it is displayed -- i.e., remove (select-window (get-buffer-window (buffer-name buffer))).  I like the bottom window to be reserved for a 3-month calendar, so that's why I have a condition to use the window above (if it exists) -- you can remove that condition if you are so inclined.  Actually, it's your function so you can modify everything as you see fit now that you see how it works.  The alist would be used like this:  '((window-width . 33)) if you wanted to control certain aspects of the target window, etc.  I find myself always going back to this document page because it is the only scanty formal example I've found . . . and, of course, the source itself window.el:  http://www.gnu.org/software/emacs/manual/html_node/elisp/Display-Action-Functions.html

(defun lawlist-list-buffers-left (&amp;optional arg)
  ""Display a list of existing buffers.
The list is displayed in a buffer named \""*Buffer List*\"".
See `buffer-menu' for a description of the Buffer Menu.
    By default, all buffers are listed except those whose names start
with a space (which are for internal use).  With prefix argument
ARG, show only buffers that are visiting files.""
  (interactive ""P"")
  (lawlist-display-buffer-left (list-buffers-noselect arg) nil))

(defun lawlist-list-buffers-right (&amp;optional arg)
  ""Display a list of existing buffers.
The list is displayed in a buffer named \""*Buffer List*\"".
See `buffer-menu' for a description of the Buffer Menu.
    By default, all buffers are listed except those whose names start
with a space (which are for internal use).  With prefix argument
ARG, show only buffers that are visiting files.""
  (interactive ""P"")
  (lawlist-display-buffer-right (list-buffers-noselect arg) nil))

(defun lawlist-display-buffer-left (buffer alist)
""(1) If `buffer` is already displayed, then display it again in the same window.
(2) If `buffer` is not already displayed, and if there is a window to the left,
then display that `buffer` in said window. (3) If `buffer` is not already
displayed, and if there is a window to the right, then use the selected window.
(4) If all else fails, then create a new window to the left and display `buffer` there.
(5) Select the target window which displays `buffer`.""
 (let (
    (window
      (cond
        ((get-buffer-window buffer (selected-frame)))
        ((window-in-direction 'above))
        ((window-in-direction 'left))
        ((window-in-direction 'right)
          (selected-window))
        (t
          (split-window (selected-window) nil 'left)))))
  (window--display-buffer buffer window 'window alist display-buffer-mark-dedicated)
  (select-window (get-buffer-window (buffer-name buffer)))))

(defun lawlist-display-buffer-right (buffer alist)
""(1) If `buffer` is already displayed, then display it again in the same window.
(2) If `buffer` is not already displayed, and if there is a window to the right,
then display that `buffer` in said window. (3) If `buffer` is not already
displayed, and if there is a window to the left, then use the selected window.
(4) If all else fails, then create a new window to the right and display `buffer` there.
(5) Select the target window which displays `buffer`.""
 (let (
    (window
      (cond
        ((get-buffer-window buffer (selected-frame)))
        ((window-in-direction 'above))
        ((window-in-direction 'right))
        ((window-in-direction 'left)
          (selected-window))
        (t
          (split-window (selected-window) nil 'right)))))
  (window--display-buffer buffer window 'window alist display-buffer-mark-dedicated)
  (select-window (get-buffer-window (buffer-name buffer)))))

",lawlist,https://stackoverflow.com/users/2112489,http://stackoverflow.com/questions/21542914/make-buffer-list-always-appear-in-horizontal-split,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.7777777777777778,0.0,1.0,1.0,1.0,0.6666666666666666,0.4444444444444444,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.8666666666666666,0.6666666666666666,0.3333333333333333,0.6666666666666666,1.0,Make * buffer list * always appear as a horizontal split,"I know that Emacs tries to be intelligent and open its auxiliary buffer based on the size of the window, so if the current width is greater than the height, it may appear in the vertical split window, otherwise it may appear in the horizontal split window.","You can remove (5) if you prefer not to select the window after it is displayed -- i.e., remove (select-window (get-buffer-window (buffer-name buffer))).  I like the bottom window to be reserved for a 3-month calendar, so that's why I have a condition to use the window above (if it exists) -- you can remove that condition if you are so inclined.  Actually, it's your function so you can modify everything as you see fit now that you see how it works.  The alist would be used like this:  '((window-width . 33)) if you wanted to control certain aspects of the target window, etc.  I find myself always going back to this document page because it is the only scanty formal example I've found . . . and, of course, the source itself window.el:  http://www.gnu.org/software/emacs/manual/html_node/elisp/Display-Action-Functions.html

(defun lawlist-list-buffers-left (&amp;optional arg)
  ""Display a list of existing buffers.
The list is displayed in a buffer named \""*Buffer List*\"".
See `buffer-menu' for a description of the Buffer Menu.
    By default, all buffers are listed except those whose names start
with a space (which are for internal use).  With prefix argument
ARG, show only buffers that are visiting files.""
  (interactive ""P"")
  (lawlist-display-buffer-left (list-buffers-noselect arg) nil))

(defun lawlist-list-buffers-right (&amp;optional arg)
  ""Display a list of existing buffers.
The list is displayed in a buffer named \""*Buffer List*\"".
See `buffer-menu' for a description of the Buffer Menu.
    By default, all buffers are listed except those whose names start
with a space (which are for internal use).  With prefix argument
ARG, show only buffers that are visiting files.""
  (interactive ""P"")
  (lawlist-display-buffer-right (list-buffers-noselect arg) nil))

(defun lawlist-display-buffer-left (buffer alist)
""(1) If `buffer` is already displayed, then display it again in the same window.
(2) If `buffer` is not already displayed, and if there is a window to the left,
then display that `buffer` in said window. (3) If `buffer` is not already
displayed, and if there is a window to the right, then use the selected window.
(4) If all else fails, then create a new window to the left and display `buffer` there.
(5) Select the target window which displays `buffer`.""
 (let (
    (window
      (cond
        ((get-buffer-window buffer (selected-frame)))
        ((window-in-direction 'above))
        ((window-in-direction 'left))
        ((window-in-direction 'right)
          (selected-window))
        (t
          (split-window (selected-window) nil 'left)))))
  (window--display-buffer buffer window 'window alist display-buffer-mark-dedicated)
  (select-window (get-buffer-window (buffer-name buffer)))))

(defun lawlist-display-buffer-right (buffer alist)
""(1) If `buffer` is already displayed, then display it again in the same window.
(2) If `buffer` is not already displayed, and if there is a window to the right,
then display that `buffer` in said window. (3) If `buffer` is not already
displayed, and if there is a window to the left, then use the selected window.
(4) If all else fails, then create a new window to the right and display `buffer` there.
(5) Select the target window which displays `buffer`.""
 (let (
    (window
      (cond
        ((get-buffer-window buffer (selected-frame)))
        ((window-in-direction 'above))
        ((window-in-direction 'right))
        ((window-in-direction 'left)
          (selected-window))
        (t
          (split-window (selected-window) nil 'right)))))
  (window--display-buffer buffer window 'window alist display-buffer-mark-dedicated)
  (select-window (get-buffer-window (buffer-name buffer)))))

"
1006,1006,1587,"Can I extend my monitors, mouse, keyboard accross a room?","I am considering building my next PC into a server rack case, the reason is I am getting a server cabinet and will be putting in a few servers in it.  It will be in my room where I use my main PC as well and in my case it just makes sense to build my next PC into this cabinet/rack.  

So my main concern, will I be able to extend my mouse, keyboard, and 2-3 monitors 10-15 feet across a room from my server rack to my desk?
",JasonDavis,https://superuser.com/users/3700,"You could, in the case of the peripherals, go wireless, [s]but 15 feet is longer than most cable specs allow for (USB, for example, is 5m)[/s], however a DVI cable must reach 16 feet, so you'll just need a long cable. I fear it may be more trouble than it's worth, though.
",Phoshi,https://superuser.com/users/6998,http://superuser.com/questions/122489,TECHNOLOGY,superuser.com,0.8888888888888888,0.7777777777777778,0.0,1.0,1.0,0.3333333333333333,0.6666666666666666,0.5555555555555556,0.0,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8888888888888888,0.8888888888888888,0.5555555555555556,1.0,1.0,1.0,0.0,0.3333333333333333,0.6666666666666666,1.0,"Can I extend the monitor, mouse and keyboard across the room?","I'm thinking about putting my next computer in a server rack because I got a server cabinet and put some servers in it. It will be in my room, I will also use my main computer, in my case, it is just meaningful to build my next computer into this cabinet / rack.","You could, in the case of the peripherals, go wireless, [s]but 15 feet is longer than most cable specs allow for (USB, for example, is 5m)[/s], however a DVI cable must reach 16 feet, so you'll just need a long cable. I fear it may be more trouble than it's worth, though.
"
2937,2937,4676,How do you score the Mayor in an unfinished city?,"How do you score the Mayor in an unfinished city at the end of a game of Carcassonne?
",Mat,https://boardgames.stackexchange.com/users/3722,"The Mayor's ability allows him to count as more than one follower. So at the end of the game, an unfinished city is scored as normal - compare the Mayor's effective follower number with that of any other player present in the city. The player(s) with the most followers each score one point per city tile, and one point for each pennant.

The only special case is that if the city has no pennants, then the Mayor doesn't count as a follower, and can't score anything.

Here are the relevant rules:


  On his turn, a player may place his mayor instead of a follower. He
  may only place his mayor in a city, which has no knight or follower.
  The usual follower placing rules apply. When a city is scored, the
  mayor counts for as many followers as there are pennants in the city. For example, if the city has 3 pennants,
  the mayor counts as 3 followers. If the city has no pennants, the mayor counts as no followers. A normal follower counts as 1 follower. The large follower from Inns &amp; Cathedrals counts as 2 followers. The value of the city is not changed by the presence of a mayor. After scoring the city, the player takes his mayor back.

",ire_and_curses,https://boardgames.stackexchange.com/users/50,http://boardgames.stackexchange.com/questions/9685/how-do-you-score-the-mayor-in-an-unfinished-city,CULTURE,boardgames.stackexchange.com,1.0,0.7777777777777778,0.0,1.0,1.0,1.0,0.7777777777777778,0.4444444444444444,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,1.0,0.6666666666666666,0.0,0.6666666666666666,0.8888888888888888,How do you rate the mayor in an unfinished city?,How do you rate the mayor after a Carlsson game in an unfinished city?,"The Mayor's ability allows him to count as more than one follower. So at the end of the game, an unfinished city is scored as normal - compare the Mayor's effective follower number with that of any other player present in the city. The player(s) with the most followers each score one point per city tile, and one point for each pennant.

The only special case is that if the city has no pennants, then the Mayor doesn't count as a follower, and can't score anything.

Here are the relevant rules:


  On his turn, a player may place his mayor instead of a follower. He
  may only place his mayor in a city, which has no knight or follower.
  The usual follower placing rules apply. When a city is scored, the
  mayor counts for as many followers as there are pennants in the city. For example, if the city has 3 pennants,
  the mayor counts as 3 followers. If the city has no pennants, the mayor counts as no followers. A normal follower counts as 1 follower. The large follower from Inns &amp; Cathedrals counts as 2 followers. The value of the city is not changed by the presence of a mayor. After scoring the city, the player takes his mayor back.

"
125,125,198,Password sending through network,"In case of no TLS/SSL available, why can't I use the hash of the password (SHA512) as the key to encrypt the password (with out any salt) to send through the network ?
MITM attacks I can understand, but what are the other possible attacks ?
",user34694,https://security.stackexchange.com/users/34694,"SSL's only purpose is to stop Man in the middle from happening. Not having SSL/TLS just means you can't have:


Confidentiality
Integrity


Furthermore the password is just a token used for authentication, it's not required to have the actual password if the access token is the hash. You can perform a repeater/replay attack if you can sniff the hash from the network and provide it to your application to authenticate to your service.

An example for such an attack can be found in Windows. It's called the pass-the-hash attack.
",Lucas Kauffman,https://security.stackexchange.com/users/3339,http://security.stackexchange.com/questions/46072/password-sending-through-network,TECHNOLOGY,security.stackexchange.com,1.0,0.4444444444444444,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.0,1.0,0.8888888888888888,Send password over the network,"If no TLS / SSL is available, why can't we use the hash of the password (SHA512) as the key to encrypt the password to be sent over the network (without any salt)?","SSL's only purpose is to stop Man in the middle from happening. Not having SSL/TLS just means you can't have:


Confidentiality
Integrity


Furthermore the password is just a token used for authentication, it's not required to have the actual password if the access token is the hash. You can perform a repeater/replay attack if you can sniff the hash from the network and provide it to your application to authenticate to your service.

An example for such an attack can be found in Windows. It's called the pass-the-hash attack.
"
5010,5010,7980,"Solve for time, given distance and acceleration","Two gangsters are flying down I-70 West at a constant 108 hm/hr. If they make it to Indiana, they will be safe. When they are 1 km away from the Indiana border, while still traveling at a constant 108 km/hr, they pass a concealed police car hidden in a speed trap. At the instant that the criminals pass the patrol car, the cop pulls onto the highway and accelerates at a constant rate of 2 m/s^2. Does the cop catch up with them before they cross the state line?

Here's what I have progressed so far


  ΔV = (ΔX)/(T)
  
  when V is velocity, X is distance, and T is time.
  
  108 = (1 - 0)/T
  
  108T = 1
  
  T = 1/108
  
  T = 0.00925 hours
  
  T = 0.00925 * 60 * 60
  
  T = 33.33 seconds (this is the time it takes the gangsters to get to
  the borders of Indiana)


What I am stuck at is the time it takes the cop to travel the same distance. I have used the distance formula to find time as follows:


  Xf = Xi + 1/2 * A * T^2
  
  where A is acceleration
  
  Since the cop is starting from rest, the initial velocity is 0 (zero),
  so
  
  1 = 0 + 1/2 * (2) * T^2
  
  1 = T^2
  
  T = 1 seconds


So it takes the cop 1 seconds to travel the whole mile to Indiana? What am I doing wrong?
",Brian Lindsey,https://math.stackexchange.com/users/123222,"Converting the gangsters' speed to ms$^{-1}$, $108$ km/h $=108/3.6$ ms$^{-1} = 30$ ms$^{-1}$.

The distance the cop travelled in time $t$ s is $\frac12at^2 = t^2$ metres, and the distance the gangsters travelled in time $t$ s is $30t$ metres. The time when they met the second time is
$$\begin{align*}t^2 =&amp; 30t\\t=&amp;30\text{ seconds}\end{align*}$$

Then the distance they have travelled in $30$ seconds is $900$ metres, and this is before they arrive Indiana.
",peterwhy,https://math.stackexchange.com/users/89922,http://math.stackexchange.com/questions/648400/solve-for-time-given-distance-and-acceleration,SCIENCE,math.stackexchange.com,1.0,0.4444444444444444,0.0,1.0,1.0,1.0,0.6666666666666666,0.5555555555555556,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.6666666666666666,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,1.0,0.6666666666666666,0.0,0.6666666666666666,0.8888888888888888,"Solution time, given distance and acceleration","Two gangsters are flying down I-70 West at a constant 108 hm/hr. If they make it to Indiana, they will be safe. When they are 1 km away from the Indiana border, while still traveling at a constant 108 km/hr, they pass a concealed police car hidden in a speed trap. At the instant that the criminals pass the patrol car, the cop pulls onto the highway and accelerates at a constant rate of 2 m/s^2. Does the cop catch up with them before they cross the state line?

Here's what I have progressed so far


  ΔV = (ΔX)/(T)
  
  when V is velocity, X is distance, and T is time.
  
  108 = (1 - 0)/T
  
  108T = 1
  
  T = 1/108
  
  T = 0.00925 hours
  
  T = 0.00925 * 60 * 60
  
  T = 33.33 seconds (this is the time it takes the gangsters to get to
  the borders of Indiana)


What I am stuck at is the time it takes the cop to travel the same distance. I have used the distance formula to find time as follows:


  Xf = Xi + 1/2 * A * T^2
  
  where A is acceleration
  
  Since the cop is starting from rest, the initial velocity is 0 (zero),
  so
  
  1 = 0 + 1/2 * (2) * T^2
  
  1 = T^2
  
  T = 1 seconds


So it takes the cop 1 seconds to travel the whole mile to Indiana? What am I doing wrong?
","Converting the gangsters' speed to ms$^{-1}$, $108$ km/h $=108/3.6$ ms$^{-1} = 30$ ms$^{-1}$.

The distance the cop travelled in time $t$ s is $\frac12at^2 = t^2$ metres, and the distance the gangsters travelled in time $t$ s is $30t$ metres. The time when they met the second time is
$$\begin{align*}t^2 =&amp; 30t\\t=&amp;30\text{ seconds}\end{align*}$$

Then the distance they have travelled in $30$ seconds is $900$ metres, and this is before they arrive Indiana.
"
3914,3914,6240,What are all of the quotes in the OP of Eden of the East from?,"In the Eden of the East opening, there are a lot of quotes from different sources. The only one I know the origin of is ""The abuse of greatness is when it disjoins remorse from power,"" which is from Julius Caesar by William Shakespeare. I don't know what the other quotes that show up on the screen are from or are in reference to. Can someone tell me?
",kuwaly,https://anime.stackexchange.com/users/93,"This blogpost has a transcript of all of the text from the opening. Not all of them are famous quotes.


  ""I saw you in Heaven
  and heard of your glory
  You saved our world from the fallen angels
  I saw Messiah standing
  Standing before me with no words
  Nothing but ""Hope""
  When we lost dread, a Demon was laughing 
  But now you are showing us wonder
  Giving your love
  With awe, down on my knees again
  I've got to know you're the one
  The only one reveals the world"" 


This is repeated multiple times throughout the OP and seems to be part of the song 東のエデン挿入歌「Reveal The World」


  ""The abuse of greatness is when it disjoins remorse from power."" 


As you've noted, it's Brutus from Julius Caesar, by William Shakespeare.


  ""Mail
  Own date
  Media tool
  Appli
  Camera
  Phone book
  Iseg
  Music
  Service
  Setting
  You've got mail
  Calling
  Talking"" 


These seem to be options (partially obscured) of the phone.


  ""Let me walk with you when I'm lost in the wild
  I know you always lead me to another Eden
  Let me bless your name, O Lord, O Lord
  Your words will never fade away
  Since we believe you're the light on earth
  Reveals the world"" 


Also from the ""Reveal the world"" song lyrics.

The rest seems to be proper names and instances from the show itself, like ""noblesse oblige"", and ""Juiz"", and ""Selecao system
12 persons selected in Japan"". So the only real quote I guess is from the Julius Caesar play.
",Jon Lin,https://anime.stackexchange.com/users/91,http://anime.stackexchange.com/questions/4869/what-are-all-of-the-quotes-in-the-op-of-eden-of-the-east-from,CULTURE,anime.stackexchange.com,1.0,0.5555555555555556,0.0,0.6666666666666666,1.0,0.3333333333333333,0.8888888888888888,0.7777777777777778,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.0,0.0,0.7777777777777778,Where do all the famous sayings in the journey to the East Garden of Eden come from?,"In the East Garden of Eden, there are many quotations from different sources. The only source I know of is ""great abuse is when it separates regret from power,"" as William Shakespeare says in Caesar the great. I don't know what the other quotes on the screen are and what they are. Can someone tell me?","This blogpost has a transcript of all of the text from the opening. Not all of them are famous quotes.


  ""I saw you in Heaven
  and heard of your glory
  You saved our world from the fallen angels
  I saw Messiah standing
  Standing before me with no words
  Nothing but ""Hope""
  When we lost dread, a Demon was laughing 
  But now you are showing us wonder
  Giving your love
  With awe, down on my knees again
  I've got to know you're the one
  The only one reveals the world"" 


This is repeated multiple times throughout the OP and seems to be part of the song 東のエデン挿入歌「Reveal The World」


  ""The abuse of greatness is when it disjoins remorse from power."" 


As you've noted, it's Brutus from Julius Caesar, by William Shakespeare.


  ""Mail
  Own date
  Media tool
  Appli
  Camera
  Phone book
  Iseg
  Music
  Service
  Setting
  You've got mail
  Calling
  Talking"" 


These seem to be options (partially obscured) of the phone.


  ""Let me walk with you when I'm lost in the wild
  I know you always lead me to another Eden
  Let me bless your name, O Lord, O Lord
  Your words will never fade away
  Since we believe you're the light on earth
  Reveals the world"" 


Also from the ""Reveal the world"" song lyrics.

The rest seems to be proper names and instances from the show itself, like ""noblesse oblige"", and ""Juiz"", and ""Selecao system
12 persons selected in Japan"". So the only real quote I guess is from the Julius Caesar play.
"
2880,2880,4585,Can a PC have more than one Default Gateway?,"I know that a PC can have multiple network adapters each of which with different network identifiers (IP,MAC etc.). 

My question is, can a certain PC have more than one active default gateway? And if so, how does the PC (or better say the OS) knows to what adapter use for any given packet?
",user4537,https://serverfault.com/users/106155,"If your server/PC is multihomed, meaning it is part of two separate networks, you would have a default gateway on each network adapter. You then prioritize the network adapters. Like others have said though, you still just have one default gateway, but it's per network adapter. 
",token,https://serverfault.com/users/108124,http://serverfault.com/questions/347032,TECHNOLOGY,serverfault.com,0.8888888888888888,0.4444444444444444,0.0,0.3333333333333333,1.0,1.0,0.4444444444444444,0.3333333333333333,1.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,1.0,Can a computer have multiple default gateways?,"I know that a PC can have multiple network adapters each of which with different network identifiers (IP,MAC etc.). 

My question is, can a certain PC have more than one active default gateway? And if so, how does the PC (or better say the OS) knows to what adapter use for any given packet?
","If your server/PC is multihomed, meaning it is part of two separate networks, you would have a default gateway on each network adapter. You then prioritize the network adapters. Like others have said though, you still just have one default gateway, but it's per network adapter. 
"
4022,4022,6421,Understanding a \@for loop,"I'm having trouble with a \@for loop. I've got a macro that takes a comma delimited list and puts each element into a row of an array.  When I do this using a \@for loop, I get an extra row that I don't understand.  I can manually get rid of it with a negative space, (as in the commented line below) but that can't be the right way to do it, so I must be doing something wrong.  Here's a minimal example.  For comparison, if I construct what I expect the result of the loop to be manually, the extra row doesn't appear.

\documentclass{article}
\usepackage{amsmath}
\makeatletter
\newcommand{\fbun}[1]
   {\ensuremath{\left[\begin{array}{c}
      \@for\xx:=#1\do {\text{\xx}\\}
%     \\ [-2.75ex] % why is this required?
      \end{array}\right]}}
\makeatother
\begin{document}
$\left[\begin{array}{c}
      A\\
      B\\
      C\\
      D\\
      \end{array}\right]$
% same array, but generated by a macro
\fbun{A,B,C,D}
\end{document}



",Alan Munn,https://tex.stackexchange.com/users/2693,"The problem is that TeX finds something following the last \\ which starts a new row (it's neither \noalign nor \crcr that wouldn't).

A solution might be to use a token register: we develop the loop while in the first cell, so there's no problem of \xx not being defined any more after TeX has seen \\ (or &amp;).

\usepackage{amsmath}
\makeatletter
\newcommand{\fbun}[1]{%
  \begin{bmatrix}
  \toks@={\@gobble}%
  \@for\next:=#1\do
    {\toks@=\@xp{\the\@xp\toks@\@xp\\\@xp\text\@xp{\next}}}%
  \the\toks@
  \end{bmatrix}}
\makeatother


I've used \@xp (from amsmath) that's a shorthand for \expandafter; if the \text around the entry wasn't required, then

\toks@=\expandafter{\the\expandafter\toks@\next}


would have sufficed. Initializing \toks@ to \@gobble has the effect that the first \\ is swallowed.

Instead of array I've used bmatrix (change it if you like) and, of course, I deleted \ensuremath as the first step. :)
",egreg,https://tex.stackexchange.com/users/4427,http://tex.stackexchange.com/questions/34995/understanding-a-for-loop,TECHNOLOGY,tex.stackexchange.com,1.0,0.6666666666666666,0.0,1.0,1.0,1.0,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.3333333333333333,0.0,1.0,1.0,Understand a \ @ for loop,"There's a problem with my for loop. I have a macro that takes a comma separated list and places each element in a row array. When I do this using the for loop, I get an extra line that I don't understand. I can manually delete it with a negative space (as shown in the comment line below), but this is not the right way, so I must have done something wrong. Here is a simple example. For comparison purposes, if I build the result of the loop manually, no additional rows are displayed.","The problem is that TeX finds something following the last \\ which starts a new row (it's neither \noalign nor \crcr that wouldn't).

A solution might be to use a token register: we develop the loop while in the first cell, so there's no problem of \xx not being defined any more after TeX has seen \\ (or &amp;).

\usepackage{amsmath}
\makeatletter
\newcommand{\fbun}[1]{%
  \begin{bmatrix}
  \toks@={\@gobble}%
  \@for\next:=#1\do
    {\toks@=\@xp{\the\@xp\toks@\@xp\\\@xp\text\@xp{\next}}}%
  \the\toks@
  \end{bmatrix}}
\makeatother


I've used \@xp (from amsmath) that's a shorthand for \expandafter; if the \text around the entry wasn't required, then

\toks@=\expandafter{\the\expandafter\toks@\next}


would have sufficed. Initializing \toks@ to \@gobble has the effect that the first \\ is swallowed.

Instead of array I've used bmatrix (change it if you like) and, of course, I deleted \ensuremath as the first step. :)
"
3831,3831,6095,What are good sets of photographic portraits to use in mockups?,"I've been using the same set of photographic portraits in my mockups for a long time, and I'm looking for a more extensive set of square, male and female avatars/photos (portraits).

What are good sets to use?
",julien_c,https://graphicdesign.stackexchange.com/users/1022,"I've noted this set before. But it's worth repeating.

Automatic UI bonus points if your avatars include luchadores.

Who doesn't like extra credit? So what are you waiting for: Head to IconFinder to get the set.

  
  
",plainclothes,https://graphicdesign.stackexchange.com/users/4216,http://graphicdesign.stackexchange.com/questions/15735/what-are-good-sets-of-photographic-portraits-to-use-in-mockups,LIFE_ARTS,graphicdesign.stackexchange.com,1.0,0.8888888888888888,0.6666666666666666,1.0,0.0,0.0,0.7777777777777778,0.5555555555555556,0.0,0.0,1.0,0.6666666666666666,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,0.0,0.7777777777777778,What is a good photographic portrait set to use in a model?,"I've been using the same set of photographic portraits in the model for a long time, and I'm looking for a broader set of squares, male and female avatars / photos (portraits).","I've noted this set before. But it's worth repeating.

Automatic UI bonus points if your avatars include luchadores.

Who doesn't like extra credit? So what are you waiting for: Head to IconFinder to get the set.

  
  
"
2595,2595,4127,House rules to make the cloister less of a game winning tile in Carcassonne?,"In my experience, cloister tiles in Carcassonne are often ""too lucky"". If you draw a cloister tile in the beginning of the game, it will typically still require an investment of quite a bit of ""meeple"" time to obtain the full 9 points, which makes it a fair trade-off. However, after about half of the game, it's relatively likely that you can ""parachute"" a cloister tile in some spot and get 8 or 9 points immediately. This adds a lot of randomness to the game.

What house rules work well to diminish this effect?
",Erik P.,https://boardgames.stackexchange.com/users/30,"I don't have bad experiences with cloisters. But if they count too heavy, you can rule that an unfinished cloister counts as 0 points in the end. Which makes it harder to spend too much meeple on them.

Another possible rule is that cloisters must have unique 9 squares, not shared with another cloister.

But use them wise.
",Toon Krijthe,https://boardgames.stackexchange.com/users/45,http://boardgames.stackexchange.com/questions/8/house-rules-to-make-the-cloister-less-of-a-game-winning-tile-in-carcassonne,CULTURE,boardgames.stackexchange.com,1.0,0.7777777777777778,0.6666666666666666,0.6666666666666666,0.0,0.3333333333333333,0.4444444444444444,0.3333333333333333,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.3333333333333333,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.8,0.6666666666666666,0.0,0.3333333333333333,0.8888888888888888,"In karkasson, let the cloister be less like the winning tile house rule?","In my experience, Carlsson's cloister tiles are usually ""too lucky."". If you draw a cloister tile at the beginning of the game, it usually still takes quite a lot of time to get a full score of 9, which is a fair trade-off. However, after about half of the game, you are likely to ""parachute"" a cloister tile somewhere and get 8 or 9 points immediately. This adds a lot of randomness to the game.","I don't have bad experiences with cloisters. But if they count too heavy, you can rule that an unfinished cloister counts as 0 points in the end. Which makes it harder to spend too much meeple on them.

Another possible rule is that cloisters must have unique 9 squares, not shared with another cloister.

But use them wise.
"
92,92,152,Determining sample size for a comparative study involving two unequal groups,"I will like to know the formula for calculating the minimum sample size required for a comparative study involving 2 groups with unequal size. Group 1 is 10 times greater than group 2.
",Ehizele,https://stats.stackexchange.com/users/30970,"The generic formula for sample size at a given power in a regression is 

$$
N = \frac{2.84^2}{p(1-p)}\frac{\sigma^2}{MDE^2}
$$

N is your sample size, p is the proportion getting the treatment, $\sigma$ is the standard deviation of the residuals, and MDE=the minimum detectable effect that you are powered for.  2.84 comes from alpha confidence of 95% and 80% power.  

The more explanatory factors you've got in your experiment the more $\sigma$ will shrink.  Knowing how much it will shrink is tricky.  

At some point, analytical formulas collapse, and you're better off simply simulating your entire dataset, multiple times doing some sort of monte carlo, and fitting the desired model to each of the plausible datasets.  Your power is the proportion of times you get the result you want.  As with the analytical methods, you're only as good as your assumptions.  

Source is from memory, roughly following this.

This answer is a verbatim copy/paste of my answer to this thread
",generic_user,https://stats.stackexchange.com/users/17359,http://stats.stackexchange.com/questions/71690/determining-sample-size-for-a-comparative-study-involving-two-unequal-groups,SCIENCE,stats.stackexchange.com,1.0,0.6666666666666666,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.0,0.5555555555555556,1.0,0.7777777777777778,1.0,1.0,0.9333333333333332,0.6666666666666666,0.0,0.6666666666666666,0.8888888888888888,Determination of sample size in comparative study of two unequal groups,I would like to know the formula for calculating the minimum sample size required for two groups of comparative studies of different sizes. Group 1 was 10 times larger than group 2.,"The generic formula for sample size at a given power in a regression is 

$$
N = \frac{2.84^2}{p(1-p)}\frac{\sigma^2}{MDE^2}
$$

N is your sample size, p is the proportion getting the treatment, $\sigma$ is the standard deviation of the residuals, and MDE=the minimum detectable effect that you are powered for.  2.84 comes from alpha confidence of 95% and 80% power.  

The more explanatory factors you've got in your experiment the more $\sigma$ will shrink.  Knowing how much it will shrink is tricky.  

At some point, analytical formulas collapse, and you're better off simply simulating your entire dataset, multiple times doing some sort of monte carlo, and fitting the desired model to each of the plausible datasets.  Your power is the proportion of times you get the result you want.  As with the analytical methods, you're only as good as your assumptions.  

Source is from memory, roughly following this.

This answer is a verbatim copy/paste of my answer to this thread
"
3585,3585,5726,What's a common mechanism for emailing in the background?,"When users sign up to my site, the connection from my server to our 3rd-party SMTP provider is very bad and the app takes from a few seconds to a few minutes to connect. While it is trying to connect and send, users are forced to wait there and sometimes they would just give up and leave the site.

This is horrible user experience. What is a good way to make this seem instantaneous (having to host our own mailserver is not an option at this point)? Some way to execute this in the background? Maybe using some type of queuing mechanism?

I'm using the LNAMP stack on a CentOS 5 x64 machine. App is using CodeIgniter.

EDIT:

It seems using a local mailserver to use as a relay is a common solution. But how does one log or track whether or not email was delivered correctly by using this method? 

Sidenote: Some ESPs provide a REST API for email delivery (ours do too). We currently use SMTP and not their REST API. 
",lamp_scaler,https://serverfault.com/users/87326,"Not sure how common it (good practise) is but sending an email is a typical asynchronous process. One that can take several seconds and beyond. This makes it a perfect candidate for the use of messaging queue. 

The delivery method is of secondary importance but third party providers such as SendGrid (for transactional emails - forgotten password, invoice etc) or MailChimp (for newsletters and marketing) offer good value and has proven reliable.

By messaging queue I mean RabbitMQ (AMQ), ZeroMQ, Gearman, AWS SQS etc
Those can be used for any sort of information exchange between applications. In this case it's an information that certain email needs sending.

In terms of delivery information this can be obtained through an API with such provider or with more expensive plans through callback.
",pawpro,https://serverfault.com/users/95815,http://serverfault.com/questions/318374,TECHNOLOGY,serverfault.com,0.8888888888888888,0.6666666666666666,0.0,1.0,0.6666666666666666,1.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.3333333333333333,0.3333333333333333,0.3333333333333333,1.0,What is the common mechanism for sending mail in the background?,"When users sign up to my site, the connection from my server to our 3rd-party SMTP provider is very bad and the app takes from a few seconds to a few minutes to connect. While it is trying to connect and send, users are forced to wait there and sometimes they would just give up and leave the site.

This is horrible user experience. What is a good way to make this seem instantaneous (having to host our own mailserver is not an option at this point)? Some way to execute this in the background? Maybe using some type of queuing mechanism?

I'm using the LNAMP stack on a CentOS 5 x64 machine. App is using CodeIgniter.

EDIT:

It seems using a local mailserver to use as a relay is a common solution. But how does one log or track whether or not email was delivered correctly by using this method? 

Sidenote: Some ESPs provide a REST API for email delivery (ours do too). We currently use SMTP and not their REST API. 
","Not sure how common it (good practise) is but sending an email is a typical asynchronous process. One that can take several seconds and beyond. This makes it a perfect candidate for the use of messaging queue. 

The delivery method is of secondary importance but third party providers such as SendGrid (for transactional emails - forgotten password, invoice etc) or MailChimp (for newsletters and marketing) offer good value and has proven reliable.

By messaging queue I mean RabbitMQ (AMQ), ZeroMQ, Gearman, AWS SQS etc
Those can be used for any sort of information exchange between applications. In this case it's an information that certain email needs sending.

In terms of delivery information this can be obtained through an API with such provider or with more expensive plans through callback.
"
858,858,1366,Word describing the reversal of emotions,"
  A boy is highly confident one day and
  the next day scared, timid and shy. 
  
  A girl is emotional one day and
  emotionless the next.


Is there a term for a drastic switching of emotions?
A term for the switching to practically opposite emotions?

EDIT: Just to clarify the emotional changes are not rapid, and are permanent.  This rules out bi-polar, because bi-polar involves multiple periods of change.

EDIT2: I'm looking for a work to demonstrate the steepness or contrasts of change, but having no relationship to the speed of change.

Example:


  Over a course of 3 years a once quiet boy become the spokesmen of the school.

",William,https://english.stackexchange.com/users/6331,"How about capricious. My wife tolerates my capricious nature
",karim,https://english.stackexchange.com/users/119163,http://english.stackexchange.com/questions/20450/word-describing-the-reversal-of-emotions,CULTURE,english.stackexchange.com,1.0,0.7777777777777778,0.0,1.0,1.0,0.3333333333333333,0.6666666666666666,0.8888888888888888,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.8888888888888888,0.7777777777777778,0.5555555555555556,0.7777777777777778,0.7777777777777778,0.6,0.0,0.0,0.0,0.7777777777777778,Words for mood reversal,"
  A boy is highly confident one day and
  the next day scared, timid and shy. 
  
  A girl is emotional one day and
  emotionless the next.


Is there a term for a drastic switching of emotions?
A term for the switching to practically opposite emotions?

EDIT: Just to clarify the emotional changes are not rapid, and are permanent.  This rules out bi-polar, because bi-polar involves multiple periods of change.

EDIT2: I'm looking for a work to demonstrate the steepness or contrasts of change, but having no relationship to the speed of change.

Example:


  Over a course of 3 years a once quiet boy become the spokesmen of the school.

","How about capricious. My wife tolerates my capricious nature
"
3570,3570,5707,Inserting a blank line in vim?,"I quite often find I have a need to insert a blank line either below or above the current line when editing in vim. o and O will do this, but they subsequently switch into insert mode, which is annoying. Is there any built-in command to do this which will remain in normal mode?
",Andrew Ferrier,https://superuser.com/users/3021,"No, there's no built-in command for that.

These mappings do what you want:

nnoremap &lt;leader&gt;o o&lt;Esc&gt;
nnoremap &lt;leader&gt;O O&lt;Esc&gt;

",romainl,https://superuser.com/users/60075,http://superuser.com/questions/607163,TECHNOLOGY,superuser.com,1.0,0.7777777777777778,0.0,1.0,1.0,1.0,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,0.8888888888888888,0.8888888888888888,0.8,0.6666666666666666,0.0,0.3333333333333333,0.7777777777777778,Insert empty row in VIM?,"When editing in VIM, I often find it necessary to insert an empty row below or above the current row. O and o do this, but they then switch to insert mode, which is annoying. Is there any built-in command to do this, which will remain in normal mode?","No, there's no built-in command for that.

These mappings do what you want:

nnoremap &lt;leader&gt;o o&lt;Esc&gt;
nnoremap &lt;leader&gt;O O&lt;Esc&gt;

"
4490,4490,7120,Could Belief in Little Fears: Nightmare Edition cause the dark side of the moon to really be dark?,"I'm writing an episode which involves a plot by the monster Vanish involving possessing the dark side of the moon (if you don't know, his power is to possess shadows). I was going with the fact that the term ""the dark side of the moon"" would cause enough children to believe that it really was dark for Belief to make it so, but I'm not entirely sure that Belief works that way. Does it?
",Ness Gardna,https://rpg.stackexchange.com/users/7726,"Yes it totally can! Believe is the immense magic force, which spawned the whole dimension called Closetland into existence!
So the far side of the moon could really be a dark place, where the sun never reached - although adults would not see it as such, or would find a scientific explanation!
",Falco,https://rpg.stackexchange.com/users/14758,http://rpg.stackexchange.com/questions/23028/could-belief-in-little-fears-nightmare-edition-cause-the-dark-side-of-the-moon,CULTURE,rpg.stackexchange.com,0.8888888888888888,1.0,0.3333333333333333,0.6666666666666666,0.3333333333333333,1.0,0.4444444444444444,0.4444444444444444,0.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,0.8888888888888888,Believe in a little fear: will the nightmare version really darken the dark side of the moon?,"I'm writing an episode where a monster disappears, including having the dark side of the moon (if you don't know, his power is to have shadows). I think the word ""dark side of the moon"" will convince enough children that it's really dark for faith, but I'm not sure that faith works that way. Is it?","Yes it totally can! Believe is the immense magic force, which spawned the whole dimension called Closetland into existence!
So the far side of the moon could really be a dark place, where the sun never reached - although adults would not see it as such, or would find a scientific explanation!
"
677,677,1070,Eclipse C++ formatter puts new line before method identifiers,"I ran into a problem with the Eclipse formatter.  It won't format my code correctly when declaring methods within a class declaration.  It puts a new line after the method's return type.

I already exported the style xml file and examined the settings in it, but none of the settings have any apparent connection to this problem, and the settings editor in Eclipse didn't show the same problem happening in it's sample code for method declarations.

Here is an example bit of code for what I want to have happen:

class MyClass
{
    public:
        MyClass();
        void myMethod();
};


However, this is what I get:

class MyClass
{
    public:
        MyClass();
        void
        myMethod();
};


Again, in the styles editor, the code doesn't have this problem and looks just how I want it to, but in the actual code, the story is different.

I'm using version 3.8.0.  Any help is appreciated.

Edit: I deleted those source files that were formatted incorrectly (after formatting the code several times to no avail) and replaced them with ""identical"" files with the same methods, same structure, etc.  I formatted the code this time and it worked.  This is probably a bug, but I'm leaving it up just in case anyone else encounters a similar problem or has a solution to avoiding this problem in the first place.
",Adam,https://stackoverflow.com/users/956216,"If you have a custom formatter config, export it first (settings>C/C++ General>Formatter>Edit>Export). Then change the following line to ""do not insert"". Save the XML.

&lt;setting id=""org.eclipse.cdt.core.formatter.insert_new_line_before_identifier_in_function_declaration"" value=""do not insert""/&gt;


Delete the current config and import the one you changed. 
",Halil Kaskavalci,https://stackoverflow.com/users/811008,http://stackoverflow.com/questions/13893942/eclipse-c-formatter-puts-new-line-before-method-identifiers,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.4444444444444444,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.3333333333333333,0.0,1.0,Eclipse C + + formatter places new lines before method identifiers,"I ran into a problem with the Eclipse formatter.  It won't format my code correctly when declaring methods within a class declaration.  It puts a new line after the method's return type.

I already exported the style xml file and examined the settings in it, but none of the settings have any apparent connection to this problem, and the settings editor in Eclipse didn't show the same problem happening in it's sample code for method declarations.

Here is an example bit of code for what I want to have happen:

class MyClass
{
    public:
        MyClass();
        void myMethod();
};


However, this is what I get:

class MyClass
{
    public:
        MyClass();
        void
        myMethod();
};


Again, in the styles editor, the code doesn't have this problem and looks just how I want it to, but in the actual code, the story is different.

I'm using version 3.8.0.  Any help is appreciated.

Edit: I deleted those source files that were formatted incorrectly (after formatting the code several times to no avail) and replaced them with ""identical"" files with the same methods, same structure, etc.  I formatted the code this time and it worked.  This is probably a bug, but I'm leaving it up just in case anyone else encounters a similar problem or has a solution to avoiding this problem in the first place.
","If you have a custom formatter config, export it first (settings>C/C++ General>Formatter>Edit>Export). Then change the following line to ""do not insert"". Save the XML.

&lt;setting id=""org.eclipse.cdt.core.formatter.insert_new_line_before_identifier_in_function_declaration"" value=""do not insert""/&gt;


Delete the current config and import the one you changed. 
"
478,478,744,Are scientifically detached professors referred to as ‘clinical’?,"I have come across this term fairly often, where full/associate/assistant professors are referred to by the term ‘clinical’. Given that their departments had nothing to do with medicine, I thought the term referred to the second meaning of clinical:


  scientifically detached; strictly objective


Is this interpretation correct? If yes, isn’t such a branding offensive?
",Sheeba,https://academia.stackexchange.com/users/37947,"There can be clinical professors in fields other than medicine, though they may be labeled something else.  The definition of a ""clinical professor"" is not limited to medicine:  


  ""The prefix Clinical identifies appointments that primarily provide practical instruction and application of practical knowledge. On the Medical Campus, the title describes faculty whose primary activity is limited to clinical or public health practice and associated teaching. The duties, terms of appointment, and salaries (if any) of such persons are specified in the letter of appointment. In general, the applicable rank and any subsequent promotions should be determined by the relevant academic achievements, professional accomplishments, and demonstrated effectiveness of the appointee.""  (Boston University faculty handbook)


So, though I don't know much about engineering, I imagine that a professional from an engineering firm that specializes in a particular process could be hired as a clinical professor.  S/he would teach about the particular niche they occupy in the industry.
",ewormuth,https://academia.stackexchange.com/users/37649,http://academia.stackexchange.com/questions/49759/are-scientifically-detached-professors-referred-to-as-clinical,LIFE_ARTS,academia.stackexchange.com,1.0,0.6666666666666666,0.0,1.0,1.0,0.0,0.6666666666666666,0.6666666666666666,1.0,0.0,1.0,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,0.8888888888888888,1.0,0.8,0.0,0.0,0.0,1.0,"Is an independent professor of science called ""clinical professor""?","I often come across this semester. The formal Professor / Associate Professor / Assistant Professor here is called ""clinical professor"". Since their department is not related to medicine, I think this word refers to the second meaning of clinical:","There can be clinical professors in fields other than medicine, though they may be labeled something else.  The definition of a ""clinical professor"" is not limited to medicine:  


  ""The prefix Clinical identifies appointments that primarily provide practical instruction and application of practical knowledge. On the Medical Campus, the title describes faculty whose primary activity is limited to clinical or public health practice and associated teaching. The duties, terms of appointment, and salaries (if any) of such persons are specified in the letter of appointment. In general, the applicable rank and any subsequent promotions should be determined by the relevant academic achievements, professional accomplishments, and demonstrated effectiveness of the appointee.""  (Boston University faculty handbook)


So, though I don't know much about engineering, I imagine that a professional from an engineering firm that specializes in a particular process could be hired as a clinical professor.  S/he would teach about the particular niche they occupy in the industry.
"
4764,4764,7565,what is exactly the difference between the Selberg class and the set of Artin L-functions?,"The question is in the title: from what I read in the answer to another question, Artin L-functions are conjecturally cuspidal automorphic L-functions for some algebraic group that can be transfered to $GL_{n}$. On the other hand, elements of the Selberg class are widely believed to be (cuspidal?) automorphic L-functions for $GL_{n}$. So where exactly lies the difference between those two sets of L-functions?
Thanks in advance.
",Sylvain JULIEN,https://mathoverflow.net/users/13625,"As far as I know, the precise conjecture for what you are asking is:


  All the elements of the Selberg class that are not Artin L-functions
  are:
  
  
  motivic L-functions of dimension bigger than 0.
  transcendental L-functions
  


Note that Artin L-functions are the 0-dimensional motivic L-functions.

Also, transcendental L-function is an umbrella term for automorphic L-functions that are not motivic.
",Myshkin,https://mathoverflow.net/users/43108,http://mathoverflow.net/questions/207306,SCIENCE,mathoverflow.net,1.0,1.0,0.0,0.0,1.0,1.0,0.5,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,0.8333333333333334,1.0,0.8,0.0,0.0,0.0,1.0,What is the difference between Selberg class and Artin L-function set?,"Question in the title: according to what I read in the answer to another question, Artin L-functions are some creepy self-sustaining L-functions of algebraic groups that can be transferred to $GL {n} $. On the other hand, it is generally believed that Selberg elements are (creepy?) The automorphic L-function of $GL {n} $. So what's the difference between these two sets of L-functions?","As far as I know, the precise conjecture for what you are asking is:


  All the elements of the Selberg class that are not Artin L-functions
  are:
  
  
  motivic L-functions of dimension bigger than 0.
  transcendental L-functions
  


Note that Artin L-functions are the 0-dimensional motivic L-functions.

Also, transcendental L-function is an umbrella term for automorphic L-functions that are not motivic.
"
3521,3521,5614,"Illustrator, snap to guide","I'm attempting to place the end of a line segment at the intersection of a circle and a guide in Adobe Illustrator:



I'm expecting the end of the line to snap into place at the intersection, but with no luck. Smart Guides and Snap to Point are turned on.

Here is a short video of the problem: http://cl.ly/K3tr

I'm using this guide/tutorial in order to ""...connect a tangent line to a curved segment in order to create a smooth geometrically correct transition from a curve to a straight line..."" - Tangent Lines to Curved Segments

Is anyone familiar with this method that could shed some light on why it's not snapping?

Thank you!
",flackend,https://graphicdesign.stackexchange.com/users/7173,"I think it's just the poor performance of snapping. Heck, even smart guides are often ""off"" by a few pixels. 

If you click-drag on the end anchor point you'll have better luck with it snapping to the intersection. Snapping is often dependent upon the position of the cursor.

However, Smart Guides will never show that intersection. Honestly.... bug in Illustrator. Snapping/Smart Guides have been pretty bad the last few versions.
",Scott,https://graphicdesign.stackexchange.com/users/3270,http://graphicdesign.stackexchange.com/questions/10968/illustrator-snap-to-guide,LIFE_ARTS,graphicdesign.stackexchange.com,1.0,0.5555555555555556,0.0,1.0,1.0,1.0,0.7777777777777778,0.6666666666666666,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.8888888888888888,0.6666666666666666,1.0,1.0,0.9,0.3333333333333333,0.3333333333333333,1.0,0.8888888888888888,"Illustration, Press Guide","I'm attempting to place the end of a line segment at the intersection of a circle and a guide in Adobe Illustrator:



I'm expecting the end of the line to snap into place at the intersection, but with no luck. Smart Guides and Snap to Point are turned on.

Here is a short video of the problem: http://cl.ly/K3tr

I'm using this guide/tutorial in order to ""...connect a tangent line to a curved segment in order to create a smooth geometrically correct transition from a curve to a straight line..."" - Tangent Lines to Curved Segments

Is anyone familiar with this method that could shed some light on why it's not snapping?

Thank you!
","I think it's just the poor performance of snapping. Heck, even smart guides are often ""off"" by a few pixels. 

If you click-drag on the end anchor point you'll have better luck with it snapping to the intersection. Snapping is often dependent upon the position of the cursor.

However, Smart Guides will never show that intersection. Honestly.... bug in Illustrator. Snapping/Smart Guides have been pretty bad the last few versions.
"
1077,1077,1697,Device including RTC EEPROM and battery?,"I am currently designing an electronic board and i got a question:

Do you know if there is any device in which are integrated an RTC, an EEPROM and a battery? I heard about this type of device (i think it is called Time keeper) but I can't find any.

Thank you
",damien,https://electronics.stackexchange.com/users/13884,"There a few RTC modules out there, here is one option that uses the DS1307 (which has 56 bytes of EEPROM IIRC) and has an onboard battery:

Sparkfun RTC module

 

Another one here with 236 bytes of non-volatile memory (battery holder on underside):


",Oli Glaser,https://electronics.stackexchange.com/users/5372,http://electronics.stackexchange.com/questions/42777/device-including-rtc-eeprom-and-battery,SCIENCE,electronics.stackexchange.com,0.3333333333333333,0.6666666666666666,0.0,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,1.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,0.0,0.6666666666666666,Device includes RTC EEPROM and battery?,"I am currently designing an electronic board and i got a question:

Do you know if there is any device in which are integrated an RTC, an EEPROM and a battery? I heard about this type of device (i think it is called Time keeper) but I can't find any.

Thank you
","There a few RTC modules out there, here is one option that uses the DS1307 (which has 56 bytes of EEPROM IIRC) and has an onboard battery:

Sparkfun RTC module

 

Another one here with 236 bytes of non-volatile memory (battery holder on underside):


"
4131,4131,6595,Is lots of red juice normal when making sous-vide steak?,"So I made a 1lb hanger steak via sous-vide the other day and cooked it for 45 minutes at 130F.

After I seared in a cast iron pan, I took the meat off of the pan and let it sit for a few minutes and then sliced it up(against the grain) into smaller portions.

I noticed a lot of red juice in the plate as I was slicing it up but after I put it on a plate and it was sitting at the table, the meat almost ended up swimming in red juice.

When I order medium rare steak at a restaurant and it comes out pre-sliced, I don't usually notice this much red juice.

Is this normal?

UPDATE:

Found this great article explaining what was going on:
http://www.seriouseats.com/2009/12/how-to-have-juicy-meats-steaks-the-food-lab-the-importance-of-resting-grilling.html#continued

He has another article about sous vide ( http://www.seriouseats.com/2010/03/how-to-sous-vide-steak.html ) where he claims that you don't need to let the meat rest after searing. This is the one that originally led me to not need to rest the steak.

Looks like there is some resting that is required. Will post up with results next time I make some steak.
",alexpotato,https://cooking.stackexchange.com/users/7454,"Usually a steak at a restaurant is allowed to ""rest"" for 10 minutes before being served, perhaps that helps? Also, cooking in a normal method gives more opportunity for moisture to escape.

OK, I'm just winging it, I don't have a sous-vide set up yet.
",Ronald Pottol,https://cooking.stackexchange.com/users/721,http://cooking.stackexchange.com/questions/17804/is-lots-of-red-juice-normal-when-making-sous-vide-steak,LIFE_ARTS,cooking.stackexchange.com,1.0,0.7777777777777778,0.0,1.0,1.0,1.0,0.7777777777777778,0.7777777777777778,0.0,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,1.0,0.8888888888888888,0.6666666666666666,0.8888888888888888,0.8888888888888888,0.7333333333333333,0.0,0.0,1.0,1.0,Is a lot of red juice normal for steak?,"So I made a 1lb hanger steak via sous-vide the other day and cooked it for 45 minutes at 130F.

After I seared in a cast iron pan, I took the meat off of the pan and let it sit for a few minutes and then sliced it up(against the grain) into smaller portions.

I noticed a lot of red juice in the plate as I was slicing it up but after I put it on a plate and it was sitting at the table, the meat almost ended up swimming in red juice.

When I order medium rare steak at a restaurant and it comes out pre-sliced, I don't usually notice this much red juice.

Is this normal?

UPDATE:

Found this great article explaining what was going on:
http://www.seriouseats.com/2009/12/how-to-have-juicy-meats-steaks-the-food-lab-the-importance-of-resting-grilling.html#continued

He has another article about sous vide ( http://www.seriouseats.com/2010/03/how-to-sous-vide-steak.html ) where he claims that you don't need to let the meat rest after searing. This is the one that originally led me to not need to rest the steak.

Looks like there is some resting that is required. Will post up with results next time I make some steak.
","Usually a steak at a restaurant is allowed to ""rest"" for 10 minutes before being served, perhaps that helps? Also, cooking in a normal method gives more opportunity for moisture to escape.

OK, I'm just winging it, I don't have a sous-vide set up yet.
"
251,251,405,Unprotect a Word Document,"
  Possible Duplicate:
  Can&rsquo;t edit a specific document in Word 2007  


How do I remove the password protection (unprotect) on a Word document if I don't know the password? (i.e. The protection provided by Tools > Unprotect Document)
",Rob Wright,https://superuser.com/users/24927,"
Save the file in Rich text format RTF
Open the file with WordPad
Save the RTF file with a different name
Open the new RTF file with Word
Save the document as a word document
Delete the two rtf files

",bugtussle,https://superuser.com/users/21685,http://superuser.com/questions/96242,TECHNOLOGY,superuser.com,1.0,0.4444444444444444,0.0,1.0,1.0,1.0,0.7777777777777778,0.8888888888888888,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,0.8888888888888888,1.0,1.0,0.0,0.0,0.7777777777777778,Unprotect word documents,"
  Possible Duplicate:
  Can&rsquo;t edit a specific document in Word 2007  


How do I remove the password protection (unprotect) on a Word document if I don't know the password? (i.e. The protection provided by Tools > Unprotect Document)
","
Save the file in Rich text format RTF
Open the file with WordPad
Save the RTF file with a different name
Open the new RTF file with Word
Save the document as a word document
Delete the two rtf files

"
5730,5730,9077,"Heathrow Customs - ""Arrivals from the EU"" exit","At Heathrow, after collecting your baggage, there are three exits.


  Green - nothing to declare
  
  Red - something to declare (not sure of text)
  
  Blue - arrivals from the EU


What is the blue one for? Is it if you have something to declare, and have come from an EU country? I saw no signage to tell me when I was there last week.
",VictorySaber,https://travel.stackexchange.com/users/11354,"The blue channel is for travelers from the EU who have nothing to declare. If you have something to declare you should in any case go through the red channel.

The difference between travelers coming from the EU and other travelers is that some procedures like declaring cash are unnecessary and the limits, e.g. for alcohol, are much higher than when coming from outside the EU. You can basically import just about anything for your personal use. Other EU countries do not offer separate channels, however, and for the system to work it seems you would need some way to make sure that people coming from outside the EU do not simply sneak through the EU lane.

I don't have any particular insights into the reason the UK organized things in that way but the blue channel could be a way to sort out travelers that are less likely to be importing something illegally. Baggage tags from EU airports are marked with green stripes so people who go there by mistake or try to cheat (without being too clever about it) can still be spotted easily.

The only difference I could find between the UK and some other EU countries without separate channels is that in the UK, declaring cash is only mandatory if you come from outside the EU (it's EU law) whereas in France or Germany it's also mandatory if you come from another EU country. But it's not clear to me how this could explain the blue channel.
",Relaxed,https://travel.stackexchange.com/users/6669,http://travel.stackexchange.com/questions/30251/heathrow-customs-arrivals-from-the-eu-exit,CULTURE,travel.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,1.0,1.0,1.0,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,1.0,0.7777777777777778,1.0,1.0,0.6666666666666667,0.0,0.0,1.0,0.4444444444444444,Heathrow customs - export from EU,"At Heathrow, after collecting your baggage, there are three exits.


  Green - nothing to declare
  
  Red - something to declare (not sure of text)
  
  Blue - arrivals from the EU


What is the blue one for? Is it if you have something to declare, and have come from an EU country? I saw no signage to tell me when I was there last week.
","The blue channel is for travelers from the EU who have nothing to declare. If you have something to declare you should in any case go through the red channel.

The difference between travelers coming from the EU and other travelers is that some procedures like declaring cash are unnecessary and the limits, e.g. for alcohol, are much higher than when coming from outside the EU. You can basically import just about anything for your personal use. Other EU countries do not offer separate channels, however, and for the system to work it seems you would need some way to make sure that people coming from outside the EU do not simply sneak through the EU lane.

I don't have any particular insights into the reason the UK organized things in that way but the blue channel could be a way to sort out travelers that are less likely to be importing something illegally. Baggage tags from EU airports are marked with green stripes so people who go there by mistake or try to cheat (without being too clever about it) can still be spotted easily.

The only difference I could find between the UK and some other EU countries without separate channels is that in the UK, declaring cash is only mandatory if you come from outside the EU (it's EU law) whereas in France or Germany it's also mandatory if you come from another EU country. But it's not clear to me how this could explain the blue channel.
"
107,107,175,Access control Service and Azure Websites Could not load System.IdentityModel.Services,"I've created an ASP.NET MVC 4 app using visual studio 2012 RC on Windows 8 release preview. I downloaded and installed the WIF toolkit and used the ""Identity and Access"" option in the solution menu to add my Access Control Service metadata endpoint. Tested locally and all is well. When I deployed to my free azure website however I get the yellow screen saying


  ""Could not load file or assembly 'System.IdentityModel.Services,
  Version=4.0.0.0, Culture=neutral, PublicKeyToken=b77a5c561934e089' or
  one of its dependencies. The system cannot find the file specified.""


These assemblies aren't referenced in the project, so I added them, sent to output to the bin folder and redeployed. I then got a message about the assembly probably being tampered with. Does anyone know how to overcome this?

EDIT
Adding local causes this error


  Could not load file or assembly 'System.IdentityModel.Services' or one
  of its dependencies. Strong name signature could not be verified.  The
  assembly may have been tampered with, or it was delay signed but not
  fully signed with the correct private key. (Exception from HRESULT:
  0x80131045)


In the web config the module is deinfed as

&lt;system.webServer&gt;
    &lt;validation validateIntegratedModeConfiguration=""false"" /&gt;
    &lt;modules&gt;
      &lt;add name=""WSFederationAuthenticationModule"" type=""System.IdentityModel.Services.WSFederationAuthenticationModule, System.IdentityModel.Services, Version=4.0.0.0, Culture=neutral, PublicKeyToken=b77a5c561934e089"" preCondition=""managedHandler"" /&gt;
      &lt;add name=""SessionAuthenticationModule"" type=""System.IdentityModel.Services.SessionAuthenticationModule, System.IdentityModel.Services, Version=4.0.0.0, Culture=neutral, PublicKeyToken=b77a5c561934e089"" preCondition=""managedHandler"" /&gt;
    &lt;/modules&gt;
  &lt;/system.webServer&gt;


Thanks
",Dylan,https://stackoverflow.com/users/246970,"System.identityModel.Services is a .NET Framework 4.5 namespace with no .NET Framework 4.0 version. .NET Framework 4.5 is not supported on Windows Azure Web Sites.
",Neil Mackenzie,https://stackoverflow.com/users/1191223,http://stackoverflow.com/questions/11595684/access-control-service-and-azure-websites-could-not-load-system-identitymodel-se,STACKOVERFLOW,stackoverflow.com,0.6666666666666666,0.5555555555555556,0.0,0.5,0.6666666666666666,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.0,0.8888888888888888,0.8888888888888888,0.4444444444444444,0.8888888888888888,0.7777777777777778,0.8,0.0,0.0,1.0,0.8888888888888888,Access control service and azure website failed to load system.identitymodel.services,"I've created an ASP.NET MVC 4 app using visual studio 2012 RC on Windows 8 release preview. I downloaded and installed the WIF toolkit and used the ""Identity and Access"" option in the solution menu to add my Access Control Service metadata endpoint. Tested locally and all is well. When I deployed to my free azure website however I get the yellow screen saying


  ""Could not load file or assembly 'System.IdentityModel.Services,
  Version=4.0.0.0, Culture=neutral, PublicKeyToken=b77a5c561934e089' or
  one of its dependencies. The system cannot find the file specified.""


These assemblies aren't referenced in the project, so I added them, sent to output to the bin folder and redeployed. I then got a message about the assembly probably being tampered with. Does anyone know how to overcome this?

EDIT
Adding local causes this error


  Could not load file or assembly 'System.IdentityModel.Services' or one
  of its dependencies. Strong name signature could not be verified.  The
  assembly may have been tampered with, or it was delay signed but not
  fully signed with the correct private key. (Exception from HRESULT:
  0x80131045)


In the web config the module is deinfed as

&lt;system.webServer&gt;
    &lt;validation validateIntegratedModeConfiguration=""false"" /&gt;
    &lt;modules&gt;
      &lt;add name=""WSFederationAuthenticationModule"" type=""System.IdentityModel.Services.WSFederationAuthenticationModule, System.IdentityModel.Services, Version=4.0.0.0, Culture=neutral, PublicKeyToken=b77a5c561934e089"" preCondition=""managedHandler"" /&gt;
      &lt;add name=""SessionAuthenticationModule"" type=""System.IdentityModel.Services.SessionAuthenticationModule, System.IdentityModel.Services, Version=4.0.0.0, Culture=neutral, PublicKeyToken=b77a5c561934e089"" preCondition=""managedHandler"" /&gt;
    &lt;/modules&gt;
  &lt;/system.webServer&gt;


Thanks
",System.identitymodel.services is a. Net framework 4.5 namespace without. Netframework version 4.0. . net framework 4.5 is not supported on Microsoft azure sites.
5661,5661,8976,"How can I organise photos on a network storage device, and what software can help me?","I have a recently bought a NAS and am in the process of transferring my photo collection onto it. I probably have over 300GB of pictures (many in various RAW formats). At the moment these are just organized in “old fashioned” file structures but I have am hoping to improve this to a some sort of cross referenced tagging system. So far though I am running into a few problems and any help would be appreciated. I have tried using the following software:


Windows photo gallery - and this appears to rapidly retrieve photos from the NAS based on chose tag words. The main down side that I have found so far is that the windows camera codec does not yet support my S95 RAW files and so they are not visible. 
Picasa – this looks as though it might work well on a local drive (and certainly get good reviews) but I am finding it very slow when scanning the photo library on the NAS (even when left for a number of hours the scan in only approx. 5% complete!). I can live with a bit of a delay when using the NAS but this is unworkable - am I getting something wrong?
Various other photo viewers - Although they allow me to see my RAW files do not appear to support tagging and the development of a cross referenced library. 


I am also considering looking at getting Lightroom but don’t want to shell out the money only to find it is as slow as Picasa.

Finally, my ideal would be to have different layers of tags so for example I could tag all my pictures from the “Lake District” but then also have the option of sub dividing within this category based on the valley etc. Without different levels of tagging I risk winding up with an unwieldy list of tag words. I do not know if this is possible/normal but if anyone has any points about what software packages support this arrangement that would also be appreciated. 
",Colin,https://photo.stackexchange.com/users/7943,"For Linux users, I would recommend Digikam. http://www.digikam.org


works with NAS
Tag support is great.
Raw is supported. After having used it for a while, I'd say it is okay but not the best. (I don't like that I don't get instant preview.)

",Unapiedra,https://photo.stackexchange.com/users/7718,http://photo.stackexchange.com/questions/18792/how-can-i-organise-photos-on-a-network-storage-device-and-what-software-can-hel,LIFE_ARTS,photo.stackexchange.com,1.0,0.7777777777777778,0.3333333333333333,1.0,0.3333333333333333,0.0,0.6666666666666666,0.5555555555555556,0.6666666666666666,0.0,1.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.7777777777777778,0.8888888888888888,0.4444444444444444,1.0,0.8888888888888888,0.7333333333333333,0.0,0.0,0.3333333333333333,0.8888888888888888,How to organize photos on network storage devices and what software can help me?,"I have a recently bought a NAS and am in the process of transferring my photo collection onto it. I probably have over 300GB of pictures (many in various RAW formats). At the moment these are just organized in “old fashioned” file structures but I have am hoping to improve this to a some sort of cross referenced tagging system. So far though I am running into a few problems and any help would be appreciated. I have tried using the following software:


Windows photo gallery - and this appears to rapidly retrieve photos from the NAS based on chose tag words. The main down side that I have found so far is that the windows camera codec does not yet support my S95 RAW files and so they are not visible. 
Picasa – this looks as though it might work well on a local drive (and certainly get good reviews) but I am finding it very slow when scanning the photo library on the NAS (even when left for a number of hours the scan in only approx. 5% complete!). I can live with a bit of a delay when using the NAS but this is unworkable - am I getting something wrong?
Various other photo viewers - Although they allow me to see my RAW files do not appear to support tagging and the development of a cross referenced library. 


I am also considering looking at getting Lightroom but don’t want to shell out the money only to find it is as slow as Picasa.

Finally, my ideal would be to have different layers of tags so for example I could tag all my pictures from the “Lake District” but then also have the option of sub dividing within this category based on the valley etc. Without different levels of tagging I risk winding up with an unwieldy list of tag words. I do not know if this is possible/normal but if anyone has any points about what software packages support this arrangement that would also be appreciated. 
","For Linux users, I would recommend Digikam. http://www.digikam.org


works with NAS
Tag support is great.
Raw is supported. After having used it for a while, I'd say it is okay but not the best. (I don't like that I don't get instant preview.)

"
741,741,1176,Adding existing user to existing group and providing permissions,"can someone shed some light on this issue

I've set up and installed vsftpd. Created a user ftp-user and created a home directory, so they can log in, and just have access to drop their files here.


>> sudo useradd -d /home/ftp/ftp-user -m ftp-user


This works fine, user successfully logs in over ftp, uploads a file.

I now need to be able to access this ftp-user directory as another user say for example ubuntu. There is a script that runs as ubuntu, and I need to be able to access the directory to be able to grab the files and copy them across to other locations.

I tried to add ubuntu to the ftp-user group:


sudo usermod -a -G ftp-user ubuntu


Although, when trying: 


>> whoami
ubuntu
>> cd ftp-user/
>> -bash: cd ftp-user/: Permission denied


Hope someone has an idea - Cheers in advance!
",williamsowen,https://serverfault.com/users/81985,"New groups are only picked up when the user logs in. Log the ubuntu user out then in again.
",Iain,https://serverfault.com/users/9517,http://serverfault.com/questions/360767,TECHNOLOGY,serverfault.com,0.8888888888888888,0.4444444444444444,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.5555555555555556,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.9,1.0,0.0,0.6666666666666666,0.8888888888888888,Add existing users to existing groups and provide permissions,"can someone shed some light on this issue

I've set up and installed vsftpd. Created a user ftp-user and created a home directory, so they can log in, and just have access to drop their files here.


>> sudo useradd -d /home/ftp/ftp-user -m ftp-user


This works fine, user successfully logs in over ftp, uploads a file.

I now need to be able to access this ftp-user directory as another user say for example ubuntu. There is a script that runs as ubuntu, and I need to be able to access the directory to be able to grab the files and copy them across to other locations.

I tried to add ubuntu to the ftp-user group:


sudo usermod -a -G ftp-user ubuntu


Although, when trying: 


>> whoami
ubuntu
>> cd ftp-user/
>> -bash: cd ftp-user/: Permission denied


Hope someone has an idea - Cheers in advance!
","New groups are only picked up when the user logs in. Log the ubuntu user out then in again.
"
3948,3948,6300,Does the a gasoline or diesel engine appy fuel at high speeds when not pressing the pedal and more,"Let say I directly connect a small engine to my bicycle, and that I'm superman who can overcome any force.
Then I start cycling (using my legs...) - the engine starts to rotate, even though I haven't ""started it"" using the switch.

Does it mean that if I press the pedal (or whatever) of the engine, it will apply force? Either on a diesel or a gasoline engine.

Another question: Lets say I'm driving down a hill in a relatively high speed in a car, and I'm not pressing the gas pedal at all. Does the engine burn fuel at all, in both diesel and gas? If I (while in gear) turn off the engine, will something actually happen? If I would press the pedal after turning it off (while it still rotates) - will it apply force? (in both diesel and gas).

If, while driving, I disconnected the idler (i.e the engine won't apply any force if I'm not pressing the pedal at any RPM and pressing the clutch will take it to zero RPM) and press the brake until I get to a complete stop, will the engine ""stall""? If I'm doing it in a hill facing down, after releasing the brakes I'd accelerate and the engine would gain RPMs, will it be able to continue applying force?

Finally: What's the difference between a ""running engine"" and one thats not running, assuming both are rotating?

I'm sorry if I'm asking too much so if you would at least explain the principle I'd be very happy. Thank you!
",Mark Segal,https://mechanics.stackexchange.com/users/3112,"All EFI engines shut off the fuel injectors when the accelerator is released above a certain RPM or speed (varies by manufacturer). It's easier to detect on newer model cars with a digital instant fuel economy gauge where when cruising at 55 MPH and the accelerator pedal is released, the economy readout will shoot from 30 MPG to the highest number or the readout goes blank.

On an automatic transmission when the gear selector is placed in neutral at highway speed, the engine computer will allow the fuel injectors to fire again and actually raises the RPMs in anticipation of it being thrown into gear again. On a manual transmission when pressing in the clutch or placing gear selector in neutral, the engine RPMs will fall to idle where the engine computer will fire the injectors to maintain idle speed.

If you turn off the engine (with the key) while moving, the car will still keep moving, but you won't accelerate or maintain speed. If the engine is off, pressing the accelerator does nothing.
",alex,https://mechanics.stackexchange.com/users/3415,http://mechanics.stackexchange.com/questions/6612/does-the-a-gasoline-or-diesel-engine-appy-fuel-at-high-speeds-when-not-pressing,CULTURE,mechanics.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,0.0,1.0,1.0,0.4444444444444444,0.4444444444444444,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,1.0,0.0,0.7777777777777778,0.7777777777777778,0.4444444444444444,0.8888888888888888,0.8888888888888888,0.7333333333333333,0.0,0.0,1.0,1.0,"Whether the gasoline engine or diesel engine refuels at high speed without stepping on the pedal, etc","Let say I directly connect a small engine to my bicycle, and that I'm superman who can overcome any force.
Then I start cycling (using my legs...) - the engine starts to rotate, even though I haven't ""started it"" using the switch.

Does it mean that if I press the pedal (or whatever) of the engine, it will apply force? Either on a diesel or a gasoline engine.

Another question: Lets say I'm driving down a hill in a relatively high speed in a car, and I'm not pressing the gas pedal at all. Does the engine burn fuel at all, in both diesel and gas? If I (while in gear) turn off the engine, will something actually happen? If I would press the pedal after turning it off (while it still rotates) - will it apply force? (in both diesel and gas).

If, while driving, I disconnected the idler (i.e the engine won't apply any force if I'm not pressing the pedal at any RPM and pressing the clutch will take it to zero RPM) and press the brake until I get to a complete stop, will the engine ""stall""? If I'm doing it in a hill facing down, after releasing the brakes I'd accelerate and the engine would gain RPMs, will it be able to continue applying force?

Finally: What's the difference between a ""running engine"" and one thats not running, assuming both are rotating?

I'm sorry if I'm asking too much so if you would at least explain the principle I'd be very happy. Thank you!
","All EFI engines shut off the fuel injectors when the accelerator is released above a certain RPM or speed (varies by manufacturer). It's easier to detect on newer model cars with a digital instant fuel economy gauge where when cruising at 55 MPH and the accelerator pedal is released, the economy readout will shoot from 30 MPG to the highest number or the readout goes blank.

On an automatic transmission when the gear selector is placed in neutral at highway speed, the engine computer will allow the fuel injectors to fire again and actually raises the RPMs in anticipation of it being thrown into gear again. On a manual transmission when pressing in the clutch or placing gear selector in neutral, the engine RPMs will fall to idle where the engine computer will fire the injectors to maintain idle speed.

If you turn off the engine (with the key) while moving, the car will still keep moving, but you won't accelerate or maintain speed. If the engine is off, pressing the accelerator does nothing.
"
419,419,651,Why the sudden popularity of .io domains?,"I've noticed a number of new webapps and sites are being hosted at .io domains (the top-level domain for the British Indian Ocean Territories). A couple examples include:


Forecast.io
GitHub.io
Firepad.io


And the list goes on and on.

Is there any particular cause for the sudden popularity of .io domains?
",samthebrand,https://webmasters.stackexchange.com/users/13067,"I guess it's just because most people would not relate .io TLDs to British Indian Ocan Territories, but with input/output or whatever abbreviation seems reasonable for the specific domain.

The same thing is happening with .tv TLDs, which is for the island of Tuvalu normally, but is more commonly interpreted by people as an abbreviation for ""television"".
",alxs,https://webmasters.stackexchange.com/users/23655,http://webmasters.stackexchange.com/questions/47106/why-the-sudden-popularity-of-io-domains,TECHNOLOGY,webmasters.stackexchange.com,1.0,1.0,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.4444444444444444,0.4444444444444444,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.8,0.0,0.0,1.0,0.8888888888888888,Why is. IO domain suddenly popular?,"I've noticed a number of new webapps and sites are being hosted at .io domains (the top-level domain for the British Indian Ocean Territories). A couple examples include:


Forecast.io
GitHub.io
Firepad.io


And the list goes on and on.

Is there any particular cause for the sudden popularity of .io domains?
","I think it's just because most people don't associate. IO TLD with the British India OKAN region, but with input / output or any abbreviation that makes sense for a particular field."
2882,2882,4587,Is there a way to query Magento Database for part OR all of an unserialized string?,"I would like to know how to query a column for all or part of a string. I have created a module which uses data additional_information column from the Sales_Flat_Order_Payment table which I have been able to unserialize and display in a grid. However, when serching/filtering this column the user has to enter the full value which can be time consuming so I would like to filter using ANY value.

At the moment my filter is setup using strlen but I would like to know if there is a better way for me to do it please?

  protected function _paymentFilter($collection, $column)
    {
                case ""additional_information_column"":
                {

                    $this-&gt;getCollection()-&gt;getSelect()-&gt;where(
                        ""sfop.additional_information like ?""
                        , '%column"";s:'.strlen($value).':""%'.$value.'%');
                    break;
                }
    }


Any ideas are much appreciated...
",user1704524,https://magento.stackexchange.com/users/2157,"Unfortunately, no, you can't do this any better/efficiently than your current solution.  

The algorithm used to serialize a variable in PHP is proprietary to PHP.  MySQL (or the other RDMS) know nothing about it, so there's no query tools other than a raw string LIKE that work with the fields. 

In theory it would be possible (via object listeners) to save the serialized data into join tables, and then alter your grid collections to pull the data you want from that join table — but this approach is complicated, fraught with problems and would require testing/iterations to work out potential bugs.
",Alan Storm,https://magento.stackexchange.com/users/4,http://magento.stackexchange.com/questions/12696/is-there-a-way-to-query-magento-database-for-part-or-all-of-an-unserialized-stri,TECHNOLOGY,magento.stackexchange.com,0.8888888888888888,1.0,0.0,0.6666666666666666,1.0,0.6666666666666666,0.4444444444444444,0.3333333333333333,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,0.8888888888888888,0.8666666666666666,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.7777777777777778,Is there any way to query some or all of the strings in the Magento database that are not serialized?,"I would like to know how to query a column for all or part of a string. I have created a module which uses data additional_information column from the Sales_Flat_Order_Payment table which I have been able to unserialize and display in a grid. However, when serching/filtering this column the user has to enter the full value which can be time consuming so I would like to filter using ANY value.

At the moment my filter is setup using strlen but I would like to know if there is a better way for me to do it please?

  protected function _paymentFilter($collection, $column)
    {
                case ""additional_information_column"":
                {

                    $this-&gt;getCollection()-&gt;getSelect()-&gt;where(
                        ""sfop.additional_information like ?""
                        , '%column"";s:'.strlen($value).':""%'.$value.'%');
                    break;
                }
    }


Any ideas are much appreciated...
","Unfortunately, no, you can't do this any better/efficiently than your current solution.  

The algorithm used to serialize a variable in PHP is proprietary to PHP.  MySQL (or the other RDMS) know nothing about it, so there's no query tools other than a raw string LIKE that work with the fields. 

In theory it would be possible (via object listeners) to save the serialized data into join tables, and then alter your grid collections to pull the data you want from that join table — but this approach is complicated, fraught with problems and would require testing/iterations to work out potential bugs.
"
3251,3251,5182,Good/functional but can do better,"I'm looking for an aphorism communicating the thought that ""this works, but we can do better"". Some high-falutin language like Shakespeare or Blake would be ideal.
",numberwang,https://english.stackexchange.com/users/94532,"Normally people would just say either of


Not bad.
Acceptable.
Impressive.
Nice.
OK.
Great.


However, let me recompose some of Yogi Berra's:


Love is the most important thing, but your project/application is pretty good too.
Little league projects are great, because it keeps engineers/programmers like you off the main concourse.
You don't have to swing hard to hit a home run. Your application could just make it, with the right timing.


a'la Edgar Allen Poe:


Once upon a midnight dreary, while I pondered weak and weary. Nice app BTW.
Words have no power to impress the mind without the exquisite horror of their reality after deployment.
Science has not yet taught us if mediocrity is or is not the normality of intelligence.
I have great faith in tools like these. My lack of confidence in them, I call it.
After all most apps, my friend, are simply evolved out of fraud, fear, greed, imagination, and creativity.


a'la Hemmingway:


Never mistake an acceptance as excellence.
You do not have to like it just because it works.
Happiness in intelligent people are the rarest thing I know. You seem pretty happy with your app.
No app named horrid, has ever won the Nobel peace prize. We'll deploy it but expect lots of rotten eggs thrown at it.


Generic religious:


The world was created in six days, so was your app. It's good enough.
From the abundance of your heart, your app manifests.

",Blessed Geek,https://english.stackexchange.com/users/18962,http://english.stackexchange.com/questions/202584/good-functional-but-can-do-better,CULTURE,english.stackexchange.com,1.0,0.3333333333333333,0.5,1.0,0.5,0.0,0.5,0.6666666666666666,0.0,0.5,0.0,0.0,0.0,0.0,0.5,0.5,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.8333333333333334,1.0,1.0,0.9,0.0,0.0,0.0,0.6666666666666666,"Good / practical, but can do better","I am looking for a maxim to express the idea: ""it works, but we can do better."". A difficult language like Shakespeare or Blake is ideal.","Normally people would just say either of


Not bad.
Acceptable.
Impressive.
Nice.
OK.
Great.


However, let me recompose some of Yogi Berra's:


Love is the most important thing, but your project/application is pretty good too.
Little league projects are great, because it keeps engineers/programmers like you off the main concourse.
You don't have to swing hard to hit a home run. Your application could just make it, with the right timing.


a'la Edgar Allen Poe:


Once upon a midnight dreary, while I pondered weak and weary. Nice app BTW.
Words have no power to impress the mind without the exquisite horror of their reality after deployment.
Science has not yet taught us if mediocrity is or is not the normality of intelligence.
I have great faith in tools like these. My lack of confidence in them, I call it.
After all most apps, my friend, are simply evolved out of fraud, fear, greed, imagination, and creativity.


a'la Hemmingway:


Never mistake an acceptance as excellence.
You do not have to like it just because it works.
Happiness in intelligent people are the rarest thing I know. You seem pretty happy with your app.
No app named horrid, has ever won the Nobel peace prize. We'll deploy it but expect lots of rotten eggs thrown at it.


Generic religious:


The world was created in six days, so was your app. It's good enough.
From the abundance of your heart, your app manifests.

"
1936,1936,3088,Would Esther really have kept silent?,"In Esther 7:4 we read


  וְאִלּוּ לַעֲבָדִים וְלִשְׁפָחוֹת נִמְכַּרְנוּ, הֶחֱרַשְׁתִּי--כִּי אֵין הַצָּר שֹׁוֶה, בְּנֵזֶק הַמֶּלֶךְ ...
  
  ... But if we had been sold for bondmen and bondwomen, I had held my peace, for the adversary is not worthy that the king be endamaged.


Is this true? Had, in fact, the entire Jewish population been sold as slaves Esther would not have said a word about it? Is this simply hyperbole? How do we understand this? 
",none,https://judaism.stackexchange.com/users/1255,"I saw an answer in the Midrash Rabba (end of Pesichta 3). Esther was saying that she would be silent, since it could be that they deserved to be sold as slaves. After all, the Torah says in the Tochacha that if the Jews don't keep the Torah they will be sold as slaves.

However, there is no curse in the Torah that says the Jews will be all eradicated. Since she knew that this punishment wasn't ""coming from Hashem"" (kavyachol), she had to do whatever it took to get rid of it.
",Shmuel Brin,https://judaism.stackexchange.com/users/732,http://judaism.stackexchange.com/questions/14737/would-esther-really-have-kept-silent,CULTURE,judaism.stackexchange.com,0.8888888888888888,0.6666666666666666,0.3333333333333333,1.0,0.0,0.0,0.5,0.6666666666666666,0.0,0.0,1.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,1.0,Will Esther really remain silent?,"In Esther 7:4 we read


  וְאִלּוּ לַעֲבָדִים וְלִשְׁפָחוֹת נִמְכַּרְנוּ, הֶחֱרַשְׁתִּי--כִּי אֵין הַצָּר שֹׁוֶה, בְּנֵזֶק הַמֶּלֶךְ ...
  
  ... But if we had been sold for bondmen and bondwomen, I had held my peace, for the adversary is not worthy that the king be endamaged.


Is this true? Had, in fact, the entire Jewish population been sold as slaves Esther would not have said a word about it? Is this simply hyperbole? How do we understand this? 
","I saw an answer in the Midrash Rabba (end of Pesichta 3). Esther was saying that she would be silent, since it could be that they deserved to be sold as slaves. After all, the Torah says in the Tochacha that if the Jews don't keep the Torah they will be sold as slaves.

However, there is no curse in the Torah that says the Jews will be all eradicated. Since she knew that this punishment wasn't ""coming from Hashem"" (kavyachol), she had to do whatever it took to get rid of it.
"
4456,4456,7071,How to upload to WebDAV using a web browser?,"I've setup and configured webdav on debian using the following tutorial:

http://www.unix-tutorials.com/go.php?id=3711

I want to be able to download and upload files to the webdav share using a web browser. I can download and upload files to the webdav share if I mount it to my file system but we don't want the other people accessing this to have to do that. We want people to be able to go to the URL in their web browser, authenticate, and do everything, download, upload in their browser. 

When I go to the webdav URL in my browser and authenticate I'm given a list of the webdav share's contents and I can download the files but I don't see any way to upload files? How can I upload files to the webdav share using a web browser? 

Thanks in advance.
",caleban,https://serverfault.com/users/37321,"AFAIK there is no built-in support for webdav in browsers.  

I think there are applications and AJAX libraries you could run on your web server that would make webdav through the browser possible.  A quick google search for ajax webdav showed one interesting looking product (http://www.webdavsystem.com/ajaxfilebrowser).  I have never used this, just happened to look neat when I did a search related to this question.
",Zoredache,https://serverfault.com/users/984,http://serverfault.com/questions/197910,TECHNOLOGY,serverfault.com,0.8888888888888888,0.7777777777777778,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.8888888888888888,0.8888888888888888,0.5555555555555556,0.8888888888888888,0.8888888888888888,0.6666666666666667,0.6666666666666666,0.0,0.0,0.8888888888888888,How do I upload to WebDAV using a web browser?,"I've setup and configured webdav on debian using the following tutorial:

http://www.unix-tutorials.com/go.php?id=3711

I want to be able to download and upload files to the webdav share using a web browser. I can download and upload files to the webdav share if I mount it to my file system but we don't want the other people accessing this to have to do that. We want people to be able to go to the URL in their web browser, authenticate, and do everything, download, upload in their browser. 

When I go to the webdav URL in my browser and authenticate I'm given a list of the webdav share's contents and I can download the files but I don't see any way to upload files? How can I upload files to the webdav share using a web browser? 

Thanks in advance.
","AFAIK there is no built-in support for webdav in browsers.  

I think there are applications and AJAX libraries you could run on your web server that would make webdav through the browser possible.  A quick google search for ajax webdav showed one interesting looking product (http://www.webdavsystem.com/ajaxfilebrowser).  I have never used this, just happened to look neat when I did a search related to this question.
"
926,926,1463,Is copyediting good for an academic career?,"I have recently been involved in managing a special issue in a scientific journal. The chief-editor was somehow appreciative of my work and now wants me to join the journal's board as a copyeditor. I am puzzled by this request since I have no example of an academic being involved in such a task. Usually, being an editor (see Why become a journal editor?) involves more content evaluation.

Would my academic career take advantage of such a duty?
",marsei,https://academia.stackexchange.com/users/7767,"The only benefit you'll get as a copyeditor is clear: money (assuming he offered to pay you).

The downsides are numerous: it takes a lot of time, it will not be considered a plus to your CV (it's a technical job, not a scientific one)… none of the benefits from being a journal editor apply to a copyeditor.

Also, I don't know exactly what you did when you say “I have recently been involved in managing a special issue”, but if you were guest editor, offering you a copyeditor job is clearly not showing appreciation for your job as a scientist.
",F'x,https://academia.stackexchange.com/users/2700,http://academia.stackexchange.com/questions/13763/is-copyediting-good-for-an-academic-career,LIFE_ARTS,academia.stackexchange.com,0.8888888888888888,1.0,1.0,0.0,0.0,0.0,0.6666666666666666,0.7777777777777778,0.3333333333333333,0.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,0.3333333333333333,1.0,Is copywriter good for academic career?,"I recently participated in the management of a special issue of a scientific journal. The editor in chief somehow appreciated my work and now wants me to join the magazine board as a copywriter. I am confused about this requirement because I don't have an example of scholars participating in this work. Usually, to be an editor (see why to be a journal editor?) Involve more content assessment.","The only benefit you'll get as a copyeditor is clear: money (assuming he offered to pay you).

The downsides are numerous: it takes a lot of time, it will not be considered a plus to your CV (it's a technical job, not a scientific one)… none of the benefits from being a journal editor apply to a copyeditor.

Also, I don't know exactly what you did when you say “I have recently been involved in managing a special issue”, but if you were guest editor, offering you a copyeditor job is clearly not showing appreciation for your job as a scientist.
"
5160,5160,8201,How to convert particles to mesh,"I need to convert a Particle System to a mesh object, so I can export it to Unity 3D. How could I do this?
",kholyphoenix1,https://blender.stackexchange.com/users/10890,"This is pretty easy to do for hair particles. In Blender, particles are ""stored"" in a Modifier, which means it can be applied like any other; This only works for hair particles, for obvious reasons.

To convert your Particles, go to the Properties editor and navigate to the Modifiers tab; Here, you'll find all modifiers applied to the selected object, including the Particle System modifier. You can then press Convert to convert your particles into a mesh.


",someonewithpc,https://blender.stackexchange.com/users/3078,http://blender.stackexchange.com/questions/24274/how-to-convert-particles-to-mesh,TECHNOLOGY,blender.stackexchange.com,0.7777777777777778,0.8888888888888888,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.3333333333333333,1.0,How to convert particles to meshes,I need to convert the particle system to a mesh object in order to export it to unity 3D. How can I do this?,"This is pretty easy to do for hair particles. In Blender, particles are ""stored"" in a Modifier, which means it can be applied like any other; This only works for hair particles, for obvious reasons.

To convert your Particles, go to the Properties editor and navigate to the Modifiers tab; Here, you'll find all modifiers applied to the selected object, including the Particle System modifier. You can then press Convert to convert your particles into a mesh.


"
704,704,1113,What are the best tips for saving money as a university student?,"What are the best tips for saving money as a university student?

I will be attending university this coming semester and am planning on maintaining a sustainable financial situation right now, but would like any good tips or suggestions to saving money as a student.
",JFW,https://money.stackexchange.com/users/1408,"Try to cash flow as much as you can. You can work and go to school, if you replace playing beer pong with a job you'll be in a lot better off at graduation, grade wise and debt wise.

Make a budget, for each month and for each semester, plan cut cost accordingly.

Used books, sometimes even the next to recent version.

Read this book for more info Debt-Free U: How I Paid for an Outstanding College Education Without Loans, Scholarships, or Mooching off My Parents 
",Move More Comments Link To Top,https://money.stackexchange.com/users/2152,http://money.stackexchange.com/questions/6455/what-are-the-best-tips-for-saving-money-as-a-university-student,LIFE_ARTS,money.stackexchange.com,1.0,1.0,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.0,1.0,0.8888888888888888,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.6666666666666666,0.3333333333333333,0.0,0.8888888888888888,"As a college student, what is the best way to save money?","What are the best tips for saving money as a university student?

I will be attending university this coming semester and am planning on maintaining a sustainable financial situation right now, but would like any good tips or suggestions to saving money as a student.
","Try to cash flow as much as you can. You can work and go to school, if you replace playing beer pong with a job you'll be in a lot better off at graduation, grade wise and debt wise.

Make a budget, for each month and for each semester, plan cut cost accordingly.

Used books, sometimes even the next to recent version.

Read this book for more info Debt-Free U: How I Paid for an Outstanding College Education Without Loans, Scholarships, or Mooching off My Parents 
"
4847,4847,7715,Why are two eigen-state-kets with different eigenvalues orthogonal?,"The operators $J_1^2$, $J_2^2$, $J_{1z}$, and $J_{2z}$ are mutually commuting operators. Likewise, $J_1^2$, $J_2^2$, $J^2$, and $J_z$ are mutually commuting operators.  The two groups are incompatible, and the simultaneous eigenkets along with their eigenvalues are given by:

${J_1}^2 \left|j_1,j_2;m_1,m_2\right&gt; = j_1 \left(j_1+1\right) \hbar^2 \left|j_1,j_2;m_1,m_2\right&gt;$
${J_2}^2 \left|j_1,j_2;m_1,m_2\right&gt; = j_2 \left(j_2+1\right) \hbar^2 \left|j_1,j_2;m_1,m_2\right&gt;$
$J_{1z} \left|j_1,j_2;m_1,m_2\right&gt; = m_1 \hbar \left|j_1,j_2;m_1,m_2\right&gt;$
$J_{2z} \left|j_1,j_2;m_1,m_2\right&gt; = m_2 \hbar \left|j_1,j_2;m_1,m_2\right&gt;$

and

${J_1}^2 \left|j_1,j_2;j,m\right&gt; = j_1 \left(j_1+1\right) \hbar^2 \left|j_1,j_2;j,m\right&gt;$
${J_2}^2 \left|j_1,j_2;j,m\right&gt; = j_2 \left(j_2+1\right) \hbar^2 \left|j_1,j_2;j,m\right&gt;$
$J^2 \left|j_1,j_2;j,m\right&gt; = j \left(j+1\right) \hbar^2 \left|j_1,j_2;j,m\right&gt;$
$J_z \left|j_1,j_2;j,m\right&gt; = m \hbar \left|j_1,j_2;j,m\right&gt;$

I read that each set of eigenkets are mutually orthogonal [1] (for eigenkets corresponding to different sets of eigenvalues).  This is what I don't understand.  In principle it makes sense, but when I plug in numbers I don't get zero for the inner product.  For example take the first eigenket: $\left|j_1,j_2;m_1,m_2\right&gt;$.  If I choose different eigenvalues for this eigenket (e.g. let $j_1 = 0$ and then let $j_1 = 1$) I get the following:

for $j_1 = 0$ I can have:
$\left|0,j_2;0,m_2\right&gt;$

for $j_1 = 1$ I can have any of the following, since $\left|m_1\right| \leq j_1$:
$\left|1,j_2;-1,m_2\right&gt;$
$\left|1,j_2;0,m_2\right&gt;$
$\left|1,j_2;1,m_2\right&gt;$  

If I take the inner-product of the $j_1 = 0$ eigenket with any of the $j_1 = 1$ eigenkets I do not get zero, e.g.:

$\left&lt;0,j_2;0,m_2 \mid 1,j_2;-1,m_2\right&gt; = {j_2}^2+{m_2}^2$  

which is non-zero unless $j_2 = 0$.  

What am I misunderstanding here? How do you show that eigenkets with different eigenvalues are orthogonal?
",okj,https://physics.stackexchange.com/users/3597,"your line $\left&lt;0,j_2;0,m_2 \mid 1,j_2;-1,m_2\right&gt; = {j_2}^2+{m_2}^2$ is making an assumption about what an inner product must look like. A technical way to express your problem is to note that the sequence of eigenvalues identify an element in a tensor product of vector spaces, not a direct sum. If it was a direct sum, your sum of squares would be right, but it isn't.

Luboš's Answer is completely right, enough so that I upvoted it because he needs all the rep he can get, but it looks like it needs you to know what you're doing already for you to understand it. When you use objects like $\left|j_1,j_2;m_1,m_2\right&gt;$ to represent a state, you implicitly claim that the operators that have the eigenvalues $j_1,j_2;m_1,m_2$ are self-adjoint and mutually commutative. In elementary terms, we can take this to define the inner product on the Hilbert space. We don't know what the inner product is until we've defined it. If the eigenvalues are different, the inner product is defined to be $0$, if the eigenvalues are the same, the inner product is defined to be $1$.

As Luboš says, all the lines above your first introduction of a bra are only about operators acting on a vector space, you haven't got a Hilbert space until you've defined an inner product (and more than that, closure in the norm). Once you've defined an inner product, $(\left|U\right&gt;,\left|V\right&gt;)$, you can define a bra as the object that acts on a vector to get this value, $\left&lt;U \mid V\right&gt;=(\left|U\right&gt;,\left|V\right&gt;)$. There's a theorem that says we can do this if we're properly careful, http://en.wikipedia.org/wiki/Riesz_representation_theorem.
",Peter Morgan,https://physics.stackexchange.com/users/1588,http://physics.stackexchange.com/questions/10426/why-are-two-eigen-state-kets-with-different-eigenvalues-orthogonal,SCIENCE,physics.stackexchange.com,0.3333333333333333,0.8333333333333334,0.0,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.8333333333333334,0.6666666666666666,0.6666666666666666,0.8333333333333334,1.0,0.7,0.0,0.0,1.0,1.0,Why are two eigenstates kets with different eigenvalues orthogonal?,"The operators $J_1^2$, $J_2^2$, $J_{1z}$, and $J_{2z}$ are mutually commuting operators. Likewise, $J_1^2$, $J_2^2$, $J^2$, and $J_z$ are mutually commuting operators.  The two groups are incompatible, and the simultaneous eigenkets along with their eigenvalues are given by:

${J_1}^2 \left|j_1,j_2;m_1,m_2\right&gt; = j_1 \left(j_1+1\right) \hbar^2 \left|j_1,j_2;m_1,m_2\right&gt;$
${J_2}^2 \left|j_1,j_2;m_1,m_2\right&gt; = j_2 \left(j_2+1\right) \hbar^2 \left|j_1,j_2;m_1,m_2\right&gt;$
$J_{1z} \left|j_1,j_2;m_1,m_2\right&gt; = m_1 \hbar \left|j_1,j_2;m_1,m_2\right&gt;$
$J_{2z} \left|j_1,j_2;m_1,m_2\right&gt; = m_2 \hbar \left|j_1,j_2;m_1,m_2\right&gt;$

and

${J_1}^2 \left|j_1,j_2;j,m\right&gt; = j_1 \left(j_1+1\right) \hbar^2 \left|j_1,j_2;j,m\right&gt;$
${J_2}^2 \left|j_1,j_2;j,m\right&gt; = j_2 \left(j_2+1\right) \hbar^2 \left|j_1,j_2;j,m\right&gt;$
$J^2 \left|j_1,j_2;j,m\right&gt; = j \left(j+1\right) \hbar^2 \left|j_1,j_2;j,m\right&gt;$
$J_z \left|j_1,j_2;j,m\right&gt; = m \hbar \left|j_1,j_2;j,m\right&gt;$

I read that each set of eigenkets are mutually orthogonal [1] (for eigenkets corresponding to different sets of eigenvalues).  This is what I don't understand.  In principle it makes sense, but when I plug in numbers I don't get zero for the inner product.  For example take the first eigenket: $\left|j_1,j_2;m_1,m_2\right&gt;$.  If I choose different eigenvalues for this eigenket (e.g. let $j_1 = 0$ and then let $j_1 = 1$) I get the following:

for $j_1 = 0$ I can have:
$\left|0,j_2;0,m_2\right&gt;$

for $j_1 = 1$ I can have any of the following, since $\left|m_1\right| \leq j_1$:
$\left|1,j_2;-1,m_2\right&gt;$
$\left|1,j_2;0,m_2\right&gt;$
$\left|1,j_2;1,m_2\right&gt;$  

If I take the inner-product of the $j_1 = 0$ eigenket with any of the $j_1 = 1$ eigenkets I do not get zero, e.g.:

$\left&lt;0,j_2;0,m_2 \mid 1,j_2;-1,m_2\right&gt; = {j_2}^2+{m_2}^2$  

which is non-zero unless $j_2 = 0$.  

What am I misunderstanding here? How do you show that eigenkets with different eigenvalues are orthogonal?
","your line $\left&lt;0,j_2;0,m_2 \mid 1,j_2;-1,m_2\right&gt; = {j_2}^2+{m_2}^2$ is making an assumption about what an inner product must look like. A technical way to express your problem is to note that the sequence of eigenvalues identify an element in a tensor product of vector spaces, not a direct sum. If it was a direct sum, your sum of squares would be right, but it isn't.

Luboš's Answer is completely right, enough so that I upvoted it because he needs all the rep he can get, but it looks like it needs you to know what you're doing already for you to understand it. When you use objects like $\left|j_1,j_2;m_1,m_2\right&gt;$ to represent a state, you implicitly claim that the operators that have the eigenvalues $j_1,j_2;m_1,m_2$ are self-adjoint and mutually commutative. In elementary terms, we can take this to define the inner product on the Hilbert space. We don't know what the inner product is until we've defined it. If the eigenvalues are different, the inner product is defined to be $0$, if the eigenvalues are the same, the inner product is defined to be $1$.

As Luboš says, all the lines above your first introduction of a bra are only about operators acting on a vector space, you haven't got a Hilbert space until you've defined an inner product (and more than that, closure in the norm). Once you've defined an inner product, $(\left|U\right&gt;,\left|V\right&gt;)$, you can define a bra as the object that acts on a vector to get this value, $\left&lt;U \mid V\right&gt;=(\left|U\right&gt;,\left|V\right&gt;)$. There's a theorem that says we can do this if we're properly careful, http://en.wikipedia.org/wiki/Riesz_representation_theorem.
"
5444,5444,8642,Is there a way to read the columns in a shapefile / layer without converting it first to an MDB file?,"My shapefile has a number of fields, like roadname, and street number.  Is there a way to get at these without converting the shapefile first into a featureclass (mdb)?  Sometimes the conversion is a time consuming operation.

I'm using ArcEngine 10 C# with VS2010
",patrick,https://gis.stackexchange.com/users/733,"To just see that other fields without caring about the geometry data, you can just open the dbf-file in any Excel, open office or something else reading dbf-files. 

Just be careful not to add or remove any rows, since that will corrupt the shapefile. 

/Nicklas
",Nicklas Avén,https://gis.stackexchange.com/users/960,http://gis.stackexchange.com/questions/4619/is-there-a-way-to-read-the-columns-in-a-shapefile-layer-without-converting-it,TECHNOLOGY,gis.stackexchange.com,1.0,0.7777777777777778,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.0,0.0,0.8888888888888888,Is there a way to read a column in the ShapeFile / layer without first converting it to an mdb file?,"My ShapeFile has many fields, such as roadname and street number. Is there a way to implement these features without first converting shapefiles to feature classes (MDBs)? Sometimes conversion is a time-consuming operation.","To view other fields without caring about geometry data, just open the DBF file in any excel, open office or other file that reads the DBF file."
1244,1244,1955,"cURL is unable to use client certificate , in local server","I set up a local server using XAMPP. I have two php scripts , a sender and a receiver. I am trying to send an XML file from the sender to the receiver using HTTP over SSL (HTTPS).

I created a self signed certificate , i configured XAMPP and i use this code on my sender :

&lt;?php
  /*
   * XML Sender/Client.
   */
  // Get our XML. You can declare it here or even load a file.


  $xml = file_get_contents(""data.xml"");

  // We send XML via CURL using POST with a http header of text/xml.
  $ch = curl_init();

  //curl_setopt($ch, CURLOPT_SSLVERSION,3);

  curl_setopt($ch, CURLOPT_SSL_VERIFYPEER, true);
  curl_setopt($ch, CURLOPT_SSL_VERIFYHOST, 2);

  curl_setopt($ch, CURLOPT_CAINFO,  getcwd().'ipm.crt');
  curl_setopt($ch, CURLOPT_SSLCERT, getcwd().'ipm.pem');

  curl_setopt($ch, CURLOPT_SSLCERTPASSWD,'pass');

  //i use this line only for debugging through fiddler. Must delete after done with debugging.
  curl_setopt($ch, CURLOPT_PROXY, '127.0.0.1:8888');

  // set URL and other appropriate options
  curl_setopt($ch, CURLOPT_URL, ""https://ipv4.fiddler/iPM/receiver.php"");
  curl_setopt($ch, CURLOPT_HTTPHEADER, array('Content-Type: text/xml'));
  curl_setopt($ch, CURLOPT_HEADER, 0);
  curl_setopt($ch, CURLOPT_POST, 1);
  curl_setopt($ch, CURLOPT_POSTFIELDS, $xml);
  curl_setopt($ch, CURLOPT_FOLLOWLOCATION, 0);
  curl_setopt($ch, CURLOPT_REFERER, 'https://ipv4.fiddler/iPM/receiver.php');
  curl_setopt($ch, CURLOPT_RETURNTRANSFER, 1);
  $ch_result = curl_exec($ch);
  echo ""Result = "".$ch_result;

  echo 'Curl error: ' . curl_error($ch);

  curl_close($ch);
  // Print CURL result.
?&gt;


However i always get this error : Curl error: unable to use client certificate (no key found or wrong pass phrase?)

What can i possibly do wrong? The passphrase IS the word pass .

I created my .crt by doing :

openssl req -config openssl.cnf -new -out ipm.csr -keyout ipm.pem

openssl rsa -in ipm.pem -out ipm.key

openssl x509 -in ipm.csr -out ipm.crt -req -signkey ipm.key -days 365


I dont want to put the SSL_VERIFYPEER and SSL_VERIFYHOST to false.
",donparalias,https://stackoverflow.com/users/1372498,"The key must be a filename, not a passphrase.
",Rygu,https://stackoverflow.com/users/217782,http://stackoverflow.com/questions/14470225/curl-is-unable-to-use-client-certificate-in-local-server,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.4444444444444444,0.0,1.0,0.6666666666666666,1.0,0.4444444444444444,0.4444444444444444,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,1.0,0.0,0.5555555555555556,1.0,0.5555555555555556,1.0,1.0,0.8666666666666666,0.3333333333333333,0.0,0.6666666666666666,1.0,Curl cannot use client certificate in local server,"I set up a local server using XAMPP. I have two php scripts , a sender and a receiver. I am trying to send an XML file from the sender to the receiver using HTTP over SSL (HTTPS).

I created a self signed certificate , i configured XAMPP and i use this code on my sender :

&lt;?php
  /*
   * XML Sender/Client.
   */
  // Get our XML. You can declare it here or even load a file.


  $xml = file_get_contents(""data.xml"");

  // We send XML via CURL using POST with a http header of text/xml.
  $ch = curl_init();

  //curl_setopt($ch, CURLOPT_SSLVERSION,3);

  curl_setopt($ch, CURLOPT_SSL_VERIFYPEER, true);
  curl_setopt($ch, CURLOPT_SSL_VERIFYHOST, 2);

  curl_setopt($ch, CURLOPT_CAINFO,  getcwd().'ipm.crt');
  curl_setopt($ch, CURLOPT_SSLCERT, getcwd().'ipm.pem');

  curl_setopt($ch, CURLOPT_SSLCERTPASSWD,'pass');

  //i use this line only for debugging through fiddler. Must delete after done with debugging.
  curl_setopt($ch, CURLOPT_PROXY, '127.0.0.1:8888');

  // set URL and other appropriate options
  curl_setopt($ch, CURLOPT_URL, ""https://ipv4.fiddler/iPM/receiver.php"");
  curl_setopt($ch, CURLOPT_HTTPHEADER, array('Content-Type: text/xml'));
  curl_setopt($ch, CURLOPT_HEADER, 0);
  curl_setopt($ch, CURLOPT_POST, 1);
  curl_setopt($ch, CURLOPT_POSTFIELDS, $xml);
  curl_setopt($ch, CURLOPT_FOLLOWLOCATION, 0);
  curl_setopt($ch, CURLOPT_REFERER, 'https://ipv4.fiddler/iPM/receiver.php');
  curl_setopt($ch, CURLOPT_RETURNTRANSFER, 1);
  $ch_result = curl_exec($ch);
  echo ""Result = "".$ch_result;

  echo 'Curl error: ' . curl_error($ch);

  curl_close($ch);
  // Print CURL result.
?&gt;


However i always get this error : Curl error: unable to use client certificate (no key found or wrong pass phrase?)

What can i possibly do wrong? The passphrase IS the word pass .

I created my .crt by doing :

openssl req -config openssl.cnf -new -out ipm.csr -keyout ipm.pem

openssl rsa -in ipm.pem -out ipm.key

openssl x509 -in ipm.csr -out ipm.crt -req -signkey ipm.key -days 365


I dont want to put the SSL_VERIFYPEER and SSL_VERIFYHOST to false.
","The key must be a filename, not a passphrase.
"
4940,4940,7866,Representation of negative integers,"Does ISO-Prolog have any prescriptions / recommendations
 regarding the representation of negative integers and operations on them? 2's complement, maybe? 

Asking as a programmer/user: Are there any assumptions I can safely make when performing bit-level operations on negative integers?
",repeat,https://stackoverflow.com/users/4609915,"Strictly speaking these are two different questions:


Actual physical representation: this isn't visible at the Prolog level, and therefore the standard quite rightly has nothing to say about it.  Note that many Prolog systems have two or more internal representations (e.g. two's complement fixed size and sign+magnitude bignums) but present a single integer type to the programmer.
Results of bitwise operations: while the standard defines these operations, it leaves much of their behaviour implementation defined.  This is a consequence of (a) not having a way to specify the width of a bit pattern, and (b) not committing to a specific mapping between negative numbers and bit patterns.


This not only means that all bitwise operations on negative numbers are officially not portable, but also has the curious effect that the result of bitwise negation is totally implementation-defined (even for positive arguments):  Y is \1 could legally give -2, 268435454, 2147483646, 9223372036854775806, etc. All you know is that negating twice returns the original number.

In practice, fortunately, there seems to be a consensus towards ""The bitwise arithmetic operations behave as if operating on an unlimited length two's complement representation"".
",jschimpf,https://stackoverflow.com/users/2353967,http://stackoverflow.com/questions/30210801/representation-of-negative-integers,STACKOVERFLOW,stackoverflow.com,0.8333333333333334,0.3333333333333333,0.0,0.0,1.0,1.0,0.6666666666666666,0.5,1.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.9,0.0,0.0,1.0,1.0,Representation of negative integers,"Does ISO-Prolog have any prescriptions / recommendations
 regarding the representation of negative integers and operations on them? 2's complement, maybe? 

Asking as a programmer/user: Are there any assumptions I can safely make when performing bit-level operations on negative integers?
","Strictly speaking these are two different questions:


Actual physical representation: this isn't visible at the Prolog level, and therefore the standard quite rightly has nothing to say about it.  Note that many Prolog systems have two or more internal representations (e.g. two's complement fixed size and sign+magnitude bignums) but present a single integer type to the programmer.
Results of bitwise operations: while the standard defines these operations, it leaves much of their behaviour implementation defined.  This is a consequence of (a) not having a way to specify the width of a bit pattern, and (b) not committing to a specific mapping between negative numbers and bit patterns.


This not only means that all bitwise operations on negative numbers are officially not portable, but also has the curious effect that the result of bitwise negation is totally implementation-defined (even for positive arguments):  Y is \1 could legally give -2, 268435454, 2147483646, 9223372036854775806, etc. All you know is that negating twice returns the original number.

In practice, fortunately, there seems to be a consensus towards ""The bitwise arithmetic operations behave as if operating on an unlimited length two's complement representation"".
"
2879,2879,4583,Can a PC have more than one Default Gateway?,"I know that a PC can have multiple network adapters each of which with different network identifiers (IP,MAC etc.). 

My question is, can a certain PC have more than one active default gateway? And if so, how does the PC (or better say the OS) knows to what adapter use for any given packet?
",user4537,https://serverfault.com/users/106155,"On Windows (at least Vista), having multiple default routes on the same interface with different metrics is fine.  Windows will automatically switch to the route with the next highest metric if the lower metric router goes down.  If there are multiple default routes with the same metric, Windows randomly selects one to use.

This allows you to have redundant routers without configuring failover on the routers.

On Linux, this does not work.  You can have multiple default routes with different metrics, but currently the Linux kernel ignores the metric value.  If the default router with the lowest metric disappears, traffic will not flow.
",JPW,https://serverfault.com/users/129119,http://serverfault.com/questions/347032,TECHNOLOGY,serverfault.com,0.8888888888888888,0.5555555555555556,0.0,1.0,1.0,1.0,0.6666666666666666,0.7777777777777778,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.3333333333333333,0.0,0.6666666666666666,0.7777777777777778,Can a computer have multiple default gateways?,"I know that a PC can have multiple network adapters each of which with different network identifiers (IP,MAC etc.). 

My question is, can a certain PC have more than one active default gateway? And if so, how does the PC (or better say the OS) knows to what adapter use for any given packet?
","On Windows (at least Vista), having multiple default routes on the same interface with different metrics is fine.  Windows will automatically switch to the route with the next highest metric if the lower metric router goes down.  If there are multiple default routes with the same metric, Windows randomly selects one to use.

This allows you to have redundant routers without configuring failover on the routers.

On Linux, this does not work.  You can have multiple default routes with different metrics, but currently the Linux kernel ignores the metric value.  If the default router with the lowest metric disappears, traffic will not flow.
"
3376,3376,5384,Making Simple IF Statements Shorter,"If we assume we have this little snippet of code:

string str = ""checked"";
bool test1;

if (str == ""checked"")
{
    test1 = true;
}
else
{
    test1 = false;
}


Is it bad practice to change a simple statement like this to the following?:

bool test2 = (str == ""checked"");


Because they work exactly the same, and work as required, so I can't imagine how it would be. However, as a young, inexperienced programmer I am not aware of whether such a thing is frowned upon or not. Can anyone tell me, if this is NOT ok, why not?

The following test program:

using System;

public class Test
{

    public static void Main()
    {
        string str = ""checked"";

        bool test1;

        if (str == ""checked"")
        {
            test1 = true;
        }
        else
        {
            test1 = false;
        }

        bool test2 = (str == ""checked"");

        bool test3 = (str != ""checked"");

        Console.WriteLine(test1.ToString());
        Console.WriteLine(test2.ToString());
        Console.WriteLine(test3.ToString());
    }
}


Outputs:

True
True
False


Any insight etc is appreciated.
",Felix Weir,https://programmers.stackexchange.com/users/81895,"
  Is it bad practice to change a simple statement like this to the following?:


bool test2 = (str == ""checked"");


No, it's good practice. To me, the longer code:

if (str == ""checked"")
{  
    test1 = true;
}
else
{
    test1 = false;
} 


indicates that the programmer doesn't understand Boolean expressions.  The shorter form is much clearer.  Similarly, don't write:

if (boolean-expression) {
    return true;
} else {
    return false;
}


Just write return boolean-expression;
",kevin cline,https://programmers.stackexchange.com/users/16929,http://programmers.stackexchange.com/questions/199939/making-simple-if-statements-shorter,TECHNOLOGY,programmers.stackexchange.com,1.0,0.3333333333333333,0.0,1.0,1.0,1.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,0.0,1.0,Simplify if statement,"If we assume we have this little snippet of code:

string str = ""checked"";
bool test1;

if (str == ""checked"")
{
    test1 = true;
}
else
{
    test1 = false;
}


Is it bad practice to change a simple statement like this to the following?:

bool test2 = (str == ""checked"");


Because they work exactly the same, and work as required, so I can't imagine how it would be. However, as a young, inexperienced programmer I am not aware of whether such a thing is frowned upon or not. Can anyone tell me, if this is NOT ok, why not?

The following test program:

using System;

public class Test
{

    public static void Main()
    {
        string str = ""checked"";

        bool test1;

        if (str == ""checked"")
        {
            test1 = true;
        }
        else
        {
            test1 = false;
        }

        bool test2 = (str == ""checked"");

        bool test3 = (str != ""checked"");

        Console.WriteLine(test1.ToString());
        Console.WriteLine(test2.ToString());
        Console.WriteLine(test3.ToString());
    }
}


Outputs:

True
True
False


Any insight etc is appreciated.
","
  Is it bad practice to change a simple statement like this to the following?:


bool test2 = (str == ""checked"");


No, it's good practice. To me, the longer code:

if (str == ""checked"")
{  
    test1 = true;
}
else
{
    test1 = false;
} 


indicates that the programmer doesn't understand Boolean expressions.  The shorter form is much clearer.  Similarly, don't write:

if (boolean-expression) {
    return true;
} else {
    return false;
}


Just write return boolean-expression;
"
2385,2385,3805,"cURL is unable to use client certificate , in local server","I set up a local server using XAMPP. I have two php scripts , a sender and a receiver. I am trying to send an XML file from the sender to the receiver using HTTP over SSL (HTTPS).

I created a self signed certificate , i configured XAMPP and i use this code on my sender :

&lt;?php
  /*
   * XML Sender/Client.
   */
  // Get our XML. You can declare it here or even load a file.


  $xml = file_get_contents(""data.xml"");

  // We send XML via CURL using POST with a http header of text/xml.
  $ch = curl_init();

  //curl_setopt($ch, CURLOPT_SSLVERSION,3);

  curl_setopt($ch, CURLOPT_SSL_VERIFYPEER, true);
  curl_setopt($ch, CURLOPT_SSL_VERIFYHOST, 2);

  curl_setopt($ch, CURLOPT_CAINFO,  getcwd().'ipm.crt');
  curl_setopt($ch, CURLOPT_SSLCERT, getcwd().'ipm.pem');

  curl_setopt($ch, CURLOPT_SSLCERTPASSWD,'pass');

  //i use this line only for debugging through fiddler. Must delete after done with debugging.
  curl_setopt($ch, CURLOPT_PROXY, '127.0.0.1:8888');

  // set URL and other appropriate options
  curl_setopt($ch, CURLOPT_URL, ""https://ipv4.fiddler/iPM/receiver.php"");
  curl_setopt($ch, CURLOPT_HTTPHEADER, array('Content-Type: text/xml'));
  curl_setopt($ch, CURLOPT_HEADER, 0);
  curl_setopt($ch, CURLOPT_POST, 1);
  curl_setopt($ch, CURLOPT_POSTFIELDS, $xml);
  curl_setopt($ch, CURLOPT_FOLLOWLOCATION, 0);
  curl_setopt($ch, CURLOPT_REFERER, 'https://ipv4.fiddler/iPM/receiver.php');
  curl_setopt($ch, CURLOPT_RETURNTRANSFER, 1);
  $ch_result = curl_exec($ch);
  echo ""Result = "".$ch_result;

  echo 'Curl error: ' . curl_error($ch);

  curl_close($ch);
  // Print CURL result.
?&gt;


However i always get this error : Curl error: unable to use client certificate (no key found or wrong pass phrase?)

What can i possibly do wrong? The passphrase IS the word pass .

I created my .crt by doing :

openssl req -config openssl.cnf -new -out ipm.csr -keyout ipm.pem

openssl rsa -in ipm.pem -out ipm.key

openssl x509 -in ipm.csr -out ipm.crt -req -signkey ipm.key -days 365


I dont want to put the SSL_VERIFYPEER and SSL_VERIFYHOST to false.
",donparalias,https://stackoverflow.com/users/1372498,"Try exchanging your files like so:

curl_setopt($ch, CURLOPT_CAINFO, getcwd().'ipm.pem');
curl_setopt($ch, CURLOPT_SSLCERT, getcwd().'ipm.crt');


I suspect you have them the wrong way round.
",Tash Pemhiwa,https://stackoverflow.com/users/430673,http://stackoverflow.com/questions/14470225/curl-is-unable-to-use-client-certificate-in-local-server,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.4444444444444444,0.0,0.6666666666666666,0.3333333333333333,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.3333333333333333,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.0,0.3333333333333333,0.8888888888888888,Curl cannot use client certificate in local server,"I set up a local server using XAMPP. I have two php scripts , a sender and a receiver. I am trying to send an XML file from the sender to the receiver using HTTP over SSL (HTTPS).

I created a self signed certificate , i configured XAMPP and i use this code on my sender :

&lt;?php
  /*
   * XML Sender/Client.
   */
  // Get our XML. You can declare it here or even load a file.


  $xml = file_get_contents(""data.xml"");

  // We send XML via CURL using POST with a http header of text/xml.
  $ch = curl_init();

  //curl_setopt($ch, CURLOPT_SSLVERSION,3);

  curl_setopt($ch, CURLOPT_SSL_VERIFYPEER, true);
  curl_setopt($ch, CURLOPT_SSL_VERIFYHOST, 2);

  curl_setopt($ch, CURLOPT_CAINFO,  getcwd().'ipm.crt');
  curl_setopt($ch, CURLOPT_SSLCERT, getcwd().'ipm.pem');

  curl_setopt($ch, CURLOPT_SSLCERTPASSWD,'pass');

  //i use this line only for debugging through fiddler. Must delete after done with debugging.
  curl_setopt($ch, CURLOPT_PROXY, '127.0.0.1:8888');

  // set URL and other appropriate options
  curl_setopt($ch, CURLOPT_URL, ""https://ipv4.fiddler/iPM/receiver.php"");
  curl_setopt($ch, CURLOPT_HTTPHEADER, array('Content-Type: text/xml'));
  curl_setopt($ch, CURLOPT_HEADER, 0);
  curl_setopt($ch, CURLOPT_POST, 1);
  curl_setopt($ch, CURLOPT_POSTFIELDS, $xml);
  curl_setopt($ch, CURLOPT_FOLLOWLOCATION, 0);
  curl_setopt($ch, CURLOPT_REFERER, 'https://ipv4.fiddler/iPM/receiver.php');
  curl_setopt($ch, CURLOPT_RETURNTRANSFER, 1);
  $ch_result = curl_exec($ch);
  echo ""Result = "".$ch_result;

  echo 'Curl error: ' . curl_error($ch);

  curl_close($ch);
  // Print CURL result.
?&gt;


However i always get this error : Curl error: unable to use client certificate (no key found or wrong pass phrase?)

What can i possibly do wrong? The passphrase IS the word pass .

I created my .crt by doing :

openssl req -config openssl.cnf -new -out ipm.csr -keyout ipm.pem

openssl rsa -in ipm.pem -out ipm.key

openssl x509 -in ipm.csr -out ipm.crt -req -signkey ipm.key -days 365


I dont want to put the SSL_VERIFYPEER and SSL_VERIFYHOST to false.
","Try exchanging your files like so:

curl_setopt($ch, CURLOPT_CAINFO, getcwd().'ipm.pem');
curl_setopt($ch, CURLOPT_SSLCERT, getcwd().'ipm.crt');


I suspect you have them the wrong way round.
"
2368,2368,3774,1/4 to 1/8 jack problem,"I was planning to record months ago, with my electric guitar, and yesterday I got myself a guitar rig software and bought some 1/4 to 1/8 adapter jack so that I can plug in unto my laptop's mic hole.

Whenever I plug my guitar cable to the 1/4 to 1/8 adapter then to the laptop I can't hear any sound (past the clicking sound you hear) but when I plug the cable almost halfway of the adapter's body (before the clicking sound) I can hear sound when I play and there's some loud buzzing sound involved.

Any explanations as to why this is happening? 
",user3736846,https://music.stackexchange.com/users/13524,"You can't just use an adapter to plug your guitar directly into your laptop -- the laptop's sound card is expecting either mic-level or line-level sound, whereas your guitar is a very high impedance signal coming in at a very low level (particularly if your pickups are passive).

It's possible that your adapter is just faulty, but it's far more likely that you will need a special interface to use with your guitar. There are countless options, but for the most basic setup you would just want to google USB guitar cable. They're pretty cheap.
",NReilingh,https://music.stackexchange.com/users/133,http://music.stackexchange.com/questions/25070/1-4-to-1-8-jack-problem,LIFE_ARTS,music.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.3333333333333333,0.0,1.0,0.8888888888888888,1 / 4 to 1 / 8 Jack problem,"I was planning to record months ago, with my electric guitar, and yesterday I got myself a guitar rig software and bought some 1/4 to 1/8 adapter jack so that I can plug in unto my laptop's mic hole.

Whenever I plug my guitar cable to the 1/4 to 1/8 adapter then to the laptop I can't hear any sound (past the clicking sound you hear) but when I plug the cable almost halfway of the adapter's body (before the clicking sound) I can hear sound when I play and there's some loud buzzing sound involved.

Any explanations as to why this is happening? 
","You can't just use an adapter to plug your guitar directly into your laptop -- the laptop's sound card is expecting either mic-level or line-level sound, whereas your guitar is a very high impedance signal coming in at a very low level (particularly if your pickups are passive).

It's possible that your adapter is just faulty, but it's far more likely that you will need a special interface to use with your guitar. There are countless options, but for the most basic setup you would just want to google USB guitar cable. They're pretty cheap.
"
5427,5427,8615,Upgrade to 12.04 Failed due to held back packages,"I run upgrade after installing all recommended updates from update manager, and I got dialog:

Could not calculate the upgrade

An unresolvable problem occurred while calculating the upgrade:
E:Unable to correct problems, you have held broken packages.

 This can be caused by:
 * Upgrading to a pre-release version of Ubuntu
 * Running the current pre-release version of Ubuntu
 * Unofficial software packages not provided by Ubuntu

If none of this applies, then please report this bug using the command 'ubuntu-bug update-manager' in a terminal.


So I reported bug.

I also tried

umpirsky@umpirsky:~$ sudo apt-get update
...
Fetched 16.6 kB in 1min 22s (200 B/s)
Reading package lists... Done
W: GPG error: http://archive.canonical.com oneiric Release: The following signatures were invalid: BADSIG 40976EAF437D05B5 Ubuntu Archive Automatic Signing Key &lt;email address hidden&gt;


Any workaround for this?


What is the easiest way to resolve apt-get BADSIG GPG errors?
First and second solution didn't work, last one returned cd: /var/cache/apt-cacher-ng: No such file or directory. Still getting GPG error.

",umpirsky,https://askubuntu.com/users/17226,"I had this issue, and found that it was resolved by setting my software-sources back to the ubuntu.com site. (I had a faster mirror selected initially.)  Through software Center, I used the Edit menu --> Software Sources ... and on the dialog for Software Sources, I chose 'Main Server'.  I then ran sudo apt-get update.   After that, it could calculate the changes and upgrade.  This primary site was slower, but this solved the problem in my case. 
",belacqua,https://askubuntu.com/users/8844,http://askubuntu.com/questions/125500/upgrade-to-12-04-failed-due-to-held-back-packages,TECHNOLOGY,askubuntu.com,0.8888888888888888,0.4444444444444444,0.0,1.0,1.0,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.5555555555555556,0.8888888888888888,0.6666666666666666,1.0,1.0,1.0,1.0,0.3333333333333333,0.0,0.8888888888888888,Upgrade to 12.04 failed due to package delay,"I run upgrade after installing all recommended updates from update manager, and I got dialog:

Could not calculate the upgrade

An unresolvable problem occurred while calculating the upgrade:
E:Unable to correct problems, you have held broken packages.

 This can be caused by:
 * Upgrading to a pre-release version of Ubuntu
 * Running the current pre-release version of Ubuntu
 * Unofficial software packages not provided by Ubuntu

If none of this applies, then please report this bug using the command 'ubuntu-bug update-manager' in a terminal.


So I reported bug.

I also tried

umpirsky@umpirsky:~$ sudo apt-get update
...
Fetched 16.6 kB in 1min 22s (200 B/s)
Reading package lists... Done
W: GPG error: http://archive.canonical.com oneiric Release: The following signatures were invalid: BADSIG 40976EAF437D05B5 Ubuntu Archive Automatic Signing Key &lt;email address hidden&gt;


Any workaround for this?


What is the easiest way to resolve apt-get BADSIG GPG errors?
First and second solution didn't work, last one returned cd: /var/cache/apt-cacher-ng: No such file or directory. Still getting GPG error.

","I ran into this problem and found that it was solved by setting my software source back to the ubuntu.com site. (I initially chose a faster mirror.) Through the software center, I used the edit menu - > software source... In the software source dialog box, I selected primary server. Then I run sudo to get the update. After that, it can calculate changes and upgrades. This main site is slow, but it solves my problem."
2460,2460,3923,Catalytic converter possibly bad. How soon do I need to replace?,"2004 Cadillac SRX V8 AWD is making a rattling sound when idle, and mostly or completely goes away when RPMs increase. From what I've found, this is a bad catalytic converter. 

It is under warranty still for this, when do I need to get it done?

Problem is that we have to take it 200 miles to get it replaced at the dealer. Is it bad to drive it at interstate or highway speeds to get there? How soon should this be done?
",Matt,https://mechanics.stackexchange.com/users/1581,"It sounds as if the internals of the cat may have broken loose. The catalytic converter is already broke so you can't make it any worse. The worst thing that can happen is it could the piece that is rattling may break free and plug the exhaust leaving you stranded. I would also ask the dealer if they will cover potential problems of a clogged muffler later on.
",mikes,https://mechanics.stackexchange.com/users/1566,http://mechanics.stackexchange.com/questions/3729/catalytic-converter-possibly-bad-how-soon-do-i-need-to-replace,SCIENCE,mechanics.stackexchange.com,1.0,0.3333333333333333,0.3333333333333333,0.0,1.0,1.0,0.5555555555555556,0.4444444444444444,1.0,0.0,0.6666666666666666,1.0,0.0,0.3333333333333333,0.0,0.0,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.8,0.0,0.0,1.0,0.7777777777777778,The catalytic converter may be damaged. How long do I need to replace it?,"2004 Cadillac SRX V8 AWD is making a rattling sound when idle, and mostly or completely goes away when RPMs increase. From what I've found, this is a bad catalytic converter. 

It is under warranty still for this, when do I need to get it done?

Problem is that we have to take it 200 miles to get it replaced at the dealer. Is it bad to drive it at interstate or highway speeds to get there? How soon should this be done?
","It sounds as if the internals of the cat may have broken loose. The catalytic converter is already broke so you can't make it any worse. The worst thing that can happen is it could the piece that is rattling may break free and plug the exhaust leaving you stranded. I would also ask the dealer if they will cover potential problems of a clogged muffler later on.
"
279,279,450,How are integers internally represented at a bit level in Java?,"I am trying to understand how Java stores integer internally. I know all java primitive integers are signed, (except short?). That means one less bit available in a byte for the number.

My question is, are all integers (positive and negative) stored as two's complement or are only negative numbers in two's complement?

I see that the specs says x bit two's complement number. But I often get confused.

For instance:

  int x = 15; // Stored as binary as is?  00000000 00000000 00000000 00001111?
  int y = -22; // Stored as two complemented value? 11111111 11111111 11111111 11101010


Edit

To be clear, x = 15 

   In binary as is: `00000000 00000000 00000000 00001111'
  Two's complement: `11111111 11111111 11111111 11110001`


So if your answer is  all numbers are stored as two's complement then:

  int x = 15; // 11111111 11111111 11111111 11110001
  int y = -22 // 11111111 11111111 11111111 11101010


The confusion here again is the sign says, both are negative numbers. May be I am misreading / misunderstanding it?

Edit
Not sure my question is confusing. Forced to isolate the question:

My question precisely: Are positive numbers stored in binary as is while negative numbers are stored as two's complement?

Some said all are stored in two's complement and one answer says only negative numbers are stored as two's complement.
",Kevin Rave,https://stackoverflow.com/users/668650,"Java integers are of 32 bits, and always signed. This means, the most significant bit (MSB) works as the sign bit. The integer represented by an int is nothing but the weighted sum of the bits. The weights are assigned as follows:

Bit#    Weight
31      -2^31
30       2^30
29       2^29
...      ...
2        2^2
1        2^1
0        2^0


Note that the weight of the MSB is negative (the largest possible negative actually), so when this bit is on, the whole number (the weighted sum) becomes negative.

Let's simulate it with 4-bit numbers:

Binary    Weighted sum            Integer value
0000       0 + 0 + 0 + 0           0
0001       0 + 0 + 0 + 2^0         1
0010       0 + 0 + 2^1 + 0         2
0011       0 + 0 + 2^1 + 2^0       3
0100       0 + 2^2 + 0 + 0         4
0101       0 + 2^2 + 0 + 2^0       5
0110       0 + 2^2 + 2^1 + 0       6
0111       0 + 2^2 + 2^1 + 2^0     7 -&gt; the most positive value
1000      -2^3 + 0 + 0 + 0        -8 -&gt; the most negative value
1001      -2^3 + 0 + 0 + 2^0      -7
1010      -2^3 + 0 + 2^1 + 0      -6
1011      -2^3 + 0 + 2^1 + 2^0    -5
1100      -2^3 + 2^2 + 0 + 0      -4
1101      -2^3 + 2^2 + 0 + 2^0    -3
1110      -2^3 + 2^2 + 2^1 + 0    -2
1111      -2^3 + 2^2 + 2^1 + 2^0  -1


So, the two's complement thing is not an exclusive scheme for representing negative integers, rather we can say that the binary representation of integers are always the same, we just negate the weight of the most significant bit. And that bit determines the sign of the integer.

In C, there is a keyword unsigned (not available in java), which can be used for declaring unsigned int x;. In the unsigned integers, the weight of the MSB is positive (2^31) rather than being negative. In that case the range of an unsigned int is 0 to 2^32 - 1, while an int has range -2^31 to 2^31 - 1.

From another point of view, if you consider the two's complement of x as ~x + 1 (NOT x plus one), here's the explanation:

For any x, ~x is just the bitwise inverse of x, so wherever x has a 1-bit, ~x will have a 0-bit there (and vice versa). So, if you add these up, there will be no carry in the addition and the sum will be just an integer every bit of which is 1.

For 32-bit integers:

x + ~x = 1111 1111 1111 1111 1111 1111 1111 1111
x + ~x + 1 =   1111 1111 1111 1111 1111 1111 1111 1111 + 1
           = 1 0000 0000 0000 0000 0000 0000 0000 0000


The leftmost 1-bit will simply be discarded, because it doesn't fit in 32-bits (integer overflow). So,

x + ~x + 1 = 0
-x = ~x + 1


So you can see that the negative x can be represented by ~x + 1, which we call the two's complement of x.
",0605002,https://stackoverflow.com/users/1102056,http://stackoverflow.com/questions/13422259/how-are-integers-internally-represented-at-a-bit-level-in-java,STACKOVERFLOW,stackoverflow.com,1.0,1.0,0.0,1.0,1.0,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.6666666666666666,0.0,1.0,0.7777777777777778,0.7777777777777778,1.0,1.0,0.8666666666666666,0.3333333333333333,0.0,1.0,1.0,"In Java, how are integers represented internally at a bit level?","I am trying to understand how Java stores integer internally. I know all java primitive integers are signed, (except short?). That means one less bit available in a byte for the number.

My question is, are all integers (positive and negative) stored as two's complement or are only negative numbers in two's complement?

I see that the specs says x bit two's complement number. But I often get confused.

For instance:

  int x = 15; // Stored as binary as is?  00000000 00000000 00000000 00001111?
  int y = -22; // Stored as two complemented value? 11111111 11111111 11111111 11101010


Edit

To be clear, x = 15 

   In binary as is: `00000000 00000000 00000000 00001111'
  Two's complement: `11111111 11111111 11111111 11110001`


So if your answer is  all numbers are stored as two's complement then:

  int x = 15; // 11111111 11111111 11111111 11110001
  int y = -22 // 11111111 11111111 11111111 11101010


The confusion here again is the sign says, both are negative numbers. May be I am misreading / misunderstanding it?

Edit
Not sure my question is confusing. Forced to isolate the question:

My question precisely: Are positive numbers stored in binary as is while negative numbers are stored as two's complement?

Some said all are stored in two's complement and one answer says only negative numbers are stored as two's complement.
","Java integers are of 32 bits, and always signed. This means, the most significant bit (MSB) works as the sign bit. The integer represented by an int is nothing but the weighted sum of the bits. The weights are assigned as follows:

Bit#    Weight
31      -2^31
30       2^30
29       2^29
...      ...
2        2^2
1        2^1
0        2^0


Note that the weight of the MSB is negative (the largest possible negative actually), so when this bit is on, the whole number (the weighted sum) becomes negative.

Let's simulate it with 4-bit numbers:

Binary    Weighted sum            Integer value
0000       0 + 0 + 0 + 0           0
0001       0 + 0 + 0 + 2^0         1
0010       0 + 0 + 2^1 + 0         2
0011       0 + 0 + 2^1 + 2^0       3
0100       0 + 2^2 + 0 + 0         4
0101       0 + 2^2 + 0 + 2^0       5
0110       0 + 2^2 + 2^1 + 0       6
0111       0 + 2^2 + 2^1 + 2^0     7 -&gt; the most positive value
1000      -2^3 + 0 + 0 + 0        -8 -&gt; the most negative value
1001      -2^3 + 0 + 0 + 2^0      -7
1010      -2^3 + 0 + 2^1 + 0      -6
1011      -2^3 + 0 + 2^1 + 2^0    -5
1100      -2^3 + 2^2 + 0 + 0      -4
1101      -2^3 + 2^2 + 0 + 2^0    -3
1110      -2^3 + 2^2 + 2^1 + 0    -2
1111      -2^3 + 2^2 + 2^1 + 2^0  -1


So, the two's complement thing is not an exclusive scheme for representing negative integers, rather we can say that the binary representation of integers are always the same, we just negate the weight of the most significant bit. And that bit determines the sign of the integer.

In C, there is a keyword unsigned (not available in java), which can be used for declaring unsigned int x;. In the unsigned integers, the weight of the MSB is positive (2^31) rather than being negative. In that case the range of an unsigned int is 0 to 2^32 - 1, while an int has range -2^31 to 2^31 - 1.

From another point of view, if you consider the two's complement of x as ~x + 1 (NOT x plus one), here's the explanation:

For any x, ~x is just the bitwise inverse of x, so wherever x has a 1-bit, ~x will have a 0-bit there (and vice versa). So, if you add these up, there will be no carry in the addition and the sum will be just an integer every bit of which is 1.

For 32-bit integers:

x + ~x = 1111 1111 1111 1111 1111 1111 1111 1111
x + ~x + 1 =   1111 1111 1111 1111 1111 1111 1111 1111 + 1
           = 1 0000 0000 0000 0000 0000 0000 0000 0000


The leftmost 1-bit will simply be discarded, because it doesn't fit in 32-bits (integer overflow). So,

x + ~x + 1 = 0
-x = ~x + 1


So you can see that the negative x can be represented by ~x + 1, which we call the two's complement of x.
"
1656,1656,2614,Access control Service and Azure Websites Could not load System.IdentityModel.Services,"I've created an ASP.NET MVC 4 app using visual studio 2012 RC on Windows 8 release preview. I downloaded and installed the WIF toolkit and used the ""Identity and Access"" option in the solution menu to add my Access Control Service metadata endpoint. Tested locally and all is well. When I deployed to my free azure website however I get the yellow screen saying


  ""Could not load file or assembly 'System.IdentityModel.Services,
  Version=4.0.0.0, Culture=neutral, PublicKeyToken=b77a5c561934e089' or
  one of its dependencies. The system cannot find the file specified.""


These assemblies aren't referenced in the project, so I added them, sent to output to the bin folder and redeployed. I then got a message about the assembly probably being tampered with. Does anyone know how to overcome this?

EDIT
Adding local causes this error


  Could not load file or assembly 'System.IdentityModel.Services' or one
  of its dependencies. Strong name signature could not be verified.  The
  assembly may have been tampered with, or it was delay signed but not
  fully signed with the correct private key. (Exception from HRESULT:
  0x80131045)


In the web config the module is deinfed as

&lt;system.webServer&gt;
    &lt;validation validateIntegratedModeConfiguration=""false"" /&gt;
    &lt;modules&gt;
      &lt;add name=""WSFederationAuthenticationModule"" type=""System.IdentityModel.Services.WSFederationAuthenticationModule, System.IdentityModel.Services, Version=4.0.0.0, Culture=neutral, PublicKeyToken=b77a5c561934e089"" preCondition=""managedHandler"" /&gt;
      &lt;add name=""SessionAuthenticationModule"" type=""System.IdentityModel.Services.SessionAuthenticationModule, System.IdentityModel.Services, Version=4.0.0.0, Culture=neutral, PublicKeyToken=b77a5c561934e089"" preCondition=""managedHandler"" /&gt;
    &lt;/modules&gt;
  &lt;/system.webServer&gt;


Thanks
",Dylan,https://stackoverflow.com/users/246970,"I think this is a known issue in Azure, you'll need to use a start-up script that runs gacutil.exe to register the IdentityModel.dll.

Follow the steps here: http://blogs.infosupport.com/adding-assemblies-to-the-gac-in-windows-azure/

Edit:
My bad, I thought you were talking about a Web Role. As astaykov said, you can't have start-up tasks in Web Sites. Well maybe this'll help somebody else out :-)
",Shahin Dohan,https://stackoverflow.com/users/1469494,http://stackoverflow.com/questions/11595684/access-control-service-and-azure-websites-could-not-load-system-identitymodel-se,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.3333333333333333,0.0,1.0,1.0,1.0,0.6666666666666666,0.4444444444444444,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.0,1.0,0.5,0.6666666666666666,0.8333333333333334,0.5555555555555556,0.4666666666666667,0.3333333333333333,0.0,1.0,1.0,Access control service and azure website failed to load system.identitymodel.services,"I've created an ASP.NET MVC 4 app using visual studio 2012 RC on Windows 8 release preview. I downloaded and installed the WIF toolkit and used the ""Identity and Access"" option in the solution menu to add my Access Control Service metadata endpoint. Tested locally and all is well. When I deployed to my free azure website however I get the yellow screen saying


  ""Could not load file or assembly 'System.IdentityModel.Services,
  Version=4.0.0.0, Culture=neutral, PublicKeyToken=b77a5c561934e089' or
  one of its dependencies. The system cannot find the file specified.""


These assemblies aren't referenced in the project, so I added them, sent to output to the bin folder and redeployed. I then got a message about the assembly probably being tampered with. Does anyone know how to overcome this?

EDIT
Adding local causes this error


  Could not load file or assembly 'System.IdentityModel.Services' or one
  of its dependencies. Strong name signature could not be verified.  The
  assembly may have been tampered with, or it was delay signed but not
  fully signed with the correct private key. (Exception from HRESULT:
  0x80131045)


In the web config the module is deinfed as

&lt;system.webServer&gt;
    &lt;validation validateIntegratedModeConfiguration=""false"" /&gt;
    &lt;modules&gt;
      &lt;add name=""WSFederationAuthenticationModule"" type=""System.IdentityModel.Services.WSFederationAuthenticationModule, System.IdentityModel.Services, Version=4.0.0.0, Culture=neutral, PublicKeyToken=b77a5c561934e089"" preCondition=""managedHandler"" /&gt;
      &lt;add name=""SessionAuthenticationModule"" type=""System.IdentityModel.Services.SessionAuthenticationModule, System.IdentityModel.Services, Version=4.0.0.0, Culture=neutral, PublicKeyToken=b77a5c561934e089"" preCondition=""managedHandler"" /&gt;
    &lt;/modules&gt;
  &lt;/system.webServer&gt;


Thanks
","I think this is a known issue in Azure, you'll need to use a start-up script that runs gacutil.exe to register the IdentityModel.dll.

Follow the steps here: http://blogs.infosupport.com/adding-assemblies-to-the-gac-in-windows-azure/

Edit:
My bad, I thought you were talking about a Web Role. As astaykov said, you can't have start-up tasks in Web Sites. Well maybe this'll help somebody else out :-)
"
1624,1624,2547,USB 3.0 to USB 3.0,"I have an external HD with USB 3.0 and a laptop with a USB 3.0 port. Can I connect the two safely to transfer data and watch films stored on the HD for instance? If so where can I buy such a cable to do so?
",Dave Rowden,https://superuser.com/users/371811,"Yep.

Pick your favorite online tech store (i.e. such as where you bought the hard drive from) and search for ""USB 3.0 Data Cable.""

USB 3.0 on the device end looks different than USB 2.0 devices.  The end that plugs into the computer ought to be colored blue to specifically identify it as a USB 3.0 cable (the port you are plugging it into will be blue as well).



When you connect it, if it's a Windows PC, go to the Start Menu, then Computer, and your external HD should show up as another drive letter.  You can then browse files and double-click them to play them.  If you have problems playing them, download and install VLC Player.
",LawrenceC,https://superuser.com/users/51705,http://superuser.com/questions/816164,TECHNOLOGY,superuser.com,1.0,0.3333333333333333,0.0,1.0,0.6666666666666666,1.0,0.4444444444444444,0.4444444444444444,1.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.7777777777777778,1.0,0.7777777777777778,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,1.0,From USB 3.0 to USB 3.0,"I have an external hard disk with USB 3.0 and a laptop with USB 3.0 port. Can I safely connect the two to transmit data and watch movies stored in HD? If so, where can I buy such a cable?","Yep.

Pick your favorite online tech store (i.e. such as where you bought the hard drive from) and search for ""USB 3.0 Data Cable.""

USB 3.0 on the device end looks different than USB 2.0 devices.  The end that plugs into the computer ought to be colored blue to specifically identify it as a USB 3.0 cable (the port you are plugging it into will be blue as well).



When you connect it, if it's a Windows PC, go to the Start Menu, then Computer, and your external HD should show up as another drive letter.  You can then browse files and double-click them to play them.  If you have problems playing them, download and install VLC Player.
"
23,23,31,Why does string theory have such a huge landscape?,"I was browsing through Foundations of Space and Time, a compilation of essays on various theories of quantum gravity. The following passage in the introduction intrigued me:


  Each compactification leads to a different vacuum state.... at least one state should describe our Universe in its entirety.... the enormous number (~10^500 at last count) of solutions, with no perturbative mechanism to select mechanism to select among them, leads some critics to question the predictive power of the theory..Even more worrying is that, while the theory is perturbatively finite order by order, the perturbation series does not seem to converge.


I don't know anything about string theory and so I could not make head or tails this. All I know is that ~$10^{500}$    is a very large number. 


What exactly is a 'solution' in string theory? Is it a spacetime metric of some sort or the terms of a S-matrix of some sort?  
Why are there so many 'solutions'? 
I thought string theory was supposed to be finite, why do perturbative series still diverge?
Is there any experimental technique to limit the number of 'solutions'?  
Will experimental techniques be able to pinpoint a solution within present day string theorists' lifetimes too? If not, how long will it take before we can experimentally probe these things? 
Are string theorists completely relaxed about these issues? Or are they in anguish? 

",dj_mummy,https://physics.stackexchange.com/users/28244,"
  ""Each compactification leads to a different vacuum state.... at least
  one state should describe our Universe in its entirety.... the
  enormous number (~10^500 at last count) of solutions, with no
  perturbative mechanism to select mechanism to select among them, leads
  some critics to question the predicitive power of the theory..Even
  more worrying is that, while the theory is perturubatively finite
  order by order, the pertrubation series does not seem to converge.""


Ok.  


  I don't know anything about string theory and so I could not make head
  or tails this. All I know is that ~10^500 is a very large number.


That, it is.      


  What exactly is a 'solution' in string theory? Is it a spacetime
  metric of some sort or the terms of a S-matrix of some sort?  


So, we have a non-peturbative definition of M-theory and string theories on AdS Space through the AdS/.CFT correspondence. Now,  these are 10 or 11-dimensional.          To get rid of the extra 6 or 7 dimensions, you need to compactify it on a 6-dimensional or 7-dimensional manifold. 

A particularly convinient compactifications of 11-dimensional M-theory is on $G(2)$-holonomy manifolds.       Particularly convinient compactifications of 10-dimensional string theories, such as Type HE, are on $SU(3)$-holonomy Calabi-Yau manifolds.      Of course, it's not necessary; e.g. if the world happens to be something with $\mathcal N=2$ supersymmetry, as opposed to                           $\mathcal N=1$.             


  Why are there so many 'solutions'?  


Because there are lots of these manifolds!       


  I thought string theory was supposed to be finite, why do perturbative
  series still diverge?  


Uh... Yes. But it's renormaliable. And there are non-peturbative definitions in AdS spacetime.     


  Is there any experimental technique to limit the number of
  'solutions'?  Will experimental techniques be able to pinpoint a
  solution within present day string theorists' life      times too? If
  not, how long will it take before we can experimentally probe these
  things?


In principle, it's possible.    But in anyone's lifetime... Do you know how big $10^{500} $ is? % See this.   


  Are string theorists completely relaxed about these issues? Or are
  they in anguish?    


There's the branch of String Phenomenology that attempts  to find the correct vacua...     
",centralcharge,https://physics.stackexchange.com/users/23119,http://physics.stackexchange.com/questions/75441/why-does-string-theory-have-such-a-huge-landscape,SCIENCE,physics.stackexchange.com,1.0,0.5555555555555556,0.0,0.6666666666666666,0.6666666666666666,1.0,0.6666666666666666,0.5555555555555556,0.6666666666666666,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,1.0,Why is string theory so promising?,"I was browsing through Foundations of Space and Time, a compilation of essays on various theories of quantum gravity. The following passage in the introduction intrigued me:


  Each compactification leads to a different vacuum state.... at least one state should describe our Universe in its entirety.... the enormous number (~10^500 at last count) of solutions, with no perturbative mechanism to select mechanism to select among them, leads some critics to question the predictive power of the theory..Even more worrying is that, while the theory is perturbatively finite order by order, the perturbation series does not seem to converge.


I don't know anything about string theory and so I could not make head or tails this. All I know is that ~$10^{500}$    is a very large number. 


What exactly is a 'solution' in string theory? Is it a spacetime metric of some sort or the terms of a S-matrix of some sort?  
Why are there so many 'solutions'? 
I thought string theory was supposed to be finite, why do perturbative series still diverge?
Is there any experimental technique to limit the number of 'solutions'?  
Will experimental techniques be able to pinpoint a solution within present day string theorists' lifetimes too? If not, how long will it take before we can experimentally probe these things? 
Are string theorists completely relaxed about these issues? Or are they in anguish? 

","
  ""Each compactification leads to a different vacuum state.... at least
  one state should describe our Universe in its entirety.... the
  enormous number (~10^500 at last count) of solutions, with no
  perturbative mechanism to select mechanism to select among them, leads
  some critics to question the predicitive power of the theory..Even
  more worrying is that, while the theory is perturubatively finite
  order by order, the pertrubation series does not seem to converge.""


Ok.  


  I don't know anything about string theory and so I could not make head
  or tails this. All I know is that ~10^500 is a very large number.


That, it is.      


  What exactly is a 'solution' in string theory? Is it a spacetime
  metric of some sort or the terms of a S-matrix of some sort?  


So, we have a non-peturbative definition of M-theory and string theories on AdS Space through the AdS/.CFT correspondence. Now,  these are 10 or 11-dimensional.          To get rid of the extra 6 or 7 dimensions, you need to compactify it on a 6-dimensional or 7-dimensional manifold. 

A particularly convinient compactifications of 11-dimensional M-theory is on $G(2)$-holonomy manifolds.       Particularly convinient compactifications of 10-dimensional string theories, such as Type HE, are on $SU(3)$-holonomy Calabi-Yau manifolds.      Of course, it's not necessary; e.g. if the world happens to be something with $\mathcal N=2$ supersymmetry, as opposed to                           $\mathcal N=1$.             


  Why are there so many 'solutions'?  


Because there are lots of these manifolds!       


  I thought string theory was supposed to be finite, why do perturbative
  series still diverge?  


Uh... Yes. But it's renormaliable. And there are non-peturbative definitions in AdS spacetime.     


  Is there any experimental technique to limit the number of
  'solutions'?  Will experimental techniques be able to pinpoint a
  solution within present day string theorists' life      times too? If
  not, how long will it take before we can experimentally probe these
  things?


In principle, it's possible.    But in anyone's lifetime... Do you know how big $10^{500} $ is? % See this.   


  Are string theorists completely relaxed about these issues? Or are
  they in anguish?    


There's the branch of String Phenomenology that attempts  to find the correct vacua...     
"
3151,3151,5018,image processing,"This is an assignment, i have put good effort since i am new to python programming:

I am running the following function which takes in image and phrase (spaces will be removed so just text) as arguments, i have already been given all the import and preprocessing code, i just need to implement this function. I can only use getpixel, putpixel, load, and save. That is why coding this has been a hard task for me.

def InsertoImage(srcImage, phrase):  
    pix = srcImage.load()  
    for index,value in enumerate(phrase):  
        pix[10+index,15] = phrase[index]  
    srcImage.save()  
pass  


This code is giving ""system error"" which says that ""new style getargs format but argument is not tuple""

Edit:

C:\Users\Nave\Desktop\a1&gt;a1_template.py lolmini.jpg Hi  
Traceback (most recent call last):  
  File ""C:\Users\Nave\Desktop\a1\a1_template.py"", line 31, in &lt;module&gt;  
    doLOLImage(srcImage, phrase)  
  File ""C:\Users\Nave\Desktop\a1\a1_template.py"", line 23, in doLOLImage  
    pix[10+index,15] = phrase[index]  
SystemError: new style getargs format but argument is not a tuple  


Edit:

Ok Thanks, i understood and now posting code but i am getting error for the if statement not sure why the if statement is not working, here is full code sorry for not adding it entirely before: 

from future import division  

letters, numbers, and punctation are dictionaries mapping (uppercase)

characters to Images representing that character

NOTE: There is no space character stored!

from imageproc import letters, numbers, punctuation, preProcess  

This is the function to implement

def InserttoImage(srcImage, phrase):
    pix = srcImage.load()
    for index,value in enumerate(phrase):
        if value in letters:
           pix[10+index, 15]  = letters[value]
        elif value in numbers:
           pix[10+index, 15]  = numbers[value]
        elif value in punctuation: 
           pix[10+index, 15]  = punctuation[value]
    srcImage.save()
    pass  

This code is performed when this script is called from the command line via:

'python .py'

if name == 'main':
    srcImage, phrase = preProcess()
    InserttoImage(srcImage, phrase)  

Thanks, letter, numbers, and punctuation are dictionaries which see the key element and open the image (font).
But still there is an issue with pix[10+index, 15] as it is giving error:

pix[10+index, 15]  = letters[value]  


SystemError: new style getargs format but argument is not a tuple  
",nman84,https://stackoverflow.com/users/427886,"Just try this:
pix[10+index:15] = letters[value]
Use "":"" instead of "",""
",Крайст,https://stackoverflow.com/users/601684,http://stackoverflow.com/questions/3553088/image-processing,STACKOVERFLOW,stackoverflow.com,0.6666666666666666,0.3333333333333333,0.0,0.0,1.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.6666666666666666,1.0,1.0,0.0,1.0,0.0,1.0,image processing,"This is an assignment, i have put good effort since i am new to python programming:

I am running the following function which takes in image and phrase (spaces will be removed so just text) as arguments, i have already been given all the import and preprocessing code, i just need to implement this function. I can only use getpixel, putpixel, load, and save. That is why coding this has been a hard task for me.

def InsertoImage(srcImage, phrase):  
    pix = srcImage.load()  
    for index,value in enumerate(phrase):  
        pix[10+index,15] = phrase[index]  
    srcImage.save()  
pass  


This code is giving ""system error"" which says that ""new style getargs format but argument is not tuple""

Edit:

C:\Users\Nave\Desktop\a1&gt;a1_template.py lolmini.jpg Hi  
Traceback (most recent call last):  
  File ""C:\Users\Nave\Desktop\a1\a1_template.py"", line 31, in &lt;module&gt;  
    doLOLImage(srcImage, phrase)  
  File ""C:\Users\Nave\Desktop\a1\a1_template.py"", line 23, in doLOLImage  
    pix[10+index,15] = phrase[index]  
SystemError: new style getargs format but argument is not a tuple  


Edit:

Ok Thanks, i understood and now posting code but i am getting error for the if statement not sure why the if statement is not working, here is full code sorry for not adding it entirely before: 

from future import division  

letters, numbers, and punctation are dictionaries mapping (uppercase)

characters to Images representing that character

NOTE: There is no space character stored!

from imageproc import letters, numbers, punctuation, preProcess  

This is the function to implement

def InserttoImage(srcImage, phrase):
    pix = srcImage.load()
    for index,value in enumerate(phrase):
        if value in letters:
           pix[10+index, 15]  = letters[value]
        elif value in numbers:
           pix[10+index, 15]  = numbers[value]
        elif value in punctuation: 
           pix[10+index, 15]  = punctuation[value]
    srcImage.save()
    pass  

This code is performed when this script is called from the command line via:

'python .py'

if name == 'main':
    srcImage, phrase = preProcess()
    InserttoImage(srcImage, phrase)  

Thanks, letter, numbers, and punctuation are dictionaries which see the key element and open the image (font).
But still there is an issue with pix[10+index, 15] as it is giving error:

pix[10+index, 15]  = letters[value]  


SystemError: new style getargs format but argument is not a tuple  
","Just try this:
pix[10+index:15] = letters[value]
Use "":"" instead of "",""
"
3670,3670,5852,Copy file from web to Google Drive,"There is a document on the web that I want to store in my Google Drive. The only way I know to do this is saving the document on my computer and then upload it again to my Google Drive.

Is there a more straightforward way to do this?
",José,https://webapps.stackexchange.com/users/6651,"Try this IFTTT receipt.


  Upload file from URL
  
  This Action will download a file at a given URL and add it to Google Drive at the path you specify.

",Alex,https://webapps.stackexchange.com/users/1512,http://webapps.stackexchange.com/questions/70126/copy-file-from-web-to-google-drive,TECHNOLOGY,webapps.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,0.6666666666666666,1.0,1.0,0.7777777777777778,0.6666666666666666,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.3333333333333333,0.0,1.0,1.0,0.5555555555555556,1.0,0.8888888888888888,0.7333333333333333,1.0,0.3333333333333333,0.0,0.7777777777777778,Copy files from the web to Google drive,There is a document on the Internet that I want to store in my Google drive. The only way I know is to save the document on my computer and upload it to my Google drive again.,"Try this IFTTT receipt.


  Upload file from URL
  
  This Action will download a file at a given URL and add it to Google Drive at the path you specify.

"
3591,3591,5734,Is the Mechromancer's Little Big Trouble tree worthwhile in UVHM (72 level cap)?,"So far, the tree seems rather underwhelming, especially the low-tier skills like Myelin, More Pep, Strength of 5 gorillas, etc.

Evil Enchantress apparently doesn't affect shock, fire and acid direct damage; it only buffs the status effects which is pretty pointless when slagging an enemy does 3X damage.

Shock storm doesn't sound useful as most enemies won't be bunched up enough.

On the other hand, the damage buffs from Wires Don't Talk and Interspersed Outburst look very useful. Make it Sparkle also apparently gives Deathtrap massive additional damage of up to 3X.

Is it worthwhile to spec into this tree just for the end-tier perks?
",Twilight Sparkle,https://gaming.stackexchange.com/users/54882,"I have a Mechromancer character focusing on the 'Best Friends Forever' and the 'Little Big Trouble' skill trees (no Anarchy from 'Ordered Chaos') that I've been playing from TVHM to UVHM with UVH Upgrade Pack Two.  As long as you have gear that will supplement Gaige's Little Big Trouble skills, you should be able to do fine on UVHM.

The most important skill in the Little Big Trouble skill tree is probably 'Wires Don't Talk' (increases all Shock and Electrocute Damage that you inflict). Due to that, I use gear that focuses on taking advantage of that skill.

Instead of More Pep, focus your points into another skill. More Pep's description is misleading, as described here. 


  Increased Elemental Chance effects are applied multiplicatively, not additively. For example, a base 20% Burn Chance with a 30% bonus will result not in 50% Burn Chance, but in 0.2 + (0.2 * 0.3) = 26% Burn Chance.   


Although, if you have a class mod that gives a bonus to More Pep, like Zapper or Legendary Catalyst, you might want to assign at least one point to the skill to get the bonuses given by that class mod.

LBT's The Stare is pretty weak (damage does not scale well) in UVHM. It also has bugs detailed here. It's pretty much a waste of a skill point.  BFF's Explosive Clap seems to scale just fine in UVHM.

Gear that helps take advantage of Little Big Trouble skills:

Class Mods


Zapper, preferably 'Wired' (gives most bonus damage to 'Wires Don't Talk') and blue or purple rarity  (Note that the Zapper class mod's description is misleading, and due to that, the mods below are better, IMO.)  
Necromancer, preferably 'Chaotic Evil' (bonus fire rate and critical damage) and the version that gives the most damage to 'Wires Don't Talk', and blue or purple rarity. This is a TTAODK class mod. More details here.
Legendary Catalyst (UVH Upgrade Pack Two class mod) -  +5 Wires Don't Talk, +5 Evil Enchantress, +5 More Pep, +5 Electrical Burn, +5 Interspersed Outburst; bonus to Team Elemental Effect Dmg - this is probably the best class mod (and the rarest) for a Mechromancer looking to spec into the 'Little Big Trouble' tree.


Relics

An Elemental Relic (common) or a Bone of the Ancients (e-tech) that increases shock damage. The Bone of the Ancients also increases the Action Skill recharge rate, which can allow you to summon Deathtrap sooner.

Grenade Mods


Quasar (legendary, shock-element only)   
Storm Front (legendary, shock-element only) 
Chain Lightning (legendary, shock-element only, TTAODK) - Always Shock. Regenerates grenade ammo over time. Shoots a bolt of lightning straight forward that explodes on impact and arcs to nearby targets.
Quoting Borderlands wiki:


  The Chain Lightning is ideally suited for Gaige builds with heavy investment in the Little Big Trouble tree (specifically Wires Don't Talk, Electrical Burn and Myelin). Its arcing effect can also help a similar build to hit targets at range with a high Anarchy stack, as it can mitigate the accuracy penalty.
  
  The Chain Lightning may pair exceptionally well with the Grog Nozzle, Rubi, and other Moxxi-brand weapons for health restoration. Because the damage from the grenade is practically instantaneous, health may be replenished as soon as the grenade is thrown. Adding to this end are its arcing effect to damage multiple enemies and ability to pass through some surfaces. As aim need not be precise in close- to mid-range, one throw may serve as a panic button when low on health. 
  Shock 'Bouncing Bonny'
  Shock 'Crossfire'    
  Magic Missile - Always slag. Grenades slowly regenerate over time. Two (Blue) or Four (Purple) child grenades home in on targets and explode instantly.
  This is mostly for slagging and for helping to heal with the Rubi. I opt to go with the Magic Missile if I am playing solo or if my co-op allies don't have much slagging capabilities. Otherwise, using a shock damage-dealing grenade mod is better.
  
  
  Shock-only weapons



Thunderball Fists, preferably 'Binary' (one trigger squeeze fires two shots) - deals heavy shock damage  
Little Evie, preferably 'Binary' - killing an enemy increases action skill cooldown rate by 12%; allows you to summon Deathtrap sooner.
Florentine, preferably 'Consummate' (more damage) - a Seraph SMG that fires shock projectiles which deal bonus slag damage on impact.  


Elemental weapons that have shock versions


Rubi, preferably 'Binary' - for healing; Any damage dealt by the player while wielding the weapon heals them, at a rate of 12% of the damage inflicted. Grenades can also be used to heal with the Rubi.
Interfacer, preferably 'Practicable' (more pellets per shot)    
Shredifier, preferably 'Rabid' or 'Ferocious' (more fire rate or damage, respectively) - deals heavy damage, eats a lot of ammo, though    
Avenger, preferably 'Hefty' (more damage) - all-around high stat SMG, regenerates bullets


FFYL weapon, or area-clearing weapons


Shock 'Norfleet' - will deal a lot of shock damage over a wide area
Shock 'Fibber' (second unique barrel version) - I'm putting this here, as IMO, it's too 'overkill' as a normal weapon. Quoting Borderlands wiki:


  The second barrel shoots bullets that shatter upon impact or ricocheting off walls, creating pellets. It bounces off walls if it doesn't hit anything and travels with the same velocity as normal pistols' bullets. For some reason, when the shatter effect and Gaige's Close Enough skill occur at the same time, the ricocheted ""homing"" pellets will do 100% damage, thus ignoring the -50% bullet damage penalty from Gaige's skill...
  
  Due to the lack of a yellow multiplier to the damage each of the 9 ricocheted bullets will receive the full bonus of amplify shields. Especially with The Bee this variant becomes one of the most powerful weapons in the game, due to the ""damage per ammo""-ratio, its rate of fire and the fact, that the player doesn't need to aim properly.
  
  
  Shield



Antagonist (Seraph) - Deflects enemy bullets with increased damage toward nearby enemies. High Damage Reduction and Capacity. Launches homing balls of slag at its attackers. A good overall shield for Gaige.   
Black Hole (legendary) - quoting Borderlands Wiki:


  This shield can be extremely effective when used by a Mechromancer investing heavily in the Little Big Trouble tree (specifically Wires Don't Talk, Electrical Burn and Myelin) and Blood Soaked Shields. Once the shield is depleted, the singularity effect will momentarily stun most enemies in the area while pulling them in for its deadly nova blast. A single kill will then recharge the shield to full capacity, immediately readying another nova. This strategy is particularly deadly under heavy fire, where the shield will be depleted almost immediately after being recharged.
  
  The Black Hole also makes a good shield for Deathtrap with Gaige's Sharing is Caring skill, because the singularity will pull enemies into Melee range for Deathtrap.   

The Bee (legendary amplify shield) - High amp shot damage, 0 amp shot drain. Lowered shield capacity. Increased shield recharge rate. Increased recharge delay.
This increases your weapons' damage at the cost of lower defensive capability. If you find that your Mechromancer's weapons' damage are lacking, you might want to use this shield. Works best with high fire rate weapons like the Shredifier and the Avenger. The Best Friends Forever skill tree's 'Fancy Mathematics' or 'Unstoppable Force' skills, or Ordered Chaos' Blood Soaked Shields skill will help keep this shield at full capacity.

",galacticninja,https://gaming.stackexchange.com/users/4797,http://gaming.stackexchange.com/questions/149664/is-the-mechromancers-little-big-trouble-tree-worthwhile-in-uvhm-72-level-cap,CULTURE,gaming.stackexchange.com,0.8888888888888888,0.7777777777777778,0.0,0.6666666666666666,0.3333333333333333,1.0,0.7777777777777778,0.5555555555555556,0.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.0,0.7777777777777778,0.8888888888888888,0.7777777777777778,0.8888888888888888,0.8888888888888888,0.8666666666666666,0.0,0.3333333333333333,1.0,0.7777777777777778,Is the machinist's little trouble tree worth it in the uvhm?,"So far, the tree seems rather underwhelming, especially the low-tier skills like Myelin, More Pep, Strength of 5 gorillas, etc.

Evil Enchantress apparently doesn't affect shock, fire and acid direct damage; it only buffs the status effects which is pretty pointless when slagging an enemy does 3X damage.

Shock storm doesn't sound useful as most enemies won't be bunched up enough.

On the other hand, the damage buffs from Wires Don't Talk and Interspersed Outburst look very useful. Make it Sparkle also apparently gives Deathtrap massive additional damage of up to 3X.

Is it worthwhile to spec into this tree just for the end-tier perks?
","I have a Mechromancer character focusing on the 'Best Friends Forever' and the 'Little Big Trouble' skill trees (no Anarchy from 'Ordered Chaos') that I've been playing from TVHM to UVHM with UVH Upgrade Pack Two.  As long as you have gear that will supplement Gaige's Little Big Trouble skills, you should be able to do fine on UVHM.

The most important skill in the Little Big Trouble skill tree is probably 'Wires Don't Talk' (increases all Shock and Electrocute Damage that you inflict). Due to that, I use gear that focuses on taking advantage of that skill.

Instead of More Pep, focus your points into another skill. More Pep's description is misleading, as described here. 


  Increased Elemental Chance effects are applied multiplicatively, not additively. For example, a base 20% Burn Chance with a 30% bonus will result not in 50% Burn Chance, but in 0.2 + (0.2 * 0.3) = 26% Burn Chance.   


Although, if you have a class mod that gives a bonus to More Pep, like Zapper or Legendary Catalyst, you might want to assign at least one point to the skill to get the bonuses given by that class mod.

LBT's The Stare is pretty weak (damage does not scale well) in UVHM. It also has bugs detailed here. It's pretty much a waste of a skill point.  BFF's Explosive Clap seems to scale just fine in UVHM.

Gear that helps take advantage of Little Big Trouble skills:

Class Mods


Zapper, preferably 'Wired' (gives most bonus damage to 'Wires Don't Talk') and blue or purple rarity  (Note that the Zapper class mod's description is misleading, and due to that, the mods below are better, IMO.)  
Necromancer, preferably 'Chaotic Evil' (bonus fire rate and critical damage) and the version that gives the most damage to 'Wires Don't Talk', and blue or purple rarity. This is a TTAODK class mod. More details here.
Legendary Catalyst (UVH Upgrade Pack Two class mod) -  +5 Wires Don't Talk, +5 Evil Enchantress, +5 More Pep, +5 Electrical Burn, +5 Interspersed Outburst; bonus to Team Elemental Effect Dmg - this is probably the best class mod (and the rarest) for a Mechromancer looking to spec into the 'Little Big Trouble' tree.


Relics

An Elemental Relic (common) or a Bone of the Ancients (e-tech) that increases shock damage. The Bone of the Ancients also increases the Action Skill recharge rate, which can allow you to summon Deathtrap sooner.

Grenade Mods


Quasar (legendary, shock-element only)   
Storm Front (legendary, shock-element only) 
Chain Lightning (legendary, shock-element only, TTAODK) - Always Shock. Regenerates grenade ammo over time. Shoots a bolt of lightning straight forward that explodes on impact and arcs to nearby targets.
Quoting Borderlands wiki:


  The Chain Lightning is ideally suited for Gaige builds with heavy investment in the Little Big Trouble tree (specifically Wires Don't Talk, Electrical Burn and Myelin). Its arcing effect can also help a similar build to hit targets at range with a high Anarchy stack, as it can mitigate the accuracy penalty.
  
  The Chain Lightning may pair exceptionally well with the Grog Nozzle, Rubi, and other Moxxi-brand weapons for health restoration. Because the damage from the grenade is practically instantaneous, health may be replenished as soon as the grenade is thrown. Adding to this end are its arcing effect to damage multiple enemies and ability to pass through some surfaces. As aim need not be precise in close- to mid-range, one throw may serve as a panic button when low on health. 
  Shock 'Bouncing Bonny'
  Shock 'Crossfire'    
  Magic Missile - Always slag. Grenades slowly regenerate over time. Two (Blue) or Four (Purple) child grenades home in on targets and explode instantly.
  This is mostly for slagging and for helping to heal with the Rubi. I opt to go with the Magic Missile if I am playing solo or if my co-op allies don't have much slagging capabilities. Otherwise, using a shock damage-dealing grenade mod is better.
  
  
  Shock-only weapons



Thunderball Fists, preferably 'Binary' (one trigger squeeze fires two shots) - deals heavy shock damage  
Little Evie, preferably 'Binary' - killing an enemy increases action skill cooldown rate by 12%; allows you to summon Deathtrap sooner.
Florentine, preferably 'Consummate' (more damage) - a Seraph SMG that fires shock projectiles which deal bonus slag damage on impact.  


Elemental weapons that have shock versions


Rubi, preferably 'Binary' - for healing; Any damage dealt by the player while wielding the weapon heals them, at a rate of 12% of the damage inflicted. Grenades can also be used to heal with the Rubi.
Interfacer, preferably 'Practicable' (more pellets per shot)    
Shredifier, preferably 'Rabid' or 'Ferocious' (more fire rate or damage, respectively) - deals heavy damage, eats a lot of ammo, though    
Avenger, preferably 'Hefty' (more damage) - all-around high stat SMG, regenerates bullets


FFYL weapon, or area-clearing weapons


Shock 'Norfleet' - will deal a lot of shock damage over a wide area
Shock 'Fibber' (second unique barrel version) - I'm putting this here, as IMO, it's too 'overkill' as a normal weapon. Quoting Borderlands wiki:


  The second barrel shoots bullets that shatter upon impact or ricocheting off walls, creating pellets. It bounces off walls if it doesn't hit anything and travels with the same velocity as normal pistols' bullets. For some reason, when the shatter effect and Gaige's Close Enough skill occur at the same time, the ricocheted ""homing"" pellets will do 100% damage, thus ignoring the -50% bullet damage penalty from Gaige's skill...
  
  Due to the lack of a yellow multiplier to the damage each of the 9 ricocheted bullets will receive the full bonus of amplify shields. Especially with The Bee this variant becomes one of the most powerful weapons in the game, due to the ""damage per ammo""-ratio, its rate of fire and the fact, that the player doesn't need to aim properly.
  
  
  Shield



Antagonist (Seraph) - Deflects enemy bullets with increased damage toward nearby enemies. High Damage Reduction and Capacity. Launches homing balls of slag at its attackers. A good overall shield for Gaige.   
Black Hole (legendary) - quoting Borderlands Wiki:


  This shield can be extremely effective when used by a Mechromancer investing heavily in the Little Big Trouble tree (specifically Wires Don't Talk, Electrical Burn and Myelin) and Blood Soaked Shields. Once the shield is depleted, the singularity effect will momentarily stun most enemies in the area while pulling them in for its deadly nova blast. A single kill will then recharge the shield to full capacity, immediately readying another nova. This strategy is particularly deadly under heavy fire, where the shield will be depleted almost immediately after being recharged.
  
  The Black Hole also makes a good shield for Deathtrap with Gaige's Sharing is Caring skill, because the singularity will pull enemies into Melee range for Deathtrap.   

The Bee (legendary amplify shield) - High amp shot damage, 0 amp shot drain. Lowered shield capacity. Increased shield recharge rate. Increased recharge delay.
This increases your weapons' damage at the cost of lower defensive capability. If you find that your Mechromancer's weapons' damage are lacking, you might want to use this shield. Works best with high fire rate weapons like the Shredifier and the Avenger. The Best Friends Forever skill tree's 'Fancy Mathematics' or 'Unstoppable Force' skills, or Ordered Chaos' Blood Soaked Shields skill will help keep this shield at full capacity.

"
5518,5518,8753,Understanding of Relays and associated circuitry,"I needed a simple understanding of how this circuit works.



I understand everything about this circuit apart from the diode. I also know the function of the diode is to protect the transistor but from what exactly? Is it something to do with back EMF from the coil? I'm not too sure. Also I needed to confirm if the relay will function correctly with a 9V supply (regulated or unregulated). The datasheet of the relay is attached here and the part I'm going to use is '40.61' on page 20 of the datasheet.

Also any tips for making this circuit work more efficiently. Note I am going to use the relay for no more than 16A at 230VAC at 50Hz.

Thanks
",David Norman,https://electronics.stackexchange.com/users/10082,"First the diode. An inductor resists to changes in current. So if you switch off the transistor the relay coil will try to keep the current flowing, it becomes a current source. If there would be a low resistance path that would only create a low voltage, according to Ohm's Law. But if there's no way out for the current the voltage will rise to several tens of volts, and destroy the transistor. The diode provides a low resistance path where the current is drained to the positive power supply. BTW, a Schottky diode is a better choice here.

R1 and Q1 look OK. The BC546B has an \$\mathrm{H_{FE}}\$ of 200 minimum, and with a 5V input you have 1 mA base current, so the 200 mA collector current is more than sufficient.
",stevenvh,https://electronics.stackexchange.com/users/2064,http://electronics.stackexchange.com/questions/33844/understanding-of-relays-and-associated-circuitry,TECHNOLOGY,electronics.stackexchange.com,0.6666666666666666,0.6666666666666666,0.0,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.0,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,1.0,Understand relays and related circuits,"I needed a simple understanding of how this circuit works.



I understand everything about this circuit apart from the diode. I also know the function of the diode is to protect the transistor but from what exactly? Is it something to do with back EMF from the coil? I'm not too sure. Also I needed to confirm if the relay will function correctly with a 9V supply (regulated or unregulated). The datasheet of the relay is attached here and the part I'm going to use is '40.61' on page 20 of the datasheet.

Also any tips for making this circuit work more efficiently. Note I am going to use the relay for no more than 16A at 230VAC at 50Hz.

Thanks
","The first is the diode. Inductors are resistant to changes in current. So if you turn off the transistor, the relay coil will try to keep the current flowing and it becomes a current source. If there is a low resistance path, only a low voltage will be generated, according to Ohm's law. But if there is no way out for the current, the voltage will rise to tens of volts and destroy the transistor. The diode provides a low resistance channel, and the current is discharged to the positive power supply. By the way, a Schottky diode is a better choice."
4528,4528,7175,Android- R.java file not found,"While working with an android project .I'm stuck with R.java file which is not found even I clean the project(project---->clean).But that file still not found .Even I create a new project the same problem occurs .
what I need to do ? I'm expecting the valuable replies from which I could overcome this problem 
",Rakesh L,https://stackoverflow.com/users/1870586,"
click  Project --> Build Automatically
check build automatically
clean the project

",Hussain Akhtar Wahid 'Ghouri',https://stackoverflow.com/users/1283215,http://stackoverflow.com/questions/15201166/android-r-java-file-not-found,STACKOVERFLOW,stackoverflow.com,0.6666666666666666,0.5,0.0,1.0,1.0,1.0,0.5,0.5,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.5,0.8333333333333334,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,1.0,Android-r.java file not found,"When dealing with an Android project, I am stuck by the r.java file. Even if I clean the project (Project -- > clean), I can't find the file. Even if I create a new project, the same problem will occur.","
click  Project --> Build Automatically
check build automatically
clean the project

"
5525,5525,8772,Can a PC have more than one Default Gateway?,"I know that a PC can have multiple network adapters each of which with different network identifiers (IP,MAC etc.). 

My question is, can a certain PC have more than one active default gateway? And if so, how does the PC (or better say the OS) knows to what adapter use for any given packet?
",user4537,https://serverfault.com/users/106155,"The default gateway is the route use if none of the other routes match. So by that definition, there can be only one at a time. 

Except not really, because your routing rules might be more complicated. Modern versions of Linux, for example, support using multiple completely independent routing tables, and making packet-by-packet determination as to which table to consult. So for example, perhaps you have one network configuration used for normal traffic, but a completely different routing table for your web browser. Or perhaps you have another routing table that's only used for packets with specific TOS bits set. But each would have its own default gateway which would reflect the default route for that specific routing table.

Normally, the routing table is as simple as, ""local traffic to the local interface, everything else to the router."" But if you're using a more complicated network setup, then the tools exist to cope with whatever network scenario you can dream up.
",tylerl,https://serverfault.com/users/6800,http://serverfault.com/questions/347032,TECHNOLOGY,serverfault.com,0.6666666666666666,1.0,0.0,0.5,1.0,1.0,0.6666666666666666,0.5,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.5,0.5,0.0,0.5,0.0,1.0,0.8333333333333334,0.8333333333333334,1.0,1.0,0.9,0.5,0.0,1.0,1.0,Can a computer have multiple default gateways?,"I know that a PC can have multiple network adapters each of which with different network identifiers (IP,MAC etc.). 

My question is, can a certain PC have more than one active default gateway? And if so, how does the PC (or better say the OS) knows to what adapter use for any given packet?
","The default gateway is the route use if none of the other routes match. So by that definition, there can be only one at a time. 

Except not really, because your routing rules might be more complicated. Modern versions of Linux, for example, support using multiple completely independent routing tables, and making packet-by-packet determination as to which table to consult. So for example, perhaps you have one network configuration used for normal traffic, but a completely different routing table for your web browser. Or perhaps you have another routing table that's only used for packets with specific TOS bits set. But each would have its own default gateway which would reflect the default route for that specific routing table.

Normally, the routing table is as simple as, ""local traffic to the local interface, everything else to the router."" But if you're using a more complicated network setup, then the tools exist to cope with whatever network scenario you can dream up.
"
1898,1898,3020,House rules to make the cloister less of a game winning tile in Carcassonne?,"In my experience, cloister tiles in Carcassonne are often ""too lucky"". If you draw a cloister tile in the beginning of the game, it will typically still require an investment of quite a bit of ""meeple"" time to obtain the full 9 points, which makes it a fair trade-off. However, after about half of the game, it's relatively likely that you can ""parachute"" a cloister tile in some spot and get 8 or 9 points immediately. This adds a lot of randomness to the game.

What house rules work well to diminish this effect?
",Erik P.,https://boardgames.stackexchange.com/users/30,"I have never had this experience with Carcassonne either - typically in our games it's more likely that a late-game cloister will be wasted because the player doesn't have the meeples to spare for it.

Even an 8-point late game cloister will be outpaced by a decent sized field, and it will tie up that meeple too.

The other factor that can affect this is experience of the players - experienced folks are wary of creating an easy 9-point-parachute-cloister spot on the board and will avoid it if they can.
",lilserf,https://boardgames.stackexchange.com/users/32,http://boardgames.stackexchange.com/questions/8/house-rules-to-make-the-cloister-less-of-a-game-winning-tile-in-carcassonne,CULTURE,boardgames.stackexchange.com,1.0,0.8888888888888888,0.0,0.6666666666666666,0.0,0.6666666666666666,0.4444444444444444,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,1.0,0.0,0.7777777777777778,0.6666666666666666,0.5555555555555556,0.8888888888888888,0.8888888888888888,0.6666666666666667,0.3333333333333333,0.0,1.0,0.8888888888888888,"In karkasson, let the cloister be less like the winning tile house rule?","In my experience, Carlsson's cloister tiles are usually ""too lucky."". If you draw a cloister tile at the beginning of the game, it usually still takes quite a lot of time to get a full score of 9, which is a fair trade-off. However, after about half of the game, you are likely to ""parachute"" a cloister tile somewhere and get 8 or 9 points immediately. This adds a lot of randomness to the game.","I have never had this experience with Carcassonne either - typically in our games it's more likely that a late-game cloister will be wasted because the player doesn't have the meeples to spare for it.

Even an 8-point late game cloister will be outpaced by a decent sized field, and it will tie up that meeple too.

The other factor that can affect this is experience of the players - experienced folks are wary of creating an easy 9-point-parachute-cloister spot on the board and will avoid it if they can.
"
595,595,930,What's going wrong when I reproject raster in EPSG:32115 in QGIS?,"I wish to make a QGIS project with an orthoimagery layer and a vector layer of GPS points. I'm using QGIS 2.8.2, 64 bit, in Windows 7 on a Lenova t430 laptop. Raster is in EPSG: 32115 (mercator, NAD83, Eastern New York): I add that layer first. When I add a *.gpx layer, which is in EPSG4326 (Lat/Long) WGS84, the points display 1000 km south from where they should be. When I add the layers in the opposite order, the raster layer ends up way up in Canada somewhere. No amount of reprojecting of either layer seems to be helping. Do you have any suggestions?
",Seth Bigelow,https://gis.stackexchange.com/users/55632,"The best way to find out which layer is correct, is to set the project CRS to EPSG:3857 with on-the-fly-reprojection enabled, then load a Google or Openstreetmap background via the OpenLayers plugin, then add your layers and check their layer CRS.

Then you see which layer ist placed on the right spot, and which might have a wrong CRS.



BTW this page http://gis.ny.gov/gateway/mg/2014/columbia/#sp notes that the data is in New York State Plane NAD 83 (2011), US Survey Feet , which is EPSG:2260 for Eastern New York. Sometimes QGIS misreads the units on guessing the CRS. You can use Set CRS for Layer to correct it.
",AndreJ,https://gis.stackexchange.com/users/9159,http://gis.stackexchange.com/questions/155503/whats-going-wrong-when-i-reproject-raster-in-epsg32115-in-qgis,TECHNOLOGY,gis.stackexchange.com,1.0,0.6666666666666666,0.0,1.0,1.0,1.0,0.5,0.5,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9,0.5,1.0,0.0,1.0,"When I re project the grating in QGIS of EPSG: 32115, what's the problem?","I want to do a QGIS project with a orthophoto layer and a GPS point vector layer. I use qgs2.8.2 64 bit in Windows 7 on my Lenova t430 laptop. Grating in EPSG: 32115 (Mercator, nad83, Eastern New York): I add this layer first. When I add a *. GPX layer (in epsg4326 (lat / long) WGS84), these points are displayed 1000 km south of where they should be. When I add layers in reverse order, the raster layer ends somewhere in Canada. No amount of condemnation on any level seems to help. Do you have any suggestions?","The best way to find out which layer is correct, is to set the project CRS to EPSG:3857 with on-the-fly-reprojection enabled, then load a Google or Openstreetmap background via the OpenLayers plugin, then add your layers and check their layer CRS.

Then you see which layer ist placed on the right spot, and which might have a wrong CRS.



BTW this page http://gis.ny.gov/gateway/mg/2014/columbia/#sp notes that the data is in New York State Plane NAD 83 (2011), US Survey Feet , which is EPSG:2260 for Eastern New York. Sometimes QGIS misreads the units on guessing the CRS. You can use Set CRS for Layer to correct it.
"
3353,3353,5350,Magento SendMail with attachment,"I have been working on a custom extension and I need a function to send the generated CSV file. Can you please let me know what might be the possible error in it.

protected function _sendCSV($filename, $subject, $last_update, $now) {
    $template_id = ""svm_export_email"";
    $email_template =  Mage::getModel('core/email_template')-&gt;loadDefault($template_id)-&gt;setSubject($subject."" ["".$now.""]"");
    $template_variables = array(
        'file_name' =&gt; $filename,
        'last_update' =&gt; $last_update,
        'now' =&gt;$now,
        );
    $email_template-&gt;getProcessedTemplate($template_variables);

    $sender = array('My Team' =&gt; Mage::getStoreConfig('trans_email/ident_general/email'));
    $email_template-&gt;setFrom($sender);


    $file = Mage::getBaseDir('var') . DS .'SVM'. DS .date('Y'). DS .date('m'). DS .$filename;
    $attachment = $email_template-&gt;getMail()-&gt;createAttachment(file_get_contents($file));
    $attachment-&gt;filename = $filename;

    try {
        $email_template-&gt;send('thecoderin@gmail.com','My Gmail');
    } catch (Exception $e) {
        Mage::log($e-&gt;getMessage(), NULL, self::LOG);
        return false;
    }
    Mage::log($filename."" File sent through mail"", NULL, self::LOG);
    return true;
}


I am getting the following error on invoking the function:

exception 'Exception' with message 'This letter cannot be sent.' in /my/magento/root/app/code/core/Mage/Core/Model/Email/Template.php:398


Thanks!
",thecoderin,https://magento.stackexchange.com/users/22911,"I found an alternate solution using Zend Mail and it works for me.

protected function _sendCSV($filename, $subject, $last_update, $now) {
    $template_id = ""svm_export_email"";
    $emailTemplate = Mage::getModel('core/email_template')-&gt;loadDefault($template_id);
    $template_variables = array(
        'file_name' =&gt; $filename,
        'last_update' =&gt; $last_update,
        'now' =&gt;$now,
        );
    $storeId = Mage::app()-&gt;getStore()-&gt;getId();
    $processedTemplate = $emailTemplate-&gt;getProcessedTemplate($template_variables);

    $recipients = array(
        ""SVM"" =&gt; Mage::getStoreConfig('svm_modules/svm_export/email'),
        );

    $subject .= "" ["".$now.""]"";
    $sender = Mage::getStoreConfig('trans_email/ident_general/email');

    $file = Mage::getBaseDir('var') . DS .'SVM'. DS .date('Y'). DS .date('m'). DS .$filename;
    $attachment = file_get_contents($file);

    try {
        $z_mail = new Zend_Mail('utf-8');

        $z_mail-&gt;setBodyHtml($processedTemplate)
            -&gt;setSubject($subject)
            -&gt;addTo($recipients)
            -&gt;setFrom($sender, ""My Team"");

        $attach = new Zend_Mime_Part($attachment);
        $attach-&gt;type = 'application/csv';
        $attach-&gt;disposition = Zend_Mime::DISPOSITION_INLINE;
        $attach-&gt;encoding    = Zend_Mime::ENCODING_8BIT;
        $attach-&gt;filename    = $filename;

        $z_mail-&gt;addAttachment($attach);
        $z_mail-&gt;send();
        Mage::log(""Mail Sent"", NULL, self::LOG);
    } catch (Exception $e) {
        Mage::log($e-&gt;getMessage(), NULL, self::LOG);
        return false;
    }
    return true;

}


Thanks for all the support. I believe this may help someone.
",thecoderin,https://magento.stackexchange.com/users/22911,http://magento.stackexchange.com/questions/62857/magento-sendmail-with-attachment,TECHNOLOGY,magento.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,1.0,0.6666666666666666,1.0,0.4444444444444444,0.4444444444444444,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,1.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,0.8888888888888888,Magento sendmail with attachments,"I have been working on a custom extension and I need a function to send the generated CSV file. Can you please let me know what might be the possible error in it.

protected function _sendCSV($filename, $subject, $last_update, $now) {
    $template_id = ""svm_export_email"";
    $email_template =  Mage::getModel('core/email_template')-&gt;loadDefault($template_id)-&gt;setSubject($subject."" ["".$now.""]"");
    $template_variables = array(
        'file_name' =&gt; $filename,
        'last_update' =&gt; $last_update,
        'now' =&gt;$now,
        );
    $email_template-&gt;getProcessedTemplate($template_variables);

    $sender = array('My Team' =&gt; Mage::getStoreConfig('trans_email/ident_general/email'));
    $email_template-&gt;setFrom($sender);


    $file = Mage::getBaseDir('var') . DS .'SVM'. DS .date('Y'). DS .date('m'). DS .$filename;
    $attachment = $email_template-&gt;getMail()-&gt;createAttachment(file_get_contents($file));
    $attachment-&gt;filename = $filename;

    try {
        $email_template-&gt;send('thecoderin@gmail.com','My Gmail');
    } catch (Exception $e) {
        Mage::log($e-&gt;getMessage(), NULL, self::LOG);
        return false;
    }
    Mage::log($filename."" File sent through mail"", NULL, self::LOG);
    return true;
}


I am getting the following error on invoking the function:

exception 'Exception' with message 'This letter cannot be sent.' in /my/magento/root/app/code/core/Mage/Core/Model/Email/Template.php:398


Thanks!
","I found an alternate solution using Zend Mail and it works for me.

protected function _sendCSV($filename, $subject, $last_update, $now) {
    $template_id = ""svm_export_email"";
    $emailTemplate = Mage::getModel('core/email_template')-&gt;loadDefault($template_id);
    $template_variables = array(
        'file_name' =&gt; $filename,
        'last_update' =&gt; $last_update,
        'now' =&gt;$now,
        );
    $storeId = Mage::app()-&gt;getStore()-&gt;getId();
    $processedTemplate = $emailTemplate-&gt;getProcessedTemplate($template_variables);

    $recipients = array(
        ""SVM"" =&gt; Mage::getStoreConfig('svm_modules/svm_export/email'),
        );

    $subject .= "" ["".$now.""]"";
    $sender = Mage::getStoreConfig('trans_email/ident_general/email');

    $file = Mage::getBaseDir('var') . DS .'SVM'. DS .date('Y'). DS .date('m'). DS .$filename;
    $attachment = file_get_contents($file);

    try {
        $z_mail = new Zend_Mail('utf-8');

        $z_mail-&gt;setBodyHtml($processedTemplate)
            -&gt;setSubject($subject)
            -&gt;addTo($recipients)
            -&gt;setFrom($sender, ""My Team"");

        $attach = new Zend_Mime_Part($attachment);
        $attach-&gt;type = 'application/csv';
        $attach-&gt;disposition = Zend_Mime::DISPOSITION_INLINE;
        $attach-&gt;encoding    = Zend_Mime::ENCODING_8BIT;
        $attach-&gt;filename    = $filename;

        $z_mail-&gt;addAttachment($attach);
        $z_mail-&gt;send();
        Mage::log(""Mail Sent"", NULL, self::LOG);
    } catch (Exception $e) {
        Mage::log($e-&gt;getMessage(), NULL, self::LOG);
        return false;
    }
    return true;

}


Thanks for all the support. I believe this may help someone.
"
3164,3164,5037,House rules to make the cloister less of a game winning tile in Carcassonne?,"In my experience, cloister tiles in Carcassonne are often ""too lucky"". If you draw a cloister tile in the beginning of the game, it will typically still require an investment of quite a bit of ""meeple"" time to obtain the full 9 points, which makes it a fair trade-off. However, after about half of the game, it's relatively likely that you can ""parachute"" a cloister tile in some spot and get 8 or 9 points immediately. This adds a lot of randomness to the game.

What house rules work well to diminish this effect?
",Erik P.,https://boardgames.stackexchange.com/users/30,"One option that I've used before is to disallow placing cloister tiles in spots where they are adjacent to more than three existing tiles.
",Erik P.,https://boardgames.stackexchange.com/users/30,http://boardgames.stackexchange.com/questions/8/house-rules-to-make-the-cloister-less-of-a-game-winning-tile-in-carcassonne,CULTURE,boardgames.stackexchange.com,1.0,0.7777777777777778,0.3333333333333333,0.5,0.6666666666666666,0.5,0.6666666666666666,0.5555555555555556,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9,0.6666666666666666,0.3333333333333333,0.0,0.8888888888888888,"In karkasson, let the cloister be less like the winning tile house rule?","In my experience, Carlsson's cloister tiles are usually ""too lucky."". If you draw a cloister tile at the beginning of the game, it usually still takes quite a lot of time to get a full score of 9, which is a fair trade-off. However, after about half of the game, you are likely to ""parachute"" a cloister tile somewhere and get 8 or 9 points immediately. This adds a lot of randomness to the game.","One option that I've used before is to disallow placing cloister tiles in spots where they are adjacent to more than three existing tiles.
"
491,491,766,EE control panel dashboard search field,"the search field in EE's dashboard doesn't seem to find anything. what is this field supposed to search?
",P..,https://expressionengine.stackexchange.com/users/1962,"I'd recommend using Switchboard as I guess it will give you more of the functions and results you'd expect from a search in the CP.
",Marc,https://expressionengine.stackexchange.com/users/847,http://expressionengine.stackexchange.com/questions/21510/ee-control-panel-dashboard-search-field,TECHNOLOGY,expressionengine.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,1.0,0.6666666666666666,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.6666666666666666,0.0,0.4444444444444444,0.5555555555555556,0.3333333333333333,0.8888888888888888,0.6666666666666666,0.4,1.0,0.0,0.3333333333333333,0.8888888888888888,EE control panel search fields,The search field in the EE dashboard does not appear to find anything. What should this field search for?,"I'd recommend using Switchboard as I guess it will give you more of the functions and results you'd expect from a search in the CP.
"
4912,4912,7821,content to display by month in archive always shows current month rather then the month selected?,"on this http://ee2.acer.edu.au/rd/archive/2013/April

I have this code 

{exp:channel:entries channel=""research-developments"" status=""Featured|Open"" orderby=""entry_date"" sort=""desc""  dynamic=""off"" display_by=""month"" limit=""1""}


but it always shows latest month so at the moment I have may for all archives when I need it to display each for each section , any ideas ?
",Andrew,https://expressionengine.stackexchange.com/users/1533,"If dynamic is ""off"", the channel:entries isn't influenced by URL parameters.
",Robson Sobral,https://expressionengine.stackexchange.com/users/343,http://expressionengine.stackexchange.com/questions/10566/content-to-display-by-month-in-archive-always-shows-current-month-rather-then-th,TECHNOLOGY,expressionengine.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.3333333333333333,0.0,0.6666666666666666,1.0,"What is displayed by month in the archive always shows the current month, not the selected month?","on this http://ee2.acer.edu.au/rd/archive/2013/April

I have this code 

{exp:channel:entries channel=""research-developments"" status=""Featured|Open"" orderby=""entry_date"" sort=""desc""  dynamic=""off"" display_by=""month"" limit=""1""}


but it always shows latest month so at the moment I have may for all archives when I need it to display each for each section , any ideas ?
","If dynamic is ""off"", then channel: entries are not affected by the URL parameter."
2353,2353,3750,Call a chain of WebRequest.BeginGetResponse in sync'ed fashion,"I am writing a Portable Class Library to be shared by desktop and WP8. In the library there is a method to get data from a website, in which method a chain of web requests have to be made in synchronized way and in certain order, result from each response feeds the next request, only the final response is interesting to user.

If this is a desktop .NET library, I would use GetResponse() and have all the logic in one method. I would invoke this whole method in a background thread to avoid blocking UI interaction. 

In PCL/WP8 there's only BeginGetResponse(), is there a design pattern or syntactic sugar I can leverage to write the synchronized call chain in a sequential way instead of having a bunch of callback methods?
",NS.X.,https://stackoverflow.com/users/986080,"HttpClient would be a better choice. If you can't use it for any reason, wrap BeginGetResponse/BeginGetResponse with Task.Factory.FromAsync, as an extension method:

static public Task&lt;WebResponse&gt; GetResponseAsTaskAsync(this WebRequest @this)
{
    return Task.Factory.FromAsync(
         (asyncCallback, state) =&gt;
             @this.BeginGetResponse(asyncCallback, state),
         (asyncResult) =&gt;
             @this.EndGetResponse(asyncResult), null);
}


Then you do a blocking call like this:

var response = request.GetResponseAsTaskAsync().Result;


If you do a series of request, one after another, you should keep this logic asynchronous and let the client of your PCL library to decide whether to block or not. Something like this:

static public async Task&lt;WebResponse&gt; GetManyResponsesAsync(string[] urls)
{
    WebResponse lastResponse = null;
    foreach (url in urls)
    {
        var request = WebRequest.Create(url);
        var response = await request.GetResponseAsTaskAsync();
        // .. process response
        lastResponse = response;
    }
    return lastResponse;
}


The caller would have a choice to await on the result of GetManyResponsesAsync, or block with GetManyResponsesAsync().Result.
",Noseratio,https://stackoverflow.com/users/1768303,http://stackoverflow.com/questions/22599878/call-a-chain-of-webrequest-begingetresponse-in-synced-fashion,STACKOVERFLOW,stackoverflow.com,0.6666666666666666,0.4444444444444444,0.0,0.0,1.0,0.6666666666666666,0.6666666666666666,0.4444444444444444,0.3333333333333333,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.3333333333333333,1.0,0.3333333333333333,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.8,0.6666666666666666,0.6666666666666666,1.0,0.8888888888888888,Call webrequest.begingetresponse chain synchronously,"I am writing a Portable Class Library to be shared by desktop and WP8. In the library there is a method to get data from a website, in which method a chain of web requests have to be made in synchronized way and in certain order, result from each response feeds the next request, only the final response is interesting to user.

If this is a desktop .NET library, I would use GetResponse() and have all the logic in one method. I would invoke this whole method in a background thread to avoid blocking UI interaction. 

In PCL/WP8 there's only BeginGetResponse(), is there a design pattern or syntactic sugar I can leverage to write the synchronized call chain in a sequential way instead of having a bunch of callback methods?
","HttpClient would be a better choice. If you can't use it for any reason, wrap BeginGetResponse/BeginGetResponse with Task.Factory.FromAsync, as an extension method:

static public Task&lt;WebResponse&gt; GetResponseAsTaskAsync(this WebRequest @this)
{
    return Task.Factory.FromAsync(
         (asyncCallback, state) =&gt;
             @this.BeginGetResponse(asyncCallback, state),
         (asyncResult) =&gt;
             @this.EndGetResponse(asyncResult), null);
}


Then you do a blocking call like this:

var response = request.GetResponseAsTaskAsync().Result;


If you do a series of request, one after another, you should keep this logic asynchronous and let the client of your PCL library to decide whether to block or not. Something like this:

static public async Task&lt;WebResponse&gt; GetManyResponsesAsync(string[] urls)
{
    WebResponse lastResponse = null;
    foreach (url in urls)
    {
        var request = WebRequest.Create(url);
        var response = await request.GetResponseAsTaskAsync();
        // .. process response
        lastResponse = response;
    }
    return lastResponse;
}


The caller would have a choice to await on the result of GetManyResponsesAsync, or block with GetManyResponsesAsync().Result.
"
1694,1694,2679,FIPS 140 compliance for encrypted files,"Does FIPS 140-2 require specific key sizes, or does it have specific requirements for the data?
In other words, if I encrypt a file, how I can check whether it is FIPS-compliant or not? Does only the key need to be checked, or does the encrypted file have to be checked too? If yes, is it possible to elaborate on how to check an encrypted file for FIPS compliance?
",user39576,https://crypto.stackexchange.com/users/2854,"You cannot tell anything related to FIPS 140 by looking at a key or by looking at a file. FIPS 140 doesn't say anything about the choice of encryption algorithm, other than requiring that all every encryption algorithm must be “approved security function” (as defined in the glossary) and there must be at least 1.

FIPS 140 is all about the module, i.e. the software or hardware component that performs the encryption and decryption. The standard sets security requirements for how keys are stored, how access to keys is controlled and so on.

If you have an encrypted file, you cannot tell whether it was encrypted by a FIPS 140-compliant module or not: an encrypted file looks like any other encrypted file produced from the same plaintext with the same key no matter who or what performed the encryption. If you have a key, you cannot tell whether that key is used in a FIPS 140-compliant module or not; although if you can access the key outside the module, it's likely that either the module isn't compliant — because it shouldn't let keys escape — or an authorized operator misused the module and let the key leak. There is only a way to be sure that a key or encrypted file did not come from a FIPS 140-compliant module, which is if the key or algorithm is not one of the approved security functions (as defined in other standards).
",Gilles,https://crypto.stackexchange.com/users/214,http://crypto.stackexchange.com/questions/5743/fips-140-compliance-for-encrypted-files,TECHNOLOGY,crypto.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,1.0,1.0,1.0,0.5555555555555556,0.3333333333333333,0.3333333333333333,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,1.0,FIPS 140 compliant encrypted files,"Does FIPS 140-2 require specific key sizes, or does it have specific requirements for the data?
In other words, if I encrypt a file, how I can check whether it is FIPS-compliant or not? Does only the key need to be checked, or does the encrypted file have to be checked too? If yes, is it possible to elaborate on how to check an encrypted file for FIPS compliance?
","You cannot tell anything related to FIPS 140 by looking at a key or by looking at a file. FIPS 140 doesn't say anything about the choice of encryption algorithm, other than requiring that all every encryption algorithm must be “approved security function” (as defined in the glossary) and there must be at least 1.

FIPS 140 is all about the module, i.e. the software or hardware component that performs the encryption and decryption. The standard sets security requirements for how keys are stored, how access to keys is controlled and so on.

If you have an encrypted file, you cannot tell whether it was encrypted by a FIPS 140-compliant module or not: an encrypted file looks like any other encrypted file produced from the same plaintext with the same key no matter who or what performed the encryption. If you have a key, you cannot tell whether that key is used in a FIPS 140-compliant module or not; although if you can access the key outside the module, it's likely that either the module isn't compliant — because it shouldn't let keys escape — or an authorized operator misused the module and let the key leak. There is only a way to be sure that a key or encrypted file did not come from a FIPS 140-compliant module, which is if the key or algorithm is not one of the approved security functions (as defined in other standards).
"
643,643,1017,Does anybody use an external battery for iPhone?,"Do external batteries for iPhones work well?

I have an iPhone 4S 

For example, is it true that I can charge up to 6 times my iphone with this product?
",aneuryzm,https://apple.stackexchange.com/users/1114,"Yes - and most people I know fit into strongly preferring a rechargeable solution when they use the device regularly to extend power on the go.

Those that use the device occasionally or on long trips seem to gravitate to an inexpensive sled for AA batteries and carry a mix of expensive lithium cells and typical non-rechargeable cells.
",bmike,https://apple.stackexchange.com/users/5472,http://apple.stackexchange.com/questions/76186/does-anybody-use-an-external-battery-for-iphone,TECHNOLOGY,apple.stackexchange.com,1.0,0.7777777777777778,0.3333333333333333,1.0,0.3333333333333333,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.7777777777777778,1.0,0.8888888888888888,1.0,1.0,1.0,0.0,0.0,0.6666666666666666,1.0,Does anyone use the external battery of the iPhone?,"Do external batteries for iPhones work well?

I have an iPhone 4S 

For example, is it true that I can charge up to 6 times my iphone with this product?
","Yes - and most people I know fit into strongly preferring a rechargeable solution when they use the device regularly to extend power on the go.

Those that use the device occasionally or on long trips seem to gravitate to an inexpensive sled for AA batteries and carry a mix of expensive lithium cells and typical non-rechargeable cells.
"
3316,3316,5292,Transform a Binary Search Tree into a Greater Sum Tree,"Given a Binary Search Tree (where all nodes on the left child branch are less than the node), and all nodes to the right are greater/equal to the node), transform it into a Greater Sum Tree where each node contains sum of it together with all nodes greater than that node. Example diagram is here:



Looking for code review, optimizations and best practices.

public class GreaterSumTree implements Iterable {

    private TreeNode root;

    public GreaterSumTree(List&lt;Integer&gt; list) {
        create(list);
    }

    private void create (List&lt;Integer&gt; items) {
        root = new TreeNode(items.get(0));

        final Queue&lt;TreeNode&gt; queue = new LinkedList&lt;TreeNode&gt;();
        queue.add(root);

        final int half = items.size() / 2;

        for (int i = 0; i &lt; half; i++) {
            if (items.get(i) != null) {
                final TreeNode current = queue.poll();
                final int left = 2 * i + 1;
                final int right = 2 * i + 2;

                if (items.get(left) != null) {
                    current.left = new TreeNode(items.get(left));
                    queue.add(current.left);
                }
                if (right &lt; items.size() &amp;&amp; items.get(right) != null) {
                    current.right = new TreeNode(items.get(right));
                    queue.add(current.right);
                }
            }
        }
    }

    public static class TreeNode {
        private TreeNode left;
        private int item;
        private TreeNode right;

        TreeNode(int item) {
            this.item = item;
        }
    }


    public static class IntObject {
        private int sum;
    }

    /**
     * Computes the greater sum, provided the tree is BST.
     * If tree is not BST, then results are unpredictable.
     */
    public void greaterSumTree() {
        if (root == null) {
            throw new IllegalArgumentException(""root is null"");
        }
        computeSum (root, new IntObject());
    }


    private void computeSum(TreeNode node, IntObject intObj) {
        if (node != null) {
            computeSum(node.right, intObj);
            int temp = node.item;
            node.item = intObj.sum;
            intObj.sum = intObj.sum + temp;
            computeSum(node.left, intObj);
        }
    }

    /**
     * Returns the preorder representation for the given tree.
     * 
     * @return  the iterator for preorder traversal
     */
    @Override
    public Iterator iterator () {
        return new PreOrderItr();
    }

    private class PreOrderItr implements Iterator {
        private final Stack&lt;TreeNode&gt; stack;

        public PreOrderItr() {
            stack = new Stack&lt;TreeNode&gt;();
            stack.add(root);
        }

        @Override
        public boolean hasNext() {
            return !stack.isEmpty();
        }

        @Override
        public Integer next() {
            if (!hasNext()) throw new NoSuchElementException(""No more nodes remain to iterate"");

            final TreeNode node = stack.pop();           

            if (node.right != null) stack.push(node.right);
            if (node.left != null) stack.push(node.left);

            return node.item;
        }

        @Override
        public void remove() {
            throw new UnsupportedOperationException(""Invalid operation for pre-order iterator."");
        }
    }
}


Here is a test case:

public class GreaterSumTreeTest {

    @Test
    public void test() {
        Integer[] a = {1, 2, 7, 11, 15, 29, 35};
        GreaterSumTree greaterSumTree = new GreaterSumTree(Arrays.asList(a));
        greaterSumTree.greaterSumTree();

        int[] expected = {71, 87, 89, 72, 35, 42, 0};
        int[] actual = new int[a.length];
        int counter = 0;
        Iterator itr = greaterSumTree.iterator();
        while (itr.hasNext()) {
           actual[counter++] = (Integer) itr.next();
        }
        assertTrue(Arrays.equals(expected, actual));
    }

}

",JavaDeveloper,https://codereview.stackexchange.com/users/28539,"Compiler Warnings


  Iterable is a raw type. References to generic type Iterable should be parameterized


This is very easy to fix. It's horrible that you haven't fixed it already. I'm sure that you know what generics is by now so I don't need to explain it to you. Whenever you see this warning, add generics!

Iterable --> Iterable&lt;Integer&gt;

Problem solved!

Then you can get rid of the (Integer) cast next to itr.next();

Why Binary Search Tree?

My first thought, once I understood the problem your solving was: Why on earth do you have the data as a Binary Search Tree? What does the tree have to do with anything?

If this was a question given to me at an interview, I would ask them this. Why a Binary Search Tree? The operations you're doing is totally unrelated to a tree. You could just as well perform this on a regular int[]. If there is a good reason for why it has to be a Binary Search Tree then please explain it to me.

Here's a simple implementation of how to perform this on a regular int[], without using a Binary Tree:

public static void main(String[] args) {
    int[] input = new int[] { 1, 2, 7, 11, 15, 29, 35, 40  };
    int[] expected = new int[] { 139, 137, 130, 119, 104, 75, 40, 0 };
    transformToGreaterSum(input);
    System.out.println(Arrays.toString(input));
    System.out.println(Arrays.toString(expected));
}

private static void transformToGreaterSum(int[] input) {
    int sum = 0;
    for (int i = input.length - 1; i &gt;= 0; i--) {
        int prevSum = sum;
        sum += input[i];
        input[i] = prevSum;
    }
}


Note that this is also \$O(n)\$ without using any extra space.

Broken Tree

I'd also like to point out that your actual search tree does not match your image. I found out by debugging your code that your actual search tree looks like this:



The fact that it looks like this, and the fact that your algorithm works at all, is just because your input is sorted: {1, 2, 7, 11, 15, 29, 35}.

Your tree is in fact not a correct Binary Search Tree. A correct tree could look like this:



Yes, that's still a tree. It just doesn't have any left nodes (it does have seven nodes left though, I didn't remove any). A child node that is bigger than its parent should be on the right, which makes this tree right. (I love the English language)

As if that was not enough, your int[] expected says:

int[] expected = {71, 87, 89, 72, 35, 42, 0};


But your image says:

119, 137, 75, 139, 130, 104, 0, 40


Given your description:


  Given a BST, transform it into greater sum tree where each node contains sum of all nodes greater than that node. Diagram is here.


I would expect the node for 11 to get the value 15 + 29 + 35 + 40 = 119. I don't see 119 anywhere in your expected or actual result though...

Verifying a Binary Search Tree

As your question contains an incorrect tree and one of your comments below has an incorrect tree, I'd like to provide you with a method to verify a correct tree:

private static void verifyNode(TreeNode node) {
    if (node.left != null) {
        if (node.left.item &gt;= node.item) {
            throw new IllegalStateException(""node.left &gt;= node: "" + node.left.item + "" &gt;= "" + node.item);
        }
        verifyNode(node.left);
    }
    if (node.right != null) {
        if (node.right.item &lt;= node.item) {
            throw new IllegalStateException(""node.right &lt;= node: "" + node.right.item + "" &lt;= "" + node.item);
        }
        verifyNode(node.right);
    }
}


Just pass it your root node and it will verify your tree recursively. Note that there are two things this method does not verify, that are also a requirement for a Binary Search Tree:


There must be no duplicate nodes.
A unique path exists from the root to every other node.


Arrays and Lists

Speaking of int[] I wonder why your constructor takes a List&lt;Integer&gt; instead of an array: int[]. I don't think you gain anything by using a list.

The only thing you gain at the moment by using Integer rather than int is the possibility for this:

if (items.get(i) != null) {


As your input never contains null (and I see no reason why it should), I don't get the point of using that non-null check. I modified your code to use int[] instead and removed the non-null checks and all worked well still. It even got rid of some indentation steps and felt like a cleanup overall.

Iterate over what?

If you would have your Iterator as Iterator&lt;TreeNode&gt; instead of Iterator&lt;Integer&gt; you could use your iterator in your computeSum method as well as in your test method to fetch the results. This would make you have to modify your iterator implementation though (but as your tree is not a real binary search tree, it's quite broken already).

Or you could just ignore the tree structure and use arrays....

Summary

Given how many trees I've seen you implement, I really thought your code would be better than this. Your current code doesn't live up to your requirements, or your requirements are messed up. Additionally, the ""raw type"" mistake is a mistake one just should not make after having written just a few Java classes.
",Simon Forsberg,https://codereview.stackexchange.com/users/31562,http://codereview.stackexchange.com/questions/55966/transform-a-binary-search-tree-into-a-greater-sum-tree,TECHNOLOGY,codereview.stackexchange.com,1.0,0.3333333333333333,0.0,1.0,1.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.0,1.0,1.0,Convert binary search tree to large sum tree,"Given a Binary Search Tree (where all nodes on the left child branch are less than the node), and all nodes to the right are greater/equal to the node), transform it into a Greater Sum Tree where each node contains sum of it together with all nodes greater than that node. Example diagram is here:



Looking for code review, optimizations and best practices.

public class GreaterSumTree implements Iterable {

    private TreeNode root;

    public GreaterSumTree(List&lt;Integer&gt; list) {
        create(list);
    }

    private void create (List&lt;Integer&gt; items) {
        root = new TreeNode(items.get(0));

        final Queue&lt;TreeNode&gt; queue = new LinkedList&lt;TreeNode&gt;();
        queue.add(root);

        final int half = items.size() / 2;

        for (int i = 0; i &lt; half; i++) {
            if (items.get(i) != null) {
                final TreeNode current = queue.poll();
                final int left = 2 * i + 1;
                final int right = 2 * i + 2;

                if (items.get(left) != null) {
                    current.left = new TreeNode(items.get(left));
                    queue.add(current.left);
                }
                if (right &lt; items.size() &amp;&amp; items.get(right) != null) {
                    current.right = new TreeNode(items.get(right));
                    queue.add(current.right);
                }
            }
        }
    }

    public static class TreeNode {
        private TreeNode left;
        private int item;
        private TreeNode right;

        TreeNode(int item) {
            this.item = item;
        }
    }


    public static class IntObject {
        private int sum;
    }

    /**
     * Computes the greater sum, provided the tree is BST.
     * If tree is not BST, then results are unpredictable.
     */
    public void greaterSumTree() {
        if (root == null) {
            throw new IllegalArgumentException(""root is null"");
        }
        computeSum (root, new IntObject());
    }


    private void computeSum(TreeNode node, IntObject intObj) {
        if (node != null) {
            computeSum(node.right, intObj);
            int temp = node.item;
            node.item = intObj.sum;
            intObj.sum = intObj.sum + temp;
            computeSum(node.left, intObj);
        }
    }

    /**
     * Returns the preorder representation for the given tree.
     * 
     * @return  the iterator for preorder traversal
     */
    @Override
    public Iterator iterator () {
        return new PreOrderItr();
    }

    private class PreOrderItr implements Iterator {
        private final Stack&lt;TreeNode&gt; stack;

        public PreOrderItr() {
            stack = new Stack&lt;TreeNode&gt;();
            stack.add(root);
        }

        @Override
        public boolean hasNext() {
            return !stack.isEmpty();
        }

        @Override
        public Integer next() {
            if (!hasNext()) throw new NoSuchElementException(""No more nodes remain to iterate"");

            final TreeNode node = stack.pop();           

            if (node.right != null) stack.push(node.right);
            if (node.left != null) stack.push(node.left);

            return node.item;
        }

        @Override
        public void remove() {
            throw new UnsupportedOperationException(""Invalid operation for pre-order iterator."");
        }
    }
}


Here is a test case:

public class GreaterSumTreeTest {

    @Test
    public void test() {
        Integer[] a = {1, 2, 7, 11, 15, 29, 35};
        GreaterSumTree greaterSumTree = new GreaterSumTree(Arrays.asList(a));
        greaterSumTree.greaterSumTree();

        int[] expected = {71, 87, 89, 72, 35, 42, 0};
        int[] actual = new int[a.length];
        int counter = 0;
        Iterator itr = greaterSumTree.iterator();
        while (itr.hasNext()) {
           actual[counter++] = (Integer) itr.next();
        }
        assertTrue(Arrays.equals(expected, actual));
    }

}

","Compiler Warnings


  Iterable is a raw type. References to generic type Iterable should be parameterized


This is very easy to fix. It's horrible that you haven't fixed it already. I'm sure that you know what generics is by now so I don't need to explain it to you. Whenever you see this warning, add generics!

Iterable --> Iterable&lt;Integer&gt;

Problem solved!

Then you can get rid of the (Integer) cast next to itr.next();

Why Binary Search Tree?

My first thought, once I understood the problem your solving was: Why on earth do you have the data as a Binary Search Tree? What does the tree have to do with anything?

If this was a question given to me at an interview, I would ask them this. Why a Binary Search Tree? The operations you're doing is totally unrelated to a tree. You could just as well perform this on a regular int[]. If there is a good reason for why it has to be a Binary Search Tree then please explain it to me.

Here's a simple implementation of how to perform this on a regular int[], without using a Binary Tree:

public static void main(String[] args) {
    int[] input = new int[] { 1, 2, 7, 11, 15, 29, 35, 40  };
    int[] expected = new int[] { 139, 137, 130, 119, 104, 75, 40, 0 };
    transformToGreaterSum(input);
    System.out.println(Arrays.toString(input));
    System.out.println(Arrays.toString(expected));
}

private static void transformToGreaterSum(int[] input) {
    int sum = 0;
    for (int i = input.length - 1; i &gt;= 0; i--) {
        int prevSum = sum;
        sum += input[i];
        input[i] = prevSum;
    }
}


Note that this is also \$O(n)\$ without using any extra space.

Broken Tree

I'd also like to point out that your actual search tree does not match your image. I found out by debugging your code that your actual search tree looks like this:



The fact that it looks like this, and the fact that your algorithm works at all, is just because your input is sorted: {1, 2, 7, 11, 15, 29, 35}.

Your tree is in fact not a correct Binary Search Tree. A correct tree could look like this:



Yes, that's still a tree. It just doesn't have any left nodes (it does have seven nodes left though, I didn't remove any). A child node that is bigger than its parent should be on the right, which makes this tree right. (I love the English language)

As if that was not enough, your int[] expected says:

int[] expected = {71, 87, 89, 72, 35, 42, 0};


But your image says:

119, 137, 75, 139, 130, 104, 0, 40


Given your description:


  Given a BST, transform it into greater sum tree where each node contains sum of all nodes greater than that node. Diagram is here.


I would expect the node for 11 to get the value 15 + 29 + 35 + 40 = 119. I don't see 119 anywhere in your expected or actual result though...

Verifying a Binary Search Tree

As your question contains an incorrect tree and one of your comments below has an incorrect tree, I'd like to provide you with a method to verify a correct tree:

private static void verifyNode(TreeNode node) {
    if (node.left != null) {
        if (node.left.item &gt;= node.item) {
            throw new IllegalStateException(""node.left &gt;= node: "" + node.left.item + "" &gt;= "" + node.item);
        }
        verifyNode(node.left);
    }
    if (node.right != null) {
        if (node.right.item &lt;= node.item) {
            throw new IllegalStateException(""node.right &lt;= node: "" + node.right.item + "" &lt;= "" + node.item);
        }
        verifyNode(node.right);
    }
}


Just pass it your root node and it will verify your tree recursively. Note that there are two things this method does not verify, that are also a requirement for a Binary Search Tree:


There must be no duplicate nodes.
A unique path exists from the root to every other node.


Arrays and Lists

Speaking of int[] I wonder why your constructor takes a List&lt;Integer&gt; instead of an array: int[]. I don't think you gain anything by using a list.

The only thing you gain at the moment by using Integer rather than int is the possibility for this:

if (items.get(i) != null) {


As your input never contains null (and I see no reason why it should), I don't get the point of using that non-null check. I modified your code to use int[] instead and removed the non-null checks and all worked well still. It even got rid of some indentation steps and felt like a cleanup overall.

Iterate over what?

If you would have your Iterator as Iterator&lt;TreeNode&gt; instead of Iterator&lt;Integer&gt; you could use your iterator in your computeSum method as well as in your test method to fetch the results. This would make you have to modify your iterator implementation though (but as your tree is not a real binary search tree, it's quite broken already).

Or you could just ignore the tree structure and use arrays....

Summary

Given how many trees I've seen you implement, I really thought your code would be better than this. Your current code doesn't live up to your requirements, or your requirements are messed up. Additionally, the ""raw type"" mistake is a mistake one just should not make after having written just a few Java classes.
"
3684,3684,5873,How long after changing a battery will it take for the Engine Check light to come on if there are other issues,"My check engine light was on.  After my car set over the weekend it wouldn't start.  I took the battery down to a shop to be checked and charged.  When I picked it up they said I needed to replace it.  When I put the new battery in the car, the check light was off.  How long before the check light could go back on if it was something else causing a problem.
",user7906,https://mechanics.stackexchange.com/users/7906,"More than likely it would show up right away. If it was on before, and now it's off, I'd say the problem's fixed. The codes for what ever triggered the CEL would no longer be present due to the lack of battery power, so you cannot just do a scan on the vehicle. You can, however, check to ensure that battery voltage at rest and while the engine is running are ~12.5+vdc and ~14.1-14.5vdc respectively. If the alternator is producing under that or if you see the voltage ticking slowly down, it could very we'll be there is an alternator problem. I doubt it, but it's worth checking.
",Pᴀᴜʟsᴛᴇʀ2,https://mechanics.stackexchange.com/users/4152,http://mechanics.stackexchange.com/questions/14773/how-long-after-changing-a-battery-will-it-take-for-the-engine-check-light-to-com,CULTURE,mechanics.stackexchange.com,1.0,0.6666666666666666,0.0,1.0,1.0,1.0,0.5555555555555556,0.6666666666666666,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,0.8888888888888888,"If there are other problems, how long does the engine check light come on after replacing the battery","My check engine light is on. My car won't start after it stops at the weekend. I took the battery to a shop to check it. When I picked it up, they said I needed to replace it. When I put the new battery in the car, the check light went out. If the problem is caused by other reasons, how long can the check light be on.","More than likely it would show up right away. If it was on before, and now it's off, I'd say the problem's fixed. The codes for what ever triggered the CEL would no longer be present due to the lack of battery power, so you cannot just do a scan on the vehicle. You can, however, check to ensure that battery voltage at rest and while the engine is running are ~12.5+vdc and ~14.1-14.5vdc respectively. If the alternator is producing under that or if you see the voltage ticking slowly down, it could very we'll be there is an alternator problem. I doubt it, but it's worth checking.
"
3105,3105,4945,Display a field of a node that is referenced on another node via a relationship,"I have two content types, ""Stores"" and ""Offers."" In the ""Offers"" content type, there is a CCK node reference field type that references the ""Stores"" nodes.  So essentially, I create a store and if the store has an offer, I create the ""Offer"" node and select the store with which it is associated.

I have a view (a default glossary view) that displays a list of stores. I would like to display the node titles of any offers that are associated with it but I can't figure out how to do it.

I have tried to add a relationship on the node reference field then add a field that uses the relationship but the result just appears blank.
",Jamie Hollern,https://drupal.stackexchange.com/users/1319,"I finally went with something similar to Stefan's answer.  I created a module using hook_views_pre_render that checks the correct table against the node id to see if there are any related nodes.  The code is shown below.

&lt;?php

/**
 * Implementation of hook_views_pre_render()
 */
function gretna_views_pre_render(&amp;$view) {
    // Select the right view
    if ($view-&gt;name == 'stores_list') {
        // Check how many results there are
        $count = count($view-&gt;result);
        // For each result (reason we don't use foreach is every result is duplicated twice)
        for($i = 0; $i &lt; $count; $i++) {
            // Get the nid for this row
            $nid = $view-&gt;result[$i]-&gt;nid;
            // Check to see if the node has any related offers
            $result = db_query(""SELECT nid FROM {content_type_store_offers} WHERE field_offer_store_nid = %d"", $nid);
            $result = db_fetch_array($result);
            // If not false, the row has offers
            if ($result !== FALSE) {
                $view-&gt;result[$i]-&gt;users_uid = ""Yes"";
            }
            // Else it doesn't
            else {
                $view-&gt;result[$i]-&gt;users_uid = ""No"";
            }
        }
    }
}

",Jamie Hollern,https://drupal.stackexchange.com/users/1319,http://drupal.stackexchange.com/questions/4148/display-a-field-of-a-node-that-is-referenced-on-another-node-via-a-relationship,TECHNOLOGY,drupal.stackexchange.com,0.8888888888888888,0.6666666666666666,0.0,0.6666666666666666,0.3333333333333333,1.0,0.4444444444444444,0.4444444444444444,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.3333333333333333,0.8888888888888888,Fields that display nodes that are referenced on another node through a relationship,"I have two content types, ""Stores"" and ""Offers."" In the ""Offers"" content type, there is a CCK node reference field type that references the ""Stores"" nodes.  So essentially, I create a store and if the store has an offer, I create the ""Offer"" node and select the store with which it is associated.

I have a view (a default glossary view) that displays a list of stores. I would like to display the node titles of any offers that are associated with it but I can't figure out how to do it.

I have tried to add a relationship on the node reference field then add a field that uses the relationship but the result just appears blank.
","I finally went with something similar to Stefan's answer.  I created a module using hook_views_pre_render that checks the correct table against the node id to see if there are any related nodes.  The code is shown below.

&lt;?php

/**
 * Implementation of hook_views_pre_render()
 */
function gretna_views_pre_render(&amp;$view) {
    // Select the right view
    if ($view-&gt;name == 'stores_list') {
        // Check how many results there are
        $count = count($view-&gt;result);
        // For each result (reason we don't use foreach is every result is duplicated twice)
        for($i = 0; $i &lt; $count; $i++) {
            // Get the nid for this row
            $nid = $view-&gt;result[$i]-&gt;nid;
            // Check to see if the node has any related offers
            $result = db_query(""SELECT nid FROM {content_type_store_offers} WHERE field_offer_store_nid = %d"", $nid);
            $result = db_fetch_array($result);
            // If not false, the row has offers
            if ($result !== FALSE) {
                $view-&gt;result[$i]-&gt;users_uid = ""Yes"";
            }
            // Else it doesn't
            else {
                $view-&gt;result[$i]-&gt;users_uid = ""No"";
            }
        }
    }
}

"
743,743,1178,What do I do wrong to get hip aches after biking?,"I ride about 17 miles each session. After the ride, the outside of my hips sore: only the parts near the outermost joints, most likely the tendon (although this is only a guess). My knees are fine, my ankles are fine, etc.

The only thing that might not fit perfectly for me is the seat height. I'd rather have a longer post so I can lift the seat up an inch or two. Do you think this might create the soreness in the area of the outer hips? 
",RJIGO,https://bicycles.stackexchange.com/users/3628,"The web site Bike Dynamics has an online guide that could help you find the right fit. To me it sounds like you're going hard. If the thigh is swelling raising the seat could make it worse. Lowering the seat would affect knees so you need to find exact spot. You may also want to look at a roller for your Iliotibial Band, you could develop chronic ITBS if your bike fit remains poor.  
",steven houghton,https://bicycles.stackexchange.com/users/18481,http://bicycles.stackexchange.com/questions/8476/what-do-i-do-wrong-to-get-hip-aches-after-biking,CULTURE,bicycles.stackexchange.com,1.0,0.3333333333333333,0.0,0.3333333333333333,1.0,0.6666666666666666,0.5555555555555556,0.5555555555555556,0.6666666666666666,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,0.8888888888888888,1.0,0.8666666666666666,0.0,0.0,1.0,1.0,How does buttock ache do after cycling?,"I ride about 17 miles at a time. After riding, my buttocks ache on the outside: only the part near the most lateral joint, most likely the tendon (although this is only a guess). My knees are good, my ankles are good, and so on.","The web site Bike Dynamics has an online guide that could help you find the right fit. To me it sounds like you're going hard. If the thigh is swelling raising the seat could make it worse. Lowering the seat would affect knees so you need to find exact spot. You may also want to look at a roller for your Iliotibial Band, you could develop chronic ITBS if your bike fit remains poor.  
"
435,435,675,SQL Help in Access – Looking for the Absence of Data,"I am trying to find the fastest way to find all of the records in a parent table that do not have certain records in a child table. For example, I want the query to return all of the family records where there are no male children or no children at all. 

Example 1

This is painfully slow:

SELECT * FROM Families
WHERE Families.FamilyID NOT IN(SELECT FamilyID FROM Children WHERE Children.Gender=""m"")

Example 2

This is faster:

SELECT * FROM Families
WHERE NOT EXISTS(SELECT * FROM Children WHERE Children.Gender=""m"" AND Children.FamilyID = Families.FamilyID)

Example 3

This is the fastest, but I'm worried about investing in it because I can't find any documentation on it. I don't even know what it's called. For want of a better term, we have been calling it an ""anonymous query"". 

SELECT * FROM Families
LEFT JOIN
[SELECT * FROM Children WHERE Gender=""m""]. AS AliasChildren
ON Families.FamilyID=AliasChildren.FamilyID
WHERE AliasChildren.FamilyID IS NULL

So my question is this:


What is this thing called in example 3?
Is it a ""mainstream"" feature of Access that
will be supported in the future?
Where can I find documentation on
it (this might be easier once I know what it's called)?


Thanks!
",Shane Miskin,https://stackoverflow.com/users/16415,"Example 3 is termed a derived table, but you can simplify the query to this:

SELECT * FROM Families
LEFT JOIN
Children ON Families.FamilyID = Children.FamilyID AND Children.Gender=""m""
WHERE Children.FamilyID IS NULL

",Mitch Wheat,https://stackoverflow.com/users/16076,http://stackoverflow.com/questions/752048/sql-help-in-access-looking-for-the-absence-of-data,STACKOVERFLOW,stackoverflow.com,1.0,0.3333333333333333,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.3333333333333333,0.6666666666666666,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.6666666666666666,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.0,0.0,0.8888888888888888,SQL help in access - finding missing data,"I am trying to find the fastest way to find all of the records in a parent table that do not have certain records in a child table. For example, I want the query to return all of the family records where there are no male children or no children at all. 

Example 1

This is painfully slow:

SELECT * FROM Families
WHERE Families.FamilyID NOT IN(SELECT FamilyID FROM Children WHERE Children.Gender=""m"")

Example 2

This is faster:

SELECT * FROM Families
WHERE NOT EXISTS(SELECT * FROM Children WHERE Children.Gender=""m"" AND Children.FamilyID = Families.FamilyID)

Example 3

This is the fastest, but I'm worried about investing in it because I can't find any documentation on it. I don't even know what it's called. For want of a better term, we have been calling it an ""anonymous query"". 

SELECT * FROM Families
LEFT JOIN
[SELECT * FROM Children WHERE Gender=""m""]. AS AliasChildren
ON Families.FamilyID=AliasChildren.FamilyID
WHERE AliasChildren.FamilyID IS NULL

So my question is this:


What is this thing called in example 3?
Is it a ""mainstream"" feature of Access that
will be supported in the future?
Where can I find documentation on
it (this might be easier once I know what it's called)?


Thanks!
","Example 3 is termed a derived table, but you can simplify the query to this:

SELECT * FROM Families
LEFT JOIN
Children ON Families.FamilyID = Children.FamilyID AND Children.Gender=""m""
WHERE Children.FamilyID IS NULL

"
3734,3734,5949,Is there a quick way to delete Foldered bookmarks directly from Safari bookmark bar?,"I like to group my bookmarks into Folders in the Bookmark Bar.

But I cannot find an easy way to delete these bookmarks!

The only way I know to do this is to go to Show All Bookmarks, then browse down to the shortcut and select it and delete it - this totally gets in the way of workflow.

Is there any way to delete a Foldered bookmark from the bookmark bar?!

NB - I am not talking about standalone bookmarks, deleting those is easy and intuitive.
",dan8394,https://apple.stackexchange.com/users/8394,"Just delete the whole safari folder in the library directory 
",Cam,https://apple.stackexchange.com/users/133893,http://apple.stackexchange.com/questions/22042/is-there-a-quick-way-to-delete-foldered-bookmarks-directly-from-safari-bookmark,TECHNOLOGY,apple.stackexchange.com,1.0,1.0,0.0,1.0,0.6666666666666666,1.0,0.6666666666666666,0.5555555555555556,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,0.8888888888888888,1.0,1.0,0.0,0.0,0.8888888888888888,Is there a quick way to remove folded bookmarks directly from the safari bookmarks bar?,"I like to group my bookmarks into Folders in the Bookmark Bar.

But I cannot find an easy way to delete these bookmarks!

The only way I know to do this is to go to Show All Bookmarks, then browse down to the shortcut and select it and delete it - this totally gets in the way of workflow.

Is there any way to delete a Foldered bookmark from the bookmark bar?!

NB - I am not talking about standalone bookmarks, deleting those is easy and intuitive.
","Just delete the whole safari folder in the library directory 
"
4089,4089,6525,Derivation of relationship between Gibbs free energy and electrochemical cell potential,"
  Why is $\Delta G=-nFE?$


I don't understand what the motivation is behind this definition. Was it derived or just given? The textbook provides no justification for this equation. In fact, much of the book associated with the Gibbs free energy provides no justification and just says, 'This is how it is. Now go and solve some problems.'
",Greg,https://chemistry.stackexchange.com/users/1758,"There are two ways to understand this equation.  

One is to realise that (reversible ideal case)$\Delta G=W_{\text{non-expansion}}$. Therefore, in an ideal chemical cell, if the potential difference between the electrodes is $E$, to move one mole electrons across the external circuit will be $FE$, which must be equal to the decrease in gibbs free energy of the system. Hence for $n$ mole electrons tranferred at the same potential, $W_{\text{non-expansion}}=\Delta G=-nFE$. 

The fact that $\Delta G=-W_{\text{non-expansion}}$ can be derived as under:-
$$dU=\delta q+W_{\text{non-expansion}}+W_{\text{expansion}}$$
$$ds ={ \delta q/t}$$(in reversible case)
$$Tds=dU-W_{\text{non-expansion}}-W_{\text{expansion}}$$
$$W_{\text{non-expansion}}=dU+pdV-Tds$$(for constant pressure and temperature)
$$W_{\text{non-expansion}}=dH-Tds=dG$$

Another approach is to use $\mu_{electrochemical}=\mu_{chemical}+zF\phi$ where $\phi$=electric potential at the point, $z$ is the charge on the species. using this and 
$$dG_{T,P}=\sum_{i=1}^n \mu_idn_i$$
we get the required equation for $z=1$ for an electron, and considering the electrochemical potential of both the electrodes. I am unsure of a rigorous derivation for the electrochemical potential but this is some basics on it.
",Satwik Pasani,https://chemistry.stackexchange.com/users/1431,http://chemistry.stackexchange.com/questions/6826/derivation-of-relationship-between-gibbs-free-energy-and-electrochemical-cell-po,SCIENCE,chemistry.stackexchange.com,0.7777777777777778,0.4444444444444444,0.0,1.0,1.0,1.0,0.6666666666666666,0.4444444444444444,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.8888888888888888,0.8333333333333334,0.8333333333333334,1.0,1.0,0.9,0.0,0.0,1.0,1.0,Derivation of the relationship between Gibbs free energy and electrochemical cell potential,"
  Why is $\Delta G=-nFE?$


I don't understand what the motivation is behind this definition. Was it derived or just given? The textbook provides no justification for this equation. In fact, much of the book associated with the Gibbs free energy provides no justification and just says, 'This is how it is. Now go and solve some problems.'
","There are two ways to understand this equation.  

One is to realise that (reversible ideal case)$\Delta G=W_{\text{non-expansion}}$. Therefore, in an ideal chemical cell, if the potential difference between the electrodes is $E$, to move one mole electrons across the external circuit will be $FE$, which must be equal to the decrease in gibbs free energy of the system. Hence for $n$ mole electrons tranferred at the same potential, $W_{\text{non-expansion}}=\Delta G=-nFE$. 

The fact that $\Delta G=-W_{\text{non-expansion}}$ can be derived as under:-
$$dU=\delta q+W_{\text{non-expansion}}+W_{\text{expansion}}$$
$$ds ={ \delta q/t}$$(in reversible case)
$$Tds=dU-W_{\text{non-expansion}}-W_{\text{expansion}}$$
$$W_{\text{non-expansion}}=dU+pdV-Tds$$(for constant pressure and temperature)
$$W_{\text{non-expansion}}=dH-Tds=dG$$

Another approach is to use $\mu_{electrochemical}=\mu_{chemical}+zF\phi$ where $\phi$=electric potential at the point, $z$ is the charge on the species. using this and 
$$dG_{T,P}=\sum_{i=1}^n \mu_idn_i$$
we get the required equation for $z=1$ for an electron, and considering the electrochemical potential of both the electrodes. I am unsure of a rigorous derivation for the electrochemical potential but this is some basics on it.
"
1916,1916,3048,What should I look for in a recording microphone for personal use?,"I was browsing through mics on Amazon and quickly realized I was out of my depth.  There are a couple closely related questions I am wondering about:


Are there different types of mics for (1) singing into at a concert, (2) singing into in a quiet room, and (3) picking up sound at more of a distance (e.g., singing and playing guitar and having both recorded with the one mic)?  What are they?
I'm most interested in a mic for case (3).  This is obviously not professional, I just want something with passable quality and not too much noise considering I'll be in a random room in a house or apartment.  What kind of things should I look for in a mic to achieve that?  What are the factors that most depend on price?  (If it's feasible I'd like to try to fit it into my $50 contest reward.)
There are a few terms I saw like ""moving coil"", ""condenser"", and ""dynamic"" that I saw used to describe mics.  If you could touch on these and any other relevant terminology that would be awesome.

",Matthew Read,https://music.stackexchange.com/users/28,"There are two (popular) types of microphones: dynamic microphones and electret/condensor mics.

Dynamic microphones

They work like a speaker in reverse. Sound moves a diaphragm/coil assembly. The coil moves over a magnet and a current gets induces. Hence we have voltage.


Almost indestructible. YOu can literally pound nails with a Sure SM58
(fun abuse video here 
            
                
                    
                    
                    
                    
                    
                
            )
Very good at very loud sources, can be shoved in front of a Marshall stack without clipping
no inherent noise on their own
However, very low sensitivity. Need a LOT of amplification for low and medium level sources
They are almost always ""Cardoid"" or ""supercardiods"". This makes them more resilient against feedback but it also creates a lot of artificial bass amplification for sources that are close to the mic. They tend to make the voice very ""boomy""
Frequency response is typically not very flat.


Electret or Condenser Microphones

They work by having a diaphragm moving against a statically charged electrode. Moving the diaphragm changes the electric capacity of the contraption which modulates the charge current. The current is super tiny so all microphone of these type have build in pre-amplifier that needs a power supply. This supply either comes from a battery, an external power supply box, 48V phantom supply from a mixer or interface box, or from the USB spigot. Electret are mostly omni directional but some are also cardioid or supercardiod or even switchable. We assume an omni here,


They tent to have a very flat frequency response, especially if it's an omni directional microphone.
Frequency response does not change with distance (no boomy voice)
Tend to have good sensitivity, good for low and medium level sources
Can clip at high volumes, so need to managed carefully
Has inherent noise in the capsule and the pre-amp. The larger the diaphragm, the smaller the noise
Fairly sensitive to feedback
Due to omni character more likely to pick up environmental noise


Because of the trade offs listed, most people use dynamic cardioid microphones in live situations and an omni-directional electret/condenser mic for recording. Electret are cleaner and truer to the original sound source but they need to be carefully managed in terms of placement, gain, noise, clipping, and external noise pick up.

Tip: if you are into DIY projects you can build your own with a very inexpensive electret capsule (such as the Panasonic WM-61A). See https://pantherfile.uwm.edu/type/www/audio-reports/PanasonicWM-61A_OtherBinauralRigs/WM61A_Webpage_Caps_Mounts.html. These can make remarkably good mics that sound as good as commercial micd that cost 100s of $.
",Hilmar,https://music.stackexchange.com/users/3532,http://music.stackexchange.com/questions/8312/what-should-i-look-for-in-a-recording-microphone-for-personal-use,LIFE_ARTS,music.stackexchange.com,1.0,0.3333333333333333,0.0,1.0,0.3333333333333333,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.6666666666666666,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.3333333333333333,0.0,0.6666666666666666,0.0,0.3333333333333333,0.0,1.0,1.0,0.7777777777777778,1.0,1.0,1.0,0.3333333333333333,0.0,1.0,1.0,What should I find in the recording microphone for personal use?,"I was browsing through mics on Amazon and quickly realized I was out of my depth.  There are a couple closely related questions I am wondering about:


Are there different types of mics for (1) singing into at a concert, (2) singing into in a quiet room, and (3) picking up sound at more of a distance (e.g., singing and playing guitar and having both recorded with the one mic)?  What are they?
I'm most interested in a mic for case (3).  This is obviously not professional, I just want something with passable quality and not too much noise considering I'll be in a random room in a house or apartment.  What kind of things should I look for in a mic to achieve that?  What are the factors that most depend on price?  (If it's feasible I'd like to try to fit it into my $50 contest reward.)
There are a few terms I saw like ""moving coil"", ""condenser"", and ""dynamic"" that I saw used to describe mics.  If you could touch on these and any other relevant terminology that would be awesome.

","There are two (popular) types of microphones: dynamic microphones and electret/condensor mics.

Dynamic microphones

They work like a speaker in reverse. Sound moves a diaphragm/coil assembly. The coil moves over a magnet and a current gets induces. Hence we have voltage.


Almost indestructible. YOu can literally pound nails with a Sure SM58
(fun abuse video here 
            
                
                    
                    
                    
                    
                    
                
            )
Very good at very loud sources, can be shoved in front of a Marshall stack without clipping
no inherent noise on their own
However, very low sensitivity. Need a LOT of amplification for low and medium level sources
They are almost always ""Cardoid"" or ""supercardiods"". This makes them more resilient against feedback but it also creates a lot of artificial bass amplification for sources that are close to the mic. They tend to make the voice very ""boomy""
Frequency response is typically not very flat.


Electret or Condenser Microphones

They work by having a diaphragm moving against a statically charged electrode. Moving the diaphragm changes the electric capacity of the contraption which modulates the charge current. The current is super tiny so all microphone of these type have build in pre-amplifier that needs a power supply. This supply either comes from a battery, an external power supply box, 48V phantom supply from a mixer or interface box, or from the USB spigot. Electret are mostly omni directional but some are also cardioid or supercardiod or even switchable. We assume an omni here,


They tent to have a very flat frequency response, especially if it's an omni directional microphone.
Frequency response does not change with distance (no boomy voice)
Tend to have good sensitivity, good for low and medium level sources
Can clip at high volumes, so need to managed carefully
Has inherent noise in the capsule and the pre-amp. The larger the diaphragm, the smaller the noise
Fairly sensitive to feedback
Due to omni character more likely to pick up environmental noise


Because of the trade offs listed, most people use dynamic cardioid microphones in live situations and an omni-directional electret/condenser mic for recording. Electret are cleaner and truer to the original sound source but they need to be carefully managed in terms of placement, gain, noise, clipping, and external noise pick up.

Tip: if you are into DIY projects you can build your own with a very inexpensive electret capsule (such as the Panasonic WM-61A). See https://pantherfile.uwm.edu/type/www/audio-reports/PanasonicWM-61A_OtherBinauralRigs/WM61A_Webpage_Caps_Mounts.html. These can make remarkably good mics that sound as good as commercial micd that cost 100s of $.
"
3544,3544,5654,Where are good photography spots in Malaysia?,"I am from Sweden and I've been in Kuala Lumpur for some time now and I wonder where I can find some good spots for shooting pictures. I've already been to Zoo Negara, but are there any other kind of places to visit? 

I will stay in Kuala Lumpur until December, feel free to make suggestions. I'm much into photographing people and life.
",Michail,https://photo.stackexchange.com/users/13326,"Awespot has a list of travel spots in Malaysia, with photos from Flickr (so it can help visualize what kind of photos you can make): Malaysia.

Interesting spots in the list:


Gunung Mulu National Park
The snake temple

",Matthieu Napoli,https://photo.stackexchange.com/users/2145,http://photo.stackexchange.com/questions/29402/where-are-good-photography-spots-in-malaysia,LIFE_ARTS,photo.stackexchange.com,1.0,0.8888888888888888,1.0,1.0,0.0,0.0,0.5555555555555556,0.6666666666666666,0.0,0.0,1.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,1.0,1.0,0.5555555555555556,1.0,1.0,0.8666666666666666,0.0,0.0,0.0,1.0,Where is a good photography spot in Malaysia?,"I'm from Sweden and have been in Kuala Lumpur for a while. I want to know where I can find some good shooting places. I've been to the South Gala zoo, but is there any other place to visit?","Awespot has a list of travel spots in Malaysia, with photos from Flickr (so it can help visualize what kind of photos you can make): Malaysia.

Interesting spots in the list:


Gunung Mulu National Park
The snake temple

"
2801,2801,4462,Session Fixation - Setting path to root without /,"I have found an XSS vulnerability on the subdomain of a site I am testing, and using it I can set cookies for both the main site and all it's subdomains. 

My url currently looks like this:

http://s1.example.com/u/%22%3E%3Cmeta%20http-equiv=Set-Cookie%20content=%22sid=1234;%20path=/;%20expires=Thursday,%2020-May-15%2000:15:00%20GMT;%20domain=example.com%22%3E


The issue is that for some reason or another, the character ""/"" is filtered out (no other characters are), meaning that although I can set cookies to the main site and all it's subdomains, I can only set them to the path /u/ as that is where the attack is launched from on the subdomain. Is there any way to set the path to / without actually using the /?

Thank you very much for any help!
",WH567,https://security.stackexchange.com/users/53399,"Try URL encoding the / character with the hex representation %2F.
",Nicholas Andre,https://security.stackexchange.com/users/53330,http://security.stackexchange.com/questions/64812/session-fixation-setting-path-to-root-without,TECHNOLOGY,security.stackexchange.com,0.5555555555555556,0.4444444444444444,0.0,0.0,1.0,0.0,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.7777777777777778,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.6,1.0,0.0,0.0,0.6666666666666666,Session fixed - set root path/,"I have found an XSS vulnerability on the subdomain of a site I am testing, and using it I can set cookies for both the main site and all it's subdomains. 

My url currently looks like this:

http://s1.example.com/u/%22%3E%3Cmeta%20http-equiv=Set-Cookie%20content=%22sid=1234;%20path=/;%20expires=Thursday,%2020-May-15%2000:15:00%20GMT;%20domain=example.com%22%3E


The issue is that for some reason or another, the character ""/"" is filtered out (no other characters are), meaning that although I can set cookies to the main site and all it's subdomains, I can only set them to the path /u/ as that is where the attack is launched from on the subdomain. Is there any way to set the path to / without actually using the /?

Thank you very much for any help!
","Try URL encoding the / character with the hex representation %2F.
"
5283,5283,8391,Splicing tiny wire inside broken mouse cable,"I don't know a lot about electronics repairs, but I've got a relatively expensive laser mouse that got a frayed connection on the wire:



I'm wanting to repair it as it's out of warranty.  I've cut the cable on either side of the ""stopper"", isolated each of the individual wires, and stripped the ends off in preparation for splicing.



I've read some instructions that indicate I should do an inline wrap and then apply some solder.  

Is there a better way for wires this small?

Is there a particular type of heat shrink wrap I should put on this after it's spliced?  Or will electrical tape suffice?



Inside the mouse, the cable is connected to a little plug.  To me, it looks a lot like the fan plugs inside a PC.  It's got 5 pins each 1mm apart.  If there were a replacement plug I could buy and crimp the wires into, that'd be great!


",James Kolpack,https://electronics.stackexchange.com/users/7046,"I disagree with Chris in that you don't just want to shorten the cable.  It's not the length of cable I'm worried about, but that tiny connector you don't want to replicate.  The connector and the wires immediately coming out of it look to be intact.  Replacing that will be a major pain in the butt, so I'd go to reasonable length to preserve that piece.

Since that piece is now short, you'll have to make a splice.  Just realize up front you're not going to make a splice in such small cable that is anything like the size of the cable.  The splice will be big, fat, and ugly in comparison.  It looks like it can be made to serve as the strain relief too, so that helps a little.

To splice such tiny wires, see if you can sortof stick the stranded ends into each other.  That may take some persuasion under a magnifying light, and then some weighty objects on your bench to hold them in place while you solder.  This won't be easy, but it should be doable.  If that just isn't practical, give up and bend each wire into a U and hook the two U ends together, flatten them together with a needlenose, then solder.

Once you have the connections made, wrap each one individually in a small piece of electrical tape, then wrap the whole bundle in electrical tape so that is looks like one fat section of cable.  Like I said, big, fat, and ugly, but it should work.  All that tape will act like a strain relief, so that section shouldn't break again.
",Olin Lathrop,https://electronics.stackexchange.com/users/4512,http://electronics.stackexchange.com/questions/23760/splicing-tiny-wire-inside-broken-mouse-cable,SCIENCE,electronics.stackexchange.com,1.0,0.3333333333333333,0.0,0.0,0.3333333333333333,1.0,0.5555555555555556,0.6666666666666666,0.3333333333333333,0.0,1.0,0.0,0.0,0.0,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,0.0,1.0,Splicing thin wires in a disconnected mouse cable,"I don't know a lot about electronics repairs, but I've got a relatively expensive laser mouse that got a frayed connection on the wire:



I'm wanting to repair it as it's out of warranty.  I've cut the cable on either side of the ""stopper"", isolated each of the individual wires, and stripped the ends off in preparation for splicing.



I've read some instructions that indicate I should do an inline wrap and then apply some solder.  

Is there a better way for wires this small?

Is there a particular type of heat shrink wrap I should put on this after it's spliced?  Or will electrical tape suffice?



Inside the mouse, the cable is connected to a little plug.  To me, it looks a lot like the fan plugs inside a PC.  It's got 5 pins each 1mm apart.  If there were a replacement plug I could buy and crimp the wires into, that'd be great!


","I disagree with Chris in that you don't just want to shorten the cable.  It's not the length of cable I'm worried about, but that tiny connector you don't want to replicate.  The connector and the wires immediately coming out of it look to be intact.  Replacing that will be a major pain in the butt, so I'd go to reasonable length to preserve that piece.

Since that piece is now short, you'll have to make a splice.  Just realize up front you're not going to make a splice in such small cable that is anything like the size of the cable.  The splice will be big, fat, and ugly in comparison.  It looks like it can be made to serve as the strain relief too, so that helps a little.

To splice such tiny wires, see if you can sortof stick the stranded ends into each other.  That may take some persuasion under a magnifying light, and then some weighty objects on your bench to hold them in place while you solder.  This won't be easy, but it should be doable.  If that just isn't practical, give up and bend each wire into a U and hook the two U ends together, flatten them together with a needlenose, then solder.

Once you have the connections made, wrap each one individually in a small piece of electrical tape, then wrap the whole bundle in electrical tape so that is looks like one fat section of cable.  Like I said, big, fat, and ugly, but it should work.  All that tape will act like a strain relief, so that section shouldn't break again.
"
5374,5374,8533,Are scientifically detached professors referred to as ‘clinical’?,"I have come across this term fairly often, where full/associate/assistant professors are referred to by the term ‘clinical’. Given that their departments had nothing to do with medicine, I thought the term referred to the second meaning of clinical:


  scientifically detached; strictly objective


Is this interpretation correct? If yes, isn’t such a branding offensive?
",Sheeba,https://academia.stackexchange.com/users/37947,"Many universities are now forced by their budgetary situations to hire people at low wages on temporary contracts to teach classes.  Then they have the problem of figuring out what title to give these employees.  Since medical schools have a longstanding practice of hiring people (though not at low wages) on temporary contracts to teach classes and (accurately in their case) call such people Clinical Professors, some universities have adopted the terminology for all such cases.
",Alexander Woo,https://academia.stackexchange.com/users/34050,http://academia.stackexchange.com/questions/49759/are-scientifically-detached-professors-referred-to-as-clinical,LIFE_ARTS,academia.stackexchange.com,0.8888888888888888,0.4444444444444444,0.3333333333333333,0.3333333333333333,1.0,0.3333333333333333,0.6666666666666666,1.0,0.6666666666666666,0.0,0.6666666666666666,1.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,1.0,0.5555555555555556,1.0,1.0,0.8,0.0,0.0,0.3333333333333333,0.8888888888888888,"Is an independent professor of science called ""clinical professor""?","I often come across this semester. The formal Professor / Associate Professor / Assistant Professor here is called ""clinical professor"". Since their department is not related to medicine, I think this word refers to the second meaning of clinical:","Many universities are now forced to hire low wage students on temporary contracts because of their budget situation. Then they have a question, which is to find out what title to give these employees. Some universities have adopted the terminology of all such cases because medical schools have long used temporary contracts to hire staff (though not underpaid) to teach and (to be precise, in their case) to refer to them as clinical professors."
5692,5692,9023,AxesLabel broken in Version 10 for 3D plots?,"In version 10.0.1 (Win7), AxesLabel with arbitrary text strings works as expected in 2D plots:

Plot[Sin[x], {x, -4, 4}, 
 AxesLabel -&gt; {""Range (km)"", ""Velocity (m/sec)""}]




In prior versions the same worked for 3D plots as well; but not anymore in v. 10:

Plot3D[Sin[x - 3 y], {x, -3, 3}, {y, -3, 3}, 
 AxesLabel -&gt; {""Range (km)"", ""Velocity (m/sec)""}, 
 LabelStyle -&gt; Directive[Blue, Large]]




Is this a bug? And is there a workaround?

Thanks
",ulvi,https://mathematica.stackexchange.com/users/1714,"There are bugs within bugs. Consider this sequence:

V9

$Version



  ""9.0 for Microsoft Windows (64-bit) (January 25, 2013)""


Plot3D[Sin[x - 3 y], {x, -3, 3}, {y, -3, 3},
 ImageSize -&gt; 500,
 AxesLabel -&gt; {""Range (km)"", ""Velocity (m/sec)""},
 LabelStyle -&gt; Directive[Blue, Large]]




Plot3D[Sin[x - 3 y], {x, -3, 3}, {y, -3, 3},
 ImageSize -&gt; 500,
 AxesLabel -&gt; {""Range (km)"", ""Velocity (m/sec)"", Automatic},
 LabelStyle -&gt; Directive[Blue, Large]]




V10

$Version



  ""10.0 for Microsoft Windows (64-bit) (June 29, 2014)""


Plot3D[Sin[x - 3 y], {x, -3, 3}, {y, -3, 3},
 AxesLabel -&gt; {""Range (km)"", ""Velocity (m/sec)""},
 LabelStyle -&gt; Directive[Blue, Large],
 PlotTheme -&gt; ""Classic"",
 ImageSize -&gt; 500]




Plot3D[Sin[x - 3 y], {x, -3, 3}, {y, -3, 3},
 AxesLabel -&gt; {""Range (km)"", ""Velocity (m/sec)"", Automatic},
 LabelStyle -&gt; Directive[Blue, Large],
 PlotTheme -&gt; ""Classic"",
 ImageSize -&gt; 500]




Well, I accept and welcome that V10 requires the third Automatic - parameter. I am, however, hesitant to accept that blue turns to black and that classic isn't classic anymore.
",eldo,https://mathematica.stackexchange.com/users/14254,http://mathematica.stackexchange.com/questions/62946/axeslabel-broken-in-version-10-for-3d-plots,TECHNOLOGY,mathematica.stackexchange.com,0.3333333333333333,0.3333333333333333,0.0,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,1.0,1.0,1.0,0.0,1.0,1.0,Axeslabel corrupted in 3D drawing version 10?,"In version 10.0.1 (Win7), AxesLabel with arbitrary text strings works as expected in 2D plots:

Plot[Sin[x], {x, -4, 4}, 
 AxesLabel -&gt; {""Range (km)"", ""Velocity (m/sec)""}]




In prior versions the same worked for 3D plots as well; but not anymore in v. 10:

Plot3D[Sin[x - 3 y], {x, -3, 3}, {y, -3, 3}, 
 AxesLabel -&gt; {""Range (km)"", ""Velocity (m/sec)""}, 
 LabelStyle -&gt; Directive[Blue, Large]]




Is this a bug? And is there a workaround?

Thanks
","There are bugs within bugs. Consider this sequence:

V9

$Version



  ""9.0 for Microsoft Windows (64-bit) (January 25, 2013)""


Plot3D[Sin[x - 3 y], {x, -3, 3}, {y, -3, 3},
 ImageSize -&gt; 500,
 AxesLabel -&gt; {""Range (km)"", ""Velocity (m/sec)""},
 LabelStyle -&gt; Directive[Blue, Large]]




Plot3D[Sin[x - 3 y], {x, -3, 3}, {y, -3, 3},
 ImageSize -&gt; 500,
 AxesLabel -&gt; {""Range (km)"", ""Velocity (m/sec)"", Automatic},
 LabelStyle -&gt; Directive[Blue, Large]]




V10

$Version



  ""10.0 for Microsoft Windows (64-bit) (June 29, 2014)""


Plot3D[Sin[x - 3 y], {x, -3, 3}, {y, -3, 3},
 AxesLabel -&gt; {""Range (km)"", ""Velocity (m/sec)""},
 LabelStyle -&gt; Directive[Blue, Large],
 PlotTheme -&gt; ""Classic"",
 ImageSize -&gt; 500]




Plot3D[Sin[x - 3 y], {x, -3, 3}, {y, -3, 3},
 AxesLabel -&gt; {""Range (km)"", ""Velocity (m/sec)"", Automatic},
 LabelStyle -&gt; Directive[Blue, Large],
 PlotTheme -&gt; ""Classic"",
 ImageSize -&gt; 500]




Well, I accept and welcome that V10 requires the third Automatic - parameter. I am, however, hesitant to accept that blue turns to black and that classic isn't classic anymore.
"
5631,5631,8928,"Can tab just mean ""insert tab character""?","Is there a way to set the tab key to simply insert the tab character in a notebook? I often find the sometimes mysterious ""features"" bound to that key detrimental.
",Rico Picone,https://mathematica.stackexchange.com/users/9150,"You can try (for a single notebook)

CreateDocument[{},
 NotebookEventActions -&gt; {{""KeyDown"", ""\t""} :&gt; 
  NotebookWrite[SelectedNotebook[], ""\t""]}]


or (for global application)

SetOptions[$FrontEnd,
 FrontEndEventActions -&gt; {{""KeyDown"", ""\t""} :&gt; 
  NotebookWrite[SelectedNotebook[], ""\t""]}]


Does this meet your needs? For me it had an effect in Input cells but didn't block autocomplete behavior, though if that's what's getting in your way it can be disabled in Preferences.
",mfvonh,https://mathematica.stackexchange.com/users/5059,http://mathematica.stackexchange.com/questions/48610/can-tab-just-mean-insert-tab-character,TECHNOLOGY,mathematica.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,1.0,0.3333333333333333,1.0,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,0.0,1.0,"Can tab simply mean ""Insert tab character""?","Is there a way to set the tab key to simply insert the tab character into the notebook? I often find that sometimes mysterious ""features"" bind to the key harmful.","You can try (for a single notebook)

CreateDocument[{},
 NotebookEventActions -&gt; {{""KeyDown"", ""\t""} :&gt; 
  NotebookWrite[SelectedNotebook[], ""\t""]}]


or (for global application)

SetOptions[$FrontEnd,
 FrontEndEventActions -&gt; {{""KeyDown"", ""\t""} :&gt; 
  NotebookWrite[SelectedNotebook[], ""\t""]}]


Does this meet your needs? For me it had an effect in Input cells but didn't block autocomplete behavior, though if that's what's getting in your way it can be disabled in Preferences.
"
3957,3957,6314,Setting up a food pantry/orphanage?,"I can't find much on how to set up any kind of establishments that are for charity. HOw would I go about this? Acquiring a building, a few volunteers, how much to run it per day, ect? Anyone have any experience in this? My character is a NG Druid, who had never been to a city and saw the poverty and lack of food and housing for people. He wants to help! But I have no idea on how to establish a continual act of help. Buying food for the town and stuff, one time is easy to figure out. How many people * ammount of food needed is the price. But for bigger acts of continual charity, who knows? 

EDIT:
So, it was suggested that I make an eco orphanage in a forest. I accidently doomed the continent with demons, so that won't work. (Wish spell to get rid of orcs, things went horribly wrong) NO one knows it was me though! :D 

I don't want the leadership feat cause I need my 6th level feat for a prestige class.

Also, I don't want to donate to the churches in this city, I'm finding a lot of corruption in some of these churches, especially this city, so I want something more controllable by me. 
",samuraiseoul,https://rpg.stackexchange.com/users/10381,"First, D&amp;D 3.5e doesn't really support this kind of play. If you want to run a food pantry, you might be happier playing a different game.

Second, if your GM is game, then you can explore the decisions and choices during play rather than attempt to preplan it all as a player. Try something—build a shelter, hire a manager, donate funds for food—and come back in a week/month/season and see what happened. Church corruption actually sounds like a potentially interesting urban plot. Rooting out evil there could leave the city with favorable clerics more aligned toward your goals.
",okeefe,https://rpg.stackexchange.com/users/307,http://rpg.stackexchange.com/questions/32292/setting-up-a-food-pantry-orphanage,CULTURE,rpg.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,0.3333333333333333,0.3333333333333333,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.5555555555555556,0.8888888888888888,0.6666666666666666,1.0,0.8888888888888888,0.7333333333333333,0.3333333333333333,0.3333333333333333,1.0,0.8888888888888888,Food storage / orphanage?,"I can't find much on how to set up any kind of establishments that are for charity. HOw would I go about this? Acquiring a building, a few volunteers, how much to run it per day, ect? Anyone have any experience in this? My character is a NG Druid, who had never been to a city and saw the poverty and lack of food and housing for people. He wants to help! But I have no idea on how to establish a continual act of help. Buying food for the town and stuff, one time is easy to figure out. How many people * ammount of food needed is the price. But for bigger acts of continual charity, who knows? 

EDIT:
So, it was suggested that I make an eco orphanage in a forest. I accidently doomed the continent with demons, so that won't work. (Wish spell to get rid of orcs, things went horribly wrong) NO one knows it was me though! :D 

I don't want the leadership feat cause I need my 6th level feat for a prestige class.

Also, I don't want to donate to the churches in this city, I'm finding a lot of corruption in some of these churches, especially this city, so I want something more controllable by me. 
","First, D&amp;D 3.5e doesn't really support this kind of play. If you want to run a food pantry, you might be happier playing a different game.

Second, if your GM is game, then you can explore the decisions and choices during play rather than attempt to preplan it all as a player. Try something—build a shelter, hire a manager, donate funds for food—and come back in a week/month/season and see what happened. Church corruption actually sounds like a potentially interesting urban plot. Rooting out evil there could leave the city with favorable clerics more aligned toward your goals.
"
552,552,867,Invisible Physics to Certain Objects in the BGE,"I'm making a first person view game.  I have an invisible collision body that I use for interaction with other objects.  I have it so that the player can ""shoot"" cubes.  How ever, if the player looks down and tries to shoot (for example if an enemy is coming close) the bullet gets bounced off the collision body for the character.  Is it possible to make it so that my bullets can collide with everything except for the collision body?  Thanks!
",Anson Savage,https://blender.stackexchange.com/users/12805,"You can do this with collision mask and collision group.



These options are found in the physics panel. To fix your particular problem, select the invisible collision box for the player and put it in collision group 2. 

Next, select the bullet and while holding Shift click on the 2nd box in collision mask. This will stop the bullet from colliding with anything in collision group/layer 2.
",Scalia,https://blender.stackexchange.com/users/6385,http://blender.stackexchange.com/questions/27335/invisible-physics-to-certain-objects-in-the-bge,TECHNOLOGY,blender.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,0.0,1.0,0.0,0.4444444444444444,0.3333333333333333,0.6666666666666666,0.0,1.0,1.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,1.0,Invisible physics of some objects in the background,"I'm doing the first person game. I have an invisible collider that I use to interact with other objects. I have it so players can ""shoot"" the cube. However, if the player looks down and tries to shoot (for example, if the enemy approaches), the bullet bounces off the character's impactor. Is it possible for my bullet to collide with all but the collider? Thank you!","You can do this with collision mask and collision group.



These options are found in the physics panel. To fix your particular problem, select the invisible collision box for the player and put it in collision group 2. 

Next, select the bullet and while holding Shift click on the 2nd box in collision mask. This will stop the bullet from colliding with anything in collision group/layer 2.
"
5403,5403,8582,Vector fields whose divergence are proper maps,"Let $X$ be a polynomial  vector field  of degree $2$ on $\mathbb{R}^{2}$. Does there exist a nonvanishing  smooth function $g$ such that $Div(gX)$ is  a  proper map?Or at least the  zero locus of $Div(gX)=0$ is  a  compact set? Can we find this  $g$ an algebraic map or  at least in the  form $e^{P(x,y)}$ where $P$ is  a  polynomial?

Is there  a  uniform upper  bound $PDH(n)$ for the  number of  limit cycles of  a  those polynomial  vector  field of degree $n$ for which the  divergence is  proper or at least $Div=0$ is  a  compact  curve. For $n=3$, two what extent thses vector field  are classified in term of their coefficients
",Ali Taghavi,https://mathoverflow.net/users/36688,"Since $\mathbb R^2$ has one end and $\mathbb R^1$ has two ends, a proper map $\mathbb R^2 \to \mathbb R^1$ must send the end of $\mathbb R^2$ to one of the two ends of $\mathbb R^1$ - that is, $f(x,y)$ is either a large positive number of a large negative number when $(x,y)$ is large.

But we can force $\nabla \cdot gX$ to oscillate  arbitrarily many times. Choose a vector field like $ \sin(x^2+y^2)( xdx + ydy)$. Then the integral of the divergence over a disc is the integral of the vector field dot the normal vector over a circle, which switches sign periodically in the radius of the function, so the divergence must switch sign arbitrarily often, so it can't be proper.

Moreover because it switches sign with arbitrarily large radius, the set where it is 0 cannot be compact.
",Will Sawin,https://mathoverflow.net/users/18060,http://mathoverflow.net/questions/190862,SCIENCE,mathoverflow.net,0.8888888888888888,0.3333333333333333,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.5555555555555556,0.8888888888888888,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,0.8888888888888888,Vector field with true divergence,"Let $x $be a 2 $degree polynomial vector field on $\ mathbb {r} ^ {2} $. Is there a non vanishing smoothing function $g $, which makes $div (GX) $an appropriate mapping? Or is the zero trajectory of at least $div (GX) = 0 $a compact set? Can we find this $g $algebra map? Or at least in the form of $e ^ {P (x, y)} $, where $p $is a polynomial?","Since $\mathbb R^2$ has one end and $\mathbb R^1$ has two ends, a proper map $\mathbb R^2 \to \mathbb R^1$ must send the end of $\mathbb R^2$ to one of the two ends of $\mathbb R^1$ - that is, $f(x,y)$ is either a large positive number of a large negative number when $(x,y)$ is large.

But we can force $\nabla \cdot gX$ to oscillate  arbitrarily many times. Choose a vector field like $ \sin(x^2+y^2)( xdx + ydy)$. Then the integral of the divergence over a disc is the integral of the vector field dot the normal vector over a circle, which switches sign periodically in the radius of the function, so the divergence must switch sign arbitrarily often, so it can't be proper.

Moreover because it switches sign with arbitrarily large radius, the set where it is 0 cannot be compact.
"
3719,3719,5930,"Is it awkward to say ""Good morning"" to roommate every day?","I know it is a bit weird to ask this question, yet in the country I am staying, China, people love to say ""Good morning"" to everyone every morning.

I have never been to other countries except China and I am going to study abroad in America.

Is this social etiquette the same in America and American people say ""Good morning"" to their roommate every day?
",Deniz Çağlayan,https://ell.stackexchange.com/users/10931,"It's completely okay in any culture, I think. That's because greeting someone in the morning is a gesture of goodwill that the day has begun with some goodness. 

Don't we greet our parents with 'Good Morning' daily? Also, I've seen kids greeting this to their parents in many Hollywood movies. That said, it's completely okay to say 'Good Morning' to your roommate everyday.  
",Maulik V,https://ell.stackexchange.com/users/3187,http://ell.stackexchange.com/questions/35464/is-it-awkward-to-say-good-morning-to-roommate-every-day,CULTURE,ell.stackexchange.com,1.0,1.0,0.3333333333333333,1.0,0.3333333333333333,1.0,0.5555555555555556,0.7777777777777778,0.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.3333333333333333,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.3333333333333333,0.0,0.6666666666666666,1.0,"Is it embarrassing to say ""good morning"" to your roommate every day?","I know it is a bit weird to ask this question, yet in the country I am staying, China, people love to say ""Good morning"" to everyone every morning.

I have never been to other countries except China and I am going to study abroad in America.

Is this social etiquette the same in America and American people say ""Good morning"" to their roommate every day?
","It's completely okay in any culture, I think. That's because greeting someone in the morning is a gesture of goodwill that the day has begun with some goodness. 

Don't we greet our parents with 'Good Morning' daily? Also, I've seen kids greeting this to their parents in many Hollywood movies. That said, it's completely okay to say 'Good Morning' to your roommate everyday.  
"
5430,5430,8620,Word describing the reversal of emotions,"
  A boy is highly confident one day and
  the next day scared, timid and shy. 
  
  A girl is emotional one day and
  emotionless the next.


Is there a term for a drastic switching of emotions?
A term for the switching to practically opposite emotions?

EDIT: Just to clarify the emotional changes are not rapid, and are permanent.  This rules out bi-polar, because bi-polar involves multiple periods of change.

EDIT2: I'm looking for a work to demonstrate the steepness or contrasts of change, but having no relationship to the speed of change.

Example:


  Over a course of 3 years a once quiet boy become the spokesmen of the school.

",William,https://english.stackexchange.com/users/6331,"mercurial

[mer-kyoor-ee-uhl] 

–adjective

changeable; volatile; fickle; flighty; erratic: a mercurial nature.
",Robb,https://english.stackexchange.com/users/6135,http://english.stackexchange.com/questions/20450/word-describing-the-reversal-of-emotions,CULTURE,english.stackexchange.com,0.8888888888888888,0.6666666666666666,0.0,1.0,1.0,0.3333333333333333,0.7777777777777778,0.8888888888888888,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.8888888888888888,0.6666666666666666,0.5555555555555556,0.6666666666666666,0.6666666666666666,0.6,0.0,0.0,0.0,1.0,Words for mood reversal,"
  A boy is highly confident one day and
  the next day scared, timid and shy. 
  
  A girl is emotional one day and
  emotionless the next.


Is there a term for a drastic switching of emotions?
A term for the switching to practically opposite emotions?

EDIT: Just to clarify the emotional changes are not rapid, and are permanent.  This rules out bi-polar, because bi-polar involves multiple periods of change.

EDIT2: I'm looking for a work to demonstrate the steepness or contrasts of change, but having no relationship to the speed of change.

Example:


  Over a course of 3 years a once quiet boy become the spokesmen of the school.

","mercurial

[mer-kyoor-ee-uhl] 

–adjective

changeable; volatile; fickle; flighty; erratic: a mercurial nature.
"
455,455,709,What is it called when a music has two concurrent tempos,"I've recently watched a BBC documentary about the history of music and recall an episode where they talk about music that has two distinct tempos (and possibly time signatures) at the same time for different sets of instruments.

Still, I can't remember how this is called and who are the famous composers that composed that way (Stravinsky?).
",Arthur Rizzo,https://music.stackexchange.com/users/16830,"This sort of thing has been explored pretty deeply by, among other people, Conlon Nancarrow. He used player pianos to perform pieces which would most likely have been too complex for anyone to perform organically. One way in which he complicated things was that he used what he called a tempo canon. As discussed here, one such piece was his Study for Player Piano 41a. It used multiple voices, each with its own tempo and the ratios were on a strict, but irrational ratio. If the ratio between tempos was rational, it would line up, or converge, so that two notes could fall at the same time. However, if the ratio was irrational, they would never converge and dance around each other until the piece ended.

This basic concept, although the effect can be jarring, is really not very different from polyrhythms and polymeters. It's just obfuscated by using complicated ratios. For example, if you have a bar and a main voice hit four evenly spaced beats, you have the standard quarter note pulse in 4/4. You can fit 3 notes evenly into that same bar in a second voice and the second voice will be playing half-note triplets. For every four notes in the main voice and every three notes in the second voice, the voices will play together. That's your bar. And that's a polyrhythm. That would be a 4:3 ratio. I'm not sure that's how it's typically notated, but the idea translates. You can imagine how this can be seen as two voices at different tempos. Say maybe one voice in 4/4 at 120 and another voice in 3/4 at 90. They would line up the same way.

Here's another example. If your main voice plays 8 eighth notes before repeating and your second voice plays 7 eighth notes before repeating, they will line up every 56 (7×8) eighth notes. In other words, after your main voice repeats seven times and your second voice repeats eight times. That's a polymeter. Now you can see how these concepts can get mixed up. As the ratios get more complicated (ie 128:73) or less rational (ie √2:φ), the tempos line up less and less and the individual tempos will get closer and/or less distinguishable. That is where you cross the line into tempo canon territory.


  Note: I understand that 'irrational ratio' is a terrible oxymoron, but
  I can't think of better terminology. Also, this is just the one conceptualization of
  the multiple tempo idea. There is world music where this is done organically and many
  people have already mentioned other composers who have worked with the idea. But hopefully this helps.

",Dan D,https://music.stackexchange.com/users/18861,http://music.stackexchange.com/questions/30524/what-is-it-called-when-a-music-has-two-concurrent-tempos,LIFE_ARTS,music.stackexchange.com,1.0,0.5555555555555556,0.0,1.0,0.6666666666666666,1.0,0.5555555555555556,0.7777777777777778,0.3333333333333333,0.0,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,1.0,1.0,0.7777777777777778,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,1.0,What is the name of a music when it has two simultaneous rhythms,"I recently watched a BBC Documentary on the history of music, and I recall an episode in which they talked about music that has two different rhythms (and possibly time characteristics) in different instrument combinations.","This sort of thing has been explored pretty deeply by, among other people, Conlon Nancarrow. He used player pianos to perform pieces which would most likely have been too complex for anyone to perform organically. One way in which he complicated things was that he used what he called a tempo canon. As discussed here, one such piece was his Study for Player Piano 41a. It used multiple voices, each with its own tempo and the ratios were on a strict, but irrational ratio. If the ratio between tempos was rational, it would line up, or converge, so that two notes could fall at the same time. However, if the ratio was irrational, they would never converge and dance around each other until the piece ended.

This basic concept, although the effect can be jarring, is really not very different from polyrhythms and polymeters. It's just obfuscated by using complicated ratios. For example, if you have a bar and a main voice hit four evenly spaced beats, you have the standard quarter note pulse in 4/4. You can fit 3 notes evenly into that same bar in a second voice and the second voice will be playing half-note triplets. For every four notes in the main voice and every three notes in the second voice, the voices will play together. That's your bar. And that's a polyrhythm. That would be a 4:3 ratio. I'm not sure that's how it's typically notated, but the idea translates. You can imagine how this can be seen as two voices at different tempos. Say maybe one voice in 4/4 at 120 and another voice in 3/4 at 90. They would line up the same way.

Here's another example. If your main voice plays 8 eighth notes before repeating and your second voice plays 7 eighth notes before repeating, they will line up every 56 (7×8) eighth notes. In other words, after your main voice repeats seven times and your second voice repeats eight times. That's a polymeter. Now you can see how these concepts can get mixed up. As the ratios get more complicated (ie 128:73) or less rational (ie √2:φ), the tempos line up less and less and the individual tempos will get closer and/or less distinguishable. That is where you cross the line into tempo canon territory.


  Note: I understand that 'irrational ratio' is a terrible oxymoron, but
  I can't think of better terminology. Also, this is just the one conceptualization of
  the multiple tempo idea. There is world music where this is done organically and many
  people have already mentioned other composers who have worked with the idea. But hopefully this helps.

"
114,114,183,"Given Ohm's law, how can current increase if voltage increases, given fixed resistance?","According to Ohm's law, V=IR (voltage equals current times resistance).

So if the voltage increases, then the current increases provided that the resistance remains constant.

I know that Voltage or potential difference means work done per unit positive charge in bringing that charge from one point to another.

So according to Ohm's law, if the work done per unit charge increases then current will increase. How can this be true? Point out my mistakes.
",Souhardya Mondal,https://physics.stackexchange.com/users/62308,"It is better to think of Ohm's Law as I=V/R.

What it is telling you is that if you apply a voltage (V) to a resistive material (characterised by R), then that voltage is capable of driving a current I.
The material could be anything, a piece of copper, or the plasma in a star.

The voltage is constantly supplying energy to the electrons in the material, but the resistivity is constantly taking that energy back out (converting it to thermal energy).
The higher the voltage, the more energy you can give to the electrons and hence the higher the current. On the other hand, the higher the resistance, the more energy is taken away from the electron flow and hence the lower the current.
",kotozna,https://physics.stackexchange.com/users/34193,http://physics.stackexchange.com/questions/141786/given-ohms-law-how-can-current-increase-if-voltage-increases-given-fixed-resi,SCIENCE,physics.stackexchange.com,1.0,0.8888888888888888,0.0,1.0,1.0,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,1.0,"Given Ohm's law, given a fixed resistance, if the voltage increases, how does the current increase?","According to Ohm's law, V=IR (voltage equals current times resistance).

So if the voltage increases, then the current increases provided that the resistance remains constant.

I know that Voltage or potential difference means work done per unit positive charge in bringing that charge from one point to another.

So according to Ohm's law, if the work done per unit charge increases then current will increase. How can this be true? Point out my mistakes.
","It is better to think of Ohm's Law as I=V/R.

What it is telling you is that if you apply a voltage (V) to a resistive material (characterised by R), then that voltage is capable of driving a current I.
The material could be anything, a piece of copper, or the plasma in a star.

The voltage is constantly supplying energy to the electrons in the material, but the resistivity is constantly taking that energy back out (converting it to thermal energy).
The higher the voltage, the more energy you can give to the electrons and hence the higher the current. On the other hand, the higher the resistance, the more energy is taken away from the electron flow and hence the lower the current.
"
180,180,280,Laravel 4 Cashier: Don't fire webhook if initiated from laravel application,"I'm using Laravel 4 with Cashier 2.0 and its webhook controller. I want to prevent following behavior: When I create a new subscription for a user within my laravel application, this turns out to execute the method subscription.updated webhook. 

However I want to prevent that the webhooks are executed if the request was made within the laravel application. The webhooks should only execute if there were initiated from the Stripe admin panel directly. Someone that can help me with this?
",Cédric Verstraeten,https://stackoverflow.com/users/1579296,"I'm not sure why you would want to do that. The point of the webhooks are to confirm actions have been received and successfully (or unsuccessfully) completed by Stripe so you know certain things have happened (i.e: A user has successfully been subscribed to a subscription, a charge has happened on a users card, etc.). All of this depends on your application successfully communicating with stripe and stripe successfully billing the card, many things could happen in that processes and the webhooks are there for you to be able to confirm what happened, and if it went wrong, what went wrong.

The behaviour you're after cannot be achieved without your application making no communications with Stripe.
",Wader,https://stackoverflow.com/users/1126663,http://stackoverflow.com/questions/28743279/laravel-4-cashier-dont-fire-webhook-if-initiated-from-laravel-application,STACKOVERFLOW,stackoverflow.com,0.6666666666666666,0.5555555555555556,0.0,0.0,1.0,0.0,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.7777777777777778,0.6666666666666666,0.5555555555555556,0.7777777777777778,1.0,0.8,0.0,0.0,1.0,0.7777777777777778,"Laravel 4 cashier: if starting from the laravel application, do not start webhook","I'm using Laravel 4 with Cashier 2.0 and its webhook controller. I want to prevent following behavior: When I create a new subscription for a user within my laravel application, this turns out to execute the method subscription.updated webhook. 

However I want to prevent that the webhooks are executed if the request was made within the laravel application. The webhooks should only execute if there were initiated from the Stripe admin panel directly. Someone that can help me with this?
","I don't know why you did that. The purpose of webhooks is to confirm that the operation has been received, and to complete the operation successfully (or not successfully) through stripe, so that you know something has happened (i.e. the user has successfully subscribed to the subscription, the user has charged on the card, etc.). All of this depends on whether your application successfully communicates with stripe, whether stripe successfully charges for the card. In this process, many things may happen, whether webhook is there, you can confirm what happened, if there is an error, what happened."
2685,2685,4282,Internal Frame Listeners doesn't work with singleton enum function,"I have the following code where I made singleton/enum manager so it keeps track of the number of internal frames that have been opened and I can get information from anyone of the frames when the user clicks on it (which activates the frame). But I don't know how to make this work because I want when a user clicks suppose on the 1st frame (out of 5 frames that have been opened), I want a save button to be enabled. When none of the windows are activated I want the button to be disabled. I put an internal frame listener and a component listener but none of them work. I was hoping if anyone could tell me where I am going wrong. 

Here is the code:

 public class Manager implements ActionListener, InternalFrameListener, ComponentListener{

private static int openFrameCount =0;
ImagePlus image;
private String tile;
final String SHOW =""show"";
static ImageWindow m;
JMenuItem showInfo;
static JMenuItem save;
static JDesktopPane desktop;
InfoGui in;

public Manager(ImagePlus img, String title, JDesktopPane desktop, JMenuItem save){
    image = img;
    this.desktop = desktop;
    this.tile = title;
    this.save = save;
}

public enum WindowManager {

    INSTANCE;
    public MyInternalFrame frame;
    private Map&lt;ImagePlus, List&lt;MyInternalFrame&gt;&gt; mapWindows;

    private WindowManager(){

        mapWindows = new HashMap&lt;&gt;(25);

    }

    public class MyInternalFrame extends JInternalFrame {

        static final int xPosition = 30, yPosition = 30;
        public MyInternalFrame(String title, ImagePlus img, JMenuItem save) {
            super(title, true,true, true, true);
            setSize(img.getWidth(),img.getHeight());

            // Set the window's location.
            setLocation(xPosition * openFrameCount, yPosition * openFrameCount);
            save.setEnabled(true);
        }
    }

    public JInternalFrame createWindowFor(ImagePlus image) {

        List&lt;MyInternalFrame&gt; frames = mapWindows.get(image);

        if (frames == null) {
            frames = new ArrayList&lt;&gt;(25);
            mapWindows.put(image, frames);
        }

        JPanel panel = new JPanel();

        ImageCanvas c = new ImageCanvas(image);
        c.getImage();

        //panel2.add(new JLabel(new ImageIcon(c.getImage())));
         m = new ImageWindow(image);

        Image n = new Image();
        //frame = new MyInternalFrame(title, img, save,m);
        //ImageCanvas c = m.getCanvas();
        ImagePlus im = new ImagePlus();
        im.setImage(image);

        frame = new MyInternalFrame(image.getTitle(), image, save);
        m.centerNextImage();
        image.getCanvas().setScaleToFit(true);

        panel.add(m.getCanvas());
        panel.setBackground(Color.white);
        frame.add(panel);
        frames.add(frame);

        frame.setVisible(true); 
        frame.setAutoscrolls(true);
        frame.setAutoscrolls(true);
        frame.setOpaque(true);
        desktop.add(frame);
        try {
                frame.setSelected(true);
        } catch (java.beans.PropertyVetoException e) {

        }

        return frame;

    }

    public List&lt;MyInternalFrame&gt; getFromFor(ImagePlus image) {

        JInternalFrame frame = null;
        return mapWindows.get(image.getTitle());

    }

}



@Override
public void actionPerformed(ActionEvent e) {
    // TODO Auto-generated method stub
    SADAPP.Manager.WindowManager.MyInternalFrame m = (SADAPP.Manager.WindowManager.MyInternalFrame) WindowManager.INSTANCE.createWindowFor(image);
}



@Override
public void internalFrameActivated(InternalFrameEvent arg0) {
    // TODO Auto-generated method stub
    save.setEnabled(true);
}



@Override
public void internalFrameClosed(InternalFrameEvent arg0) {
    // TODO Auto-generated method stub
    save.setEnabled(false);
}



@Override
public void internalFrameClosing(InternalFrameEvent arg0) {
    // TODO Auto-generated method stub
    save.setEnabled(false);
}



@Override
public void internalFrameDeactivated(InternalFrameEvent arg0) {
    // TODO Auto-generated method stub
    save.setEnabled(false);
}



@Override
public void internalFrameDeiconified(InternalFrameEvent arg0) {
    // TODO Auto-generated method stub
    save.setEnabled(true);
}



@Override
public void internalFrameIconified(InternalFrameEvent arg0) {
    // TODO Auto-generated method stub
    save.setEnabled(false);
}



@Override
public void internalFrameOpened(InternalFrameEvent arg0) {
    // TODO Auto-generated method stub
    save.setEnabled(true);
}



@Override
public void componentHidden(ComponentEvent arg0) {
    // TODO Auto-generated method stub
    save.setEnabled(false);
}



@Override
public void componentMoved(ComponentEvent arg0) {
    // TODO Auto-generated method stub

}



@Override
public void componentResized(ComponentEvent arg0) {
    // TODO Auto-generated method stub
    Rectangle r = WindowManager.INSTANCE.frame.getBounds();

    m.getCanvas().fitToWindow(r);
    System.out.println(""resized- the real one"");
}



@Override
public void componentShown(ComponentEvent arg0) {
    // TODO Auto-generated method stub

}

 }

",selena,https://stackoverflow.com/users/3630146,"The methods of the InternalFrameListener and ComponentListener interfaces won't be called merely by existing. You need to call addInternalFrameListener or addComponentListener on the frame to tell it about your listener.

For example, in the constructor of MyInternalFrame, you want something like:

this.addInternalFrameListener(someInstanceOfTheManagerObject);

",Boann,https://stackoverflow.com/users/964243,http://stackoverflow.com/questions/23789097/internal-frame-listeners-doesnt-work-with-singleton-enum-function,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.3333333333333333,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.3333333333333333,0.0,0.3333333333333333,1.0,0.6666666666666666,1.0,1.0,1.0,0.6666666666666666,0.0,0.6666666666666666,1.0,Internal frame listener cannot be used with singleton enum function,"I have the following code where I made singleton/enum manager so it keeps track of the number of internal frames that have been opened and I can get information from anyone of the frames when the user clicks on it (which activates the frame). But I don't know how to make this work because I want when a user clicks suppose on the 1st frame (out of 5 frames that have been opened), I want a save button to be enabled. When none of the windows are activated I want the button to be disabled. I put an internal frame listener and a component listener but none of them work. I was hoping if anyone could tell me where I am going wrong. 

Here is the code:

 public class Manager implements ActionListener, InternalFrameListener, ComponentListener{

private static int openFrameCount =0;
ImagePlus image;
private String tile;
final String SHOW =""show"";
static ImageWindow m;
JMenuItem showInfo;
static JMenuItem save;
static JDesktopPane desktop;
InfoGui in;

public Manager(ImagePlus img, String title, JDesktopPane desktop, JMenuItem save){
    image = img;
    this.desktop = desktop;
    this.tile = title;
    this.save = save;
}

public enum WindowManager {

    INSTANCE;
    public MyInternalFrame frame;
    private Map&lt;ImagePlus, List&lt;MyInternalFrame&gt;&gt; mapWindows;

    private WindowManager(){

        mapWindows = new HashMap&lt;&gt;(25);

    }

    public class MyInternalFrame extends JInternalFrame {

        static final int xPosition = 30, yPosition = 30;
        public MyInternalFrame(String title, ImagePlus img, JMenuItem save) {
            super(title, true,true, true, true);
            setSize(img.getWidth(),img.getHeight());

            // Set the window's location.
            setLocation(xPosition * openFrameCount, yPosition * openFrameCount);
            save.setEnabled(true);
        }
    }

    public JInternalFrame createWindowFor(ImagePlus image) {

        List&lt;MyInternalFrame&gt; frames = mapWindows.get(image);

        if (frames == null) {
            frames = new ArrayList&lt;&gt;(25);
            mapWindows.put(image, frames);
        }

        JPanel panel = new JPanel();

        ImageCanvas c = new ImageCanvas(image);
        c.getImage();

        //panel2.add(new JLabel(new ImageIcon(c.getImage())));
         m = new ImageWindow(image);

        Image n = new Image();
        //frame = new MyInternalFrame(title, img, save,m);
        //ImageCanvas c = m.getCanvas();
        ImagePlus im = new ImagePlus();
        im.setImage(image);

        frame = new MyInternalFrame(image.getTitle(), image, save);
        m.centerNextImage();
        image.getCanvas().setScaleToFit(true);

        panel.add(m.getCanvas());
        panel.setBackground(Color.white);
        frame.add(panel);
        frames.add(frame);

        frame.setVisible(true); 
        frame.setAutoscrolls(true);
        frame.setAutoscrolls(true);
        frame.setOpaque(true);
        desktop.add(frame);
        try {
                frame.setSelected(true);
        } catch (java.beans.PropertyVetoException e) {

        }

        return frame;

    }

    public List&lt;MyInternalFrame&gt; getFromFor(ImagePlus image) {

        JInternalFrame frame = null;
        return mapWindows.get(image.getTitle());

    }

}



@Override
public void actionPerformed(ActionEvent e) {
    // TODO Auto-generated method stub
    SADAPP.Manager.WindowManager.MyInternalFrame m = (SADAPP.Manager.WindowManager.MyInternalFrame) WindowManager.INSTANCE.createWindowFor(image);
}



@Override
public void internalFrameActivated(InternalFrameEvent arg0) {
    // TODO Auto-generated method stub
    save.setEnabled(true);
}



@Override
public void internalFrameClosed(InternalFrameEvent arg0) {
    // TODO Auto-generated method stub
    save.setEnabled(false);
}



@Override
public void internalFrameClosing(InternalFrameEvent arg0) {
    // TODO Auto-generated method stub
    save.setEnabled(false);
}



@Override
public void internalFrameDeactivated(InternalFrameEvent arg0) {
    // TODO Auto-generated method stub
    save.setEnabled(false);
}



@Override
public void internalFrameDeiconified(InternalFrameEvent arg0) {
    // TODO Auto-generated method stub
    save.setEnabled(true);
}



@Override
public void internalFrameIconified(InternalFrameEvent arg0) {
    // TODO Auto-generated method stub
    save.setEnabled(false);
}



@Override
public void internalFrameOpened(InternalFrameEvent arg0) {
    // TODO Auto-generated method stub
    save.setEnabled(true);
}



@Override
public void componentHidden(ComponentEvent arg0) {
    // TODO Auto-generated method stub
    save.setEnabled(false);
}



@Override
public void componentMoved(ComponentEvent arg0) {
    // TODO Auto-generated method stub

}



@Override
public void componentResized(ComponentEvent arg0) {
    // TODO Auto-generated method stub
    Rectangle r = WindowManager.INSTANCE.frame.getBounds();

    m.getCanvas().fitToWindow(r);
    System.out.println(""resized- the real one"");
}



@Override
public void componentShown(ComponentEvent arg0) {
    // TODO Auto-generated method stub

}

 }

","The methods of the InternalFrameListener and ComponentListener interfaces won't be called merely by existing. You need to call addInternalFrameListener or addComponentListener on the frame to tell it about your listener.

For example, in the constructor of MyInternalFrame, you want something like:

this.addInternalFrameListener(someInstanceOfTheManagerObject);

"
4944,4944,7873,Is there a general term for a single note or a chord?,"Take a passage like this:



Fill in the blank: Each of these boxes denote a ______

Is there a single general term for these that's better than note or chord? Or maybe there's a term for ""anything that has a duration"" that also encompasses rests? It seems like enough of a fundamental concept that it should have a name.
",Trillian,https://music.stackexchange.com/users/16,"Sound is as good as any. That's till someone writes a rest. Then I'm in trouble...
",Tim,https://music.stackexchange.com/users/2808,http://music.stackexchange.com/questions/17282/is-there-a-general-term-for-a-single-note-or-a-chord,LIFE_ARTS,music.stackexchange.com,1.0,1.0,0.0,1.0,1.0,1.0,0.6666666666666666,0.8333333333333334,1.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,1.0,0.6,0.0,0.0,0.0,1.0,Is there a general term for a single note or chord?,"Take a passage like this:



Fill in the blank: Each of these boxes denote a ______

Is there a single general term for these that's better than note or chord? Or maybe there's a term for ""anything that has a duration"" that also encompasses rests? It seems like enough of a fundamental concept that it should have a name.
",The voice is as good as the others. Until someone wrote a rest. Then I'm in trouble...
1281,1281,2020,Is appending a double quote at the end of an input query a valid XSS prevention method?,"I was wondering if appending a double quote at the end of a query is considered a valid XSS filter. Let's say we have a search function and I entered: 

""&gt;&lt;script&gt;alert('hi')&lt;/script&gt;


If I look at the source of the resulting query I will see the following:

&lt;input name=""search"" type=""text"" value=""""&gt;&lt;script&gt;alert('hi')&lt;/script&gt;""&gt;


The double quote will be appended automatically at the end of my query. 

Assuming that the filter also scrubs out the null char, and HTML comments &lt;!--, would this be an effective XSS filter or is this just wishful thinking?
",Alistair,https://security.stackexchange.com/users/22562,"I can think of no condition in which this would mitigate XSS. 
If an attacker supplies &lt;script&gt;alert(1)&lt;/script&gt;  the result will be:
&lt;script&gt;alert(1)&lt;/script&gt;"" which will still execute.  

Further more,  an attacker can just comment out the double quote in javascript:
alert(1)//""

You don't need an html comment to build valid html:

&lt;input name=""search"" type=""text"" value=""""&gt;&lt;script&gt;alert('hi')&lt;/script&gt;&lt;input name=""inject""&gt;


You should read the XSS prevention cheat sheet,  XSS is extremely common and you shouldn't come up with home-brew solutions to well known problems.
",rook,https://security.stackexchange.com/users/975,http://security.stackexchange.com/questions/33106/is-appending-a-double-quote-at-the-end-of-an-input-query-a-valid-xss-prevention,TECHNOLOGY,security.stackexchange.com,0.8888888888888888,1.0,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,0.8888888888888888,0.8,0.6666666666666666,0.0,0.3333333333333333,0.7777777777777778,Is appending double quotes at the end of an input query an effective XSS prevention method?,"I was wondering if appending a double quote at the end of a query is considered a valid XSS filter. Let's say we have a search function and I entered: 

""&gt;&lt;script&gt;alert('hi')&lt;/script&gt;


If I look at the source of the resulting query I will see the following:

&lt;input name=""search"" type=""text"" value=""""&gt;&lt;script&gt;alert('hi')&lt;/script&gt;""&gt;


The double quote will be appended automatically at the end of my query. 

Assuming that the filter also scrubs out the null char, and HTML comments &lt;!--, would this be an effective XSS filter or is this just wishful thinking?
","I can think of no condition in which this would mitigate XSS. 
If an attacker supplies &lt;script&gt;alert(1)&lt;/script&gt;  the result will be:
&lt;script&gt;alert(1)&lt;/script&gt;"" which will still execute.  

Further more,  an attacker can just comment out the double quote in javascript:
alert(1)//""

You don't need an html comment to build valid html:

&lt;input name=""search"" type=""text"" value=""""&gt;&lt;script&gt;alert('hi')&lt;/script&gt;&lt;input name=""inject""&gt;


You should read the XSS prevention cheat sheet,  XSS is extremely common and you shouldn't come up with home-brew solutions to well known problems.
"
5531,5531,8784,Session Fixation - Setting path to root without /,"I have found an XSS vulnerability on the subdomain of a site I am testing, and using it I can set cookies for both the main site and all it's subdomains. 

My url currently looks like this:

http://s1.example.com/u/%22%3E%3Cmeta%20http-equiv=Set-Cookie%20content=%22sid=1234;%20path=/;%20expires=Thursday,%2020-May-15%2000:15:00%20GMT;%20domain=example.com%22%3E


The issue is that for some reason or another, the character ""/"" is filtered out (no other characters are), meaning that although I can set cookies to the main site and all it's subdomains, I can only set them to the path /u/ as that is where the attack is launched from on the subdomain. Is there any way to set the path to / without actually using the /?

Thank you very much for any help!
",WH567,https://security.stackexchange.com/users/53399,"Remove the whole %20path=/ section - the HTTP response header should set everything at root level.

If that doesn't work inside a meta http-eqiv, try the HTML encoded version of the path as because the content is in HTML should be correctly decoded (&amp;#47;).

Alternatively you could inject JavaScript to set the cookie via client-side script and set the path via entity encoding (\x2f).
",SilverlightFox,https://security.stackexchange.com/users/8340,http://security.stackexchange.com/questions/64812/session-fixation-setting-path-to-root-without,TECHNOLOGY,security.stackexchange.com,1.0,0.5,0.0,1.0,1.0,1.0,0.5,0.5,0.0,0.0,0.5,0.5,0.0,0.0,0.0,0.0,1.0,0.5,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,0.8333333333333334,Session fixed - set root path/,"I have found an XSS vulnerability on the subdomain of a site I am testing, and using it I can set cookies for both the main site and all it's subdomains. 

My url currently looks like this:

http://s1.example.com/u/%22%3E%3Cmeta%20http-equiv=Set-Cookie%20content=%22sid=1234;%20path=/;%20expires=Thursday,%2020-May-15%2000:15:00%20GMT;%20domain=example.com%22%3E


The issue is that for some reason or another, the character ""/"" is filtered out (no other characters are), meaning that although I can set cookies to the main site and all it's subdomains, I can only set them to the path /u/ as that is where the attack is launched from on the subdomain. Is there any way to set the path to / without actually using the /?

Thank you very much for any help!
","Remove the whole %20path=/ section - the HTTP response header should set everything at root level.

If that doesn't work inside a meta http-eqiv, try the HTML encoded version of the path as because the content is in HTML should be correctly decoded (&amp;#47;).

Alternatively you could inject JavaScript to set the cookie via client-side script and set the path via entity encoding (\x2f).
"
5137,5137,8170,Is it okay to vacuum a laptop keyboard?,"Is it okay to vacuum a laptop keyboard? Would it cause any damage?
",dsafdsf,https://superuser.com/users/97559,"There are small (usually USB-powered) vacuums that you can use that do not generate enough force, nor have large enough intakes, to suck the keys of the board.

Most laptops keyboards have pop-off keys and a normal vacuum will take those keys right off. Those that have what are sometimes called ""chiclet"" keys do not generally pop off and should be safe from this particular hazard.

However, a more serious problem is the static charge that the friction from the airflow will create. For this reason it is never recommended to use a normal vacuum for cleaning any computer, ever. Canned air does not create this problem, and there are special electronics vacuums that are properly grounded and use other special components that are much less likely to generate enough of a static charge to damage the sensitive electronic components in a computer. Even these electronics vacuums, though, have no protection against sucking keys off keyboards.

For these reasons, I would recommend against using a vacuum to clean any part of any computer. Canned air should be sufficient for your needs. It's also cheap.
",music2myear,https://superuser.com/users/74026,http://superuser.com/questions/334626,TECHNOLOGY,superuser.com,0.8888888888888888,1.0,0.0,1.0,1.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,0.8888888888888888,0.9333333333333332,0.0,0.3333333333333333,1.0,0.8888888888888888,Can I vacuum my laptop keyboard?,Can I vacuum my laptop keyboard? Is there any damage?,"There are small (usually USB-powered) vacuums that you can use that do not generate enough force, nor have large enough intakes, to suck the keys of the board.

Most laptops keyboards have pop-off keys and a normal vacuum will take those keys right off. Those that have what are sometimes called ""chiclet"" keys do not generally pop off and should be safe from this particular hazard.

However, a more serious problem is the static charge that the friction from the airflow will create. For this reason it is never recommended to use a normal vacuum for cleaning any computer, ever. Canned air does not create this problem, and there are special electronics vacuums that are properly grounded and use other special components that are much less likely to generate enough of a static charge to damage the sensitive electronic components in a computer. Even these electronics vacuums, though, have no protection against sucking keys off keyboards.

For these reasons, I would recommend against using a vacuum to clean any part of any computer. Canned air should be sufficient for your needs. It's also cheap.
"
4017,4017,6414,"What's the difference in meaning between ""emigrate"" and ""immigrate""?","What's the difference between emigrate and immigrate? They seem to have the same definitions in the dictionary but they are antonyms...

&nbsp;
",JFW,https://english.stackexchange.com/users/482,"The ""e"" in emigrate is short for ""ex"", which means ""out"". You see it in words like exit (to leave), expire (out of breath >> out of time >> death), exterminate (to drive out).  

The ""im"" in immigrate is a variant of ""in"", which means in. You see it in words like internal (inside), insinuate (to curve in), input (that which is put in).

This ""in"" should not be confused with the other ""in"" which means ""not"", used in such words as indiscriminate, incapable, and insatiable. 

So, to emigrate means to exit a location. To immigrate means to come into a location.
",Evik James,https://english.stackexchange.com/users/5609,http://english.stackexchange.com/questions/16781/whats-the-difference-in-meaning-between-emigrate-and-immigrate,CULTURE,english.stackexchange.com,1.0,1.0,0.0,1.0,1.0,1.0,0.5555555555555556,0.7777777777777778,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.7777777777777778,1.0,1.0,0.9333333333333332,0.0,0.0,0.0,1.0,"What's the difference between ""immigrants"" and ""immigrants""?","What's the difference between immigrants and immigrants? The dictionary seems to have the same definition, but they are antonyms...","The ""e"" in emigrate is short for ""ex"", which means ""out"". You see it in words like exit (to leave), expire (out of breath >> out of time >> death), exterminate (to drive out).  

The ""im"" in immigrate is a variant of ""in"", which means in. You see it in words like internal (inside), insinuate (to curve in), input (that which is put in).

This ""in"" should not be confused with the other ""in"" which means ""not"", used in such words as indiscriminate, incapable, and insatiable. 

So, to emigrate means to exit a location. To immigrate means to come into a location.
"
5953,5953,9432,What should my credit limit be?,"I have two credit cards (through the same bank).  The first I got at age 18, and the 2nd I applied for while in grad school for better rewards.  I use credit cards (primarily the more recent one) for routine monthly expenses and I pay them off in full every month and reap the rewards.  The limits were pretty low while I was in school, but every 6 months or so they would notify me that they were raising my credit limit by a modest amount.  This continued for a while, but it stopped not long after I left school (which roughly coincided with banks becoming more reluctant to offer credit).

My income has increased several hundred percent over what it was while I was in grad school, and I feel my credit limits do not reflect that.  My combined credit limit between the two cards is a little over 12% of my yearly gross income.  I feel this is probably low, and I might like to increase it both to increase my credit score and to easier allow for multiple large purchases (computer, furniture, etc.) in the same month without using an excessively high portion of my available credit.  What guidelines should I use to determine how much of an increase, if any, to request?
",Michael McGowan,https://money.stackexchange.com/users/3360,"They probably stopped raising your limit because of the credit crisis and new regulations. If you are planning a large purchase then call them and ask for a higher limit. Although with current rates you might be better off finding financing through the retailer or getting a new card with promotions. If you have a good credit score you shouldn't have a problem either way.

I don't think raising a limit ""just because"" makes a lot of sense. Some say it effects your credit score in the long run, but chances are they'll pull your credit when you ask for a raise and that will just lower the score.
",Vitalik,https://money.stackexchange.com/users/1353,http://money.stackexchange.com/questions/8024/what-should-my-credit-limit-be,LIFE_ARTS,money.stackexchange.com,1.0,0.3333333333333333,0.0,1.0,1.0,1.0,0.7777777777777778,0.8888888888888888,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.6666666666666666,0.0,1.0,0.7777777777777778,0.4444444444444444,0.8888888888888888,0.7777777777777778,0.6,0.0,0.0,1.0,1.0,What's my credit limit?,"I have two credit cards (through the same bank). The first was when I was 18, and the second was when I applied for Graduate School in order to get better rewards. I use my credit card (mainly the latest one) to pay for my daily expenses every month. Every month, I will pay in full and get a return. When I went to school, the credit limit was very low, but every six months or so, they would inform me that they would increase my credit limit appropriately. This continued for a while, but stopped shortly after I left school (roughly in line with the growing reluctance of banks to provide credit).","They may stop raising your limit because of the credit crunch and new regulations. If you are planning a big purchase, then call them and ask for a higher limit. Although at current rates, you may be better able to find financing through retailers or get a new card with promotions. If you have a good credit score, you should not have any questions."
891,891,1413,How can I create a recurring task in Google Tasks?,"There's a task that I need to do every Tuesday and Thursday. Is there a way to configure a recurring task in Google Tasks? I can't find it. :-(
",Dan Fabulich,https://webapps.stackexchange.com/users/5507,"As of this moment, no. It seems they are working on it, since it ranked among the top five in a ""top requests"" survey.
",Alex,https://webapps.stackexchange.com/users/1512,http://webapps.stackexchange.com/questions/17020/how-can-i-create-a-recurring-task-in-google-tasks,TECHNOLOGY,webapps.stackexchange.com,1.0,1.0,0.0,1.0,0.3333333333333333,1.0,0.7777777777777778,0.6666666666666666,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,0.6666666666666666,1.0,How to create periodic tasks in Google tasks?,I do one thing every Tuesday and Thursday. Is there any way to configure recurring tasks in Google tasks? I can't find it. - - (,"As of this moment, no. It seems they are working on it, since it ranked among the top five in a ""top requests"" survey.
"
1660,1660,2623,Is lots of red juice normal when making sous-vide steak?,"So I made a 1lb hanger steak via sous-vide the other day and cooked it for 45 minutes at 130F.

After I seared in a cast iron pan, I took the meat off of the pan and let it sit for a few minutes and then sliced it up(against the grain) into smaller portions.

I noticed a lot of red juice in the plate as I was slicing it up but after I put it on a plate and it was sitting at the table, the meat almost ended up swimming in red juice.

When I order medium rare steak at a restaurant and it comes out pre-sliced, I don't usually notice this much red juice.

Is this normal?

UPDATE:

Found this great article explaining what was going on:
http://www.seriouseats.com/2009/12/how-to-have-juicy-meats-steaks-the-food-lab-the-importance-of-resting-grilling.html#continued

He has another article about sous vide ( http://www.seriouseats.com/2010/03/how-to-sous-vide-steak.html ) where he claims that you don't need to let the meat rest after searing. This is the one that originally led me to not need to rest the steak.

Looks like there is some resting that is required. Will post up with results next time I make some steak.
",alexpotato,https://cooking.stackexchange.com/users/7454,"Pretty much...yes, but you can fix it!.

When you properly sous vide or very slow cook anything, you'll retain more of the myoglobin color because of the even cooking that often doesn't go above 140 at all.  So a properly cooked steak like this will retain much more of its red colored myoglobin.  Simply put, the meat will have more red juices to release! (Its a great, great thing about sous vide.)

As @Ronald mentions, the other thing is the resting of the meat.  It's an important step as the muscle fibers relax after the heat is off and hold juices better then.  An often misstep for the home cook is they allow a hot piece of meat to rest on a flat, solid surface.  This causes the bottom of the meat to steam against the board, open the fibers in the meat more, and release the juices on to the board.  Rest your meat on a raised baking rack so that it has air circulation all around it.  

After a short rest - for most steak 10 minutes is fine, then you can cut into the steak.  Use a very sharp knife to slice.  The meat here is essentially a sponge and you don't want to compress it and squeeze out the juices.  A dull knife will do this and you'll lose more juice on the cutting board again.  Use a sharp knife and apply steady, even, but light pressure while slicing - let the edge do the work (if it won't, sharpen the knife more).
",rfusca,https://cooking.stackexchange.com/users/1374,http://cooking.stackexchange.com/questions/17804/is-lots-of-red-juice-normal-when-making-sous-vide-steak,LIFE_ARTS,cooking.stackexchange.com,1.0,1.0,0.0,0.6666666666666666,0.6666666666666666,1.0,0.7777777777777778,0.4444444444444444,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.7777777777777778,1.0,1.0,1.0,0.3333333333333333,0.0,1.0,1.0,Is a lot of red juice normal for steak?,"So I made a 1lb hanger steak via sous-vide the other day and cooked it for 45 minutes at 130F.

After I seared in a cast iron pan, I took the meat off of the pan and let it sit for a few minutes and then sliced it up(against the grain) into smaller portions.

I noticed a lot of red juice in the plate as I was slicing it up but after I put it on a plate and it was sitting at the table, the meat almost ended up swimming in red juice.

When I order medium rare steak at a restaurant and it comes out pre-sliced, I don't usually notice this much red juice.

Is this normal?

UPDATE:

Found this great article explaining what was going on:
http://www.seriouseats.com/2009/12/how-to-have-juicy-meats-steaks-the-food-lab-the-importance-of-resting-grilling.html#continued

He has another article about sous vide ( http://www.seriouseats.com/2010/03/how-to-sous-vide-steak.html ) where he claims that you don't need to let the meat rest after searing. This is the one that originally led me to not need to rest the steak.

Looks like there is some resting that is required. Will post up with results next time I make some steak.
","Pretty much...yes, but you can fix it!.

When you properly sous vide or very slow cook anything, you'll retain more of the myoglobin color because of the even cooking that often doesn't go above 140 at all.  So a properly cooked steak like this will retain much more of its red colored myoglobin.  Simply put, the meat will have more red juices to release! (Its a great, great thing about sous vide.)

As @Ronald mentions, the other thing is the resting of the meat.  It's an important step as the muscle fibers relax after the heat is off and hold juices better then.  An often misstep for the home cook is they allow a hot piece of meat to rest on a flat, solid surface.  This causes the bottom of the meat to steam against the board, open the fibers in the meat more, and release the juices on to the board.  Rest your meat on a raised baking rack so that it has air circulation all around it.  

After a short rest - for most steak 10 minutes is fine, then you can cut into the steak.  Use a very sharp knife to slice.  The meat here is essentially a sponge and you don't want to compress it and squeeze out the juices.  A dull knife will do this and you'll lose more juice on the cutting board again.  Use a sharp knife and apply steady, even, but light pressure while slicing - let the edge do the work (if it won't, sharpen the knife more).
"
3614,3614,5770,Chicken Tikka Masala tastes a bit off,"I have made chicken tikka masala recently and it turned out alright. I got the texture and look properly, but, however, the taste seems a bit off. I have used the chicken tikka masala, onions, cihlli powder, heavy cream, tomato puree and orange peppers, as per directions.

However the taste is not satisfying as I had in restaurants. Anyone can suggest anything to improve my taste? Any spices that I can add or something?

Thanks!
",Nick,https://cooking.stackexchange.com/users/29661,"You aren't getting the 'Indian restaurant' taste because you aren't using Indian restaurant techniques. Most Indian restaurant curries are based on a 'gravy' made with copious amounts of garlic, onions and ginger, stewed for several hours. They also use large amounts of ghee to add richness (and a boatload of calories), and finally they use marinaded chicken, cooked in a tandoor (a very hot, dry oven) which gives a unique flavour.

It is simply not possible to replicate the flavours at home without using the same ingredients or similar techniques. It is not something you can knock up in half an hour.

If you'd like to have a go at replicating a restaurant curry, try reading The Curry Secret by Kris Dhillion.
",ElendilTheTall,https://cooking.stackexchange.com/users/4194,http://cooking.stackexchange.com/questions/50228/chicken-tikka-masala-tastes-a-bit-off,LIFE_ARTS,cooking.stackexchange.com,0.7777777777777778,0.5555555555555556,0.3333333333333333,1.0,0.0,0.3333333333333333,0.6666666666666666,0.5555555555555556,0.3333333333333333,0.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,1.0,0.3333333333333333,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.6666666666666666,0.3333333333333333,0.6666666666666666,1.0,Chicken tikamasala tastes a little bad,"I recently made chicken tikamasala and it turned out to be OK. I got the texture. It looks good, but the taste is not right. I used chicken, onion, sesame powder, heavy cream, tomato puree and orange pepper as instructed.","You aren't getting the 'Indian restaurant' taste because you aren't using Indian restaurant techniques. Most Indian restaurant curries are based on a 'gravy' made with copious amounts of garlic, onions and ginger, stewed for several hours. They also use large amounts of ghee to add richness (and a boatload of calories), and finally they use marinaded chicken, cooked in a tandoor (a very hot, dry oven) which gives a unique flavour.

It is simply not possible to replicate the flavours at home without using the same ingredients or similar techniques. It is not something you can knock up in half an hour.

If you'd like to have a go at replicating a restaurant curry, try reading The Curry Secret by Kris Dhillion.
"
3399,3399,5420,The figure below shows the graph of a function $f(x)$. How many solutions does the equation $f(f(x)) = 15$ have?,"From the graph we can find that, $f(-5)=f(-1)=f(9)=0$


",HOLYBIBLETHE,https://math.stackexchange.com/users/35492,"As Babak points out, we assume the domain of our function is restricted to the interval $(-10, 13)$: 


When $f(x) =4,\;$ $f(f(4)) = 15:\;$ Find the x-values that correspond to all the points where $f(x) = 4$: you should find four such $x$-values: $x = -8, 1, 7.5, 10$.
When $f(x) = 12$, note that $f(f(12)) = 15:$Find the x-values that correspond to where $f(x) = 12$. Again, there should be three or four such values, depending on whether you include the value at the far, far left of the graph: (approximations by ""eying up"" $x =? = -10, x = 3.5, 5.25, 11.5$

",amWhy,https://math.stackexchange.com/users/9003,http://math.stackexchange.com/questions/292119/the-figure-below-shows-the-graph-of-a-function-fx-how-many-solutions-does-t,SCIENCE,math.stackexchange.com,1.0,0.3333333333333333,0.0,0.3333333333333333,1.0,1.0,0.5555555555555556,0.8888888888888888,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,1.0,1.0,0.7777777777777778,1.0,1.0,0.9333333333333332,0.6666666666666666,0.0,0.3333333333333333,1.0,The figure below shows the graph of the function $f (x) $. How many solutions does equation $f (f (x)) = 15 $?,"From the graph, we can see that $f (- 5) = f (- 1) = f (9) = 0$","As Babak points out, we assume the domain of our function is restricted to the interval $(-10, 13)$: 


When $f(x) =4,\;$ $f(f(4)) = 15:\;$ Find the x-values that correspond to all the points where $f(x) = 4$: you should find four such $x$-values: $x = -8, 1, 7.5, 10$.
When $f(x) = 12$, note that $f(f(12)) = 15:$Find the x-values that correspond to where $f(x) = 12$. Again, there should be three or four such values, depending on whether you include the value at the far, far left of the graph: (approximations by ""eying up"" $x =? = -10, x = 3.5, 5.25, 11.5$

"
4946,4946,7876,Shared memory: shmget fails: No space left on device -- how to increase limits?,"I call shmget many times in my program, to get shm of of average size 85840 bytes. I obtain about 32771 shm ok, then shmget doesn't return a shm, but the error: ""No space left on device"".

I have increased the kernel limits to:

$ sysctl -A|grep shm
kernel.shmmax = 33554432
kernel.shmall = 1677721600
kernel.shmmni = 409600


But still get the issue. Why?

Do I have to put something into /etc/security/limits.conf too? I only have
""user             -       nofile          1000000""
because the program also opens about as many files as shms.

This is the output of free

$ free
          total       used       free     shared    buffers     cached
Mem:       8150236    7261676     888560          0     488100    3270792
-/+ buffers/cache:    3502784    4647452 
Swap:     12287992     554692   11733300


And ipcs

$ ipcs -lm                                                                         

------ Shared Memory Limits --------
max number of segments = 409600
max seg size (kbytes) = 1638400
max total shared memory (kbytes) = 6710886400
min seg size (bytes) = 1


Since I assume shm is capable of being swapped out, there should be enough space.
",j13r,https://serverfault.com/users/64249,"As shmget() allocates a new shared memory segment, and you seem to use a lot of them (considering your limits.conf), isn't possible you are using too many shared memory segments? I do not have a lot of experience with calling shmget(), but it seems to me the number of possible open files (1000000) is larger than the amount of allowed shared memory segments (SHMMNI), which is 409600. 
",wzzrd,https://serverfault.com/users/3950,http://serverfault.com/questions/371068,TECHNOLOGY,serverfault.com,0.7777777777777778,0.6666666666666666,0.0,0.3333333333333333,1.0,0.6666666666666666,0.6666666666666666,0.4444444444444444,0.6666666666666666,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.6666666666666666,0.0,0.7777777777777778,0.6666666666666666,0.4444444444444444,0.8888888888888888,0.8888888888888888,0.8,0.0,0.0,1.0,0.6666666666666666,Shared memory: shmget failed: there is no space left on the device -- how to increase the limit?,"I call shmget many times in my program, to get shm of of average size 85840 bytes. I obtain about 32771 shm ok, then shmget doesn't return a shm, but the error: ""No space left on device"".

I have increased the kernel limits to:

$ sysctl -A|grep shm
kernel.shmmax = 33554432
kernel.shmall = 1677721600
kernel.shmmni = 409600


But still get the issue. Why?

Do I have to put something into /etc/security/limits.conf too? I only have
""user             -       nofile          1000000""
because the program also opens about as many files as shms.

This is the output of free

$ free
          total       used       free     shared    buffers     cached
Mem:       8150236    7261676     888560          0     488100    3270792
-/+ buffers/cache:    3502784    4647452 
Swap:     12287992     554692   11733300


And ipcs

$ ipcs -lm                                                                         

------ Shared Memory Limits --------
max number of segments = 409600
max seg size (kbytes) = 1638400
max total shared memory (kbytes) = 6710886400
min seg size (bytes) = 1


Since I assume shm is capable of being swapped out, there should be enough space.
","Because shmget () allocates a new shared memory segment, and you seem to use a lot of shared memory segments (considering your limits. CONF), can't you use too many shared memory segments? I don't have a lot of experience calling shmget(), but in my opinion, the number of files that may be opened (1000000) is greater than the number of shared memory segments (SHMMNI) allowed (409600)."
3916,3916,6244,How can I open a window on a different monitor?,"With multiple monitors, I have so far been dragging windows manually around. Is there a way to make a window open on a specific screen in a dual-head setup? (Not to be confused with multiple X server displays.)

Something like: SCREEN=2 firefox or open-in-screen 2 firefox.

If it matters, my environment is KDE using the KWin window manager. KWin window rules can only match some properties like title, but I could not find an environment variable as filter.

The secondary display extends the primary screen:

$ xrandr -q
Screen 0: minimum 320 x 200, current 3520 x 1080, maximum 32767 x 32767
LVDS1 connected 1600x900+0+0 (normal left inverted right x axis y axis) 382mm x 214mm
   1600x900       60.1*+
   1024x768       60.0  
   800x600        60.3     56.2  
   640x480        59.9  
VGA1 disconnected (normal left inverted right x axis y axis)
HDMI1 connected 1920x1080+1600+0 (normal left inverted right x axis y axis) 477mm x 268mm
   1920x1080      60.0*    50.0     59.9  
   1920x1080i     60.1     50.0     60.0  
   1680x1050      59.9  
   1280x1024      75.0     60.0  
   1440x900       59.9  
   1280x960       60.0  
   1280x720       60.0     50.0     59.9  
   1024x768       75.1     70.1     60.0  
   832x624        74.6  
   800x600        72.2     75.0     60.3     56.2  
   720x576        50.0  
   720x480        60.0     59.9  
   640x480        75.0     72.8     66.7     60.0     59.9  
   720x400        70.1  
DP1 disconnected (normal left inverted right x axis y axis)

",Lekensteyn,https://unix.stackexchange.com/users/8250,"I did come across this method which makes use of xdotool, xprop, &amp; wmctrl.

Here’s what the below script will do:


Find the active window
Get its maximized state and remember it
Remove maximization
Get its geometry
Calculate the new position
Move it
Maximize based on the previous state
Raise it
Here’s a script that does that:


script

This will move the active window to the other monitor. It can only handle a side by side, aka. horizontal, configuration of monitors.

wid=`xdotool getactivewindow`
max_state=`xprop -id $wid _NET_WM_STATE`

wmctrl -ir $wid -b remove,maximized_vert,maximized_horz
eval `xdotool getwindowgeometry --shell $wid`

new_x=1600
if [[ ""$X"" -ge ""$new_x"" ]]; then
  new_x=0
fi

xdotool windowmove $wid $new_x $Y
if [ -z ""${max_state/*_NET_WM_STATE_MAXIMIZED_*/}"" ]; then
  wmctrl -ir $wid -b add,maximized_vert,maximized_horz
fi

xdotool windowraise $wid


Source: Xubuntu – moving windows between monitors
",slm,https://unix.stackexchange.com/users/7453,http://unix.stackexchange.com/questions/106793/how-can-i-open-a-window-on-a-different-monitor,TECHNOLOGY,unix.stackexchange.com,0.8888888888888888,0.6666666666666666,0.0,0.0,1.0,0.5,0.5555555555555556,0.5555555555555556,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.8666666666666666,1.0,0.6666666666666666,0.3333333333333333,0.7777777777777778,How to open windows on different monitors?,"With multiple monitors, I have so far been dragging windows manually around. Is there a way to make a window open on a specific screen in a dual-head setup? (Not to be confused with multiple X server displays.)

Something like: SCREEN=2 firefox or open-in-screen 2 firefox.

If it matters, my environment is KDE using the KWin window manager. KWin window rules can only match some properties like title, but I could not find an environment variable as filter.

The secondary display extends the primary screen:

$ xrandr -q
Screen 0: minimum 320 x 200, current 3520 x 1080, maximum 32767 x 32767
LVDS1 connected 1600x900+0+0 (normal left inverted right x axis y axis) 382mm x 214mm
   1600x900       60.1*+
   1024x768       60.0  
   800x600        60.3     56.2  
   640x480        59.9  
VGA1 disconnected (normal left inverted right x axis y axis)
HDMI1 connected 1920x1080+1600+0 (normal left inverted right x axis y axis) 477mm x 268mm
   1920x1080      60.0*    50.0     59.9  
   1920x1080i     60.1     50.0     60.0  
   1680x1050      59.9  
   1280x1024      75.0     60.0  
   1440x900       59.9  
   1280x960       60.0  
   1280x720       60.0     50.0     59.9  
   1024x768       75.1     70.1     60.0  
   832x624        74.6  
   800x600        72.2     75.0     60.3     56.2  
   720x576        50.0  
   720x480        60.0     59.9  
   640x480        75.0     72.8     66.7     60.0     59.9  
   720x400        70.1  
DP1 disconnected (normal left inverted right x axis y axis)

","I did come across this method which makes use of xdotool, xprop, &amp; wmctrl.

Here’s what the below script will do:


Find the active window
Get its maximized state and remember it
Remove maximization
Get its geometry
Calculate the new position
Move it
Maximize based on the previous state
Raise it
Here’s a script that does that:


script

This will move the active window to the other monitor. It can only handle a side by side, aka. horizontal, configuration of monitors.

wid=`xdotool getactivewindow`
max_state=`xprop -id $wid _NET_WM_STATE`

wmctrl -ir $wid -b remove,maximized_vert,maximized_horz
eval `xdotool getwindowgeometry --shell $wid`

new_x=1600
if [[ ""$X"" -ge ""$new_x"" ]]; then
  new_x=0
fi

xdotool windowmove $wid $new_x $Y
if [ -z ""${max_state/*_NET_WM_STATE_MAXIMIZED_*/}"" ]; then
  wmctrl -ir $wid -b add,maximized_vert,maximized_horz
fi

xdotool windowraise $wid


Source: Xubuntu – moving windows between monitors
"
5162,5162,8203,Energy vs. Power,"Is there a rule in English regarding when to use the word ""energy"" and when to use ""power""?

For example:


  
  I don't have the energy to deal with the problem now.
  It takes a lot of brain power to understand the problem.
  

",Steven,https://english.stackexchange.com/users/118888,"In physics, energy is the ability to do work (or the work done), while power is rate of energy output.  So if I push a boulder up a hill, I expend the same amount of energy regardless of how long it takes me.  However, doing it in a shorter time period requires more power.

I know you're probably not concerned with this technical distinction.  But it is good to know.  For example, now you know that it is correct to say ""The car is very powerful: It can accelerate from zero to sixty in three seconds,"" and ""It required a huge amount of energy to erect the ancient pyramids.""
",Anthony,https://english.stackexchange.com/users/118899,http://english.stackexchange.com/questions/242359/energy-vs-power,CULTURE,english.stackexchange.com,1.0,0.4444444444444444,0.0,1.0,1.0,1.0,0.5555555555555556,0.7777777777777778,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.4444444444444444,0.7777777777777778,0.6666666666666666,1.0,0.8888888888888888,0.8,0.0,0.0,0.6666666666666666,0.8888888888888888,Energy and power,"Is there a rule in English regarding when to use the word ""energy"" and when to use ""power""?

For example:


  
  I don't have the energy to deal with the problem now.
  It takes a lot of brain power to understand the problem.
  

","In physics, energy is the ability to do work (or the work done), while power is rate of energy output.  So if I push a boulder up a hill, I expend the same amount of energy regardless of how long it takes me.  However, doing it in a shorter time period requires more power.

I know you're probably not concerned with this technical distinction.  But it is good to know.  For example, now you know that it is correct to say ""The car is very powerful: It can accelerate from zero to sixty in three seconds,"" and ""It required a huge amount of energy to erect the ancient pyramids.""
"
2000,2000,3193,Connect OpenLayers3 Client with QGIS Server,"at the moment I am developing a map editor on a  web.

After researching at the internet about map clients, I decided to use OpenLayers3 client because it is very simple an has all the tools i need for my project.

So, my question is:

 - It is possible to connect OpenLayers3 Client with QGIS Server?

",Alcaamado,https://gis.stackexchange.com/users/44972,"Yes you can for example use the WMS-Layer from your QGIS-Server in ol3:

http://jsfiddle.net/expedio/0woc6xL3/
",Thomas B,https://gis.stackexchange.com/users/45041,http://gis.stackexchange.com/questions/130200/connect-openlayers3-client-with-qgis-server,TECHNOLOGY,gis.stackexchange.com,1.0,0.6666666666666666,0.0,1.0,1.0,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,1.0,0.6666666666666666,0.0,0.3333333333333333,0.8888888888888888,Connect openlayers3 client to QGIS server,"at the moment I am developing a map editor on a  web.

After researching at the internet about map clients, I decided to use OpenLayers3 client because it is very simple an has all the tools i need for my project.

So, my question is:

 - It is possible to connect OpenLayers3 Client with QGIS Server?

","Yes you can for example use the WMS-Layer from your QGIS-Server in ol3:

http://jsfiddle.net/expedio/0woc6xL3/
"
414,414,644,Why choose an 80-200mm over an 18-200mm lens?,"Being a beginner, I can't see why I must choose an 80-200 over an 18-200. Are there scenarios where an 80-200 would be preferable over an 18-200?

I will be buying a D7000 soon and am looking at these:


AF Zoom-NIKKOR 80-200mm f/2.8D ED
AF-S DX NIKKOR 18-200mm f/3.5-5.6G ED VR II


but similar considerations would apply to other brands as well.
",Ygam,https://photo.stackexchange.com/users/2362,"As a really, really broad generalization, it's easier to make a high-quality zoom lens with a smaller zoom range, rather than a larger one.  Although it's really tempting to look for one zoom that'll cover your entire range of shooting (Tamron's 18-270 comes to mind), these lenses tend to be fairly ill-behaved over portions of their range (at least), and suffer from softness and complex distortions that aren't easily fixed in post-processing.

The two lenses you indicate are really fairly different; the 80-200 is a fast lens (f/2.8), while the 18-200 is quite a bit slower.  You'd be giving up a lot of optical performance to get that extra range, which is why most people end up covering this range with two lenses, more or less.
",D. Lambert,https://photo.stackexchange.com/users/269,http://photo.stackexchange.com/questions/11247/why-choose-an-80-200mm-over-an-18-200mm-lens,LIFE_ARTS,photo.stackexchange.com,1.0,0.7777777777777778,0.0,0.3333333333333333,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.0,0.0,0.6666666666666666,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,0.6666666666666666,0.8888888888888888,Why 80-200mm instead of 18-200mm?,"Being a beginner, I can't see why I must choose an 80-200 over an 18-200. Are there scenarios where an 80-200 would be preferable over an 18-200?

I will be buying a D7000 soon and am looking at these:


AF Zoom-NIKKOR 80-200mm f/2.8D ED
AF-S DX NIKKOR 18-200mm f/3.5-5.6G ED VR II


but similar considerations would apply to other brands as well.
","As a very broad generalization, it is easier to make a high quality zoom lens with a smaller zoom range than with a larger zoom range. Although it's tempting to find a zoom lens that can cover the whole shooting range (think of Tamron's 18-270), these lenses are not very good (at least) in part of the shooting range, and have soft and complex distortions, which are not easy to repair in post-processing."
5195,5195,8253,How to change rotation direction of 3-phase electrical machines?,"I was taught that if you want to change the direction of a three phase rotating machine that is rotating in forward direction, you interchange the phases. Since the phases has the same features (voltage and current), what is responsible for making the machine to rotate in reverse direction, when the phases are interchanged?
",Ezeatum Solomon,https://electronics.stackexchange.com/users/82333,"The windings in a 3 phase motor, when activated by a 3 phase supply produce a rotating magnetic field in the rotor area of the motor. Swapping phase A with phase B re-orders the fluxes so that the flux rotates in the opposite direction. Swapping B with C does exactly the same thing as does swapping A with C. Think of it like a triangle with corners called A, B and C. If you swap any two corners and follow the points A, B and C you'll go in anopposite direction. Swap two more corners and you're back to the original rotation.

This is what it looks like. The black arrow is the flux produced by the three phase windings: -



Clearly, if yellow phase were swapped with blue phase the rotation would be opposite.
",Andy aka,https://electronics.stackexchange.com/users/20218,http://electronics.stackexchange.com/questions/182800/how-to-change-rotation-direction-of-3-phase-electrical-machines,SCIENCE,electronics.stackexchange.com,1.0,0.7777777777777778,0.0,1.0,0.6666666666666666,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.3333333333333333,0.3333333333333333,1.0,1.0,How to change the rotation direction of three-phase motor?,"I have been taught that if you want to change the direction of a three-phase rotating machine that is rotating in a positive direction, you have to change the phase. Since the phases have the same characteristics (voltage and current), when the phases are interchanged, what causes the machine to rotate in reverse?","When the winding in a three-phase motor is activated by a three-phase power supply, a rotating magnetic field is generated in the rotor area of the motor. Change phase A and phase B to each other, rearrange the flux, and make the flux rotate in the opposite direction. Replacing B with C does exactly the same thing as replacing a with C. Think of it as a triangle. The angles of a triangle are called a, B and C. If you replace points a, B and C with any two corners, you will move in the opposite direction. If you exchange two more angles, you will return to the original direction of rotation."
105,105,171,Is my old bike safe?,"The old bike is a Cannondale R-600 purchased in 1999. 


Original key components. Frame, fork. (Aluminum frame, carbon fork)
Ridden for several thousand miles. 
Well maintained. (Various parts have been replaced and upgraded over time.)
A few visible minor dings here and there.


Question: Is the frame/fork safe? I can sell it or trash it. 
",none,https://bicycles.stackexchange.com/users/4389,"If it were a steel frame and fork there would be no question -- steel lasts nearly forever, even when moderately rusty, and can take all sorts of abuse.

Aluminum is a bit less robust, but if it only has ""a few thousand"" miles on it (and not 30,000) and has not been abused (or hit by a car) then it should be good.  The problem with aluminum is that it can develop hidden cracks, but you've given us no reason to suspect that of this bike.

The carbon fork is also less robust than steel, and can develop hidden cracks.  But again, unless there's something in its history to make it suspect then it should be fine.

Certainly age is not a problem.  Nothing really ""ages"" on a bike beyond the tires (and, to a slight extent, the lubes).  (It could be true that the carbon fiber will deteriorate after 50 years or so, but that's something for your grandchildren to worry about.)

Frankly, I'm a little curious as to why you're concerned.
",Daniel R Hicks,https://bicycles.stackexchange.com/users/1584,http://bicycles.stackexchange.com/questions/14279/is-my-old-bike-safe,CULTURE,bicycles.stackexchange.com,1.0,0.3333333333333333,0.3333333333333333,1.0,0.0,0.0,0.8888888888888888,0.6666666666666666,0.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.8888888888888888,0.7777777777777778,1.0,1.0,0.8666666666666666,0.0,0.0,0.6666666666666666,1.0,Is my old bike safe?,"The old bike is a Cannondale R-600 purchased in 1999. 


Original key components. Frame, fork. (Aluminum frame, carbon fork)
Ridden for several thousand miles. 
Well maintained. (Various parts have been replaced and upgraded over time.)
A few visible minor dings here and there.


Question: Is the frame/fork safe? I can sell it or trash it. 
","If it were a steel frame and fork there would be no question -- steel lasts nearly forever, even when moderately rusty, and can take all sorts of abuse.

Aluminum is a bit less robust, but if it only has ""a few thousand"" miles on it (and not 30,000) and has not been abused (or hit by a car) then it should be good.  The problem with aluminum is that it can develop hidden cracks, but you've given us no reason to suspect that of this bike.

The carbon fork is also less robust than steel, and can develop hidden cracks.  But again, unless there's something in its history to make it suspect then it should be fine.

Certainly age is not a problem.  Nothing really ""ages"" on a bike beyond the tires (and, to a slight extent, the lubes).  (It could be true that the carbon fiber will deteriorate after 50 years or so, but that's something for your grandchildren to worry about.)

Frankly, I'm a little curious as to why you're concerned.
"
3440,3440,5472,What is it called when a music has two concurrent tempos,"I've recently watched a BBC documentary about the history of music and recall an episode where they talk about music that has two distinct tempos (and possibly time signatures) at the same time for different sets of instruments.

Still, I can't remember how this is called and who are the famous composers that composed that way (Stravinsky?).
",Arthur Rizzo,https://music.stackexchange.com/users/16830,"Neilsen's 5th symphony was an early example (1922). Towards the end of the first movement, the side drum part is in a different tempo and time signature from the rest of the orchestra. The first edition of the score instructed the drummer to ""improvise as if at all costs he wants to stop the progress of the orchestra"". 

In a later edition that instruction was replaced by a written part which breaks off with the direction ""cadenza ad lib"".

Skip to about 14:45 here: 
            
                
                    
                    
                    
                    
                    
                
             (There is also an important side drum part in a more ""conventional"" rhythm earlier in the piece.
",alephzero,https://music.stackexchange.com/users/19146,http://music.stackexchange.com/questions/30524/what-is-it-called-when-a-music-has-two-concurrent-tempos,LIFE_ARTS,music.stackexchange.com,1.0,0.4444444444444444,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.6666666666666666,0.0,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.8888888888888888,1.0,0.4444444444444444,1.0,1.0,0.8666666666666666,0.3333333333333333,0.0,0.6666666666666666,1.0,What is the name of a music when it has two simultaneous rhythms,"I recently watched a BBC Documentary on the history of music, and I recall an episode in which they talked about music that has two different rhythms (and possibly time characteristics) in different instrument combinations.","Neilsen's 5th symphony was an early example (1922). Towards the end of the first movement, the side drum part is in a different tempo and time signature from the rest of the orchestra. The first edition of the score instructed the drummer to ""improvise as if at all costs he wants to stop the progress of the orchestra"". 

In a later edition that instruction was replaced by a written part which breaks off with the direction ""cadenza ad lib"".

Skip to about 14:45 here: 
            
                
                    
                    
                    
                    
                    
                
             (There is also an important side drum part in a more ""conventional"" rhythm earlier in the piece.
"
4304,4304,6859,Water Supply pressure,"What size supply pipe must be used from a 5000 litre water tank to supply 4 bars of pressure to a house that is 20m below and 300m away from the tank?
",Sandy,https://diy.stackexchange.com/users/35971,"Pressure of the gravity fed water delivered from the overhead tank will have nothing to do with the pipe size used. The pressure is dependent only on the vertical distance between the top of the water in the tank and the delivery point. 

Where pipe size does come into play is in the flow rate that is needed at the delivery point. If you only have one delivery point being used at a time you can get by with a pipe size that can deliver the desired flow rate all the way back to the tank. 

If you have multiple delivery points in use at one time then the branch lines from those delivery points will have to merge into a larger pipe at some point and then this larger pipe goes the rest of the way back to the tank. You roughly work out the size of this larger pipe needing to have a cross sectional area that is the sum of the cross sectional areas of the multiple use delivery point pipes.
",Michael Karas,https://diy.stackexchange.com/users/7367,http://diy.stackexchange.com/questions/64247/water-supply-pressure,LIFE_ARTS,diy.stackexchange.com,1.0,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,1.0,0.6666666666666666,0.5555555555555556,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.5555555555555556,1.0,0.8888888888888888,1.0,1.0,0.8666666666666666,0.3333333333333333,0.3333333333333333,1.0,1.0,Water supply pressure,How much water supply pipe must be used from a 5000 litre tank to provide 4 bar pressure for a house 20 meters below and 300 meters from the tank?,"Pressure of the gravity fed water delivered from the overhead tank will have nothing to do with the pipe size used. The pressure is dependent only on the vertical distance between the top of the water in the tank and the delivery point. 

Where pipe size does come into play is in the flow rate that is needed at the delivery point. If you only have one delivery point being used at a time you can get by with a pipe size that can deliver the desired flow rate all the way back to the tank. 

If you have multiple delivery points in use at one time then the branch lines from those delivery points will have to merge into a larger pipe at some point and then this larger pipe goes the rest of the way back to the tank. You roughly work out the size of this larger pipe needing to have a cross sectional area that is the sum of the cross sectional areas of the multiple use delivery point pipes.
"
5422,5422,8608,"Which parts of the Eclipse Platform, if any, adhere to ISO 9241?","Has the Eclipse Platform implemented with any concepts of ISO-9241 in mind? If so, which parts?

Is the menu functionality provided by the Eclipse Rich Client Platform adhering to ISO 9241-14:1997. Ergonomic requirements for office work with visual display terminals (VDTs) -- Part 14: Menu dialogues, if used standardly, as implicated by the providers?
",s.d,https://ux.stackexchange.com/users/35602,"In the 2007 Master thesis Exploring Usability Guidelines for Rich Internet Applications  Eclipse is mentioned as a tool used, but never in compliance with ISO 9241. The same goes for the Eclipse wiki, where Rich Client Platform is a big part. Nothing on ISO 9241 is mentioned on these pages. If you search for ""ISO"" you find reference to other standards such as 8807, ISO-8859-1 (8-bit single-byte coded graphic character sets used in web pages), 3166, 704, 9000 and more standards - but not 9241.

To conclude, it's a fair assumption that Eclipse Rich Client Platform is not complaint with ISO-9241. If it where, it would have been mentioned.
",Benny Skogberg,https://ux.stackexchange.com/users/4679,http://ux.stackexchange.com/questions/45003/which-parts-of-the-eclipse-platform-if-any-adhere-to-iso-9241,TECHNOLOGY,ux.stackexchange.com,1.0,0.6666666666666666,0.0,0.3333333333333333,1.0,1.0,0.3333333333333333,0.3333333333333333,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,0.8888888888888888,"Which parts of the Eclipse platform, if any, follow ISO 9241?","Has the Eclipse Platform implemented with any concepts of ISO-9241 in mind? If so, which parts?

Is the menu functionality provided by the Eclipse Rich Client Platform adhering to ISO 9241-14:1997. Ergonomic requirements for office work with visual display terminals (VDTs) -- Part 14: Menu dialogues, if used standardly, as implicated by the providers?
","In a 2007 master's thesis, exploring the usability guidelines for rich Internet applications, eclipse was mentioned as a tool to use, but it never met iso9241. The same is true for eclipse wikis, where the rich client platform is an important part. Iso9241 is not mentioned on these pages. If you search for ""ISO,"" you will find references to other standards, such as 8807, iso-8859-1 (8-bit single byte coded graphic character set used in web pages), 3166, 704, 9000, and more, but not 9241."
1606,1606,2524,iTextSharp read pdf template from hard drive and write text,"I have a basic PDF file that I has 5 different blank content areas that I want to use iTextSharp to write text too.  The problem is I'm not sure the best way to accomplish this.  I have attempted to use ColumnText to accomplish this, but I cannot seem to add multiple ColumnText objects.  

            ColumnText tagColumn = new ColumnText(pdfContentByte);
            tagColumn.SetSimpleColumn(460, 100, 620, 160);
            string[] tagColors = bt.DealerTagColor.Split('|');
            Font tagFont = FontFactory.GetFont(bt.DealerTagFont, bt.DealerTagSize, Font.NORMAL, new BaseColor(int.Parse(tagColors[0]), int.Parse(tagColors[1]), int.Parse(tagColors[2])));
            Paragraph p = new Paragraph(dto.Tag, tagFont);
            p.Leading = bt.DealerTagSize;
            tagColumn.AddElement(p);
            tagColumn.Go();


What I like about the ColumnText is it allows me to essential define a heigth/width, and position of the text area.  

Any thoughts on how I can accomplish this with or without using ColumnText?   I just need to have control of the font/fontsize/font color/leading/and width of the area which will allow the text to wrap.
",aherrick,https://stackoverflow.com/users/20446,"The easiest way would be to create and use form fields on your template PDF.  This way you can reference a form field by name and set its value with a simple function call.

This article helped me:

Fill in PDF Form Fields using the Open Source iTextSharp Dynamic Link Library

EDIT: PdfPTables?

If your ColumnTexts are tabularly arranged consider using a PdfPTable.  I've used PdfPTables to fill rows of data in forms generated from a blank template form.  You need to figure out the x-coordinate of each of your columns and use these values when adding PdfPCells to your table, but it does work.  I've never had to set an upper limit to the height of a PdfPCell but I image you can do it.

Check this page for more on PdfPTables.
",Jay Riggs,https://stackoverflow.com/users/52249,http://stackoverflow.com/questions/2039351/itextsharp-read-pdf-template-from-hard-drive-and-write-text,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.4444444444444444,0.0,0.5,1.0,1.0,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,1.0,0.6666666666666666,0.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.8,0.3333333333333333,0.6666666666666666,0.0,0.7777777777777778,Itextsharp reads PDF templates from the hard disk and writes text,"I have a basic PDF file that I has 5 different blank content areas that I want to use iTextSharp to write text too.  The problem is I'm not sure the best way to accomplish this.  I have attempted to use ColumnText to accomplish this, but I cannot seem to add multiple ColumnText objects.  

            ColumnText tagColumn = new ColumnText(pdfContentByte);
            tagColumn.SetSimpleColumn(460, 100, 620, 160);
            string[] tagColors = bt.DealerTagColor.Split('|');
            Font tagFont = FontFactory.GetFont(bt.DealerTagFont, bt.DealerTagSize, Font.NORMAL, new BaseColor(int.Parse(tagColors[0]), int.Parse(tagColors[1]), int.Parse(tagColors[2])));
            Paragraph p = new Paragraph(dto.Tag, tagFont);
            p.Leading = bt.DealerTagSize;
            tagColumn.AddElement(p);
            tagColumn.Go();


What I like about the ColumnText is it allows me to essential define a heigth/width, and position of the text area.  

Any thoughts on how I can accomplish this with or without using ColumnText?   I just need to have control of the font/fontsize/font color/leading/and width of the area which will allow the text to wrap.
","The easiest way would be to create and use form fields on your template PDF.  This way you can reference a form field by name and set its value with a simple function call.

This article helped me:

Fill in PDF Form Fields using the Open Source iTextSharp Dynamic Link Library

EDIT: PdfPTables?

If your ColumnTexts are tabularly arranged consider using a PdfPTable.  I've used PdfPTables to fill rows of data in forms generated from a blank template form.  You need to figure out the x-coordinate of each of your columns and use these values when adding PdfPCells to your table, but it does work.  I've never had to set an upper limit to the height of a PdfPCell but I image you can do it.

Check this page for more on PdfPTables.
"
1611,1611,2529,iOS fetching from managed object context before saved,"If I add entities to a moc and I execute a fetch request on that moc before its document gets a chance to save, will my fetch contain the newly added entities? (I'm unsure how to test this out because of the auto-save feature)
",user1529956,https://stackoverflow.com/users/1529956,"I guess you're using UIDocument when you say 'auto-saving'. If you aren't, then there is no 'auto-saving' (except when using Apple template code and the app delegate saves before termination).

When you create the fetch request, you can choose whether it should include unsaved items using the includesPendingChanges property. It defaults to YES so by default you will see unsaved items in the results.
",Wain,https://stackoverflow.com/users/1988185,http://stackoverflow.com/questions/17054254/ios-fetching-from-managed-object-context-before-saved,STACKOVERFLOW,stackoverflow.com,1.0,0.3333333333333333,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,0.0,1.0,Get IOS from managed object context before saving,"If I add an entity to a MOC and perform a fetch request on the MOC's document before it has a chance to save, does my fetch contain the newly added entity? (I'm not sure how to test due to the auto save feature)","I guess you're using UIDocument when you say 'auto-saving'. If you aren't, then there is no 'auto-saving' (except when using Apple template code and the app delegate saves before termination).

When you create the fetch request, you can choose whether it should include unsaved items using the includesPendingChanges property. It defaults to YES so by default you will see unsaved items in the results.
"
2234,2234,3563,What are the best tips for saving money as a university student?,"What are the best tips for saving money as a university student?

I will be attending university this coming semester and am planning on maintaining a sustainable financial situation right now, but would like any good tips or suggestions to saving money as a student.
",JFW,https://money.stackexchange.com/users/1408,"Here's a few:


If your plan results in carrying $100k in student debt at the end, you need a new plan.
Don't drink unless someone else is paying, or if you're buying a special.
Don't live beyond your means.

",duffbeer703,https://money.stackexchange.com/users/1288,http://money.stackexchange.com/questions/6455/what-are-the-best-tips-for-saving-money-as-a-university-student,LIFE_ARTS,money.stackexchange.com,1.0,0.8888888888888888,0.6666666666666666,0.3333333333333333,0.0,0.0,0.7777777777777778,0.7777777777777778,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,1.0,0.5555555555555556,0.4444444444444444,0.6666666666666666,1.0,0.5333333333333333,0.3333333333333333,0.0,0.0,0.8888888888888888,"As a college student, what is the best way to save money?","What are the best tips for saving money as a university student?

I will be attending university this coming semester and am planning on maintaining a sustainable financial situation right now, but would like any good tips or suggestions to saving money as a student.
","Here's a few:


If your plan results in carrying $100k in student debt at the end, you need a new plan.
Don't drink unless someone else is paying, or if you're buying a special.
Don't live beyond your means.

"
1251,1251,1967,How can toddlers expend seemingly boundless energy when they eat so little?,"A toddler's food intake seems very little: only milk and water and some solid food. Therefore, from where does this energy come?
",Jack,https://biology.stackexchange.com/users/6589,"They don't eat little. Consider the volume of milk / food they consume as a ratio of their weight. Quite the contrary they are ravenous machines and their consumption is much higher than an average adult. All cellular energy comes from the hydrolysis of ATP, and the production of ATP comes from the breakdown of glucose. The glucose comes from a sugar found in breast milk, called lactose.
",rhill45,https://biology.stackexchange.com/users/6061,http://biology.stackexchange.com/questions/17117/how-can-toddlers-expend-seemingly-boundless-energy-when-they-eat-so-little,SCIENCE,biology.stackexchange.com,1.0,0.7777777777777778,0.0,1.0,1.0,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,1.0,"Children eat so little, how can you consume seemingly endless energy?","Children's food intake seems to be small: only milk, water and some solid food. So where does this energy come from?","They don't eat little. Consider the volume of milk / food they consume as a ratio of their weight. Quite the contrary they are ravenous machines and their consumption is much higher than an average adult. All cellular energy comes from the hydrolysis of ATP, and the production of ATP comes from the breakdown of glucose. The glucose comes from a sugar found in breast milk, called lactose.
"
3046,3046,4854,Derivation of relationship between Gibbs free energy and electrochemical cell potential,"
  Why is $\Delta G=-nFE?$


I don't understand what the motivation is behind this definition. Was it derived or just given? The textbook provides no justification for this equation. In fact, much of the book associated with the Gibbs free energy provides no justification and just says, 'This is how it is. Now go and solve some problems.'
",Greg,https://chemistry.stackexchange.com/users/1758,"I'm surprised your textbook did not derive this equation from the reaction isotherm relationship between $\Delta G$ and the reaction quotient $Q$ and the Nernst equation. The derivation is not hard.

Reaction isotherm equation:

$$\Delta_r G =\Delta_r G^\circ +RT\ln Q$$

Nernst Equation:

$$E_{cell}=E^\circ_{cell} -\frac{RT}{nF}\ln Q$$

If we solve both equations for $RT\ln Q$, we get your equation (almost).

$$RT\ln Q = \Delta_r G -\Delta_r G^\circ$$
$$RT\ln Q = nFE^\circ_{cell} - nFE_{cell}$$
$$\Delta_r G -\Delta_r G^\circ = nFE^\circ_{cell} - nFE_{cell}$$

Why is my equation not as simple as the one you started with? Your equation is at equilibrium, and I assumed that we might not be at equilibrium. At equilibrium, the following are true, which simplify the relationship.

$$Q=K$$
$$\Delta_r G = 0$$
$$E_{cell} = 0$$

At equilibrium, $\Delta_r G = 0$ because the reaction has achieved a minimum energy state - the chemical potential $\mu_i=(\dfrac{\partial G}{\partial N_i})_{T,P}$ is also $0$ because there is no net change of state at equilibrium. Similarly $E_{cell} = 0$ at equilibrium. There is no change of state, and thus the redox reaction has ground to a halt.

At equilibrium, the final relationship is 

$$\Delta_RG^\circ = nFE^\circ_{cell}$$
",Ben Norris,https://chemistry.stackexchange.com/users/275,http://chemistry.stackexchange.com/questions/6826/derivation-of-relationship-between-gibbs-free-energy-and-electrochemical-cell-po,SCIENCE,chemistry.stackexchange.com,0.5,0.5,0.0,0.5,1.0,0.5,0.6666666666666666,0.3333333333333333,0.5,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.5,0.0,0.5,0.0,0.8333333333333334,0.6666666666666666,0.8333333333333334,0.6666666666666666,1.0,0.9,1.0,0.5,1.0,0.8333333333333334,Derivation of the relationship between Gibbs free energy and electrochemical cell potential,"
  Why is $\Delta G=-nFE?$


I don't understand what the motivation is behind this definition. Was it derived or just given? The textbook provides no justification for this equation. In fact, much of the book associated with the Gibbs free energy provides no justification and just says, 'This is how it is. Now go and solve some problems.'
","I'm surprised your textbook did not derive this equation from the reaction isotherm relationship between $\Delta G$ and the reaction quotient $Q$ and the Nernst equation. The derivation is not hard.

Reaction isotherm equation:

$$\Delta_r G =\Delta_r G^\circ +RT\ln Q$$

Nernst Equation:

$$E_{cell}=E^\circ_{cell} -\frac{RT}{nF}\ln Q$$

If we solve both equations for $RT\ln Q$, we get your equation (almost).

$$RT\ln Q = \Delta_r G -\Delta_r G^\circ$$
$$RT\ln Q = nFE^\circ_{cell} - nFE_{cell}$$
$$\Delta_r G -\Delta_r G^\circ = nFE^\circ_{cell} - nFE_{cell}$$

Why is my equation not as simple as the one you started with? Your equation is at equilibrium, and I assumed that we might not be at equilibrium. At equilibrium, the following are true, which simplify the relationship.

$$Q=K$$
$$\Delta_r G = 0$$
$$E_{cell} = 0$$

At equilibrium, $\Delta_r G = 0$ because the reaction has achieved a minimum energy state - the chemical potential $\mu_i=(\dfrac{\partial G}{\partial N_i})_{T,P}$ is also $0$ because there is no net change of state at equilibrium. Similarly $E_{cell} = 0$ at equilibrium. There is no change of state, and thus the redox reaction has ground to a halt.

At equilibrium, the final relationship is 

$$\Delta_RG^\circ = nFE^\circ_{cell}$$
"
5923,5923,9380,QGIS: How to get Symbols saved in GPX Files,"I have some waypoint layers that contain different types of points and I distinguish these in QGIS by different symbols and colours.  I want to export these to a GPX file that I can download to my GPS but The GPX file contains just the lat, long and the 'type'.  

Is there a way of getting gpstool to save other attributes in a gpx file?

I do get some more data out in  (gid, source and classification) so I can write a script to process the xml and add the necessary attributes that the GPS expects.

Secondary question:  Would this make a useful plugin?
",Russell Fulton,https://gis.stackexchange.com/users/14406,"Using pure GDAL, you can preserve the waypoint symbol and type of an original GPX file with

ogr2ogr -f GPX -dsco GPX_USE_EXTENSIONS=YES out.gpx in.gpx waypoints

&lt;wpt lat=""51.295094"" lon=""6.790674""&gt;
  &lt;ele&gt;39.0&lt;/ele&gt;
  &lt;time&gt;2014-10-14T13:56:58Z&lt;/time&gt;
  &lt;name&gt;Push Log Point #1&lt;/name&gt;
  &lt;desc&gt;Lat.=51.295094, Long.=6.790674, Alt.=39.000000m, Speed=3Km/h, Course=45deg.&lt;/desc&gt;
  &lt;sym&gt;Waypoint&lt;/sym&gt;
  &lt;type&gt;Other&lt;/type&gt;
  &lt;extensions&gt;
    &lt;label&gt;&lt;label_text&gt;Push Log Point #1&lt;/label_text&gt;&lt;/label&gt;
  &lt;/extensions&gt;
&lt;/wpt&gt;


So if you have a shapefile in QGIS, create columns with names sym and type and export it to GPX format with GPX_USE_EXTENSIONS=YES (which is default for GPX since QGIS 2.4).

Remember to save into EPSG:4326, as GPX only allows that.

Other features (like label) will be exported in the &lt;extensions&gt; element, and probably ignored by a GPS unit. My output reads as follows:

&lt;wpt lat=""51.295094"" lon=""6.790674""&gt;
  &lt;name&gt;Push Log Point #1&lt;/name&gt;
  &lt;sym&gt;Waypoint&lt;/sym&gt;
  &lt;type&gt;Other&lt;/type&gt;
  &lt;extensions&gt;
    &lt;ogr:elevation&gt;39.0&lt;/ogr:elevation&gt;
    &lt;ogr:label&gt;1&lt;/ogr:label&gt;
  &lt;/extensions&gt;
&lt;/wpt&gt;
&lt;wpt lat=""51.295091"" lon=""6.790663""&gt;
  &lt;name&gt;Push Log Point #2&lt;/name&gt;
  &lt;sym&gt;church&lt;/sym&gt;
  &lt;type&gt;tower&lt;/type&gt;
  &lt;extensions&gt;
    &lt;ogr:elevation&gt;38.0&lt;/ogr:elevation&gt;
    &lt;ogr:label&gt;2&lt;/ogr:label&gt;
  &lt;/extensions&gt;
&lt;/wpt&gt;


The available symbols depend on the GPS units, so you might create a sample GPX file with the unit and test all available symbols. These will not be imported into QGIS, but you can read the file with a text editor.

As an example, symbols of the Garmin Oregon 6xx are listed at this site. You can even create your own symbols and upload them.
",AndreJ,https://gis.stackexchange.com/users/9159,http://gis.stackexchange.com/questions/118852/qgis-how-to-get-symbols-saved-in-gpx-files,TECHNOLOGY,gis.stackexchange.com,1.0,0.4444444444444444,0.0,0.0,1.0,0.0,0.3333333333333333,1.0,1.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,0.0,1.0,1.0,0.5555555555555556,1.0,1.0,0.8666666666666666,1.0,0.0,0.0,1.0,QGIS: how to get symbols saved in GPX file,"I have some waypoint layers that contain different types of points and I distinguish these in QGIS by different symbols and colours.  I want to export these to a GPX file that I can download to my GPS but The GPX file contains just the lat, long and the 'type'.  

Is there a way of getting gpstool to save other attributes in a gpx file?

I do get some more data out in  (gid, source and classification) so I can write a script to process the xml and add the necessary attributes that the GPS expects.

Secondary question:  Would this make a useful plugin?
","Using pure GDAL, you can preserve the waypoint symbol and type of an original GPX file with

ogr2ogr -f GPX -dsco GPX_USE_EXTENSIONS=YES out.gpx in.gpx waypoints

&lt;wpt lat=""51.295094"" lon=""6.790674""&gt;
  &lt;ele&gt;39.0&lt;/ele&gt;
  &lt;time&gt;2014-10-14T13:56:58Z&lt;/time&gt;
  &lt;name&gt;Push Log Point #1&lt;/name&gt;
  &lt;desc&gt;Lat.=51.295094, Long.=6.790674, Alt.=39.000000m, Speed=3Km/h, Course=45deg.&lt;/desc&gt;
  &lt;sym&gt;Waypoint&lt;/sym&gt;
  &lt;type&gt;Other&lt;/type&gt;
  &lt;extensions&gt;
    &lt;label&gt;&lt;label_text&gt;Push Log Point #1&lt;/label_text&gt;&lt;/label&gt;
  &lt;/extensions&gt;
&lt;/wpt&gt;


So if you have a shapefile in QGIS, create columns with names sym and type and export it to GPX format with GPX_USE_EXTENSIONS=YES (which is default for GPX since QGIS 2.4).

Remember to save into EPSG:4326, as GPX only allows that.

Other features (like label) will be exported in the &lt;extensions&gt; element, and probably ignored by a GPS unit. My output reads as follows:

&lt;wpt lat=""51.295094"" lon=""6.790674""&gt;
  &lt;name&gt;Push Log Point #1&lt;/name&gt;
  &lt;sym&gt;Waypoint&lt;/sym&gt;
  &lt;type&gt;Other&lt;/type&gt;
  &lt;extensions&gt;
    &lt;ogr:elevation&gt;39.0&lt;/ogr:elevation&gt;
    &lt;ogr:label&gt;1&lt;/ogr:label&gt;
  &lt;/extensions&gt;
&lt;/wpt&gt;
&lt;wpt lat=""51.295091"" lon=""6.790663""&gt;
  &lt;name&gt;Push Log Point #2&lt;/name&gt;
  &lt;sym&gt;church&lt;/sym&gt;
  &lt;type&gt;tower&lt;/type&gt;
  &lt;extensions&gt;
    &lt;ogr:elevation&gt;38.0&lt;/ogr:elevation&gt;
    &lt;ogr:label&gt;2&lt;/ogr:label&gt;
  &lt;/extensions&gt;
&lt;/wpt&gt;


The available symbols depend on the GPS units, so you might create a sample GPX file with the unit and test all available symbols. These will not be imported into QGIS, but you can read the file with a text editor.

As an example, symbols of the Garmin Oregon 6xx are listed at this site. You can even create your own symbols and upload them.
"
5609,5609,8899,rails rspec integration_tests and http authentication,"I am using Rspec 2 and capybara and defined the basic integration test, i.e.

describe ""EeRequisitions"" do
  describe ""GET /ee_requisitions"" do
    it ""works! (now write some real specs)"" do
      get ee_requisitions_path
      response.status.should be(200)
    end
  end
end


Since the app uses HTTP basic authentication and since capybara says it includes Rack::Test, I expected that adding the line:

authorize 'user', 'password'


would handle it (I've since lost the stackoverflow post that told me that). Unfortunately it didn't - it kept throwing a 'method not found' error.  I finally found the solution in a comment to this post: Rails/Rspec Make tests to pass with http basic authentication where Matt Connelly pointed me to this gist: https://gist.github.com/mattconnolly/4158961 which finally solved my problem.

However, I'm still wondering why the Rack::Test approach failed as it seems to have worked for others.
",JESii,https://stackoverflow.com/users/446464,"Does including the line

include Rack::Test::Methods


at the top of the tests make a difference?
",tyler,https://stackoverflow.com/users/1023216,http://stackoverflow.com/questions/15174495/rails-rspec-integration-tests-and-http-authentication,STACKOVERFLOW,stackoverflow.com,0.6666666666666666,0.4444444444444444,0.0,1.0,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,0.0,0.6666666666666666,0.6666666666666666,0.5555555555555556,1.0,0.8888888888888888,0.4,0.6666666666666666,0.0,0.0,0.8888888888888888,Rails rspec integration testing and HTTP authentication,"I am using Rspec 2 and capybara and defined the basic integration test, i.e.

describe ""EeRequisitions"" do
  describe ""GET /ee_requisitions"" do
    it ""works! (now write some real specs)"" do
      get ee_requisitions_path
      response.status.should be(200)
    end
  end
end


Since the app uses HTTP basic authentication and since capybara says it includes Rack::Test, I expected that adding the line:

authorize 'user', 'password'


would handle it (I've since lost the stackoverflow post that told me that). Unfortunately it didn't - it kept throwing a 'method not found' error.  I finally found the solution in a comment to this post: Rails/Rspec Make tests to pass with http basic authentication where Matt Connelly pointed me to this gist: https://gist.github.com/mattconnolly/4158961 which finally solved my problem.

However, I'm still wondering why the Rack::Test approach failed as it seems to have worked for others.
","Does including the line

include Rack::Test::Methods


at the top of the tests make a difference?
"
1977,1977,3151,Understanding of Relays and associated circuitry,"I needed a simple understanding of how this circuit works.



I understand everything about this circuit apart from the diode. I also know the function of the diode is to protect the transistor but from what exactly? Is it something to do with back EMF from the coil? I'm not too sure. Also I needed to confirm if the relay will function correctly with a 9V supply (regulated or unregulated). The datasheet of the relay is attached here and the part I'm going to use is '40.61' on page 20 of the datasheet.

Also any tips for making this circuit work more efficiently. Note I am going to use the relay for no more than 16A at 230VAC at 50Hz.

Thanks
",David Norman,https://electronics.stackexchange.com/users/10082,"Voltage difference between terminals of coil when current is changing is defined as:
U=L*di/dt

If the the rate of current change is high, you will have a very large voltage spikes that will sooner or later ""fry"" your transistor. Reverse biased diode is used to clamp these voltage spikes so that you transistor is safe and you don't have to use transistor with high voltage ratings. As an added protection I would add small value resistor between coil of relay and transistor.
",jpou,https://electronics.stackexchange.com/users/10042,http://electronics.stackexchange.com/questions/33844/understanding-of-relays-and-associated-circuitry,TECHNOLOGY,electronics.stackexchange.com,1.0,0.5,0.0,0.5,1.0,1.0,0.6666666666666666,0.3333333333333333,1.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.5,0.0,0.8333333333333334,1.0,0.6666666666666666,1.0,1.0,0.9,0.0,0.0,0.5,0.8333333333333334,Understand relays and related circuits,"I needed a simple understanding of how this circuit works.



I understand everything about this circuit apart from the diode. I also know the function of the diode is to protect the transistor but from what exactly? Is it something to do with back EMF from the coil? I'm not too sure. Also I needed to confirm if the relay will function correctly with a 9V supply (regulated or unregulated). The datasheet of the relay is attached here and the part I'm going to use is '40.61' on page 20 of the datasheet.

Also any tips for making this circuit work more efficiently. Note I am going to use the relay for no more than 16A at 230VAC at 50Hz.

Thanks
","Voltage difference between terminals of coil when current is changing is defined as:
U=L*di/dt

If the the rate of current change is high, you will have a very large voltage spikes that will sooner or later ""fry"" your transistor. Reverse biased diode is used to clamp these voltage spikes so that you transistor is safe and you don't have to use transistor with high voltage ratings. As an added protection I would add small value resistor between coil of relay and transistor.
"
2301,2301,3665,android magento - customer login(authentication) using SOAP API,"We are devoloping an android app for a Magento site.

I am facing problem while I try to login(authentication) as magento customer.

I can't find a proper way to login as a customer using email and password.

how can I authenticate or login as a customer?

I followed this links answer: http://stackoverflow.com/questions/25055700/android-magento-customer-loginauthentication-using-using-soap-api

according to that, I created this file: http://pastebin.com/RJAGxTDS under http://hotwheelstoys.in/testing/testing/Mage3.php

But when we pass the values using JSON, we are getting ""null"".

I saw this link : http://www.magentocommerce.com/api/soap/introduction.html

But there is no API for login through android.
",Baby in Magento,https://magento.stackexchange.com/users/12982,"Magento SOAP Api has no method to authenticate customers.

What you can do is, get the customer info and then check the password. The problem is, doing this client side is a really bad idea.

The alternative is to implement your own method to just pass email and password to check it.
",Fabian Blechschmidt,https://magento.stackexchange.com/users/217,http://magento.stackexchange.com/questions/72901/android-magento-customer-loginauthentication-using-soap-api,TECHNOLOGY,magento.stackexchange.com,0.5,0.3333333333333333,0.0,0.5,1.0,0.5,0.5,0.3333333333333333,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.5,0.0,0.0,0.5,0.8333333333333334,0.6666666666666666,0.8333333333333334,0.8333333333333334,0.8,0.5,0.5,0.5,0.8333333333333334,Android Magento - customer login (authentication) using soap API,"We are devoloping an android app for a Magento site.

I am facing problem while I try to login(authentication) as magento customer.

I can't find a proper way to login as a customer using email and password.

how can I authenticate or login as a customer?

I followed this links answer: http://stackoverflow.com/questions/25055700/android-magento-customer-loginauthentication-using-using-soap-api

according to that, I created this file: http://pastebin.com/RJAGxTDS under http://hotwheelstoys.in/testing/testing/Mage3.php

But when we pass the values using JSON, we are getting ""null"".

I saw this link : http://www.magentocommerce.com/api/soap/introduction.html

But there is no API for login through android.
","Magento SOAP Api has no method to authenticate customers.

What you can do is, get the customer info and then check the password. The problem is, doing this client side is a really bad idea.

The alternative is to implement your own method to just pass email and password to check it.
"
4254,4254,6782,Potentiometer protection circuitry,"My question arose from my previous question about a wind direction measuring circuit.
Please have a look at the manual: http://www.fondriest.com/pdf/rm_young_05103_manual.pdf
And here is the figures about my questions:


In Figure A, the potentiometer is used to output voltage proportional to the wind vane rotation angle.

In Figure B, the potentiometer comes to an end at point 1 and causes a short between the lines WHT(wind excitation voltage) and GRN(wind direction signal). But in theory current flows from + to ground. Do you think there is a path for current to flow in Figure B?

In Figure C, it seems like the situation is safe. Although the lines GRN and BLK are shorted at point 2, there is no potential difference and no current flows. Is that right?

My real confusion is about D6 and D7 the transzorb diodes(zener clampers?). I couldn’t really figure out in which circumstances they function and what happens in the absence of them. Why do we really need them? 

In the manual it states: “To prevent false readings, signal conditioning electronics should clamp the signal to excitation or reference level when this occurs.” Do you think one needs an extra circuitry at the output?
",user16307,https://electronics.stackexchange.com/users/16307,"The transzorbs are there to protect your electronics from induced voltages on the cables. You could have very long outdoor cables from your electronics to the wind vane. Without some kind of protection the electronics would be wiped out during the next thunderstorm.

As to your second question, you left out the sentence before the one you quote. We don't know what the phrase ""when this occurs"" is referring to. However, adding some kind of input protection is good idea whenever you connect a long cable to sensitive electronics.
",Joe Hass,https://electronics.stackexchange.com/users/11791,http://electronics.stackexchange.com/questions/93464/potentiometer-protection-circuitry,TECHNOLOGY,electronics.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,1.0,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.4444444444444444,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8,0.3333333333333333,0.3333333333333333,1.0,0.8888888888888888,Potentiometer protection circuit,"My question arose from my previous question about a wind direction measuring circuit.
Please have a look at the manual: http://www.fondriest.com/pdf/rm_young_05103_manual.pdf
And here is the figures about my questions:


In Figure A, the potentiometer is used to output voltage proportional to the wind vane rotation angle.

In Figure B, the potentiometer comes to an end at point 1 and causes a short between the lines WHT(wind excitation voltage) and GRN(wind direction signal). But in theory current flows from + to ground. Do you think there is a path for current to flow in Figure B?

In Figure C, it seems like the situation is safe. Although the lines GRN and BLK are shorted at point 2, there is no potential difference and no current flows. Is that right?

My real confusion is about D6 and D7 the transzorb diodes(zener clampers?). I couldn’t really figure out in which circumstances they function and what happens in the absence of them. Why do we really need them? 

In the manual it states: “To prevent false readings, signal conditioning electronics should clamp the signal to excitation or reference level when this occurs.” Do you think one needs an extra circuitry at the output?
","The transzorbs are there to protect your electronics from induced voltages on the cables. You could have very long outdoor cables from your electronics to the wind vane. Without some kind of protection the electronics would be wiped out during the next thunderstorm.

As to your second question, you left out the sentence before the one you quote. We don't know what the phrase ""when this occurs"" is referring to. However, adding some kind of input protection is good idea whenever you connect a long cable to sensitive electronics.
"
2336,2336,3724,How to change rotation direction of 3-phase electrical machines?,"I was taught that if you want to change the direction of a three phase rotating machine that is rotating in forward direction, you interchange the phases. Since the phases has the same features (voltage and current), what is responsible for making the machine to rotate in reverse direction, when the phases are interchanged?
",Ezeatum Solomon,https://electronics.stackexchange.com/users/82333,"The phases have a phase shift of 120 degress - called electrical phase angle, meanwhile the windings on the motor are also shifted by 120 deg - mechanical angle. 
In a such way, when the current passes trough windings the rotating magnetic field is formed, which is the sum of all three vectors. This is the principle of induction motor that Nikola Tesla made 130 yrs ago.

If you simply swap two wires, the magnetic fieled changes the direction of rotation.
",Marko Buršič,https://electronics.stackexchange.com/users/82111,http://electronics.stackexchange.com/questions/182800/how-to-change-rotation-direction-of-3-phase-electrical-machines,SCIENCE,electronics.stackexchange.com,1.0,1.0,0.0,1.0,0.5,1.0,0.6666666666666666,0.5,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.5,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,1.0,How to change the rotation direction of three-phase motor?,"I have been taught that if you want to change the direction of a three-phase rotating machine that is rotating in a positive direction, you have to change the phase. Since the phases have the same characteristics (voltage and current), when the phases are interchanged, what causes the machine to rotate in reverse?","The phases have a phase shift of 120 degress - called electrical phase angle, meanwhile the windings on the motor are also shifted by 120 deg - mechanical angle. 
In a such way, when the current passes trough windings the rotating magnetic field is formed, which is the sum of all three vectors. This is the principle of induction motor that Nikola Tesla made 130 yrs ago.

If you simply swap two wires, the magnetic fieled changes the direction of rotation.
"
297,297,478,When to use layoutSubview in iOS,"I am writing iOS application for iPad that require custom layout.

The layout from portrait and landscape are totally difference, so it can't be solve by using UIAutoResizingMask.

I try to use the layoutSubview Method, but I detected that layout subview is called a lot (from UIScrollView).
How can i reduce the layoutSubview call to optimize the code , or I should call it by my self when ever the device is rotated. 

Thank.
",Isara Rungvitayakul,https://stackoverflow.com/users/475479,"You should not do expensive calculations in layoutSubviews:
",Albert Schulz,https://stackoverflow.com/users/1176264,http://stackoverflow.com/questions/6953373/when-to-use-layoutsubview-in-ios,STACKOVERFLOW,stackoverflow.com,0.6666666666666666,0.5555555555555556,0.0,1.0,1.0,1.0,0.5555555555555556,0.5555555555555556,0.3333333333333333,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.7777777777777778,1.0,0.26666666666666666,0.0,0.0,0.0,0.7777777777777778,When to use layoutsubview in IOS,"I am writing iOS application for iPad that require custom layout.

The layout from portrait and landscape are totally difference, so it can't be solve by using UIAutoResizingMask.

I try to use the layoutSubview Method, but I detected that layout subview is called a lot (from UIScrollView).
How can i reduce the layoutSubview call to optimize the code , or I should call it by my self when ever the device is rotated. 

Thank.
",Expensive calculations should not be done in layoutsubview:
2593,2593,4123,Where does the Bible say to read itself?,"It seems rather basic, but I'm having trouble finding verses that say to read God's Word often. It seems like something that Paul said quite a few times, and it's obviously a good thing, but I can't find any specific verses. Can someone help me?
",Ullallulloo,https://christianity.stackexchange.com/users/103,"Isaiah 28:10New King James Version (NKJV)

10 For precept must be upon precept, precept upon precept,
Line upon line, line upon line,
Here a little, there a little.”
",user18698,https://christianity.stackexchange.com/users/18698,http://christianity.stackexchange.com/questions/5520/where-does-the-bible-say-to-read-itself,CULTURE,christianity.stackexchange.com,0.7777777777777778,0.6666666666666666,0.3333333333333333,1.0,1.0,0.6666666666666666,0.7777777777777778,0.5555555555555556,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.8888888888888888,0.6666666666666666,0.6666666666666666,0.6666666666666666,1.0,0.8,0.0,0.0,0.6666666666666666,0.8888888888888888,Where does the Bible say to read?,"It seems to be very basic, but I find it hard to find scriptures that read God's word often. Paul seems to have said it many times, which is obviously a good thing, but I can't find the specific verse. Can someone help me?","Isaiah 28:10New King James Version (NKJV)

10 For precept must be upon precept, precept upon precept,
Line upon line, line upon line,
Here a little, there a little.”
"
3118,3118,4967,How can natural selection occur at species level whilst not occuring at the individual level?,"The chapter by Douglas Futuyma in 'Evolution' (Losos et al 2013, Princeton) states that natural selection can occur at the species level. Futuyma states that if natural selection occurs at the species level it does not occur at the individual level: 


  Neither gene selection nor species selection has molded the advantageous characteristics of individual organisms; rather, they have affected properties at the gene level or at the species level. 


But how does natural selection occuring at the species level not affect individuals? Surely any selective advantage of a particular species must occur among particular individuals of that species. For example, if Species A is selected because it is browner than Species B, this will be because individuals of Species A are browner than individuals of Species B. 
",luciano,https://biology.stackexchange.com/users/1216,"I think there is some misunderstanding there, natural selection does act on an individual and can be determined by its genes (assuming there is genetic variance underlying the variance in trait). Those with more favourable genes will have more favourable phenotypes and thus be more likely to survive/reproduce. However, (genetic) evolution does not occur within an individual, evolution occurs at the population level as the frequencies of existing and new mutations changes over time or space.

Following from your example: Two morphs of a species exist, brown and white (like the classic peppered moth), which is genetically determined, and one has a selective advantage - let's say brown. Thus all individuals of the brown morph are more likely to survive and reproduce. Over time the genes causing the brown phenotype will increase in frequency in the population and frequency of brown (white) moths will have increased (decreased).

I suspect it would be helpful if you included more of the text preceding the statement. 

Edit: having seen @fileunderwaters answer, which arrived seconds before I posted mine, I see that I was right, more of the text was useful :)

So going back to the moths, an individual moth would not be able to change it's trait in response to selection.
",Ell,https://biology.stackexchange.com/users/1590,http://biology.stackexchange.com/questions/24312/how-can-natural-selection-occur-at-species-level-whilst-not-occuring-at-the-indi,SCIENCE,biology.stackexchange.com,1.0,1.0,0.0,0.3333333333333333,1.0,1.0,0.5555555555555556,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.0,0.8888888888888888,1.0,0.7777777777777778,1.0,1.0,1.0,0.0,0.3333333333333333,1.0,0.8888888888888888,How can natural selection occur at the species level rather than at the individual level?,"The chapter by Douglas Futuyma in 'Evolution' (Losos et al 2013, Princeton) states that natural selection can occur at the species level. Futuyma states that if natural selection occurs at the species level it does not occur at the individual level: 


  Neither gene selection nor species selection has molded the advantageous characteristics of individual organisms; rather, they have affected properties at the gene level or at the species level. 


But how does natural selection occuring at the species level not affect individuals? Surely any selective advantage of a particular species must occur among particular individuals of that species. For example, if Species A is selected because it is browner than Species B, this will be because individuals of Species A are browner than individuals of Species B. 
","I think there is some misunderstanding there, natural selection does act on an individual and can be determined by its genes (assuming there is genetic variance underlying the variance in trait). Those with more favourable genes will have more favourable phenotypes and thus be more likely to survive/reproduce. However, (genetic) evolution does not occur within an individual, evolution occurs at the population level as the frequencies of existing and new mutations changes over time or space.

Following from your example: Two morphs of a species exist, brown and white (like the classic peppered moth), which is genetically determined, and one has a selective advantage - let's say brown. Thus all individuals of the brown morph are more likely to survive and reproduce. Over time the genes causing the brown phenotype will increase in frequency in the population and frequency of brown (white) moths will have increased (decreased).

I suspect it would be helpful if you included more of the text preceding the statement. 

Edit: having seen @fileunderwaters answer, which arrived seconds before I posted mine, I see that I was right, more of the text was useful :)

So going back to the moths, an individual moth would not be able to change it's trait in response to selection.
"
555,555,874,Eclipse C++ formatter puts new line before method identifiers,"I ran into a problem with the Eclipse formatter.  It won't format my code correctly when declaring methods within a class declaration.  It puts a new line after the method's return type.

I already exported the style xml file and examined the settings in it, but none of the settings have any apparent connection to this problem, and the settings editor in Eclipse didn't show the same problem happening in it's sample code for method declarations.

Here is an example bit of code for what I want to have happen:

class MyClass
{
    public:
        MyClass();
        void myMethod();
};


However, this is what I get:

class MyClass
{
    public:
        MyClass();
        void
        myMethod();
};


Again, in the styles editor, the code doesn't have this problem and looks just how I want it to, but in the actual code, the story is different.

I'm using version 3.8.0.  Any help is appreciated.

Edit: I deleted those source files that were formatted incorrectly (after formatting the code several times to no avail) and replaced them with ""identical"" files with the same methods, same structure, etc.  I formatted the code this time and it worked.  This is probably a bug, but I'm leaving it up just in case anyone else encounters a similar problem or has a solution to avoiding this problem in the first place.
",Adam,https://stackoverflow.com/users/956216,"I hand edited two files under the main eclipse projects directory

.metadata\.plugins\org.eclipse.core.runtime\.settings


The two files:

file 1: org.eclipse.cdt.core.prefs, change this line from ""insert"" to ""do not insert""
 org.eclipse.cdt.core.formatter.insert_new_line_before_identifier_in_function_declaration=do not insert


file 2: org.eclipse.cdt.ui.prefs,
scan this file for ""insert_new_line_before_identifier_in_function_declaration"" and make a similar change from insert to do not insert next to it, should be obvious


Note I seen this problem on indigo and juno, the fix described above was in juno.
",user1967159,https://stackoverflow.com/users/1967159,http://stackoverflow.com/questions/13893942/eclipse-c-formatter-puts-new-line-before-method-identifiers,STACKOVERFLOW,stackoverflow.com,0.8333333333333334,0.6666666666666666,0.0,0.5,1.0,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.9,1.0,0.3333333333333333,0.3333333333333333,0.8333333333333334,Eclipse C + + formatter places new lines before method identifiers,"I ran into a problem with the Eclipse formatter.  It won't format my code correctly when declaring methods within a class declaration.  It puts a new line after the method's return type.

I already exported the style xml file and examined the settings in it, but none of the settings have any apparent connection to this problem, and the settings editor in Eclipse didn't show the same problem happening in it's sample code for method declarations.

Here is an example bit of code for what I want to have happen:

class MyClass
{
    public:
        MyClass();
        void myMethod();
};


However, this is what I get:

class MyClass
{
    public:
        MyClass();
        void
        myMethod();
};


Again, in the styles editor, the code doesn't have this problem and looks just how I want it to, but in the actual code, the story is different.

I'm using version 3.8.0.  Any help is appreciated.

Edit: I deleted those source files that were formatted incorrectly (after formatting the code several times to no avail) and replaced them with ""identical"" files with the same methods, same structure, etc.  I formatted the code this time and it worked.  This is probably a bug, but I'm leaving it up just in case anyone else encounters a similar problem or has a solution to avoiding this problem in the first place.
","I hand edited two files under the main eclipse projects directory

.metadata\.plugins\org.eclipse.core.runtime\.settings


The two files:

file 1: org.eclipse.cdt.core.prefs, change this line from ""insert"" to ""do not insert""
 org.eclipse.cdt.core.formatter.insert_new_line_before_identifier_in_function_declaration=do not insert


file 2: org.eclipse.cdt.ui.prefs,
scan this file for ""insert_new_line_before_identifier_in_function_declaration"" and make a similar change from insert to do not insert next to it, should be obvious


Note I seen this problem on indigo and juno, the fix described above was in juno.
"
783,783,1245,How to convert particles to mesh,"I need to convert a Particle System to a mesh object, so I can export it to Unity 3D. How could I do this?
",kholyphoenix1,https://blender.stackexchange.com/users/10890,"The following assumes that you are using 'Particle System-> Render-> Object -> Dupli Object'.  

Option 1) You can press the Convert button for the Particles Modifier. 

 

Option 2) If you would like to keep the particle Emitter intact, you can use the 'Make Duplicates Real' Tool Shift+Ctrl+a.
This will create object particles at every particle position just as if you applied the Modifier but the particle emitter and its particle system will still be intact in case you would like to make further changes.  
",MarcClintDion,https://blender.stackexchange.com/users/1448,http://blender.stackexchange.com/questions/24274/how-to-convert-particles-to-mesh,TECHNOLOGY,blender.stackexchange.com,1.0,1.0,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.8888888888888888,1.0,0.7777777777777778,1.0,1.0,0.9333333333333332,1.0,0.3333333333333333,0.6666666666666666,1.0,How to convert particles to meshes,I need to convert the particle system to a mesh object in order to export it to unity 3D. How can I do this?,"The following assumes that you are using 'Particle System-> Render-> Object -> Dupli Object'.  

Option 1) You can press the Convert button for the Particles Modifier. 

 

Option 2) If you would like to keep the particle Emitter intact, you can use the 'Make Duplicates Real' Tool Shift+Ctrl+a.
This will create object particles at every particle position just as if you applied the Modifier but the particle emitter and its particle system will still be intact in case you would like to make further changes.  
"
4224,4224,6738,Setting up a food pantry/orphanage?,"I can't find much on how to set up any kind of establishments that are for charity. HOw would I go about this? Acquiring a building, a few volunteers, how much to run it per day, ect? Anyone have any experience in this? My character is a NG Druid, who had never been to a city and saw the poverty and lack of food and housing for people. He wants to help! But I have no idea on how to establish a continual act of help. Buying food for the town and stuff, one time is easy to figure out. How many people * ammount of food needed is the price. But for bigger acts of continual charity, who knows? 

EDIT:
So, it was suggested that I make an eco orphanage in a forest. I accidently doomed the continent with demons, so that won't work. (Wish spell to get rid of orcs, things went horribly wrong) NO one knows it was me though! :D 

I don't want the leadership feat cause I need my 6th level feat for a prestige class.

Also, I don't want to donate to the churches in this city, I'm finding a lot of corruption in some of these churches, especially this city, so I want something more controllable by me. 
",samuraiseoul,https://rpg.stackexchange.com/users/10381,"Focus on efforts outside of the city. Your spells are more powerful than your money.

You possess three crucial spells:


Goodberry
Tree Shape
Plant Growth


I'm going to skip over silly solutions like magic traps of create food and water for in-character solutions possible immediately.

You're a druid, and so overpopulation is a fact of nature. You're a good druid, so just killing the excess populace is distasteful. Instead, you can create suburbs in local forest via tree shape. Thereby, you can provide environmentally friendly housing to local orphans and people who take care of them. Untrained hirelings are 1sp per day, and you can purchase mouldy food and fix it via purify food and drink (my recommendation is to negotiate a deal with various innkeepers: you'll cast this on mouldy food stores. They keep half, and they transport the rest to your little suburb.)

You can use many castings of goodberry to make 2d4 servings per meal. (If you want to make this work when you're not there, make sure someone with craft wondrous is nearby, and enchant the spell into a command-word activated bowl for 1800 gold). 

You can also use Plant Growth to enhance the productivity of surrounding fields. Make sure to enhance the productivity of both freeholds and sharecroppers, as annoying local lords by ignoring their money-generating resources is bad for your health, but improving other productivity should actually pass on lower prices to the city in terms of its food supply.
",Brian Ballsun-Stanton,https://rpg.stackexchange.com/users/760,http://rpg.stackexchange.com/questions/32292/setting-up-a-food-pantry-orphanage,CULTURE,rpg.stackexchange.com,0.8888888888888888,0.4444444444444444,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.5555555555555556,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,0.8888888888888888,0.7777777777777778,0.8888888888888888,1.0,0.8,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.8888888888888888,Food storage / orphanage?,"I can't find much on how to set up any kind of establishments that are for charity. HOw would I go about this? Acquiring a building, a few volunteers, how much to run it per day, ect? Anyone have any experience in this? My character is a NG Druid, who had never been to a city and saw the poverty and lack of food and housing for people. He wants to help! But I have no idea on how to establish a continual act of help. Buying food for the town and stuff, one time is easy to figure out. How many people * ammount of food needed is the price. But for bigger acts of continual charity, who knows? 

EDIT:
So, it was suggested that I make an eco orphanage in a forest. I accidently doomed the continent with demons, so that won't work. (Wish spell to get rid of orcs, things went horribly wrong) NO one knows it was me though! :D 

I don't want the leadership feat cause I need my 6th level feat for a prestige class.

Also, I don't want to donate to the churches in this city, I'm finding a lot of corruption in some of these churches, especially this city, so I want something more controllable by me. 
","Focus on efforts outside of the city. Your spells are more powerful than your money.

You possess three crucial spells:


Goodberry
Tree Shape
Plant Growth


I'm going to skip over silly solutions like magic traps of create food and water for in-character solutions possible immediately.

You're a druid, and so overpopulation is a fact of nature. You're a good druid, so just killing the excess populace is distasteful. Instead, you can create suburbs in local forest via tree shape. Thereby, you can provide environmentally friendly housing to local orphans and people who take care of them. Untrained hirelings are 1sp per day, and you can purchase mouldy food and fix it via purify food and drink (my recommendation is to negotiate a deal with various innkeepers: you'll cast this on mouldy food stores. They keep half, and they transport the rest to your little suburb.)

You can use many castings of goodberry to make 2d4 servings per meal. (If you want to make this work when you're not there, make sure someone with craft wondrous is nearby, and enchant the spell into a command-word activated bowl for 1800 gold). 

You can also use Plant Growth to enhance the productivity of surrounding fields. Make sure to enhance the productivity of both freeholds and sharecroppers, as annoying local lords by ignoring their money-generating resources is bad for your health, but improving other productivity should actually pass on lower prices to the city in terms of its food supply.
"
4592,4592,7277,Unprotect a Word Document,"
  Possible Duplicate:
  Can&rsquo;t edit a specific document in Word 2007  


How do I remove the password protection (unprotect) on a Word document if I don't know the password? (i.e. The protection provided by Tools > Unprotect Document)
",Rob Wright,https://superuser.com/users/24927,"One possible solution.  I think there are others as well.


Open a protected document in MS Word
Save as ""Web Page (*.htm; *.html)"", close Word
Open html-document in any Text-Editor
Search &lt;w:UnprotectPassword&gt; tag, the line reads something like that: &lt;w:UnprotectPassword&gt;ABCDEF01&lt;/w:UnprotectPassword&gt; (password is already in hex-format)
Keep the ""password"" in mind
Open original document (.doc) with any hex-editor
Search for hex-values of the password, which is stored in reverse order. (e.g. If password is 0xAB 0xCD 0xEF 0x01.  Then the password is in the .doc file as 0x01 0xEF 0xCD 0xAB)
Overwrite all 4 double-bytes with 0x00, Save, Close
Open document with MS Word, Select ""Tools / Unprotect Document"" (password is blank)

",Rob Wright,https://superuser.com/users/24927,http://superuser.com/questions/96242,TECHNOLOGY,superuser.com,1.0,0.5555555555555556,0.0,1.0,1.0,1.0,0.7777777777777778,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.6666666666666666,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.9,0.6666666666666666,0.3333333333333333,0.0,0.7777777777777778,Unprotect word documents,"
  Possible Duplicate:
  Can&rsquo;t edit a specific document in Word 2007  


How do I remove the password protection (unprotect) on a Word document if I don't know the password? (i.e. The protection provided by Tools > Unprotect Document)
","One possible solution.  I think there are others as well.


Open a protected document in MS Word
Save as ""Web Page (*.htm; *.html)"", close Word
Open html-document in any Text-Editor
Search &lt;w:UnprotectPassword&gt; tag, the line reads something like that: &lt;w:UnprotectPassword&gt;ABCDEF01&lt;/w:UnprotectPassword&gt; (password is already in hex-format)
Keep the ""password"" in mind
Open original document (.doc) with any hex-editor
Search for hex-values of the password, which is stored in reverse order. (e.g. If password is 0xAB 0xCD 0xEF 0x01.  Then the password is in the .doc file as 0x01 0xEF 0xCD 0xAB)
Overwrite all 4 double-bytes with 0x00, Save, Close
Open document with MS Word, Select ""Tools / Unprotect Document"" (password is blank)

"
1360,1360,2141,"How should a Christian respond to ""Does this dress me look fat?""?","If your wife asks, ""Does this dress make me look fat?"" And you think it does, but you tell her, ""Of course not, honey!"" Is that a sin?
",Jim G.,https://christianity.stackexchange.com/users/1100,"Just as a small counter-argument to the obvious answer, remember that Jesus said the entire law was summed up as this:


  30 Love the Lord your God with all your heart and with all your soul and with all your mind and with all your strength.’ 31 The second is this: ‘Love your neighbor as yourself.’ There is no commandment greater than these.”


The question, of course, is whether being a true witness would cause injury. 

Oddly enough, if your wife is just looking to see that you love her, I would argue it is loving to ""lie"".  A better tack, however, might be to answer a different question - to say that indeed, to you, she looks beautiful.  And really, her words may be ""Am I fat?"" but she's really wanting to know, ""Am I beautiful?""  Answer that question instead, and you'll be safe. 

If she were asking a medical question, a loving answer might be, ""Dear, the doctor does want to you lose weight, and because I love you and want you to be with me for a long time, yes I think you need to do what the doctor says.""

If she insists on asking the question out of vanity, however, then may I suggest the best answer is found in Job 40:14:


  Behold, I am of small account; what shall I answer you? I lay my hand on my mouth

",Affable Geek,https://christianity.stackexchange.com/users/1039,http://christianity.stackexchange.com/questions/6469/how-should-a-christian-respond-to-does-this-dress-me-look-fat,CULTURE,christianity.stackexchange.com,1.0,0.7777777777777778,0.6666666666666666,1.0,0.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.0,1.0,1.0,0.7777777777777778,1.0,1.0,0.9333333333333332,0.3333333333333333,0.0,1.0,0.8888888888888888,"How do Christians respond to ""do I look fat in this dress?"" ?","If your wife asks, ""does this dress make me look fat?"" You think so, but you tell her, ""of course not, honey!"" Is this a crime?","Just as a small counter-argument to the obvious answer, remember that Jesus said the entire law was summed up as this:


  30 Love the Lord your God with all your heart and with all your soul and with all your mind and with all your strength.’ 31 The second is this: ‘Love your neighbor as yourself.’ There is no commandment greater than these.”


The question, of course, is whether being a true witness would cause injury. 

Oddly enough, if your wife is just looking to see that you love her, I would argue it is loving to ""lie"".  A better tack, however, might be to answer a different question - to say that indeed, to you, she looks beautiful.  And really, her words may be ""Am I fat?"" but she's really wanting to know, ""Am I beautiful?""  Answer that question instead, and you'll be safe. 

If she were asking a medical question, a loving answer might be, ""Dear, the doctor does want to you lose weight, and because I love you and want you to be with me for a long time, yes I think you need to do what the doctor says.""

If she insists on asking the question out of vanity, however, then may I suggest the best answer is found in Job 40:14:


  Behold, I am of small account; what shall I answer you? I lay my hand on my mouth

"
671,671,1064,Can a PC have more than one Default Gateway?,"I know that a PC can have multiple network adapters each of which with different network identifiers (IP,MAC etc.). 

My question is, can a certain PC have more than one active default gateway? And if so, how does the PC (or better say the OS) knows to what adapter use for any given packet?
",user4537,https://serverfault.com/users/106155,"Technically yes, practically no.

The key is in the term 'default', it's the default - I have a default sandwich I order from Subway (Meatball Marinara with cheese and jalapeños) which I vary from routinely, still my default though, I don't have two defaults.

So it's the same with network interfaces, you define the 'norm' and then specify whenever you want to break from that norm via 'static routes' (look at the 'route' command on your OS of choice).

Hope this helps, and didn't make you too hungry...
",Chopper3,https://serverfault.com/users/1435,http://serverfault.com/questions/347032,TECHNOLOGY,serverfault.com,1.0,0.5555555555555556,0.0,0.0,1.0,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.3333333333333333,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.6666666666666666,0.0,1.0,1.0,Can a computer have multiple default gateways?,"I know that a PC can have multiple network adapters each of which with different network identifiers (IP,MAC etc.). 

My question is, can a certain PC have more than one active default gateway? And if so, how does the PC (or better say the OS) knows to what adapter use for any given packet?
","Technically yes, practically no.

The key is in the term 'default', it's the default - I have a default sandwich I order from Subway (Meatball Marinara with cheese and jalapeños) which I vary from routinely, still my default though, I don't have two defaults.

So it's the same with network interfaces, you define the 'norm' and then specify whenever you want to break from that norm via 'static routes' (look at the 'route' command on your OS of choice).

Hope this helps, and didn't make you too hungry...
"
3066,3066,4883,How can I superimpose LaTeX / TeX output over a PDF file?,"I have a form as a PDF file.  I would like to use LaTeX/TeX to overlay my text over the form, and send the output to either a print or another PDF file.

Is this possible?  How would I go about it?
",chernevik,https://tex.stackexchange.com/users/4754,"You can use TikZ to place the form as image at the center of an otherwise empty page and then draw on it. This is similar to the suggested pdfpages solution but avoid passing around the tikzpictures, which isn't really necessary. 

See also Drawing on an image with TikZ and Is there the easiest way to toggle (show/hide) navigational grids in TikZ? for related code.

You could even add real PDF form fields to it. See Creating fillable PDFs for how it can be done.

\documentclass[letterpaper]{article}% ensure identical page size

\usepackage{tikz}

\pagestyle{empty}
\begin{document}
% Page 1
\begin{tikzpicture}[remember picture,overlay]
    \node at (current page.center) {\includegraphics[page=1]{form}};
    \begin{scope}[shift={(current page.south west)},every node/.style={anchor=base west}]
        % Grid to help find the positions (remove in final version)
        \draw [help lines] (0,0) grid (current page.north east);
        \draw [help lines,thick] (0,0) grid [step=5cm] (current page.north east);
        %
        \node at (2cm,9.75cm) {John Doe};
        \node at (13cm,9.75cm) {\today};
    \end{scope}
\end{tikzpicture}
\clearpage
% Page 2
\begin{tikzpicture}[remember picture,overlay]
    \node at (current page.center) {\includegraphics[page=2]{form}};
    \begin{scope}[shift={(current page.south west)},every node/.style={anchor=base west}]
        % Grid to help find the positions (remove in final version)
        \draw [help lines] (0,0) grid (current page.north east);
        \draw [help lines,thick] (0,0) grid [step=5cm] (current page.north east);
        %
        %\node at (2.5cm,10.75cm) {John Doe};
    \end{scope}
\end{tikzpicture}
\clearpage
\end{document}


This example used the IEEE copyright form. Just download it and rename it to form.pdf. The second page actually does not include any fillable form fields, but I found it important to show how to handle multiple pages.
",Martin Scharrer,https://tex.stackexchange.com/users/2975,http://tex.stackexchange.com/questions/15314/how-can-i-superimpose-latex-tex-output-over-a-pdf-file,TECHNOLOGY,tex.stackexchange.com,1.0,0.8888888888888888,0.0,1.0,0.6666666666666666,1.0,0.5555555555555556,0.5555555555555556,0.6666666666666666,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,1.0,1.0,0.6666666666666666,0.8888888888888888,1.0,0.9333333333333332,1.0,0.3333333333333333,0.0,1.0,How do I stack latex / tex output onto a PDF file?,I have a PDF form. I want to use latex / tex to overlay text on the form and send the output to a print file or other PDF file.,"You can use TikZ to place the form as image at the center of an otherwise empty page and then draw on it. This is similar to the suggested pdfpages solution but avoid passing around the tikzpictures, which isn't really necessary. 

See also Drawing on an image with TikZ and Is there the easiest way to toggle (show/hide) navigational grids in TikZ? for related code.

You could even add real PDF form fields to it. See Creating fillable PDFs for how it can be done.

\documentclass[letterpaper]{article}% ensure identical page size

\usepackage{tikz}

\pagestyle{empty}
\begin{document}
% Page 1
\begin{tikzpicture}[remember picture,overlay]
    \node at (current page.center) {\includegraphics[page=1]{form}};
    \begin{scope}[shift={(current page.south west)},every node/.style={anchor=base west}]
        % Grid to help find the positions (remove in final version)
        \draw [help lines] (0,0) grid (current page.north east);
        \draw [help lines,thick] (0,0) grid [step=5cm] (current page.north east);
        %
        \node at (2cm,9.75cm) {John Doe};
        \node at (13cm,9.75cm) {\today};
    \end{scope}
\end{tikzpicture}
\clearpage
% Page 2
\begin{tikzpicture}[remember picture,overlay]
    \node at (current page.center) {\includegraphics[page=2]{form}};
    \begin{scope}[shift={(current page.south west)},every node/.style={anchor=base west}]
        % Grid to help find the positions (remove in final version)
        \draw [help lines] (0,0) grid (current page.north east);
        \draw [help lines,thick] (0,0) grid [step=5cm] (current page.north east);
        %
        %\node at (2.5cm,10.75cm) {John Doe};
    \end{scope}
\end{tikzpicture}
\clearpage
\end{document}


This example used the IEEE copyright form. Just download it and rename it to form.pdf. The second page actually does not include any fillable form fields, but I found it important to show how to handle multiple pages.
"
5799,5799,9187,Help with SQL Trace,"I have setup SQL Profiler as follows -

Template: Tuning

Save to dbo.myTable

Event selection: Duration greater than or equal to 2000 (ms)

This will record TextData, Duration, SPID, DatabaseID, DatabaseName, ObjectType, LoginName for the events RPC:Completed, SP:StmtCompleted &amp; SQL:BatchCompleted.

I exported the script for the SQL Trace and the script below was created. However I need the trace to write to a database table rather than a file. How do I change the script to write to a db table instead?

/****************************************************/
/* Created by: SQL Server Profiler 2005             */
/* Date: 21/06/2010  09:32:56         */
/****************************************************/


-- Create a Queue
declare @rc int
declare @TraceID int
declare @maxfilesize bigint
set @maxfilesize = 5 

-- Please replace the text InsertFileNameHere, with an appropriate
-- filename prefixed by a path, e.g., c:\MyFolder\MyTrace. The .trc extension
-- will be appended to the filename automatically. If you are writing from
-- remote server to local drive, please use UNC path and make sure server has
-- write access to your network share

exec @rc = sp_trace_create @TraceID output, 0, N'InsertFileNameHere', @maxfilesize, NULL 
if (@rc != 0) goto error

-- Client side File and Table cannot be scripted

-- Set the events
declare @on bit
set @on = 1
exec sp_trace_setevent @TraceID, 10, 1, @on
exec sp_trace_setevent @TraceID, 10, 3, @on
exec sp_trace_setevent @TraceID, 10, 11, @on
exec sp_trace_setevent @TraceID, 10, 35, @on
exec sp_trace_setevent @TraceID, 10, 12, @on
exec sp_trace_setevent @TraceID, 10, 13, @on
exec sp_trace_setevent @TraceID, 45, 1, @on
exec sp_trace_setevent @TraceID, 45, 3, @on
exec sp_trace_setevent @TraceID, 45, 11, @on
exec sp_trace_setevent @TraceID, 45, 35, @on
exec sp_trace_setevent @TraceID, 45, 12, @on
exec sp_trace_setevent @TraceID, 45, 28, @on
exec sp_trace_setevent @TraceID, 45, 13, @on
exec sp_trace_setevent @TraceID, 12, 1, @on
exec sp_trace_setevent @TraceID, 12, 3, @on
exec sp_trace_setevent @TraceID, 12, 11, @on
exec sp_trace_setevent @TraceID, 12, 35, @on
exec sp_trace_setevent @TraceID, 12, 12, @on
exec sp_trace_setevent @TraceID, 12, 13, @on


-- Set the Filters
declare @intfilter int
declare @bigintfilter bigint

set @bigintfilter = 2000000
exec sp_trace_setfilter @TraceID, 13, 0, 4, @bigintfilter

-- Set the trace status to start
exec sp_trace_setstatus @TraceID, 1

-- display trace id for future references
select TraceID=@TraceID
goto finish

error: 
select ErrorCode=@rc

finish: 
go

",user23048345,https://stackoverflow.com/users/190578,"You can't. Profiler does that by using the rowset provider. 

Only the flatfile provider is available for server side traces. It is easy to insert from file to table or just read the file as though it was a table with fn_trace_gettable though.
",Martin Smith,https://stackoverflow.com/users/73226,http://stackoverflow.com/questions/3083115/help-with-sql-trace,STACKOVERFLOW,stackoverflow.com,1.0,0.3333333333333333,0.0,1.0,1.0,1.0,0.5,0.5,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9,0.0,0.0,1.0,1.0,Help on SQL tracing,"I have setup SQL Profiler as follows -

Template: Tuning

Save to dbo.myTable

Event selection: Duration greater than or equal to 2000 (ms)

This will record TextData, Duration, SPID, DatabaseID, DatabaseName, ObjectType, LoginName for the events RPC:Completed, SP:StmtCompleted &amp; SQL:BatchCompleted.

I exported the script for the SQL Trace and the script below was created. However I need the trace to write to a database table rather than a file. How do I change the script to write to a db table instead?

/****************************************************/
/* Created by: SQL Server Profiler 2005             */
/* Date: 21/06/2010  09:32:56         */
/****************************************************/


-- Create a Queue
declare @rc int
declare @TraceID int
declare @maxfilesize bigint
set @maxfilesize = 5 

-- Please replace the text InsertFileNameHere, with an appropriate
-- filename prefixed by a path, e.g., c:\MyFolder\MyTrace. The .trc extension
-- will be appended to the filename automatically. If you are writing from
-- remote server to local drive, please use UNC path and make sure server has
-- write access to your network share

exec @rc = sp_trace_create @TraceID output, 0, N'InsertFileNameHere', @maxfilesize, NULL 
if (@rc != 0) goto error

-- Client side File and Table cannot be scripted

-- Set the events
declare @on bit
set @on = 1
exec sp_trace_setevent @TraceID, 10, 1, @on
exec sp_trace_setevent @TraceID, 10, 3, @on
exec sp_trace_setevent @TraceID, 10, 11, @on
exec sp_trace_setevent @TraceID, 10, 35, @on
exec sp_trace_setevent @TraceID, 10, 12, @on
exec sp_trace_setevent @TraceID, 10, 13, @on
exec sp_trace_setevent @TraceID, 45, 1, @on
exec sp_trace_setevent @TraceID, 45, 3, @on
exec sp_trace_setevent @TraceID, 45, 11, @on
exec sp_trace_setevent @TraceID, 45, 35, @on
exec sp_trace_setevent @TraceID, 45, 12, @on
exec sp_trace_setevent @TraceID, 45, 28, @on
exec sp_trace_setevent @TraceID, 45, 13, @on
exec sp_trace_setevent @TraceID, 12, 1, @on
exec sp_trace_setevent @TraceID, 12, 3, @on
exec sp_trace_setevent @TraceID, 12, 11, @on
exec sp_trace_setevent @TraceID, 12, 35, @on
exec sp_trace_setevent @TraceID, 12, 12, @on
exec sp_trace_setevent @TraceID, 12, 13, @on


-- Set the Filters
declare @intfilter int
declare @bigintfilter bigint

set @bigintfilter = 2000000
exec sp_trace_setfilter @TraceID, 13, 0, 4, @bigintfilter

-- Set the trace status to start
exec sp_trace_setstatus @TraceID, 1

-- display trace id for future references
select TraceID=@TraceID
goto finish

error: 
select ErrorCode=@rc

finish: 
go

","You can't. Profiler does that by using the rowset provider. 

Only the flatfile provider is available for server side traces. It is easy to insert from file to table or just read the file as though it was a table with fn_trace_gettable though.
"
1685,1685,2662,'Request invitation' doesn't give any feedback of successfully sending,"I filled the ""Request an Invitation"" form:


  


But after submitting, I just got bumped back to the ""check your profiles"" page without being told whether it worked or not.

If it does work, I may have sent several requests...
",Tom,https://meta.stackexchange.com/users/270644,"Looks like Jon got you set. I'm going to go ahead and mark this completed.
",Juice,https://meta.stackexchange.com/users/141235,http://meta.stackexchange.com/questions/239453/request-invitation-doesnt-give-any-feedback-of-successfully-sending,TECHNOLOGY,meta.stackexchange.com,0.7777777777777778,0.4444444444444444,0.0,0.5,0.5,0.5,0.4444444444444444,0.3333333333333333,0.0,0.5,0.5,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.5555555555555556,0.5555555555555556,0.4444444444444444,0.7777777777777778,0.5555555555555556,0.4666666666666667,0.0,0.0,0.0,1.0,The request invitation did not give any feedback that was successfully sent,"I filled the ""Request an Invitation"" form:


  


But after submitting, I just got bumped back to the ""check your profiles"" page without being told whether it worked or not.

If it does work, I may have sent several requests...
","Looks like Jon got you set. I'm going to go ahead and mark this completed.
"
5847,5847,9265,Identify my Motobécane racing bike,"I bought a Motobécane last year (pics below), and now that the bottom bracket is broken, I really need to know the model of the bike, to help me change that piece.

It would also be helpful if someone could redirect me to the Motobécane catalogs of the years 82, 83, I can't find them, and I suspect my bike is from this period.

Technical specifications:


frame color: green and black (How customizable was that? I think they didn't sell the same colors each year)
frame: tubing inexternal 707, ""trainer"" (I don't find the appropriate info about it)
brakes: Weinmann
derailleur: Sachs - Huret. 12 gears
Wheel: Maillard
Bottom Crank: ?? width of the shell: 74mm. From this page http://sheldonbrown.com/vrbn-g-n.html, the old french ones have special dimensions. Also on Motobécane, they are swiss type (left-threaded). I don't know if this is a cotterless one, shimano octalink, or if I can put something more standard?


[EDIT: As suggested by @Blam, I took the bottom bracket out.
First mistake: shell width doesn't correspond to the red line on the pic, but less, so width should be 68mm, I'll double check on the bike.
The Brand is Stronglight, french brand, but the threading is the normal one (left-threaded on the right side, and right-threaded on the left side).
The axle is 120mm long, tapered square. Like this model: http://www.ebay.com/itm/VP-Components-Bottom-Bracket-120mm-Square-Taper-Unsealed-Bike-NEW-/311359596201?pt=LH_DefaultDomain_0&amp;hash=item487e7a66a9

But anyway, I'm still interested in knowing the model of this bike, and/or finding the Motobécane catalogues of years 1982-83]

Important Note: The rear wheel is not the original (was broken). I also changed the part of the crank where I put the feet when I bought it (maybe I shouldn't have...). 

Sorry if it looks quite dirty, I didn't have time to clean.

Pics:











",PlasmaBinturong,https://bicycles.stackexchange.com/users/19414,"Turbulent times for Motobecane.

You can find the (last that I have found) French Motobecane for 1985-6 (dated Sept. 85) on forum.tontonvelo.com  (with the French model designations).

However, no Trainer in them and there are not many models listed - MBK/Motobecane was producing many other models many with older tube types from the past (decals similar to Peugoet - later with red/orange/yellow colors) during 85-6. The Motobecane name appears to have been dropped late 1986 the same year Yamaha became the main shareholder. 

I suspect your Trainer is one of the earlier ones possibly late 85/early 86, the later ""Trainers"" I've seen have either a ""Reseau Motobecane"" badge on the steerer tube or ""MBK Motobecane"" on the down tube. If you check the components and the serial numbers with data on the web, you should be able to get a good idea. I stumbled on a few sources out there on the Motobecane/MBK Trainer when searching for info on another bike of that period.

Recently got caught up into this period as well due to a Motobecane ""Ranger"" (no MBK on the frame) from the same period, picked it up for the missing Espace bars on a 1984 Mt. Becane. Oddly and apprently the MBK label had already been used for the ""Mt. Becane"" in 85 (MBK model=Ranger) with the same specs as the '84 Motobecane (with the platform tandem fork and Espace handlebars through 86), the same time Motobecane Ranger was made with a different frame and unicorn fork. The later 1987 MBK Ranger model looks the same as the earlier Motobecane Ranger including the unicrown fork. All very odd.

Hope this helps and good luck!
Geo
",Geo,https://bicycles.stackexchange.com/users/20354,http://bicycles.stackexchange.com/questions/30473/identify-my-motob%C3%A9cane-racing-bike,CULTURE,bicycles.stackexchange.com,1.0,0.3333333333333333,0.0,1.0,1.0,1.0,0.5555555555555556,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.8888888888888888,0.8888888888888888,1.0,0.8888888888888888,1.0,0.9,0.0,0.0,0.0,0.8888888888888888,Identify my motorcycle,"I bought a Motobécane last year (pics below), and now that the bottom bracket is broken, I really need to know the model of the bike, to help me change that piece.

It would also be helpful if someone could redirect me to the Motobécane catalogs of the years 82, 83, I can't find them, and I suspect my bike is from this period.

Technical specifications:


frame color: green and black (How customizable was that? I think they didn't sell the same colors each year)
frame: tubing inexternal 707, ""trainer"" (I don't find the appropriate info about it)
brakes: Weinmann
derailleur: Sachs - Huret. 12 gears
Wheel: Maillard
Bottom Crank: ?? width of the shell: 74mm. From this page http://sheldonbrown.com/vrbn-g-n.html, the old french ones have special dimensions. Also on Motobécane, they are swiss type (left-threaded). I don't know if this is a cotterless one, shimano octalink, or if I can put something more standard?


[EDIT: As suggested by @Blam, I took the bottom bracket out.
First mistake: shell width doesn't correspond to the red line on the pic, but less, so width should be 68mm, I'll double check on the bike.
The Brand is Stronglight, french brand, but the threading is the normal one (left-threaded on the right side, and right-threaded on the left side).
The axle is 120mm long, tapered square. Like this model: http://www.ebay.com/itm/VP-Components-Bottom-Bracket-120mm-Square-Taper-Unsealed-Bike-NEW-/311359596201?pt=LH_DefaultDomain_0&amp;hash=item487e7a66a9

But anyway, I'm still interested in knowing the model of this bike, and/or finding the Motobécane catalogues of years 1982-83]

Important Note: The rear wheel is not the original (was broken). I also changed the part of the crank where I put the feet when I bought it (maybe I shouldn't have...). 

Sorry if it looks quite dirty, I didn't have time to clean.

Pics:











","Turbulent times for Motobecane.

You can find the (last that I have found) French Motobecane for 1985-6 (dated Sept. 85) on forum.tontonvelo.com  (with the French model designations).

However, no Trainer in them and there are not many models listed - MBK/Motobecane was producing many other models many with older tube types from the past (decals similar to Peugoet - later with red/orange/yellow colors) during 85-6. The Motobecane name appears to have been dropped late 1986 the same year Yamaha became the main shareholder. 

I suspect your Trainer is one of the earlier ones possibly late 85/early 86, the later ""Trainers"" I've seen have either a ""Reseau Motobecane"" badge on the steerer tube or ""MBK Motobecane"" on the down tube. If you check the components and the serial numbers with data on the web, you should be able to get a good idea. I stumbled on a few sources out there on the Motobecane/MBK Trainer when searching for info on another bike of that period.

Recently got caught up into this period as well due to a Motobecane ""Ranger"" (no MBK on the frame) from the same period, picked it up for the missing Espace bars on a 1984 Mt. Becane. Oddly and apprently the MBK label had already been used for the ""Mt. Becane"" in 85 (MBK model=Ranger) with the same specs as the '84 Motobecane (with the platform tandem fork and Espace handlebars through 86), the same time Motobecane Ranger was made with a different frame and unicorn fork. The later 1987 MBK Ranger model looks the same as the earlier Motobecane Ranger including the unicrown fork. All very odd.

Hope this helps and good luck!
Geo
"
110,110,178,How was the sword of Gryffindor pulled from the hat a second time?,"Spoilers follow, and this is from the books (not the movies)...

In The Chamber of Secrets:


   Harry retrieves Goderic Gryffindor's sword from the sorting hat during the confrontation with the basilisk. After this Dumbledore keeps hold of the sword in a glass case in his office. 


Then in The Deathly Hallows:


   Harry and Ron do a deal with Griphook to return Gryffindor's sword to the goblins after they have retrieved Hufflepuff's cup, planning to partially double cross him by holding on to it until all the horcruxes have been destroyed. However Griphook double crosses them first, and keeps hold of the sword.


Then, in the battle at the end of the book:


   Voldemort puts the sorting hat on Neville Longbottom's head and sets him on fire. Instead of burning Neville pulls Gryffindor's sword out of the sorting hat and beheads Nagini, destroying Voldemort's last horcrux.


However, if the sword could always be pulled out of the hat by someone sufficiently heroic then why the need to:


   Create a copy of the sword to fool Bellatrix Lestrange into thinking she had the real one in Gringott's vault? Why forge a copy and risk Snape placing it in the lake if it could always have been pulled from the sorting hat, regardless of where it was or how it was protected?


How was Gryffindor's sword pulled from the hat the second time? Surely it was beyond the reach of accio or any other charms once returned to its goblin creators?
",Keith,https://scifi.stackexchange.com/users/2154,"In Chamber of Secrets, page 320, chapter 17:


   A gleaming silver sword had APPEARED inside the hat... 


Also in CoS, page 334, chapter 18:


   ""Only a true Gryffindor could have PULLED that out of the hat, Harry"" (Dumbledore to Harry)


In Deathly Hallows, page 689, chapter 23:


   ""Now, Severus, the sword!  Do not forget that it must be taken under conditions of NEED and VALOR...""


(The emphasis is mine)

The short answer is that the magic of the sword and the hat worked together to provide the sword to Neville.

It appeared to him since Neville fulfilled all the qualities necessary for the sword to appear in the Sorting Hat:


true Gryffindor:  Sorting Hat put Neville in the house
need:  Neville needed to kill Nagini
valor:  definition of valor is ""strength of mind or spirit that enables a person to encounter danger with firmness"" (Merriam-Webster.com) and I think Neville demonstrated that numerous times

",Treborcram,https://scifi.stackexchange.com/users/8757,http://scifi.stackexchange.com/questions/34005/how-was-the-sword-of-gryffindor-pulled-from-the-hat-a-second-time,LIFE_ARTS,scifi.stackexchange.com,1.0,0.7777777777777778,0.6666666666666666,0.0,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.6666666666666666,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.5555555555555556,1.0,1.0,0.8666666666666666,0.0,0.0,1.0,0.8888888888888888,How did Gryffindor's sword come out of his hat?,"Spoilers follow, and this is from the books (not the movies)...

In The Chamber of Secrets:


   Harry retrieves Goderic Gryffindor's sword from the sorting hat during the confrontation with the basilisk. After this Dumbledore keeps hold of the sword in a glass case in his office. 


Then in The Deathly Hallows:


   Harry and Ron do a deal with Griphook to return Gryffindor's sword to the goblins after they have retrieved Hufflepuff's cup, planning to partially double cross him by holding on to it until all the horcruxes have been destroyed. However Griphook double crosses them first, and keeps hold of the sword.


Then, in the battle at the end of the book:


   Voldemort puts the sorting hat on Neville Longbottom's head and sets him on fire. Instead of burning Neville pulls Gryffindor's sword out of the sorting hat and beheads Nagini, destroying Voldemort's last horcrux.


However, if the sword could always be pulled out of the hat by someone sufficiently heroic then why the need to:


   Create a copy of the sword to fool Bellatrix Lestrange into thinking she had the real one in Gringott's vault? Why forge a copy and risk Snape placing it in the lake if it could always have been pulled from the sorting hat, regardless of where it was or how it was protected?


How was Gryffindor's sword pulled from the hat the second time? Surely it was beyond the reach of accio or any other charms once returned to its goblin creators?
","In Chamber of Secrets, page 320, chapter 17:


   A gleaming silver sword had APPEARED inside the hat... 


Also in CoS, page 334, chapter 18:


   ""Only a true Gryffindor could have PULLED that out of the hat, Harry"" (Dumbledore to Harry)


In Deathly Hallows, page 689, chapter 23:


   ""Now, Severus, the sword!  Do not forget that it must be taken under conditions of NEED and VALOR...""


(The emphasis is mine)

The short answer is that the magic of the sword and the hat worked together to provide the sword to Neville.

It appeared to him since Neville fulfilled all the qualities necessary for the sword to appear in the Sorting Hat:


true Gryffindor:  Sorting Hat put Neville in the house
need:  Neville needed to kill Nagini
valor:  definition of valor is ""strength of mind or spirit that enables a person to encounter danger with firmness"" (Merriam-Webster.com) and I think Neville demonstrated that numerous times

"
536,536,841,Water Supply pressure,"What size supply pipe must be used from a 5000 litre water tank to supply 4 bars of pressure to a house that is 20m below and 300m away from the tank?
",Sandy,https://diy.stackexchange.com/users/35971,"It's a trick question, you can never get 4 bar of pressure with only a 20 m head.

The pressure due to a vertical column of liquid is equal to the density x height of the column x the acceleration due to gravity (little g = 9.8 m/s2).

Your height is 20m

Density of water is 1000 kg/m3

g = 9.8

So, pressure is 196,000 Pascals 

100,000 Pascal per bar, so you have 1.96 bar as the max pressure you could get, independent of flow rate or pipe size.  
",Joel Keene,https://diy.stackexchange.com/users/30154,http://diy.stackexchange.com/questions/64247/water-supply-pressure,LIFE_ARTS,diy.stackexchange.com,1.0,0.3333333333333333,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.3333333333333333,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.3333333333333333,1.0,0.8888888888888888,Water supply pressure,How much water supply pipe must be used from a 5000 litre tank to provide 4 bar pressure for a house 20 meters below and 300 meters from the tank?,"It's a trick question, you can never get 4 bar of pressure with only a 20 m head.

The pressure due to a vertical column of liquid is equal to the density x height of the column x the acceleration due to gravity (little g = 9.8 m/s2).

Your height is 20m

Density of water is 1000 kg/m3

g = 9.8

So, pressure is 196,000 Pascals 

100,000 Pascal per bar, so you have 1.96 bar as the max pressure you could get, independent of flow rate or pipe size.  
"
819,819,1298,Positioning using textpos and animated blocks,"I am trying to position a figure on a page using textpos and then have a block appear over it in the next slide. I am inspired by the Gonzalo Medina's code given here. Here is what my code looks like, but the figure that is positioned on the page using textpos covers over the block as seen below -- block should cover that portion of the figure. Any suggestions?

\documentclass{beamer}
\usetheme{Madrid}

\usepackage[absolute,overlay]{textpos}

\begin{document}

\begin{frame}{III. Override pages}
    \begin{enumerate}
      \item Bookmark manager
      \item History
      \item New tab
  \end{enumerate}
  \begin{textblock*}{20mm}(50mm,30mm)%
    \rule{2cm}{4cm}
  \end{textblock*}

  \only&lt;2-&gt;{
    \centering
    \begin{block}{Block Title}
        Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.
     \end{block}
   }
\end{frame}

\end{document}




",ozsu,https://tex.stackexchange.com/users/8801,"I think in this case it's better to use TikZ and not textpos (more information in Christian's answer to How can I position an image in an arbitrary position in beamer?)

textpos manual explains that overlay option places the contents over anything else, so it's not possible to draw something over the rule later on because the rule is on top of each slide.

Next code using TikZ remember picture and overlay options worked for me in this particular case.

\documentclass{beamer}
\usetheme{Madrid}

\usepackage{tikz}

\begin{document}

\begin{frame}{III. Override pages}
    \begin{enumerate}
      \item Bookmark manager
      \item History
      \item New tab
  \end{enumerate}

  \tikz[remember picture, overlay]\node at (current page.center) {\rule{2cm}{4cm}};

  \only&lt;2-&gt;{
    \centering
    \begin{block}{Block Title}
        Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.
     \end{block}
   }
\end{frame}

\end{document}



",Ignasi,https://tex.stackexchange.com/users/1952,http://tex.stackexchange.com/questions/244963/positioning-using-textpos-and-animated-blocks,TECHNOLOGY,tex.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,1.0,0.6666666666666666,1.0,0.6666666666666666,0.4444444444444444,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,0.0,0.4444444444444444,0.8888888888888888,0.6666666666666666,1.0,0.8888888888888888,0.8666666666666666,1.0,0.0,0.6666666666666666,0.8888888888888888,Positioning with textpos and animation blocks,"I am trying to position a figure on a page using textpos and then have a block appear over it in the next slide. I am inspired by the Gonzalo Medina's code given here. Here is what my code looks like, but the figure that is positioned on the page using textpos covers over the block as seen below -- block should cover that portion of the figure. Any suggestions?

\documentclass{beamer}
\usetheme{Madrid}

\usepackage[absolute,overlay]{textpos}

\begin{document}

\begin{frame}{III. Override pages}
    \begin{enumerate}
      \item Bookmark manager
      \item History
      \item New tab
  \end{enumerate}
  \begin{textblock*}{20mm}(50mm,30mm)%
    \rule{2cm}{4cm}
  \end{textblock*}

  \only&lt;2-&gt;{
    \centering
    \begin{block}{Block Title}
        Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.
     \end{block}
   }
\end{frame}

\end{document}




","I think in this case it's better to use TikZ and not textpos (more information in Christian's answer to How can I position an image in an arbitrary position in beamer?)

textpos manual explains that overlay option places the contents over anything else, so it's not possible to draw something over the rule later on because the rule is on top of each slide.

Next code using TikZ remember picture and overlay options worked for me in this particular case.

\documentclass{beamer}
\usetheme{Madrid}

\usepackage{tikz}

\begin{document}

\begin{frame}{III. Override pages}
    \begin{enumerate}
      \item Bookmark manager
      \item History
      \item New tab
  \end{enumerate}

  \tikz[remember picture, overlay]\node at (current page.center) {\rule{2cm}{4cm}};

  \only&lt;2-&gt;{
    \centering
    \begin{block}{Block Title}
        Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.
     \end{block}
   }
\end{frame}

\end{document}



"
3037,3037,4845,"highcharts: stop chart from trapping mouse events, or capture mouse click on the ENTIRE chart","All,

I'm using HighCharts in a web app I'm working on, and generally, I like it very much.

However, I'm having a hard time figuring out how capture a mouse click on the ENTIRE chart.

In other words - I'd like to know when the user clicks ANYWHERE on the chart (e.g., the plot area, the title, the x- or y-axis, the margins and padding around the chart elements, etc.)

Or, I'd like to disable events altogether, so I can trap the event in the container itself.

More detailed version...

I have a DIV that contains my HighChart.

I want to know if the user clicks ANYWHERE within that DIV.

So - initially I tried attaching an ""onclick"" event to the DIV, but that never gets fired, presumably because the click is getting trapped by the HighChart.

So, in the code that sets up the HighChart, I added this:

var chart = new Highcharts.Chart({
    chart: {
        renderTo: ""container"",
        events: {
            click: function(event) {
                // do something
            }
        },
        ...
    }
    ...
});


This works OK IF the user clicks somewhere within the plot area, but not if she clicks anywhere else in the chart (e.g., the x-axis, the y-axis, the title, the padding around the chart elements, etc.)

So - how can I make the ENTIRE chart clickable?

Many thanks in advance!
",mattstuehler,https://stackoverflow.com/users/49383,"A very late answer, but still necessary, in my opinion.

The highcharts documentation
http://api.highcharts.com/highcharts#chart.events.click

refers to a script that simply forwards an event to the chart's container:
http://jsfiddle.net/gh/get/jquery/1.7.2/highslide-software/highcharts.com/tree/master/samples/highcharts/chart/events-container/

$(function () {
    $('#chart1').highcharts({
        ...
    });


    $('.chart-container').bind('mousedown', function () {
        $(this).toggleClass('modal');
        $('.chart', this).highcharts().reflow();
    });
});

",BurninLeo,https://stackoverflow.com/users/336311,http://stackoverflow.com/questions/11618075/highcharts-stop-chart-from-trapping-mouse-events-or-capture-mouse-click-on-the,STACKOVERFLOW,stackoverflow.com,1.0,0.3333333333333333,0.0,1.0,1.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.3333333333333333,1.0,0.6666666666666666,0.6,0.0,0.0,1.0,1.0,"Highcharts: prevents the chart from capturing mouse events, or the capture mouse from clicking the entire chart","All,

I'm using HighCharts in a web app I'm working on, and generally, I like it very much.

However, I'm having a hard time figuring out how capture a mouse click on the ENTIRE chart.

In other words - I'd like to know when the user clicks ANYWHERE on the chart (e.g., the plot area, the title, the x- or y-axis, the margins and padding around the chart elements, etc.)

Or, I'd like to disable events altogether, so I can trap the event in the container itself.

More detailed version...

I have a DIV that contains my HighChart.

I want to know if the user clicks ANYWHERE within that DIV.

So - initially I tried attaching an ""onclick"" event to the DIV, but that never gets fired, presumably because the click is getting trapped by the HighChart.

So, in the code that sets up the HighChart, I added this:

var chart = new Highcharts.Chart({
    chart: {
        renderTo: ""container"",
        events: {
            click: function(event) {
                // do something
            }
        },
        ...
    }
    ...
});


This works OK IF the user clicks somewhere within the plot area, but not if she clicks anywhere else in the chart (e.g., the x-axis, the y-axis, the title, the padding around the chart elements, etc.)

So - how can I make the ENTIRE chart clickable?

Many thanks in advance!
","A very late answer, but still necessary, in my opinion.

The highcharts documentation
http://api.highcharts.com/highcharts#chart.events.click

refers to a script that simply forwards an event to the chart's container:
http://jsfiddle.net/gh/get/jquery/1.7.2/highslide-software/highcharts.com/tree/master/samples/highcharts/chart/events-container/

$(function () {
    $('#chart1').highcharts({
        ...
    });


    $('.chart-container').bind('mousedown', function () {
        $(this).toggleClass('modal');
        $('.chart', this).highcharts().reflow();
    });
});

"
4689,4689,7435,Next & Previous (Pagination in this case) Not Appearing,"I am using a custom page template for my portfolio.  The code is calling the correct number of posts per page but for some reason the pagination links won't show up :-S

My query

&lt;?php 
    $loop = new WP_Query(array('post_type' =&gt; 'portfolio', 'posts_per_page' =&gt; 2)); 
?&gt;
&lt;?php while ( $loop-&gt;have_posts() ) : $loop-&gt;the_post(); ?&gt;
&lt;?php   
    $custom = get_post_custom($post-&gt;ID);
    $screenshot_url = $custom[""screenshot_url""][0];
    $website_url = $custom[""website_url""][0];
?&gt;


The entire markup

&lt;?php
/*
Template Name: Portfolio
*/
?&gt;

&lt;?php get_header(); ?&gt;

&lt;div id=""full_container""&gt;
&lt;div id=""portfolio_content""&gt;
&lt;div id=""portfolio_wrap""&gt;
&lt;div id=""content""&gt;

    &lt;?php 
        $loop = new WP_Query(array('post_type' =&gt; 'portfolio', 'posts_per_page' =&gt; 2)); 
    ?&gt;
    &lt;?php while ( $loop-&gt;have_posts() ) : $loop-&gt;the_post(); ?&gt;
    &lt;?php   
        $custom = get_post_custom($post-&gt;ID);
        $screenshot_url = $custom[""screenshot_url""][0];
        $website_url = $custom[""website_url""][0];
    ?&gt;


&lt;a href=""&lt;?php the_permalink() ?&gt;""&gt;

&lt;span class=""img""&gt;
&lt;?php if ( has_post_thumbnail() ) { the_post_thumbnail( 'thmb-portfolio' ); } ?&gt;

&lt;span class=""under""&gt;
&lt;!-- Excerpt title --&gt;
&lt;span class=""title""&gt;&lt;?php the_title(); ?&gt;&lt;/span&gt;

&lt;!-- Excerpt description --&gt;
&lt;span class=""desc""&gt;
    &lt;?php my_excerpt('short'); ?&gt;
&lt;/span&gt;
&lt;/span&gt;
&lt;/span&gt;
&lt;/a&gt;


        &lt;?php endwhile; ?&gt;  

&lt;!-- Next/Previous Posts --&gt;
&lt;?php if (function_exists(""pagination"")) {
    pagination($additional_loop-&gt;max_num_pages);
} ?&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;?php get_footer(); ?&gt;

",AndrettiMilas,https://wordpress.stackexchange.com/users/5205,"&lt;?php
/*
Template Name: Portfolio
*/
?&gt;

&lt;?php get_header(); ?&gt;

&lt;div id=""full_container""&gt;
&lt;div id=""portfolio_content""&gt;
&lt;div id=""portfolio_wrap""&gt;
&lt;div id=""content""&gt;

    &lt;?php 
        $loop = new WP_Query(array('post_type' =&gt; 'portfolio', 'posts_per_page' =&gt; 2)); 
    ?&gt;
    &lt;?php while ( $loop-&gt;have_posts() ) : $loop-&gt;the_post(); ?&gt;
    &lt;?php   
        $custom = get_post_custom($post-&gt;ID);
        $screenshot_url = $custom[""screenshot_url""][0];
        $website_url = $custom[""website_url""][0];
    ?&gt;


&lt;a href=""&lt;?php the_permalink() ?&gt;""&gt;

&lt;span class=""img""&gt;
&lt;?php if ( has_post_thumbnail() ) { the_post_thumbnail( 'thmb-portfolio' ); } ?&gt;

&lt;span class=""under""&gt;
&lt;!-- Excerpt title --&gt;
&lt;span class=""title""&gt;&lt;?php the_title(); ?&gt;&lt;/span&gt;

&lt;!-- Excerpt description --&gt;
&lt;span class=""desc""&gt;
    &lt;?php my_excerpt('short'); ?&gt;
&lt;/span&gt;
&lt;/span&gt;
&lt;/span&gt;
&lt;/a&gt;
&lt;?php previous_posts_link('Previous'); ?&gt; / &lt;?php next_posts_link('Next') ?&gt;

        &lt;?php endwhile; ?&gt;  

&lt;?php if (function_exists(""pagination"")) {
    pagination($additional_loop-&gt;max_num_pages);
} ?&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;?php get_footer(); ?&gt;

",Mohit Bumb,https://wordpress.stackexchange.com/users/8184,http://wordpress.stackexchange.com/questions/30616/next-previous-pagination-in-this-case-not-appearing,TECHNOLOGY,wordpress.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,0.0,1.0,0.0,0.6666666666666666,0.7777777777777778,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,0.7777777777777778,0.7777777777777778,0.5555555555555556,1.0,1.0,0.8666666666666666,1.0,0.0,0.0,0.8888888888888888,Next and previous (paging in this case) do not appear,"I am using a custom page template for my portfolio.  The code is calling the correct number of posts per page but for some reason the pagination links won't show up :-S

My query

&lt;?php 
    $loop = new WP_Query(array('post_type' =&gt; 'portfolio', 'posts_per_page' =&gt; 2)); 
?&gt;
&lt;?php while ( $loop-&gt;have_posts() ) : $loop-&gt;the_post(); ?&gt;
&lt;?php   
    $custom = get_post_custom($post-&gt;ID);
    $screenshot_url = $custom[""screenshot_url""][0];
    $website_url = $custom[""website_url""][0];
?&gt;


The entire markup

&lt;?php
/*
Template Name: Portfolio
*/
?&gt;

&lt;?php get_header(); ?&gt;

&lt;div id=""full_container""&gt;
&lt;div id=""portfolio_content""&gt;
&lt;div id=""portfolio_wrap""&gt;
&lt;div id=""content""&gt;

    &lt;?php 
        $loop = new WP_Query(array('post_type' =&gt; 'portfolio', 'posts_per_page' =&gt; 2)); 
    ?&gt;
    &lt;?php while ( $loop-&gt;have_posts() ) : $loop-&gt;the_post(); ?&gt;
    &lt;?php   
        $custom = get_post_custom($post-&gt;ID);
        $screenshot_url = $custom[""screenshot_url""][0];
        $website_url = $custom[""website_url""][0];
    ?&gt;


&lt;a href=""&lt;?php the_permalink() ?&gt;""&gt;

&lt;span class=""img""&gt;
&lt;?php if ( has_post_thumbnail() ) { the_post_thumbnail( 'thmb-portfolio' ); } ?&gt;

&lt;span class=""under""&gt;
&lt;!-- Excerpt title --&gt;
&lt;span class=""title""&gt;&lt;?php the_title(); ?&gt;&lt;/span&gt;

&lt;!-- Excerpt description --&gt;
&lt;span class=""desc""&gt;
    &lt;?php my_excerpt('short'); ?&gt;
&lt;/span&gt;
&lt;/span&gt;
&lt;/span&gt;
&lt;/a&gt;


        &lt;?php endwhile; ?&gt;  

&lt;!-- Next/Previous Posts --&gt;
&lt;?php if (function_exists(""pagination"")) {
    pagination($additional_loop-&gt;max_num_pages);
} ?&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;?php get_footer(); ?&gt;

","&lt;?php
/*
Template Name: Portfolio
*/
?&gt;

&lt;?php get_header(); ?&gt;

&lt;div id=""full_container""&gt;
&lt;div id=""portfolio_content""&gt;
&lt;div id=""portfolio_wrap""&gt;
&lt;div id=""content""&gt;

    &lt;?php 
        $loop = new WP_Query(array('post_type' =&gt; 'portfolio', 'posts_per_page' =&gt; 2)); 
    ?&gt;
    &lt;?php while ( $loop-&gt;have_posts() ) : $loop-&gt;the_post(); ?&gt;
    &lt;?php   
        $custom = get_post_custom($post-&gt;ID);
        $screenshot_url = $custom[""screenshot_url""][0];
        $website_url = $custom[""website_url""][0];
    ?&gt;


&lt;a href=""&lt;?php the_permalink() ?&gt;""&gt;

&lt;span class=""img""&gt;
&lt;?php if ( has_post_thumbnail() ) { the_post_thumbnail( 'thmb-portfolio' ); } ?&gt;

&lt;span class=""under""&gt;
&lt;!-- Excerpt title --&gt;
&lt;span class=""title""&gt;&lt;?php the_title(); ?&gt;&lt;/span&gt;

&lt;!-- Excerpt description --&gt;
&lt;span class=""desc""&gt;
    &lt;?php my_excerpt('short'); ?&gt;
&lt;/span&gt;
&lt;/span&gt;
&lt;/span&gt;
&lt;/a&gt;
&lt;?php previous_posts_link('Previous'); ?&gt; / &lt;?php next_posts_link('Next') ?&gt;

        &lt;?php endwhile; ?&gt;  

&lt;?php if (function_exists(""pagination"")) {
    pagination($additional_loop-&gt;max_num_pages);
} ?&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;?php get_footer(); ?&gt;

"
1376,1376,2167,Mounting a PCB in an Extruded Aluminum case,"I want to make a case for a PCB using extruded aluminum. (Such as the IPOD nano shown below, and the portable amp under it).


How do I mount the PCB inside the alumimum extrusion? (I know some come with slots but are there different options?
Who are some good suppliers of extruded aluminum? (bonus if they do milling on small quantities too)



",stbtra,https://electronics.stackexchange.com/users/582,"For extruded aluminum, find the local distributor for aluminum structural framing in your area. Try 8020.net in the US and Bosch-Rexroth in Europe. You might also try frontpanelexpress.com, though their stuff might be too big.

Here are some options to mount the PCB:


The slots
PEM studs (you'd need a fabricator to press these in for you)
Bolts and standoffs (try Digikey)


For the PEM studs, check out the KSSB family-- they're designed specially for mounting PCBs without extra fasteners.
",pingswept,https://electronics.stackexchange.com/users/712,http://electronics.stackexchange.com/questions/2898/mounting-a-pcb-in-an-extruded-aluminum-case,TECHNOLOGY,electronics.stackexchange.com,0.8333333333333334,0.3333333333333333,0.0,0.0,1.0,1.0,0.6666666666666666,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,0.0,1.0,Installing PCB in extruded aluminum housing,"I want to make a case for a PCB using extruded aluminum. (Such as the IPOD nano shown below, and the portable amp under it).


How do I mount the PCB inside the alumimum extrusion? (I know some come with slots but are there different options?
Who are some good suppliers of extruded aluminum? (bonus if they do milling on small quantities too)



","For extruded aluminum, find the local distributor for aluminum structural framing in your area. Try 8020.net in the US and Bosch-Rexroth in Europe. You might also try frontpanelexpress.com, though their stuff might be too big.

Here are some options to mount the PCB:


The slots
PEM studs (you'd need a fabricator to press these in for you)
Bolts and standoffs (try Digikey)


For the PEM studs, check out the KSSB family-- they're designed specially for mounting PCBs without extra fasteners.
"
4887,4887,7777,"What's the difference in meaning between ""emigrate"" and ""immigrate""?","What's the difference between emigrate and immigrate? They seem to have the same definitions in the dictionary but they are antonyms...

&nbsp;
",JFW,https://english.stackexchange.com/users/482,"In my experience, as an Indian ex-pat living and working in the UK:

If you're white-skinned and you move to another country you're said to have emigrated. If you're not white-skinned and you move to another country you're an immigrant. 
",5arx,https://english.stackexchange.com/users/336,http://english.stackexchange.com/questions/16781/whats-the-difference-in-meaning-between-emigrate-and-immigrate,CULTURE,english.stackexchange.com,1.0,1.0,0.0,1.0,1.0,1.0,0.7777777777777778,0.8888888888888888,0.0,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.5555555555555556,0.5555555555555556,0.5555555555555556,0.6666666666666666,0.4666666666666667,0.0,0.0,0.6666666666666666,0.7777777777777778,"What's the difference between ""immigrants"" and ""immigrants""?","What's the difference between immigrants and immigrants? The dictionary seems to have the same definition, but they are antonyms...","In my experience, as an Indian ex-pat living and working in the UK:

If you're white-skinned and you move to another country you're said to have emigrated. If you're not white-skinned and you move to another country you're an immigrant. 
"
2540,2540,4046,How do I create a great fantasy villain that inspires the party to rally against them?,"In my early years of GMing it was simple enough to say that the badguys were evil and that was all the justification we needed.  They are attacking the village because they are evil, they are stealing the princess because they are evil, etc.

Over time, my group needs have grown to need more complicated and detailed villains. It is important to consider motives.  What is it that defines them as 'evil' to the party?  In terms of a fantasy setting, what would you consider to be an interesting villain?

What qualities make a villain that inspires your party to rally against him?  What kind of villains have worked for your games in the past?

Example:


  A member of nobility is using trade connections to move valuable pieces of art into another country that is secretly paying him quite well and is framing a member of the party to take the fall.  In addition, someone important to the party member has been taken hostage with a promise of release once they party member takes the blame for the crime.

",Maximillian,https://rpg.stackexchange.com/users/18,"Providing context for your setting. Define enough of your cultures, religions, and society so that there is conflict. This will generate motives for PCs and NPCs alike. 

For example all the gods in my setting hates demons which are considered universally evil. One of the common traits of my ""evil"" gods  are extreme philosophies in dealing with Demons. For example Set believes in absolute order, a rigid hierarchy, blind obedience. Mitra likewise believes in order, hierarchy, and obedience but tempered with virtues like justice and mercy. So this aspect of my campaign setups a three way conflict. I had PCs utterly at odds with the Church of Set and yet had to ally because they discovered something demonic that was beyond their ability to handle. Then in the aftermath they are at odds again because of attitudes of the adherents of Set.

You don't have to be a Tolkien, a M.A.R. Barker (Tekemal) to do this. Just think about the consequences of some of the assumptions you and the rules make about the fantasy setting and write up it in a page or two. 

Then fit your NPCs motivations within that framework and play it out from there. On the flip side give PCs a background embedded in that framework. Make their association with the various elements of the framework beneficial. This give a bigger chance that they will care about the Villain NPC's motives and truly despise him for it.
",RS Conley,https://rpg.stackexchange.com/users/93,http://rpg.stackexchange.com/questions/584/how-do-i-create-a-great-fantasy-villain-that-inspires-the-party-to-rally-against,CULTURE,rpg.stackexchange.com,0.8888888888888888,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.5555555555555556,0.6666666666666666,1.0,0.0,1.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.8,0.3333333333333333,0.0,0.0,0.7777777777777778,How can I create a great fantasy villain to inspire the party to unite against them?,"In my early years of GMing it was simple enough to say that the badguys were evil and that was all the justification we needed.  They are attacking the village because they are evil, they are stealing the princess because they are evil, etc.

Over time, my group needs have grown to need more complicated and detailed villains. It is important to consider motives.  What is it that defines them as 'evil' to the party?  In terms of a fantasy setting, what would you consider to be an interesting villain?

What qualities make a villain that inspires your party to rally against him?  What kind of villains have worked for your games in the past?

Example:


  A member of nobility is using trade connections to move valuable pieces of art into another country that is secretly paying him quite well and is framing a member of the party to take the fall.  In addition, someone important to the party member has been taken hostage with a promise of release once they party member takes the blame for the crime.

","Providing context for your setting. Define enough of your cultures, religions, and society so that there is conflict. This will generate motives for PCs and NPCs alike. 

For example all the gods in my setting hates demons which are considered universally evil. One of the common traits of my ""evil"" gods  are extreme philosophies in dealing with Demons. For example Set believes in absolute order, a rigid hierarchy, blind obedience. Mitra likewise believes in order, hierarchy, and obedience but tempered with virtues like justice and mercy. So this aspect of my campaign setups a three way conflict. I had PCs utterly at odds with the Church of Set and yet had to ally because they discovered something demonic that was beyond their ability to handle. Then in the aftermath they are at odds again because of attitudes of the adherents of Set.

You don't have to be a Tolkien, a M.A.R. Barker (Tekemal) to do this. Just think about the consequences of some of the assumptions you and the rules make about the fantasy setting and write up it in a page or two. 

Then fit your NPCs motivations within that framework and play it out from there. On the flip side give PCs a background embedded in that framework. Make their association with the various elements of the framework beneficial. This give a bigger chance that they will care about the Villain NPC's motives and truly despise him for it.
"
5299,5299,8417,Problem when installing “ia32-libs”,"I'm using x64 Ubuntu. A few months ago I accidentally messed up the groups/owners of all files on /, but managed to fix it using a VirtualBox install of Ubuntu.

Now I'm running into a problem that I think is related to that mistake. When I try to reinstall ia32-libs (Skype is having problems so I need to reinstall those libs) I get an error message:


  /var/lib/dpkg/info/ia32-libs.postinst: 40: /usr/lib32/gdk-pixbuf-2.0/gdk-pixbuf-query-loaders: Permission denied


ls -al /usr/lib32/gdk-pixbuf-2.0/` is this:

total 476
drwxr-xr-x  3 root root   4096 2011-09-24 17:08 .
drwxr-xr-x 53 root root 143360 2011-09-24 17:08 ..
drwxr-xr-x  3 root root     40 2011-09-24 04:44 2.10.0
-rwxr-xr-x  1 root root   9648 2011-04-05 00:40 gdk-pixbuf-query-loaders


I have tried to reinstall gdk-pixbuff-2.0, but it didn't work. How can I fix this?
",BoPe,https://unix.stackexchange.com/users/11004,"Run ldd /usr/lib32/gdk-pixbuf-2.0//gdk-pixbuf-query-loaders and make sure every file is accounted for (the line must end with an address like (0xf7789000)). In particular, check the permissions on the dynamic loader /lib/ld-linux.so.2. This is the only file in the lot that could cause that particular error message, but you may need to fix other permissions while you're at it.

chown root:root /lib*/*
chmod a+rx /lib*/ld-* /lib*/*/
chmod -R a+r /lib

",Gilles,https://unix.stackexchange.com/users/885,http://unix.stackexchange.com/questions/21357/problem-when-installing-ia32-libs,TECHNOLOGY,unix.stackexchange.com,1.0,0.4444444444444444,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.0,0.0,0.8888888888888888,There was a problem installing 'IA32 LIBS',"I'm using x64 Ubuntu. A few months ago I accidentally messed up the groups/owners of all files on /, but managed to fix it using a VirtualBox install of Ubuntu.

Now I'm running into a problem that I think is related to that mistake. When I try to reinstall ia32-libs (Skype is having problems so I need to reinstall those libs) I get an error message:


  /var/lib/dpkg/info/ia32-libs.postinst: 40: /usr/lib32/gdk-pixbuf-2.0/gdk-pixbuf-query-loaders: Permission denied


ls -al /usr/lib32/gdk-pixbuf-2.0/` is this:

total 476
drwxr-xr-x  3 root root   4096 2011-09-24 17:08 .
drwxr-xr-x 53 root root 143360 2011-09-24 17:08 ..
drwxr-xr-x  3 root root     40 2011-09-24 04:44 2.10.0
-rwxr-xr-x  1 root root   9648 2011-04-05 00:40 gdk-pixbuf-query-loaders


I have tried to reinstall gdk-pixbuff-2.0, but it didn't work. How can I fix this?
","Run LDD / usr / lib32 / gdk-pixbuf-2.0 / / gdk-pixbuf-query-loaders and make sure that each file is taken into account (the line must end with an address similar to (0xf7789000)). In particular, check the permissions on the dynamic loader / lib / LD Linux. So. 2. This is the only file in the batch file that may cause this particular error message, but you may need to fix other permissions while processing."
4583,4583,7264,"Can you send data usefully over one wire, literally one wire?","It is possible to design networking systems that only use two wires: one for data and one for a common ground. Examples include 1-wire and Pin&amp;Play. These are called single wire systems because the requirement for an earth wire is implied too. But you can also get systems to extend home networks that use the home earth to connect network points, like Power Line Communication. How is this possible over just one wire?

== EDIT ==

From the answers (thanks!) I think I failed to word this question clearly. Let me try again.

Can you send data usefully over one wire, literally one wire? Radio is zero, 1-wire is two, but is it possible with one? ""No, and here's why"" or ""Yes, here's how it is done in X"" are the kind of answers I am hoping for.

(N.B. I'll also change the question title from ""Single wire systems need two wires; so how does ethernet over ground work?"" to ""Can you send data usefully over one wire, literally one wire?"")
",dumbledad,https://electronics.stackexchange.com/users/10772,"Over a very limited range - yes.  You will need to have a return path that is supported by electric fields.  The best way to look at this would be like a AC coupled circuit - coupled through a capacitor of which the capacitor is formed by some plate that the circuit is coupled to and another plate that is providing a return path.

We know that electric fields can couple over long-ish distances, some Anti-aircraft proximity fuzes from WWII used an e-field detection technique that would trigger the bomb because the shell and the aircraft would be carrying different levels of charge and thus e-field lines would form linking the two and thus change the capacitance in an internal circuit.

This in no way violates physics, it's best to view it as a capacitor that is so physically large that you can walk between the plates.  However, the actual capacitance value would be very small.

uChip just released some technology that uses a similar effect that is called GestIC and they couple with E-Fields.  Here they couple on both the top rail and the return path so it is a ""Zero"" wire solution.  But it will also work if you ground one of the plates inside the remote device to one polarity of the plate in the ""pad"".
",placeholder,https://electronics.stackexchange.com/users/11861,http://electronics.stackexchange.com/questions/67692/can-you-send-data-usefully-over-one-wire-literally-one-wire,TECHNOLOGY,electronics.stackexchange.com,0.8888888888888888,0.6666666666666666,0.0,0.3333333333333333,1.0,1.0,0.5555555555555556,0.3333333333333333,0.6666666666666666,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.7777777777777778,1.0,0.7777777777777778,1.0,1.0,0.8666666666666666,0.0,0.0,1.0,0.7777777777777778,Can you use a wire to send data effectively? Is it really a wire?,"It is possible to design networking systems that only use two wires: one for data and one for a common ground. Examples include 1-wire and Pin&amp;Play. These are called single wire systems because the requirement for an earth wire is implied too. But you can also get systems to extend home networks that use the home earth to connect network points, like Power Line Communication. How is this possible over just one wire?

== EDIT ==

From the answers (thanks!) I think I failed to word this question clearly. Let me try again.

Can you send data usefully over one wire, literally one wire? Radio is zero, 1-wire is two, but is it possible with one? ""No, and here's why"" or ""Yes, here's how it is done in X"" are the kind of answers I am hoping for.

(N.B. I'll also change the question title from ""Single wire systems need two wires; so how does ethernet over ground work?"" to ""Can you send data usefully over one wire, literally one wire?"")
","Over a very limited range - yes.  You will need to have a return path that is supported by electric fields.  The best way to look at this would be like a AC coupled circuit - coupled through a capacitor of which the capacitor is formed by some plate that the circuit is coupled to and another plate that is providing a return path.

We know that electric fields can couple over long-ish distances, some Anti-aircraft proximity fuzes from WWII used an e-field detection technique that would trigger the bomb because the shell and the aircraft would be carrying different levels of charge and thus e-field lines would form linking the two and thus change the capacitance in an internal circuit.

This in no way violates physics, it's best to view it as a capacitor that is so physically large that you can walk between the plates.  However, the actual capacitance value would be very small.

uChip just released some technology that uses a similar effect that is called GestIC and they couple with E-Fields.  Here they couple on both the top rail and the return path so it is a ""Zero"" wire solution.  But it will also work if you ground one of the plates inside the remote device to one polarity of the plate in the ""pad"".
"
4654,4654,7377,What version of flash uses Actionscript 3?,"I have been given a book on Actionscript 3 and I am looking to get started with learning it. What version of flash uses actionscript 3?

Also does anyone know if adobe offer trial versions of their software for OSX? (10.6 snow leapard).
",James Jeffery,https://stackoverflow.com/users/359916,"Flash IDE versions CS3 and upwards can use ActionScript 3.

Flash Player 9, was the first player to support AS3 SWFs: http://en.wikipedia.org/wiki/Adobe_Flash_Player
",JBRWilkinson,https://stackoverflow.com/users/102345,http://stackoverflow.com/questions/3129335/what-version-of-flash-uses-actionscript-3,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.3333333333333333,0.0,1.0,1.0,1.0,0.4444444444444444,1.0,1.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,1.0,0.6666666666666666,0.0,0.0,0.0,1.0,1.0,0.3333333333333333,1.0,0.7777777777777778,0.6,0.0,0.0,0.0,0.8888888888888888,What version of flash uses ActionScript 3?,"I have been given a book on Actionscript 3 and I am looking to get started with learning it. What version of flash uses actionscript 3?

Also does anyone know if adobe offer trial versions of their software for OSX? (10.6 snow leapard).
","Flash IDE versions CS3 and upwards can use ActionScript 3.

Flash Player 9, was the first player to support AS3 SWFs: http://en.wikipedia.org/wiki/Adobe_Flash_Player
"
2147,2147,3419,can´t save new field in magento(1.9) customer registration checkout form,"I followed the instructions to add a new field in customer registration from add new field in magento(1.9) customer registration, works perfect!

I need help to add this field to customer registration on checkout page also.

I added this to my module xml (ea_dni is the name of my module):

&lt;checkout_onepage_index&gt;
    &lt;reference name=""checkout.onepage.billing""&gt;
        &lt;action method=""setTemplate""&gt;
            &lt;template&gt;ea_dni/billing.phtml&lt;/template&gt;
        &lt;/action&gt;
    &lt;/reference&gt;
&lt;/checkout_onepage_index&gt;


And I added the field in billing.phtml

            &lt;li&gt;
                &lt;label for=""eadni""&gt;&lt;?php echo $this-&gt;__('DNI') ?&gt;&lt;/label&gt;
                &lt;div class=""input-box""&gt;
                    &lt;input type=""text"" name=""eadni"" id=""eadni"" value=""&lt;?php echo $this-&gt;htmlEscape($this-&gt;getCustomer()-&gt;getDNI()) ?&gt;"" title=""&lt;?php echo $this-&gt;__('DNI') ?&gt;"" class=""input-text"" /&gt;
                &lt;/div&gt;
            &lt;/li&gt;


So, I see the new field in checkout registration form, but this field is not saving to the database!

This is my install-1.0.0.php

&lt;?php

$this-&gt;addAttribute('customer', 'eadni', array(
    'type'      =&gt; 'varchar',
    'label'     =&gt; 'DNI',
    'input'     =&gt; 'text',
    'position'  =&gt; 120,
    'required'  =&gt; false,//or true
    'is_system' =&gt; 0,
));
$attribute = Mage::getSingleton('eav/config')-&gt;getAttribute('customer', 'eadni');
$attribute-&gt;setData('used_in_forms', array(
    'adminhtml_customer',
    'checkout_register',
    'customer_account_create',
    'customer_account_edit',
));
$attribute-&gt;setData('is_user_defined', 0);
$attribute-&gt;save();


Can you help me? What am I missing?

Here is my app/code/local/EA/DNI/config.xml

&lt;?xml version=""1.0""?&gt;
&lt;config&gt;
    &lt;modules&gt;
        &lt;EA_DNI&gt;
            &lt;version&gt;1.0.0&lt;/version&gt;
        &lt;/EA_DNI&gt;
    &lt;/modules&gt;
    &lt;global&gt;
        &lt;helpers&gt;
            &lt;ea_dni&gt;
                &lt;class&gt;EA_DNI_Helper&lt;/class&gt;
            &lt;/ea_dni&gt;
        &lt;/helpers&gt;
        &lt;resources&gt;
            &lt;ea_dni_setup&gt;
                &lt;setup&gt;
                    &lt;module&gt;EA_DNI&lt;/module&gt;
                    &lt;class&gt;Mage_Customer_Model_Resource_Setup&lt;/class&gt;
                &lt;/setup&gt;
            &lt;/ea_dni_setup&gt;
        &lt;/resources&gt;
    &lt;/global&gt;
    &lt;frontend&gt;
        &lt;layout&gt;
            &lt;updates&gt;
                &lt;ea_dni&gt;
                    &lt;file&gt;ea_dni.xml&lt;/file&gt;
                &lt;/ea_dni&gt;
            &lt;/updates&gt;
        &lt;/layout&gt;
        &lt;translate&gt;
            &lt;modules&gt;
                &lt;EA_DNI&gt;
                    &lt;files&gt;
                        &lt;default&gt;EA_DNI.csv&lt;/default&gt;
                    &lt;/files&gt;
                &lt;/EA_DNI&gt;
            &lt;/modules&gt;
        &lt;/translate&gt;
    &lt;/frontend&gt;
&lt;/config&gt;

",elismoran,https://magento.stackexchange.com/users/27241,"Replace your code in install-1.0.0.php with the following code

&lt;?php
$installer = $this;
$installer-&gt;startSetup();
$setup = Mage::getModel('customer/entity_setup', 'core_setup');
$setup-&gt;addAttribute('customer', 'eadni', array(
    'type' =&gt; 'varchar',
    'input' =&gt; 'text',
    'label' =&gt; 'DNI',
    'position'  =&gt; 120,
    'required' =&gt; 0,
    'is_system' =&gt; 0,
    'user_defined' =&gt; 1,

));
if (version_compare(Mage::getVersion(), '1.6.0', '&lt;='))
{
      $customer = Mage::getModel('customer/customer');
      $attrSetId = $customer-&gt;getResource()-&gt;getEntityType()-&gt;getDefaultAttributeSetId();
      $setup-&gt;addAttributeToSet('customer', $attrSetId, 'General', 'eadni');
}
if (version_compare(Mage::getVersion(), '1.4.2', '&gt;='))
{
    Mage::getSingleton('eav/config')
    -&gt;getAttribute('customer', 'eadni')
    -&gt;setData('used_in_forms',     array('adminhtml_customer','customer_account_create','customer_account_edit','checkout_register'))
    -&gt;save();
}

$tablequote = $this-&gt;getTable('sales/quote');
$installer-&gt;run(""
ALTER TABLE  $tablequote ADD  `customer_eadni` VARCHAR( 255 ) NOT NULL
"");

$installer-&gt;endSetup();


and add this code in your config.xml under &lt;global&gt; tag

&lt;fieldsets&gt;
        &lt;customer_account&gt;
             &lt;eadni&gt;&lt;create&gt;1&lt;/create&gt;&lt;update&gt;1&lt;/update&gt;&lt;name&gt;1&lt;/name&gt;&lt;/eadni&gt;
        &lt;/customer_account&gt;

        &lt;checkout_onepage_quote&gt;
            &lt;customer_eadni&gt;
                &lt;to_customer&gt;eadni&lt;/to_customer&gt;
            &lt;/customer_eadni&gt;
        &lt;/checkout_onepage_quote&gt;
        &lt;customer_account&gt;
            &lt;eadni&gt;
                &lt;to_quote&gt;customer_eadni&lt;/to_quote&gt;
            &lt;/eadni&gt;
        &lt;/customer_account&gt; 
    &lt;/fieldsets&gt;

",Piyush,https://magento.stackexchange.com/users/20064,http://magento.stackexchange.com/questions/71579/can%C2%B4t-save-new-field-in-magento1-9-customer-registration-checkout-form,TECHNOLOGY,magento.stackexchange.com,1.0,0.5555555555555556,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,0.8888888888888888,Unable to save new fields in the Magento (1.9) customer registration checkout form,"I followed the instructions to add a new field in customer registration from add new field in magento(1.9) customer registration, works perfect!

I need help to add this field to customer registration on checkout page also.

I added this to my module xml (ea_dni is the name of my module):

&lt;checkout_onepage_index&gt;
    &lt;reference name=""checkout.onepage.billing""&gt;
        &lt;action method=""setTemplate""&gt;
            &lt;template&gt;ea_dni/billing.phtml&lt;/template&gt;
        &lt;/action&gt;
    &lt;/reference&gt;
&lt;/checkout_onepage_index&gt;


And I added the field in billing.phtml

            &lt;li&gt;
                &lt;label for=""eadni""&gt;&lt;?php echo $this-&gt;__('DNI') ?&gt;&lt;/label&gt;
                &lt;div class=""input-box""&gt;
                    &lt;input type=""text"" name=""eadni"" id=""eadni"" value=""&lt;?php echo $this-&gt;htmlEscape($this-&gt;getCustomer()-&gt;getDNI()) ?&gt;"" title=""&lt;?php echo $this-&gt;__('DNI') ?&gt;"" class=""input-text"" /&gt;
                &lt;/div&gt;
            &lt;/li&gt;


So, I see the new field in checkout registration form, but this field is not saving to the database!

This is my install-1.0.0.php

&lt;?php

$this-&gt;addAttribute('customer', 'eadni', array(
    'type'      =&gt; 'varchar',
    'label'     =&gt; 'DNI',
    'input'     =&gt; 'text',
    'position'  =&gt; 120,
    'required'  =&gt; false,//or true
    'is_system' =&gt; 0,
));
$attribute = Mage::getSingleton('eav/config')-&gt;getAttribute('customer', 'eadni');
$attribute-&gt;setData('used_in_forms', array(
    'adminhtml_customer',
    'checkout_register',
    'customer_account_create',
    'customer_account_edit',
));
$attribute-&gt;setData('is_user_defined', 0);
$attribute-&gt;save();


Can you help me? What am I missing?

Here is my app/code/local/EA/DNI/config.xml

&lt;?xml version=""1.0""?&gt;
&lt;config&gt;
    &lt;modules&gt;
        &lt;EA_DNI&gt;
            &lt;version&gt;1.0.0&lt;/version&gt;
        &lt;/EA_DNI&gt;
    &lt;/modules&gt;
    &lt;global&gt;
        &lt;helpers&gt;
            &lt;ea_dni&gt;
                &lt;class&gt;EA_DNI_Helper&lt;/class&gt;
            &lt;/ea_dni&gt;
        &lt;/helpers&gt;
        &lt;resources&gt;
            &lt;ea_dni_setup&gt;
                &lt;setup&gt;
                    &lt;module&gt;EA_DNI&lt;/module&gt;
                    &lt;class&gt;Mage_Customer_Model_Resource_Setup&lt;/class&gt;
                &lt;/setup&gt;
            &lt;/ea_dni_setup&gt;
        &lt;/resources&gt;
    &lt;/global&gt;
    &lt;frontend&gt;
        &lt;layout&gt;
            &lt;updates&gt;
                &lt;ea_dni&gt;
                    &lt;file&gt;ea_dni.xml&lt;/file&gt;
                &lt;/ea_dni&gt;
            &lt;/updates&gt;
        &lt;/layout&gt;
        &lt;translate&gt;
            &lt;modules&gt;
                &lt;EA_DNI&gt;
                    &lt;files&gt;
                        &lt;default&gt;EA_DNI.csv&lt;/default&gt;
                    &lt;/files&gt;
                &lt;/EA_DNI&gt;
            &lt;/modules&gt;
        &lt;/translate&gt;
    &lt;/frontend&gt;
&lt;/config&gt;

","Replace your code in install-1.0.0.php with the following code

&lt;?php
$installer = $this;
$installer-&gt;startSetup();
$setup = Mage::getModel('customer/entity_setup', 'core_setup');
$setup-&gt;addAttribute('customer', 'eadni', array(
    'type' =&gt; 'varchar',
    'input' =&gt; 'text',
    'label' =&gt; 'DNI',
    'position'  =&gt; 120,
    'required' =&gt; 0,
    'is_system' =&gt; 0,
    'user_defined' =&gt; 1,

));
if (version_compare(Mage::getVersion(), '1.6.0', '&lt;='))
{
      $customer = Mage::getModel('customer/customer');
      $attrSetId = $customer-&gt;getResource()-&gt;getEntityType()-&gt;getDefaultAttributeSetId();
      $setup-&gt;addAttributeToSet('customer', $attrSetId, 'General', 'eadni');
}
if (version_compare(Mage::getVersion(), '1.4.2', '&gt;='))
{
    Mage::getSingleton('eav/config')
    -&gt;getAttribute('customer', 'eadni')
    -&gt;setData('used_in_forms',     array('adminhtml_customer','customer_account_create','customer_account_edit','checkout_register'))
    -&gt;save();
}

$tablequote = $this-&gt;getTable('sales/quote');
$installer-&gt;run(""
ALTER TABLE  $tablequote ADD  `customer_eadni` VARCHAR( 255 ) NOT NULL
"");

$installer-&gt;endSetup();


and add this code in your config.xml under &lt;global&gt; tag

&lt;fieldsets&gt;
        &lt;customer_account&gt;
             &lt;eadni&gt;&lt;create&gt;1&lt;/create&gt;&lt;update&gt;1&lt;/update&gt;&lt;name&gt;1&lt;/name&gt;&lt;/eadni&gt;
        &lt;/customer_account&gt;

        &lt;checkout_onepage_quote&gt;
            &lt;customer_eadni&gt;
                &lt;to_customer&gt;eadni&lt;/to_customer&gt;
            &lt;/customer_eadni&gt;
        &lt;/checkout_onepage_quote&gt;
        &lt;customer_account&gt;
            &lt;eadni&gt;
                &lt;to_quote&gt;customer_eadni&lt;/to_quote&gt;
            &lt;/eadni&gt;
        &lt;/customer_account&gt; 
    &lt;/fieldsets&gt;

"
4275,4275,6812,Why choose an 80-200mm over an 18-200mm lens?,"Being a beginner, I can't see why I must choose an 80-200 over an 18-200. Are there scenarios where an 80-200 would be preferable over an 18-200?

I will be buying a D7000 soon and am looking at these:


AF Zoom-NIKKOR 80-200mm f/2.8D ED
AF-S DX NIKKOR 18-200mm f/3.5-5.6G ED VR II


but similar considerations would apply to other brands as well.
",Ygam,https://photo.stackexchange.com/users/2362,"Usually lenses with a large focal ranges end up having poorer quality than lenses for each ""normal"" focal range (tele, wide, regular zoom). You get more versatility with lower image quality, it's a case of ""Jack of all trades, master of none"".
",t3mujin,https://photo.stackexchange.com/users/938,http://photo.stackexchange.com/questions/11247/why-choose-an-80-200mm-over-an-18-200mm-lens,LIFE_ARTS,photo.stackexchange.com,0.8888888888888888,0.8888888888888888,0.6666666666666666,1.0,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.0,0.0,0.6666666666666666,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.0,0.3333333333333333,0.8888888888888888,Why 80-200mm instead of 18-200mm?,"Being a beginner, I can't see why I must choose an 80-200 over an 18-200. Are there scenarios where an 80-200 would be preferable over an 18-200?

I will be buying a D7000 soon and am looking at these:


AF Zoom-NIKKOR 80-200mm f/2.8D ED
AF-S DX NIKKOR 18-200mm f/3.5-5.6G ED VR II


but similar considerations would apply to other brands as well.
","Generally, the quality of a lens with a larger focal length is worse than that of a lens at each ""normal"" focal length (telephoto, wide focus, conventional zoom). You get more versatility and lower image quality, which is a case of ""Jack of all trades, no masters.""."
214,214,345,What route do I use to refer to the path of the current user's profile? Devise,"Users of my application upload an avatar when they create their profiles. Here is how I display a small version of their profile picture in the navbar:

 &lt;li&gt;&lt;%= link_to image_tag current_user.avatar(:nav) %&gt;&lt;/li&gt;


I want that link to to go to the profile page of the current user. Here are my routes:

  Prefix Verb   URI Pattern                    Controller#Action
                  things GET    /things(.:format)              things#index
                         POST   /things(.:format)              things#create
               new_thing GET    /things/new(.:format)          things#new
              edit_thing GET    /things/:id/edit(.:format)     things#edit
                   thing GET    /things/:id(.:format)          things#show
                         PATCH  /things/:id(.:format)          things#update
                         PUT    /things/:id(.:format)          things#update
                         DELETE /things/:id(.:format)          things#destroy
        new_user_session GET    /users/sign_in(.:format)       devise/sessions#new
            user_session POST   /users/sign_in(.:format)       devise/sessions#create
    destroy_user_session DELETE /users/sign_out(.:format)      devise/sessions#destroy
           user_password POST   /users/password(.:format)      devise/passwords#create
       new_user_password GET    /users/password/new(.:format)  devise/passwords#new
      edit_user_password GET    /users/password/edit(.:format) devise/passwords#edit
                         PATCH  /users/password(.:format)      devise/passwords#update
                         PUT    /users/password(.:format)      devise/passwords#update
cancel_user_registration GET    /users/cancel(.:format)        devise/registrations#cancel
       user_registration POST   /users(.:format)               devise/registrations#create
   new_user_registration GET    /users/sign_up(.:format)       devise/registrations#new
  edit_user_registration GET    /users/edit(.:format)          devise/registrations#edit
                         PATCH  /users(.:format)               devise/registrations#update
                         PUT    /users(.:format)               devise/registrations#update
                         DELETE /users(.:format)               devise/registrations#destroy
                   users POST   /users(.:format)               users#create
                new_user GET    /users/new(.:format)           users#new
                    user GET    /users/:id(.:format)           users#show
                   about GET    /about(.:format)               pagess#about
                    root GET    /                              things#index


I am currently using Devise for authentication.

Here is my UsersController

class UsersController &lt; ApplicationController
  def show
    @user = User.find_by_username(params[:id])
  end

  def user_params
      params.require(:user).permit(:avatar)
  end
end

",Dylan Richards,https://stackoverflow.com/users/2966990,"From the routes you've provided, your user's profile would be users#show.  So the path you're looking for should be user_path. 

#app/controllers/users_controller.rb
class UsersController &lt; ApplicationController
  def show
    @user = User.find(params[:id]
    ...
  end
end


Then in app/views/users/show.html.erb you show the user's profile information. 
",vee,https://stackoverflow.com/users/2453699,http://stackoverflow.com/questions/20305008/what-route-do-i-use-to-refer-to-the-path-of-the-current-users-profile-devise,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.7777777777777778,0.0,1.0,1.0,1.0,0.6666666666666666,0.4444444444444444,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.6666666666666666,0.3333333333333333,0.0,0.7777777777777778,What path do I use to refer to the path of the current user profile? Design,"Users of my application upload an avatar when they create their profiles. Here is how I display a small version of their profile picture in the navbar:

 &lt;li&gt;&lt;%= link_to image_tag current_user.avatar(:nav) %&gt;&lt;/li&gt;


I want that link to to go to the profile page of the current user. Here are my routes:

  Prefix Verb   URI Pattern                    Controller#Action
                  things GET    /things(.:format)              things#index
                         POST   /things(.:format)              things#create
               new_thing GET    /things/new(.:format)          things#new
              edit_thing GET    /things/:id/edit(.:format)     things#edit
                   thing GET    /things/:id(.:format)          things#show
                         PATCH  /things/:id(.:format)          things#update
                         PUT    /things/:id(.:format)          things#update
                         DELETE /things/:id(.:format)          things#destroy
        new_user_session GET    /users/sign_in(.:format)       devise/sessions#new
            user_session POST   /users/sign_in(.:format)       devise/sessions#create
    destroy_user_session DELETE /users/sign_out(.:format)      devise/sessions#destroy
           user_password POST   /users/password(.:format)      devise/passwords#create
       new_user_password GET    /users/password/new(.:format)  devise/passwords#new
      edit_user_password GET    /users/password/edit(.:format) devise/passwords#edit
                         PATCH  /users/password(.:format)      devise/passwords#update
                         PUT    /users/password(.:format)      devise/passwords#update
cancel_user_registration GET    /users/cancel(.:format)        devise/registrations#cancel
       user_registration POST   /users(.:format)               devise/registrations#create
   new_user_registration GET    /users/sign_up(.:format)       devise/registrations#new
  edit_user_registration GET    /users/edit(.:format)          devise/registrations#edit
                         PATCH  /users(.:format)               devise/registrations#update
                         PUT    /users(.:format)               devise/registrations#update
                         DELETE /users(.:format)               devise/registrations#destroy
                   users POST   /users(.:format)               users#create
                new_user GET    /users/new(.:format)           users#new
                    user GET    /users/:id(.:format)           users#show
                   about GET    /about(.:format)               pagess#about
                    root GET    /                              things#index


I am currently using Devise for authentication.

Here is my UsersController

class UsersController &lt; ApplicationController
  def show
    @user = User.find_by_username(params[:id])
  end

  def user_params
      params.require(:user).permit(:avatar)
  end
end

","From the routes you've provided, your user's profile would be users#show.  So the path you're looking for should be user_path. 

#app/controllers/users_controller.rb
class UsersController &lt; ApplicationController
  def show
    @user = User.find(params[:id]
    ...
  end
end


Then in app/views/users/show.html.erb you show the user's profile information. 
"
4605,4605,7301,Reverse iteration from a given map iterator,"I want to find an element in the map using map::find(key), and then iterate the map in reverse order from the point where I found the element, till the beginning (i.e. until  map::rend()).

However, I get a compile error when I try to assign my iterator to a reverse_iterator.  How do I solve this?
",OverTheEdge,https://stackoverflow.com/users/120481,"Converting an iterator to a reverse iterator via the constructor should work fine, e.g. std::map&lt;K, V&gt;::reverse_iterator rit(mypos).

A minimal example using std::vector:

#include &lt;vector&gt;
#include &lt;iostream&gt;
#include &lt;algorithm&gt;

int main() {
  typedef std::vector&lt;int&gt; intVec;
  intVec vec;
  for(int i = 0; i &lt; 20; ++i) vec.push_back(i);

  for(intVec::reverse_iterator it(std::find(vec.begin(), vec.end(), 10));
      it != vec.rend(); it++)
    std::cout &lt;&lt; *it;
}

",pmr,https://stackoverflow.com/users/105672,http://stackoverflow.com/questions/2310656/reverse-iteration-from-a-given-map-iterator,STACKOVERFLOW,stackoverflow.com,1.0,0.3333333333333333,0.0,0.6666666666666666,1.0,0.0,0.6666666666666666,0.8888888888888888,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,1.0,Reverse iteration from a given map iterator,"I want to use map:: find (key) to find an element in the map, and then iterate the map from the point where the element was found to the beginning (that is, until map:: rend()).","Converting an iterator to a reverse iterator via the constructor should work fine, e.g. std::map&lt;K, V&gt;::reverse_iterator rit(mypos).

A minimal example using std::vector:

#include &lt;vector&gt;
#include &lt;iostream&gt;
#include &lt;algorithm&gt;

int main() {
  typedef std::vector&lt;int&gt; intVec;
  intVec vec;
  for(int i = 0; i &lt; 20; ++i) vec.push_back(i);

  for(intVec::reverse_iterator it(std::find(vec.begin(), vec.end(), 10));
      it != vec.rend(); it++)
    std::cout &lt;&lt; *it;
}

"
652,652,1035,How much of the universe is observable at visible wavelengths?,"Knowing that:


The Zone of Avoidance (Looking towards the center of the Milky Way) blocks roughly 20%
Each Milky Way star has an angular size, depending on proximity, that obscures a certain percentage of our optical view.
Each Galaxy has an angular size, depending on proximity, that obscures a certain percentage of our optical view.


And so on through Galaxy Clusters, Superstructures, etc...

What percentage of our universe can we not see at visible wavelengths?
",PJL71,https://physics.stackexchange.com/users/16638,"Surprisingly, it makes no sense to make calculations with the angle subtended by objects. They don't simply ""block out"" the light of foreground objects. The Universe is more subtle than that and, when you spot a galaxy, in most cases you can be pretty sure that there isn't anything behind it, at least anything that you would be able to see if the galaxy were removed.

Moreover, the fact that two objects lie along the same line of sight is a happy coincidence, that helps seeing the most distant one, due to gravitational lensing amplification. Usually the background object would be too faint to be detected otherwise. Whole Ph.D. thesis are written every year due to this extraordinary coincidences. See this beautiful image, called the Horseshoe lens, where the image of a distant blue galaxy, that lies far behind a red foreground elliptical, not only is not blocked out, but is even amplified:



(image from Wikipedia Commons http://en.wikipedia.org/wiki/File:A_Horseshoe_Einstein_Ring_from_Hubble.JPG)

This effect happens too with individual stars, and nowadays telescopes are not able yet to resolve the images in that case, but we can still detect an increase in brightness (that is how a lot of extrasolar planents are being detected). See http://en.wikipedia.org/wiki/Microlensing .In addition to that, typical transverse speeds of stars make unrealistic that a star can hide another fainter one for much time...

Another fact is that, for nearly all practical purposes, galaxies are transparent. In the worst scenario you can think of, at least the different redshifts in the lines would allow to distinguish between two overimposed images. A famous example is the galaxy ngc7603. Two foreground objects with redshifts ~0.2 and ~0.4 are seen through the galaxy itself at redshift ~0.03:


 (Image from http://quasars.org/ngc7603.htm)

Another famous example is Q2237+030 (known as ""Huchra Lens"" or ""Einstein Cross""), a background quasar that is seen through the very center of a galaxy. As an additional effect, we see four images of the background quasar, thanks to the bulk mass of the foreground galaxy acting as a lens:



(downloaded from http://www.astr.ua.edu/keel/agn/qso2237.html)

And, finally the image of a star is not a tiny circle, but a diffuse spot, in the ideal case with faint rings (the so called Airy diffraction pattern, impossible to avoid even for the HST) but usually blurred by the atmosphere and spatially extended thorough the CCD plane. That is why it is so difficult to spot Pluto's moon. Not because the angle the objects subtend, but rather due to technical optical limitations (and atmospheric blurring). In some cases, sophisticated deconvolution algorithms have allowed to see additional objects that were embedded in the blurry image of the star. That is how three planets could be seen around HR8977, a star 140 light-years away:

 

(image from http://keckobservatory.org/gallery/detail/milky_way/27)  

The zone of avoidance is only an annoyance if you want to have data from a particular object in a particular wavelength interval, but it is not important for our understanding of the Universe, since at large scales the Universe is homogeneous and isotropic. Consider too that, if we don't restrict to the tiny portion of the spectrum called visible light, the zone of avoidance is not as bad as it seems. I am still amazed by this infrared movie of stars orbiting the central black hole in our galaxy, that was made looking directly through the avoidance zone:

http://www.astro.ucla.edu/~ghezgroup/gc/pictures/orbitsMovie.shtml

A big progress is being made too in gamma and x-rays detectors. It is not completely unrealistic to think that, in the future, there might be neutrino telescopes that achieve the same resolution of today optical instruments (radio astronomy with optical resolution was too a fantasy at the beginning). That would unveil new regions, for instance it would allow us to look directly at the center of the Sun...
",Eduardo Guerras Valera,https://physics.stackexchange.com/users/14182,http://physics.stackexchange.com/questions/46189/how-much-of-the-universe-is-observable-at-visible-wavelengths,SCIENCE,physics.stackexchange.com,1.0,0.8888888888888888,0.0,1.0,1.0,1.0,0.5555555555555556,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.7777777777777778,0.7777777777777778,0.8888888888888888,0.8888888888888888,0.7777777777777778,0.6666666666666667,0.0,0.0,1.0,0.7777777777777778,How much of the universe can be observed in visible light?,"Knowing that:


The Zone of Avoidance (Looking towards the center of the Milky Way) blocks roughly 20%
Each Milky Way star has an angular size, depending on proximity, that obscures a certain percentage of our optical view.
Each Galaxy has an angular size, depending on proximity, that obscures a certain percentage of our optical view.


And so on through Galaxy Clusters, Superstructures, etc...

What percentage of our universe can we not see at visible wavelengths?
","Surprisingly, it makes no sense to make calculations with the angle subtended by objects. They don't simply ""block out"" the light of foreground objects. The Universe is more subtle than that and, when you spot a galaxy, in most cases you can be pretty sure that there isn't anything behind it, at least anything that you would be able to see if the galaxy were removed.

Moreover, the fact that two objects lie along the same line of sight is a happy coincidence, that helps seeing the most distant one, due to gravitational lensing amplification. Usually the background object would be too faint to be detected otherwise. Whole Ph.D. thesis are written every year due to this extraordinary coincidences. See this beautiful image, called the Horseshoe lens, where the image of a distant blue galaxy, that lies far behind a red foreground elliptical, not only is not blocked out, but is even amplified:



(image from Wikipedia Commons http://en.wikipedia.org/wiki/File:A_Horseshoe_Einstein_Ring_from_Hubble.JPG)

This effect happens too with individual stars, and nowadays telescopes are not able yet to resolve the images in that case, but we can still detect an increase in brightness (that is how a lot of extrasolar planents are being detected). See http://en.wikipedia.org/wiki/Microlensing .In addition to that, typical transverse speeds of stars make unrealistic that a star can hide another fainter one for much time...

Another fact is that, for nearly all practical purposes, galaxies are transparent. In the worst scenario you can think of, at least the different redshifts in the lines would allow to distinguish between two overimposed images. A famous example is the galaxy ngc7603. Two foreground objects with redshifts ~0.2 and ~0.4 are seen through the galaxy itself at redshift ~0.03:


 (Image from http://quasars.org/ngc7603.htm)

Another famous example is Q2237+030 (known as ""Huchra Lens"" or ""Einstein Cross""), a background quasar that is seen through the very center of a galaxy. As an additional effect, we see four images of the background quasar, thanks to the bulk mass of the foreground galaxy acting as a lens:



(downloaded from http://www.astr.ua.edu/keel/agn/qso2237.html)

And, finally the image of a star is not a tiny circle, but a diffuse spot, in the ideal case with faint rings (the so called Airy diffraction pattern, impossible to avoid even for the HST) but usually blurred by the atmosphere and spatially extended thorough the CCD plane. That is why it is so difficult to spot Pluto's moon. Not because the angle the objects subtend, but rather due to technical optical limitations (and atmospheric blurring). In some cases, sophisticated deconvolution algorithms have allowed to see additional objects that were embedded in the blurry image of the star. That is how three planets could be seen around HR8977, a star 140 light-years away:

 

(image from http://keckobservatory.org/gallery/detail/milky_way/27)  

The zone of avoidance is only an annoyance if you want to have data from a particular object in a particular wavelength interval, but it is not important for our understanding of the Universe, since at large scales the Universe is homogeneous and isotropic. Consider too that, if we don't restrict to the tiny portion of the spectrum called visible light, the zone of avoidance is not as bad as it seems. I am still amazed by this infrared movie of stars orbiting the central black hole in our galaxy, that was made looking directly through the avoidance zone:

http://www.astro.ucla.edu/~ghezgroup/gc/pictures/orbitsMovie.shtml

A big progress is being made too in gamma and x-rays detectors. It is not completely unrealistic to think that, in the future, there might be neutrino telescopes that achieve the same resolution of today optical instruments (radio astronomy with optical resolution was too a fantasy at the beginning). That would unveil new regions, for instance it would allow us to look directly at the center of the Sun...
"
3584,3584,5725,"Solve for time, given distance and acceleration","Two gangsters are flying down I-70 West at a constant 108 hm/hr. If they make it to Indiana, they will be safe. When they are 1 km away from the Indiana border, while still traveling at a constant 108 km/hr, they pass a concealed police car hidden in a speed trap. At the instant that the criminals pass the patrol car, the cop pulls onto the highway and accelerates at a constant rate of 2 m/s^2. Does the cop catch up with them before they cross the state line?

Here's what I have progressed so far


  ΔV = (ΔX)/(T)
  
  when V is velocity, X is distance, and T is time.
  
  108 = (1 - 0)/T
  
  108T = 1
  
  T = 1/108
  
  T = 0.00925 hours
  
  T = 0.00925 * 60 * 60
  
  T = 33.33 seconds (this is the time it takes the gangsters to get to
  the borders of Indiana)


What I am stuck at is the time it takes the cop to travel the same distance. I have used the distance formula to find time as follows:


  Xf = Xi + 1/2 * A * T^2
  
  where A is acceleration
  
  Since the cop is starting from rest, the initial velocity is 0 (zero),
  so
  
  1 = 0 + 1/2 * (2) * T^2
  
  1 = T^2
  
  T = 1 seconds


So it takes the cop 1 seconds to travel the whole mile to Indiana? What am I doing wrong?
",Brian Lindsey,https://math.stackexchange.com/users/123222,"The acceleration is in meters/second^2 but the distance is 1 kilometer=1000 meters.  The left side should be 1000, not 1.
",Ross Millikan,https://math.stackexchange.com/users/1827,http://math.stackexchange.com/questions/648400/solve-for-time-given-distance-and-acceleration,SCIENCE,math.stackexchange.com,1.0,0.3333333333333333,0.0,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.6666666666666666,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,1.0,0.6666666666666666,0.0,1.0,1.0,"Solution time, given distance and acceleration","Two gangsters are flying down I-70 West at a constant 108 hm/hr. If they make it to Indiana, they will be safe. When they are 1 km away from the Indiana border, while still traveling at a constant 108 km/hr, they pass a concealed police car hidden in a speed trap. At the instant that the criminals pass the patrol car, the cop pulls onto the highway and accelerates at a constant rate of 2 m/s^2. Does the cop catch up with them before they cross the state line?

Here's what I have progressed so far


  ΔV = (ΔX)/(T)
  
  when V is velocity, X is distance, and T is time.
  
  108 = (1 - 0)/T
  
  108T = 1
  
  T = 1/108
  
  T = 0.00925 hours
  
  T = 0.00925 * 60 * 60
  
  T = 33.33 seconds (this is the time it takes the gangsters to get to
  the borders of Indiana)


What I am stuck at is the time it takes the cop to travel the same distance. I have used the distance formula to find time as follows:


  Xf = Xi + 1/2 * A * T^2
  
  where A is acceleration
  
  Since the cop is starting from rest, the initial velocity is 0 (zero),
  so
  
  1 = 0 + 1/2 * (2) * T^2
  
  1 = T^2
  
  T = 1 seconds


So it takes the cop 1 seconds to travel the whole mile to Indiana? What am I doing wrong?
","The acceleration is in meters/second^2 but the distance is 1 kilometer=1000 meters.  The left side should be 1000, not 1.
"
5734,5734,9083,Do you say certificate about or certificate of?,"Do you say certificate about or certificate of? 

""Additional certificate about grading system.""
",Khashayar,https://ell.stackexchange.com/users/11935,"Good question! 

I won't get into the nuance of what that certificate is all about. I'd address the question in the title -do you say certificate 'about' or 'of'.

Though both convey the same meaning, in my opinion, in most of the cases, when you say 'certificate about...' it takes a phrase. I mean to say that there could be some explanation of what that certificate is all about, and not just one word.

For instance a doctor's certificate about the applicant's fitness for the job 

On the other hand, 'certificate of' is short and terse. It directly says what is that certificate with no explanation. 

Say - a certificate of registration/membership/excellence/participation...and so on

But I repeat, both conveys the same meaning and there's no strict rule about what I said. It's just my minute observation. 
",Maulik V,https://ell.stackexchange.com/users/3187,http://ell.stackexchange.com/questions/47034/do-you-say-certificate-about-or-certificate-of,CULTURE,ell.stackexchange.com,1.0,0.8888888888888888,0.0,1.0,1.0,1.0,0.6666666666666666,0.7777777777777778,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.8666666666666666,0.0,0.0,1.0,0.8888888888888888,Are you talking about the certificate or about it?,Are you talking about the certificate or about it?,"Good question! 

I won't get into the nuance of what that certificate is all about. I'd address the question in the title -do you say certificate 'about' or 'of'.

Though both convey the same meaning, in my opinion, in most of the cases, when you say 'certificate about...' it takes a phrase. I mean to say that there could be some explanation of what that certificate is all about, and not just one word.

For instance a doctor's certificate about the applicant's fitness for the job 

On the other hand, 'certificate of' is short and terse. It directly says what is that certificate with no explanation. 

Say - a certificate of registration/membership/excellence/participation...and so on

But I repeat, both conveys the same meaning and there's no strict rule about what I said. It's just my minute observation. 
"
5204,5204,8270,"Why do some programmers categorize C, Python, C++ differently? - regarding level","I am taking an introductory course on python and the instructor says that python is a high level language and C and C++ are low level languages. It's just damn confusing. I thought that C, C++, Python, Java, etc were all high level languages. I was reading questions at stackoverflow on C, C++, etc and they all seem to refer to those languages as high level. it seems to me that some programmers use those terms interchangably. Please clarify this for me.
",atheistlearner,https://programmers.stackexchange.com/users/66433,"Think of this in terms of a sliding scale, from LOW-level languages all the way through to HIGH-level languages. As a language moves up the scale, from LOW to HIGH, the language provides more and more abstraction from the specific interface with the computer.

LOW-level languages are written to explicitly direct the computer - think machine code and assembly code.

HIGH-level languages attempt to abstract away the nitty-gritty details (particularly memory allocation and release of memory). The idea is to provide a more ""natural"" interface to programming and hopefully allow the programmer to focus on design and production.

These days, C is regarded as a LOW-level language. It still has some significant abstractions from machine code and assembly code, so is technically 'higher' than these. However, it does still provide direct memory addressing and not provide garbage collection. So these are details a programmer must design for.

Compare this to other languages such as Python, Ruby or Haskell and you have a much more obscure interface. These languages have large libraries of code that abstract away most of the computer command. Ever wondered what happens to a variable in Python when you leave the local scope of a function, or delete it? Probably haven't right? And that is because in a HIGH-level language you don't have to! They look after the memory allocation / release for you.

HIGH-level languages have the advantage of function. They allow us to design and develop freely (and safely!).

LOW-level languages have the advantage of speed in most cases. There is a cost to interpreting HIGH-level code. Plus, it is kinda cool to write something in 'computer speek'.

Hope this helps
",Nick Burns,https://programmers.stackexchange.com/users/89388,http://programmers.stackexchange.com/questions/196996/why-do-some-programmers-categorize-c-python-c-differently-regarding-level,TECHNOLOGY,programmers.stackexchange.com,1.0,0.7777777777777778,0.0,1.0,0.6666666666666666,0.0,0.7777777777777778,0.7777777777777778,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,1.0,0.7777777777777778,1.0,1.0,0.9333333333333332,0.0,0.0,0.3333333333333333,1.0,"Why do some programmers classify C, Python and C + + differently? -About levels","I'm introducing the introductory course of Python. The lecturer said that Python is a high-level language, and C and C + + are low-level languages. I can't fucking understand. I think C, C + +, python, Java and so on are all high-level languages. I read in C, C + +, and so on. They all seem to call these languages high-level languages. In my opinion, some programmers seem to be able to use these terms in exchange. Please clarify for me.","Think of this in terms of a sliding scale, from LOW-level languages all the way through to HIGH-level languages. As a language moves up the scale, from LOW to HIGH, the language provides more and more abstraction from the specific interface with the computer.

LOW-level languages are written to explicitly direct the computer - think machine code and assembly code.

HIGH-level languages attempt to abstract away the nitty-gritty details (particularly memory allocation and release of memory). The idea is to provide a more ""natural"" interface to programming and hopefully allow the programmer to focus on design and production.

These days, C is regarded as a LOW-level language. It still has some significant abstractions from machine code and assembly code, so is technically 'higher' than these. However, it does still provide direct memory addressing and not provide garbage collection. So these are details a programmer must design for.

Compare this to other languages such as Python, Ruby or Haskell and you have a much more obscure interface. These languages have large libraries of code that abstract away most of the computer command. Ever wondered what happens to a variable in Python when you leave the local scope of a function, or delete it? Probably haven't right? And that is because in a HIGH-level language you don't have to! They look after the memory allocation / release for you.

HIGH-level languages have the advantage of function. They allow us to design and develop freely (and safely!).

LOW-level languages have the advantage of speed in most cases. There is a cost to interpreting HIGH-level code. Plus, it is kinda cool to write something in 'computer speek'.

Hope this helps
"
1520,1520,2390,Idolatry in churches allowed?,"It is very frequent to see idols of Jesus or any biblical entities in  a Church , So is such idolatry allowed by  the bible,considering the following verses?


  ""You must not make for yourself an idol of any kind or an image of anything in the heavens or on the earth or in the sea"".
  Exodus 20:4


History tells us that:


  sometimes objects that God instructed to be made were turned into
  idols by the Israelites. The Book of Numbers contains a narrative in
  which God instructed Moses to make a bronze snake as part of
  addressing a plague of venomous snakes that had broken out among the
  Israelites as a punishment for sin. The bronze snake is mentioned
  again in 2 Kings 18; however, rather than remaining a memorial of
  God's providence, it became an idol that the people named and
  worshiped. Thus the bronze snake was destroyed in King Hezekiah's
  reforms.


More specifically in India I see Christians carry idols of Jesus and other biblical  entities with them kiss them and revere them too. Infact they allow the Hindus in the Church and let them perform worship in their way(Like putting incense sticks, offering flowers , foodstuff to the Idol of Jesus etc) as shown below a very common view in India. I studied in a Christian school for 10 years and i am yet to see Christians not doing these things.

I have seen the same on TV and in videos of people venerating the Idol of biblical entities.


",JesusBoughtIslam,https://christianity.stackexchange.com/users/3812,"The whole iconoclastic controversy has raged for thousands of years. In a nutshell, iconoclasts are taking your position, whereas iconodules maintain the position that what Christians do is venerate not worship these images. Muslims obviously are strict iconoclasts, and thus reject any depiction whatsoever. 

Over the centuries, Christian thought has alternated on what artistic representations are. When Cromwell took Power in the 1650s, for example, they went all Iconoclast and started smashing all the icons they could find, not altogether unlike the rebels in Mali or the Taliban in Afghanistan who blew up the Bamuyan Buddhas. 

The Seventh Ecumenical Council in particular weighed in on this, however, declaring that representations of Christ do not infringe on the person of Christ and are thus not idols. Unlike Hinduism where there is a spectrum  of attitude towards what one is doing with, say, a lingam,  there is official ruling, accepted by ""all"" of the  worlds  Christians (at least  by   Catholics, Protestants and orthodox ) that declares this is veneration and not Latreia.  

St. John of Damascus says:


  Concerning the charge of idolatry: Icons are not idols but symbols, therefore when an Orthodox venerates an icon, he is not guilty of idolatry. He is not worshipping the symbol, but merely venerating it. Such veneration is not directed toward wood, or paint or stone, but towards the person depicted. Therefore relative honor is shown to material objects, but worship is due to God alone.
  
  We do not make obeisance to the nature of wood, but we revere and do obeisance to Him who was crucified on the Cross... When the two beams of the Cross are joined together I adore the figure because of Christ who was crucified on the Cross, but if the beams are separated, I throw them away and burn them.


Does actual practice sometimes get this wrong? Sure. The nature of syncretism is such that in some cultures, practices bleed across beliefs. Offering incense, devotion, and performing  rites that look like idol. Worship is not surprising in a culture where the majority pursues it. Doesn't mean it's orthodox in any event. 

One could look at the perversion of Jihad and say, ""Muslims are  all suicide bombers,  "" too- but many don't because we can distinguish between orthodoxic pronouncement and individual  (mis)practice.  You would do well to consider the same. 
",Affable Geek,https://christianity.stackexchange.com/users/1039,http://christianity.stackexchange.com/questions/14615/idolatry-in-churches-allowed,CULTURE,christianity.stackexchange.com,1.0,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.3333333333333333,0.4444444444444444,0.6666666666666666,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.7777777777777778,1.0,0.8888888888888888,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,1.0,Are idolatry allowed in church?,"It is very frequent to see idols of Jesus or any biblical entities in  a Church , So is such idolatry allowed by  the bible,considering the following verses?


  ""You must not make for yourself an idol of any kind or an image of anything in the heavens or on the earth or in the sea"".
  Exodus 20:4


History tells us that:


  sometimes objects that God instructed to be made were turned into
  idols by the Israelites. The Book of Numbers contains a narrative in
  which God instructed Moses to make a bronze snake as part of
  addressing a plague of venomous snakes that had broken out among the
  Israelites as a punishment for sin. The bronze snake is mentioned
  again in 2 Kings 18; however, rather than remaining a memorial of
  God's providence, it became an idol that the people named and
  worshiped. Thus the bronze snake was destroyed in King Hezekiah's
  reforms.


More specifically in India I see Christians carry idols of Jesus and other biblical  entities with them kiss them and revere them too. Infact they allow the Hindus in the Church and let them perform worship in their way(Like putting incense sticks, offering flowers , foodstuff to the Idol of Jesus etc) as shown below a very common view in India. I studied in a Christian school for 10 years and i am yet to see Christians not doing these things.

I have seen the same on TV and in videos of people venerating the Idol of biblical entities.


","The whole iconoclastic controversy has raged for thousands of years. In a nutshell, iconoclasts are taking your position, whereas iconodules maintain the position that what Christians do is venerate not worship these images. Muslims obviously are strict iconoclasts, and thus reject any depiction whatsoever. 

Over the centuries, Christian thought has alternated on what artistic representations are. When Cromwell took Power in the 1650s, for example, they went all Iconoclast and started smashing all the icons they could find, not altogether unlike the rebels in Mali or the Taliban in Afghanistan who blew up the Bamuyan Buddhas. 

The Seventh Ecumenical Council in particular weighed in on this, however, declaring that representations of Christ do not infringe on the person of Christ and are thus not idols. Unlike Hinduism where there is a spectrum  of attitude towards what one is doing with, say, a lingam,  there is official ruling, accepted by ""all"" of the  worlds  Christians (at least  by   Catholics, Protestants and orthodox ) that declares this is veneration and not Latreia.  

St. John of Damascus says:


  Concerning the charge of idolatry: Icons are not idols but symbols, therefore when an Orthodox venerates an icon, he is not guilty of idolatry. He is not worshipping the symbol, but merely venerating it. Such veneration is not directed toward wood, or paint or stone, but towards the person depicted. Therefore relative honor is shown to material objects, but worship is due to God alone.
  
  We do not make obeisance to the nature of wood, but we revere and do obeisance to Him who was crucified on the Cross... When the two beams of the Cross are joined together I adore the figure because of Christ who was crucified on the Cross, but if the beams are separated, I throw them away and burn them.


Does actual practice sometimes get this wrong? Sure. The nature of syncretism is such that in some cultures, practices bleed across beliefs. Offering incense, devotion, and performing  rites that look like idol. Worship is not surprising in a culture where the majority pursues it. Doesn't mean it's orthodox in any event. 

One could look at the perversion of Jihad and say, ""Muslims are  all suicide bombers,  "" too- but many don't because we can distinguish between orthodoxic pronouncement and individual  (mis)practice.  You would do well to consider the same. 
"
4813,4813,7649,Make *Buffer List* always appear in horizontal split,"I know Emacs tries to be intellectual and opens its helper buffers depending on which dimension of the window is bigger, so it may appear in vertical split window if current width is bigger than height, and in horizontal split otherwise.

But I’d prefer it to open that list always in horizontal split, because there are long paths I can’t see when the buffer is placed in vertical split. How can I do this?
",tijagi,https://stackoverflow.com/users/685107,"I believe you've got the horizontal/vertical split terminology back to front (I can never remember which is which either), but as your goal was to retain the original window's width, I'm forcing a vertical split.

See C-hf split-window-sensibly RET. It tells you what to do:

You can enforce this function to not split WINDOW horizontally,
by setting (or binding) the variable `split-width-threshold' to
nil.  If, in addition, you set `split-height-threshold' to zero,
chances increase that this function does split WINDOW vertically.


So as a permanent setting:

(setq split-width-threshold nil)
(setq split-height-threshold 0)


For just a specific function, you can advise that function (but see Edit 2 below!):

(defadvice list-buffers (around list-buffers-split-vertically)
  ""Always split vertically when displaying the buffer list.
See `split-window-sensibly'.""
  (let ((split-width-threshold nil)
        (split-height-threshold 0))
    ad-do-it))
(ad-activate 'list-buffers)


Edit: Actually, in this instance I suspect you're only concerned with the interactive case, in which case it's preferable to define a function and remap the bindings:

(defun my-list-buffers-vertical-split ()
  ""`list-buffers', but forcing a vertical split.
    See `split-window-sensibly'.""
  (interactive)
  (let ((split-width-threshold nil)
        (split-height-threshold 0))
    (call-interactively 'list-buffers)))

(global-set-key [remap list-buffers] 'my-list-buffers-vertical-split)


Edit 2: And Stefan points out that display-buffer-alist facilitates such things without advising functions (and of course avoiding unnecessary advice is always a good thing). I believe we still need a custom action, so:

(defun my-display-buffer-pop-up-same-width-window (buffer alist)
  ""A `display-buffer' ACTION forcing a vertical window split.
    See `split-window-sensibly' and `display-buffer-pop-up-window'.""
  (let ((split-width-threshold nil)
        (split-height-threshold 0))
    (display-buffer-pop-up-window buffer alist)))

(add-to-list 'display-buffer-alist
             '(""\\*Buffer List\\*"" my-display-buffer-pop-up-same-width-window))

",phils,https://stackoverflow.com/users/324105,http://stackoverflow.com/questions/21542914/make-buffer-list-always-appear-in-horizontal-split,STACKOVERFLOW,stackoverflow.com,1.0,0.6666666666666666,0.0,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.3333333333333333,1.0,0.6666666666666666,1.0,0.8,1.0,0.0,0.0,0.6666666666666666,Make * buffer list * always appear as a horizontal split,"I know that Emacs attempts to be intelligent and opens its secondary buffer based on the size of the window, so if the current width is greater than the height, it may appear in the vertical split window, otherwise it may appear in the horizontal split window.","I believe you've got the horizontal/vertical split terminology back to front (I can never remember which is which either), but as your goal was to retain the original window's width, I'm forcing a vertical split.

See C-hf split-window-sensibly RET. It tells you what to do:

You can enforce this function to not split WINDOW horizontally,
by setting (or binding) the variable `split-width-threshold' to
nil.  If, in addition, you set `split-height-threshold' to zero,
chances increase that this function does split WINDOW vertically.


So as a permanent setting:

(setq split-width-threshold nil)
(setq split-height-threshold 0)


For just a specific function, you can advise that function (but see Edit 2 below!):

(defadvice list-buffers (around list-buffers-split-vertically)
  ""Always split vertically when displaying the buffer list.
See `split-window-sensibly'.""
  (let ((split-width-threshold nil)
        (split-height-threshold 0))
    ad-do-it))
(ad-activate 'list-buffers)


Edit: Actually, in this instance I suspect you're only concerned with the interactive case, in which case it's preferable to define a function and remap the bindings:

(defun my-list-buffers-vertical-split ()
  ""`list-buffers', but forcing a vertical split.
    See `split-window-sensibly'.""
  (interactive)
  (let ((split-width-threshold nil)
        (split-height-threshold 0))
    (call-interactively 'list-buffers)))

(global-set-key [remap list-buffers] 'my-list-buffers-vertical-split)


Edit 2: And Stefan points out that display-buffer-alist facilitates such things without advising functions (and of course avoiding unnecessary advice is always a good thing). I believe we still need a custom action, so:

(defun my-display-buffer-pop-up-same-width-window (buffer alist)
  ""A `display-buffer' ACTION forcing a vertical window split.
    See `split-window-sensibly' and `display-buffer-pop-up-window'.""
  (let ((split-width-threshold nil)
        (split-height-threshold 0))
    (display-buffer-pop-up-window buffer alist)))

(add-to-list 'display-buffer-alist
             '(""\\*Buffer List\\*"" my-display-buffer-pop-up-same-width-window))

"
5535,5535,8791,Can I limit the time a table lock is being held server side?,"I have a SQL Azure server with some stored procedures with TABLOCKX hints that I call from C# code on a Windows Azure web role VM. 

I'm kinda paranoid about those hints - what if there's some network protocol failure and the transaction doesn't end or something like that and a lock is held forever and all invokations of that stored procedure block on the statement with the TABLOCKX hint and all my stuff comes to a halt.

Is it somehow possible to tell SQL Server that the lock should not be held for more than say one minute so that it is unconditionally released after that time?
",sharptooth,https://dba.stackexchange.com/users/7689,"You can explicitly specify using :

SET LOCK_TIMEOUT timeout_period


  timeout_period
  
  Is the number of milliseconds that will pass before Microsoft SQL Server returns a locking error. A value of -1 (default) indicates no time-out period (that is, wait forever).
  When a wait for a lock exceeds the time-out value, an error is returned. A value of 0 means to not wait at all and return a message as soon as a lock is encountered.
  
  At the beginning of a connection, this setting has a value of -1. After it is changed, the new setting stays in effect for the remainder of the connection.
  
  The setting of SET LOCK_TIMEOUT is set at execute or run time and not at parse time.
  
  The READPAST locking hint provides an alternative to this SET option.
  
  CREATE DATABASE, ALTER DATABASE, and DROP DATABASE statements do not honor the SET LOCK_TIMEOUT setting.


Refer to : Support for SET statements in Azure

UPDATE: 


  Is it somehow possible to tell SQL Server that the lock should not be held for more than say one minute so that it is unconditionally released after that time?


No. As I mentioned in the comments section. 

THe database wont be able to maintain its ACID properties.

Either the query fails and returns an error or the lock is held by SQL Server  until the transaction is completed and then released.
",Kin,https://dba.stackexchange.com/users/8783,http://dba.stackexchange.com/questions/54902/can-i-limit-the-time-a-table-lock-is-being-held-server-side,TECHNOLOGY,dba.stackexchange.com,1.0,0.6666666666666666,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.3333333333333333,0.0,0.8888888888888888,1.0,0.7777777777777778,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,0.8888888888888888,Can I limit the time that the server holds the table lock?,"I have a SQL Azure server with some stored procedures with TABLOCKX hints that I call from C# code on a Windows Azure web role VM. 

I'm kinda paranoid about those hints - what if there's some network protocol failure and the transaction doesn't end or something like that and a lock is held forever and all invokations of that stored procedure block on the statement with the TABLOCKX hint and all my stuff comes to a halt.

Is it somehow possible to tell SQL Server that the lock should not be held for more than say one minute so that it is unconditionally released after that time?
","You can explicitly specify using :

SET LOCK_TIMEOUT timeout_period


  timeout_period
  
  Is the number of milliseconds that will pass before Microsoft SQL Server returns a locking error. A value of -1 (default) indicates no time-out period (that is, wait forever).
  When a wait for a lock exceeds the time-out value, an error is returned. A value of 0 means to not wait at all and return a message as soon as a lock is encountered.
  
  At the beginning of a connection, this setting has a value of -1. After it is changed, the new setting stays in effect for the remainder of the connection.
  
  The setting of SET LOCK_TIMEOUT is set at execute or run time and not at parse time.
  
  The READPAST locking hint provides an alternative to this SET option.
  
  CREATE DATABASE, ALTER DATABASE, and DROP DATABASE statements do not honor the SET LOCK_TIMEOUT setting.


Refer to : Support for SET statements in Azure

UPDATE: 


  Is it somehow possible to tell SQL Server that the lock should not be held for more than say one minute so that it is unconditionally released after that time?


No. As I mentioned in the comments section. 

THe database wont be able to maintain its ACID properties.

Either the query fails and returns an error or the lock is held by SQL Server  until the transaction is completed and then released.
"
1444,1444,2274,Is apt-get upgrade a dangerous command?,"When I use apt-get update and apt-get upgrade,there are some packages should installed in newest version,like below:

The following packages will be upgraded:
  accountsservice apparmor apport apt apt-transport-https apt-utils binutils
  cloud-init cpp-4.8 dpkg fuse g++-4.8 gcc-4.8 gcc-4.8-base gdisk gnupg gpgv
  grub-common grub-legacy-ec2 grub-pc grub-pc-bin grub2-common initscripts
  isc-dhcp-client isc-dhcp-common libaccountsservice0 libapparmor-perl
  libapparmor1 libapt-inst1.5 libapt-pkg4.12 libasan0 libatomic1 libbsd0
  libcurl3-gnutls libdrm2 libedit2 libfuse2 libgcc-4.8-dev libgd3 libgomp1
  libitm1 libjson-c2 libjson0 libnuma1 libpam-systemd libpolkit-agent-1-0
  libpolkit-backend-1-0 libpolkit-gobject-1-0 libquadmath0 libstdc++-4.8-dev
  libstdc++6 libsystemd-daemon0 libsystemd-login0 libtsan0 libudev1 libxext6
  linux-libc-dev ntpdate openssl overlayroot patch policykit-1 ppp
  python-urllib3 python3-apport python3-problem-report python3-update-manager
  rsyslog systemd-services sysv-rc sysvinit-utils tcpdump tzdata udev
  update-manager-core
75 upgraded, 0 newly installed, 0 to remove and 4 not upgraded.


If I didn't know every one of there packages what will happen if there update in newest version.I shouldn't execute this command(apt-get upgrade).

For example:

This php version is before I upgrade

yzxu@ubuntu:/tmp/git-2.1.2$ php --version
PHP 5.6.6-1+deb.sury.org~precise+1 (cli) 
Copyright (c) 1997-2015 The PHP Group
Zend Engine v2.6.0, Copyright (c) 1998-2015 Zend Technologies
    with Zend OPcache v7.0.6-dev, Copyright (c) 1999-2015, by Zend Technologies


and after I upgrade:

yzxu@ubuntu:/tmp/git-2.1.2$ php --version
PHP 5.6.10-1+deb.sury.org~precise+1 (cli) 
Copyright (c) 1997-2015 The PHP Group
Zend Engine v2.6.0, Copyright (c) 1998-2015 Zend Technologies
    with Zend OPcache v7.0.6-dev, Copyright (c) 1999-2015, by Zend Technologies


The php version is changed.And if I didn't what what was change in two version,should I upgrade it?Is it will influence product?
",大易归真,https://askubuntu.com/users/422775,"Maybe. But you should regularly update your system. Updates can have risk, yes. This risk also depends on things I do not know such as what PPAs you may or may not have added or other sources. But again in general it's a good idea to keep you system up to date. When you update, you get stability fixes and security updates. So I will say that it is even more dangerous not to update(upgrade) your system.
",gnaservicesinc,https://askubuntu.com/users/422779,http://askubuntu.com/questions/639822/is-apt-get-upgrade-a-dangerous-command/639838,TECHNOLOGY,askubuntu.com,0.7777777777777778,0.4444444444444444,0.0,0.0,0.6666666666666666,0.0,0.6666666666666666,0.8888888888888888,0.3333333333333333,0.0,1.0,0.3333333333333333,0.0,0.6666666666666666,0.0,0.0,0.6666666666666666,0.0,0.3333333333333333,0.0,0.5555555555555556,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.0,1.0,1.0,Is apt get upgrade a dangerous command?,"When I use apt-get update and apt-get upgrade,there are some packages should installed in newest version,like below:

The following packages will be upgraded:
  accountsservice apparmor apport apt apt-transport-https apt-utils binutils
  cloud-init cpp-4.8 dpkg fuse g++-4.8 gcc-4.8 gcc-4.8-base gdisk gnupg gpgv
  grub-common grub-legacy-ec2 grub-pc grub-pc-bin grub2-common initscripts
  isc-dhcp-client isc-dhcp-common libaccountsservice0 libapparmor-perl
  libapparmor1 libapt-inst1.5 libapt-pkg4.12 libasan0 libatomic1 libbsd0
  libcurl3-gnutls libdrm2 libedit2 libfuse2 libgcc-4.8-dev libgd3 libgomp1
  libitm1 libjson-c2 libjson0 libnuma1 libpam-systemd libpolkit-agent-1-0
  libpolkit-backend-1-0 libpolkit-gobject-1-0 libquadmath0 libstdc++-4.8-dev
  libstdc++6 libsystemd-daemon0 libsystemd-login0 libtsan0 libudev1 libxext6
  linux-libc-dev ntpdate openssl overlayroot patch policykit-1 ppp
  python-urllib3 python3-apport python3-problem-report python3-update-manager
  rsyslog systemd-services sysv-rc sysvinit-utils tcpdump tzdata udev
  update-manager-core
75 upgraded, 0 newly installed, 0 to remove and 4 not upgraded.


If I didn't know every one of there packages what will happen if there update in newest version.I shouldn't execute this command(apt-get upgrade).

For example:

This php version is before I upgrade

yzxu@ubuntu:/tmp/git-2.1.2$ php --version
PHP 5.6.6-1+deb.sury.org~precise+1 (cli) 
Copyright (c) 1997-2015 The PHP Group
Zend Engine v2.6.0, Copyright (c) 1998-2015 Zend Technologies
    with Zend OPcache v7.0.6-dev, Copyright (c) 1999-2015, by Zend Technologies


and after I upgrade:

yzxu@ubuntu:/tmp/git-2.1.2$ php --version
PHP 5.6.10-1+deb.sury.org~precise+1 (cli) 
Copyright (c) 1997-2015 The PHP Group
Zend Engine v2.6.0, Copyright (c) 1998-2015 Zend Technologies
    with Zend OPcache v7.0.6-dev, Copyright (c) 1999-2015, by Zend Technologies


The php version is changed.And if I didn't what what was change in two version,should I upgrade it?Is it will influence product?
","Maybe. But you should regularly update your system. Updates can have risk, yes. This risk also depends on things I do not know such as what PPAs you may or may not have added or other sources. But again in general it's a good idea to keep you system up to date. When you update, you get stability fixes and security updates. So I will say that it is even more dangerous not to update(upgrade) your system.
"
4610,4610,7309,Array of Fibonacci values; Value of high index turns array value into negative,"I created an array called numbers that will store values of a Fibonacci sequence. 1, 2, 3, 5, etc. 
The problem is that when I try to call the array value at a very high index value, the array value becomes negative. 

numbers[10] = 144 


which is reasonable but 

numbers[9999998] = -1448735941


Any help?

public static void main(String[] args) {

    int[] numbers = new int[10000000];

    numbers[0] = 1;
    numbers[1] = 2;

    for(int x = 2; x&lt;=numbers.length-1; x++)
    {
        numbers[x] = numbers[x-1] + numbers[x-2];
    }

    System.out.println(numbers[9999998]);
    System.out.println(numbers[10]);

",Rohan,https://stackoverflow.com/users/2475380,"You are experiencing integer overflow. Take a look at BigInteger for one workaround.
",Jeffrey,https://stackoverflow.com/users/758280,http://stackoverflow.com/questions/18223089/array-of-fibonacci-values-value-of-high-index-turns-array-value-into-negative,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.7777777777777778,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.3333333333333333,0.6666666666666666,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,0.7777777777777778,0.7777777777777778,0.4444444444444444,0.7777777777777778,0.8888888888888888,0.6666666666666667,1.0,0.0,1.0,0.7777777777777778,Fibonacci value array; high index values convert array values to negative values,"I created an array called numbers that will store values of a Fibonacci sequence. 1, 2, 3, 5, etc. 
The problem is that when I try to call the array value at a very high index value, the array value becomes negative. 

numbers[10] = 144 


which is reasonable but 

numbers[9999998] = -1448735941


Any help?

public static void main(String[] args) {

    int[] numbers = new int[10000000];

    numbers[0] = 1;
    numbers[1] = 2;

    for(int x = 2; x&lt;=numbers.length-1; x++)
    {
        numbers[x] = numbers[x-1] + numbers[x-2];
    }

    System.out.println(numbers[9999998]);
    System.out.println(numbers[10]);

",You have encountered an integer overflow. Take a look at one of BigInteger's solutions.
3300,3300,5264,Earth-Moon system,"While learning about motion of centre of mass, I came across this statement online, 


  It is also more accurate to say that the Earth and Moon together revolve about their common center of mass. 


I am not able to understand this. Can anyone please explain this statement?
",Saravanan Ramesh,https://physics.stackexchange.com/users/57641,"Suppose the Earth was stationary, and the Moon revolved around the centre of the Earth:



If $v$ is the orbital velocity of the Moon then at point $A$ the linear momentum of the Moon is $mv$. Half an orbit later, at point $B$, the velocity of the Moon is $-v$, because it's in the opposite direction, so the momentum of the Moon is $-mv$.

If the Earth is stationary then its momentum is zero, and that means the total momentum of the Earth Moon system is not conserved, because it's changing from $mv$ to $-mv$ every half an orbit. But if we take the Earth-Moon system as an isolated system then its momentum must be conserved so we have a contradiction. That means the Earth can't be stationary.

Obviously what happens is that the Earth moves as well as the Moon:



At any point in time the momentum of the Earth is equal and opposite to the momentum of the Moon, so the total momentum (in the centre of mass frame) is zero.



And that's why conservation of momentum requires both the Earth and the Moon to revolve around the centre of mass.
",John Rennie,https://physics.stackexchange.com/users/1325,http://physics.stackexchange.com/questions/135108/earth-moon-system,SCIENCE,physics.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,1.0,0.5555555555555556,0.5555555555555556,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,1.0,Earth Moon system,"While learning about motion of centre of mass, I came across this statement online, 


  It is also more accurate to say that the Earth and Moon together revolve about their common center of mass. 


I am not able to understand this. Can anyone please explain this statement?
","Suppose the Earth was stationary, and the Moon revolved around the centre of the Earth:



If $v$ is the orbital velocity of the Moon then at point $A$ the linear momentum of the Moon is $mv$. Half an orbit later, at point $B$, the velocity of the Moon is $-v$, because it's in the opposite direction, so the momentum of the Moon is $-mv$.

If the Earth is stationary then its momentum is zero, and that means the total momentum of the Earth Moon system is not conserved, because it's changing from $mv$ to $-mv$ every half an orbit. But if we take the Earth-Moon system as an isolated system then its momentum must be conserved so we have a contradiction. That means the Earth can't be stationary.

Obviously what happens is that the Earth moves as well as the Moon:



At any point in time the momentum of the Earth is equal and opposite to the momentum of the Moon, so the total momentum (in the centre of mass frame) is zero.



And that's why conservation of momentum requires both the Earth and the Moon to revolve around the centre of mass.
"
334,334,534,How to specify stream/project in ClearCase snapshot view load rules?,"How to specify load rules in this case?

Previously discussed in http://stackoverflow.com/questions/1367635/how-do-i-create-a-snapshot-view-of-some-project-or-stream-in-clearcase 
",JtR,https://stackoverflow.com/users/30958,"When you create a UCM snapshot view, you reference the stream at the creation:

cleartool mkview -snap -tag myView_myStream_snap -stream myStream@\myPVob -stg myStorge myRootDir


Note: ""myView_myStream_snap"" is a convention of mine for naming a UCM snapshot view using the stream ""myStream"". You can actually name that snapshot view with whatever naame you want.

The load rules are only there to specify what to load within a snapshot view whatever the selection rules are (the ""element ..."" rules which are before the load rules)

 load /myVob/dirA
 load /myVob/dirB/dirB1
 load /myVob/dirB/dirB2


There is no notion of stream or projects here.


The stream represents the ""configuration"" (i.e. the list of labels referencing some files)
The load rules represent what you want to load, without making any assumptions on the exact version selected


The combination of the two (the select rules based on the stream + the load rules) enable you to see the actual files within your newly created snapshot view.
",VonC,https://stackoverflow.com/users/6309,http://stackoverflow.com/questions/1367984/how-to-specify-stream-project-in-clearcase-snapshot-view-load-rules,STACKOVERFLOW,stackoverflow.com,0.6666666666666666,1.0,0.0,0.0,1.0,0.0,0.6666666666666666,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,1.0,How do I specify flows / projects in ClearCase snapshot view load rules?,"How to specify load rules in this case?

Previously discussed in http://stackoverflow.com/questions/1367635/how-do-i-create-a-snapshot-view-of-some-project-or-stream-in-clearcase 
","When you create a UCM snapshot view, you reference the stream at the creation:

cleartool mkview -snap -tag myView_myStream_snap -stream myStream@\myPVob -stg myStorge myRootDir


Note: ""myView_myStream_snap"" is a convention of mine for naming a UCM snapshot view using the stream ""myStream"". You can actually name that snapshot view with whatever naame you want.

The load rules are only there to specify what to load within a snapshot view whatever the selection rules are (the ""element ..."" rules which are before the load rules)

 load /myVob/dirA
 load /myVob/dirB/dirB1
 load /myVob/dirB/dirB2


There is no notion of stream or projects here.


The stream represents the ""configuration"" (i.e. the list of labels referencing some files)
The load rules represent what you want to load, without making any assumptions on the exact version selected


The combination of the two (the select rules based on the stream + the load rules) enable you to see the actual files within your newly created snapshot view.
"
3196,3196,5094,Is the Mechromancer's Little Big Trouble tree worthwhile in UVHM (72 level cap)?,"So far, the tree seems rather underwhelming, especially the low-tier skills like Myelin, More Pep, Strength of 5 gorillas, etc.

Evil Enchantress apparently doesn't affect shock, fire and acid direct damage; it only buffs the status effects which is pretty pointless when slagging an enemy does 3X damage.

Shock storm doesn't sound useful as most enemies won't be bunched up enough.

On the other hand, the damage buffs from Wires Don't Talk and Interspersed Outburst look very useful. Make it Sparkle also apparently gives Deathtrap massive additional damage of up to 3X.

Is it worthwhile to spec into this tree just for the end-tier perks?
",Twilight Sparkle,https://gaming.stackexchange.com/users/54882,"With good shock weapons and a Class Mod that boosts Shock damage you can deal insane damage. With a good Zapper class mod and 5 ranks in Wires Don't Talk you're dealing over 50% more damage with Shock, and Electrical Burn means it does a bit of extra damage to Flesh enemies.

The shock boosts also stack very well with Anarchy's effects; I survive quite well with 3 of 4 weapons being shock, due to the elemental damage boost there's rarely a reason to change weapons, especially with teammates about. And shock based badasses are pretty rare compared to fire and corrosive ones. Really the only significant limiting factor to the skill tree is you need at least decent shock weapons to make it work. Personally I use a shock Maliwan sniper rifle, a shock Dahl e-tech SMG (Dahl burst fire is immune to Anarchy's accuracy reduction by the way) and a shock Moxxie's Slow Hand.

Shock storm, One Two Boom and shock and auugh look cool but aren't as useful, and Strength of Five Gorillas isn't either as I usually don't use Death Trap that often (he gets in the way in co op). The entire tree is just there for Wires Don't Talk + Zapper class mod though. Maxing out the whole tree isn't as necessary, though Interspersed Outburst can be quite useful to slag enemies without having to use a slag weapon (no switching weapons is very nice), and Make it Sparkle also makes Deathtrap relatively useful since he can get situationally relevant elements in addition to the 3x straight-up damage boost.
",Ben Brocka,https://gaming.stackexchange.com/users/11920,http://gaming.stackexchange.com/questions/149664/is-the-mechromancers-little-big-trouble-tree-worthwhile-in-uvhm-72-level-cap,CULTURE,gaming.stackexchange.com,1.0,1.0,0.6666666666666666,1.0,0.0,0.3333333333333333,0.4444444444444444,0.3333333333333333,0.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.7777777777777778,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,1.0,Is the machinist's little trouble tree worth it in the uvhm?,"So far, the tree seems rather underwhelming, especially the low-tier skills like Myelin, More Pep, Strength of 5 gorillas, etc.

Evil Enchantress apparently doesn't affect shock, fire and acid direct damage; it only buffs the status effects which is pretty pointless when slagging an enemy does 3X damage.

Shock storm doesn't sound useful as most enemies won't be bunched up enough.

On the other hand, the damage buffs from Wires Don't Talk and Interspersed Outburst look very useful. Make it Sparkle also apparently gives Deathtrap massive additional damage of up to 3X.

Is it worthwhile to spec into this tree just for the end-tier perks?
","With good shock weapons and a Class Mod that boosts Shock damage you can deal insane damage. With a good Zapper class mod and 5 ranks in Wires Don't Talk you're dealing over 50% more damage with Shock, and Electrical Burn means it does a bit of extra damage to Flesh enemies.

The shock boosts also stack very well with Anarchy's effects; I survive quite well with 3 of 4 weapons being shock, due to the elemental damage boost there's rarely a reason to change weapons, especially with teammates about. And shock based badasses are pretty rare compared to fire and corrosive ones. Really the only significant limiting factor to the skill tree is you need at least decent shock weapons to make it work. Personally I use a shock Maliwan sniper rifle, a shock Dahl e-tech SMG (Dahl burst fire is immune to Anarchy's accuracy reduction by the way) and a shock Moxxie's Slow Hand.

Shock storm, One Two Boom and shock and auugh look cool but aren't as useful, and Strength of Five Gorillas isn't either as I usually don't use Death Trap that often (he gets in the way in co op). The entire tree is just there for Wires Don't Talk + Zapper class mod though. Maxing out the whole tree isn't as necessary, though Interspersed Outburst can be quite useful to slag enemies without having to use a slag weapon (no switching weapons is very nice), and Make it Sparkle also makes Deathtrap relatively useful since he can get situationally relevant elements in addition to the 3x straight-up damage boost.
"
4522,4522,7167,NRZ vs. Manchester pulse shaping filter (Modulator),"I'm trying to visualize the differences on the output waveform of a modulator when using NRZ or a Manchester pulse shaping filter. To keep it simple, let's think of a binary PAM signal with an input bit sequence 101011. 

My thoughts are that with a Half Sine or a Raised Cosine pulse shaping filter, I will see the transitions between the 1's and 0's smooth out, but I'm struggling to think about the differences between the NRZ and the Manchester.
",Kyle Weller,https://dsp.stackexchange.com/users/3733,"Manchester coding effectively creates a bit sequence that is twice as long as the given bit sequence and then applies NRZ pulses to the resulting bit stream.
There are two types of Manchester coding. In one form, each $0$ in the original
sequence is replaced by $01$ and each $1$ by $10$ while the other form complements
these bit patterns.  Using the first form, 
$$101011 \to 10\,01\,10\,01\,10\,10$$ while the second form gives the complementary
bit sequence $01\,10\,01\,10\,0101$. If each data bit is of duration $T$, the NRZ
waveform with Half Sine pulses has sines of period $2T$ so that each bit
pulse has duration half a period. Thus, that leading $1$ gets
modulated to $\sin(\pi t/T)$ lasting from $t = 0$ till $t = T$.
With Manchester coding, each channel bit
(of duration $T/2$) gets a Half Sine of a sine of period $T$. Put another 
way, 


with plain NRZ, that first $1$ in your bit sequence will have
pulse $\sin(\pi t/T)$ lasting from $t = 0$ to $t = T$. This is a positive
going pulse rising from $0$ at $t=0$, peaking at $1$ at $t=T/2$, and
falling to $0$ at $t = T$
with Manchester coding, that data $1$ will become channel $10$ giving a positive pulse $\sin(2\pi t/T)$ from $0$ to $T/2$. The next channel bit
$0$ has the delayed half-sine pulse $\sin(2\pi (t-T/2)/T$ from $t=T/2$
to $t = T$, but with a negative amplitude (the channel bit 
during this interval is $0$ instead of a $1$) which
works out to be
$$\begin{align*}
-\sin(2\pi(t-T/2)/T) &amp;= -\sin(2\pi t/T - \pi)\\
&amp;= -\sin(2\pi t/T)\cos(\pi) + \cos(2\pi t/T)\sin(\pi)\\
&amp;= \sin(2\pi t/T)
\end{align*}$$
lasting from $t = T/2$ to $t = T$. In short, during the entire data
bit interval $[0,T]$ the signal can be expressed as $\sin(2\pi t/T)$
and is one cycle of the sine wave of period T. If the data
bit were a $0$ instead of a $1$, the channel bits would be $01$
and we would get $-\sin(2\pi t/T)$ from $t=0$ to $t=T$. In short,
Manchester coding with half-sine pulses
effectively creates a phase-modulated signal
from the data sequence with a carrier frequency of $1/T$ Hz and
each data bit interval contains exactly one period of the sinusoid.
If you look at the figure for Thomas's Manchester coding
in Wikipedia,
what we have is the $\pm$ rectangular pulses comprising each
data bit interval, which look like a hard-limited sinusoid
of period $T$, being replaced by the sinusoid.



  The OP says, ""My thoughts are that with a Half Sine ....  pulse shaping 
  filter, I will see the transitions between the 1's and 0's smooth out,...""
  but this does not happen, there will be abrupt reversals of carrier
  phase at those data bit boundaries where there is a transition
  from $0$ to $1$ or from $1$ to $0$, pretty much as happens
  in plain PSK.

",Dilip Sarwate,https://dsp.stackexchange.com/users/235,http://dsp.stackexchange.com/questions/7806/nrz-vs-manchester-pulse-shaping-filter-modulator,TECHNOLOGY,dsp.stackexchange.com,0.6666666666666666,0.3333333333333333,0.0,0.0,1.0,0.6666666666666666,0.4444444444444444,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,0.6666666666666666,1.0,NRZ and Manchester pulse shaping filter (modulator),"I'm trying to visualize the differences on the output waveform of a modulator when using NRZ or a Manchester pulse shaping filter. To keep it simple, let's think of a binary PAM signal with an input bit sequence 101011. 

My thoughts are that with a Half Sine or a Raised Cosine pulse shaping filter, I will see the transitions between the 1's and 0's smooth out, but I'm struggling to think about the differences between the NRZ and the Manchester.
","Manchester coding effectively creates a bit sequence that is twice as long as the given bit sequence and then applies NRZ pulses to the resulting bit stream.
There are two types of Manchester coding. In one form, each $0$ in the original
sequence is replaced by $01$ and each $1$ by $10$ while the other form complements
these bit patterns.  Using the first form, 
$$101011 \to 10\,01\,10\,01\,10\,10$$ while the second form gives the complementary
bit sequence $01\,10\,01\,10\,0101$. If each data bit is of duration $T$, the NRZ
waveform with Half Sine pulses has sines of period $2T$ so that each bit
pulse has duration half a period. Thus, that leading $1$ gets
modulated to $\sin(\pi t/T)$ lasting from $t = 0$ till $t = T$.
With Manchester coding, each channel bit
(of duration $T/2$) gets a Half Sine of a sine of period $T$. Put another 
way, 


with plain NRZ, that first $1$ in your bit sequence will have
pulse $\sin(\pi t/T)$ lasting from $t = 0$ to $t = T$. This is a positive
going pulse rising from $0$ at $t=0$, peaking at $1$ at $t=T/2$, and
falling to $0$ at $t = T$
with Manchester coding, that data $1$ will become channel $10$ giving a positive pulse $\sin(2\pi t/T)$ from $0$ to $T/2$. The next channel bit
$0$ has the delayed half-sine pulse $\sin(2\pi (t-T/2)/T$ from $t=T/2$
to $t = T$, but with a negative amplitude (the channel bit 
during this interval is $0$ instead of a $1$) which
works out to be
$$\begin{align*}
-\sin(2\pi(t-T/2)/T) &amp;= -\sin(2\pi t/T - \pi)\\
&amp;= -\sin(2\pi t/T)\cos(\pi) + \cos(2\pi t/T)\sin(\pi)\\
&amp;= \sin(2\pi t/T)
\end{align*}$$
lasting from $t = T/2$ to $t = T$. In short, during the entire data
bit interval $[0,T]$ the signal can be expressed as $\sin(2\pi t/T)$
and is one cycle of the sine wave of period T. If the data
bit were a $0$ instead of a $1$, the channel bits would be $01$
and we would get $-\sin(2\pi t/T)$ from $t=0$ to $t=T$. In short,
Manchester coding with half-sine pulses
effectively creates a phase-modulated signal
from the data sequence with a carrier frequency of $1/T$ Hz and
each data bit interval contains exactly one period of the sinusoid.
If you look at the figure for Thomas's Manchester coding
in Wikipedia,
what we have is the $\pm$ rectangular pulses comprising each
data bit interval, which look like a hard-limited sinusoid
of period $T$, being replaced by the sinusoid.



  The OP says, ""My thoughts are that with a Half Sine ....  pulse shaping 
  filter, I will see the transitions between the 1's and 0's smooth out,...""
  but this does not happen, there will be abrupt reversals of carrier
  phase at those data bit boundaries where there is a transition
  from $0$ to $1$ or from $1$ to $0$, pretty much as happens
  in plain PSK.

"
1644,1644,2586,Rate-limiting in transition state theory,"Suppose an initial state $A$ can transition to either state $C$ or state $D$. Suppose further that both of these two processes are rate-limited by a transition to the same intermediate state $B$, as follows:



Note that $\Delta G_{AB}&gt; \Delta G_{BC}&gt;\Delta G_{BD}$.

According to transition state theory, rates are determined by the rate-limiting step. So the rate of each process will be the same,

\begin{align}
r_{A\to C}&amp;=r_{A\to B} \\
r_{A\to D}&amp;=r_{A\to B}
\end{align}

from which it follows that the number of transitions made during some large $\Delta t$ will also be the same,

\begin{align}
N_{A\to C}&amp;=r_{A\to B}\Delta t \\
N_{A\to D}&amp;=r_{A\to B}\Delta t
\end{align}

However, if we were to consider the two pathways collectively then we would predict more transitions to be made to state $D$ than $B$ since $\Delta G_{BD}&lt;\Delta G_{BC}$.

How do we resolve this apparent discrepancy?
",lemon,https://chemistry.stackexchange.com/users/7265,"On remark: just because activation energy high/low it doesn't necessarily mean that reaction is slow or fast. You cannot tell this without the pre-exponential factor. 

The answer: Off course, the original statement should not applied as you do it. 
""According to transition state theory, rates are determined by the rate-limiting step."" doesn't mean automatically that all the reaction rates are equal.

A to B conversion is slow compared to other processes, is true, but still B to C and B to D are competing processes. The original statement only means that B will not build up in bigger quantities, so during the reaction all the final products (C and D together) are approximately equal with the used A after you consider stoichimetries.

Edited for clarification (sorry, pretty new to LaTex):

You should consider all the transformations as independent equations. Black magic is not involved, ""rate determining step"" and such only helps making approximations so one can solve the coupled differential equations on napkin.

Example 1. 

Let us assume a reaction system with $A \to B \to C$. The kinetics of the system can be describe by two independent equations

$A \to B$ with a corresponding $k1$ and  $B \to C$ with a corresponding $k2$

To describe conversions we can get different equations:

$$ \frac{d[A]}{dt} = -k1 [A] $$ 

$$ \frac{d[B]}{dt} = k1 [A] - k2 [B]$$ 

$$ \frac{d[C]}{dt} = k2 [B] $$ 

We see that it is already pretty messy, so assumptions like $k1 &lt;&lt; k2$ can help. The general way is that we say, this difference in the rate constants allows us to asume  $$ \frac{d[B]}{dt} \approx 0 $$. So we have  pipeline, and in first approximation have that much $B \to C$ conversion going as $A \to B$. I.e. the is no ""clogging"" in the middle. Not much magic here.

Example 2.

Now what if we have e.g. two slow reactions as second step instead of one? Noting special:
$A\to B$ , with $k1$,
$B\to C$ , with $k2$,
$B\to D$ , with $k3$ 
which translates to 

$$ \frac{d[A]}{dt} = -k1 [A] $$ 

$$ \frac{d[B]}{dt} = k1 [A] -( k2 [B] + k3 [B])$$ 

$$ \frac{d[C]}{dt} = k2 [B] $$ 

$$ \frac{d[D]}{dt} = k3 [B] $$ 

Now we have the same assumption that the first step is much slower than the others than 

$$ \frac{d[B]}{dt} = k1 [A] -( k2 [B] + k3 [B]) \approx 0$$

I think you can try it from here and see how the rates comes out.
",Greg,https://chemistry.stackexchange.com/users/5172,http://chemistry.stackexchange.com/questions/14815/rate-limiting-in-transition-state-theory,SCIENCE,chemistry.stackexchange.com,0.5555555555555556,0.4444444444444444,0.0,0.5,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.0,1.0,0.8333333333333334,0.6666666666666666,1.0,1.0,0.8,0.3333333333333333,0.3333333333333333,1.0,0.7777777777777778,Rate limitation in transition state theory,"Suppose an initial state $A$ can transition to either state $C$ or state $D$. Suppose further that both of these two processes are rate-limited by a transition to the same intermediate state $B$, as follows:



Note that $\Delta G_{AB}&gt; \Delta G_{BC}&gt;\Delta G_{BD}$.

According to transition state theory, rates are determined by the rate-limiting step. So the rate of each process will be the same,

\begin{align}
r_{A\to C}&amp;=r_{A\to B} \\
r_{A\to D}&amp;=r_{A\to B}
\end{align}

from which it follows that the number of transitions made during some large $\Delta t$ will also be the same,

\begin{align}
N_{A\to C}&amp;=r_{A\to B}\Delta t \\
N_{A\to D}&amp;=r_{A\to B}\Delta t
\end{align}

However, if we were to consider the two pathways collectively then we would predict more transitions to be made to state $D$ than $B$ since $\Delta G_{BD}&lt;\Delta G_{BC}$.

How do we resolve this apparent discrepancy?
","On remark: just because activation energy high/low it doesn't necessarily mean that reaction is slow or fast. You cannot tell this without the pre-exponential factor. 

The answer: Off course, the original statement should not applied as you do it. 
""According to transition state theory, rates are determined by the rate-limiting step."" doesn't mean automatically that all the reaction rates are equal.

A to B conversion is slow compared to other processes, is true, but still B to C and B to D are competing processes. The original statement only means that B will not build up in bigger quantities, so during the reaction all the final products (C and D together) are approximately equal with the used A after you consider stoichimetries.

Edited for clarification (sorry, pretty new to LaTex):

You should consider all the transformations as independent equations. Black magic is not involved, ""rate determining step"" and such only helps making approximations so one can solve the coupled differential equations on napkin.

Example 1. 

Let us assume a reaction system with $A \to B \to C$. The kinetics of the system can be describe by two independent equations

$A \to B$ with a corresponding $k1$ and  $B \to C$ with a corresponding $k2$

To describe conversions we can get different equations:

$$ \frac{d[A]}{dt} = -k1 [A] $$ 

$$ \frac{d[B]}{dt} = k1 [A] - k2 [B]$$ 

$$ \frac{d[C]}{dt} = k2 [B] $$ 

We see that it is already pretty messy, so assumptions like $k1 &lt;&lt; k2$ can help. The general way is that we say, this difference in the rate constants allows us to asume  $$ \frac{d[B]}{dt} \approx 0 $$. So we have  pipeline, and in first approximation have that much $B \to C$ conversion going as $A \to B$. I.e. the is no ""clogging"" in the middle. Not much magic here.

Example 2.

Now what if we have e.g. two slow reactions as second step instead of one? Noting special:
$A\to B$ , with $k1$,
$B\to C$ , with $k2$,
$B\to D$ , with $k3$ 
which translates to 

$$ \frac{d[A]}{dt} = -k1 [A] $$ 

$$ \frac{d[B]}{dt} = k1 [A] -( k2 [B] + k3 [B])$$ 

$$ \frac{d[C]}{dt} = k2 [B] $$ 

$$ \frac{d[D]}{dt} = k3 [B] $$ 

Now we have the same assumption that the first step is much slower than the others than 

$$ \frac{d[B]}{dt} = k1 [A] -( k2 [B] + k3 [B]) \approx 0$$

I think you can try it from here and see how the rates comes out.
"
2070,2070,3299,"How do indirect, session-specific resource tokens increase security?","The OWASP web site recommends this:


Use per user or session indirect object references. This prevents attackers from directly targeting unauthorized resources. For example, instead of using the resource’s database key, a drop down list of six resources authorized for the current user could use the numbers 1 to 6 to indicate which value the user selected. [italics mine]
Check access. Each use of a direct object reference from an untrusted source must include an access control check to ensure the user is authorized for the requested object. [italics mine]


So if a user doesn't have access to the requested resource, how does obfuscating the direct object reference improve security?

Given the increased complexity that, say, an ASP.NET MVC site would accrue, is this worth the additional trouble for anything but banking sites?
",Robert Harvey,https://security.stackexchange.com/users/2709,"I will explain this by giving an example:

Suggest you have a list of objects in your database named:


Pear
Apple
Orange


You have a query which fills up a hash table stored in your session which maps the fruits you are authorized to have to a number:


1 => Pear
2 => Apple


You do not have access  to Orange. You then have a function which allows you to add fruits to a basket, so you choose a number 1 or 2 (this is the indirect object reference). Orange is not accessible in this session as it's not present in the hashtable (there is no number 3). With direct object reference you would have a function which just uses Apple, Pear, Orange rather than a number. So you could abuse the function (if no access controls are used) to add the Orange to your basket as well.

I personally do not see issues with direct object reference IF adequate access controls are in place. These access controls should be tested extensively. There might be more critical applications than others where this might be required, but imagine applications where there are thousands of users with each 100 or 1.000 options unique to them. Storing all of these in a session could have a significant impact on performance (considering the server will need to store this information for each client on the webserver).  

Now to answer your first question: simply because it won't be loaded into the session. As in my hashtable example you simply won't have orange available.
",Lucas Kauffman,https://security.stackexchange.com/users/3339,http://security.stackexchange.com/questions/38777/how-do-indirect-session-specific-resource-tokens-increase-security,TECHNOLOGY,security.stackexchange.com,1.0,0.7777777777777778,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.6666666666666666,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.0,1.0,0.8888888888888888,"How can indirect, session specific resource tokens improve security?","The OWASP web site recommends this:


Use per user or session indirect object references. This prevents attackers from directly targeting unauthorized resources. For example, instead of using the resource’s database key, a drop down list of six resources authorized for the current user could use the numbers 1 to 6 to indicate which value the user selected. [italics mine]
Check access. Each use of a direct object reference from an untrusted source must include an access control check to ensure the user is authorized for the requested object. [italics mine]


So if a user doesn't have access to the requested resource, how does obfuscating the direct object reference improve security?

Given the increased complexity that, say, an ASP.NET MVC site would accrue, is this worth the additional trouble for anything but banking sites?
","I will explain this by giving an example:

Suggest you have a list of objects in your database named:


Pear
Apple
Orange


You have a query which fills up a hash table stored in your session which maps the fruits you are authorized to have to a number:


1 => Pear
2 => Apple


You do not have access  to Orange. You then have a function which allows you to add fruits to a basket, so you choose a number 1 or 2 (this is the indirect object reference). Orange is not accessible in this session as it's not present in the hashtable (there is no number 3). With direct object reference you would have a function which just uses Apple, Pear, Orange rather than a number. So you could abuse the function (if no access controls are used) to add the Orange to your basket as well.

I personally do not see issues with direct object reference IF adequate access controls are in place. These access controls should be tested extensively. There might be more critical applications than others where this might be required, but imagine applications where there are thousands of users with each 100 or 1.000 options unique to them. Storing all of these in a session could have a significant impact on performance (considering the server will need to store this information for each client on the webserver).  

Now to answer your first question: simply because it won't be loaded into the session. As in my hashtable example you simply won't have orange available.
"
1434,1434,2255,How to proceed when you are coordinating a project among several research groups and they do not contribute to the progress of the project,"I am principal investigator in some project that involves other research groups from other countries. When I was writing the proposal, I asked them if they would like to joint the project, and they agreed. I wrote everything, all paperwork, etc. Now, 6 months after the project has been officially started, they are not contributing in any way to the project, only attending project meetings where they talk about their universities, but nothing about the project. I am really annoyed because the situation. From my point of view they should get involved, as my group does. Before asking them directly for the last time in probably in an unpolite way if they will do their assigned part, how would you proceed here?
",flow,https://academia.stackexchange.com/users/284,"The path to proceed likely depends strongly on four factors:


Does the project have clear and specific milestones in the contract that the collaborators are failing to meet?
Are the others subcontractors to your institution or independently contracted?
What type of oversight is being exerted by the funding agency, and how is the relationship with the responsible program manager?
Are you willing to burn a bridge?


Typically, as lead PI you are responsible for the execution of the entire project, not just your portion, and therefore have a responsibility to your funding agency to appropriately manage your subcontracting collaborators.  If the funding agency has instead decided to execute independent contracts to each of the PIs in the grant, then it is largely out of your hands and there is little that you can (or should) do.

Assuming you are lead PI, then if the contract (not the proposal) has requirements in its statement of work that they are not meeting by the given milestone deadlines, then you have much more leverage and a clear case for a ""shape up or get defunded"" conversation.  Similarly, if the funding agency is exerting strong oversight (e.g., in the USA, DARPA often threatens de-funding unless you meet strong milestones by particular frequent deadlines or regularly outperform other research teams; NSF has a much looser oversight process that often just wants to see that something interesting is being accomplished) then you have a strong case that their failure to perform is directly imperiling the whole research project.  In either case, as lead PI you have both the right and the responsibility to cancel their funding and redirect it to better accomplish the research tasks that you are being held accountable for.  

If the contract doesn't have accountable goals and you aren't being held accountable for their behavior, however, then it is more just a moral offense to you, and you have much less basis on which to legitimately defund your colleagues.  Instead, you might look at it as a lesson for the future on writing more specific contracts that can give you the leverage you need to deal with non-performers.

Now if you do defund your colleagues, this has a high likelihood of burning bridges.  If you didn't trust them to shape up, why would you want to work with them again?  If they feel you defunded them unfairly, why would they want to work with you again?
If the mandate comes from the funding agency program manager rather than you, that may make the defunding somewhat more acceptable by making it ""not your fault,"" but your colleagues may still see it that way.  Thus, if the relationship is more important than the money being lost, you may then want to just write this off as a lesson learned and plan more carefully for the future.

In short: there are no easy paths, but which one to walk depends on the balance of relationship value vs. accountability in your contract with your funder and your colleagues.
",jakebeal,https://academia.stackexchange.com/users/22733,http://academia.stackexchange.com/questions/47516/how-to-proceed-when-you-are-coordinating-a-project-among-several-research-groups,LIFE_ARTS,academia.stackexchange.com,1.0,0.8888888888888888,0.0,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.5555555555555556,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,1.0,0.0,0.0,0.8888888888888888,1.0,0.8888888888888888,1.0,1.0,0.9333333333333332,0.3333333333333333,0.3333333333333333,0.6666666666666666,1.0,How to proceed when you coordinate a project in several research groups and they do not contribute to the progress of the project,"I am the lead researcher of some projects involving other research groups in other countries. When I wrote the proposal, I asked them if they would like to participate in the project, and they all agreed. I wrote everything, all paperwork, etc. Now, six months after the project officially started, they didn't contribute in any way to the project, just attended the project meeting, where they talked about their university, but not about the project. I'm really angry because of the situation. In my opinion, they should be as involved as my team. What would you do before asking them directly for the last time if they would do the assigned work?","The path to proceed likely depends strongly on four factors:


Does the project have clear and specific milestones in the contract that the collaborators are failing to meet?
Are the others subcontractors to your institution or independently contracted?
What type of oversight is being exerted by the funding agency, and how is the relationship with the responsible program manager?
Are you willing to burn a bridge?


Typically, as lead PI you are responsible for the execution of the entire project, not just your portion, and therefore have a responsibility to your funding agency to appropriately manage your subcontracting collaborators.  If the funding agency has instead decided to execute independent contracts to each of the PIs in the grant, then it is largely out of your hands and there is little that you can (or should) do.

Assuming you are lead PI, then if the contract (not the proposal) has requirements in its statement of work that they are not meeting by the given milestone deadlines, then you have much more leverage and a clear case for a ""shape up or get defunded"" conversation.  Similarly, if the funding agency is exerting strong oversight (e.g., in the USA, DARPA often threatens de-funding unless you meet strong milestones by particular frequent deadlines or regularly outperform other research teams; NSF has a much looser oversight process that often just wants to see that something interesting is being accomplished) then you have a strong case that their failure to perform is directly imperiling the whole research project.  In either case, as lead PI you have both the right and the responsibility to cancel their funding and redirect it to better accomplish the research tasks that you are being held accountable for.  

If the contract doesn't have accountable goals and you aren't being held accountable for their behavior, however, then it is more just a moral offense to you, and you have much less basis on which to legitimately defund your colleagues.  Instead, you might look at it as a lesson for the future on writing more specific contracts that can give you the leverage you need to deal with non-performers.

Now if you do defund your colleagues, this has a high likelihood of burning bridges.  If you didn't trust them to shape up, why would you want to work with them again?  If they feel you defunded them unfairly, why would they want to work with you again?
If the mandate comes from the funding agency program manager rather than you, that may make the defunding somewhat more acceptable by making it ""not your fault,"" but your colleagues may still see it that way.  Thus, if the relationship is more important than the money being lost, you may then want to just write this off as a lesson learned and plan more carefully for the future.

In short: there are no easy paths, but which one to walk depends on the balance of relationship value vs. accountability in your contract with your funder and your colleagues.
"
999,999,1577,Identify my Motobécane racing bike,"I bought a Motobécane last year (pics below), and now that the bottom bracket is broken, I really need to know the model of the bike, to help me change that piece.

It would also be helpful if someone could redirect me to the Motobécane catalogs of the years 82, 83, I can't find them, and I suspect my bike is from this period.

Technical specifications:


frame color: green and black (How customizable was that? I think they didn't sell the same colors each year)
frame: tubing inexternal 707, ""trainer"" (I don't find the appropriate info about it)
brakes: Weinmann
derailleur: Sachs - Huret. 12 gears
Wheel: Maillard
Bottom Crank: ?? width of the shell: 74mm. From this page http://sheldonbrown.com/vrbn-g-n.html, the old french ones have special dimensions. Also on Motobécane, they are swiss type (left-threaded). I don't know if this is a cotterless one, shimano octalink, or if I can put something more standard?


[EDIT: As suggested by @Blam, I took the bottom bracket out.
First mistake: shell width doesn't correspond to the red line on the pic, but less, so width should be 68mm, I'll double check on the bike.
The Brand is Stronglight, french brand, but the threading is the normal one (left-threaded on the right side, and right-threaded on the left side).
The axle is 120mm long, tapered square. Like this model: http://www.ebay.com/itm/VP-Components-Bottom-Bracket-120mm-Square-Taper-Unsealed-Bike-NEW-/311359596201?pt=LH_DefaultDomain_0&amp;hash=item487e7a66a9

But anyway, I'm still interested in knowing the model of this bike, and/or finding the Motobécane catalogues of years 1982-83]

Important Note: The rear wheel is not the original (was broken). I also changed the part of the crank where I put the feet when I bought it (maybe I shouldn't have...). 

Sorry if it looks quite dirty, I didn't have time to clean.

Pics:











",PlasmaBinturong,https://bicycles.stackexchange.com/users/19414,"Here's a partial answer (how to deal with the bottom bracket, not what bike it is):

The easiest solution (and likely best) is to buy the universal bottom bracket from Velo Orange (or similar). These basically expand to fit in, and don't affect or use the threads so they'll work on most standard BB road bike frames. It will be JIS (square taper). There is some more information at this link. 

I wouldn't bother trying non-square taper -- you're likely not to find a way to fit anything else in. If you want to match the original threading, you'll likely have to buy from Phil Wood or Velo Orange and end up with a square taper anyway. Phil Wood will cost a lot of money, but Velo Orange will be around 40-50 bucks for the right threading (and around 70 for the universal). 

Then, just buy your favorite square taper crankset (there are still a lot of good ones on the market) and go to town.
",Batman,https://bicycles.stackexchange.com/users/8219,http://bicycles.stackexchange.com/questions/30473/identify-my-motob%C3%A9cane-racing-bike,CULTURE,bicycles.stackexchange.com,1.0,0.3333333333333333,0.0,1.0,0.3333333333333333,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.0,0.0,0.5555555555555556,0.6666666666666666,0.3333333333333333,1.0,1.0,1.0,0.3333333333333333,0.6666666666666666,0.0,1.0,Identify my motorcycle,"I bought a Motobécane last year (pics below), and now that the bottom bracket is broken, I really need to know the model of the bike, to help me change that piece.

It would also be helpful if someone could redirect me to the Motobécane catalogs of the years 82, 83, I can't find them, and I suspect my bike is from this period.

Technical specifications:


frame color: green and black (How customizable was that? I think they didn't sell the same colors each year)
frame: tubing inexternal 707, ""trainer"" (I don't find the appropriate info about it)
brakes: Weinmann
derailleur: Sachs - Huret. 12 gears
Wheel: Maillard
Bottom Crank: ?? width of the shell: 74mm. From this page http://sheldonbrown.com/vrbn-g-n.html, the old french ones have special dimensions. Also on Motobécane, they are swiss type (left-threaded). I don't know if this is a cotterless one, shimano octalink, or if I can put something more standard?


[EDIT: As suggested by @Blam, I took the bottom bracket out.
First mistake: shell width doesn't correspond to the red line on the pic, but less, so width should be 68mm, I'll double check on the bike.
The Brand is Stronglight, french brand, but the threading is the normal one (left-threaded on the right side, and right-threaded on the left side).
The axle is 120mm long, tapered square. Like this model: http://www.ebay.com/itm/VP-Components-Bottom-Bracket-120mm-Square-Taper-Unsealed-Bike-NEW-/311359596201?pt=LH_DefaultDomain_0&amp;hash=item487e7a66a9

But anyway, I'm still interested in knowing the model of this bike, and/or finding the Motobécane catalogues of years 1982-83]

Important Note: The rear wheel is not the original (was broken). I also changed the part of the crank where I put the feet when I bought it (maybe I shouldn't have...). 

Sorry if it looks quite dirty, I didn't have time to clean.

Pics:











","Here's a partial answer (how to deal with the bottom bracket, not what bike it is):

The easiest solution (and likely best) is to buy the universal bottom bracket from Velo Orange (or similar). These basically expand to fit in, and don't affect or use the threads so they'll work on most standard BB road bike frames. It will be JIS (square taper). There is some more information at this link. 

I wouldn't bother trying non-square taper -- you're likely not to find a way to fit anything else in. If you want to match the original threading, you'll likely have to buy from Phil Wood or Velo Orange and end up with a square taper anyway. Phil Wood will cost a lot of money, but Velo Orange will be around 40-50 bucks for the right threading (and around 70 for the universal). 

Then, just buy your favorite square taper crankset (there are still a lot of good ones on the market) and go to town.
"
3675,3675,5859,Why a Transistor is considered to be an active device?,"How it a Transistor an active device? Because it it not producing energy. We just feed it with energy and it amplifies it and that too not on his own but using a bias battery. So how it is considered to be an active device? Please can anyone provide full explanation?
",radiantshaw,https://electronics.stackexchange.com/users/34847,"That does not matter if it uses biasing to amplify input or not, the main thing here is that i can amplify the input.

see you cannot carry such operation with resister or inductors 
",user2175309,https://electronics.stackexchange.com/users/36358,http://electronics.stackexchange.com/questions/98151/why-a-transistor-is-considered-to-be-an-active-device,TECHNOLOGY,electronics.stackexchange.com,0.8888888888888888,0.8888888888888888,0.0,0.5,1.0,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.7777777777777778,0.8333333333333334,0.4444444444444444,0.8333333333333334,0.6666666666666666,0.6,0.0,0.0,1.0,0.5555555555555556,Why are transistors considered active devices?,"How do transistors become active devices? Because it doesn't produce energy. We just give it energy, it enlarges it, not by itself, but by using a bias battery. So how is it considered an active device? Can anyone provide a complete explanation?","That does not matter if it uses biasing to amplify input or not, the main thing here is that i can amplify the input.

see you cannot carry such operation with resister or inductors 
"
590,590,918,Energy vs. Power,"Is there a rule in English regarding when to use the word ""energy"" and when to use ""power""?

For example:


  
  I don't have the energy to deal with the problem now.
  It takes a lot of brain power to understand the problem.
  

",Steven,https://english.stackexchange.com/users/118888,"Energy is expendable. Power is inherent.

If you say you don't have the power to do something, it usually implies you don't have the inherent ability (or authority) to do that.


  
  I don't have the power to lift this.
  I don't have the power to suspend you.
  


If you say you don't have the energy to do something, it implies you can't do it currently, but you may have in the past and/or you can in the future.


  
  I don't have the energy to walk another mile (but I have the power, and can walk after I've rested for a bit)
  I don't have the energy to argue with you (I'm able to, but I'm not feeling up to it)
  


Basically, no energy means you're temporarily not able. No power is more permanent.
",Tushar Raj,https://english.stackexchange.com/users/77339,http://english.stackexchange.com/questions/242359/energy-vs-power,CULTURE,english.stackexchange.com,1.0,0.4444444444444444,0.0,1.0,1.0,1.0,0.6666666666666666,0.7777777777777778,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.3333333333333333,1.0,0.8888888888888888,Energy and power,"Is there a rule in English regarding when to use the word ""energy"" and when to use ""power""?

For example:


  
  I don't have the energy to deal with the problem now.
  It takes a lot of brain power to understand the problem.
  

","Energy is expendable. Power is inherent.

If you say you don't have the power to do something, it usually implies you don't have the inherent ability (or authority) to do that.


  
  I don't have the power to lift this.
  I don't have the power to suspend you.
  


If you say you don't have the energy to do something, it implies you can't do it currently, but you may have in the past and/or you can in the future.


  
  I don't have the energy to walk another mile (but I have the power, and can walk after I've rested for a bit)
  I don't have the energy to argue with you (I'm able to, but I'm not feeling up to it)
  


Basically, no energy means you're temporarily not able. No power is more permanent.
"
5868,5868,9290,Can grep return true/false or are there alternative methods,"I'm trying to write this script for an assignment - it's only the second one I've written so bear with me. 

As a part of this script, I need to be able to check if the first argument given matches the first word of file. If it does, exit with an error message, if it doesn't, append the arguments to the file. I understand how to write the if statement, but not how to use grep within a script. I understand that grep will look something like this

grep ^$1 schemas.txt

I feel like this should be much easier than I am making it. Any help appreciated. 

Update:
I'm getting an error too many arguments on the if statement. I got rid of the space between grep-q and then got an error binary operator expected. I've been poking around at it, but I don't see what it sees.

if [ grep -q ^$1 schemas.txt ]
then
        echo ""Schema already exists. Please try again""
        exit 1
else
        echo ""$@"" &gt;&gt; schemas.txt
fi

",Lauren,https://unix.stackexchange.com/users/23551,"grep returns a different exit code if its found something (zero) vs. if it hasn't found something (non-zero). In an if statement, a zero exit code is mapped to ""true"" and a non-zero exit code is mapped to false. In addition, grep has a -q argument to not output the matched text (but only return the exit status code)

So, you can use grep like this:

if grep -q PATTERN file.txt; then
    echo found
else
    echo not found
fi


As a quick note, when you do something like if [ -z ""$var"" ]…, it turns out that [ is actually a command you're running, just like grep. On my system, it's /usr/bin/[. (Well, technically, your shell probably has it built-in, but that's an optimization. It behaves as if it were a command). It works the same way, [ returns a zero exit code for true, a non-zero exit code for false. (test is the same thing as [, except for the closing ])
",derobert,https://unix.stackexchange.com/users/977,http://unix.stackexchange.com/questions/48535/can-grep-return-true-false-or-are-there-alternative-methods,TECHNOLOGY,unix.stackexchange.com,0.8888888888888888,0.6666666666666666,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.6666666666666666,0.0,1.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.3333333333333333,0.3333333333333333,0.6666666666666666,1.0,"Whether grep can return true / false, or whether there are other methods","I'm trying to write this script for an assignment - it's only the second one I've written so bear with me. 

As a part of this script, I need to be able to check if the first argument given matches the first word of file. If it does, exit with an error message, if it doesn't, append the arguments to the file. I understand how to write the if statement, but not how to use grep within a script. I understand that grep will look something like this

grep ^$1 schemas.txt

I feel like this should be much easier than I am making it. Any help appreciated. 

Update:
I'm getting an error too many arguments on the if statement. I got rid of the space between grep-q and then got an error binary operator expected. I've been poking around at it, but I don't see what it sees.

if [ grep -q ^$1 schemas.txt ]
then
        echo ""Schema already exists. Please try again""
        exit 1
else
        echo ""$@"" &gt;&gt; schemas.txt
fi

","grep returns a different exit code if its found something (zero) vs. if it hasn't found something (non-zero). In an if statement, a zero exit code is mapped to ""true"" and a non-zero exit code is mapped to false. In addition, grep has a -q argument to not output the matched text (but only return the exit status code)

So, you can use grep like this:

if grep -q PATTERN file.txt; then
    echo found
else
    echo not found
fi


As a quick note, when you do something like if [ -z ""$var"" ]…, it turns out that [ is actually a command you're running, just like grep. On my system, it's /usr/bin/[. (Well, technically, your shell probably has it built-in, but that's an optimization. It behaves as if it were a command). It works the same way, [ returns a zero exit code for true, a non-zero exit code for false. (test is the same thing as [, except for the closing ])
"
4756,4756,7548,Several attempts at cranking required to start car,"Every time I get in and turn the key nothing happens. After turning the key a number of times, it will start up as normal. I have had a new battery, and new wiring to the starter motor installed, and also gotten a new key. Still the same thing is happening. My car is a 2006 Kia Sedona diesel.
",colin,https://mechanics.stackexchange.com/users/4159,"If the engine does not turn over on the first few times of turning the key, then in the light of what you have already had done, the switch on the bottom of your ignition key barrel may be at fault, or you starter motor solonoid sticking. If the engine turns over but does not start, and you have let the glow plug warning light go out, then an ECU relay defect may be your answer.
",Allan Osborne,https://mechanics.stackexchange.com/users/3975,http://mechanics.stackexchange.com/questions/8029/several-attempts-at-cranking-required-to-start-car,CULTURE,mechanics.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.6666666666666666,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.6666666666666666,0.0,1.0,0.8888888888888888,Try to turn the crank several times to start the car,"Every time I go in and turn on the key, nothing happens. After turning the key several times, it will start normally. I've got a new battery, new starter wiring and a new key. The same thing is happening. My car is a 2006 Kia Sedona diesel engine.","If the engine does not turn when you turn the key for the first few times, the switch at the bottom of the ignition key cylinder may be faulty, or your starting motor solonoid may be stuck, depending on what you have done. If the engine flips but does not start and you have let the glow plug warning light go out, your answer may be that the ECU relay is faulty."
3726,3726,5939,rsync partial LVM volume to Remote Directory,"Can I rsync a full hdd partition (which is inaccessible) to a remote directory?

Inaccessible means it cannot be mounted, it was part of LV volume merged with other HDD which is faulty and removed from the server. I tried to mount it but not working unknown filesystem type 'LVM2_member' so I'm using rsync to mount it on remote desktop. Advise me what's the best solution?

rsync -avz /dev/sda1 user@ip:/backup/


I want to copy all files and directories of /dev/sda1 to remote device at the directory backup.
",Zaher,https://unix.stackexchange.com/users/116021,"You can do 

dd if=/dev/sda of=back.sda bs=10M 


You can increase or reduce the bs(block size) based on your i/o capacity(fast increase,slow decrease),then copy the back.sda with scp or rsync on backup.
Later you can mount the image and recovery the files,this will work if sda is not broken disk,if is corrupted you can try a fsck.
Rsync works for files,i have never tried on block device but i think rsync sda copy only the sda block file(size 0) on remote backup
If the problem is unavaliable partition, you will resolve nothing with rsync,you must use kpartx,search google for kpartx lvm
Or try this

pvscan
vgscan
vgchange -ay


See the output and mount the volume
",elbarna,https://unix.stackexchange.com/users/80389,http://unix.stackexchange.com/questions/205093/rsync-partial-lvm-volume-to-remote-directory,TECHNOLOGY,unix.stackexchange.com,1.0,0.5,0.0,0.5,1.0,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.5,0.5,0.0,0.0,0.0,0.0,0.5,0.5,0.0,0.0,0.8333333333333334,1.0,0.6666666666666666,1.0,0.8888888888888888,0.8,1.0,0.3333333333333333,0.3333333333333333,0.6666666666666666,Rsync part LVM volume to remote directory,"Can I rsync a full hdd partition (which is inaccessible) to a remote directory?

Inaccessible means it cannot be mounted, it was part of LV volume merged with other HDD which is faulty and removed from the server. I tried to mount it but not working unknown filesystem type 'LVM2_member' so I'm using rsync to mount it on remote desktop. Advise me what's the best solution?

rsync -avz /dev/sda1 user@ip:/backup/


I want to copy all files and directories of /dev/sda1 to remote device at the directory backup.
","You can do 

dd if=/dev/sda of=back.sda bs=10M 


You can increase or reduce the bs(block size) based on your i/o capacity(fast increase,slow decrease),then copy the back.sda with scp or rsync on backup.
Later you can mount the image and recovery the files,this will work if sda is not broken disk,if is corrupted you can try a fsck.
Rsync works for files,i have never tried on block device but i think rsync sda copy only the sda block file(size 0) on remote backup
If the problem is unavaliable partition, you will resolve nothing with rsync,you must use kpartx,search google for kpartx lvm
Or try this

pvscan
vgscan
vgchange -ay


See the output and mount the volume
"
5007,5007,7973,Magento SendMail with attachment,"I have been working on a custom extension and I need a function to send the generated CSV file. Can you please let me know what might be the possible error in it.

protected function _sendCSV($filename, $subject, $last_update, $now) {
    $template_id = ""svm_export_email"";
    $email_template =  Mage::getModel('core/email_template')-&gt;loadDefault($template_id)-&gt;setSubject($subject."" ["".$now.""]"");
    $template_variables = array(
        'file_name' =&gt; $filename,
        'last_update' =&gt; $last_update,
        'now' =&gt;$now,
        );
    $email_template-&gt;getProcessedTemplate($template_variables);

    $sender = array('My Team' =&gt; Mage::getStoreConfig('trans_email/ident_general/email'));
    $email_template-&gt;setFrom($sender);


    $file = Mage::getBaseDir('var') . DS .'SVM'. DS .date('Y'). DS .date('m'). DS .$filename;
    $attachment = $email_template-&gt;getMail()-&gt;createAttachment(file_get_contents($file));
    $attachment-&gt;filename = $filename;

    try {
        $email_template-&gt;send('thecoderin@gmail.com','My Gmail');
    } catch (Exception $e) {
        Mage::log($e-&gt;getMessage(), NULL, self::LOG);
        return false;
    }
    Mage::log($filename."" File sent through mail"", NULL, self::LOG);
    return true;
}


I am getting the following error on invoking the function:

exception 'Exception' with message 'This letter cannot be sent.' in /my/magento/root/app/code/core/Mage/Core/Model/Email/Template.php:398


Thanks!
",thecoderin,https://magento.stackexchange.com/users/22911,"Check the createAttachment function from the file lib/Zend/Mail.php. See the function from below:

public function createAttachment($body,
                                 $mimeType    = Zend_Mime::TYPE_OCTETSTREAM,
                                 $disposition = Zend_Mime::DISPOSITION_ATTACHMENT,
                                 $encoding    = Zend_Mime::ENCODING_BASE64,
                                 $filename    = null)
{

    $mp = new Zend_Mime_Part($body);
    $mp-&gt;encoding = $encoding;
    $mp-&gt;type = $mimeType;
    $mp-&gt;disposition = $disposition;
    $mp-&gt;filename = $filename;

    $this-&gt;addAttachment($mp);

    return $mp;
}


We have to pass the extra parameters to the function. See example at http://stackoverflow.com/questions/17164077/magento-send-transactional-email-with-pdf-attachment 
",PHP Bugs,https://magento.stackexchange.com/users/2870,http://magento.stackexchange.com/questions/62857/magento-sendmail-with-attachment,TECHNOLOGY,magento.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,0.5,1.0,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,1.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.9,1.0,0.3333333333333333,0.0,1.0,Magento sendmail with attachments,"I have been working on a custom extension and I need a function to send the generated CSV file. Can you please let me know what might be the possible error in it.

protected function _sendCSV($filename, $subject, $last_update, $now) {
    $template_id = ""svm_export_email"";
    $email_template =  Mage::getModel('core/email_template')-&gt;loadDefault($template_id)-&gt;setSubject($subject."" ["".$now.""]"");
    $template_variables = array(
        'file_name' =&gt; $filename,
        'last_update' =&gt; $last_update,
        'now' =&gt;$now,
        );
    $email_template-&gt;getProcessedTemplate($template_variables);

    $sender = array('My Team' =&gt; Mage::getStoreConfig('trans_email/ident_general/email'));
    $email_template-&gt;setFrom($sender);


    $file = Mage::getBaseDir('var') . DS .'SVM'. DS .date('Y'). DS .date('m'). DS .$filename;
    $attachment = $email_template-&gt;getMail()-&gt;createAttachment(file_get_contents($file));
    $attachment-&gt;filename = $filename;

    try {
        $email_template-&gt;send('thecoderin@gmail.com','My Gmail');
    } catch (Exception $e) {
        Mage::log($e-&gt;getMessage(), NULL, self::LOG);
        return false;
    }
    Mage::log($filename."" File sent through mail"", NULL, self::LOG);
    return true;
}


I am getting the following error on invoking the function:

exception 'Exception' with message 'This letter cannot be sent.' in /my/magento/root/app/code/core/Mage/Core/Model/Email/Template.php:398


Thanks!
","Check the createAttachment function from the file lib/Zend/Mail.php. See the function from below:

public function createAttachment($body,
                                 $mimeType    = Zend_Mime::TYPE_OCTETSTREAM,
                                 $disposition = Zend_Mime::DISPOSITION_ATTACHMENT,
                                 $encoding    = Zend_Mime::ENCODING_BASE64,
                                 $filename    = null)
{

    $mp = new Zend_Mime_Part($body);
    $mp-&gt;encoding = $encoding;
    $mp-&gt;type = $mimeType;
    $mp-&gt;disposition = $disposition;
    $mp-&gt;filename = $filename;

    $this-&gt;addAttachment($mp);

    return $mp;
}


We have to pass the extra parameters to the function. See example at http://stackoverflow.com/questions/17164077/magento-send-transactional-email-with-pdf-attachment 
"
227,227,364,Change Product Quantity Without Edit on Magento,"I have a question here, how to change product stock without click ""Edit"" on Magento ?


Thanks Before
",Reggie Trichandra P,https://magento.stackexchange.com/users/23144,"There are third party modules for that.

Take a look at http://www.magentocommerce.com/magento-connect/catalogsearch/result/?q=grid+edit&amp;pl=0
",Jeroen,https://magento.stackexchange.com/users/3156,http://magento.stackexchange.com/questions/59703/change-product-quantity-without-edit-on-magento,TECHNOLOGY,magento.stackexchange.com,0.6666666666666666,0.8888888888888888,0.0,1.0,1.0,1.0,0.6666666666666666,0.4444444444444444,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.7777777777777778,0.7777777777777778,0.4444444444444444,1.0,0.8888888888888888,0.6666666666666667,1.0,0.0,0.0,0.8888888888888888,Change product quantity without editing Magento,"I have a question, how to change the product inventory without clicking ""Edit"" in Magento?","There are third party modules for that.

Take a look at http://www.magentocommerce.com/magento-connect/catalogsearch/result/?q=grid+edit&amp;pl=0
"
4823,4823,7665,Simanim on Rosh Hashanah,"Halacha (Kitzur) brings that besides for the Simanim (symbolic foods) mentioned in the Gemara Horiyas and Shulchan Aruch you can Make your own according to the Language of the Country you live in, this had lead to some creative stuff lets see some original Ideas for the Yehi Ratzons and symbolic foods (the  example in the Kitzur brings carrots(Meren) which in Yiddish the language of his country also means to inrease)?
",SimchasTorah,https://judaism.stackexchange.com/users/87,"Don't forget Dates for dates...
",yydl,https://judaism.stackexchange.com/users/128,http://judaism.stackexchange.com/questions/2713/simanim-on-rosh-hashanah,CULTURE,judaism.stackexchange.com,0.6666666666666666,0.3333333333333333,1.0,0.5,0.0,0.0,0.5555555555555556,0.6666666666666666,0.0,0.3333333333333333,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.5555555555555556,0.6666666666666666,0.6666666666666666,1.0,0.7777777777777778,0.6,0.0,0.0,0.0,0.7777777777777778,Seaman of Roche hasana,"Halacha (kitzur) believes that in addition to the simanim (symbolic food) mentioned in Gemara horiyas and shulchan aruch, you can also make your own food according to the language of the country where you live, which leads to some creative things. Let's look at some original ideas of Greek intestines and symbolic food (such as bringing carrots (Meron) in kitzur), and Yiddish, the language of his country also means invasion?",Don't forget the date of the appointment...
3278,3278,5222,What do I do wrong to get hip aches after biking?,"I ride about 17 miles each session. After the ride, the outside of my hips sore: only the parts near the outermost joints, most likely the tendon (although this is only a guess). My knees are fine, my ankles are fine, etc.

The only thing that might not fit perfectly for me is the seat height. I'd rather have a longer post so I can lift the seat up an inch or two. Do you think this might create the soreness in the area of the outer hips? 
",RJIGO,https://bicycles.stackexchange.com/users/3628,"I might be inclined to try out a different saddle, look for a smoother route, or invest in wider tires (if your bike will accommodate them). If heltonbiker is correct (above), your bursae may be absorbing more shocks than they can handle, causing the pain you're feeling. If you're a woman riding on a man's saddle, consider looking for a women's saddle, as women's sit-bones are usually further apart than men's. 

If you're able to consult the medical establishment, it may be worth trying for a referral to a physical therapist. Lacking that, a good massage therapist can be a wonder-worker.

Good luck! I hope you can get back to biking pain-free.
",D.Salo,https://bicycles.stackexchange.com/users/3631,http://bicycles.stackexchange.com/questions/8476/what-do-i-do-wrong-to-get-hip-aches-after-biking,CULTURE,bicycles.stackexchange.com,0.7777777777777778,0.4444444444444444,0.0,0.0,1.0,0.0,0.8888888888888888,0.8888888888888888,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.6666666666666666,0.0,1.0,1.0,How does buttock ache do after cycling?,"I ride about 17 miles at a time. After riding, my buttocks ache on the outside: only the part near the most lateral joint, most likely the tendon (although this is only a guess). My knees are good, my ankles are good, and so on.","I might be inclined to try out a different saddle, look for a smoother route, or invest in wider tires (if your bike will accommodate them). If heltonbiker is correct (above), your bursae may be absorbing more shocks than they can handle, causing the pain you're feeling. If you're a woman riding on a man's saddle, consider looking for a women's saddle, as women's sit-bones are usually further apart than men's. 

If you're able to consult the medical establishment, it may be worth trying for a referral to a physical therapist. Lacking that, a good massage therapist can be a wonder-worker.

Good luck! I hope you can get back to biking pain-free.
"
2143,2143,3415,"cURL is unable to use client certificate , in local server","I set up a local server using XAMPP. I have two php scripts , a sender and a receiver. I am trying to send an XML file from the sender to the receiver using HTTP over SSL (HTTPS).

I created a self signed certificate , i configured XAMPP and i use this code on my sender :

&lt;?php
  /*
   * XML Sender/Client.
   */
  // Get our XML. You can declare it here or even load a file.


  $xml = file_get_contents(""data.xml"");

  // We send XML via CURL using POST with a http header of text/xml.
  $ch = curl_init();

  //curl_setopt($ch, CURLOPT_SSLVERSION,3);

  curl_setopt($ch, CURLOPT_SSL_VERIFYPEER, true);
  curl_setopt($ch, CURLOPT_SSL_VERIFYHOST, 2);

  curl_setopt($ch, CURLOPT_CAINFO,  getcwd().'ipm.crt');
  curl_setopt($ch, CURLOPT_SSLCERT, getcwd().'ipm.pem');

  curl_setopt($ch, CURLOPT_SSLCERTPASSWD,'pass');

  //i use this line only for debugging through fiddler. Must delete after done with debugging.
  curl_setopt($ch, CURLOPT_PROXY, '127.0.0.1:8888');

  // set URL and other appropriate options
  curl_setopt($ch, CURLOPT_URL, ""https://ipv4.fiddler/iPM/receiver.php"");
  curl_setopt($ch, CURLOPT_HTTPHEADER, array('Content-Type: text/xml'));
  curl_setopt($ch, CURLOPT_HEADER, 0);
  curl_setopt($ch, CURLOPT_POST, 1);
  curl_setopt($ch, CURLOPT_POSTFIELDS, $xml);
  curl_setopt($ch, CURLOPT_FOLLOWLOCATION, 0);
  curl_setopt($ch, CURLOPT_REFERER, 'https://ipv4.fiddler/iPM/receiver.php');
  curl_setopt($ch, CURLOPT_RETURNTRANSFER, 1);
  $ch_result = curl_exec($ch);
  echo ""Result = "".$ch_result;

  echo 'Curl error: ' . curl_error($ch);

  curl_close($ch);
  // Print CURL result.
?&gt;


However i always get this error : Curl error: unable to use client certificate (no key found or wrong pass phrase?)

What can i possibly do wrong? The passphrase IS the word pass .

I created my .crt by doing :

openssl req -config openssl.cnf -new -out ipm.csr -keyout ipm.pem

openssl rsa -in ipm.pem -out ipm.key

openssl x509 -in ipm.csr -out ipm.crt -req -signkey ipm.key -days 365


I dont want to put the SSL_VERIFYPEER and SSL_VERIFYHOST to false.
",donparalias,https://stackoverflow.com/users/1372498,"I think that you already fixed your problem, but I can see two problems:


you forgot about a slash between getcwd() and filename:
curl_setopt($ch, CURLOPT_CAINFO,  getcwd().'/ipm.crt');
curl_setopt($ch, CURLOPT_SSLCERT, getcwd().'/ipm.pem');
you need to attach a key file as @donparalias already said

",kayo,https://stackoverflow.com/users/3884374,http://stackoverflow.com/questions/14470225/curl-is-unable-to-use-client-certificate-in-local-server,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.4444444444444444,0.0,1.0,1.0,1.0,0.5555555555555556,0.5555555555555556,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.3333333333333333,0.0,0.8888888888888888,Curl cannot use client certificate in local server,"I set up a local server using XAMPP. I have two php scripts , a sender and a receiver. I am trying to send an XML file from the sender to the receiver using HTTP over SSL (HTTPS).

I created a self signed certificate , i configured XAMPP and i use this code on my sender :

&lt;?php
  /*
   * XML Sender/Client.
   */
  // Get our XML. You can declare it here or even load a file.


  $xml = file_get_contents(""data.xml"");

  // We send XML via CURL using POST with a http header of text/xml.
  $ch = curl_init();

  //curl_setopt($ch, CURLOPT_SSLVERSION,3);

  curl_setopt($ch, CURLOPT_SSL_VERIFYPEER, true);
  curl_setopt($ch, CURLOPT_SSL_VERIFYHOST, 2);

  curl_setopt($ch, CURLOPT_CAINFO,  getcwd().'ipm.crt');
  curl_setopt($ch, CURLOPT_SSLCERT, getcwd().'ipm.pem');

  curl_setopt($ch, CURLOPT_SSLCERTPASSWD,'pass');

  //i use this line only for debugging through fiddler. Must delete after done with debugging.
  curl_setopt($ch, CURLOPT_PROXY, '127.0.0.1:8888');

  // set URL and other appropriate options
  curl_setopt($ch, CURLOPT_URL, ""https://ipv4.fiddler/iPM/receiver.php"");
  curl_setopt($ch, CURLOPT_HTTPHEADER, array('Content-Type: text/xml'));
  curl_setopt($ch, CURLOPT_HEADER, 0);
  curl_setopt($ch, CURLOPT_POST, 1);
  curl_setopt($ch, CURLOPT_POSTFIELDS, $xml);
  curl_setopt($ch, CURLOPT_FOLLOWLOCATION, 0);
  curl_setopt($ch, CURLOPT_REFERER, 'https://ipv4.fiddler/iPM/receiver.php');
  curl_setopt($ch, CURLOPT_RETURNTRANSFER, 1);
  $ch_result = curl_exec($ch);
  echo ""Result = "".$ch_result;

  echo 'Curl error: ' . curl_error($ch);

  curl_close($ch);
  // Print CURL result.
?&gt;


However i always get this error : Curl error: unable to use client certificate (no key found or wrong pass phrase?)

What can i possibly do wrong? The passphrase IS the word pass .

I created my .crt by doing :

openssl req -config openssl.cnf -new -out ipm.csr -keyout ipm.pem

openssl rsa -in ipm.pem -out ipm.key

openssl x509 -in ipm.csr -out ipm.crt -req -signkey ipm.key -days 365


I dont want to put the SSL_VERIFYPEER and SSL_VERIFYHOST to false.
","I think that you already fixed your problem, but I can see two problems:


you forgot about a slash between getcwd() and filename:
curl_setopt($ch, CURLOPT_CAINFO,  getcwd().'/ipm.crt');
curl_setopt($ch, CURLOPT_SSLCERT, getcwd().'/ipm.pem');
you need to attach a key file as @donparalias already said

"
1623,1623,2546,Replacing the thermocouple for a multimeter?,"I bought a no-name but decent multimeter, and it came with a thermocouple. Let's say I broke it in some way. Can I just replace it with any other thermocouple, or is each thermocouple calibrated for one specific model of a multimeter?

I have been looking at thermocouples, eg on eBay, e.g. this one. They write some specs but they don't write which multimeter it fits with?

So does any thermocouple fit with any multimeter (or digital thermometer)?
",Mads Skjern,https://electronics.stackexchange.com/users/35827,"There are a few different types of thermocouples. In general you can replace a thermocouple with the same type, but you can't with different a different type because the calibration constants will be different.
",helloworld922,https://electronics.stackexchange.com/users/10658,http://electronics.stackexchange.com/questions/132748/replacing-the-thermocouple-for-a-multimeter,TECHNOLOGY,electronics.stackexchange.com,1.0,0.3333333333333333,0.0,1.0,1.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,0.6666666666666666,Change thermocouple to multimeter?,"I bought a no-name but decent multimeter, and it came with a thermocouple. Let's say I broke it in some way. Can I just replace it with any other thermocouple, or is each thermocouple calibrated for one specific model of a multimeter?

I have been looking at thermocouples, eg on eBay, e.g. this one. They write some specs but they don't write which multimeter it fits with?

So does any thermocouple fit with any multimeter (or digital thermometer)?
","There are a few different types of thermocouples. In general you can replace a thermocouple with the same type, but you can't with different a different type because the calibration constants will be different.
"
645,645,1024,How do I create a simple yet complex business layer?,"I'm working with a fairly complex web application. It's split up into the following layers:


Presentation - HTML
Service layer - A REST and SOAP API communicating with the business layer
Business layer - Contains the business logic.
Data access - Provides access to the storage (SQL etc)


The business layers contains classes encapsulating specific areas, such as customer registration, user management and more. The problem we are seeing is that the business layer is starting to get a bit messy. We have a single class handling customer management but as this area of the application grows more and more complex, the class grows and grows and become messy.

For example, we may have the following classes


class CustomerManager


void CreateCustomer(...)
void DeleteCustomer(...)

class UserManager


void CreateUser(..)
void DeleteUser(...) 
void ActivateUser(...)
void InactivateUser(...)
void ResetPassword(...) 



Creating a customer involves creating users as well. So CustomerManager calls misc methods in the UserManager class. As the application has evolved, creating a new customer means roughly 10 different things needs to be done except for registring the customer in the database, such as informing sales, audit logging, configuring default user accounts, creating a default configuration for the customer, notifying end-users of their auto-generated passwords and more. So CustomerManager.CreateCustomer grows to ~100 lines of fairly hairy code.

I'm trying to think of a good way to handle this but am assuming that there's some common good way to do this which I'm simply not aware of.

I've considered creating ""Task""/""Command"" classes implementing small sub-processes and then let the CustomerCreation.CreateCustomer simply execute a set of tasks. I would have more classes but they would each do less things.

I've also considering implementing some kind of global application-level event/plug-in systems where CustomerManager.CreateCustomer just creates the customer in the database and then publishes an event that the customer is created. Plug-ins/something can then subscribe to these events and do stuff such as informing sales and logging the fact. Using this method, I wouldn't have to actually update CustomerManager.CreateCustomer when I want to do more stuff which is something which feels attractive to me.

What obvious design pattern am I missing?
",Nitra,https://programmers.stackexchange.com/users/90440,"As @DocBrown said, plugins are mostly useful when you want to allow third parties to be able to extend your application. But that doesn't mean you can't use similar techniques in your design as what gets commonly used when interfacing with plugins.

For example, if a lot of the code you have is along the lines of ""after creating the customer in the databse, components X, Y and Z need to be informed so they can take their appropriate actions"", then you can use the Observer pattern there to decouple CustomerRegistration from X, Y and Z (and at a later time, A and B could get added to that list as well).

On the other hand, if your logic has a lot of ifs, buts and unless tests in it, then there is no real way to reduce the complexity of the code, because it is inherent in the business rules that the code represents.
",Bart van Ingen Schenau,https://programmers.stackexchange.com/users/5099,http://programmers.stackexchange.com/questions/211491/how-do-i-create-a-simple-yet-complex-business-layer,TECHNOLOGY,programmers.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,1.0,0.6666666666666666,1.0,0.8888888888888888,0.4444444444444444,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.6666666666666666,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,1.0,1.0,0.9,0.6666666666666666,0.3333333333333333,0.6666666666666666,1.0,How to create a simple and complex business layer?,"I'm working with a fairly complex web application. It's split up into the following layers:


Presentation - HTML
Service layer - A REST and SOAP API communicating with the business layer
Business layer - Contains the business logic.
Data access - Provides access to the storage (SQL etc)


The business layers contains classes encapsulating specific areas, such as customer registration, user management and more. The problem we are seeing is that the business layer is starting to get a bit messy. We have a single class handling customer management but as this area of the application grows more and more complex, the class grows and grows and become messy.

For example, we may have the following classes


class CustomerManager


void CreateCustomer(...)
void DeleteCustomer(...)

class UserManager


void CreateUser(..)
void DeleteUser(...) 
void ActivateUser(...)
void InactivateUser(...)
void ResetPassword(...) 



Creating a customer involves creating users as well. So CustomerManager calls misc methods in the UserManager class. As the application has evolved, creating a new customer means roughly 10 different things needs to be done except for registring the customer in the database, such as informing sales, audit logging, configuring default user accounts, creating a default configuration for the customer, notifying end-users of their auto-generated passwords and more. So CustomerManager.CreateCustomer grows to ~100 lines of fairly hairy code.

I'm trying to think of a good way to handle this but am assuming that there's some common good way to do this which I'm simply not aware of.

I've considered creating ""Task""/""Command"" classes implementing small sub-processes and then let the CustomerCreation.CreateCustomer simply execute a set of tasks. I would have more classes but they would each do less things.

I've also considering implementing some kind of global application-level event/plug-in systems where CustomerManager.CreateCustomer just creates the customer in the database and then publishes an event that the customer is created. Plug-ins/something can then subscribe to these events and do stuff such as informing sales and logging the fact. Using this method, I wouldn't have to actually update CustomerManager.CreateCustomer when I want to do more stuff which is something which feels attractive to me.

What obvious design pattern am I missing?
","As @DocBrown said, plugins are mostly useful when you want to allow third parties to be able to extend your application. But that doesn't mean you can't use similar techniques in your design as what gets commonly used when interfacing with plugins.

For example, if a lot of the code you have is along the lines of ""after creating the customer in the databse, components X, Y and Z need to be informed so they can take their appropriate actions"", then you can use the Observer pattern there to decouple CustomerRegistration from X, Y and Z (and at a later time, A and B could get added to that list as well).

On the other hand, if your logic has a lot of ifs, buts and unless tests in it, then there is no real way to reduce the complexity of the code, because it is inherent in the business rules that the code represents.
"
5350,5350,8494,Bottom bracket bearing Issues,"Been having some bottom bracket (BB) woes. Noticed a click on the top of the left pedal stroke decided to re-grease the BB. Took it apart cleaned everything re-greased, put it back together. 
Roll forward a week.
Notice my cranks sticking here and there, gets progressively worse on the ride. Get it home and off the bike notice my bike has turned into a rain-stick (this provided no calming effect)
Que another strip down of the BB.
Upon inspection, I found all the bearing on the non lockring side of the where out of the cage, which now would no longer hold them. I pinched the cages with pilers to secure the ball bearings back in place. Re-greased repacked.
Lifted my bike out today for my cycle to work jingle-jingle; LOOSE BEARING!
Cycle to work was sub 3miles so risked it.
Want to take care of this ASAP, so my questions are:

1. I figure I am over-tighting the bottom bracket, causing the damage to the cage, however what else could cause?

BB info:


Campagnolo Italian threaded
plastic sleeve is in two parts, the smaller part pushes into the
other.
2 caged bearings from memory 8/9 bearings in each cage.
Two screw in cones one locking.


here is a pics of my spindle:


Brev whatever that means


2. What size bearing does an Italian threaded BB take?
",will,https://bicycles.stackexchange.com/users/3068,"Take everything apart,get all the grease out of the bb and feel inside where the bearings go,it should be fairly smooth,do this to both sides and compare the ""feel"" of each..If it doesn't feel right(burrs,cracks) there's your problem...I just replaced the bearings in my bike and they were 1/4 inch but your bearings will probally be metric in that general size,it's easy enough to find online...don't skimp on the bearings,get grade 25 bearings,there the best...amazon has them for short money and good luck
",Bill Marcum,https://bicycles.stackexchange.com/users/4327,http://bicycles.stackexchange.com/questions/9882/bottom-bracket-bearing-issues,CULTURE,bicycles.stackexchange.com,0.6666666666666666,0.3333333333333333,0.0,0.0,1.0,1.0,0.6666666666666666,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,0.0,1.0,Bearing problem of bottom bracket,"Been having some bottom bracket (BB) woes. Noticed a click on the top of the left pedal stroke decided to re-grease the BB. Took it apart cleaned everything re-greased, put it back together. 
Roll forward a week.
Notice my cranks sticking here and there, gets progressively worse on the ride. Get it home and off the bike notice my bike has turned into a rain-stick (this provided no calming effect)
Que another strip down of the BB.
Upon inspection, I found all the bearing on the non lockring side of the where out of the cage, which now would no longer hold them. I pinched the cages with pilers to secure the ball bearings back in place. Re-greased repacked.
Lifted my bike out today for my cycle to work jingle-jingle; LOOSE BEARING!
Cycle to work was sub 3miles so risked it.
Want to take care of this ASAP, so my questions are:

1. I figure I am over-tighting the bottom bracket, causing the damage to the cage, however what else could cause?

BB info:


Campagnolo Italian threaded
plastic sleeve is in two parts, the smaller part pushes into the
other.
2 caged bearings from memory 8/9 bearings in each cage.
Two screw in cones one locking.


here is a pics of my spindle:


Brev whatever that means


2. What size bearing does an Italian threaded BB take?
","Take everything apart, take all the grease out of BB, feel the inside of the bearing, it should be quite smooth, do this for both sides, compare the ""feeling"" of each bearing If it doesn't feel right (burr, crack), it's your problem I just changed the bearings of my bicycle. They are 1 / 4 inch. But your bearings may be of the same size as metric system. It's easy to find them on the Internet Don't be stingy with the bearings, get 25 grade bearings, where the best Amazon has their short-term funding and good luck"
3663,3663,5843,House rules to make the cloister less of a game winning tile in Carcassonne?,"In my experience, cloister tiles in Carcassonne are often ""too lucky"". If you draw a cloister tile in the beginning of the game, it will typically still require an investment of quite a bit of ""meeple"" time to obtain the full 9 points, which makes it a fair trade-off. However, after about half of the game, it's relatively likely that you can ""parachute"" a cloister tile in some spot and get 8 or 9 points immediately. This adds a lot of randomness to the game.

What house rules work well to diminish this effect?
",Erik P.,https://boardgames.stackexchange.com/users/30,"You could borrow the ""Abbey"" idea from the Abbyes and Mayors expansion.

Abbeys are special tiles (6 of them divided equally among all players) which you can play rather than drawing and playing a random tile. The abbey counts as a cloister for scoring and playing a meeple on, and has a solid edge, so that it ends a road, and walls off citys and farms that it borders. Abbeys can only be played in holes - spaces that have tiles on all four sides.

The effect of this is that areas that are prime ""gotcha"" cloister locations at end game are a little less likely as they either get Abbeys dropped into them, or players shy away from letting such places appear.

Without Abbeys and Mayors, you could allow each player once or twice a game, the option of playing a tile face down in a whole rather as an Abbey than as a normal play, and otherwise following the normal Abbey rules.
",Simon Withers,https://boardgames.stackexchange.com/users/55,http://boardgames.stackexchange.com/questions/8/house-rules-to-make-the-cloister-less-of-a-game-winning-tile-in-carcassonne,CULTURE,boardgames.stackexchange.com,0.7777777777777778,0.7777777777777778,0.0,0.6666666666666666,1.0,1.0,0.5555555555555556,0.5555555555555556,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,0.0,0.7777777777777778,0.7777777777777778,0.6666666666666666,0.8888888888888888,0.8888888888888888,0.8666666666666666,0.0,0.3333333333333333,0.6666666666666666,0.7777777777777778,"In karkasson, let the cloister be less like the winning tile house rule?","In my experience, Carlsson's cloister tiles are usually ""too lucky."". If you draw a cloister tile at the beginning of the game, it usually still takes quite a lot of time to get a full score of 9, which is a fair trade-off. However, after about half of the game, you are likely to ""parachute"" a cloister tile somewhere and get 8 or 9 points immediately. This adds a lot of randomness to the game.","You could borrow the ""Abbey"" idea from the Abbyes and Mayors expansion.

Abbeys are special tiles (6 of them divided equally among all players) which you can play rather than drawing and playing a random tile. The abbey counts as a cloister for scoring and playing a meeple on, and has a solid edge, so that it ends a road, and walls off citys and farms that it borders. Abbeys can only be played in holes - spaces that have tiles on all four sides.

The effect of this is that areas that are prime ""gotcha"" cloister locations at end game are a little less likely as they either get Abbeys dropped into them, or players shy away from letting such places appear.

Without Abbeys and Mayors, you could allow each player once or twice a game, the option of playing a tile face down in a whole rather as an Abbey than as a normal play, and otherwise following the normal Abbey rules.
"
5751,5751,9106,Hexagon with exscribed triangle,"I am learning tikz now, it is painfully slow, but I am slowly learning. I am trying to reproduce the image below.



Here is my code so far. This is basically a rip of from the pgf manual. 

\documentclass[10pt,a4paper]{article}
\usepackage{mathtools}
\usepackage{tikz}
\usetikzlibrary{calc}
\usetikzlibrary{backgrounds}
\usepgflibrary{shapes}
\usetikzlibrary{through}

\begin{document}

\begin{figure}[!htpb] \centering
\begin{tikzpicture}
\foreach \a in {5,...,5}{
 \draw[blue, dashed] (\a*2,0) circle(0.5cm);
\node[regular polygon, regular polygon sides=\a, minimum size=1cm, draw] at    (\a*2,0) {};
}
\end{tikzpicture}
\end{figure}
\end{document}


Some problems with this code


How do i scale this image?
How do I label each side ?
Once again, how do I make that pesky angle ? 
Is there a way to do this for a n-gon?


When I scaled the image using simply \begin{tikzpicture}[scale=3]... only the circle grew. Labeling each point manually is sort of tedious.. =(



EDIT: I DID IT WOEEE Code us ugly though... :D:DD:

\documentclass[10pt,a4paper]{article}
\usepackage{mathtools}
\usepackage{tikz}
\usetikzlibrary{calc}
\usetikzlibrary{backgrounds}
\usepgflibrary{shapes}
\usetikzlibrary{through}

\pgfdeclarelayer{background}
\pgfdeclarelayer{foreground}
\pgfsetlayers{background,main,foreground}

\begin{document}

\begin{figure}[!htbp]
\centering
\Large 
\begin{tikzpicture}[scale=1]
\node (A) [draw,thick,regular polygon, regular polygon sides=6, minimum     size=7cm,outer sep=0pt,fill=gray!20] {};
\node at (A.corner 1) [anchor=360/6*(1-1)+270] {$D$};
\node at (A.corner 2) [anchor=360/6*(2-1)+270] {$E$};
\node at (A.corner 3) [anchor=360/6*(3-1)+270] {$F$};
\node at (A.corner 4) [anchor=360/6*(4-1)+270] {$A$};
\node at (A.corner 5) [anchor=360/6*(5-1)+270] {$B$};
\node at (A.corner 6) [anchor=360/6*(5-1)+270] {$C$};
\node at (A.corner 4) [right,above] {\hspace{3.5cm}$AB=16$cm};
\coordinate [label=above:\textcolor{blue}{$S$}] (S) at (0.95,1);
\draw[gray, thick, dashed] (0,0) circle(3.52cm);
\path[draw] (0.7,-0.3) node {$\alpha$};
{
\begin{pgfonlayer}{foreground}
\draw[gray,thick, dashed] (A.corner 4) -- (S) -- (A.corner 5);
\end{pgfonlayer}
}

\begin{scope}
  \path[clip] (S) -- (A.corner 4) -- (A.corner 5) -- cycle;
  \draw [red, fill=red!20] (S) circle (30pt);
  \draw [black] (S) circle (30pt);
\end{scope}
\end{tikzpicture}
\end{figure}
\end{document}

",N3buchadnezzar,https://tex.stackexchange.com/users/8306,"I'm pleased to see that Altermundus has posted a method using tkz-euclide.  There were two preliminary things that I wanted to say about this diagram and one of them was that if you're doing geometrical diagrams then you should take a look at the tkz packages (I don't know much about them myself but I've seen Altermundus do some pretty amazing diagrams here using them).

The other thing I wanted to say was that whilst it is tempting to use nodes to draw particular shapes, it has its drawbacks.  Nodes are designed to hold text and some of their behaviours stem from that - in particular how they are affected by transformations.  It is possible to circumvent these behaviours, but you do have to know how.

That's not an answer, though, more of a comment.

I do have an answer for you and one that doesn't use nodes.

\documentclass{article}
%\url{http://tex.stackexchange.com/q/35266/86}
\usepackage{tikz}
\usetikzlibrary{calc}

\makeatletter
% This provides a translation from numbers to letters for labelling
% the vertices
\newcommand\numToAlpha[1]{\@Alph#1}
\makeatother

\begin{document}
\begin{tikzpicture}
% This draws the circle
\draw[dashed] (0,0) circle[radius=3cm];
% This draws,fills and labels the polygon
\draw[ultra thick,blue,fill=blue!25] (0,0)
% Set the number of sides
    let \n1=7 in
% We start so that the second line is the lower horizontal
% This means that the first vertex that we label is the left
% end of the lower horizontal
    ({-90 - 3*360/(2*\n1)}:3)
% Now we iterate over the edges
    \foreach \l in {1,...,\n1} {
% This saves our next angle (as we use it twice)
      let \n2={-90 + (2 * \l - 3) * 360/(2 * \n1)} in
% This draws the edge and labels it
% As our first edge is actually the last one, our label needs
% shifting round (modulo the number of edges)
      -- node[auto,swap,text=black] {\pgfmathparse{int(Mod(\l-2,\n1)+1)}\pgfmathresult}
% This is the endpoint of the edge
     (\n2:3)
% This is the label at the endpoint, we could have chosen to
% label the start of the edge, but then the offset would have
% been slightly more complicated.
% We also save these nodes since we'll want two of them later
     node[label={[text=black]\n2:{\numToAlpha{\l}}}] (\numToAlpha{\l}) {}
    };
% This is our point ""S"", I chose coordinates at random
\fill (1,.5) circle[radius=2pt] coordinate (S) node[above] {S};
% This draws the dashed lines to the edge
\draw[dashed] (A) -- (S) -- (B);
\begin{scope}
% My method for drawing the angle is sneaky: I clip a circle
% against the dashed path
\clip (A) -- (S) -- (B);
\draw[blue,ultra thick,fill=blue!50] (S) circle[radius=1cm];
\end{scope}
% Then to position the alpha, I use an invisible path that
% goes from S to the midpoint of A-B
\path ($(S)!1.2cm!($(B)!.5!(A)$)$) node {\(\alpha\)};
% Finally, we label the edge A-B with its distance
\path (A) -- node[auto] {\(A B = 16m\)} (B);
\end{tikzpicture}
\end{document}


Here's the result:



(Forgot a text=black.  The code's correct but the numbers in the picture are blue instead of black.)
",Loop Space,https://tex.stackexchange.com/users/86,http://tex.stackexchange.com/questions/35266/hexagon-with-exscribed-triangle,TECHNOLOGY,tex.stackexchange.com,1.0,0.3333333333333333,0.0,1.0,1.0,1.0,0.6666666666666666,0.5555555555555556,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.9,0.6666666666666666,0.3333333333333333,1.0,1.0,Circumscribed triangle hexagon,"I am learning tikz now, it is painfully slow, but I am slowly learning. I am trying to reproduce the image below.



Here is my code so far. This is basically a rip of from the pgf manual. 

\documentclass[10pt,a4paper]{article}
\usepackage{mathtools}
\usepackage{tikz}
\usetikzlibrary{calc}
\usetikzlibrary{backgrounds}
\usepgflibrary{shapes}
\usetikzlibrary{through}

\begin{document}

\begin{figure}[!htpb] \centering
\begin{tikzpicture}
\foreach \a in {5,...,5}{
 \draw[blue, dashed] (\a*2,0) circle(0.5cm);
\node[regular polygon, regular polygon sides=\a, minimum size=1cm, draw] at    (\a*2,0) {};
}
\end{tikzpicture}
\end{figure}
\end{document}


Some problems with this code


How do i scale this image?
How do I label each side ?
Once again, how do I make that pesky angle ? 
Is there a way to do this for a n-gon?


When I scaled the image using simply \begin{tikzpicture}[scale=3]... only the circle grew. Labeling each point manually is sort of tedious.. =(



EDIT: I DID IT WOEEE Code us ugly though... :D:DD:

\documentclass[10pt,a4paper]{article}
\usepackage{mathtools}
\usepackage{tikz}
\usetikzlibrary{calc}
\usetikzlibrary{backgrounds}
\usepgflibrary{shapes}
\usetikzlibrary{through}

\pgfdeclarelayer{background}
\pgfdeclarelayer{foreground}
\pgfsetlayers{background,main,foreground}

\begin{document}

\begin{figure}[!htbp]
\centering
\Large 
\begin{tikzpicture}[scale=1]
\node (A) [draw,thick,regular polygon, regular polygon sides=6, minimum     size=7cm,outer sep=0pt,fill=gray!20] {};
\node at (A.corner 1) [anchor=360/6*(1-1)+270] {$D$};
\node at (A.corner 2) [anchor=360/6*(2-1)+270] {$E$};
\node at (A.corner 3) [anchor=360/6*(3-1)+270] {$F$};
\node at (A.corner 4) [anchor=360/6*(4-1)+270] {$A$};
\node at (A.corner 5) [anchor=360/6*(5-1)+270] {$B$};
\node at (A.corner 6) [anchor=360/6*(5-1)+270] {$C$};
\node at (A.corner 4) [right,above] {\hspace{3.5cm}$AB=16$cm};
\coordinate [label=above:\textcolor{blue}{$S$}] (S) at (0.95,1);
\draw[gray, thick, dashed] (0,0) circle(3.52cm);
\path[draw] (0.7,-0.3) node {$\alpha$};
{
\begin{pgfonlayer}{foreground}
\draw[gray,thick, dashed] (A.corner 4) -- (S) -- (A.corner 5);
\end{pgfonlayer}
}

\begin{scope}
  \path[clip] (S) -- (A.corner 4) -- (A.corner 5) -- cycle;
  \draw [red, fill=red!20] (S) circle (30pt);
  \draw [black] (S) circle (30pt);
\end{scope}
\end{tikzpicture}
\end{figure}
\end{document}

","I'm pleased to see that Altermundus has posted a method using tkz-euclide.  There were two preliminary things that I wanted to say about this diagram and one of them was that if you're doing geometrical diagrams then you should take a look at the tkz packages (I don't know much about them myself but I've seen Altermundus do some pretty amazing diagrams here using them).

The other thing I wanted to say was that whilst it is tempting to use nodes to draw particular shapes, it has its drawbacks.  Nodes are designed to hold text and some of their behaviours stem from that - in particular how they are affected by transformations.  It is possible to circumvent these behaviours, but you do have to know how.

That's not an answer, though, more of a comment.

I do have an answer for you and one that doesn't use nodes.

\documentclass{article}
%\url{http://tex.stackexchange.com/q/35266/86}
\usepackage{tikz}
\usetikzlibrary{calc}

\makeatletter
% This provides a translation from numbers to letters for labelling
% the vertices
\newcommand\numToAlpha[1]{\@Alph#1}
\makeatother

\begin{document}
\begin{tikzpicture}
% This draws the circle
\draw[dashed] (0,0) circle[radius=3cm];
% This draws,fills and labels the polygon
\draw[ultra thick,blue,fill=blue!25] (0,0)
% Set the number of sides
    let \n1=7 in
% We start so that the second line is the lower horizontal
% This means that the first vertex that we label is the left
% end of the lower horizontal
    ({-90 - 3*360/(2*\n1)}:3)
% Now we iterate over the edges
    \foreach \l in {1,...,\n1} {
% This saves our next angle (as we use it twice)
      let \n2={-90 + (2 * \l - 3) * 360/(2 * \n1)} in
% This draws the edge and labels it
% As our first edge is actually the last one, our label needs
% shifting round (modulo the number of edges)
      -- node[auto,swap,text=black] {\pgfmathparse{int(Mod(\l-2,\n1)+1)}\pgfmathresult}
% This is the endpoint of the edge
     (\n2:3)
% This is the label at the endpoint, we could have chosen to
% label the start of the edge, but then the offset would have
% been slightly more complicated.
% We also save these nodes since we'll want two of them later
     node[label={[text=black]\n2:{\numToAlpha{\l}}}] (\numToAlpha{\l}) {}
    };
% This is our point ""S"", I chose coordinates at random
\fill (1,.5) circle[radius=2pt] coordinate (S) node[above] {S};
% This draws the dashed lines to the edge
\draw[dashed] (A) -- (S) -- (B);
\begin{scope}
% My method for drawing the angle is sneaky: I clip a circle
% against the dashed path
\clip (A) -- (S) -- (B);
\draw[blue,ultra thick,fill=blue!50] (S) circle[radius=1cm];
\end{scope}
% Then to position the alpha, I use an invisible path that
% goes from S to the midpoint of A-B
\path ($(S)!1.2cm!($(B)!.5!(A)$)$) node {\(\alpha\)};
% Finally, we label the edge A-B with its distance
\path (A) -- node[auto] {\(A B = 16m\)} (B);
\end{tikzpicture}
\end{document}


Here's the result:



(Forgot a text=black.  The code's correct but the numbers in the picture are blue instead of black.)
"
191,191,305,Inserting a blank line in vim?,"I quite often find I have a need to insert a blank line either below or above the current line when editing in vim. o and O will do this, but they subsequently switch into insert mode, which is annoying. Is there any built-in command to do this which will remain in normal mode?
",Andrew Ferrier,https://superuser.com/users/3021,"I've been using these

map &lt;Enter&gt; o&lt;ESC&gt;
map &lt;S-Enter&gt; O&lt;ESC&gt;


in my .vimrc for years.

Press Enter to insert a blank line below current, Shift + Enter to insert it above.
",Mr Shunz,https://superuser.com/users/7951,http://superuser.com/questions/607163,TECHNOLOGY,superuser.com,1.0,0.5555555555555556,0.0,1.0,1.0,1.0,0.4444444444444444,0.3333333333333333,0.6666666666666666,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,0.8888888888888888,1.0,0.9333333333333332,1.0,0.0,0.0,1.0,Insert empty row in VIM?,"When editing in VIM, I often find it necessary to insert an empty row below or above the current row. O and o do this, but they then switch to insert mode, which is annoying. Is there any built-in command to do this, which will remain in normal mode?","I've been using these

map &lt;Enter&gt; o&lt;ESC&gt;
map &lt;S-Enter&gt; O&lt;ESC&gt;


in my .vimrc for years.

Press Enter to insert a blank line below current, Shift + Enter to insert it above.
"
5962,5962,9449,Is it reasonable to use Javascript MVC Frameworks for closed source paid web applications?,"I am wondering if it is reasonable to write closed source, paid web apps in Javascript (JS MVC Frameworks like AngularJS, Backbone, Knockout, ...)? I'm concerned because in this type of frameworks you use typically a REST backend for CRUD operations and the majority of business and application logic happens in Javascript which can be looked up by anyone using my app. He can see how i do things. 

When I use for example PHP or Java (Wicket) most of the logic is happening on the server and so a lot less of my source code is exposed. This seems to me a lot safer if I want to have an edge over my competitors, so potentially I earn more money.

So is it reasonable to use JavaScript MVC Frameworks for paid applications? Does it depend on something and if yes on what? 
",Robert Niestroj,https://programmers.stackexchange.com/users/80370,"If you are only using REST as your entire backend to communicate with the database, that maybe your problem. Using EJB and JPA, the business logic is abstracted away from the user, and handled by the server and its database. 

If your application logic is happening in your java code, well then I would suggest that it is not clean code. A servers job is to respond to the questions asked by the client. If the business application logic happens in javascript, then the client is essentially answering their own questions. Essentially, your questions makes no sense.
",jononeeno,https://programmers.stackexchange.com/users/88261,http://programmers.stackexchange.com/questions/194845/is-it-reasonable-to-use-javascript-mvc-frameworks-for-closed-source-paid-web-app,TECHNOLOGY,programmers.stackexchange.com,1.0,0.5555555555555556,0.0,1.0,1.0,1.0,0.5555555555555556,0.5555555555555556,0.6666666666666666,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.3333333333333333,1.0,0.3333333333333333,0.0,0.8888888888888888,0.7777777777777778,0.6666666666666666,0.7777777777777778,1.0,0.7,0.0,0.3333333333333333,0.6666666666666666,0.8888888888888888,Is it reasonable to use JavaScript MVC framework for closed source paid web applications?,"I want to know how to use JavaScript (JS MVC framework, such as angularjs, backbone, knockout,...) Is it reasonable to write closed source paid web applications? My concern is that in such frameworks, you usually use the rest backend to perform CRUD operations, while most business and application logic occurs in JavaScript, which can be found by anyone who uses my application. He knows how I do things.","If you are only using REST as your entire backend to communicate with the database, that maybe your problem. Using EJB and JPA, the business logic is abstracted away from the user, and handled by the server and its database. 

If your application logic is happening in your java code, well then I would suggest that it is not clean code. A servers job is to respond to the questions asked by the client. If the business application logic happens in javascript, then the client is essentially answering their own questions. Essentially, your questions makes no sense.
"
3369,3369,5376,"Do Jews view Scripture as the ""word of God""?","I am curious whether Jews view Scripture (i.e. the Tanach) as ""the word of God,"" and if so, in what way? Is it ""inspired"" by God? Is it a ""product of the Spirit of God""? Is God the ""Author""? [etc.]

In other words, what was God's role in the production of Scripture from a Jewish perspective?
",Jas 3.1,https://judaism.stackexchange.com/users/2657,"Rambam's Eighth Principle (translation by Aish.com):


  We believe that the entire Torah in our possession was given [to us] by the Almighty through Moshe Rabbeinu, by means of the medium we metaphorically call ""speech."" No one knows the real nature of this communication except Moshe, to whom it was transmitted. He was like a scribe receiving dictation. He wrote the history, the stories, and the commandments. Therefore he is called ""[the] inscriber.""


With regards to the last 8 verses, see here.
",Menachem,https://judaism.stackexchange.com/users/603,http://judaism.stackexchange.com/questions/29780/do-jews-view-scripture-as-the-word-of-god,CULTURE,judaism.stackexchange.com,1.0,0.8888888888888888,0.3333333333333333,0.6666666666666666,1.0,1.0,0.7777777777777778,0.8888888888888888,0.3333333333333333,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,1.0,0.0,1.0,1.0,0.5555555555555556,1.0,0.8888888888888888,0.8,0.0,0.0,1.0,0.8888888888888888,"Do Jews think the Bible is ""the way of God""?","I wonder if Jews think the Bible (i.e. tanaceh) is ""the word of God."" if so, in what way? Is it God's ""Revelation""? Is it the product of the spirit of God? Is God the author? [etc.]","Rambam's Eighth Principle (translation by Aish.com):


  We believe that the entire Torah in our possession was given [to us] by the Almighty through Moshe Rabbeinu, by means of the medium we metaphorically call ""speech."" No one knows the real nature of this communication except Moshe, to whom it was transmitted. He was like a scribe receiving dictation. He wrote the history, the stories, and the commandments. Therefore he is called ""[the] inscriber.""


With regards to the last 8 verses, see here.
"
1067,1067,1684,Good backup options for Mac pre-TimeMachine,"I have a friend with an iBook G4 who is looking for a cheap backup option for her Mac running OS 10.4.  Money is tight, so getting 10.5 is not really an option (in addition to buy a backup drive etc, yes money is really that tight).

What suggestions can you offer for backups that's better than trying to remember to burn a CD once a month?
",acrosman,https://superuser.com/users/8908,"Use snapshot. Free and functions effectivelly like TimeMachine. There's a writeup on how to get it going on older Macs somewhere on the Web. 
",MarceloR,https://superuser.com/users/39407,http://superuser.com/questions/176211,TECHNOLOGY,superuser.com,1.0,0.5555555555555556,0.3333333333333333,0.6666666666666666,1.0,0.0,0.5555555555555556,0.5555555555555556,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.8888888888888888,0.8888888888888888,0.3333333333333333,1.0,1.0,0.8,0.6666666666666666,0.0,0.0,0.8888888888888888,Good backup options for Mac pre timemachine,"I have a friend with an ibookg4 who is looking for a cheap backup option for a Mac running OS 10.4. Money is tight, so getting 10.5 is not a real choice (except for buying a backup drive, etc., yes, money is really tight).","Use snapshot. Free and functions effectivelly like TimeMachine. There's a writeup on how to get it going on older Macs somewhere on the Web. 
"
4115,4115,6569,MVC 4 and JsonResult format,"have a problem with the result format of this code

public JsonResult getCategorias(int? id)
{
  var res = from c in db.Categorias
  where (( id.HasValue &amp;&amp; c.CategoriaPadre == id.Value) || (!id.HasValue &amp;&amp; c.CategoriaPadre == null))
  select new { id = c.Id, label = c.Descripcion };

  return this.Json(res, JsonRequestBehavior.AllowGet);
}


this return a json:

[{""id"":21,""label"":""Marketing3""},{""id"":22,""label"":""Marketing4""}]

But i need a json with this format:

{""21"":""Marketing3"",""22"":""Marketing4""}

What can i do?

Thanks a lot and sorry my english.
",jotero,https://stackoverflow.com/users/993831,"You can also use this:-

public static KeyValuePair&lt;string,string&gt; KeyValue(YourClass obj)
        {
            return new KeyValuePair&lt;string, string&gt;(obj.id, obj.label);
        }


Before call

Json(result.ConvertAll(i =&gt; KeyValue(i)), JsonRequestBehavior.AllowGet);

",PSL,https://stackoverflow.com/users/1009603,http://stackoverflow.com/questions/15940397/mvc-4-and-jsonresult-format,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.3333333333333333,0.0,1.0,0.6666666666666666,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.5555555555555556,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.9,0.6666666666666666,0.3333333333333333,0.0,1.0,MVC 4 and jsonresult formats,"have a problem with the result format of this code

public JsonResult getCategorias(int? id)
{
  var res = from c in db.Categorias
  where (( id.HasValue &amp;&amp; c.CategoriaPadre == id.Value) || (!id.HasValue &amp;&amp; c.CategoriaPadre == null))
  select new { id = c.Id, label = c.Descripcion };

  return this.Json(res, JsonRequestBehavior.AllowGet);
}


this return a json:

[{""id"":21,""label"":""Marketing3""},{""id"":22,""label"":""Marketing4""}]

But i need a json with this format:

{""21"":""Marketing3"",""22"":""Marketing4""}

What can i do?

Thanks a lot and sorry my english.
","You can also use this:-

public static KeyValuePair&lt;string,string&gt; KeyValue(YourClass obj)
        {
            return new KeyValuePair&lt;string, string&gt;(obj.id, obj.label);
        }


Before call

Json(result.ConvertAll(i =&gt; KeyValue(i)), JsonRequestBehavior.AllowGet);

"
1242,1242,1952,Why are two eigen-state-kets with different eigenvalues orthogonal?,"The operators $J_1^2$, $J_2^2$, $J_{1z}$, and $J_{2z}$ are mutually commuting operators. Likewise, $J_1^2$, $J_2^2$, $J^2$, and $J_z$ are mutually commuting operators.  The two groups are incompatible, and the simultaneous eigenkets along with their eigenvalues are given by:

${J_1}^2 \left|j_1,j_2;m_1,m_2\right&gt; = j_1 \left(j_1+1\right) \hbar^2 \left|j_1,j_2;m_1,m_2\right&gt;$
${J_2}^2 \left|j_1,j_2;m_1,m_2\right&gt; = j_2 \left(j_2+1\right) \hbar^2 \left|j_1,j_2;m_1,m_2\right&gt;$
$J_{1z} \left|j_1,j_2;m_1,m_2\right&gt; = m_1 \hbar \left|j_1,j_2;m_1,m_2\right&gt;$
$J_{2z} \left|j_1,j_2;m_1,m_2\right&gt; = m_2 \hbar \left|j_1,j_2;m_1,m_2\right&gt;$

and

${J_1}^2 \left|j_1,j_2;j,m\right&gt; = j_1 \left(j_1+1\right) \hbar^2 \left|j_1,j_2;j,m\right&gt;$
${J_2}^2 \left|j_1,j_2;j,m\right&gt; = j_2 \left(j_2+1\right) \hbar^2 \left|j_1,j_2;j,m\right&gt;$
$J^2 \left|j_1,j_2;j,m\right&gt; = j \left(j+1\right) \hbar^2 \left|j_1,j_2;j,m\right&gt;$
$J_z \left|j_1,j_2;j,m\right&gt; = m \hbar \left|j_1,j_2;j,m\right&gt;$

I read that each set of eigenkets are mutually orthogonal [1] (for eigenkets corresponding to different sets of eigenvalues).  This is what I don't understand.  In principle it makes sense, but when I plug in numbers I don't get zero for the inner product.  For example take the first eigenket: $\left|j_1,j_2;m_1,m_2\right&gt;$.  If I choose different eigenvalues for this eigenket (e.g. let $j_1 = 0$ and then let $j_1 = 1$) I get the following:

for $j_1 = 0$ I can have:
$\left|0,j_2;0,m_2\right&gt;$

for $j_1 = 1$ I can have any of the following, since $\left|m_1\right| \leq j_1$:
$\left|1,j_2;-1,m_2\right&gt;$
$\left|1,j_2;0,m_2\right&gt;$
$\left|1,j_2;1,m_2\right&gt;$  

If I take the inner-product of the $j_1 = 0$ eigenket with any of the $j_1 = 1$ eigenkets I do not get zero, e.g.:

$\left&lt;0,j_2;0,m_2 \mid 1,j_2;-1,m_2\right&gt; = {j_2}^2+{m_2}^2$  

which is non-zero unless $j_2 = 0$.  

What am I misunderstanding here? How do you show that eigenkets with different eigenvalues are orthogonal?
",okj,https://physics.stackexchange.com/users/3597,"The error is most likely that you are using 

$$\left&lt;j_1,j_2;m_1,m_2 \mid j&#39;_1,j&#39;_2;m&#39;_1,m&#39;_2\right&gt; = j_1j&#39;_1+j_2j&#39;_2+m_1m&#39;_1+m_2m&#39;_2,
\quad \mathrm{(Wrong!)}$$

where you should be using 

$$\left&lt;j_1,j_2;m_1,m_2 \mid j&#39;_1,j&#39;_2;m&#39;_1,m&#39;_2\right&gt; = \delta_{j_1,j&#39;_1}\delta_{j_2,j&#39;_2}\delta_{m_1,m&#39;_1}\delta_{m_2,m&#39;_2},$$

where $\delta_{k,\ell}$ is the Kronecker delta function. 

In other words, the $j$'s and $m$'s are not the coefficients $v^i$ of a vector $\vec{v}=\sum_i v^i \vec{e}_i$ in a Hilbert space, where $\vec{e}_i$ is an orthonormal basis, so that

$$ \left&lt;\vec{v}\mid\vec{v}&#39;\right&gt; =  \sum_i (v^i)^*v&#39;^i, \qquad \left&lt;\vec{e}_i\mid\vec{e}_{i&#39;}\right&gt; = \delta_{i,i&#39;}.
$$

Rather, the $j$'s and $m$'s correspond to the $i$-labels of the basis $\vec{e}_i$. For brevity, we often write $\left&lt; i \mid i&#39;\right&gt;$ instead of $\left&lt;\vec{e}_i\mid\vec{e}_{i&#39;}\right&gt;$.

Finally, to give a complete answer, let me include my comment above that it is a general property of eigenvectors for different eigenvalues of a Hermitian operator, that they are orthogonal to each other, see e.g., Lubos Motl's answer or here.
",Qmechanic,https://physics.stackexchange.com/users/2451,http://physics.stackexchange.com/questions/10426/why-are-two-eigen-state-kets-with-different-eigenvalues-orthogonal,SCIENCE,physics.stackexchange.com,1.0,0.5,0.0,1.0,1.0,1.0,0.5,0.5,0.5,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.5,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9,0.5,0.0,1.0,1.0,Why are two eigenstates kets with different eigenvalues orthogonal?,"The operators $J_1^2$, $J_2^2$, $J_{1z}$, and $J_{2z}$ are mutually commuting operators. Likewise, $J_1^2$, $J_2^2$, $J^2$, and $J_z$ are mutually commuting operators.  The two groups are incompatible, and the simultaneous eigenkets along with their eigenvalues are given by:

${J_1}^2 \left|j_1,j_2;m_1,m_2\right&gt; = j_1 \left(j_1+1\right) \hbar^2 \left|j_1,j_2;m_1,m_2\right&gt;$
${J_2}^2 \left|j_1,j_2;m_1,m_2\right&gt; = j_2 \left(j_2+1\right) \hbar^2 \left|j_1,j_2;m_1,m_2\right&gt;$
$J_{1z} \left|j_1,j_2;m_1,m_2\right&gt; = m_1 \hbar \left|j_1,j_2;m_1,m_2\right&gt;$
$J_{2z} \left|j_1,j_2;m_1,m_2\right&gt; = m_2 \hbar \left|j_1,j_2;m_1,m_2\right&gt;$

and

${J_1}^2 \left|j_1,j_2;j,m\right&gt; = j_1 \left(j_1+1\right) \hbar^2 \left|j_1,j_2;j,m\right&gt;$
${J_2}^2 \left|j_1,j_2;j,m\right&gt; = j_2 \left(j_2+1\right) \hbar^2 \left|j_1,j_2;j,m\right&gt;$
$J^2 \left|j_1,j_2;j,m\right&gt; = j \left(j+1\right) \hbar^2 \left|j_1,j_2;j,m\right&gt;$
$J_z \left|j_1,j_2;j,m\right&gt; = m \hbar \left|j_1,j_2;j,m\right&gt;$

I read that each set of eigenkets are mutually orthogonal [1] (for eigenkets corresponding to different sets of eigenvalues).  This is what I don't understand.  In principle it makes sense, but when I plug in numbers I don't get zero for the inner product.  For example take the first eigenket: $\left|j_1,j_2;m_1,m_2\right&gt;$.  If I choose different eigenvalues for this eigenket (e.g. let $j_1 = 0$ and then let $j_1 = 1$) I get the following:

for $j_1 = 0$ I can have:
$\left|0,j_2;0,m_2\right&gt;$

for $j_1 = 1$ I can have any of the following, since $\left|m_1\right| \leq j_1$:
$\left|1,j_2;-1,m_2\right&gt;$
$\left|1,j_2;0,m_2\right&gt;$
$\left|1,j_2;1,m_2\right&gt;$  

If I take the inner-product of the $j_1 = 0$ eigenket with any of the $j_1 = 1$ eigenkets I do not get zero, e.g.:

$\left&lt;0,j_2;0,m_2 \mid 1,j_2;-1,m_2\right&gt; = {j_2}^2+{m_2}^2$  

which is non-zero unless $j_2 = 0$.  

What am I misunderstanding here? How do you show that eigenkets with different eigenvalues are orthogonal?
","The error is most likely that you are using 

$$\left&lt;j_1,j_2;m_1,m_2 \mid j&#39;_1,j&#39;_2;m&#39;_1,m&#39;_2\right&gt; = j_1j&#39;_1+j_2j&#39;_2+m_1m&#39;_1+m_2m&#39;_2,
\quad \mathrm{(Wrong!)}$$

where you should be using 

$$\left&lt;j_1,j_2;m_1,m_2 \mid j&#39;_1,j&#39;_2;m&#39;_1,m&#39;_2\right&gt; = \delta_{j_1,j&#39;_1}\delta_{j_2,j&#39;_2}\delta_{m_1,m&#39;_1}\delta_{m_2,m&#39;_2},$$

where $\delta_{k,\ell}$ is the Kronecker delta function. 

In other words, the $j$'s and $m$'s are not the coefficients $v^i$ of a vector $\vec{v}=\sum_i v^i \vec{e}_i$ in a Hilbert space, where $\vec{e}_i$ is an orthonormal basis, so that

$$ \left&lt;\vec{v}\mid\vec{v}&#39;\right&gt; =  \sum_i (v^i)^*v&#39;^i, \qquad \left&lt;\vec{e}_i\mid\vec{e}_{i&#39;}\right&gt; = \delta_{i,i&#39;}.
$$

Rather, the $j$'s and $m$'s correspond to the $i$-labels of the basis $\vec{e}_i$. For brevity, we often write $\left&lt; i \mid i&#39;\right&gt;$ instead of $\left&lt;\vec{e}_i\mid\vec{e}_{i&#39;}\right&gt;$.

Finally, to give a complete answer, let me include my comment above that it is a general property of eigenvectors for different eigenvalues of a Hermitian operator, that they are orthogonal to each other, see e.g., Lubos Motl's answer or here.
"
2338,2338,3727,how to set up wired and wireless to be used by different applications,"My wired interface (eth0) is connected to a corporate VPN (which disallows all sorts of things via a proxy) while at the same time the wireless interface is connected to a guest wireless network on eth1 which has no restrictions. 

How can I configure things (Ubuntu) in such a way that my wireless handles all browser connections while my wired handles the rest (nfs, etc.).
",c4urself,https://serverfault.com/users/130936,"Since you're using an Ubuntu desktop, I presume you're managing your connections with NetworkManager.

You will need to do two things:


Edit your Ethernet interface in NetworkManager, choose Routes and then select Use this connection only for resources on its network.
Add static routes here for all of the IP address ranges in use on your corporate network that you need to access. The gateway for these should be your current gateway IP address for the eth0 interface. You can obtain a list of these networks from your network admin staff.




Once you have completed this, all of your traffic will go out via your wireless connection unless it's on one of the networks you specified a static route for.

You will probably need to set up your browser as well, so that it only proxies traffic bound for IP address ranges inside the corporate network. Better yet, use two Firefox profiles: one for the corporate network and one for general Internet usage.

(Part of this answer, and the above image, borrowed from the Ask Ubuntu question Force network-manager to use wireless for an Internet connection.)
",Michael Hampton,https://serverfault.com/users/126632,http://serverfault.com/questions/527781,TECHNOLOGY,serverfault.com,1.0,0.7777777777777778,0.0,1.0,1.0,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,1.0,How to set up wired and wireless for different applications,"My wired interface (eth0) connects to a corporate VPN (it does not allow various operations through the proxy), while the wireless interface connects to an unlimited guest wireless network on eth1.","Since you're using an Ubuntu desktop, I presume you're managing your connections with NetworkManager.

You will need to do two things:


Edit your Ethernet interface in NetworkManager, choose Routes and then select Use this connection only for resources on its network.
Add static routes here for all of the IP address ranges in use on your corporate network that you need to access. The gateway for these should be your current gateway IP address for the eth0 interface. You can obtain a list of these networks from your network admin staff.




Once you have completed this, all of your traffic will go out via your wireless connection unless it's on one of the networks you specified a static route for.

You will probably need to set up your browser as well, so that it only proxies traffic bound for IP address ranges inside the corporate network. Better yet, use two Firefox profiles: one for the corporate network and one for general Internet usage.

(Part of this answer, and the above image, borrowed from the Ask Ubuntu question Force network-manager to use wireless for an Internet connection.)
"
5536,5536,8794,Can I connect iPad to computer so I can use iPad as a keyboard?,"The computer keys seem to be stuck after coffee was spilt. Only a mouthful but that seems to have done it. The computer switches on all right, but the keyboard doesn't work.

Can I use my I pad as a keyboard until I can check out the problem on laptop as I need to print off from my laptop.
",Paula marks,https://superuser.com/users/291789,"Short answer: Yes, you can use your iPad as a keyboard for your Mac or PC laptop.

Longer answer...

Dry out the laptop first

As Xavierjazz mentioned in a comment, make sure the laptop is completely dry before you try to use it.

The only way to be sure it is completely dry is to completely dismantle the laptop, wipe up any moisture you see, and allow all the components to dry for several days.  If you do not dry it, moisture could remain in place or wick further into the laptop and cause permanent damage.  You can use a vacuum to suck air out of crevices or low-velocity airflow from a fan, but do NOT use high-velocity air such as compressed air (which can push moisture further into crevices).  Although rice is widely recommended for drying out electronics, more recent studies have debunked its ability as a desiccant.

You might need to disconnect the built-in keyboard

If the keys are indeed stuck ""on"" then you may need to disconnect the laptop's keyboard cable from the motherboard in order to prevent the stuck keys from affecting the input from any other keyboard you try to use.  For example, if the laptop's Shift key is stuck ""on"" then anything you type on a different keyboard connected to the same laptop will be affected by the Shift key.

USB keyboard or iPad as a keyboard

Once you've gotten past that hurdle, the simplest solution is to use an USB keyboard.  However, you can also use a remote desktop app such as Splashtop, a keyboard app such as Air Keyboard, or any number of other apps that you can find by searching ""ipad as keyboard"" in Google.
",rob,https://superuser.com/users/6091,http://superuser.com/questions/704557,TECHNOLOGY,superuser.com,1.0,0.8888888888888888,0.0,1.0,1.0,1.0,0.8888888888888888,0.7777777777777778,0.3333333333333333,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.7777777777777778,1.0,0.8888888888888888,1.0,1.0,0.9333333333333332,0.3333333333333333,0.6666666666666666,0.0,1.0,Can I connect the iPad to the computer so that I can use the iPad as a keyboard?,"The computer key seems to be stuck after the coffee is spilt. Only one bite, but it seems to have been done. The computer is OK, but the keyboard is broken.","Short answer: Yes, you can use your iPad as a keyboard for your Mac or PC laptop.

Longer answer...

Dry out the laptop first

As Xavierjazz mentioned in a comment, make sure the laptop is completely dry before you try to use it.

The only way to be sure it is completely dry is to completely dismantle the laptop, wipe up any moisture you see, and allow all the components to dry for several days.  If you do not dry it, moisture could remain in place or wick further into the laptop and cause permanent damage.  You can use a vacuum to suck air out of crevices or low-velocity airflow from a fan, but do NOT use high-velocity air such as compressed air (which can push moisture further into crevices).  Although rice is widely recommended for drying out electronics, more recent studies have debunked its ability as a desiccant.

You might need to disconnect the built-in keyboard

If the keys are indeed stuck ""on"" then you may need to disconnect the laptop's keyboard cable from the motherboard in order to prevent the stuck keys from affecting the input from any other keyboard you try to use.  For example, if the laptop's Shift key is stuck ""on"" then anything you type on a different keyboard connected to the same laptop will be affected by the Shift key.

USB keyboard or iPad as a keyboard

Once you've gotten past that hurdle, the simplest solution is to use an USB keyboard.  However, you can also use a remote desktop app such as Splashtop, a keyboard app such as Air Keyboard, or any number of other apps that you can find by searching ""ipad as keyboard"" in Google.
"
1929,1929,3076,How do you prove $S=-\sum p\ln p$?,"How does one prove the formula for entropy $S=-\sum p\ln p$?
Obviously systems on the microscopic level are fully determined by the microscopic equations of motion. So if you want to introduce a law on top of that, you have to prove consistency, i.e. entropy cannot be a postulate.
I can imagine that it is derived from probability theory for general system. Do you know such a line?

Once you have such a reasoning, what are the assumptions to it?
Can these assumptions be invalid for special systems? Would these system not obey thermodynamics, statistical mechanics and not have any sort of temperature no matter how general?

If therodynamics/statmech are completely general, how would you apply them the system where one point particle orbits another?
",Gerenuk,https://physics.stackexchange.com/users/5152,"The functional form of the entropy $S = - \sum p \ln p$ can be understood if one requires that entropy is extensive, and depends on the microscopic state probabilities $p$.

Consider a system $S_{AB}$ composed of two independent subsystems A and B. Then $S_{AB} = S_A +S_B$ and $p_{AB} = p_A p_B$ since A and B are decoupled.

$$
S_{AB} = - \sum p_{AB} \ln p_{AB} = -\sum p_{A} \sum p_B \ln p_A  -\sum p_{A} \sum p_B \ln p_B
$$

$$
 = -\sum p_{A}  \ln p_A  - \sum p_B \ln p_B = S_A + S_B
$$
This argument is valid up to a factor, which turns out to be the Boltzmann constant $k_B$ in statistical mechanics: $S = - k_B \sum p \ln p$ which is due to Gibbs, long before Shannon. 
",Felix,https://physics.stackexchange.com/users/5912,http://physics.stackexchange.com/questions/14436/how-do-you-prove-s-sum-p-ln-p,SCIENCE,physics.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,0.6666666666666666,1.0,1.0,0.7777777777777778,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,0.8888888888888888,0.8666666666666666,1.0,0.0,0.6666666666666666,1.0,How to prove $s = - \ sum P \ ln p $?,"How does one prove the formula for entropy $S=-\sum p\ln p$?
Obviously systems on the microscopic level are fully determined by the microscopic equations of motion. So if you want to introduce a law on top of that, you have to prove consistency, i.e. entropy cannot be a postulate.
I can imagine that it is derived from probability theory for general system. Do you know such a line?

Once you have such a reasoning, what are the assumptions to it?
Can these assumptions be invalid for special systems? Would these system not obey thermodynamics, statistical mechanics and not have any sort of temperature no matter how general?

If therodynamics/statmech are completely general, how would you apply them the system where one point particle orbits another?
","The functional form of the entropy $S = - \sum p \ln p$ can be understood if one requires that entropy is extensive, and depends on the microscopic state probabilities $p$.

Consider a system $S_{AB}$ composed of two independent subsystems A and B. Then $S_{AB} = S_A +S_B$ and $p_{AB} = p_A p_B$ since A and B are decoupled.

$$
S_{AB} = - \sum p_{AB} \ln p_{AB} = -\sum p_{A} \sum p_B \ln p_A  -\sum p_{A} \sum p_B \ln p_B
$$

$$
 = -\sum p_{A}  \ln p_A  - \sum p_B \ln p_B = S_A + S_B
$$
This argument is valid up to a factor, which turns out to be the Boltzmann constant $k_B$ in statistical mechanics: $S = - k_B \sum p \ln p$ which is due to Gibbs, long before Shannon. 
"
703,703,1112,ListView OnItemClickListener is not listening,"I checked all the previous questions regarding this issue , but none of them are helpfull to me .

My listview is not responding  , i tried changing this
list.setOnItemClickListener(new ContactsListItemClickListener(this));

to 

list.setOnItemClickListener(this);

by making my PrioritiseContacts activity just imeplement OnItemClickListener , but then too its not working . 

The activity is successfully running , but i am unable to listen for listclick events. 

How to correct this? 

Here is my class : 

public class PrioritiseContacts extends Activity implements OnClickListener {

    private ListView list;
    // list of contacts with name
    private List&lt;Contacts&gt; contactsList;
    private Controller controll;
    private ContactListAdapters adapter;

    @Override
    public void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        setContentView(R.layout.select_contacts);

        controll = new Controller();
        contactsList = controll.fetchContacts(this);

        // call the adapter to set the list view layout
        adapter = new ContactListAdapters(contactsList, this);

        list = (ListView) findViewById(R.id.lv_contacts);
        // set the adapter to list
        list.setAdapter(adapter);
        list.setOnItemClickListener(new ContactsListItemClickListener(this));

        // inflate the list of contact
    }

    @Override
    public void onClick(View arg0) {
        Toast.makeText(this, ""clicked"", 1000).show();

    }

    class ContactsListItemClickListener implements OnItemClickListener {
        private Context c;

        public ContactsListItemClickListener(
                PrioritiseContacts prioritiseContacts) {
            this.c = prioritiseContacts;

        }

        @Override
        public void onItemClick(AdapterView&lt;?&gt; parent, View view, int position,
                long id) {
            Toast.makeText(c, ""Clicked"", 1500).show();
            System.out.print(""clicked"");
        }
    }
}


My select_contacts xml : 

&lt;LinearLayout xmlns:android=""http://schemas.android.com/apk/res/android""
    xmlns:tools=""http://schemas.android.com/tools""
    android:layout_width=""match_parent""
    android:layout_height=""match_parent""
    android:background=""#000000"" 
    android:orientation=""vertical""&gt;


    &lt;TextView
        android:id=""@+id/tv_select_contacts""
        android:layout_width=""match_parent""
        android:layout_height=""wrap_content""
        android:layout_margin=""5dp""
        android:text=""Choose Contacts""
        android:textColor=""#fdfdfd""
        android:textSize=""30dip""
        android:gravity=""center"" &gt;
    &lt;/TextView&gt;


    &lt;ListView
        android:id=""@+id/lv_contacts""
        android:layout_width=""match_parent""
        android:layout_height=""match_parent""
        android:layout_margin=""5dp""
        android:cacheColorHint=""#00000000""
        android:clickable=""true""
        android:focusable=""true""
        android:divider=""@android:color/transparent""
        android:dividerHeight=""10.0sp""
        android:scrollbars=""none"" &gt;
    &lt;/ListView&gt;

&lt;/LinearLayout&gt;


And this is my adapter's getview() : 

@Override
    public View getView(int position, View convertView, ViewGroup parent) {
        View view = convertView;

        // layout infklater to inflate the post list view
        LayoutInflater inflater = (LayoutInflater) context
                .getSystemService(Activity.LAYOUT_INFLATER_SERVICE);

        if (convertView == null) {
            view = inflater.inflate(R.layout.contacts_list_view, null);
        }

        Contacts c = contactList.get(position);

        // set text views in contact lists
        // Typeface custom_font =
        // Typeface.createFromAsset(context.getAssets(),""fonts/calibril.ttf"");
        TextView name = (TextView) view.findViewById(R.id.tv_contact_name);
        // date.setTypeface(custom_font);
        name.setText(c.getName());

        TextView number = (TextView) view.findViewById(R.id.tv_number);
        // title.setTypeface(custom_font);
        number.setText(c.getPhone());

        ImageView contact_image = (ImageView) view.findViewById(R.id.iv_single_contact);
        // hut.setTypeface(custom_font);
        if(c.getContactImage() != null)
        contact_image.setImageBitmap(c.getContactImage());
        else
            contact_image.setImageDrawable(view.getResources().getDrawable(R.drawable.ic_contact_picture_2));


        return view;
    }


My contacts_list_view xml : 

&lt;?xml version=""1.0"" encoding=""utf-8""?&gt;
    &lt;LinearLayout xmlns:android=""http://schemas.android.com/apk/res/android""
        android:id=""@+id/rl_post_list""
        android:layout_width=""match_parent""
        android:layout_height=""50dip""
        android:background=""#000000""
        android:gravity=""left""
        android:orientation=""horizontal""
        android:paddingBottom=""2dp""
        android:paddingTop=""2dp"" &gt;
        &lt;ImageView
            android:id=""@+id/iv_single_contact""
            android:layout_width=""70dp""
            android:layout_height=""fill_parent""
            android:layout_weight=""0.05""
            android:padding=""2dp"" /&gt;
        &lt;LinearLayout
            android:layout_width=""wrap_content""
            android:layout_height=""wrap_content""
            android:layout_weight=""0.87""
            android:orientation=""vertical"" &gt;
            &lt;TextView
                android:id=""@+id/tv_contact_name""
                android:layout_width=""match_parent""
                android:layout_height=""wrap_content""
                android:background=""#000000""
                android:gravity=""left""
                android:paddingLeft=""2dp""
                android:text=""Contact Name""
                android:textColor=""#fdfbfb""
                android:textStyle=""bold"" /&gt;
            &lt;View style=""@style/Divider"" /&gt;
            &lt;TextView
                android:id=""@+id/tv_number""
                android:layout_width=""wrap_content""
                android:layout_height=""wrap_content""
                android:fontFamily=""sans-serif-thin""
                android:gravity=""left""
                android:text=""this is number""
                android:textColor=""#fdfbfb""
                android:textSize=""10dp""
                android:textStyle=""bold"" /&gt;


        &lt;/LinearLayout&gt;
        &lt;CheckBox
            android:id=""@+id/cb_contact""
            android:layout_width=""70dp""
            android:layout_height=""fill_parent""
            android:layout_weight=""0.05""
            android:padding=""2dp"" /&gt;


    &lt;/LinearLayout&gt;

",Divyanshu Jimmy,https://stackoverflow.com/users/2442565,"If any row item of list contains focusable or clickable view then OnItemClickListener won't work such as for checkbox or button etc in the row item.There are two solution:

1. row item must be having param like android:descendantFocusability=""blocksDescendants""

&lt;LinearLayout xmlns:android=""http://schemas.android.com/apk/res/android""
    android:layout_width=""match_parent""
    android:layout_height=""wrap_content""
    android:baselineAligned=""false""
    android:descendantFocusability=""blocksDescendants""
    android:gravity=""center_vertical"" &gt;

    // your other widgets here

&lt;/LinearLayout&gt;


2. Set given two attributes to false
like

 android:focusable=""false""
   android:focusableInTouchMode=""false""


For example if there is any checkbox or button or image in the row item then

&lt;CheckBox
    android:id=""@+id/fav_check_box""
    android:layout_width=""wrap_content""
    android:layout_height=""wrap_content""
    android:focusable=""false"" /&gt;

",setu basak,https://stackoverflow.com/users/4299527,http://stackoverflow.com/questions/28930125/listview-onitemclicklistener-is-not-listening,STACKOVERFLOW,stackoverflow.com,0.6666666666666666,0.5,0.0,0.5,1.0,0.5,0.6666666666666666,0.5,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.5,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.8,1.0,0.5,1.0,0.8333333333333334,Listview onemclicklistener is not listening,"I checked all the previous questions regarding this issue , but none of them are helpfull to me .

My listview is not responding  , i tried changing this
list.setOnItemClickListener(new ContactsListItemClickListener(this));

to 

list.setOnItemClickListener(this);

by making my PrioritiseContacts activity just imeplement OnItemClickListener , but then too its not working . 

The activity is successfully running , but i am unable to listen for listclick events. 

How to correct this? 

Here is my class : 

public class PrioritiseContacts extends Activity implements OnClickListener {

    private ListView list;
    // list of contacts with name
    private List&lt;Contacts&gt; contactsList;
    private Controller controll;
    private ContactListAdapters adapter;

    @Override
    public void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        setContentView(R.layout.select_contacts);

        controll = new Controller();
        contactsList = controll.fetchContacts(this);

        // call the adapter to set the list view layout
        adapter = new ContactListAdapters(contactsList, this);

        list = (ListView) findViewById(R.id.lv_contacts);
        // set the adapter to list
        list.setAdapter(adapter);
        list.setOnItemClickListener(new ContactsListItemClickListener(this));

        // inflate the list of contact
    }

    @Override
    public void onClick(View arg0) {
        Toast.makeText(this, ""clicked"", 1000).show();

    }

    class ContactsListItemClickListener implements OnItemClickListener {
        private Context c;

        public ContactsListItemClickListener(
                PrioritiseContacts prioritiseContacts) {
            this.c = prioritiseContacts;

        }

        @Override
        public void onItemClick(AdapterView&lt;?&gt; parent, View view, int position,
                long id) {
            Toast.makeText(c, ""Clicked"", 1500).show();
            System.out.print(""clicked"");
        }
    }
}


My select_contacts xml : 

&lt;LinearLayout xmlns:android=""http://schemas.android.com/apk/res/android""
    xmlns:tools=""http://schemas.android.com/tools""
    android:layout_width=""match_parent""
    android:layout_height=""match_parent""
    android:background=""#000000"" 
    android:orientation=""vertical""&gt;


    &lt;TextView
        android:id=""@+id/tv_select_contacts""
        android:layout_width=""match_parent""
        android:layout_height=""wrap_content""
        android:layout_margin=""5dp""
        android:text=""Choose Contacts""
        android:textColor=""#fdfdfd""
        android:textSize=""30dip""
        android:gravity=""center"" &gt;
    &lt;/TextView&gt;


    &lt;ListView
        android:id=""@+id/lv_contacts""
        android:layout_width=""match_parent""
        android:layout_height=""match_parent""
        android:layout_margin=""5dp""
        android:cacheColorHint=""#00000000""
        android:clickable=""true""
        android:focusable=""true""
        android:divider=""@android:color/transparent""
        android:dividerHeight=""10.0sp""
        android:scrollbars=""none"" &gt;
    &lt;/ListView&gt;

&lt;/LinearLayout&gt;


And this is my adapter's getview() : 

@Override
    public View getView(int position, View convertView, ViewGroup parent) {
        View view = convertView;

        // layout infklater to inflate the post list view
        LayoutInflater inflater = (LayoutInflater) context
                .getSystemService(Activity.LAYOUT_INFLATER_SERVICE);

        if (convertView == null) {
            view = inflater.inflate(R.layout.contacts_list_view, null);
        }

        Contacts c = contactList.get(position);

        // set text views in contact lists
        // Typeface custom_font =
        // Typeface.createFromAsset(context.getAssets(),""fonts/calibril.ttf"");
        TextView name = (TextView) view.findViewById(R.id.tv_contact_name);
        // date.setTypeface(custom_font);
        name.setText(c.getName());

        TextView number = (TextView) view.findViewById(R.id.tv_number);
        // title.setTypeface(custom_font);
        number.setText(c.getPhone());

        ImageView contact_image = (ImageView) view.findViewById(R.id.iv_single_contact);
        // hut.setTypeface(custom_font);
        if(c.getContactImage() != null)
        contact_image.setImageBitmap(c.getContactImage());
        else
            contact_image.setImageDrawable(view.getResources().getDrawable(R.drawable.ic_contact_picture_2));


        return view;
    }


My contacts_list_view xml : 

&lt;?xml version=""1.0"" encoding=""utf-8""?&gt;
    &lt;LinearLayout xmlns:android=""http://schemas.android.com/apk/res/android""
        android:id=""@+id/rl_post_list""
        android:layout_width=""match_parent""
        android:layout_height=""50dip""
        android:background=""#000000""
        android:gravity=""left""
        android:orientation=""horizontal""
        android:paddingBottom=""2dp""
        android:paddingTop=""2dp"" &gt;
        &lt;ImageView
            android:id=""@+id/iv_single_contact""
            android:layout_width=""70dp""
            android:layout_height=""fill_parent""
            android:layout_weight=""0.05""
            android:padding=""2dp"" /&gt;
        &lt;LinearLayout
            android:layout_width=""wrap_content""
            android:layout_height=""wrap_content""
            android:layout_weight=""0.87""
            android:orientation=""vertical"" &gt;
            &lt;TextView
                android:id=""@+id/tv_contact_name""
                android:layout_width=""match_parent""
                android:layout_height=""wrap_content""
                android:background=""#000000""
                android:gravity=""left""
                android:paddingLeft=""2dp""
                android:text=""Contact Name""
                android:textColor=""#fdfbfb""
                android:textStyle=""bold"" /&gt;
            &lt;View style=""@style/Divider"" /&gt;
            &lt;TextView
                android:id=""@+id/tv_number""
                android:layout_width=""wrap_content""
                android:layout_height=""wrap_content""
                android:fontFamily=""sans-serif-thin""
                android:gravity=""left""
                android:text=""this is number""
                android:textColor=""#fdfbfb""
                android:textSize=""10dp""
                android:textStyle=""bold"" /&gt;


        &lt;/LinearLayout&gt;
        &lt;CheckBox
            android:id=""@+id/cb_contact""
            android:layout_width=""70dp""
            android:layout_height=""fill_parent""
            android:layout_weight=""0.05""
            android:padding=""2dp"" /&gt;


    &lt;/LinearLayout&gt;

","If any row item of list contains focusable or clickable view then OnItemClickListener won't work such as for checkbox or button etc in the row item.There are two solution:

1. row item must be having param like android:descendantFocusability=""blocksDescendants""

&lt;LinearLayout xmlns:android=""http://schemas.android.com/apk/res/android""
    android:layout_width=""match_parent""
    android:layout_height=""wrap_content""
    android:baselineAligned=""false""
    android:descendantFocusability=""blocksDescendants""
    android:gravity=""center_vertical"" &gt;

    // your other widgets here

&lt;/LinearLayout&gt;


2. Set given two attributes to false
like

 android:focusable=""false""
   android:focusableInTouchMode=""false""


For example if there is any checkbox or button or image in the row item then

&lt;CheckBox
    android:id=""@+id/fav_check_box""
    android:layout_width=""wrap_content""
    android:layout_height=""wrap_content""
    android:focusable=""false"" /&gt;

"
3894,3894,6202,Negatively curved metrics minimizing the length of a homotopy class of simple closed curves,"Good afternoon everyone !

I have the following question of Riemannian geometry :

Let $M$ be a smooth closed orientable manifold of dimension at least $3$, and let $\mathcal{T} = \{ $ smooth Riemannian metric on $M$ with sectional curvature pinched between $-1- \epsilon$ and $-1$ $\}$ where $\epsilon$ is an arbitrary positive number. Assume that $\mathcal{T}$ is non-empty.

Let $\gamma $ be a simple closed curve in $M$. It is classical that for every negatively curved metric $g$ there is a unique closed curve in the free homotopy class of $\gamma$ that is length minimizing. Note $L_g(\gamma)$ the length of such a curve.

1) Is it known whether $ \inf_{g \in \mathcal{T} }{L_g(\gamma)}$ is positive or zero ?

2) Is it known whether $ \sup_{g \in \mathcal{T} }{L_g(\gamma)}$ is finite or infinite ? 

3) Can one say more in specific cases, say when $M$ is hyperbolic ?

Obviously in dimension 2 Fenchel Nielsen coordinates show that $ \inf_{g \in \mathcal{T} }{L_g(\gamma)}$ is zero and  $ \sup_{g \in \mathcal{T} }{L_g(\gamma)}$ is infinite. Nonetheless, the lack of topological symmetries for higher-dimensional hyperbolic manifolds make me hope that the opposite might be true.

Thanks for your attention !
",Selim G,https://mathoverflow.net/users/25511,"We have $0&lt;\inf_{g\in \mathcal{T}} L_g(\gamma) \leq \sup_{g\in \mathcal{T}} L_g(\gamma) &lt;\infty$. In fact, there should be a universal bound on the ratio
$\sup_{g\in \mathcal{T}} L_g(\gamma)/ \inf_{g\in \mathcal{T}} L_g(\gamma)$ for all $\gamma \in \pi_1 M$.

This follows from a theorem of Belegradek, who proves that the class of such metrics (actually, with just a fixed fundamental group $\pi$) is precompact in the Lipschitz topology. In particular, all such metrics are uniformly bi-Lipschitz, and thus one has the bound on the ratio between maximal and minimal lengths, as well as absolute bounds. 

Quoting from the paper: 
Recall that the class of all compact Riemannian manifolds of a given dimension
has the so-called Lipschitz topology, namely, two manifolds $M$ and $N$ are said to be
$\epsilon$-close if there exists a diffeomorphism $f : M → N$ such that both $f$ and $f^{−1}$ are
$e^\epsilon$-Lipschitz. A class of manifolds is called precompact if for any positive $\epsilon$, every
sequence of manifolds in the class has a subsequence whose members are mutually
$\epsilon$-close. 

Now, suppose there is no upper bound $C$ so that any two metric $g,h\in \mathcal{T}$ are $C$-close. Take sequences $g_i,h_i\in \mathcal{T}$, such
that $g_i$ and $h_i$ are not $N_i$-close, for a sequence $N_i\to \infty$. Passing to subsequences, we may assume that $\{g_i\}$ are mutually $\delta$-close for any $\delta&gt;0$, and similarly for $\{h_i\}$. But $g_i$ is $\delta$-close to $g_1$, which is $C$-close to $h_1$ for some $C$ (since these are metrics on the same manifold), and which is $\delta$-close to $h_i$ for all $i$. Thus, $g_i$ is $2\delta+C$-close to $h_i$ for all $i$, a contradiction. 

So we see that any two metrics in $\mathcal{T}$ are $C$-close for some $C$. This implies that $\sup_{g\in \mathcal{T}} L_g(\gamma)/ \inf_{g\in \mathcal{T}} L_g(\gamma)\leq e^C$ for all $\gamma \in \pi_1 M$. Moreover, comparing to any fixed metric in $\mathcal{T}$, we see that $0&lt;\inf_{g\in \mathcal{T}} L_g(\gamma) \leq \sup_{g\in \mathcal{T}} L_g(\gamma) &lt;\infty$.
",Ian Agol,https://mathoverflow.net/users/1345,http://mathoverflow.net/questions/203422,SCIENCE,mathoverflow.net,0.7777777777777778,0.4444444444444444,0.0,0.3333333333333333,1.0,1.0,0.7777777777777778,0.4444444444444444,0.3333333333333333,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,1.0,0.0,0.7777777777777778,0.7777777777777778,0.6666666666666666,0.8888888888888888,0.8888888888888888,0.8666666666666666,1.0,0.3333333333333333,1.0,0.8888888888888888,A negative curve measure to minimize the homotopy length of a class of simple closed curves,"Good afternoon everyone !

I have the following question of Riemannian geometry :

Let $M$ be a smooth closed orientable manifold of dimension at least $3$, and let $\mathcal{T} = \{ $ smooth Riemannian metric on $M$ with sectional curvature pinched between $-1- \epsilon$ and $-1$ $\}$ where $\epsilon$ is an arbitrary positive number. Assume that $\mathcal{T}$ is non-empty.

Let $\gamma $ be a simple closed curve in $M$. It is classical that for every negatively curved metric $g$ there is a unique closed curve in the free homotopy class of $\gamma$ that is length minimizing. Note $L_g(\gamma)$ the length of such a curve.

1) Is it known whether $ \inf_{g \in \mathcal{T} }{L_g(\gamma)}$ is positive or zero ?

2) Is it known whether $ \sup_{g \in \mathcal{T} }{L_g(\gamma)}$ is finite or infinite ? 

3) Can one say more in specific cases, say when $M$ is hyperbolic ?

Obviously in dimension 2 Fenchel Nielsen coordinates show that $ \inf_{g \in \mathcal{T} }{L_g(\gamma)}$ is zero and  $ \sup_{g \in \mathcal{T} }{L_g(\gamma)}$ is infinite. Nonetheless, the lack of topological symmetries for higher-dimensional hyperbolic manifolds make me hope that the opposite might be true.

Thanks for your attention !
","We have $0&lt;\inf_{g\in \mathcal{T}} L_g(\gamma) \leq \sup_{g\in \mathcal{T}} L_g(\gamma) &lt;\infty$. In fact, there should be a universal bound on the ratio
$\sup_{g\in \mathcal{T}} L_g(\gamma)/ \inf_{g\in \mathcal{T}} L_g(\gamma)$ for all $\gamma \in \pi_1 M$.

This follows from a theorem of Belegradek, who proves that the class of such metrics (actually, with just a fixed fundamental group $\pi$) is precompact in the Lipschitz topology. In particular, all such metrics are uniformly bi-Lipschitz, and thus one has the bound on the ratio between maximal and minimal lengths, as well as absolute bounds. 

Quoting from the paper: 
Recall that the class of all compact Riemannian manifolds of a given dimension
has the so-called Lipschitz topology, namely, two manifolds $M$ and $N$ are said to be
$\epsilon$-close if there exists a diffeomorphism $f : M → N$ such that both $f$ and $f^{−1}$ are
$e^\epsilon$-Lipschitz. A class of manifolds is called precompact if for any positive $\epsilon$, every
sequence of manifolds in the class has a subsequence whose members are mutually
$\epsilon$-close. 

Now, suppose there is no upper bound $C$ so that any two metric $g,h\in \mathcal{T}$ are $C$-close. Take sequences $g_i,h_i\in \mathcal{T}$, such
that $g_i$ and $h_i$ are not $N_i$-close, for a sequence $N_i\to \infty$. Passing to subsequences, we may assume that $\{g_i\}$ are mutually $\delta$-close for any $\delta&gt;0$, and similarly for $\{h_i\}$. But $g_i$ is $\delta$-close to $g_1$, which is $C$-close to $h_1$ for some $C$ (since these are metrics on the same manifold), and which is $\delta$-close to $h_i$ for all $i$. Thus, $g_i$ is $2\delta+C$-close to $h_i$ for all $i$, a contradiction. 

So we see that any two metrics in $\mathcal{T}$ are $C$-close for some $C$. This implies that $\sup_{g\in \mathcal{T}} L_g(\gamma)/ \inf_{g\in \mathcal{T}} L_g(\gamma)\leq e^C$ for all $\gamma \in \pi_1 M$. Moreover, comparing to any fixed metric in $\mathcal{T}$, we see that $0&lt;\inf_{g\in \mathcal{T}} L_g(\gamma) \leq \sup_{g\in \mathcal{T}} L_g(\gamma) &lt;\infty$.
"
4035,4035,6443,"Why do some programmers categorize C, Python, C++ differently? - regarding level","I am taking an introductory course on python and the instructor says that python is a high level language and C and C++ are low level languages. It's just damn confusing. I thought that C, C++, Python, Java, etc were all high level languages. I was reading questions at stackoverflow on C, C++, etc and they all seem to refer to those languages as high level. it seems to me that some programmers use those terms interchangably. Please clarify this for me.
",atheistlearner,https://programmers.stackexchange.com/users/66433,"The line between the ""low-level"" and the ""high-level"" languages shifts from time to time.
For example:
Back in the days of UNIX, C was a high level language.
Today C doesn't have the structures like the mapping types(dictionaries), iterators etc. which today's high-level languages like Python have. So the line has shifted, and C has now fallen into the low-level group.

Low-Level Languages:
These languages are ""close"" to what the machine can execute (the lowest level being : Assembly Code!).
When working with these languages, the programmer has to think about the lowest level stuff like memory management.. You are close in that sense to the hardware, that you have to directly work with it.

High-level Languages:
These languages take you away from the hardware, as they manage things like memory themselves. When you work with these languages, memory is a factor(obviously), but you don't work with the hardware directly. Instead the language manages that, keeping you away (maybe higher) from the lower, hardware interface.
",pradyunsg,https://programmers.stackexchange.com/users/83274,http://programmers.stackexchange.com/questions/196996/why-do-some-programmers-categorize-c-python-c-differently-regarding-level,TECHNOLOGY,programmers.stackexchange.com,1.0,0.5555555555555556,0.0,0.0,1.0,0.3333333333333333,0.4444444444444444,0.5555555555555556,0.0,0.0,0.6666666666666666,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,0.6666666666666666,1.0,"Why do some programmers classify C, Python and C + + differently? -About levels","I'm introducing the introductory course of Python. The lecturer said that Python is a high-level language, and C and C + + are low-level languages. I can't fucking understand. I think C, C + +, python, Java and so on are all high-level languages. I read in C, C + +, and so on. They all seem to call these languages high-level languages. In my opinion, some programmers seem to be able to use these terms in exchange. Please clarify for me.","The line between the ""low-level"" and the ""high-level"" languages shifts from time to time.
For example:
Back in the days of UNIX, C was a high level language.
Today C doesn't have the structures like the mapping types(dictionaries), iterators etc. which today's high-level languages like Python have. So the line has shifted, and C has now fallen into the low-level group.

Low-Level Languages:
These languages are ""close"" to what the machine can execute (the lowest level being : Assembly Code!).
When working with these languages, the programmer has to think about the lowest level stuff like memory management.. You are close in that sense to the hardware, that you have to directly work with it.

High-level Languages:
These languages take you away from the hardware, as they manage things like memory themselves. When you work with these languages, memory is a factor(obviously), but you don't work with the hardware directly. Instead the language manages that, keeping you away (maybe higher) from the lower, hardware interface.
"
5036,5036,8015,How can I open a window on a different monitor?,"With multiple monitors, I have so far been dragging windows manually around. Is there a way to make a window open on a specific screen in a dual-head setup? (Not to be confused with multiple X server displays.)

Something like: SCREEN=2 firefox or open-in-screen 2 firefox.

If it matters, my environment is KDE using the KWin window manager. KWin window rules can only match some properties like title, but I could not find an environment variable as filter.

The secondary display extends the primary screen:

$ xrandr -q
Screen 0: minimum 320 x 200, current 3520 x 1080, maximum 32767 x 32767
LVDS1 connected 1600x900+0+0 (normal left inverted right x axis y axis) 382mm x 214mm
   1600x900       60.1*+
   1024x768       60.0  
   800x600        60.3     56.2  
   640x480        59.9  
VGA1 disconnected (normal left inverted right x axis y axis)
HDMI1 connected 1920x1080+1600+0 (normal left inverted right x axis y axis) 477mm x 268mm
   1920x1080      60.0*    50.0     59.9  
   1920x1080i     60.1     50.0     60.0  
   1680x1050      59.9  
   1280x1024      75.0     60.0  
   1440x900       59.9  
   1280x960       60.0  
   1280x720       60.0     50.0     59.9  
   1024x768       75.1     70.1     60.0  
   832x624        74.6  
   800x600        72.2     75.0     60.3     56.2  
   720x576        50.0  
   720x480        60.0     59.9  
   640x480        75.0     72.8     66.7     60.0     59.9  
   720x400        70.1  
DP1 disconnected (normal left inverted right x axis y axis)

",Lekensteyn,https://unix.stackexchange.com/users/8250,"This depends on how your dual-monitors are setup. 

If you are using XINERAMA to make both displays look like one to X, then you would use the -geometry option to ask applications to appear at a specific location. If you have the displays setup as different screens then you will use the DISPLAY to achieve this. 

Give these a try:

$ DISPLAY=0.0 xterm &amp;
$ DISPLAY=0.1 xterm &amp;


If your monitors are screen 0 and 1, this should spawn an xterm on each monitor.  
",casey,https://unix.stackexchange.com/users/53706,http://unix.stackexchange.com/questions/106793/how-can-i-open-a-window-on-a-different-monitor,TECHNOLOGY,unix.stackexchange.com,0.8888888888888888,0.7777777777777778,0.0,0.6666666666666666,1.0,1.0,0.6666666666666666,0.5555555555555556,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,0.8888888888888888,0.8666666666666666,1.0,0.3333333333333333,0.3333333333333333,0.8888888888888888,How do I open windows on different displays?,"With multiple monitors, I have so far been dragging windows manually around. Is there a way to make a window open on a specific screen in a dual-head setup? (Not to be confused with multiple X server displays.)

Something like: SCREEN=2 firefox or open-in-screen 2 firefox.

If it matters, my environment is KDE using the KWin window manager. KWin window rules can only match some properties like title, but I could not find an environment variable as filter.

The secondary display extends the primary screen:

$ xrandr -q
Screen 0: minimum 320 x 200, current 3520 x 1080, maximum 32767 x 32767
LVDS1 connected 1600x900+0+0 (normal left inverted right x axis y axis) 382mm x 214mm
   1600x900       60.1*+
   1024x768       60.0  
   800x600        60.3     56.2  
   640x480        59.9  
VGA1 disconnected (normal left inverted right x axis y axis)
HDMI1 connected 1920x1080+1600+0 (normal left inverted right x axis y axis) 477mm x 268mm
   1920x1080      60.0*    50.0     59.9  
   1920x1080i     60.1     50.0     60.0  
   1680x1050      59.9  
   1280x1024      75.0     60.0  
   1440x900       59.9  
   1280x960       60.0  
   1280x720       60.0     50.0     59.9  
   1024x768       75.1     70.1     60.0  
   832x624        74.6  
   800x600        72.2     75.0     60.3     56.2  
   720x576        50.0  
   720x480        60.0     59.9  
   640x480        75.0     72.8     66.7     60.0     59.9  
   720x400        70.1  
DP1 disconnected (normal left inverted right x axis y axis)

","This depends on how your dual-monitors are setup. 

If you are using XINERAMA to make both displays look like one to X, then you would use the -geometry option to ask applications to appear at a specific location. If you have the displays setup as different screens then you will use the DISPLAY to achieve this. 

Give these a try:

$ DISPLAY=0.0 xterm &amp;
$ DISPLAY=0.1 xterm &amp;


If your monitors are screen 0 and 1, this should spawn an xterm on each monitor.  
"
4343,4343,6918,How do I make certain areas editable?,"I'm new to wordpress and I'm currently converting an HTML/CSS site I made to wordpress to make it easier for my client to edit it from the admin panel.

I have provided 3 screenshots and I'll refer to them here.

The first screenshot shows how my website looks so far. It's using a template I made called homepage.php (see screenshot 3 for code). The template includes header.php which contains the logo, navigation menu etc. It has the image banner and finally includes footer.php. I want the ""Our Values"" part to be editable so that my client can change the text any time they need to. 

Currently, they can edit the top part which says ""PROtential Coaching"" and that's because it's included on the page within the admin panel and not in the template. I want the bottom part including""Our Values"" to be editable from that panel too, is there a way to do this or does this content have to be static and within the template? ""Our Values"" and ""Our People"" are in a dynamic secondary navigation menu which my client can add items to if they want to, however they can't change the content for the menu item.

Images:
http://imgur.com/yq9y8SQ,5IqOPzr,SHkzrFz

Please help me out guys, I've been looking all over the place for days to get this done.
",Jamie O'Hanlon,https://wordpress.stackexchange.com/users/31205,"I would recommend installing the Advanced Custom Fields plugin 

in order to achieve the desired functionality. Once you download it, create a few fields. For example, create a field called ""footer_text"" and print it like this:

&lt;?php the_field('footer_text'); ?&gt;


and so on with the rest of the fields.
",Johann,https://wordpress.stackexchange.com/users/21245,http://wordpress.stackexchange.com/questions/95182/how-do-i-make-certain-areas-editable,TECHNOLOGY,wordpress.stackexchange.com,0.7777777777777778,0.4444444444444444,0.0,0.6666666666666666,1.0,0.3333333333333333,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.7777777777777778,1.0,0.5555555555555556,1.0,1.0,0.8666666666666666,1.0,0.0,0.0,1.0,How do I make certain areas editable?,"I'm new to wordpress and I'm currently converting an HTML/CSS site I made to wordpress to make it easier for my client to edit it from the admin panel.

I have provided 3 screenshots and I'll refer to them here.

The first screenshot shows how my website looks so far. It's using a template I made called homepage.php (see screenshot 3 for code). The template includes header.php which contains the logo, navigation menu etc. It has the image banner and finally includes footer.php. I want the ""Our Values"" part to be editable so that my client can change the text any time they need to. 

Currently, they can edit the top part which says ""PROtential Coaching"" and that's because it's included on the page within the admin panel and not in the template. I want the bottom part including""Our Values"" to be editable from that panel too, is there a way to do this or does this content have to be static and within the template? ""Our Values"" and ""Our People"" are in a dynamic secondary navigation menu which my client can add items to if they want to, however they can't change the content for the menu item.

Images:
http://imgur.com/yq9y8SQ,5IqOPzr,SHkzrFz

Please help me out guys, I've been looking all over the place for days to get this done.
","I would recommend installing the Advanced Custom Fields plugin 

in order to achieve the desired functionality. Once you download it, create a few fields. For example, create a field called ""footer_text"" and print it like this:

&lt;?php the_field('footer_text'); ?&gt;


and so on with the rest of the fields.
"
438,438,678,Why choose an 80-200mm over an 18-200mm lens?,"Being a beginner, I can't see why I must choose an 80-200 over an 18-200. Are there scenarios where an 80-200 would be preferable over an 18-200?

I will be buying a D7000 soon and am looking at these:


AF Zoom-NIKKOR 80-200mm f/2.8D ED
AF-S DX NIKKOR 18-200mm f/3.5-5.6G ED VR II


but similar considerations would apply to other brands as well.
",Ygam,https://photo.stackexchange.com/users/2362,"Optically a lot superior.
Constant 2.8 aperture up-to 200mm focal length.
Sharp as a razor across the zoom range.
Superior bokeh.
Better build quality.
Faster AF (assuming you buy the AF-S version).
Performs much better on Full Frame.
",ben,https://photo.stackexchange.com/users/4246,http://photo.stackexchange.com/questions/11247/why-choose-an-80-200mm-over-an-18-200mm-lens,LIFE_ARTS,photo.stackexchange.com,1.0,0.7777777777777778,0.0,0.0,1.0,0.6666666666666666,0.8888888888888888,0.7777777777777778,0.3333333333333333,0.0,0.6666666666666666,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.0,1.0,0.7777777777777778,Why 80-200mm instead of 18-200mm?,"Being a beginner, I can't see why I must choose an 80-200 over an 18-200. Are there scenarios where an 80-200 would be preferable over an 18-200?

I will be buying a D7000 soon and am looking at these:


AF Zoom-NIKKOR 80-200mm f/2.8D ED
AF-S DX NIKKOR 18-200mm f/3.5-5.6G ED VR II


but similar considerations would apply to other brands as well.
","Optically a lot superior.
Constant 2.8 aperture up-to 200mm focal length.
Sharp as a razor across the zoom range.
Superior bokeh.
Better build quality.
Faster AF (assuming you buy the AF-S version).
Performs much better on Full Frame.
"
2013,2013,3211,Are there any publicly available databases ( not just web apps ) of guitar chords?,"I need guitar chords in a database for a project I'm working on ( preferably MySQL, CSV or some other easily portable format ). I can imagine many formats by which one could store this information, so I don't particularly care how it's setup.

This information must exist in databases all over the internet, but is there anything freely and publicly available?
",T. Brian Jones,https://music.stackexchange.com/users/2340,"A quick google of ""downloadable guitar chords"" took me to the Chordpda site. It is an app for windows mobile devices but it has an XML database of chords so that would be simple to use.

Free and downloadable - I'm giving no assurances as to how good it is, but there must be more - that was just a 5 second google search.
",Dr Mayhem,https://music.stackexchange.com/users/104,http://music.stackexchange.com/questions/6173/are-there-any-publicly-available-databases-not-just-web-apps-of-guitar-chord,LIFE_ARTS,music.stackexchange.com,1.0,0.8888888888888888,0.0,1.0,1.0,0.3333333333333333,0.4444444444444444,0.5555555555555556,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.0,0.0,1.0,Is there a public database of guitar chords (not just web applications)?,"I need guitar chords in a database for a project I am working on (preferably mysql, CSV or some other easy to port format). I can imagine that there are many formats for storing this information, so I don't particularly care how it's set up.","A quick google of ""downloadable guitar chords"" took me to the Chordpda site. It is an app for windows mobile devices but it has an XML database of chords so that would be simple to use.

Free and downloadable - I'm giving no assurances as to how good it is, but there must be more - that was just a 5 second google search.
"
714,714,1131,Is there a quick way to delete Foldered bookmarks directly from Safari bookmark bar?,"I like to group my bookmarks into Folders in the Bookmark Bar.

But I cannot find an easy way to delete these bookmarks!

The only way I know to do this is to go to Show All Bookmarks, then browse down to the shortcut and select it and delete it - this totally gets in the way of workflow.

Is there any way to delete a Foldered bookmark from the bookmark bar?!

NB - I am not talking about standalone bookmarks, deleting those is easy and intuitive.
",dan8394,https://apple.stackexchange.com/users/8394,"Hit option+command+B. It will open a bookmark editor; it's very easy to delete anything within a folder from there.
",Helper,https://apple.stackexchange.com/users/66976,http://apple.stackexchange.com/questions/22042/is-there-a-quick-way-to-delete-foldered-bookmarks-directly-from-safari-bookmark,TECHNOLOGY,apple.stackexchange.com,1.0,1.0,0.0,1.0,1.0,1.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,1.0,0.7777777777777778,0.5555555555555556,1.0,0.8888888888888888,0.8,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.8888888888888888,Is there a quick way to remove folded bookmarks directly from the safari bookmarks bar?,"I like to group my bookmarks into Folders in the Bookmark Bar.

But I cannot find an easy way to delete these bookmarks!

The only way I know to do this is to go to Show All Bookmarks, then browse down to the shortcut and select it and delete it - this totally gets in the way of workflow.

Is there any way to delete a Foldered bookmark from the bookmark bar?!

NB - I am not talking about standalone bookmarks, deleting those is easy and intuitive.
","Hit option+command+B. It will open a bookmark editor; it's very easy to delete anything within a folder from there.
"
4397,4397,6987,C compiler supported by Windows 7,"I'm having a problem finding which compiler can support Windows7 for C or C++ programming.
I had installed Turbo but it does not work in full screen on Windows 7.
Please let me know which compiler will be appropriate.
",shruti bansal,https://superuser.com/users/52642,"lcc-win32 is a free compiler for Windows.
",vtest,https://superuser.com/users/38596,http://superuser.com/questions/200435,TECHNOLOGY,superuser.com,0.6666666666666666,0.4444444444444444,0.3333333333333333,1.0,0.6666666666666666,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.8,0.0,0.0,0.0,0.8888888888888888,C compiler supported by Windows 7,"I'm having a problem finding which compiler can support Windows7 for C or C++ programming.
I had installed Turbo but it does not work in full screen on Windows 7.
Please let me know which compiler will be appropriate.
",Lcc-win32 is a free windows compiler.
5813,5813,9206,How do you run an installer?,"we bought a CrashPlan-Install program for backing up the computer. Since I am still learning about Ubuntu, I don't know how to run the installer. These are the only instructions that I have- To install CrashPlan run the installer in this directory:

./install.sh

Does this mean I need to create the directory? I know how to do that, but if that is the case where (or how) do you run the installer?
",BJsgoodlife,https://askubuntu.com/users/157447,"You downloaded a file named CrashPlan_3.5.3_Linux.tar.gz file from the website and stored this somewhere on your computer. Open a termimal and go to the directory you downloaded it into and type

tar xvfz CrashPlan_3.5.3_Linux.tar.gz


This will extract the file. After it is done cd into the directory it created and install...

cd CrashPlan-install/
./install


It will then start installing CrashPlan. From their website: 


  CrashPlan automatically starts up after installation and prompts you to create a new account.  Enter the information and click Create Account. CrashPlan will send backup reports and notifications to the email address you enter. 


Extra: there is a README file inside the directory. Notable:

NOTES:

1) CrashPlan for Linux uses the Sun Java Runtime Environment to run.  If
you do not have the Sun Java Runtime Environment installed, CrashPlan
can download a version of the Runtime Environment and install it alongside
CrashPlan itself.  This will not overwrite your system's installed Java.

2) Once installed, the GUI can be launched by using the command 'CrashPlanDesktop',
which will be linked from your chosen directory.  If defaults are used, it
will be:

/usr/local/bin/CrashPlanDesktop


3) The background service, now called 'CrashPlan' which starts the
backup engine, will be installed and setup to run from your designated
directory. If defaults are used, it will be:

/etc/init.d/crashplan


and it will be linked from:

/etc/rc2.d


Note that on some flavors of Linux you may need to added the following to /etc/init.d/boot.local:

/etc/init.d/crashplan start

",Rinzwind,https://askubuntu.com/users/15811,http://askubuntu.com/questions/314863/how-do-you-run-an-installer,TECHNOLOGY,askubuntu.com,1.0,0.4444444444444444,0.0,0.0,1.0,0.6666666666666666,0.4444444444444444,0.8888888888888888,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.0,0.0,0.8888888888888888,How do I run setup?,"We bought a crashplan installer for backup computers. Because I'm still learning Ubuntu, I don't know how to run setup. Here are the only instructions I need to install crashplan to run the installer in this directory:","You downloaded a file named CrashPlan_3.5.3_Linux.tar.gz file from the website and stored this somewhere on your computer. Open a termimal and go to the directory you downloaded it into and type

tar xvfz CrashPlan_3.5.3_Linux.tar.gz


This will extract the file. After it is done cd into the directory it created and install...

cd CrashPlan-install/
./install


It will then start installing CrashPlan. From their website: 


  CrashPlan automatically starts up after installation and prompts you to create a new account.  Enter the information and click Create Account. CrashPlan will send backup reports and notifications to the email address you enter. 


Extra: there is a README file inside the directory. Notable:

NOTES:

1) CrashPlan for Linux uses the Sun Java Runtime Environment to run.  If
you do not have the Sun Java Runtime Environment installed, CrashPlan
can download a version of the Runtime Environment and install it alongside
CrashPlan itself.  This will not overwrite your system's installed Java.

2) Once installed, the GUI can be launched by using the command 'CrashPlanDesktop',
which will be linked from your chosen directory.  If defaults are used, it
will be:

/usr/local/bin/CrashPlanDesktop


3) The background service, now called 'CrashPlan' which starts the
backup engine, will be installed and setup to run from your designated
directory. If defaults are used, it will be:

/etc/init.d/crashplan


and it will be linked from:

/etc/rc2.d


Note that on some flavors of Linux you may need to added the following to /etc/init.d/boot.local:

/etc/init.d/crashplan start

"
1330,1330,2098,How to scale entire document including Maths symbols?,"I'm trying to make a cheat-sheet for my Math class. I wonder is there a way to scale the entire document so that I can fit more formulas and theorems into it. It doesn't need to be super tiny though. I tried tiny font, but it still waste too much space. Have anyone done it before could share me some experiences? Thanks in advance.
",Chan,https://tex.stackexchange.com/users/4322,"The best way to create some space in your document is to use a combination of geometry (for setting/removing margin dimensions) and some standard documentclass font settings:

\documentclass[10pt]{article}% default is 10pt font


However, in terms of creating a cheat-sheet that should condense a number of pages on (say) a two-sided single piece of stock, I would suggest creating a document as per usual and then creating a second document that includes the pages of the first in ""n-up"" style, depending on your page count. Let me explain...

Consider your original straight-forward document that has a bunch of content in it, including formulas and nifty how-to's:

cheat-material.tex

\documentclass{article}
\usepackage[margin=1cm]{geometry}% http://ctan.org/pkg/geometry
\usepackage{blindtext}% http://ctan.org/pkg/blindtext
\usepackage[english]{babel}% http://ctan.org/pkg/babel
\begin{document}
\Blinddocument% Creates a 8-page document in the current style
\end{document}


The above is just a mock-up of your document using the blindtext package. It creates 8 pages of wholesome cheat-sheet material.

Now I create my second document using the pdfpages package to insert output of cheat-material.tex in n-up style (I chose 4-up, since 8 is divisible by 4):

cheat-sheet.tex

\documentclass{article}
\usepackage{pdfpages}% http://ctan.org/pkg/pdfpages
\begin{document}
\includepdf[nup=4,pages=-,frame]{cheat-material}
\end{document}


pages=- includes all pages of cheat-material.pdf, and frame adds a page border around each included page.



This way you're not bound as much by trying to modify things - you're merely creating a document (cheat-material) and squeezing it as needed into a specific shape (cheat-sheet). This is especially helpful if you have multiple pages that you want to condense, as seems to be the case for you.
",Werner,https://tex.stackexchange.com/users/5764,http://tex.stackexchange.com/questions/33164/how-to-scale-entire-document-including-maths-symbols,TECHNOLOGY,tex.stackexchange.com,1.0,0.7777777777777778,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.4444444444444444,0.5555555555555556,0.3333333333333333,0.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.8888888888888888,1.0,0.7777777777777778,1.0,1.0,1.0,1.0,0.3333333333333333,0.0,0.8888888888888888,"How do I scale an entire document, including mathematical symbols?","I'm making a memo for my math class. I wonder if there's a way to scale the entire document so I can put more formulas and theorems in it. However, it doesn't need to be super small. I've tried small fonts, but I've wasted too much space. Can someone share some experience with me before? Thank you in advance.","The best way to create some space in your document is to use a combination of geometry (for setting/removing margin dimensions) and some standard documentclass font settings:

\documentclass[10pt]{article}% default is 10pt font


However, in terms of creating a cheat-sheet that should condense a number of pages on (say) a two-sided single piece of stock, I would suggest creating a document as per usual and then creating a second document that includes the pages of the first in ""n-up"" style, depending on your page count. Let me explain...

Consider your original straight-forward document that has a bunch of content in it, including formulas and nifty how-to's:

cheat-material.tex

\documentclass{article}
\usepackage[margin=1cm]{geometry}% http://ctan.org/pkg/geometry
\usepackage{blindtext}% http://ctan.org/pkg/blindtext
\usepackage[english]{babel}% http://ctan.org/pkg/babel
\begin{document}
\Blinddocument% Creates a 8-page document in the current style
\end{document}


The above is just a mock-up of your document using the blindtext package. It creates 8 pages of wholesome cheat-sheet material.

Now I create my second document using the pdfpages package to insert output of cheat-material.tex in n-up style (I chose 4-up, since 8 is divisible by 4):

cheat-sheet.tex

\documentclass{article}
\usepackage{pdfpages}% http://ctan.org/pkg/pdfpages
\begin{document}
\includepdf[nup=4,pages=-,frame]{cheat-material}
\end{document}


pages=- includes all pages of cheat-material.pdf, and frame adds a page border around each included page.



This way you're not bound as much by trying to modify things - you're merely creating a document (cheat-material) and squeezing it as needed into a specific shape (cheat-sheet). This is especially helpful if you have multiple pages that you want to condense, as seems to be the case for you.
"
265,265,430,Upgrade to 12.04 Failed due to held back packages,"I run upgrade after installing all recommended updates from update manager, and I got dialog:

Could not calculate the upgrade

An unresolvable problem occurred while calculating the upgrade:
E:Unable to correct problems, you have held broken packages.

 This can be caused by:
 * Upgrading to a pre-release version of Ubuntu
 * Running the current pre-release version of Ubuntu
 * Unofficial software packages not provided by Ubuntu

If none of this applies, then please report this bug using the command 'ubuntu-bug update-manager' in a terminal.


So I reported bug.

I also tried

umpirsky@umpirsky:~$ sudo apt-get update
...
Fetched 16.6 kB in 1min 22s (200 B/s)
Reading package lists... Done
W: GPG error: http://archive.canonical.com oneiric Release: The following signatures were invalid: BADSIG 40976EAF437D05B5 Ubuntu Archive Automatic Signing Key &lt;email address hidden&gt;


Any workaround for this?


What is the easiest way to resolve apt-get BADSIG GPG errors?
First and second solution didn't work, last one returned cd: /var/cache/apt-cacher-ng: No such file or directory. Still getting GPG error.

",umpirsky,https://askubuntu.com/users/17226,"I had this problem too on my Lenovo Thinkpad due to ppa graphics dirvers. I solved it by installing ppa-purge and then removing the https://launchpad.net/~oibaf/+archive/graphics-drivers ppa:


sudo apt-get install ppa-purge

sudo ppa-purge ppa:oibaf/graphics-drivers

",Alb,https://askubuntu.com/users/9289,http://askubuntu.com/questions/125500/upgrade-to-12-04-failed-due-to-held-back-packages,TECHNOLOGY,askubuntu.com,1.0,0.4444444444444444,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.5555555555555556,0.8888888888888888,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,0.8888888888888888,Upgrade to 12.04 failed due to package delay,"I run upgrade after installing all recommended updates from update manager, and I got dialog:

Could not calculate the upgrade

An unresolvable problem occurred while calculating the upgrade:
E:Unable to correct problems, you have held broken packages.

 This can be caused by:
 * Upgrading to a pre-release version of Ubuntu
 * Running the current pre-release version of Ubuntu
 * Unofficial software packages not provided by Ubuntu

If none of this applies, then please report this bug using the command 'ubuntu-bug update-manager' in a terminal.


So I reported bug.

I also tried

umpirsky@umpirsky:~$ sudo apt-get update
...
Fetched 16.6 kB in 1min 22s (200 B/s)
Reading package lists... Done
W: GPG error: http://archive.canonical.com oneiric Release: The following signatures were invalid: BADSIG 40976EAF437D05B5 Ubuntu Archive Automatic Signing Key &lt;email address hidden&gt;


Any workaround for this?


What is the easiest way to resolve apt-get BADSIG GPG errors?
First and second solution didn't work, last one returned cd: /var/cache/apt-cacher-ng: No such file or directory. Still getting GPG error.

",My Lenovo ThinkPad also has this problem because of PPA's graphic catalog. I solved this problem by installing PPA purge and removing HTTPS: / / launchpad. Net / ~ oibaf / + archive / graphics drivers PPA:
2149,2149,3425,How do I create a great fantasy villain that inspires the party to rally against them?,"In my early years of GMing it was simple enough to say that the badguys were evil and that was all the justification we needed.  They are attacking the village because they are evil, they are stealing the princess because they are evil, etc.

Over time, my group needs have grown to need more complicated and detailed villains. It is important to consider motives.  What is it that defines them as 'evil' to the party?  In terms of a fantasy setting, what would you consider to be an interesting villain?

What qualities make a villain that inspires your party to rally against him?  What kind of villains have worked for your games in the past?

Example:


  A member of nobility is using trade connections to move valuable pieces of art into another country that is secretly paying him quite well and is framing a member of the party to take the fall.  In addition, someone important to the party member has been taken hostage with a promise of release once they party member takes the blame for the crime.

",Maximillian,https://rpg.stackexchange.com/users/18,"TSR has a ""Villains Lorebook"" on their website here that I think has some good example villains that can be mined for your use.  AD&amp;D had a book called the ""Complete Book of Villains"" that had good advice.  A post about it here. Wolfgang Baur has a series about villains that I liked a lot.  Click here.

Here's more of the Baur stuff -- Wizards doesn't make it easy to find...
Part 2
Part 3
Part 4
Part 5
Part 6
Part 7
",Wilmanric,https://rpg.stackexchange.com/users/106,http://rpg.stackexchange.com/questions/584/how-do-i-create-a-great-fantasy-villain-that-inspires-the-party-to-rally-against,CULTURE,rpg.stackexchange.com,1.0,0.7777777777777778,1.0,0.0,0.0,0.0,0.5555555555555556,0.6666666666666666,0.6666666666666666,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.6666666666666666,0.0,1.0,0.8888888888888888,0.5555555555555556,1.0,0.8888888888888888,0.6666666666666667,0.0,0.0,0.3333333333333333,1.0,How can I create a great fantasy villain to inspire the party to unite against them?,"In my early years of GMing it was simple enough to say that the badguys were evil and that was all the justification we needed.  They are attacking the village because they are evil, they are stealing the princess because they are evil, etc.

Over time, my group needs have grown to need more complicated and detailed villains. It is important to consider motives.  What is it that defines them as 'evil' to the party?  In terms of a fantasy setting, what would you consider to be an interesting villain?

What qualities make a villain that inspires your party to rally against him?  What kind of villains have worked for your games in the past?

Example:


  A member of nobility is using trade connections to move valuable pieces of art into another country that is secretly paying him quite well and is framing a member of the party to take the fall.  In addition, someone important to the party member has been taken hostage with a promise of release once they party member takes the blame for the crime.

","TSR has a ""Villains Lorebook"" on their website here that I think has some good example villains that can be mined for your use.  AD&amp;D had a book called the ""Complete Book of Villains"" that had good advice.  A post about it here. Wolfgang Baur has a series about villains that I liked a lot.  Click here.

Here's more of the Baur stuff -- Wizards doesn't make it easy to find...
Part 2
Part 3
Part 4
Part 5
Part 6
Part 7
"
3927,3927,6264,Is the ability cost of the commander part of the color identity?,"Consider the card  Rhys the Exiled. Are you allowed to play black (and green) cards in your deck with this commander?

Or are you only allowed to play cards that are the same color as the commander's cost? If so, would this then make it impossible to use his ability?
",SirDuckduck,https://boardgames.stackexchange.com/users/3616,"The colour identity of  Rhys the Exiled is Green and Black.

As per the Commander colour identity rules:


  A card's colour identity is its colour plus the colour of any mana symbols in the card's rules text.


The colour doesn't have to be just in the casting cost (which determines the card's colour), any mana symbol cost in the rules text counts towards the card's colour identity.

See also Comprehensive Rule 903.4: 


  903.4. The Commander variant uses color identity to determine what cards can be in a deck with a certain commander. The color identity of a card is the color or colors of any mana symbols in that card's mana cost or rules text, plus any colors defined by its characteristic-defining abilities (see rule 604.3) or color indicator (see rule 204).
  Example: Bosh, Iron Golem is a legendary artifact creature with mana cost {8} and the ability ""{3}{R}, Sacrifice an artifact: Bosh, Iron Golem deals damage equal to the sacrificed artifact's converted mana cost to target creature or player."" Bosh's color identity is red.

",ghoppe,https://boardgames.stackexchange.com/users/632,http://boardgames.stackexchange.com/questions/11220/is-the-ability-cost-of-the-commander-part-of-the-color-identity,CULTURE,boardgames.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,1.0,0.6666666666666666,1.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,0.8888888888888888,1.0,0.0,0.0,1.0,0.8888888888888888,Is commander's capability cost part of color identity?,"Consider the card  Rhys the Exiled. Are you allowed to play black (and green) cards in your deck with this commander?

Or are you only allowed to play cards that are the same color as the commander's cost? If so, would this then make it impossible to use his ability?
","The colour identity of  Rhys the Exiled is Green and Black.

As per the Commander colour identity rules:


  A card's colour identity is its colour plus the colour of any mana symbols in the card's rules text.


The colour doesn't have to be just in the casting cost (which determines the card's colour), any mana symbol cost in the rules text counts towards the card's colour identity.

See also Comprehensive Rule 903.4: 


  903.4. The Commander variant uses color identity to determine what cards can be in a deck with a certain commander. The color identity of a card is the color or colors of any mana symbols in that card's mana cost or rules text, plus any colors defined by its characteristic-defining abilities (see rule 604.3) or color indicator (see rule 204).
  Example: Bosh, Iron Golem is a legendary artifact creature with mana cost {8} and the ability ""{3}{R}, Sacrifice an artifact: Bosh, Iron Golem deals damage equal to the sacrificed artifact's converted mana cost to target creature or player."" Bosh's color identity is red.

"
4808,4808,7638,"highcharts: stop chart from trapping mouse events, or capture mouse click on the ENTIRE chart","All,

I'm using HighCharts in a web app I'm working on, and generally, I like it very much.

However, I'm having a hard time figuring out how capture a mouse click on the ENTIRE chart.

In other words - I'd like to know when the user clicks ANYWHERE on the chart (e.g., the plot area, the title, the x- or y-axis, the margins and padding around the chart elements, etc.)

Or, I'd like to disable events altogether, so I can trap the event in the container itself.

More detailed version...

I have a DIV that contains my HighChart.

I want to know if the user clicks ANYWHERE within that DIV.

So - initially I tried attaching an ""onclick"" event to the DIV, but that never gets fired, presumably because the click is getting trapped by the HighChart.

So, in the code that sets up the HighChart, I added this:

var chart = new Highcharts.Chart({
    chart: {
        renderTo: ""container"",
        events: {
            click: function(event) {
                // do something
            }
        },
        ...
    }
    ...
});


This works OK IF the user clicks somewhere within the plot area, but not if she clicks anywhere else in the chart (e.g., the x-axis, the y-axis, the title, the padding around the chart elements, etc.)

So - how can I make the ENTIRE chart clickable?

Many thanks in advance!
",mattstuehler,https://stackoverflow.com/users/49383,"I had this same issue.

Using the webkit inspector I can see that Highcharts binds a click event to the chart container (the div with the 'highcharts-container' class), and this seems to interfere with clicking.

Provided you don't want any of the functionality in that click event, you can remove it by setting 

chart.container.onclick = null;

Otherwise, you'll need to use the built-in highcharts event properties to set your callbacks.
As the OP noted, there is an 'events' property for the chart object, which should trigger when clicking the plot background. 
There is also an event property for the plot options which triggers when clicking the series itself. 

For example, for area plots:

var chart = new Highcharts.Chart({
    ...
    plotOptions: {
        area: {
            events: {
                click: function(event) {
                    // do something
                }
            },
        ...
        }
    }
    ...
});


More more info see:
http://www.highcharts.com/ref/#plotOptions-area-events
",grahamgilchrist,https://stackoverflow.com/users/1590465,http://stackoverflow.com/questions/11618075/highcharts-stop-chart-from-trapping-mouse-events-or-capture-mouse-click-on-the,STACKOVERFLOW,stackoverflow.com,0.6666666666666666,0.6666666666666666,0.0,0.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,0.0,1.0,"Highcharts: prevents the chart from capturing mouse events, or the capture mouse from clicking the entire chart","All,

I'm using HighCharts in a web app I'm working on, and generally, I like it very much.

However, I'm having a hard time figuring out how capture a mouse click on the ENTIRE chart.

In other words - I'd like to know when the user clicks ANYWHERE on the chart (e.g., the plot area, the title, the x- or y-axis, the margins and padding around the chart elements, etc.)

Or, I'd like to disable events altogether, so I can trap the event in the container itself.

More detailed version...

I have a DIV that contains my HighChart.

I want to know if the user clicks ANYWHERE within that DIV.

So - initially I tried attaching an ""onclick"" event to the DIV, but that never gets fired, presumably because the click is getting trapped by the HighChart.

So, in the code that sets up the HighChart, I added this:

var chart = new Highcharts.Chart({
    chart: {
        renderTo: ""container"",
        events: {
            click: function(event) {
                // do something
            }
        },
        ...
    }
    ...
});


This works OK IF the user clicks somewhere within the plot area, but not if she clicks anywhere else in the chart (e.g., the x-axis, the y-axis, the title, the padding around the chart elements, etc.)

So - how can I make the ENTIRE chart clickable?

Many thanks in advance!
","I had this same issue.

Using the webkit inspector I can see that Highcharts binds a click event to the chart container (the div with the 'highcharts-container' class), and this seems to interfere with clicking.

Provided you don't want any of the functionality in that click event, you can remove it by setting 

chart.container.onclick = null;

Otherwise, you'll need to use the built-in highcharts event properties to set your callbacks.
As the OP noted, there is an 'events' property for the chart object, which should trigger when clicking the plot background. 
There is also an event property for the plot options which triggers when clicking the series itself. 

For example, for area plots:

var chart = new Highcharts.Chart({
    ...
    plotOptions: {
        area: {
            events: {
                click: function(event) {
                    // do something
                }
            },
        ...
        }
    }
    ...
});


More more info see:
http://www.highcharts.com/ref/#plotOptions-area-events
"
4023,4023,6423,Difference in technique for cooking with non-stick and standard pans?,"Following up from my previous question, which I'd raised because I have concerns that my non-stick wok will need replacing very soon (again), and was having a think about ""standard"" pans.

I'm not currently interested in differences in care/cleaning/etc, I think those are quite well covered in other questions.

So, I'm wondering what's the difference in the required technique when using them to cook food?
",DMA57361,https://cooking.stackexchange.com/users/1181,"The big thing that you you are going to see cooking in regular pans vs. non-stick is the addition of pan sauces to your table.  It is almost impossible to get a pan sauce out of the non-sticks because they prevent the formation of fond in the pan.  As for stick in a regular pan, it is not much of a concern for most items, but there are a few things that non-stick are invaluable for so I generally keep a cheap non-stick around for those. (Talking cepes and eggs, mostly) The biggest trick with regular pans is learning to stop messing with your food while it cooks. You want to let it form that crust which as a by-product will help prevent sticking. Also, you will find that you start at a higher tempature when cooking with regular pans.   
",sarge_smith,https://cooking.stackexchange.com/users/446,http://cooking.stackexchange.com/questions/3122/difference-in-technique-for-cooking-with-non-stick-and-standard-pans,LIFE_ARTS,cooking.stackexchange.com,1.0,1.0,0.0,1.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.8888888888888888,0.0,0.0,0.6666666666666666,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,0.3333333333333333,1.0,What's the difference between nonstick cooking and standard cooking?,"Following up from my previous question, which I'd raised because I have concerns that my non-stick wok will need replacing very soon (again), and was having a think about ""standard"" pans.

I'm not currently interested in differences in care/cleaning/etc, I think those are quite well covered in other questions.

So, I'm wondering what's the difference in the required technique when using them to cook food?
","The big thing that you you are going to see cooking in regular pans vs. non-stick is the addition of pan sauces to your table.  It is almost impossible to get a pan sauce out of the non-sticks because they prevent the formation of fond in the pan.  As for stick in a regular pan, it is not much of a concern for most items, but there are a few things that non-stick are invaluable for so I generally keep a cheap non-stick around for those. (Talking cepes and eggs, mostly) The biggest trick with regular pans is learning to stop messing with your food while it cooks. You want to let it form that crust which as a by-product will help prevent sticking. Also, you will find that you start at a higher tempature when cooking with regular pans.   
"
5671,5671,8992,"Relationship between user story, feature, and epic?","As someone whose still new to agile, I'm not sure I completely understand the relationship or difference between a user story, feature, and epic.

According to this question, a feature is a collection of stories.  One of the answers suggest that a feature is actually an epic.  

So are features and epics considered the same thing, which is basically a collection of related user stories?

Our project manager insists that there's a hierarchical structure:

Epic -> Features -> User stories

... basically all user stories must fall within this structure.  Therefore all user stories must fall under an umbrella feature and all features must fall under an epic.

To me, that sounds awkward.  Can someone please clarify how user stories, features, and epics are related?  Or is there an article that clearly outlines the differences?
",nivlam,https://programmers.stackexchange.com/users/45,"Epic:   A very large user story that is eventually broken down into smaller stories.

User story: A very high-level definition of a requirement, containing just enough information so that the developers can produce a reasonable estimate of the effort to implement it.

http://www.telerik.com/agile-project-management-tools/agile-resources/vocabulary.aspx

Feature: A distinguishing characteristic or capability of a software application or library (e.g., performance, portability, or functionality).

http://en.wikipedia.org/wiki/Software_feature
",Robert Harvey,https://programmers.stackexchange.com/users/1204,http://programmers.stackexchange.com/questions/182158/relationship-between-user-story-feature-and-epic,TECHNOLOGY,programmers.stackexchange.com,1.0,0.5555555555555556,0.0,1.0,0.6666666666666666,0.5,0.5555555555555556,0.4444444444444444,0.6666666666666666,0.0,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.0,0.0,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,1.0,1.0,0.5,1.0,0.7777777777777778,0.8,0.0,0.0,0.3333333333333333,1.0,"The relationship between user stories, features, and epics?","As someone whose still new to agile, I'm not sure I completely understand the relationship or difference between a user story, feature, and epic.

According to this question, a feature is a collection of stories.  One of the answers suggest that a feature is actually an epic.  

So are features and epics considered the same thing, which is basically a collection of related user stories?

Our project manager insists that there's a hierarchical structure:

Epic -> Features -> User stories

... basically all user stories must fall within this structure.  Therefore all user stories must fall under an umbrella feature and all features must fall under an epic.

To me, that sounds awkward.  Can someone please clarify how user stories, features, and epics are related?  Or is there an article that clearly outlines the differences?
","Epic:   A very large user story that is eventually broken down into smaller stories.

User story: A very high-level definition of a requirement, containing just enough information so that the developers can produce a reasonable estimate of the effort to implement it.

http://www.telerik.com/agile-project-management-tools/agile-resources/vocabulary.aspx

Feature: A distinguishing characteristic or capability of a software application or library (e.g., performance, portability, or functionality).

http://en.wikipedia.org/wiki/Software_feature
"
165,165,262,Is Start & Stop technology good or bad for my car? (Alfa MiTO),"I was recently in the lucky position to obtain an (almost brand new) Alfa Romeo MiTo, Progression. Like many new cars coming out these days, it has ""Start &amp; Stop"" technology that turns the engine off when the car is stationary and is put in neutral and the clutch is released. When putting down the clutch again the engine fires back up.

My question then is this: 

a) Is start-stop technology bad for my engine in any way? 

b) What impact might start-stop have on my battery? I.e. won't it deteriorate battery life with the constant turning on and off? (The radio, fans and lights remain on whilst in ""stop""-mode, but not things like the aircon.)

c) Will this technology really benefit me that much with regards to fuel-consumption? I can imagine it will be more economic when stops in heavy traffic become really long or traffic lights are red for long periods, but for the most part when driving the car doesn't turn off for longer than a minute at most before I have to ""start"" it up again.

As many new cars lately have this technology I imagine that it can't be that bad, but I'm curious as to it's actual real benefits. I can turn this feature off, but I have to do so every time I start my car up for the first time and then I'm stuck with this glaring orange light in my dash, letting me know it's turned off.
",DeVil,https://mechanics.stackexchange.com/users/538,"Potential savings from reduced idling should greatly outweigh any increased wear and tear on starting and charging systems. I answered similar question about idling before (Is idling bad for your engine?). To summarise the negative effects of idling:


Fuel combustion is incomplete, which leads to contamination of combustion chamber (glazing), spark plugs (wich reduces their effectiveness), exhaust system (including catalytic converter).
Motor does not operate at optimal temperature, which leads to excessive condensation of water vapour in exhaust system, which leads to its corrosion (ergo premature replacement), and increased emissions.


At the same time cost of wear and tear is low (American governmental agencies routinely cite $10 added per year). Roughly, it means if one would expect to replace the starter at 10–12 years normally, now one would do it at 8–10 (I pulled these numbers out of me arse, but they seem reasonable).

To quantify fuel savings we need to consider savings from reduced idling, and savings from avoided performance losses. Research paper from Vanderbilt University (Amanda R. Carrico et al, “Costly myths: An analysis of idling beliefs and behavior in personal motor vehicles.”) based on the survey of 1300 U.S. residents estimates that on average Americans spend about 16 minutes a day idling (4 minutes warming, 4 minutes waiting, 8 minutes in traffic). Possibly, in more compact European or South African municipalities these numbers could be lower.

Let us say we cut American number by about 60% and save around 6 minutes a day. 2.0L 4-cylinder petrol engine burns around 1 litre per hour idling. 6 × 365 / 60 = 36.5 hours/year, or 36.5 litres/year.

Reduced efficiency can cost even more. If a car is driven 1500 km (930 miles) a month or 18000 km (11100 miles) a year, and consumes on average 9L/100 km (2.0L compact), 5% reduction in efficiency leads to 0.05 (18000 / 100 × 9) = 81 litres per year extra.

So average Golf-class 2.0L 4-cylinder compact can consume extra ~120 litres (31 U.S. gallons) every year due to excessive idling. Multiply that by the price of petrol, and see potential savings on the fuel alone.
",theUg,https://mechanics.stackexchange.com/users/1764,http://mechanics.stackexchange.com/questions/825/is-start-stop-technology-good-or-bad-for-my-car-alfa-mito/827,CULTURE,mechanics.stackexchange.com,1.0,0.8888888888888888,0.0,0.6666666666666666,1.0,0.6666666666666666,0.6666666666666666,0.5555555555555556,1.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.8888888888888888,0.5555555555555556,1.0,1.0,0.8,0.0,0.0,1.0,1.0,Is start stop technology good or bad for my car? (alpha mitto),"I was recently in the lucky position to obtain an (almost brand new) Alfa Romeo MiTo, Progression. Like many new cars coming out these days, it has ""Start &amp; Stop"" technology that turns the engine off when the car is stationary and is put in neutral and the clutch is released. When putting down the clutch again the engine fires back up.

My question then is this: 

a) Is start-stop technology bad for my engine in any way? 

b) What impact might start-stop have on my battery? I.e. won't it deteriorate battery life with the constant turning on and off? (The radio, fans and lights remain on whilst in ""stop""-mode, but not things like the aircon.)

c) Will this technology really benefit me that much with regards to fuel-consumption? I can imagine it will be more economic when stops in heavy traffic become really long or traffic lights are red for long periods, but for the most part when driving the car doesn't turn off for longer than a minute at most before I have to ""start"" it up again.

As many new cars lately have this technology I imagine that it can't be that bad, but I'm curious as to it's actual real benefits. I can turn this feature off, but I have to do so every time I start my car up for the first time and then I'm stuck with this glaring orange light in my dash, letting me know it's turned off.
","Potential savings from reduced idling should greatly outweigh any increased wear and tear on starting and charging systems. I answered similar question about idling before (Is idling bad for your engine?). To summarise the negative effects of idling:


Fuel combustion is incomplete, which leads to contamination of combustion chamber (glazing), spark plugs (wich reduces their effectiveness), exhaust system (including catalytic converter).
Motor does not operate at optimal temperature, which leads to excessive condensation of water vapour in exhaust system, which leads to its corrosion (ergo premature replacement), and increased emissions.


At the same time cost of wear and tear is low (American governmental agencies routinely cite $10 added per year). Roughly, it means if one would expect to replace the starter at 10–12 years normally, now one would do it at 8–10 (I pulled these numbers out of me arse, but they seem reasonable).

To quantify fuel savings we need to consider savings from reduced idling, and savings from avoided performance losses. Research paper from Vanderbilt University (Amanda R. Carrico et al, “Costly myths: An analysis of idling beliefs and behavior in personal motor vehicles.”) based on the survey of 1300 U.S. residents estimates that on average Americans spend about 16 minutes a day idling (4 minutes warming, 4 minutes waiting, 8 minutes in traffic). Possibly, in more compact European or South African municipalities these numbers could be lower.

Let us say we cut American number by about 60% and save around 6 minutes a day. 2.0L 4-cylinder petrol engine burns around 1 litre per hour idling. 6 × 365 / 60 = 36.5 hours/year, or 36.5 litres/year.

Reduced efficiency can cost even more. If a car is driven 1500 km (930 miles) a month or 18000 km (11100 miles) a year, and consumes on average 9L/100 km (2.0L compact), 5% reduction in efficiency leads to 0.05 (18000 / 100 × 9) = 81 litres per year extra.

So average Golf-class 2.0L 4-cylinder compact can consume extra ~120 litres (31 U.S. gallons) every year due to excessive idling. Multiply that by the price of petrol, and see potential savings on the fuel alone.
"
5232,5232,8316,How to deploy OSGi bundle to Maven repo with deploy:deploy-file?,"I have an OSGi bundle that was built using Maven by another team. The POM file declares its packaging as ""bundle"" and uses the Apache Felix plugin.

I need to deploy this artifact to a local Maven repository (Nexus) so that it can be used by our internal projects.

I have used the deploy:deploy-file target to deploy the bundle to the repository, just as you would with a standard JAR file and this works without error. I extracted the embedded POM from the bundle and passed that on the command line, so the command line was:

mvn deploy:deploy-file -Dfile=3rdpartybundle.jar -DpomFile=pom.xml -DrepositoryId=internal -Durl=http://internalserver/nexus


The issue is that when I deploy it like this, the packaging is set to bundle and as a result the name of the artifact in the repository ends up with a .bundle extension, instead of a .jar extension.

Now, we cannot figure out how to declare it as a dependency. If we declare it like this:

        &lt;dependency&gt;
            &lt;groupId&gt;...&lt;/groupId&gt;
            &lt;artifactId&gt;...&lt;/artifactId&gt;
            &lt;version&gt;...&lt;/version&gt;
            &lt;type&gt;bundle&lt;/type&gt;
        &lt;/dependency&gt;


We get an error stating that the dependency cannot be resolved. The interesting thing is that the GAV coordinates in the error message actually has ""jar"" as the value for the type of the dependency even though we set it as ""bundle"".

If we change the dependency to:

        &lt;dependency&gt;
            &lt;groupId&gt;...&lt;/groupId&gt;
            &lt;artifactId&gt;...&lt;/artifactId&gt;
            &lt;version&gt;...&lt;/version&gt;
            &lt;type&gt;jar&lt;/type&gt;
        &lt;/dependency&gt;


We get the exact same unresolved dependency error.

So how are you supposed to deploy an artifact packaged as a bundle to a Maven repository, so that it can be used as a compile time dependency for another project?

Thanks
",Craig S. Dickson,https://stackoverflow.com/users/860117,"The issue is that ""3rdpartybundle.jar"" is being built without setting extensions=true and/or supported types:

&lt;plugin&gt;
    &lt;groupId&gt;org.apache.felix&lt;/groupId&gt;
    &lt;artifactId&gt;maven-bundle-plugin&lt;/artifactId&gt;
...
    &lt;extensions&gt;true&lt;/extensions&gt;
...
    &lt;configuration&gt;
        &lt;supportedProjectTypes&gt;
            &lt;supportedProjectType&gt;jar&lt;/supportedProjectType&gt;
            &lt;supportedProjectType&gt;war&lt;/supportedProjectType&gt;
        &lt;/supportedProjectTypes&gt;


If you can't fix that upstream, then there's a couple of options;

1) Repack it as a Jar using a new project pom:

                    &lt;plugin&gt;
                            &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                            &lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt;
                            &lt;version&gt;2.3&lt;/version&gt;
                            &lt;configuration&gt;
                                    &lt;actTransitively&gt;false&lt;/actTransitively&gt;
                                    &lt;outputDirectory&gt;target/classes&lt;/outputDirectory&gt;
                                    &lt;artifactItems&gt;
                                            &lt;artifactItem&gt;
                                                    &lt;groupId&gt;3rd&lt;/groupId&gt;
                                                    &lt;artifactId&gt;party&lt;/artifactId&gt;
                                                    &lt;version&gt;X.Y.Z&lt;/version&gt;
                                            &lt;/artifactItem&gt;
                                    &lt;/artifactItems&gt;
                            &lt;/configuration&gt;
                            &lt;executions&gt;
                                    &lt;execution&gt;
                                            &lt;goals&gt;
                                                    &lt;goal&gt;unpack&lt;/goal&gt;
                                            &lt;/goals&gt;
                                            &lt;phase&gt;compile&lt;/phase&gt;
                                    &lt;/execution&gt;
                            &lt;/executions&gt;
                    &lt;/plugin&gt;


2) Try using  mvn deploy:deploy-file with -DgeneratePom=false -Dpackaging=jar -Dfile=/path/to/3rdpartybundle.jar but without specifying -DpomFile= - hope there's no META-INF/maven/pom.xml inside the 3rdpartybundle.jar - it should work using this but you'll need to specify the groupId/artifactId/version parameters as these won't be derived from the project's pom.

I know I've build bundle artifacts in the past and deployed these to our nexus (v1.9.0.1) and those in the Spring repo are typed bundle too, but don't recall any issue. (Incidentally you don't need to specify the bundle in dependency declarations, AFAIK if it's the only artifact it should be inferred)
",earcam,https://stackoverflow.com/users/573057,http://stackoverflow.com/questions/7406600/how-to-deploy-osgi-bundle-to-maven-repo-with-deploydeploy-file,STACKOVERFLOW,stackoverflow.com,0.3333333333333333,0.5,0.0,0.0,1.0,1.0,0.6666666666666666,0.5,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.5,1.0,0.5,0.0,1.0,0.6666666666666666,1.0,0.8333333333333334,1.0,1.0,1.0,0.0,0.5,0.3333333333333333,How to use the deploy: deploy file to deploy OSGi package to Maven repo?,"I have an OSGi bundle that was built using Maven by another team. The POM file declares its packaging as ""bundle"" and uses the Apache Felix plugin.

I need to deploy this artifact to a local Maven repository (Nexus) so that it can be used by our internal projects.

I have used the deploy:deploy-file target to deploy the bundle to the repository, just as you would with a standard JAR file and this works without error. I extracted the embedded POM from the bundle and passed that on the command line, so the command line was:

mvn deploy:deploy-file -Dfile=3rdpartybundle.jar -DpomFile=pom.xml -DrepositoryId=internal -Durl=http://internalserver/nexus


The issue is that when I deploy it like this, the packaging is set to bundle and as a result the name of the artifact in the repository ends up with a .bundle extension, instead of a .jar extension.

Now, we cannot figure out how to declare it as a dependency. If we declare it like this:

        &lt;dependency&gt;
            &lt;groupId&gt;...&lt;/groupId&gt;
            &lt;artifactId&gt;...&lt;/artifactId&gt;
            &lt;version&gt;...&lt;/version&gt;
            &lt;type&gt;bundle&lt;/type&gt;
        &lt;/dependency&gt;


We get an error stating that the dependency cannot be resolved. The interesting thing is that the GAV coordinates in the error message actually has ""jar"" as the value for the type of the dependency even though we set it as ""bundle"".

If we change the dependency to:

        &lt;dependency&gt;
            &lt;groupId&gt;...&lt;/groupId&gt;
            &lt;artifactId&gt;...&lt;/artifactId&gt;
            &lt;version&gt;...&lt;/version&gt;
            &lt;type&gt;jar&lt;/type&gt;
        &lt;/dependency&gt;


We get the exact same unresolved dependency error.

So how are you supposed to deploy an artifact packaged as a bundle to a Maven repository, so that it can be used as a compile time dependency for another project?

Thanks
","The issue is that ""3rdpartybundle.jar"" is being built without setting extensions=true and/or supported types:

&lt;plugin&gt;
    &lt;groupId&gt;org.apache.felix&lt;/groupId&gt;
    &lt;artifactId&gt;maven-bundle-plugin&lt;/artifactId&gt;
...
    &lt;extensions&gt;true&lt;/extensions&gt;
...
    &lt;configuration&gt;
        &lt;supportedProjectTypes&gt;
            &lt;supportedProjectType&gt;jar&lt;/supportedProjectType&gt;
            &lt;supportedProjectType&gt;war&lt;/supportedProjectType&gt;
        &lt;/supportedProjectTypes&gt;


If you can't fix that upstream, then there's a couple of options;

1) Repack it as a Jar using a new project pom:

                    &lt;plugin&gt;
                            &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                            &lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt;
                            &lt;version&gt;2.3&lt;/version&gt;
                            &lt;configuration&gt;
                                    &lt;actTransitively&gt;false&lt;/actTransitively&gt;
                                    &lt;outputDirectory&gt;target/classes&lt;/outputDirectory&gt;
                                    &lt;artifactItems&gt;
                                            &lt;artifactItem&gt;
                                                    &lt;groupId&gt;3rd&lt;/groupId&gt;
                                                    &lt;artifactId&gt;party&lt;/artifactId&gt;
                                                    &lt;version&gt;X.Y.Z&lt;/version&gt;
                                            &lt;/artifactItem&gt;
                                    &lt;/artifactItems&gt;
                            &lt;/configuration&gt;
                            &lt;executions&gt;
                                    &lt;execution&gt;
                                            &lt;goals&gt;
                                                    &lt;goal&gt;unpack&lt;/goal&gt;
                                            &lt;/goals&gt;
                                            &lt;phase&gt;compile&lt;/phase&gt;
                                    &lt;/execution&gt;
                            &lt;/executions&gt;
                    &lt;/plugin&gt;


2) Try using  mvn deploy:deploy-file with -DgeneratePom=false -Dpackaging=jar -Dfile=/path/to/3rdpartybundle.jar but without specifying -DpomFile= - hope there's no META-INF/maven/pom.xml inside the 3rdpartybundle.jar - it should work using this but you'll need to specify the groupId/artifactId/version parameters as these won't be derived from the project's pom.

I know I've build bundle artifacts in the past and deployed these to our nexus (v1.9.0.1) and those in the Spring repo are typed bundle too, but don't recall any issue. (Incidentally you don't need to specify the bundle in dependency declarations, AFAIK if it's the only artifact it should be inferred)
"
2483,2483,3955,How can I open a window on a different monitor?,"With multiple monitors, I have so far been dragging windows manually around. Is there a way to make a window open on a specific screen in a dual-head setup? (Not to be confused with multiple X server displays.)

Something like: SCREEN=2 firefox or open-in-screen 2 firefox.

If it matters, my environment is KDE using the KWin window manager. KWin window rules can only match some properties like title, but I could not find an environment variable as filter.

The secondary display extends the primary screen:

$ xrandr -q
Screen 0: minimum 320 x 200, current 3520 x 1080, maximum 32767 x 32767
LVDS1 connected 1600x900+0+0 (normal left inverted right x axis y axis) 382mm x 214mm
   1600x900       60.1*+
   1024x768       60.0  
   800x600        60.3     56.2  
   640x480        59.9  
VGA1 disconnected (normal left inverted right x axis y axis)
HDMI1 connected 1920x1080+1600+0 (normal left inverted right x axis y axis) 477mm x 268mm
   1920x1080      60.0*    50.0     59.9  
   1920x1080i     60.1     50.0     60.0  
   1680x1050      59.9  
   1280x1024      75.0     60.0  
   1440x900       59.9  
   1280x960       60.0  
   1280x720       60.0     50.0     59.9  
   1024x768       75.1     70.1     60.0  
   832x624        74.6  
   800x600        72.2     75.0     60.3     56.2  
   720x576        50.0  
   720x480        60.0     59.9  
   640x480        75.0     72.8     66.7     60.0     59.9  
   720x400        70.1  
DP1 disconnected (normal left inverted right x axis y axis)

",Lekensteyn,https://unix.stackexchange.com/users/8250,"This is a window manager specific solution. This is how to do it with kwin which is KDE's default window manager.

If you right click on the application Title Bar and select more settings -> special application settings.

Go to Window matching tab. Click on Detect Window Properties button. Then with mouse cursor click on application main window. It will select window class etc and also get window positioning info etc.

Then click on Size and Position tab. Click the Box Position and box Size and drop down box to right of both and set to remember.

Then click ok.

Next time you run the app it should be the same size and on same monitor.

I use this in KDE to open my uRxvt terminal on my left monitor on a 3-monitor setup and it works every time.

Good luck.
",rking,https://unix.stackexchange.com/users/57334,http://unix.stackexchange.com/questions/106793/how-can-i-open-a-window-on-a-different-monitor,TECHNOLOGY,unix.stackexchange.com,1.0,0.5555555555555556,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,0.8888888888888888,How to open windows on different monitors?,"With multiple monitors, I have so far been dragging windows manually around. Is there a way to make a window open on a specific screen in a dual-head setup? (Not to be confused with multiple X server displays.)

Something like: SCREEN=2 firefox or open-in-screen 2 firefox.

If it matters, my environment is KDE using the KWin window manager. KWin window rules can only match some properties like title, but I could not find an environment variable as filter.

The secondary display extends the primary screen:

$ xrandr -q
Screen 0: minimum 320 x 200, current 3520 x 1080, maximum 32767 x 32767
LVDS1 connected 1600x900+0+0 (normal left inverted right x axis y axis) 382mm x 214mm
   1600x900       60.1*+
   1024x768       60.0  
   800x600        60.3     56.2  
   640x480        59.9  
VGA1 disconnected (normal left inverted right x axis y axis)
HDMI1 connected 1920x1080+1600+0 (normal left inverted right x axis y axis) 477mm x 268mm
   1920x1080      60.0*    50.0     59.9  
   1920x1080i     60.1     50.0     60.0  
   1680x1050      59.9  
   1280x1024      75.0     60.0  
   1440x900       59.9  
   1280x960       60.0  
   1280x720       60.0     50.0     59.9  
   1024x768       75.1     70.1     60.0  
   832x624        74.6  
   800x600        72.2     75.0     60.3     56.2  
   720x576        50.0  
   720x480        60.0     59.9  
   640x480        75.0     72.8     66.7     60.0     59.9  
   720x400        70.1  
DP1 disconnected (normal left inverted right x axis y axis)

","This is a window manager specific solution. This is how to do it with kwin which is KDE's default window manager.

If you right click on the application Title Bar and select more settings -> special application settings.

Go to Window matching tab. Click on Detect Window Properties button. Then with mouse cursor click on application main window. It will select window class etc and also get window positioning info etc.

Then click on Size and Position tab. Click the Box Position and box Size and drop down box to right of both and set to remember.

Then click ok.

Next time you run the app it should be the same size and on same monitor.

I use this in KDE to open my uRxvt terminal on my left monitor on a 3-monitor setup and it works every time.

Good luck.
"
4910,4910,7819,Making Simple IF Statements Shorter,"If we assume we have this little snippet of code:

string str = ""checked"";
bool test1;

if (str == ""checked"")
{
    test1 = true;
}
else
{
    test1 = false;
}


Is it bad practice to change a simple statement like this to the following?:

bool test2 = (str == ""checked"");


Because they work exactly the same, and work as required, so I can't imagine how it would be. However, as a young, inexperienced programmer I am not aware of whether such a thing is frowned upon or not. Can anyone tell me, if this is NOT ok, why not?

The following test program:

using System;

public class Test
{

    public static void Main()
    {
        string str = ""checked"";

        bool test1;

        if (str == ""checked"")
        {
            test1 = true;
        }
        else
        {
            test1 = false;
        }

        bool test2 = (str == ""checked"");

        bool test3 = (str != ""checked"");

        Console.WriteLine(test1.ToString());
        Console.WriteLine(test2.ToString());
        Console.WriteLine(test3.ToString());
    }
}


Outputs:

True
True
False


Any insight etc is appreciated.
",Felix Weir,https://programmers.stackexchange.com/users/81895,"I would be very annoyed at someone who used the long form when the statement is that simple.

It hints that the one who wrote it either doesn't understand boolean data types, or doesn't realize == is independent of if.
",Izkata,https://programmers.stackexchange.com/users/27881,http://programmers.stackexchange.com/questions/199939/making-simple-if-statements-shorter,TECHNOLOGY,programmers.stackexchange.com,0.7777777777777778,0.5555555555555556,0.0,1.0,1.0,0.0,0.6666666666666666,0.5555555555555556,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8,0.0,0.0,1.0,1.0,Simplify if statement,"If we assume we have this little snippet of code:

string str = ""checked"";
bool test1;

if (str == ""checked"")
{
    test1 = true;
}
else
{
    test1 = false;
}


Is it bad practice to change a simple statement like this to the following?:

bool test2 = (str == ""checked"");


Because they work exactly the same, and work as required, so I can't imagine how it would be. However, as a young, inexperienced programmer I am not aware of whether such a thing is frowned upon or not. Can anyone tell me, if this is NOT ok, why not?

The following test program:

using System;

public class Test
{

    public static void Main()
    {
        string str = ""checked"";

        bool test1;

        if (str == ""checked"")
        {
            test1 = true;
        }
        else
        {
            test1 = false;
        }

        bool test2 = (str == ""checked"");

        bool test3 = (str != ""checked"");

        Console.WriteLine(test1.ToString());
        Console.WriteLine(test2.ToString());
        Console.WriteLine(test3.ToString());
    }
}


Outputs:

True
True
False


Any insight etc is appreciated.
","I would be very annoyed at someone who used the long form when the statement is that simple.

It hints that the one who wrote it either doesn't understand boolean data types, or doesn't realize == is independent of if.
"
996,996,1573,Why is CuSO4 used as electrolyte while purifying copper?,"During the electrolytic purification of copper, the electrolyte is taken as copper(II) sulphate ($\ce{CuSO_4}$). Is there any particular reason for this? Could another salt of copper, say $\ce{CuCl_2}$ work?

I mean, I don't see any reason why it shouldn't. The only difference will be, that at the anode chlorine instead of oxygen will be evolved, which doesn't seem to be such a big thing. 

Why, then, is $\ce{CuSO_4}$ preferred?  
",Gerard,https://chemistry.stackexchange.com/users/1888,"During copper electrorefining, impure $\ce{Cu}$ from the anode is oxidized and dissolved, while $\ce{Cu^2+}$ is reduced at the cathode, forming the deposit of refined copper. Because anodic impurities which are less noble than copper – most notably $\ce{Ni}$, $\ce{As}$ and $\ce{Sb}$ – also dissolve in the electrolyte, the cell voltage is kept in the range of 0.2-0.4 V to avoid co-deposition of these metals at the cathode. 

Copper dissolution is the main oxidation half-reaction at the anode, and the oxidation of anions from the electrolyte needs to be minimized, since it is an unwanted side reaction which reduces current efficiency of the process. In a $\ce{CuSO4}$ electrolyte, this would be oxidation of $\ce{OH-}$ (from water dissociation, so concentration will be low) to $\ce{O2}$, while in a $\ce{CuCl2}$ solution, $\ce{Cl-}$ will be oxidized to chlorine gas, which would present a greater hazard because of its toxicity.

The electric conductivity of the electrolyte is another important factor, which varies with different copper salts and their concentrations. $\ce{CuCl2}$ and $\ce{CuSO4}$ are both readily soluble in water; however, the relative molar conductivities of these solutions will be different. In this study, a copper chloride electrolyte proved to be inferior to copper sulfate and copper nitrate in terms of deposit quality and stability of cell potential.
",Jannis Andreska,https://chemistry.stackexchange.com/users/5016,http://chemistry.stackexchange.com/questions/6778/why-is-cuso4-used-as-electrolyte-while-purifying-copper,SCIENCE,chemistry.stackexchange.com,0.8333333333333334,0.8333333333333334,0.0,1.0,1.0,1.0,0.5,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.8333333333333334,0.8333333333333334,0.8333333333333334,1.0,1.0,0.7,0.0,0.0,1.0,0.6666666666666666,Why use sulfuric acid as electrolyte while purifying copper?,"During the electrolytic purification of copper, the electrolyte is taken as copper(II) sulphate ($\ce{CuSO_4}$). Is there any particular reason for this? Could another salt of copper, say $\ce{CuCl_2}$ work?

I mean, I don't see any reason why it shouldn't. The only difference will be, that at the anode chlorine instead of oxygen will be evolved, which doesn't seem to be such a big thing. 

Why, then, is $\ce{CuSO_4}$ preferred?  
","During copper electrorefining, impure $\ce{Cu}$ from the anode is oxidized and dissolved, while $\ce{Cu^2+}$ is reduced at the cathode, forming the deposit of refined copper. Because anodic impurities which are less noble than copper – most notably $\ce{Ni}$, $\ce{As}$ and $\ce{Sb}$ – also dissolve in the electrolyte, the cell voltage is kept in the range of 0.2-0.4 V to avoid co-deposition of these metals at the cathode. 

Copper dissolution is the main oxidation half-reaction at the anode, and the oxidation of anions from the electrolyte needs to be minimized, since it is an unwanted side reaction which reduces current efficiency of the process. In a $\ce{CuSO4}$ electrolyte, this would be oxidation of $\ce{OH-}$ (from water dissociation, so concentration will be low) to $\ce{O2}$, while in a $\ce{CuCl2}$ solution, $\ce{Cl-}$ will be oxidized to chlorine gas, which would present a greater hazard because of its toxicity.

The electric conductivity of the electrolyte is another important factor, which varies with different copper salts and their concentrations. $\ce{CuCl2}$ and $\ce{CuSO4}$ are both readily soluble in water; however, the relative molar conductivities of these solutions will be different. In this study, a copper chloride electrolyte proved to be inferior to copper sulfate and copper nitrate in terms of deposit quality and stability of cell potential.
"
3432,3432,5458,"Is there a iOS Configuration Profile Key for ""Find My iPhone?""","I've been looking at this page:

http://developer.apple.com/library/ios/#featuredarticles/iPhoneConfigurationProfileRef/Introduction/Introduction.html

for the configuration profile keys. I couldn't find one for the feature ""Find My iPhone."" Is there a key for that? If so what is it?
",Di Zou,https://stackoverflow.com/users/873268,"I agree with @titaniumdecoy (and +1 to him).  

If you are trying to push ""Find My iPhone"" onto all your iPhone(s) and you have more than just 3 or 4 iPhones to manage, maybe you can use something like Apple's iPhone Configuration Utility for Windows to install the app onto all the iPhones you have control over. 
",Michael Dautermann,https://stackoverflow.com/users/981049,http://stackoverflow.com/questions/8392213/is-there-a-ios-configuration-profile-key-for-find-my-iphone,STACKOVERFLOW,stackoverflow.com,1.0,0.8333333333333334,0.0,1.0,1.0,1.0,0.5,0.5,0.5,0.0,0.0,0.5,0.0,0.0,0.0,0.5,1.0,0.0,0.0,0.0,0.8333333333333334,0.5,0.5,0.8333333333333334,0.6666666666666666,0.4,0.5,0.5,0.0,0.8333333333333334,Is there an IOS profile key for find my iPhone,"I've been looking at this page:

http://developer.apple.com/library/ios/#featuredarticles/iPhoneConfigurationProfileRef/Introduction/Introduction.html

for the configuration profile keys. I couldn't find one for the feature ""Find My iPhone."" Is there a key for that? If so what is it?
","I agree with @titaniumdecoy (and +1 to him).  

If you are trying to push ""Find My iPhone"" onto all your iPhone(s) and you have more than just 3 or 4 iPhones to manage, maybe you can use something like Apple's iPhone Configuration Utility for Windows to install the app onto all the iPhones you have control over. 
"
5742,5742,9091,What is the cardinality of the family of unlabelled bipartite graphs on n vertices?,"I have attempted to calculate the number of unlabelled bipartite graphs as follows:


  Let $G = (V_1, V_2, E)$ be a bipartite graph on $n$ vertices with $|V_1| = m$ and $|V_2| = n-m$. Assume without loss of generality that $|V_1| \leq |V_2|$ so $m \leq \left\lfloor \frac{n}{2} \right\rfloor$. If $G$ is complete bipartite then it has $m(n-m)$ edges since each of the vertices in $V_1$ is connected to each in $V_2$. Thus, the total number of bipartite graphs with parts of size $m$ and $n-m$ is $2^{m(n-m)}$. In order to find the total number of possible bipartite graphs on $n$ vertices we sum over all possible $m$:
  \begin{align}
\sum^{\left\lfloor \frac{n}{2} \right\rfloor}_{m=1} 2^{m(n-m)}
\end{align}


However, I notice that I have counted labelled bipartite graphs where I need the number of unlabelled graphs. I'm struggling to see how to account for this.
",Andrew,https://mathoverflow.net/users/31128,"The answer to your problem is detailed in the Thesis of Ji Li (2007)
Counting Prime Graphs and Point-Determining Graphs Using Combinatorial Theory of Species
http://people.brandeis.edu/~gessel/homepage/students/jilithesis.pdf

Section 4.4. p.112
The formulae are to be found p.115.
",Samuel Vidal,https://mathoverflow.net/users/20997,http://mathoverflow.net/questions/120674,SCIENCE,mathoverflow.net,0.7777777777777778,0.5555555555555556,0.0,0.3333333333333333,1.0,1.0,0.5555555555555556,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.0,0.8888888888888888,0.7777777777777778,0.5555555555555556,0.7777777777777778,1.0,0.8,0.3333333333333333,0.0,0.3333333333333333,0.7777777777777778,What is the cardinality of a family of unmarked bipartite graphs on n vertices?,"I have attempted to calculate the number of unlabelled bipartite graphs as follows:


  Let $G = (V_1, V_2, E)$ be a bipartite graph on $n$ vertices with $|V_1| = m$ and $|V_2| = n-m$. Assume without loss of generality that $|V_1| \leq |V_2|$ so $m \leq \left\lfloor \frac{n}{2} \right\rfloor$. If $G$ is complete bipartite then it has $m(n-m)$ edges since each of the vertices in $V_1$ is connected to each in $V_2$. Thus, the total number of bipartite graphs with parts of size $m$ and $n-m$ is $2^{m(n-m)}$. In order to find the total number of possible bipartite graphs on $n$ vertices we sum over all possible $m$:
  \begin{align}
\sum^{\left\lfloor \frac{n}{2} \right\rfloor}_{m=1} 2^{m(n-m)}
\end{align}


However, I notice that I have counted labelled bipartite graphs where I need the number of unlabelled graphs. I'm struggling to see how to account for this.
","The answer to your problem is detailed in the Thesis of Ji Li (2007)
Counting Prime Graphs and Point-Determining Graphs Using Combinatorial Theory of Species
http://people.brandeis.edu/~gessel/homepage/students/jilithesis.pdf

Section 4.4. p.112
The formulae are to be found p.115.
"
5499,5499,8724,Do cold blooded animals generate any heat?,"In explaining energy and work to an 8 year-old I said that all conversion of energy generates heat as a by-product.  For example, cars generate heat in their engines and running generates heat in our bodies.  Then the 8 year-old said, except for cold-blooded animals.

So my question is, do cold-blooded animals generate any heat in their conversion of stored energy (food, fat, etc) into motion?  If they generate heat, why are they cold-blooded?
",Jeff,https://biology.stackexchange.com/users/3031,"I'm fairly certain that you were right in your initial hunch that heat is almost always a byproduct of metabolism (which is never 100% efficient). The difference between endothermic ('warm-blooded') and ectothermic ('cold-blooded') organisms is just where the primary source of body temperature regulation comes from (either from metabolic reactions in endotherms or from the environment in ectotherms).
",Atticus29,https://biology.stackexchange.com/users/1906,http://biology.stackexchange.com/questions/7076/do-cold-blooded-animals-generate-any-heat,SCIENCE,biology.stackexchange.com,1.0,0.6666666666666666,0.0,1.0,1.0,1.0,0.6666666666666666,0.7777777777777778,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,1.0,0.0,0.8888888888888888,0.6666666666666666,0.6666666666666666,0.6666666666666666,1.0,0.8,0.0,0.0,1.0,0.7777777777777778,Can cold-blooded animals produce heat?,"When explaining energy and work to an 8-year-old, I said that all energy conversion is a by-product of heat generation. For example, cars generate heat in the engine, while running in our bodies generates heat. Then the 8-year-old said, except for cold-blooded animals.","I'm sure your initial hunch was right. Heat is almost always a byproduct of metabolism (never 100% effective). The difference between endothermic (""warm blood"") and exothermic (""cold blood"") organisms is the main source of thermoregulation (either from endothermic metabolic reactions or from exothermic environments)."
2334,2334,3719,Daydream with transparent background,"I'm trying to implement a daydream service with a transparent background.

I wrote the following code:

public void onAttachedToWindow() {
    super.onAttachedToWindow();
    setContentView(R.layout.mydream);
    getWindow().setBackgroundDrawable(new ColorDrawable(0));
    .
    .
    .
}


But when I start up the daydream, the background is only transparent for 1 second. After that it turns to black background.

Can anyone help me with this?
",0s0ft,https://stackoverflow.com/users/610839,"This question may have the answer you need:
How to create Transparent Activity in Android?

You can do that by creating a Transparent theme and applying it to your activity.
",Luiza Utsch,https://stackoverflow.com/users/2177999,http://stackoverflow.com/questions/16822410/daydream-with-transparent-background,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.4444444444444444,0.0,0.5,1.0,1.0,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.6666666666666666,0.0,0.7777777777777778,0.6666666666666666,0.4444444444444444,0.6666666666666666,1.0,0.5,0.0,0.3333333333333333,0.3333333333333333,0.7777777777777778,Daydream on transparent background,"I'm trying to implement a daydream service with a transparent background.

I wrote the following code:

public void onAttachedToWindow() {
    super.onAttachedToWindow();
    setContentView(R.layout.mydream);
    getWindow().setBackgroundDrawable(new ColorDrawable(0));
    .
    .
    .
}


But when I start up the daydream, the background is only transparent for 1 second. After that it turns to black background.

Can anyone help me with this?
","This question may have the answer you need:
How to create Transparent Activity in Android?

You can do that by creating a Transparent theme and applying it to your activity.
"
1742,1742,2754,Entire website in Silverlight 4. Practical or not?,"Similar question: Using Silverlight for an entire website?

That question is over 2 years old. Silverlight has gone a long way from Silverlight 1.0 Beta 1 to Silverlight 4.0 Final. Would it be practical to create a full Silverlight web application these days? I plan to deploy the website sometime around Q1 2011. 

I have thought about going ASP.NET + AJAX way, but it just won't give me the same rich features as Silverlight.

A lot of people when they hear ASP.NET or Silverlight instantly think about business or enterprise applications. But all I want to create is a fansite, with rich user interface and a great ""WOW"" factor.
",Sahat Yalkabov,https://stackoverflow.com/users/274117,"Absolutely you can. And if your target users all have SL4 it might look very stylish. however many people who don't have SL will be put off, and many many picky technical people will be dismayed or refuse to go there.

If you had a site for skateboarders or graphic designers, then it would be something you could probably get away with... you do see sites like this for media-focused companies e.g sites for films or video games.

edit: reading the linked thread, I'd say most of the top-ranked answers still apply - they just apply a bit less these days. Corporate sites may block SL, grannies may not understand it, some people have slow web. But if you are aiming at young hip people it's feasible and the stylistic bonus could outweigh the problems for a minority of users. Weigh your target demographic carefully...
",Mr. Boy,https://stackoverflow.com/users/197229,http://stackoverflow.com/questions/3070882/entire-website-in-silverlight-4-practical-or-not,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.5555555555555556,0.0,1.0,0.6666666666666666,0.0,0.4444444444444444,0.4444444444444444,0.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.3333333333333333,0.0,0.7777777777777778,0.8333333333333334,0.6666666666666666,0.8333333333333334,1.0,0.9,0.3333333333333333,0.0,0.6666666666666666,1.0,The entire site is in Silverlight 4. Is it practical?,"Similar question: Using Silverlight for an entire website?

That question is over 2 years old. Silverlight has gone a long way from Silverlight 1.0 Beta 1 to Silverlight 4.0 Final. Would it be practical to create a full Silverlight web application these days? I plan to deploy the website sometime around Q1 2011. 

I have thought about going ASP.NET + AJAX way, but it just won't give me the same rich features as Silverlight.

A lot of people when they hear ASP.NET or Silverlight instantly think about business or enterprise applications. But all I want to create is a fansite, with rich user interface and a great ""WOW"" factor.
","Absolutely you can. And if your target users all have SL4 it might look very stylish. however many people who don't have SL will be put off, and many many picky technical people will be dismayed or refuse to go there.

If you had a site for skateboarders or graphic designers, then it would be something you could probably get away with... you do see sites like this for media-focused companies e.g sites for films or video games.

edit: reading the linked thread, I'd say most of the top-ranked answers still apply - they just apply a bit less these days. Corporate sites may block SL, grannies may not understand it, some people have slow web. But if you are aiming at young hip people it's feasible and the stylistic bonus could outweigh the problems for a minority of users. Weigh your target demographic carefully...
"
1932,1932,3079,After what period of time does a PhD position count towards the two possible attempts in Germany?,"I am not sure if this holds true everywhere, but here in Germany you only get two attemps at getting your PhD. I am currently wondering at which point it counts towards those two attempts. If I were to start a position and quit during the first few weeks, would it still count?
",Simon Eismann,https://academia.stackexchange.com/users/33688,"I think you are conflating the issue of being a Wissenschaftliche Mitarbeiter (research personnel) with that of receiving a PhD. It is possible to work in a ""research"" position for an extended period of time without being part of a PhD process, so such positions obviously would not count towards ""two attempts.""

In addition, it is entirely possible that people might have to move or change positions because of personal circumstances (health, parental leave, or the two-body problem, among other reasons). Restricting people to two ""shots"" in this manner would be unfair.

Instead, I believe what you are referring to is the rule that there are at most two attempts at the thesis defense. If you fail the first one, then you must wait for a prescribed period of time (but not longer than another period of time), and attempt again to defend your thesis. If the second attempt fails, then you are not allowed further attempts. (However, if you work with your advisor, there shouldn't be a problem here, as you shouldn't be allowed to hold a defense if there's a substantial risk of failure!)
",aeismail,https://academia.stackexchange.com/users/53,http://academia.stackexchange.com/questions/44283/after-what-period-of-time-does-a-phd-position-count-towards-the-two-possible-att,LIFE_ARTS,academia.stackexchange.com,1.0,0.8888888888888888,0.0,1.0,1.0,1.0,0.5555555555555556,0.6666666666666666,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.3333333333333333,0.0,0.6666666666666666,1.0,"In Germany, after what period of time can a doctor's degree be counted as two possible attempts?","I'm not sure if this applies anywhere, but in Germany, you only have two attempts to get a PhD. Now I want to know where these two attempts count. If I start a job and quit in the first few weeks, will that count?","I think you are conflating the issue of being a Wissenschaftliche Mitarbeiter (research personnel) with that of receiving a PhD. It is possible to work in a ""research"" position for an extended period of time without being part of a PhD process, so such positions obviously would not count towards ""two attempts.""

In addition, it is entirely possible that people might have to move or change positions because of personal circumstances (health, parental leave, or the two-body problem, among other reasons). Restricting people to two ""shots"" in this manner would be unfair.

Instead, I believe what you are referring to is the rule that there are at most two attempts at the thesis defense. If you fail the first one, then you must wait for a prescribed period of time (but not longer than another period of time), and attempt again to defend your thesis. If the second attempt fails, then you are not allowed further attempts. (However, if you work with your advisor, there shouldn't be a problem here, as you shouldn't be allowed to hold a defense if there's a substantial risk of failure!)
"
545,545,858,How Do I Fix Excess Contribution Withdrawl,"This is a kind of a straight forward situation but I made it little complex due to my limited knowledge of Traditional IRA and 401(k).

In the year 2012, I was working as a contractor. I had a traditional IRA account with Fidelity and contributed $4000 to it for the Tax Year 2012.

Later in that year (2012), I got a full time job and my employer enrolled me in their 401(k) plan.

When the time came to file the taxes, I called Fidelity and explained them the situation as I thought I cannot contribute to Traditional IRA as I have employer sponsored 401(k). Someone at the Fidelity said I can withdraw the money as ""Excess Contribution Withdrawal"". So I filled out the form and pulled $4000 from it. I did not claim the $4000 contribution in my tax return as ""Traditional IRA Contribution"". I just treated it as like I never contributed that money.

Now I got 1099-R from them saying the $4000 that I withdraw was actually processed as ""Early Withdrawal"" and I have to pay tax (33%) on it.

When I explained them what happened in 2012, they said they may be able to go back and correct the problem.

What I do not understand is that even if they correct the situation and send me revised 1099-R, I will still pay Tax on $4000 as it will be treated as ""Excess Contribution"".

Why can this not be simple as I made a mistake when I contributed the money and then I took it back and did not claim so that should be treated as like it never went to my IRA account.

What can I do to avoid paying ""Excess Withdrawal"" tax as I already paid the tax on this $4000 as I never claimed them on my 2012 return.

Am I missing something here or am I not able to explain them the situation correctly?
",Asdfg,https://money.stackexchange.com/users/5105,"I think there are several issues here.

First, there's the contribution. As littleadv said, there is no excess contribution. Excess contribution is only if you exceed the contribution limit. The contribution limit for Traditional IRAs does not depend on how high your income goes or whether you have a 401(k). It's the deduction limit that may depend on those things. Not deducting it is perfectly legitimate, and is completely different than an ""excess contribution"", which has a penalty.

Second, the withdrawal. You are allowed to withdraw contributions made during a year, plus any earnings from those contributions, before the tax filing deadline for the taxes of that year (which is April 15 of the following year, or even up to October 15 of the following year), and it will be treated as if the contribution never happened. No penalties. The earnings will be taxed as regular income (as if you put it in a bank account). That sounds like what you did. So the withdrawal was not an ""early withdrawal"", and the 1099-R should reflect that (what distribution code did they put?).

Third, even if (and it does not sound like the case, but if) it doesn't qualify as a return of contributions before the tax due date as described above (maybe you withdrew it after October 15 of the following year), as littleadv mentioned, your contribution was a non-deductible contribution, and when withdrawing it, only the earnings portion (which after such a short time should only be a very small part of the distribution) would be subject to tax and penalty.
",user102008,https://money.stackexchange.com/users/5920,http://money.stackexchange.com/questions/29315/how-do-i-fix-excess-contribution-withdrawl,LIFE_ARTS,money.stackexchange.com,1.0,0.3333333333333333,0.0,0.0,1.0,0.3333333333333333,0.8888888888888888,0.8888888888888888,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,1.0,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.6666666666666666,1.0,1.0,How to determine the over contribution withdrawal,"This is a kind of a straight forward situation but I made it little complex due to my limited knowledge of Traditional IRA and 401(k).

In the year 2012, I was working as a contractor. I had a traditional IRA account with Fidelity and contributed $4000 to it for the Tax Year 2012.

Later in that year (2012), I got a full time job and my employer enrolled me in their 401(k) plan.

When the time came to file the taxes, I called Fidelity and explained them the situation as I thought I cannot contribute to Traditional IRA as I have employer sponsored 401(k). Someone at the Fidelity said I can withdraw the money as ""Excess Contribution Withdrawal"". So I filled out the form and pulled $4000 from it. I did not claim the $4000 contribution in my tax return as ""Traditional IRA Contribution"". I just treated it as like I never contributed that money.

Now I got 1099-R from them saying the $4000 that I withdraw was actually processed as ""Early Withdrawal"" and I have to pay tax (33%) on it.

When I explained them what happened in 2012, they said they may be able to go back and correct the problem.

What I do not understand is that even if they correct the situation and send me revised 1099-R, I will still pay Tax on $4000 as it will be treated as ""Excess Contribution"".

Why can this not be simple as I made a mistake when I contributed the money and then I took it back and did not claim so that should be treated as like it never went to my IRA account.

What can I do to avoid paying ""Excess Withdrawal"" tax as I already paid the tax on this $4000 as I never claimed them on my 2012 return.

Am I missing something here or am I not able to explain them the situation correctly?
","I think there are several issues here.

First, there's the contribution. As littleadv said, there is no excess contribution. Excess contribution is only if you exceed the contribution limit. The contribution limit for Traditional IRAs does not depend on how high your income goes or whether you have a 401(k). It's the deduction limit that may depend on those things. Not deducting it is perfectly legitimate, and is completely different than an ""excess contribution"", which has a penalty.

Second, the withdrawal. You are allowed to withdraw contributions made during a year, plus any earnings from those contributions, before the tax filing deadline for the taxes of that year (which is April 15 of the following year, or even up to October 15 of the following year), and it will be treated as if the contribution never happened. No penalties. The earnings will be taxed as regular income (as if you put it in a bank account). That sounds like what you did. So the withdrawal was not an ""early withdrawal"", and the 1099-R should reflect that (what distribution code did they put?).

Third, even if (and it does not sound like the case, but if) it doesn't qualify as a return of contributions before the tax due date as described above (maybe you withdrew it after October 15 of the following year), as littleadv mentioned, your contribution was a non-deductible contribution, and when withdrawing it, only the earnings portion (which after such a short time should only be a very small part of the distribution) would be subject to tax and penalty.
"
5045,5045,8027,Get current Activity with Android,"I have a method that scans the position and gets called on every activity I have, everytime an actions trigger I need to show an alertDialog, this is the code:

AlertDialog.Builder builder = new AlertDialog.Builder(mMainActivity.this);
                        builder.setMessage(""test"")
                           .setCancelable(false)
                           .setPositiveButton(""go"", new DialogInterface.OnClickListener() {
                               public void onClick(DialogInterface dialog, int id) {
                                   Intent intent = new Intent(mMainActivity.this,LocationDetails.class);
                                    intent.putExtra(""placeId"",1);
                                    startActivity(intent);

                               }
                           })
                           .setNegativeButton(""cancel"", new DialogInterface.OnClickListener() {
                               public void onClick(DialogInterface dialog, int id) {

                                    dialog.cancel();
                               }
                           });
                        AlertDialog alert = builder.create();
                        alert.show();


But How can I create the alert on the current activity? Because now it only gets created on AlertDialog.Builder(mMainActivity.this);
",Signo,https://stackoverflow.com/users/3789527,"Have this AlertDialog logic in a public class and make call using a method with passing context .

For example:

showAlert(youractivitycontext);


Use the Context as your current activity.
",Gowtham Kumar,https://stackoverflow.com/users/1614270,http://stackoverflow.com/questions/30511271/get-current-activity-with-android,STACKOVERFLOW,stackoverflow.com,1.0,0.3333333333333333,0.0,1.0,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.3333333333333333,0.0,1.0,Get current activity using Android,"I have a method that scans the position and gets called on every activity I have, everytime an actions trigger I need to show an alertDialog, this is the code:

AlertDialog.Builder builder = new AlertDialog.Builder(mMainActivity.this);
                        builder.setMessage(""test"")
                           .setCancelable(false)
                           .setPositiveButton(""go"", new DialogInterface.OnClickListener() {
                               public void onClick(DialogInterface dialog, int id) {
                                   Intent intent = new Intent(mMainActivity.this,LocationDetails.class);
                                    intent.putExtra(""placeId"",1);
                                    startActivity(intent);

                               }
                           })
                           .setNegativeButton(""cancel"", new DialogInterface.OnClickListener() {
                               public void onClick(DialogInterface dialog, int id) {

                                    dialog.cancel();
                               }
                           });
                        AlertDialog alert = builder.create();
                        alert.show();


But How can I create the alert on the current activity? Because now it only gets created on AlertDialog.Builder(mMainActivity.this);
",Use this alertdialog logic in a public class and call it with a method with a delivery context.
4046,4046,6459,How do I list all files a given grunt task depends on for a Makefile?,"As Grunt doesn't support only rebuilding what has changed, I'd like to wrap a Makefile around it, to just compute the set of ""input"" files and not invoke grunt at all, unless any of them have changed since last build.

Can you tell grunt to just list what files a given task would depend on on stdout somehow?
",ecmanaut,https://stackoverflow.com/users/1130377,"Based on jsoverson's answer, I managed to cobble together a proof-of-concept that defers dependency tracking to the Gruntfile, so I can add Makefile rules that invoke the grunt bits to build the project. This project uses coffee-script (use http://js2coffee.org/ to convert to js if you want to reuse this for some non-coffee project), so in my Gruntfile.coffee I added

gruntGetPaths = (fn) -&gt; -&gt;
  taskConfig = grunt.config @args.join '.'
  grunt.task.normalizeMultiTaskFiles(taskConfig)
    .forEach fn ? (files) -&gt;
      files.src.forEach (path) -&gt;
        console.log path

grunt.registerTask 'src', gruntGetPaths
grunt.registerTask 'dst', gruntGetPaths (files) -&gt; console.log files.dest


giving me the grunt src:... and grunt dst:... rules that produce grunt-junk-wrapped file lists.

It seems the junk is guaranteed to be colorized / adds a trailing empty line (at least with grunt v0.4.1 / grunt-cli v0.1.9), so chopping that off by piping their output to egrep -v '\e|^$' worked.

Near the top of my Makefile I added some macros for that:

define GRUNT
    $(shell grunt --no-write $1 | egrep -v '\e|^$$')
endef
define SRC
    $(call GRUNT,src:$1)
endef
define DST
    $(call GRUNT,dst:$1)
endef


...and then rules that borrow knowledge from the Gruntfile:

$(call DST,stylus:compile): coffee $(call SRC,stylus:compile)
    grunt stylus

$(call DST,coffee:glob_to_multiple): coffee $(call SRC,coffee:glob_to_multiple)
    grunt coffee

$(call DST,uglify:my_target): coffee $(call SRC,uglify:my_target)
    grunt uglify

coffee:
    npm install 2&gt;&amp;1 | tee $@


...which has corresponding setup looking like this:

  @initConfig
    pkg: grunt.file.readJSON ""package.json""

    stylus:
      compile:
        options:
          paths: [""src/stylus/""]
          import: [""nib""]
        files:
          ""stylesheets/foo.css"": ""src/stylus/foo.styl""
          ""stylesheets/foo-dev.css"": [""src/stylus/foo.styl"", ""src/stylus/foo-dev.styl""]

    coffee:
      glob_to_multiple:
        expand: true
        cwd: 'src/coffee/'
        src: ['*.coffee']
        dest: 'javascripts/'
        ext: '.js'

    uglify:
      my_target:
        files:
          ""javascripts/foo.min.js"": [""javascripts/foo.js""]


This works, but is slow. Given a bare grunt stylus run that takes 2.94s to run, running these make rules to regenerate css takes another 5.41s of pure overhead, which is sort of horrible - and if I nuke all the generated files and try to regenerate the min.js, there is no dependency resolution as the glob rules can't be traced back to find all intermediate files.

So while it's possible to do this, it did not end up being a solution to the problem ""running grunt is slow and stupid, when no source files have changed"", as running grunt stylus coffee uglify in this project takes 3.25 seconds to reproduce what was already there, and a bare make run that just resolves dependencies and finds nothing relevant changed takes over five.

It would of course be great if grunt had its own dependency management to know when it can exit immediately, like our grandfather's tools would. :-)
",ecmanaut,https://stackoverflow.com/users/1130377,http://stackoverflow.com/questions/18647056/how-do-i-list-all-files-a-given-grunt-task-depends-on-for-a-makefile,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.5555555555555556,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.6666666666666666,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,0.8888888888888888,How do I list all the files of the makefile that a given grunt task depends on?,"Since grunt does not support rebuilding only what has changed, I want to wrap a makefile around it so that only the input file set is evaluated, and grunt is not called, unless any of them have changed since the last build.","Based on jsoverson's answer, I managed to cobble together a proof-of-concept that defers dependency tracking to the Gruntfile, so I can add Makefile rules that invoke the grunt bits to build the project. This project uses coffee-script (use http://js2coffee.org/ to convert to js if you want to reuse this for some non-coffee project), so in my Gruntfile.coffee I added

gruntGetPaths = (fn) -&gt; -&gt;
  taskConfig = grunt.config @args.join '.'
  grunt.task.normalizeMultiTaskFiles(taskConfig)
    .forEach fn ? (files) -&gt;
      files.src.forEach (path) -&gt;
        console.log path

grunt.registerTask 'src', gruntGetPaths
grunt.registerTask 'dst', gruntGetPaths (files) -&gt; console.log files.dest


giving me the grunt src:... and grunt dst:... rules that produce grunt-junk-wrapped file lists.

It seems the junk is guaranteed to be colorized / adds a trailing empty line (at least with grunt v0.4.1 / grunt-cli v0.1.9), so chopping that off by piping their output to egrep -v '\e|^$' worked.

Near the top of my Makefile I added some macros for that:

define GRUNT
    $(shell grunt --no-write $1 | egrep -v '\e|^$$')
endef
define SRC
    $(call GRUNT,src:$1)
endef
define DST
    $(call GRUNT,dst:$1)
endef


...and then rules that borrow knowledge from the Gruntfile:

$(call DST,stylus:compile): coffee $(call SRC,stylus:compile)
    grunt stylus

$(call DST,coffee:glob_to_multiple): coffee $(call SRC,coffee:glob_to_multiple)
    grunt coffee

$(call DST,uglify:my_target): coffee $(call SRC,uglify:my_target)
    grunt uglify

coffee:
    npm install 2&gt;&amp;1 | tee $@


...which has corresponding setup looking like this:

  @initConfig
    pkg: grunt.file.readJSON ""package.json""

    stylus:
      compile:
        options:
          paths: [""src/stylus/""]
          import: [""nib""]
        files:
          ""stylesheets/foo.css"": ""src/stylus/foo.styl""
          ""stylesheets/foo-dev.css"": [""src/stylus/foo.styl"", ""src/stylus/foo-dev.styl""]

    coffee:
      glob_to_multiple:
        expand: true
        cwd: 'src/coffee/'
        src: ['*.coffee']
        dest: 'javascripts/'
        ext: '.js'

    uglify:
      my_target:
        files:
          ""javascripts/foo.min.js"": [""javascripts/foo.js""]


This works, but is slow. Given a bare grunt stylus run that takes 2.94s to run, running these make rules to regenerate css takes another 5.41s of pure overhead, which is sort of horrible - and if I nuke all the generated files and try to regenerate the min.js, there is no dependency resolution as the glob rules can't be traced back to find all intermediate files.

So while it's possible to do this, it did not end up being a solution to the problem ""running grunt is slow and stupid, when no source files have changed"", as running grunt stylus coffee uglify in this project takes 3.25 seconds to reproduce what was already there, and a bare make run that just resolves dependencies and finds nothing relevant changed takes over five.

It would of course be great if grunt had its own dependency management to know when it can exit immediately, like our grandfather's tools would. :-)
"
2081,2081,3314,High ping on games while streaming,"I'm streaming with Elgato Capture Card to Twitch. I get high pings on games while streaming (1700kbps). How can I decrease pings while streaming? Here is my bandwidth:


",WalkerJetBat,https://gaming.stackexchange.com/users/76837,"You are almost completely saturating your upload bandwidth with the stream you're sending. Despite streaming out not using much of your download speed, you need plenty of bandwidth available in both directions to have reduced latency in games.

As I see it, you've two options.


Increase the available bandwidth on your upload speed. You can achieve this by either reducing the quality of your stream, or increasing the available upload speed.
Purchase a router with Quality of Service (QoS), this will you to prioritise traffic. You need to set a lower priority on stream traffic, so the game latency is reduced.


Ideally, I'd suggest you considered implementing both options, if you want the best performance for both the stream and the game.

For what it's worth, I do think trying to stream at 1700kbps is way too high for an upload speed of 1.92Mbps. For best performance, I'd be reducing that to around half of your available upload bandwidth, i.e. 1000kbps.
",Bryan,https://gaming.stackexchange.com/users/22078,http://gaming.stackexchange.com/questions/168457/high-ping-on-games-while-streaming,CULTURE,gaming.stackexchange.com,1.0,1.0,0.0,0.5,0.5,1.0,0.5,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.5,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,0.8333333333333334,High Ping of games in streaming media,I'm twitching with the elgato capture card. I get high Ping when playing streaming (1700kbps). How to reduce Ping during streaming? This is my bandwidth:,"You are almost completely saturating your upload bandwidth with the stream you're sending. Despite streaming out not using much of your download speed, you need plenty of bandwidth available in both directions to have reduced latency in games.

As I see it, you've two options.


Increase the available bandwidth on your upload speed. You can achieve this by either reducing the quality of your stream, or increasing the available upload speed.
Purchase a router with Quality of Service (QoS), this will you to prioritise traffic. You need to set a lower priority on stream traffic, so the game latency is reduced.


Ideally, I'd suggest you considered implementing both options, if you want the best performance for both the stream and the game.

For what it's worth, I do think trying to stream at 1700kbps is way too high for an upload speed of 1.92Mbps. For best performance, I'd be reducing that to around half of your available upload bandwidth, i.e. 1000kbps.
"
5974,5974,9473,SQL Server 2000 - 'Performance: Deadlock',"We had to restart our SQL Server today, we had made no changes to it.

When it came back up we immediately started getting this error from the server


  DATE/TIME:    2/27/2014 3:09:31 PM
  
  DESCRIPTION:  The SQL Server performance counter 'Number of
  Deadlocks/sec' (instance 'Database') of object 'SQLServer:Locks' is
  now above the threshold of 1.00 (the current value is 2.00).
  
  COMMENT:  (None)
  
  JOB RUN:  (None)


We ran the DBCC TRACEON (1204) command and have watched the log's but it's not reporting any deadlocks.

Any idea what could trigger this to just go off? We are getting the alert every minute yet can't find any actual deadlocks.

Edit: I should add that before this reboot we had never received this error

Edit 2: We used SQL Server Profiler as well to look for deadlocks, let it run for 5 minutes over which we received 5 error alerts and when we checked the details we had NO deadlocks found.

Edit 3: March 06/2014: Ran the query and it worked, but it reports what our other details have said that we have no locks we where still getting the error above the whole time.

Thanks again for all your help!



Edit 4: March 06/2014: I ran the query and here is a sampling of the result set, I will admit I am not exactly sure what I am looking at here, that is to say I am not sure if it shows me something that I can act on or not.



Edit 5: March 07/2014: Image below shows the Alert that generates this error all of a sudden.



Thanks
",Stephen Archbold,https://dba.stackexchange.com/users/35059,"Update March 5th 2014

-- Removed the CTE and any options that could be incompatible with SQL SERVER 2000

if OBJECT_ID(N'tempdb..#process', N'U') is not null
    drop table #process
GO

if OBJECT_ID(N'tempdb..#tmp', N'U') is not null
    drop table #tmp
GO

select spid as victim, blocked as blocker
into #process
from master..sysprocesses p1 
where spid &gt; 50
and blocked &gt; 0
and spid &lt;&gt; blocked

insert into #process
select spid as victim, blocked as blocker
from master..sysprocesses p 
inner join #process
on #process.blocker = p.spid
where spid &gt; 50


select  distinct 'dbcc inputbuffer(' + CAST( victim as nvarchar(4)) + ')' as cmd, 'sp_who2 ' + CAST( victim as nvarchar(4)) as spwho, *
into #tmp
from #process 
where blocker = 0
order by victim


select *
from #tmp 
order by victim

DECLARE @cmd nvarchar(400)
DECLARE @spwho nvarchar(12)

DECLARE curseur CURSOR
FOR
    select  cmd, spwho
    from #tmp 
    order by victim

OPEN curseur
FETCH NEXT FROM curseur INTO @cmd, @spwho

WHILE @@FETCH_STATUS = 0
BEGIN
    print (@cmd)
    exec (@cmd)
    print (@spwho)
    exec (@spwho)
    FETCH NEXT FROM curseur INTO @cmd, @spwho
END

CLOSE curseur
DEALLOCATE curseur 

GO

select
    db_name(dbid),
    'dbcc inputbuffer(' + CAST(a.spid as nvarchar(4)) + ')',
    a.spid,
    a.blocked,
    a.status, 
    a.cmd, 
    a.cpu,
    a.waittime,
    a.loginame,
    Base = DB_NAME(a.dbid),
    *
from master.dbo.sysprocesses a
where 1 = 1
    and a.spid &gt; 50
    and spid &lt;&gt; @@spid
order by
    a.blocked desc,
    a.waittime desc,
    a.cpu desc         




Update 3/6/2013

So we've seen that no sessions are being blocked. Now we can also look at all current locks on your system. 

Show locks server wide MSSQL 2000

Monitoring Lock Activity

select convert(varchar(30), suser_sname(p.sid)) as login,
       convert (smallint, req_spid) As spid,
       convert(varchar(30), db_name(rsc_dbid)) As db_name,
       case rsc_dbid when db_id()
            then convert(varchar(30), object_name(rsc_objid))
            else convert(varchar(30), rsc_objid) end As Object,
       rsc_indid As indid,
       substring (lock_type.name, 1, 4) As Type,
       substring (lock_mode.name, 1, 12) As Mode,
       substring (lock_status.name, 1, 5) As Status,
       substring (rsc_text, 1, 16) as Resource
   from master..syslockinfo s
   join master..spt_values lock_type on s.rsc_type = lock_type.number
   join master..spt_values lock_status on s.req_status = lock_status.number
   join master..spt_values lock_mode on s.req_mode = lock_mode.number -1
   join master..sysprocesses p on s.req_spid = p.spid
   where lock_type.type = 'LR'
     and lock_status.type = 'LS'
     and lock_mode.type = 'L'
     and db_name(rsc_dbid) not in ('master', 'msdb', 'tempdb', 'model')
order by spid, lock_type.number
go


The output will you tell you 
1. what type of lock is being held: database, table, page.
2. the mode of the lock: S shared, X exclusive, RangeS-S where a range of values is locked in an index



Update 3/7/2014

I have updated your screen shot with some basic explanations. What we are seeing, is just a bunch of shared database locks. 

To be brief, the locks on your system are shared (in other words, they don't block other sessions from accessing the database) and those locks are meant to prevent the database from being dropped, detached or renamed while data is being read and/or written from and to that database and its contents.

Getting back to your original question; there are no deadlocks or blocked sessions on your server. I don't remember having seen this message before, but from what you are sending back, this is definitely not about deadlocks and more likely to be just an informational message. 

Or use sp_lock

sp_lock [[@spid1 =] 'spid1'] [,[@spid2 =] 'spid2']

Which will give you a more detailed view of all locks currently being held on your server.

http://technet.microsoft.com/en-us/library/aa238824(v=sql.80).aspx
",Craig Efrein,https://dba.stackexchange.com/users/4659,http://dba.stackexchange.com/questions/59843/sql-server-2000-performance-deadlock,TECHNOLOGY,dba.stackexchange.com,0.8888888888888888,0.4444444444444444,0.0,1.0,0.3333333333333333,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,1.0,0.0,0.6666666666666666,1.0,0.7777777777777778,1.0,1.0,0.9333333333333332,1.0,0.3333333333333333,1.0,0.8888888888888888,SQL Server 2000 - Performance: deadlock,"We had to restart our SQL Server today, we had made no changes to it.

When it came back up we immediately started getting this error from the server


  DATE/TIME:    2/27/2014 3:09:31 PM
  
  DESCRIPTION:  The SQL Server performance counter 'Number of
  Deadlocks/sec' (instance 'Database') of object 'SQLServer:Locks' is
  now above the threshold of 1.00 (the current value is 2.00).
  
  COMMENT:  (None)
  
  JOB RUN:  (None)


We ran the DBCC TRACEON (1204) command and have watched the log's but it's not reporting any deadlocks.

Any idea what could trigger this to just go off? We are getting the alert every minute yet can't find any actual deadlocks.

Edit: I should add that before this reboot we had never received this error

Edit 2: We used SQL Server Profiler as well to look for deadlocks, let it run for 5 minutes over which we received 5 error alerts and when we checked the details we had NO deadlocks found.

Edit 3: March 06/2014: Ran the query and it worked, but it reports what our other details have said that we have no locks we where still getting the error above the whole time.

Thanks again for all your help!



Edit 4: March 06/2014: I ran the query and here is a sampling of the result set, I will admit I am not exactly sure what I am looking at here, that is to say I am not sure if it shows me something that I can act on or not.



Edit 5: March 07/2014: Image below shows the Alert that generates this error all of a sudden.



Thanks
","Update March 5th 2014

-- Removed the CTE and any options that could be incompatible with SQL SERVER 2000

if OBJECT_ID(N'tempdb..#process', N'U') is not null
    drop table #process
GO

if OBJECT_ID(N'tempdb..#tmp', N'U') is not null
    drop table #tmp
GO

select spid as victim, blocked as blocker
into #process
from master..sysprocesses p1 
where spid &gt; 50
and blocked &gt; 0
and spid &lt;&gt; blocked

insert into #process
select spid as victim, blocked as blocker
from master..sysprocesses p 
inner join #process
on #process.blocker = p.spid
where spid &gt; 50


select  distinct 'dbcc inputbuffer(' + CAST( victim as nvarchar(4)) + ')' as cmd, 'sp_who2 ' + CAST( victim as nvarchar(4)) as spwho, *
into #tmp
from #process 
where blocker = 0
order by victim


select *
from #tmp 
order by victim

DECLARE @cmd nvarchar(400)
DECLARE @spwho nvarchar(12)

DECLARE curseur CURSOR
FOR
    select  cmd, spwho
    from #tmp 
    order by victim

OPEN curseur
FETCH NEXT FROM curseur INTO @cmd, @spwho

WHILE @@FETCH_STATUS = 0
BEGIN
    print (@cmd)
    exec (@cmd)
    print (@spwho)
    exec (@spwho)
    FETCH NEXT FROM curseur INTO @cmd, @spwho
END

CLOSE curseur
DEALLOCATE curseur 

GO

select
    db_name(dbid),
    'dbcc inputbuffer(' + CAST(a.spid as nvarchar(4)) + ')',
    a.spid,
    a.blocked,
    a.status, 
    a.cmd, 
    a.cpu,
    a.waittime,
    a.loginame,
    Base = DB_NAME(a.dbid),
    *
from master.dbo.sysprocesses a
where 1 = 1
    and a.spid &gt; 50
    and spid &lt;&gt; @@spid
order by
    a.blocked desc,
    a.waittime desc,
    a.cpu desc         




Update 3/6/2013

So we've seen that no sessions are being blocked. Now we can also look at all current locks on your system. 

Show locks server wide MSSQL 2000

Monitoring Lock Activity

select convert(varchar(30), suser_sname(p.sid)) as login,
       convert (smallint, req_spid) As spid,
       convert(varchar(30), db_name(rsc_dbid)) As db_name,
       case rsc_dbid when db_id()
            then convert(varchar(30), object_name(rsc_objid))
            else convert(varchar(30), rsc_objid) end As Object,
       rsc_indid As indid,
       substring (lock_type.name, 1, 4) As Type,
       substring (lock_mode.name, 1, 12) As Mode,
       substring (lock_status.name, 1, 5) As Status,
       substring (rsc_text, 1, 16) as Resource
   from master..syslockinfo s
   join master..spt_values lock_type on s.rsc_type = lock_type.number
   join master..spt_values lock_status on s.req_status = lock_status.number
   join master..spt_values lock_mode on s.req_mode = lock_mode.number -1
   join master..sysprocesses p on s.req_spid = p.spid
   where lock_type.type = 'LR'
     and lock_status.type = 'LS'
     and lock_mode.type = 'L'
     and db_name(rsc_dbid) not in ('master', 'msdb', 'tempdb', 'model')
order by spid, lock_type.number
go


The output will you tell you 
1. what type of lock is being held: database, table, page.
2. the mode of the lock: S shared, X exclusive, RangeS-S where a range of values is locked in an index



Update 3/7/2014

I have updated your screen shot with some basic explanations. What we are seeing, is just a bunch of shared database locks. 

To be brief, the locks on your system are shared (in other words, they don't block other sessions from accessing the database) and those locks are meant to prevent the database from being dropped, detached or renamed while data is being read and/or written from and to that database and its contents.

Getting back to your original question; there are no deadlocks or blocked sessions on your server. I don't remember having seen this message before, but from what you are sending back, this is definitely not about deadlocks and more likely to be just an informational message. 

Or use sp_lock

sp_lock [[@spid1 =] 'spid1'] [,[@spid2 =] 'spid2']

Which will give you a more detailed view of all locks currently being held on your server.

http://technet.microsoft.com/en-us/library/aa238824(v=sql.80).aspx
"
5093,5093,8101,What version of flash uses Actionscript 3?,"I have been given a book on Actionscript 3 and I am looking to get started with learning it. What version of flash uses actionscript 3?

Also does anyone know if adobe offer trial versions of their software for OSX? (10.6 snow leapard).
",James Jeffery,https://stackoverflow.com/users/359916,"Flash Player 9. The first IDE to export to FP9 was CS3. But you don't need Flash to use ActionScript. You can use the open-source IDE FlashDevelop. It is hugely popular, and totally free. You will also need to get the free Adobe Flex SDK to compile to SWFs, but the install page of FlashDevelop's website gives details on everything you need, and current versions of FlashDevelop will even ask if you want it to get the SDK automatically for you.
",Adam Harte,https://stackoverflow.com/users/78782,http://stackoverflow.com/questions/3129335/what-version-of-flash-uses-actionscript-3,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.7777777777777778,0.0,1.0,1.0,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.6666666666666666,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.3333333333333333,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.3333333333333333,0.0,1.0,1.0,What version of flash uses ActionScript 3?,"I have been given a book on Actionscript 3 and I am looking to get started with learning it. What version of flash uses actionscript 3?

Also does anyone know if adobe offer trial versions of their software for OSX? (10.6 snow leapard).
","Flash Player 9. The first ide to export to fp9 is CS3. But you don't need flash to use ActionScript. You can use open source ide flash development. It's very popular and it's completely free. You also need to get a free Adobe flex SDK to compile into SWFs, but the flash development website installation page provides all the details you need, and the current version of flash development even asks if you want it to automatically get the SDK for you."
1786,1786,2838,Are there any Animal Companions that are not actually Animals?,"I&rsquo;m just curious if any supplement out there includes an Animal Companion that is not, in fact, an Animal. As in the type.

I mean that just any Druid of sufficient level can take; there are probably feats that allow you to get nonstandard Companions from other types, but I mean just ordinary &ldquo;Animal&rdquo; Companions.

Bonus points if the Animal Companion in question is an Aberration, Dragon, Elemental, Magical Beast, or Plant, and thus qualifies for Rapidstrike.

Super bonus points if you find a Construct or Undead, because that would just be weird.
",KRyan,https://rpg.stackexchange.com/users/4563,"The 3.5e book ""Dungeonscape"" has the ""Beast Heart Adept"" Prestige Class (pg. 48), which allows an eligible character to select from numerous monstrous companions, gain more monstrous companions (Up to a total of 3 by 9th level, not including any familiars or animal companions), and class abilities that improve teamwork between yourself and your monstrous companion.
",Tao,https://rpg.stackexchange.com/users/7407,http://rpg.stackexchange.com/questions/20177/are-there-any-animal-companions-that-are-not-actually-animals,CULTURE,rpg.stackexchange.com,0.8888888888888888,0.7777777777777778,0.3333333333333333,0.6666666666666666,0.6666666666666666,1.0,0.7777777777777778,0.6666666666666666,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.7777777777777778,0.6666666666666666,0.7777777777777778,0.7777777777777778,0.8333333333333334,0.8,0.0,0.0,0.6666666666666666,1.0,Are there any animal companions that are not real animals?,"I&rsquo;m just curious if any supplement out there includes an Animal Companion that is not, in fact, an Animal. As in the type.

I mean that just any Druid of sufficient level can take; there are probably feats that allow you to get nonstandard Companions from other types, but I mean just ordinary &ldquo;Animal&rdquo; Companions.

Bonus points if the Animal Companion in question is an Aberration, Dragon, Elemental, Magical Beast, or Plant, and thus qualifies for Rapidstrike.

Super bonus points if you find a Construct or Undead, because that would just be weird.
","The 3.5e book ""Dungeonscape"" has the ""Beast Heart Adept"" Prestige Class (pg. 48), which allows an eligible character to select from numerous monstrous companions, gain more monstrous companions (Up to a total of 3 by 9th level, not including any familiars or animal companions), and class abilities that improve teamwork between yourself and your monstrous companion.
"
1227,1227,1923,The Google Time Zone API always returns Error status,"I am using  Google Time Zone API  to retrieve time zone, my code is 

$lat = round($location['lat'], 2);
$lng = round($location['lng'], 2);

$url = ""https://maps.googleapis.com/maps/api/timezone/jsonlocation="".$lat."","".$lng.""&amp;amp;timestamp=1419283200&amp;sensor=false"";
$url = str_replace(' ','',$url);
$json_timezone = file_get_contents($url);
echo $url;
echo '&lt;pre&gt;';print_r($json_timezone);


And the output is 

https://maps.googleapis.com/maps/api/timezone/json?location=39.29,-76.64&amp;timestamp=1419283200&amp;sensor=false

{
   ""status"" : ""INVALID_REQUEST""
}


When I run the above url, I get the correct output

{
   ""dstOffset"" : 0,
   ""rawOffset"" : -18000,
   ""status"" : ""OK"",
   ""timeZoneId"" : ""America/New_York"",
   ""timeZoneName"" : ""Eastern Standard Time""
}


Any Idea how to solve this
",Nithin Dev,https://stackoverflow.com/users/1820790,"Your $url is invalid. Try this:

$url = ""https://maps.googleapis.com/maps/api/timezone/json?location="".$lat."","".$lng.""&amp;timestamp=1419283200&amp;sensor=false"";

",Glavić,https://stackoverflow.com/users/67332,http://stackoverflow.com/questions/20117911/the-google-time-zone-api-always-returns-error-status,STACKOVERFLOW,stackoverflow.com,1.0,0.5555555555555556,0.0,1.0,1.0,1.0,0.4444444444444444,0.4444444444444444,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,1.0,0.8888888888888888,Google time zone API always returns error status,"I am using  Google Time Zone API  to retrieve time zone, my code is 

$lat = round($location['lat'], 2);
$lng = round($location['lng'], 2);

$url = ""https://maps.googleapis.com/maps/api/timezone/jsonlocation="".$lat."","".$lng.""&amp;amp;timestamp=1419283200&amp;sensor=false"";
$url = str_replace(' ','',$url);
$json_timezone = file_get_contents($url);
echo $url;
echo '&lt;pre&gt;';print_r($json_timezone);


And the output is 

https://maps.googleapis.com/maps/api/timezone/json?location=39.29,-76.64&amp;timestamp=1419283200&amp;sensor=false

{
   ""status"" : ""INVALID_REQUEST""
}


When I run the above url, I get the correct output

{
   ""dstOffset"" : 0,
   ""rawOffset"" : -18000,
   ""status"" : ""OK"",
   ""timeZoneId"" : ""America/New_York"",
   ""timeZoneName"" : ""Eastern Standard Time""
}


Any Idea how to solve this
","Your $url is invalid. Try this:

$url = ""https://maps.googleapis.com/maps/api/timezone/json?location="".$lat."","".$lng.""&amp;timestamp=1419283200&amp;sensor=false"";

"
1455,1455,2291,AES 256 Encryption - Is it really easy to decrypt if you have the key?,"So this might sound like a crazy question but bear with me for a minute. I can't find any info on the internet and so am here, although this might have been a good place to start.

I've recently developed an encryption engine using the .net's AES managed classes. I use a 256 bit key generated by the Rfc2898DeriveBytes function. The key is generated from a pass phrase that is at least 40 characters long. The IV is also generated from this pass phrase. The encryption class uses a CypherMode of CBC and a padding mode of PKCS7. There is a static salt that is 8 bytes long. 

The key is stored in a separate database to the data and is itself encrypted using a certificate based on the database master key.

So, my question is: is it really easy to decrypt the data if the attacker has the key? I'm not talking about the Chinese government (or even GHCQ given recent headlines), I'm talking about an attacker who steals both databases. 

What would be the steps they have to follow and/or how can I stop them on their path? The reason I ask this is that I want to know how feasible it is. Is it something that can be done in minutes or does it fall into the bracket of being infeasible? Do they have to calculate all of the parameters used when encrypting?
",bhs,https://crypto.stackexchange.com/users/7684,"
  So to clarify then the question would be this: The attacker has the encrypted data and the plain text key and no other knowledge. How easy is it to decrypt the data and why.


As I understand it, modern ciphers can't be broken knowing just the ciphertext (and no other information). But, the cipher algorithym (eg. AES) is only one part of a wider system using RNGs, keys, salts, IVs, padding, signatures, certificates, and so on. People have developed amazing exploits against tiny deficiencies in how those parts all fit together. So even though the ciper itself is secure, that does not mean that the system as a whole is secure.

Here's a simple analogue. SCUBA tanks have a threaded hole where the valve screws in. Some of those holes use a ""3/4 NPS"" thread, others use an ""M25"" thread. An M25 valve will screw ""perfectly"" into a 3/4 NPS hole - but those two threads aren't quite the same. Result: the valve can explode from the tank when it is pressurized. Each component is fine on its own; they seem to fit together correctly; an amateur won't see any problem; but the resultant system can fail catastrophically.

Crypto's the same!

TC
",user7576,https://crypto.stackexchange.com/users/7576,http://crypto.stackexchange.com/questions/9276/aes-256-encryption-is-it-really-easy-to-decrypt-if-you-have-the-key,TECHNOLOGY,crypto.stackexchange.com,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.5,1.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8,0.0,0.0,1.0,1.0,"Aes256 encryption - if you have a key, is decryption really easy?","So this might sound like a crazy question but bear with me for a minute. I can't find any info on the internet and so am here, although this might have been a good place to start.

I've recently developed an encryption engine using the .net's AES managed classes. I use a 256 bit key generated by the Rfc2898DeriveBytes function. The key is generated from a pass phrase that is at least 40 characters long. The IV is also generated from this pass phrase. The encryption class uses a CypherMode of CBC and a padding mode of PKCS7. There is a static salt that is 8 bytes long. 

The key is stored in a separate database to the data and is itself encrypted using a certificate based on the database master key.

So, my question is: is it really easy to decrypt the data if the attacker has the key? I'm not talking about the Chinese government (or even GHCQ given recent headlines), I'm talking about an attacker who steals both databases. 

What would be the steps they have to follow and/or how can I stop them on their path? The reason I ask this is that I want to know how feasible it is. Is it something that can be done in minutes or does it fall into the bracket of being infeasible? Do they have to calculate all of the parameters used when encrypting?
","
  So to clarify then the question would be this: The attacker has the encrypted data and the plain text key and no other knowledge. How easy is it to decrypt the data and why.


As I understand it, modern ciphers can't be broken knowing just the ciphertext (and no other information). But, the cipher algorithym (eg. AES) is only one part of a wider system using RNGs, keys, salts, IVs, padding, signatures, certificates, and so on. People have developed amazing exploits against tiny deficiencies in how those parts all fit together. So even though the ciper itself is secure, that does not mean that the system as a whole is secure.

Here's a simple analogue. SCUBA tanks have a threaded hole where the valve screws in. Some of those holes use a ""3/4 NPS"" thread, others use an ""M25"" thread. An M25 valve will screw ""perfectly"" into a 3/4 NPS hole - but those two threads aren't quite the same. Result: the valve can explode from the tank when it is pressurized. Each component is fine on its own; they seem to fit together correctly; an amateur won't see any problem; but the resultant system can fail catastrophically.

Crypto's the same!

TC
"
4203,4203,6703,What are the best tips for saving money as a university student?,"What are the best tips for saving money as a university student?

I will be attending university this coming semester and am planning on maintaining a sustainable financial situation right now, but would like any good tips or suggestions to saving money as a student.
",JFW,https://money.stackexchange.com/users/1408,"Get a decent job while at university - it will make all the difference. And calculate your budget and don't spend more than your budget allows

Worked for me. That was the time when I had the greatest disposable income - all gone downhill since :-)
",Rory Alsop,https://money.stackexchange.com/users/2196,http://money.stackexchange.com/questions/6455/what-are-the-best-tips-for-saving-money-as-a-university-student,LIFE_ARTS,money.stackexchange.com,1.0,1.0,0.3333333333333333,0.6666666666666666,0.0,0.0,1.0,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,1.0,1.0,0.7777777777777778,1.0,1.0,1.0,0.6666666666666666,0.0,0.0,1.0,"As a college student, what is the best way to save money?","What are the best tips for saving money as a university student?

I will be attending university this coming semester and am planning on maintaining a sustainable financial situation right now, but would like any good tips or suggestions to saving money as a student.
",Finding a decent job in College - it's going to be a big difference. Calculate your budget. Don't spend more than you have budgeted
2667,2667,4247,How do I create a great fantasy villain that inspires the party to rally against them?,"In my early years of GMing it was simple enough to say that the badguys were evil and that was all the justification we needed.  They are attacking the village because they are evil, they are stealing the princess because they are evil, etc.

Over time, my group needs have grown to need more complicated and detailed villains. It is important to consider motives.  What is it that defines them as 'evil' to the party?  In terms of a fantasy setting, what would you consider to be an interesting villain?

What qualities make a villain that inspires your party to rally against him?  What kind of villains have worked for your games in the past?

Example:


  A member of nobility is using trade connections to move valuable pieces of art into another country that is secretly paying him quite well and is framing a member of the party to take the fall.  In addition, someone important to the party member has been taken hostage with a promise of release once they party member takes the blame for the crime.

",Maximillian,https://rpg.stackexchange.com/users/18,"The most memorable villians in my experience are the ones that defeat the PCs especially if it happens more than once. Nothing drives the passions of the players more than a familiar villian who has managed to outwit them. I was once had an entire campaign revolve around defeating a single recurring villian. The key was to allow the players to frequently win. Each time creating set backs for the villian and his minions but not fatally.
",Eric Weilnau,https://rpg.stackexchange.com/users/119,http://rpg.stackexchange.com/questions/584/how-do-i-create-a-great-fantasy-villain-that-inspires-the-party-to-rally-against,CULTURE,rpg.stackexchange.com,1.0,0.8888888888888888,0.6666666666666666,0.3333333333333333,0.0,0.0,0.5555555555555556,0.6666666666666666,0.6666666666666666,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.0,1.0,1.0,0.5555555555555556,1.0,1.0,0.8,0.0,0.3333333333333333,0.3333333333333333,0.8888888888888888,How can I create a great fantasy villain to inspire the party to unite against them?,"In my early years of GMing it was simple enough to say that the badguys were evil and that was all the justification we needed.  They are attacking the village because they are evil, they are stealing the princess because they are evil, etc.

Over time, my group needs have grown to need more complicated and detailed villains. It is important to consider motives.  What is it that defines them as 'evil' to the party?  In terms of a fantasy setting, what would you consider to be an interesting villain?

What qualities make a villain that inspires your party to rally against him?  What kind of villains have worked for your games in the past?

Example:


  A member of nobility is using trade connections to move valuable pieces of art into another country that is secretly paying him quite well and is framing a member of the party to take the fall.  In addition, someone important to the party member has been taken hostage with a promise of release once they party member takes the blame for the crime.

","The most memorable villians in my experience are the ones that defeat the PCs especially if it happens more than once. Nothing drives the passions of the players more than a familiar villian who has managed to outwit them. I was once had an entire campaign revolve around defeating a single recurring villian. The key was to allow the players to frequently win. Each time creating set backs for the villian and his minions but not fatally.
"
1748,1748,2768,Display a field of a node that is referenced on another node via a relationship,"I have two content types, ""Stores"" and ""Offers."" In the ""Offers"" content type, there is a CCK node reference field type that references the ""Stores"" nodes.  So essentially, I create a store and if the store has an offer, I create the ""Offer"" node and select the store with which it is associated.

I have a view (a default glossary view) that displays a list of stores. I would like to display the node titles of any offers that are associated with it but I can't figure out how to do it.

I have tried to add a relationship on the node reference field then add a field that uses the relationship but the result just appears blank.
",Jamie Hollern,https://drupal.stackexchange.com/users/1319,"In your view style template you can access the node reference value, load the related node and then do whatever you need with that. You don't need a relationship for this approach.
",Stefan,https://drupal.stackexchange.com/users/1422,http://drupal.stackexchange.com/questions/4148/display-a-field-of-a-node-that-is-referenced-on-another-node-via-a-relationship,TECHNOLOGY,drupal.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,1.0,Fields that display nodes that are referenced on another node through a relationship,"I have two content types, ""Stores"" and ""Offers."" In the ""Offers"" content type, there is a CCK node reference field type that references the ""Stores"" nodes.  So essentially, I create a store and if the store has an offer, I create the ""Offer"" node and select the store with which it is associated.

I have a view (a default glossary view) that displays a list of stores. I would like to display the node titles of any offers that are associated with it but I can't figure out how to do it.

I have tried to add a relationship on the node reference field then add a field that uses the relationship but the result just appears blank.
","In your view style template you can access the node reference value, load the related node and then do whatever you need with that. You don't need a relationship for this approach.
"
368,368,581,"How did Superman play the ""disappearing"" game as a kid?","In Superman II, during the final battle between Superman, Zod, Ursa and Non (in the Fortress of Solitude), there was a part where they were disappearing and reappearing as false images (like holograms) to fool each other. Superman says to Lois that he used to play the game as a kid and that he never was very good at it. With whom did he play that would have had those powers? He came to Earth as an infant. Furthermore I don't buy that he was simply talking about hide and seek or some Earthly game. His statement that he was never good at it would not have made sense in that context. 
",Gelfamat,https://scifi.stackexchange.com/users/20154,"The canon quote from the film transcript is 


  ""We used to play this game at school. I never was very good at it!"".


I think it's pretty clear that he's referring to 'hide and seek' rather than his newfound ability to make himself appear in multiple locations since that would have obviously have raised a very considerable number of questions. Furthermore, it's very likely that he's being ironic since his x-ray vision must have given him an incomparable advantage against his schoolmates.

In the original shooting script the line is slightly different; 


  ""How do you like these odds, General ? Or are they too odd for you?""


closely followed by 


  ""One more mistake like that and you'll be busted to Corporal, Zod.

",Valorum,https://scifi.stackexchange.com/users/20774,http://scifi.stackexchange.com/questions/51216/how-did-superman-play-the-disappearing-game-as-a-kid,LIFE_ARTS,scifi.stackexchange.com,1.0,0.5555555555555556,0.0,1.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,1.0,"How did Superman play ""disappear"" when he was a kid?","In Superman 2, in the last battle of Superman, Zod, Ursa and noone (in lonely fortress), some of them disappear and reappear in the form of false images (such as holograms) to fool each other. Superman told Louise that he used to play the game when he was a child, and he was never very good at it. Who does he play with has these powers? He was born as a child. Besides, I don't believe he's just talking about hide and seek or some secular games. In this case, it is unreasonable for him to say that he was never good at it.","The canon quote from the film transcript is 


  ""We used to play this game at school. I never was very good at it!"".


I think it's pretty clear that he's referring to 'hide and seek' rather than his newfound ability to make himself appear in multiple locations since that would have obviously have raised a very considerable number of questions. Furthermore, it's very likely that he's being ironic since his x-ray vision must have given him an incomparable advantage against his schoolmates.

In the original shooting script the line is slightly different; 


  ""How do you like these odds, General ? Or are they too odd for you?""


closely followed by 


  ""One more mistake like that and you'll be busted to Corporal, Zod.

"
353,353,560,Why the sudden popularity of .io domains?,"I've noticed a number of new webapps and sites are being hosted at .io domains (the top-level domain for the British Indian Ocean Territories). A couple examples include:


Forecast.io
GitHub.io
Firepad.io


And the list goes on and on.

Is there any particular cause for the sudden popularity of .io domains?
",samthebrand,https://webmasters.stackexchange.com/users/13067,"
They're available…
…probably because they're significantly more expensive(from any registrar I've ever seen) than the usual TLDs…
…and somewhat desirable to techs because of a cheap I/O joke.


The usage itself among web/tech people isn't terribly new. There were several bloggers who started using the TLD years ago that I can't remember at the moment. Over time, it just seems to have slowly built an association with those sorts of people and their output/products. You have to remember that it's gotten really hard to find a decent short domain with .com et al, and very few alternative TLDs like .ws have ever gained much traction, so there's a bit of community convergence going on here, stemming in part from that shared joke.
",Su',https://webmasters.stackexchange.com/users/4502,http://webmasters.stackexchange.com/questions/47106/why-the-sudden-popularity-of-io-domains,TECHNOLOGY,webmasters.stackexchange.com,0.8888888888888888,0.7777777777777778,0.6666666666666666,0.0,0.3333333333333333,0.0,0.7777777777777778,0.5555555555555556,0.0,0.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.8888888888888888,0.8888888888888888,0.7777777777777778,1.0,1.0,0.8,0.0,0.0,1.0,0.8888888888888888,Why is. IO domain suddenly popular?,"I've noticed a number of new webapps and sites are being hosted at .io domains (the top-level domain for the British Indian Ocean Territories). A couple examples include:


Forecast.io
GitHub.io
Firepad.io


And the list goes on and on.

Is there any particular cause for the sudden popularity of .io domains?
","
They're available…
…probably because they're significantly more expensive(from any registrar I've ever seen) than the usual TLDs…
…and somewhat desirable to techs because of a cheap I/O joke.


The usage itself among web/tech people isn't terribly new. There were several bloggers who started using the TLD years ago that I can't remember at the moment. Over time, it just seems to have slowly built an association with those sorts of people and their output/products. You have to remember that it's gotten really hard to find a decent short domain with .com et al, and very few alternative TLDs like .ws have ever gained much traction, so there's a bit of community convergence going on here, stemming in part from that shared joke.
"
2251,2251,3588,Zero point fluctuation of an harmonic oscillator,"In a paper, I ran into the following definition of the zero point fluctuation of our favorite toy, the harmonic oscillator:
$$x_{ZPF} = \sqrt{\frac{\hbar}{2m\Omega}} $$
where m is its mass and $\Omega$ its natural frequency.
However, when I try to derive it with simple arguments, I think of the equality:
$$E = \frac12 \hbar\Omega=\frac12 m \Omega^2 x_{ZPF}^²$$
(using the energy eigenvalue of the $n=0$ state)
giving me:

$$x_{ZPF} = \sqrt{\frac{\hbar}{m\Omega}} $$
differing from the previous one by a factor $\sqrt2$. I am just puzzled, is it a matter of conventions or is there a fundamental misconception in my (too?) naive derivation? 
",Learning is a mess,https://physics.stackexchange.com/users/16890,"You can find the value of zero point fluctuations just by calculating the variance $\langle(\Delta\hat{x})^2\rangle = \langle\hat{x}^2\rangle$ in the vacuum state. You can do this either using the $x$-representation or expressing the $\hat{x}$ operator using creation and annihilation operators. These are usually introduced by
$$
\hat{a} = \sqrt{\frac{m\Omega}{2\hbar}}\left(\hat{x}+i\frac{\hat{p}}{m\Omega}\right),
$$
so that you get
$$
\hat{x} = \sqrt{\frac{\hbar}{2m\Omega}}(\hat{a}+\hat{a}^\dagger).
$$
Using this to calculate $\langle\hat{x}^2\rangle = \langle 0|\hat{x}^2|0\rangle$ indeed gives you $$x_{ZPF} = \sqrt{\langle\hat{x}^2\rangle} = \sqrt{\frac{\hbar}{2m\Omega}}.$$
",Ondřej Černotík,https://physics.stackexchange.com/users/12623,http://physics.stackexchange.com/questions/46925/zero-point-fluctuation-of-an-harmonic-oscillator,SCIENCE,physics.stackexchange.com,0.5555555555555556,0.3333333333333333,0.0,1.0,1.0,0.3333333333333333,0.6666666666666666,0.5555555555555556,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9,0.6666666666666666,0.3333333333333333,0.6666666666666666,1.0,Zero fluctuation of harmonic oscillator,"In a paper, I ran into the following definition of the zero point fluctuation of our favorite toy, the harmonic oscillator:
$$x_{ZPF} = \sqrt{\frac{\hbar}{2m\Omega}} $$
where m is its mass and $\Omega$ its natural frequency.
However, when I try to derive it with simple arguments, I think of the equality:
$$E = \frac12 \hbar\Omega=\frac12 m \Omega^2 x_{ZPF}^²$$
(using the energy eigenvalue of the $n=0$ state)
giving me:

$$x_{ZPF} = \sqrt{\frac{\hbar}{m\Omega}} $$
differing from the previous one by a factor $\sqrt2$. I am just puzzled, is it a matter of conventions or is there a fundamental misconception in my (too?) naive derivation? 
","You can find the value of zero point fluctuations just by calculating the variance $\langle(\Delta\hat{x})^2\rangle = \langle\hat{x}^2\rangle$ in the vacuum state. You can do this either using the $x$-representation or expressing the $\hat{x}$ operator using creation and annihilation operators. These are usually introduced by
$$
\hat{a} = \sqrt{\frac{m\Omega}{2\hbar}}\left(\hat{x}+i\frac{\hat{p}}{m\Omega}\right),
$$
so that you get
$$
\hat{x} = \sqrt{\frac{\hbar}{2m\Omega}}(\hat{a}+\hat{a}^\dagger).
$$
Using this to calculate $\langle\hat{x}^2\rangle = \langle 0|\hat{x}^2|0\rangle$ indeed gives you $$x_{ZPF} = \sqrt{\langle\hat{x}^2\rangle} = \sqrt{\frac{\hbar}{2m\Omega}}.$$
"
587,587,914,"How should a Christian respond to ""Does this dress me look fat?""?","If your wife asks, ""Does this dress make me look fat?"" And you think it does, but you tell her, ""Of course not, honey!"" Is that a sin?
",Jim G.,https://christianity.stackexchange.com/users/1100,"A successful marriage relationship will need a full measure of agape love.  Here's how Paul defines it with particularly relevant words bolded:


  Love is patient and kind; love does not envy or boast; it is not arrogant or rude. It does not insist on its own way; it is not irritable or resentful; it does not rejoice at wrongdoing, but rejoices with the truth. Love bears all things, believes all things, hopes all things, endures all things.&mdash;1st Corinthians 13:4-7 (ESV)


Let's take these in reverse order:

Rejoices with the truth

Presumably, the husband does not think he is telling the truth.  By this standard, lying to your wife is not loving.

It is not arrogant or rude

However, if the husband said exactly what he thought, that would be rude (and possibly arrogant):


  It makes you look like a pregnant cow.


Honestly, given the choice, it would be more loving to lie to your wive than to be rude.

Love is patient and kind

But there's another way.  The patient thing to do is to ask questions or let the wife down easy.  I've found that saying things like ""I wonder if it would be a good idea to accessorize?"" communicates that something is not quite right, without being rude.  (I don't know what accessorizing means exactly or how it could help, but it shows my wife that I care.)  Another thing that works for me is to spend ""too long"" appraising the outfit.  After a minute of looking and contemplating, my wife will get the hint: something isn't right.

If we are about to go out and I think there's a good chance she will be embarrassed if someone posts a picture of the outfit on Facebook.  The kindest thing I can do is let her know:


  Dearest, I know you spent the last hour and a half getting ready to go, but I really think you'd look better in some other dress.


Then I will (Lord willing) spend whatever time is needed helping her look her best.
",Jon Ericson,https://christianity.stackexchange.com/users/914,http://christianity.stackexchange.com/questions/6469/how-should-a-christian-respond-to-does-this-dress-me-look-fat,CULTURE,christianity.stackexchange.com,1.0,1.0,1.0,1.0,0.0,0.3333333333333333,0.6666666666666666,0.7777777777777778,0.0,0.0,1.0,0.3333333333333333,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,0.8888888888888888,1.0,0.7777777777777778,1.0,1.0,0.9333333333333332,0.0,0.3333333333333333,1.0,0.8888888888888888,"How do Christians respond to ""do I look fat in this dress?"" ?","If your wife asks, ""does this dress make me look fat?"" You think so, but you tell her, ""of course not, honey!"" Is this a crime?","A successful marriage relationship will need a full measure of agape love.  Here's how Paul defines it with particularly relevant words bolded:


  Love is patient and kind; love does not envy or boast; it is not arrogant or rude. It does not insist on its own way; it is not irritable or resentful; it does not rejoice at wrongdoing, but rejoices with the truth. Love bears all things, believes all things, hopes all things, endures all things.&mdash;1st Corinthians 13:4-7 (ESV)


Let's take these in reverse order:

Rejoices with the truth

Presumably, the husband does not think he is telling the truth.  By this standard, lying to your wife is not loving.

It is not arrogant or rude

However, if the husband said exactly what he thought, that would be rude (and possibly arrogant):


  It makes you look like a pregnant cow.


Honestly, given the choice, it would be more loving to lie to your wive than to be rude.

Love is patient and kind

But there's another way.  The patient thing to do is to ask questions or let the wife down easy.  I've found that saying things like ""I wonder if it would be a good idea to accessorize?"" communicates that something is not quite right, without being rude.  (I don't know what accessorizing means exactly or how it could help, but it shows my wife that I care.)  Another thing that works for me is to spend ""too long"" appraising the outfit.  After a minute of looking and contemplating, my wife will get the hint: something isn't right.

If we are about to go out and I think there's a good chance she will be embarrassed if someone posts a picture of the outfit on Facebook.  The kindest thing I can do is let her know:


  Dearest, I know you spent the last hour and a half getting ready to go, but I really think you'd look better in some other dress.


Then I will (Lord willing) spend whatever time is needed helping her look her best.
"
2729,2729,4350,How does sulfuric acid dehydrate sugars?,"I know sugars have $\ce{-OH}$ groups, and that sulfuric acid is a strong acid. What I'm failing to see is how exactly sulfuric acid dehydrates sugars. Does it protonate the hydroxyl groups, making them good leaving groups? What about the case of sucrose? 



For example, how are the oxygens ""taken care of"" by the sulfuric acid? Are they doubly protonated? Is there some established mechanism for the dehydration of sugars by sulfuric acid, because I can't find any - I just find general equations and I've looked on Google and through textbooks. 

After some further research I learned that the gas, sulfur dioxide, is evolved. This suggests to me that this reaction is also redox in nature. So is this reaction both an acid-base reaction and a redox reaction? Sulfur in sulfuric acid has an oxidation state of +6; sulfur in sulfur dioxide has an oxidation state of +4. Plus the elemental carbon formed has an oxidation state of 0 while in sucrose, carbon has various oxidation states. 
",Dissenter,https://chemistry.stackexchange.com/users/5084,"The sulfuric acid brakes up the bonds of the sugar and absorbs the water from the crystallization
",user13222,https://chemistry.stackexchange.com/users/13222,http://chemistry.stackexchange.com/questions/15442/how-does-sulfuric-acid-dehydrate-sugars,SCIENCE,chemistry.stackexchange.com,0.6666666666666666,1.0,0.0,1.0,1.0,1.0,1.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,1.0,0.0,1.0,How does sulfuric acid dehydrate sugar?,"I know sugars have $\ce{-OH}$ groups, and that sulfuric acid is a strong acid. What I'm failing to see is how exactly sulfuric acid dehydrates sugars. Does it protonate the hydroxyl groups, making them good leaving groups? What about the case of sucrose? 



For example, how are the oxygens ""taken care of"" by the sulfuric acid? Are they doubly protonated? Is there some established mechanism for the dehydration of sugars by sulfuric acid, because I can't find any - I just find general equations and I've looked on Google and through textbooks. 

After some further research I learned that the gas, sulfur dioxide, is evolved. This suggests to me that this reaction is also redox in nature. So is this reaction both an acid-base reaction and a redox reaction? Sulfur in sulfuric acid has an oxidation state of +6; sulfur in sulfur dioxide has an oxidation state of +4. Plus the elemental carbon formed has an oxidation state of 0 while in sucrose, carbon has various oxidation states. 
","The sulfuric acid brakes up the bonds of the sugar and absorbs the water from the crystallization
"
3847,3847,6116,Free RF Simulation Software,"What free tools are there to simulate RF circuits?
",cksa361,https://electronics.stackexchange.com/users/1688,"For normal lumped circuits, your favorite version of spice will work fine.

For analyzing matching networks, I've used gsmc.

For analyzing a layout and extracting parasitics and computing fields, I dunno.  It's usually easier to just build the circuit and see what happens.
",markrages,https://electronics.stackexchange.com/users/411,http://electronics.stackexchange.com/questions/8645/free-rf-simulation-software,SCIENCE,electronics.stackexchange.com,0.8888888888888888,0.4444444444444444,0.0,1.0,0.6666666666666666,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.0,0.6666666666666666,1.0,Free RF simulation software,What free tools are available to simulate RF circuits?,"For normal lumped circuits, your favorite version of spice will work fine.

For analyzing matching networks, I've used gsmc.

For analyzing a layout and extracting parasitics and computing fields, I dunno.  It's usually easier to just build the circuit and see what happens.
"
5766,5766,9137,What is the best introductory Bayesian statistics textbook?,"Which is the best introductory textbook for Bayesian statistics?

One book per answer, please.
",Shane,https://stats.stackexchange.com/users/5,"Coming from non-statistical background I found Introduction to Applied Bayesian Statistics and Estimation for Social Scientists quite informative and easy to follow.
",radek,https://stats.stackexchange.com/users/22,http://stats.stackexchange.com/questions/125/what-is-the-best-introductory-bayesian-statistics-textbook,SCIENCE,stats.stackexchange.com,1.0,1.0,0.0,1.0,0.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,1.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,1.0,What is the best introduction to Bayesian statistics?,Which is the best introduction to Bayesian statistics?,"From a non statistical background, I find that the introduction of Bayesian statistics and estimation provides social scientists with rich information and easy to follow."
5255,5255,8356,Need help clearing the schema cache,"I am checking of a particular field type in the schema using: 

drupal_get_schema('MY_FIELD');


I see in the database the field type is int, but when I check after:

$schema[$table]['fields']['MY_FIELD']['type'] 


is giving me always 'datetime'.

I assume is a cache issue: I am using: 

cache_clear_all('schema', 'cache');


but still no luck.
",drupal_stuff_alter,https://drupal.stackexchange.com/users/3143,"There are a few different cache entries for the schema, schema:, schema:runtime, schema:runtime:1, and so on.

To clear the lot, try using a wildcard:

cache_clear_all('schema', 'cache', TRUE);

",Clive,https://drupal.stackexchange.com/users/2800,http://drupal.stackexchange.com/questions/87362/need-help-clearing-the-schema-cache,TECHNOLOGY,drupal.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.0,0.0,0.8888888888888888,Need help clearing schema cache,"I am checking of a particular field type in the schema using: 

drupal_get_schema('MY_FIELD');


I see in the database the field type is int, but when I check after:

$schema[$table]['fields']['MY_FIELD']['type'] 


is giving me always 'datetime'.

I assume is a cache issue: I am using: 

cache_clear_all('schema', 'cache');


but still no luck.
","Schema, schema:, schema: runtime, schema: Runtime: 1 and so on have several different cache entries."
4937,4937,7863,Word-order and meaning - which is correct for this notice?,"I'm creating some signs for the office car park, and one of these signs is to control access. What I'm trying to get it to indicate is that cars aren't permitted between 10 am and 4pm except for access.

Which of the below mean what I want to say above?


Except for access 10 am - 4 pm  
10 am - 4 pm except for access


Am I correct in thinking that the first one means ""Cars allowed for access between 10 am and 4 pm only "" and the second one is ""No cars between 10 am and 4 pm except for access"".

I realize the ambiguity of the sign, and want to make sure what I'm saying is correct.
",AN Other,https://english.stackexchange.com/users/12429,"I'd say, stating it in a clearer way would be better:


  10am - 4pm access only. No parking during this time.

",Thursagen,https://english.stackexchange.com/users/8183,http://english.stackexchange.com/questions/39494/word-order-and-meaning-which-is-correct-for-this-notice,CULTURE,english.stackexchange.com,0.8888888888888888,0.3333333333333333,0.6666666666666666,1.0,0.3333333333333333,1.0,0.6666666666666666,0.6666666666666666,0.0,0.0,1.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.0,0.3333333333333333,0.8888888888888888,Word order and meaning - which is correct for this notice?,"I'm creating some signs for the office car park, and one of these signs is to control access. What I'm trying to get it to indicate is that cars aren't permitted between 10 am and 4pm except for access.

Which of the below mean what I want to say above?


Except for access 10 am - 4 pm  
10 am - 4 pm except for access


Am I correct in thinking that the first one means ""Cars allowed for access between 10 am and 4 pm only "" and the second one is ""No cars between 10 am and 4 pm except for access"".

I realize the ambiguity of the sign, and want to make sure what I'm saying is correct.
",I would like to say that it would be better to express it in a clearer way:
1801,1801,2859,Experience with direct data access components,"I would like to know as to what has been the experience of using direct data access components like devart's MyDAC which allows a direct connection to the mysql server rather than through the client library or ODBC.
",Vinayak Mahadevan,https://stackoverflow.com/users/366347,"Mydac is the best when you try to connect to MySql, it's fast stable and real powerful components.

Also the same for other components like Sdac and Odac.

and if you would like to use more than database you can use Unidac, which you can use to connect to (oracle, Sql server, Mysql, Interbase, Firebird and ODBC drivers.).

Another great point for Devart components that you don't need client library to be installed on the clients machine (libmysql.dll).
",Mohammed Nasman,https://stackoverflow.com/users/24462,http://stackoverflow.com/questions/3042008/experience-with-direct-data-access-components,STACKOVERFLOW,stackoverflow.com,0.6666666666666666,0.4444444444444444,0.6666666666666666,0.0,0.3333333333333333,0.0,0.5555555555555556,0.3333333333333333,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.6666666666666666,0.5555555555555556,0.6666666666666666,0.5555555555555556,1.0,0.9333333333333332,0.0,0.0,0.6666666666666666,0.6666666666666666,Experience with direct data access components,"I'd like to know about the experience of using direct data access components such as devirt's mydac, which allows direct connections to MySQL servers, rather than through client libraries or ODBC.","Mydac is the best when you try to connect to MySql, it's fast stable and real powerful components.

Also the same for other components like Sdac and Odac.

and if you would like to use more than database you can use Unidac, which you can use to connect to (oracle, Sql server, Mysql, Interbase, Firebird and ODBC drivers.).

Another great point for Devart components that you don't need client library to be installed on the clients machine (libmysql.dll).
"
3193,3193,5087,How do you prove $S=-\sum p\ln p$?,"How does one prove the formula for entropy $S=-\sum p\ln p$?
Obviously systems on the microscopic level are fully determined by the microscopic equations of motion. So if you want to introduce a law on top of that, you have to prove consistency, i.e. entropy cannot be a postulate.
I can imagine that it is derived from probability theory for general system. Do you know such a line?

Once you have such a reasoning, what are the assumptions to it?
Can these assumptions be invalid for special systems? Would these system not obey thermodynamics, statistical mechanics and not have any sort of temperature no matter how general?

If therodynamics/statmech are completely general, how would you apply them the system where one point particle orbits another?
",Gerenuk,https://physics.stackexchange.com/users/5152,"The best (IMHO) derivation of the $\sum p \log p$ formula from basic postulates is the one given originally by Shannon:

Shannon (1948) A Mathematical Theory of Communication. Bell System Technical Journal. http://cm.bell-labs.com/cm/ms/what/shannonday/shannon1948.pdf

However, Shannon was concerned not with physics but with telegraphy, so his proof appears in the context of information transmission rather than statistical mechanics.  To see the relevance of Shannon's work to physics, the best references are papers by Edwin Jaynes. He wrote dozens of papers on the subject.  My favorite is the admittedly rather long

Jaynes, E. T., 1979, `Where do we Stand on Maximum Entropy?' in The Maximum Entropy Formalism, R. D. Levine and M. Tribus (eds.), M. I. T. Press, Cambridge, MA, p. 15; http://bayes.wustl.edu/etj/articles/stand.on.entropy.pdf
",Nathaniel,https://physics.stackexchange.com/users/5477,http://physics.stackexchange.com/questions/14436/how-do-you-prove-s-sum-p-ln-p,SCIENCE,physics.stackexchange.com,0.8888888888888888,0.4444444444444444,0.0,0.3333333333333333,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.6666666666666666,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,1.0,0.0,0.7777777777777778,0.7777777777777778,0.5555555555555556,0.7777777777777778,0.8333333333333334,0.8,0.3333333333333333,0.3333333333333333,0.3333333333333333,1.0,How to prove $s = - \ sum P \ ln p $?,"How does one prove the formula for entropy $S=-\sum p\ln p$?
Obviously systems on the microscopic level are fully determined by the microscopic equations of motion. So if you want to introduce a law on top of that, you have to prove consistency, i.e. entropy cannot be a postulate.
I can imagine that it is derived from probability theory for general system. Do you know such a line?

Once you have such a reasoning, what are the assumptions to it?
Can these assumptions be invalid for special systems? Would these system not obey thermodynamics, statistical mechanics and not have any sort of temperature no matter how general?

If therodynamics/statmech are completely general, how would you apply them the system where one point particle orbits another?
","The best (IMHO) derivation of the $\sum p \log p$ formula from basic postulates is the one given originally by Shannon:

Shannon (1948) A Mathematical Theory of Communication. Bell System Technical Journal. http://cm.bell-labs.com/cm/ms/what/shannonday/shannon1948.pdf

However, Shannon was concerned not with physics but with telegraphy, so his proof appears in the context of information transmission rather than statistical mechanics.  To see the relevance of Shannon's work to physics, the best references are papers by Edwin Jaynes. He wrote dozens of papers on the subject.  My favorite is the admittedly rather long

Jaynes, E. T., 1979, `Where do we Stand on Maximum Entropy?' in The Maximum Entropy Formalism, R. D. Levine and M. Tribus (eds.), M. I. T. Press, Cambridge, MA, p. 15; http://bayes.wustl.edu/etj/articles/stand.on.entropy.pdf
"
4755,4755,7547,How to Implement composite primary key with Hibernate Annonations,"I would like to know how to create a Composite Combination through Hibernate annotation method. 

I have 3 tables Employee, Department &amp; Employee-Department-Juntion

Since I want to make Employee and Department as individual table, i created a Junction Table in order maintain the Many-to-Many relationship.

I would like to know how to Create Composite Primary Key for the Department Table
For the column Center_Code &amp; Depart_Code through Hibernate Annotations.

Could you please somebody help me how to solve this issue.

Below Here I also attached the Table Relation Ship and the Java POJO Class.

Table Relationship



JAVA POJO CLASS

package com.hibernate;

import java.util.Objects;
import javax.persistence.Entity;
import javax.persistence.Id;

/**
 *
 * @author SPAR
 */
@Entity
public class Department {

    @Id
    private String cost_Center_Code;
    private String dep_Code;
    private String department;
    private String sub_Department;
    private String division;

    public String getDepartment() {
        return department;
    }

    public void setDepartment(String department) {
        this.department = department;
    }

    public String getDep_Code() {
        return dep_Code;
    }

    public void setDep_Code(String dep_Code) {
        this.dep_Code = dep_Code;
    }

    public String getCost_Center_Code() {
        return cost_Center_Code;
    }

    public void setCost_Center_Code(String cost_Center_Code) {
        this.cost_Center_Code = cost_Center_Code;
    }

    public String getDivision() {
        return division;
    }

    public void setDivision(String division) {
        this.division = division;
    }

    public String getSub_Department() {
        return sub_Department;
    }

    public void setSub_Department(String sub_Department) {
        this.sub_Department = sub_Department;
    }

    @Override
    public String toString() {
        return ""Department{"" + ""cost_Center_Code="" + cost_Center_Code + "", dep_Code="" + dep_Code + "", department="" + department + "", sub_Department="" + sub_Department + "", division="" + division + '}';
    }

    @Override
    public int hashCode() {
        int hash = 7;
        hash = 79 * hash + Objects.hashCode(this.cost_Center_Code);
        hash = 79 * hash + Objects.hashCode(this.dep_Code);
        return hash;
    }

    @Override
    public boolean equals(Object obj) {
        if (obj == null) {
            return false;
        }
        if (getClass() != obj.getClass()) {
            return false;
        }
        final Department other = (Department) obj;
        if (!Objects.equals(this.cost_Center_Code, other.cost_Center_Code)) {
            return false;
        }
        if (!Objects.equals(this.dep_Code, other.dep_Code)) {
            return false;
        }
        return true;
    }

}

",Arun,https://stackoverflow.com/users/2535203,"@Entity
public class Department {

    @EmbeddedId
    private DepartmentId departmentId

    private String department;
    private String sub_Department;
    private String division;
}

@Embeddable
public class DepartmentId {
    @Column(name = """")
    private String cost_Center_Code;

    @Column(name = """")
    private String dep_Code;

    //getter, setter methods
}

",Andy Dufresne,https://stackoverflow.com/users/537503,http://stackoverflow.com/questions/27666707/how-to-implement-composite-primary-key-with-hibernate-annonations,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.5555555555555556,0.0,1.0,0.3333333333333333,1.0,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.0,0.3333333333333333,0.8888888888888888,How to realize compound primary key with hibernate annotation,"I would like to know how to create a Composite Combination through Hibernate annotation method. 

I have 3 tables Employee, Department &amp; Employee-Department-Juntion

Since I want to make Employee and Department as individual table, i created a Junction Table in order maintain the Many-to-Many relationship.

I would like to know how to Create Composite Primary Key for the Department Table
For the column Center_Code &amp; Depart_Code through Hibernate Annotations.

Could you please somebody help me how to solve this issue.

Below Here I also attached the Table Relation Ship and the Java POJO Class.

Table Relationship



JAVA POJO CLASS

package com.hibernate;

import java.util.Objects;
import javax.persistence.Entity;
import javax.persistence.Id;

/**
 *
 * @author SPAR
 */
@Entity
public class Department {

    @Id
    private String cost_Center_Code;
    private String dep_Code;
    private String department;
    private String sub_Department;
    private String division;

    public String getDepartment() {
        return department;
    }

    public void setDepartment(String department) {
        this.department = department;
    }

    public String getDep_Code() {
        return dep_Code;
    }

    public void setDep_Code(String dep_Code) {
        this.dep_Code = dep_Code;
    }

    public String getCost_Center_Code() {
        return cost_Center_Code;
    }

    public void setCost_Center_Code(String cost_Center_Code) {
        this.cost_Center_Code = cost_Center_Code;
    }

    public String getDivision() {
        return division;
    }

    public void setDivision(String division) {
        this.division = division;
    }

    public String getSub_Department() {
        return sub_Department;
    }

    public void setSub_Department(String sub_Department) {
        this.sub_Department = sub_Department;
    }

    @Override
    public String toString() {
        return ""Department{"" + ""cost_Center_Code="" + cost_Center_Code + "", dep_Code="" + dep_Code + "", department="" + department + "", sub_Department="" + sub_Department + "", division="" + division + '}';
    }

    @Override
    public int hashCode() {
        int hash = 7;
        hash = 79 * hash + Objects.hashCode(this.cost_Center_Code);
        hash = 79 * hash + Objects.hashCode(this.dep_Code);
        return hash;
    }

    @Override
    public boolean equals(Object obj) {
        if (obj == null) {
            return false;
        }
        if (getClass() != obj.getClass()) {
            return false;
        }
        final Department other = (Department) obj;
        if (!Objects.equals(this.cost_Center_Code, other.cost_Center_Code)) {
            return false;
        }
        if (!Objects.equals(this.dep_Code, other.dep_Code)) {
            return false;
        }
        return true;
    }

}

","@Entity
public class Department {

    @EmbeddedId
    private DepartmentId departmentId

    private String department;
    private String sub_Department;
    private String division;
}

@Embeddable
public class DepartmentId {
    @Column(name = """")
    private String cost_Center_Code;

    @Column(name = """")
    private String dep_Code;

    //getter, setter methods
}

"
75,75,118,"Can you send data usefully over one wire, literally one wire?","It is possible to design networking systems that only use two wires: one for data and one for a common ground. Examples include 1-wire and Pin&amp;Play. These are called single wire systems because the requirement for an earth wire is implied too. But you can also get systems to extend home networks that use the home earth to connect network points, like Power Line Communication. How is this possible over just one wire?

== EDIT ==

From the answers (thanks!) I think I failed to word this question clearly. Let me try again.

Can you send data usefully over one wire, literally one wire? Radio is zero, 1-wire is two, but is it possible with one? ""No, and here's why"" or ""Yes, here's how it is done in X"" are the kind of answers I am hoping for.

(N.B. I'll also change the question title from ""Single wire systems need two wires; so how does ethernet over ground work?"" to ""Can you send data usefully over one wire, literally one wire?"")
",dumbledad,https://electronics.stackexchange.com/users/10772,"EDIT - because of the reshaping of the question. my answer at the bottom isn't that relevant. To the edited question: -


  ""Can you send data usefully over one wire, literally one wire?""


My answer is ""Not with any level of success"". Reasoning - if you are sending signals you need a forward and a return path for the current. If the return path is tenuously connected (such as through the ground), any ground interference in the vicinity of the return path adds to the signal received and has a tendency to corrupt that signal. However, couldn't the ground be classed as a wire? Avoiding this issue, if there were a tenuous ground connection that is validated as not adding an extra wire, the answer could be ""Yes"" providing the transmitted signal was powerful enough to overcome natural and unnatural interference in the vicinity of the return path.

If the signal were RF and transmitted via ""a single wire"" such as an antenna you could argue the answer is ""Yes"" but would the receiving antenna be counted as a wire making the RF argument null and void? Ultrasonic signalling or optical signalling don't need wires to make a connection so they are invalidated in my answer.

Answer to question before revision: -

I use zero-wire systems quite a lot - these receive their power and transmit data using NO (repeat NO) interconnecting wires. Data transmission is a little under 1Mb per second and of course for a (decent) network that is dreadful. Ditto for powerline comms and 1-wire and Pin&amp;Play (worst of the lot).

If you want a decent high-speed network then wide-bandwidth systems are required and twisted pair is needed to get any reasonable distance between offices. WiFi is good but this uses sophisticated modulation techniques and radio to achieve high-speed - the ones in your home haven't got a lot of range though.

Yes you can design networking systems that only use two wires but they would be significantly faster and less-prone to errors if they were a balanced pair. You can even phantom power equipment connected to them just like 1-wire (2 really) does.

Don't be hoodwinked by all the marketing up-front blurb
",Andy aka,https://electronics.stackexchange.com/users/20218,http://electronics.stackexchange.com/questions/67692/can-you-send-data-usefully-over-one-wire-literally-one-wire,TECHNOLOGY,electronics.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,1.0,0.6666666666666666,1.0,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.6666666666666666,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,1.0,Can you use a wire to send data effectively? Is it really a wire?,"It is possible to design networking systems that only use two wires: one for data and one for a common ground. Examples include 1-wire and Pin&amp;Play. These are called single wire systems because the requirement for an earth wire is implied too. But you can also get systems to extend home networks that use the home earth to connect network points, like Power Line Communication. How is this possible over just one wire?

== EDIT ==

From the answers (thanks!) I think I failed to word this question clearly. Let me try again.

Can you send data usefully over one wire, literally one wire? Radio is zero, 1-wire is two, but is it possible with one? ""No, and here's why"" or ""Yes, here's how it is done in X"" are the kind of answers I am hoping for.

(N.B. I'll also change the question title from ""Single wire systems need two wires; so how does ethernet over ground work?"" to ""Can you send data usefully over one wire, literally one wire?"")
","EDIT - because of the reshaping of the question. my answer at the bottom isn't that relevant. To the edited question: -


  ""Can you send data usefully over one wire, literally one wire?""


My answer is ""Not with any level of success"". Reasoning - if you are sending signals you need a forward and a return path for the current. If the return path is tenuously connected (such as through the ground), any ground interference in the vicinity of the return path adds to the signal received and has a tendency to corrupt that signal. However, couldn't the ground be classed as a wire? Avoiding this issue, if there were a tenuous ground connection that is validated as not adding an extra wire, the answer could be ""Yes"" providing the transmitted signal was powerful enough to overcome natural and unnatural interference in the vicinity of the return path.

If the signal were RF and transmitted via ""a single wire"" such as an antenna you could argue the answer is ""Yes"" but would the receiving antenna be counted as a wire making the RF argument null and void? Ultrasonic signalling or optical signalling don't need wires to make a connection so they are invalidated in my answer.

Answer to question before revision: -

I use zero-wire systems quite a lot - these receive their power and transmit data using NO (repeat NO) interconnecting wires. Data transmission is a little under 1Mb per second and of course for a (decent) network that is dreadful. Ditto for powerline comms and 1-wire and Pin&amp;Play (worst of the lot).

If you want a decent high-speed network then wide-bandwidth systems are required and twisted pair is needed to get any reasonable distance between offices. WiFi is good but this uses sophisticated modulation techniques and radio to achieve high-speed - the ones in your home haven't got a lot of range though.

Yes you can design networking systems that only use two wires but they would be significantly faster and less-prone to errors if they were a balanced pair. You can even phantom power equipment connected to them just like 1-wire (2 really) does.

Don't be hoodwinked by all the marketing up-front blurb
"
1799,1799,2857,Can you book hotels on a prepaid credit card worldwide?,"I tend to stay at smaller boutique hotels or local apartments when I visit a city but recently due to some credit card issues I will need to depend on prepaid Visa.  But I noticed when I try to shop online a lot of retailers don't accept prepaid credit cards so I'm thinking hotels would be even stricter.  Is there a list somewhere of countries or particular hotel chains than ban prepaid cards? If so, how does one book online or reserve a room without a card?  Do all hotels worldwide accept cash?
",verve,https://travel.stackexchange.com/users/2283,"I did some research and could find information about the standards of Hilton Hotel Chain. They are one of the leading hotel chains and might set the standards for smaller hotel chains. 

Hilton offers also an American Express Prepaid credit card. See link: Hilton AMEX prepaid card. And you would expect that their own prepaid credit card would be acceptable for Hilton, but think again. 

In their FAQ they state: 


  Where can the Card be used? Are there any usage restrictions?
  THE CARD MAY ONLY BE USED AT THE FOLLOWING SELECT MERCHANTS AND RETAILERS AROUND THE WORLD THAT ACCEPT THE AMERICAN EXPRESS CARD (""SELECT MERCHANTS""):
  
  Hilton Worldwide portfolio of brands, which include Waldorf Astoria™ Hotels &amp; Resorts, Conrad® Hotels and Resorts, Hilton Hotels and Resorts, Doubletree by Hilton™, Embassy Suites by Hilton™, Hilton Garden Inn™, Hampton by Hilton™, Homewood Suites by Hilton™, Home2 Suites by Hilton™, and Hilton Grand Vacations™.
  
  RESTRICTION: Card may not be used to hold hotel reservations.
  
  We reserve the right at any time to add other merchants to the list of Select Merchants or to remove merchants that cease business, change locations or stop accepting the American Express Card from the list of Select Merchants.Please note that while the Card is usable at the Select Merchants listed above, it may not be usable internationally at non-affiliated third party establishments that are located within or on the same property as Select Merchants (e.g. coffee shops, boutiques).


I have checked many other hotel chains and I can`t find anything else about this. I do notice based on the information on the internet that if a hotel would accept it. They would hold at a minimum the total amount of your stay + 15% + additional amount for minibar and other used services as an guarantee. 

Some hotel would hold up to 3x the amount of your stay (I cant verify if that is really true). Just realize that a prepaid credit cards usually (not always) for people who have a bad credit record. Hotels take more protection when dealing with these kind of risks. 

Im not sure if the information will help, but at least you know Hilton Hotel is not an option. 
",Summerset Travel Agency,https://travel.stackexchange.com/users/15323,http://travel.stackexchange.com/questions/35395/can-you-book-hotels-on-a-prepaid-credit-card-worldwide,CULTURE,travel.stackexchange.com,1.0,0.3333333333333333,0.0,1.0,1.0,1.0,0.6666666666666666,0.7777777777777778,1.0,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.0,1.0,0.7777777777777778,0.5555555555555556,1.0,1.0,0.7333333333333333,0.0,0.3333333333333333,0.6666666666666666,0.7777777777777778,Can you book hotels around the world by prepaid credit card?,"When I visit a city, I tend to stay in smaller boutique hotels or local apartments, but recently due to some credit card problems, I need to rely on a prepaid Visa. But I've noticed that when I try to shop online, many retailers don't accept prepaid credit cards, so I think hotels will be more strict. In addition to banning prepaid cards, is there a list of other countries or specific chains of hotels? If so, how can I book a room online or without a card? Do hotels around the world receive cash?","I did some research and could find information about the standards of Hilton Hotel Chain. They are one of the leading hotel chains and might set the standards for smaller hotel chains. 

Hilton offers also an American Express Prepaid credit card. See link: Hilton AMEX prepaid card. And you would expect that their own prepaid credit card would be acceptable for Hilton, but think again. 

In their FAQ they state: 


  Where can the Card be used? Are there any usage restrictions?
  THE CARD MAY ONLY BE USED AT THE FOLLOWING SELECT MERCHANTS AND RETAILERS AROUND THE WORLD THAT ACCEPT THE AMERICAN EXPRESS CARD (""SELECT MERCHANTS""):
  
  Hilton Worldwide portfolio of brands, which include Waldorf Astoria™ Hotels &amp; Resorts, Conrad® Hotels and Resorts, Hilton Hotels and Resorts, Doubletree by Hilton™, Embassy Suites by Hilton™, Hilton Garden Inn™, Hampton by Hilton™, Homewood Suites by Hilton™, Home2 Suites by Hilton™, and Hilton Grand Vacations™.
  
  RESTRICTION: Card may not be used to hold hotel reservations.
  
  We reserve the right at any time to add other merchants to the list of Select Merchants or to remove merchants that cease business, change locations or stop accepting the American Express Card from the list of Select Merchants.Please note that while the Card is usable at the Select Merchants listed above, it may not be usable internationally at non-affiliated third party establishments that are located within or on the same property as Select Merchants (e.g. coffee shops, boutiques).


I have checked many other hotel chains and I can`t find anything else about this. I do notice based on the information on the internet that if a hotel would accept it. They would hold at a minimum the total amount of your stay + 15% + additional amount for minibar and other used services as an guarantee. 

Some hotel would hold up to 3x the amount of your stay (I cant verify if that is really true). Just realize that a prepaid credit cards usually (not always) for people who have a bad credit record. Hotels take more protection when dealing with these kind of risks. 

Im not sure if the information will help, but at least you know Hilton Hotel is not an option. 
"
2104,2104,3349,What is the best introductory Bayesian statistics textbook?,"Which is the best introductory textbook for Bayesian statistics?

One book per answer, please.
",Shane,https://stats.stackexchange.com/users/5,"I have read some parts of A First Course in Bayesian Statistical Methods by Peter Hoff, and I found it easy to follow. (Example R-code is provided throughout the text)
",George Dontas,https://stats.stackexchange.com/users/339,http://stats.stackexchange.com/questions/125/what-is-the-best-introductory-bayesian-statistics-textbook,SCIENCE,stats.stackexchange.com,1.0,1.0,1.0,1.0,0.3333333333333333,0.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.7777777777777778,0.5555555555555556,1.0,1.0,0.8,0.0,0.0,0.0,0.8888888888888888,What is the best introduction to Bayesian statistics?,Which is the best introduction to Bayesian statistics?,"I have read some parts of A First Course in Bayesian Statistical Methods by Peter Hoff, and I found it easy to follow. (Example R-code is provided throughout the text)
"
2561,2561,4076,Didn't Say Uno Before Running Out of Cards,"So my family is having a disagreement on the uno rules. Here's what happened:

Player 1 completes turn by playing a regular numbered blue card

Player 2 has 3 cards left. Player 2 plays a blue skip, and plays a red skip. Player 2 has 1 card now. Player 2 plays their last card (a red numbered card). 

They are out of cards, having played 3 cards really close together, with no chance for Player 1 to call them out on not saying uno. Player 1 calls it right after Player 2 has already run out of cards.

Here's the question - Player 2 is already out of cards, and never said Uno, and now Player 1 is calling them out on it. Has player 2 already won, or must Player 2 now take 2 cards?
",James T,https://boardgames.stackexchange.com/users/11745,"From the rules, the hand is over. 

http://www.wonkavator.com/uno/unorules.html


  When you have one card left, you must yell ""UNO"" (meaning one).
  Failure to do this results in you having to pick two cards from the
  DRAW pile. That is, of course if you get caught by the other players.
  Once a player has no cards left, the hand is over. Points are scored
  (see scoring section) and you start over again. That's UNO in a
  nutshell.


Further, you only have until the next player starts playing a card before it is to late to call them out. In this scenario once Player 2 started his 3rd turn (by starting the motion to play his last card), it was too late to call him out.


  A player who forgets to say UNO before his card touches the discard
  pile, but ""catches"" himself before any other player catches him, is
  safe and is not subject to the penalty. You may not catch a player for
  failure to say UNO until his second to last card touches the DISCARD
  pile. Also, you may not catch a player for failure to say UNO after
  the next player begins his turn. ""Beginning a turn is defines as
  either drawing a card from the DRAW pile or drawing a card from your
  hand to play. If the last card played in a hand is a Draw Two or Wild
  Draw Four card, the next player must draw the two or four cards. These
  cards are counted when points are totaled. If no one is out of cards
  by the time the DRAW pile is depleted, reshuffle and continue play.


In order to call out Player2 and force him to draw cards for not saying 'UNO', Player 1 would have had to say it directly after his second to last card was played (touched the discard pile) but before he started to play his last card. Incredibly short, but possible.
",Colin D,https://boardgames.stackexchange.com/users/3128,http://boardgames.stackexchange.com/questions/22851/didnt-say-uno-before-running-out-of-cards,CULTURE,boardgames.stackexchange.com,1.0,0.3333333333333333,0.0,1.0,1.0,1.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.8888888888888888,1.0,0.8888888888888888,1.0,1.0,1.0,0.0,0.0,1.0,0.8888888888888888,Didn't say uno before the card ran out,"So my family is having a disagreement on the uno rules. Here's what happened:

Player 1 completes turn by playing a regular numbered blue card

Player 2 has 3 cards left. Player 2 plays a blue skip, and plays a red skip. Player 2 has 1 card now. Player 2 plays their last card (a red numbered card). 

They are out of cards, having played 3 cards really close together, with no chance for Player 1 to call them out on not saying uno. Player 1 calls it right after Player 2 has already run out of cards.

Here's the question - Player 2 is already out of cards, and never said Uno, and now Player 1 is calling them out on it. Has player 2 already won, or must Player 2 now take 2 cards?
","From the rules, the hand is over. 

http://www.wonkavator.com/uno/unorules.html


  When you have one card left, you must yell ""UNO"" (meaning one).
  Failure to do this results in you having to pick two cards from the
  DRAW pile. That is, of course if you get caught by the other players.
  Once a player has no cards left, the hand is over. Points are scored
  (see scoring section) and you start over again. That's UNO in a
  nutshell.


Further, you only have until the next player starts playing a card before it is to late to call them out. In this scenario once Player 2 started his 3rd turn (by starting the motion to play his last card), it was too late to call him out.


  A player who forgets to say UNO before his card touches the discard
  pile, but ""catches"" himself before any other player catches him, is
  safe and is not subject to the penalty. You may not catch a player for
  failure to say UNO until his second to last card touches the DISCARD
  pile. Also, you may not catch a player for failure to say UNO after
  the next player begins his turn. ""Beginning a turn is defines as
  either drawing a card from the DRAW pile or drawing a card from your
  hand to play. If the last card played in a hand is a Draw Two or Wild
  Draw Four card, the next player must draw the two or four cards. These
  cards are counted when points are totaled. If no one is out of cards
  by the time the DRAW pile is depleted, reshuffle and continue play.


In order to call out Player2 and force him to draw cards for not saying 'UNO', Player 1 would have had to say it directly after his second to last card was played (touched the discard pile) but before he started to play his last card. Incredibly short, but possible.
"
4644,4644,7364,Why ducklings are yellow?,"Why ducklings are yellow, what the evolutionary background for this? How could it help to survive?

UPDATE 

I agree with comment below,
I did remember then that ducks are wild animals too (when I asked the question I imagined domesticated ducklings as widely pictured in media), but anyway it is interesting to know why the domesticated ducklings are yellow now. What is the reason of selection drove such coloration to young ducks or yellow pigment is just a side effect?
",rook,https://biology.stackexchange.com/users/4123,"Wild ducklings, like these baby Mallard ducks, are in fact typically only partly yellow:


Photo by TheBrockenInaGlory via Wikimedia Commons, used under the CC-By-SA 3.0 license.

While I'm no expert, I would guess that the mottled yellow-brown coloring of the juveniles is, at least partially, protective coloration, just like the somewhat similar pattern on the adult female's feathers.  While it may appear conspicuous on open water, ducks in their natural habitat will often seek shelter among reeds and other vegetation, where the irregular pattern of light and shadow would create a very effective camouflage for the ducklings.

As for the all-yellow ducklings of domestic ducks, these presumably arose via elimination of the darker parts of the coloring as a result of selective breeding, perhaps as a side effect of artificial selection for the white adult plumage found in many domestic ducks today.
",Ilmari Karonen,https://biology.stackexchange.com/users/239,http://biology.stackexchange.com/questions/10008/why-ducklings-are-yellow,SCIENCE,biology.stackexchange.com,1.0,0.8888888888888888,0.0,0.6666666666666666,1.0,1.0,0.7777777777777778,0.7777777777777778,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.7777777777777778,0.8888888888888888,0.5555555555555556,0.8888888888888888,0.8888888888888888,0.8,0.0,0.0,1.0,0.8888888888888888,Why is the duckling yellow?,"Why ducklings are yellow, what the evolutionary background for this? How could it help to survive?

UPDATE 

I agree with comment below,
I did remember then that ducks are wild animals too (when I asked the question I imagined domesticated ducklings as widely pictured in media), but anyway it is interesting to know why the domesticated ducklings are yellow now. What is the reason of selection drove such coloration to young ducks or yellow pigment is just a side effect?
","Wild ducklings, like these baby Mallard ducks, are in fact typically only partly yellow:


Photo by TheBrockenInaGlory via Wikimedia Commons, used under the CC-By-SA 3.0 license.

While I'm no expert, I would guess that the mottled yellow-brown coloring of the juveniles is, at least partially, protective coloration, just like the somewhat similar pattern on the adult female's feathers.  While it may appear conspicuous on open water, ducks in their natural habitat will often seek shelter among reeds and other vegetation, where the irregular pattern of light and shadow would create a very effective camouflage for the ducklings.

As for the all-yellow ducklings of domestic ducks, these presumably arose via elimination of the darker parts of the coloring as a result of selective breeding, perhaps as a side effect of artificial selection for the white adult plumage found in many domestic ducks today.
"
29,29,41,"Relationship between user story, feature, and epic?","As someone whose still new to agile, I'm not sure I completely understand the relationship or difference between a user story, feature, and epic.

According to this question, a feature is a collection of stories.  One of the answers suggest that a feature is actually an epic.  

So are features and epics considered the same thing, which is basically a collection of related user stories?

Our project manager insists that there's a hierarchical structure:

Epic -> Features -> User stories

... basically all user stories must fall within this structure.  Therefore all user stories must fall under an umbrella feature and all features must fall under an epic.

To me, that sounds awkward.  Can someone please clarify how user stories, features, and epics are related?  Or is there an article that clearly outlines the differences?
",nivlam,https://programmers.stackexchange.com/users/45,"I caution you against applying too rigid a hierarchy to these terms.  We tried to do that in my previous job.  Twice.  Both attempts were different and both times we found we had unnecessarily limited ourselves.  The only constant was the definition of a User Story.  From a planning perspective, a story is the basic building block of a project.  The larger terms (epic, feature, etc.) are effectively just tags.  Tags are an easy way to allow a story to exist as part of multiple Epics and multiple Features at the same time.  It's not worth the mental effort to be more strict than that.

Tags work for Stack Exchange and they can work for you too.
",Kristo,https://programmers.stackexchange.com/users/1111,http://programmers.stackexchange.com/questions/182158/relationship-between-user-story-feature-and-epic,TECHNOLOGY,programmers.stackexchange.com,0.8888888888888888,0.6666666666666666,0.0,0.3333333333333333,1.0,0.6666666666666666,0.5555555555555556,0.4444444444444444,1.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,1.0,0.8888888888888888,0.5555555555555556,1.0,1.0,0.8,0.0,0.0,0.3333333333333333,1.0,"What is the relationship between user stories, features, and epics?","As someone whose still new to agile, I'm not sure I completely understand the relationship or difference between a user story, feature, and epic.

According to this question, a feature is a collection of stories.  One of the answers suggest that a feature is actually an epic.  

So are features and epics considered the same thing, which is basically a collection of related user stories?

Our project manager insists that there's a hierarchical structure:

Epic -> Features -> User stories

... basically all user stories must fall within this structure.  Therefore all user stories must fall under an umbrella feature and all features must fall under an epic.

To me, that sounds awkward.  Can someone please clarify how user stories, features, and epics are related?  Or is there an article that clearly outlines the differences?
","I warn you not to apply too strict a hierarchy to these terms. We tried it in our previous work. Twice. Both attempts are different, and both of us find ourselves unnecessarily limited. The only constant is the definition of the user story. From a planning point of view, stories are an essential part of the project. Larger terms (epic, character, etc.) are really just labels. Tagging is a simple way to allow stories to exist as part of multiple epics and multiple features at the same time. No matter how strict it is, it is not worthy of spiritual efforts."
2140,2140,3408,Android- R.java file not found,"While working with an android project .I'm stuck with R.java file which is not found even I clean the project(project---->clean).But that file still not found .Even I create a new project the same problem occurs .
what I need to do ? I'm expecting the valuable replies from which I could overcome this problem 
",Rakesh L,https://stackoverflow.com/users/1870586,"R.java is missing implicate that your resource folder is having some issues. please try to look at your resource files(layout,drawable etc). and after that clean the project. it will solve the problem for sure.
",Dinesh Prajapati,https://stackoverflow.com/users/579718,http://stackoverflow.com/questions/15201166/android-r-java-file-not-found,STACKOVERFLOW,stackoverflow.com,0.5555555555555556,0.6666666666666666,0.0,1.0,0.6666666666666666,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.5555555555555556,0.8333333333333334,0.6666666666666666,1.0,1.0,0.9,1.0,0.0,0.3333333333333333,0.8888888888888888,Android-r.java file not found,"When dealing with an Android project, I am stuck by the r.java file. Even if I clean the project (Project -- > clean), I can't find the file. Even if I create a new project, the same problem will occur.","R.java is missing implicate that your resource folder is having some issues. please try to look at your resource files(layout,drawable etc). and after that clean the project. it will solve the problem for sure.
"
2888,2888,4594,Get current Activity with Android,"I have a method that scans the position and gets called on every activity I have, everytime an actions trigger I need to show an alertDialog, this is the code:

AlertDialog.Builder builder = new AlertDialog.Builder(mMainActivity.this);
                        builder.setMessage(""test"")
                           .setCancelable(false)
                           .setPositiveButton(""go"", new DialogInterface.OnClickListener() {
                               public void onClick(DialogInterface dialog, int id) {
                                   Intent intent = new Intent(mMainActivity.this,LocationDetails.class);
                                    intent.putExtra(""placeId"",1);
                                    startActivity(intent);

                               }
                           })
                           .setNegativeButton(""cancel"", new DialogInterface.OnClickListener() {
                               public void onClick(DialogInterface dialog, int id) {

                                    dialog.cancel();
                               }
                           });
                        AlertDialog alert = builder.create();
                        alert.show();


But How can I create the alert on the current activity? Because now it only gets created on AlertDialog.Builder(mMainActivity.this);
",Signo,https://stackoverflow.com/users/3789527,"create class vis static method in vich you transfer ""link"" yours activitis 
for example from MainActivity call :
DialogUtils.createSomeDialog(MainActivity.this); 
or from SecondActivity:
DialogUtils.createSomeDialog(SecondActivity.this);


    public class DialogUtils
{
    public static void createSomeDialog(final Context context){
        AlertDialog.Builder builder = new AlertDialog.Builder(context);
        builder.setMessage(""test"")
                .setCancelable(false)
                .setPositiveButton(""go"", new DialogInterface.OnClickListener() {
                    public void onClick(DialogInterface dialog, int id) {
                        Intent intent = new Intent(context,LocationDetails.class);
                        intent.putExtra(""placeId"",1);
                        context.startActivity(intent);

                    }
                })
                .setNegativeButton(""cancel"", new DialogInterface.OnClickListener() {
                    public void onClick(DialogInterface dialog, int id) {

                        dialog.cancel();
                    }
                });
        AlertDialog alert = builder.create();
        alert.show();
    }
}

",Iatsenko Anton,https://stackoverflow.com/users/4147030,http://stackoverflow.com/questions/30511271/get-current-activity-with-android,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.4444444444444444,0.0,1.0,0.6666666666666666,1.0,0.4444444444444444,0.4444444444444444,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,0.7777777777777778,Get current activity using Android,"I have a method that scans the position and gets called on every activity I have, everytime an actions trigger I need to show an alertDialog, this is the code:

AlertDialog.Builder builder = new AlertDialog.Builder(mMainActivity.this);
                        builder.setMessage(""test"")
                           .setCancelable(false)
                           .setPositiveButton(""go"", new DialogInterface.OnClickListener() {
                               public void onClick(DialogInterface dialog, int id) {
                                   Intent intent = new Intent(mMainActivity.this,LocationDetails.class);
                                    intent.putExtra(""placeId"",1);
                                    startActivity(intent);

                               }
                           })
                           .setNegativeButton(""cancel"", new DialogInterface.OnClickListener() {
                               public void onClick(DialogInterface dialog, int id) {

                                    dialog.cancel();
                               }
                           });
                        AlertDialog alert = builder.create();
                        alert.show();


But How can I create the alert on the current activity? Because now it only gets created on AlertDialog.Builder(mMainActivity.this);
","create class vis static method in vich you transfer ""link"" yours activitis 
for example from MainActivity call :
DialogUtils.createSomeDialog(MainActivity.this); 
or from SecondActivity:
DialogUtils.createSomeDialog(SecondActivity.this);


    public class DialogUtils
{
    public static void createSomeDialog(final Context context){
        AlertDialog.Builder builder = new AlertDialog.Builder(context);
        builder.setMessage(""test"")
                .setCancelable(false)
                .setPositiveButton(""go"", new DialogInterface.OnClickListener() {
                    public void onClick(DialogInterface dialog, int id) {
                        Intent intent = new Intent(context,LocationDetails.class);
                        intent.putExtra(""placeId"",1);
                        context.startActivity(intent);

                    }
                })
                .setNegativeButton(""cancel"", new DialogInterface.OnClickListener() {
                    public void onClick(DialogInterface dialog, int id) {

                        dialog.cancel();
                    }
                });
        AlertDialog alert = builder.create();
        alert.show();
    }
}

"
852,852,1358,Apache won't allow multiple name-based virtual hosts,"Here's the problem I'm facing: I've added multiple virtual hosts(name based) to apache yet still only one is loaded.

For example I have two domains with different contents.
Site1 Domain -> Site1 Content 
Site2 Domain -> Site1 Content aswell..
I've included the httpd-vhosts file in the httpd config file, and I've edited it to match what it asks me to do on their documentation yet still only one folder of contents is served.

Here is my httpd-vhosts file, the httpd file I assume doesn't need posting but if required I shall:

NameVirtualHost *
&lt;Directory ""C:/www/""&gt;
    Options Indexes FollowSymLinks
    AllowOverride None
    Order allow,deny
    Allow from all

&lt;/Directory&gt;
&lt;VirtualHost *&gt;
    ServerName www.*****.com
    DocumentRoot ""C:\www*****""
&lt;/VirtualHost&gt;

&lt;VirtualHost *&gt;
    ServerName ****.co.cc
    DocumentRoot ""C:\www\****""
&lt;/VirtualHost&gt;


ofcourse I removed the unnecessary comments and my domains names(private reasons). Oh yeah, and my server is hosted on Windows Server 2008 Standard
",Harry,https://serverfault.com/users/81138,"First off, can you check the log files for errors when you start up Apache?  It might be complaining, and it will give very useful information if it does..

Secondly, are you making similar changes to the SSL side of things?  MOD_SSL is handled via a different config file, and if you're trying to access these sides of things on port 443, you're not going to get all the different sites working.


",Christopher Karel,https://serverfault.com/users/29354,http://serverfault.com/questions/268626,TECHNOLOGY,serverfault.com,0.8888888888888888,0.6666666666666666,0.0,1.0,0.6666666666666666,1.0,0.5555555555555556,0.3333333333333333,0.3333333333333333,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.6666666666666666,0.0,0.6666666666666666,0.8888888888888888,0.3333333333333333,0.8888888888888888,0.8888888888888888,0.5,0.3333333333333333,0.0,0.6666666666666666,1.0,Apache does not allow multiple name based virtual hosts,"Here's the problem I'm facing: I've added multiple virtual hosts(name based) to apache yet still only one is loaded.

For example I have two domains with different contents.
Site1 Domain -> Site1 Content 
Site2 Domain -> Site1 Content aswell..
I've included the httpd-vhosts file in the httpd config file, and I've edited it to match what it asks me to do on their documentation yet still only one folder of contents is served.

Here is my httpd-vhosts file, the httpd file I assume doesn't need posting but if required I shall:

NameVirtualHost *
&lt;Directory ""C:/www/""&gt;
    Options Indexes FollowSymLinks
    AllowOverride None
    Order allow,deny
    Allow from all

&lt;/Directory&gt;
&lt;VirtualHost *&gt;
    ServerName www.*****.com
    DocumentRoot ""C:\www*****""
&lt;/VirtualHost&gt;

&lt;VirtualHost *&gt;
    ServerName ****.co.cc
    DocumentRoot ""C:\www\****""
&lt;/VirtualHost&gt;


ofcourse I removed the unnecessary comments and my domains names(private reasons). Oh yeah, and my server is hosted on Windows Server 2008 Standard
","First off, can you check the log files for errors when you start up Apache?  It might be complaining, and it will give very useful information if it does..

Secondly, are you making similar changes to the SSL side of things?  MOD_SSL is handled via a different config file, and if you're trying to access these sides of things on port 443, you're not going to get all the different sites working.


"
6013,6013,9539,Is there a way to read the columns in a shapefile / layer without converting it first to an MDB file?,"My shapefile has a number of fields, like roadname, and street number.  Is there a way to get at these without converting the shapefile first into a featureclass (mdb)?  Sometimes the conversion is a time consuming operation.

I'm using ArcEngine 10 C# with VS2010
",patrick,https://gis.stackexchange.com/users/733,"Yes, a shapefile in this context is a feature class just like any other feature class, regardless where it resides, be it folder-based (shapefiles), geodatabase or SDE workspace. There is no need for any conversion.

Just open the shapefile feature class from the workspace and access the Fields property on the shapefile table. If you need to query for the actual data, you can use (for example) the IFeatureClass.Search method.
",Petr Krebs,https://gis.stackexchange.com/users/434,http://gis.stackexchange.com/questions/4619/is-there-a-way-to-read-the-columns-in-a-shapefile-layer-without-converting-it,TECHNOLOGY,gis.stackexchange.com,1.0,1.0,0.0,0.6666666666666666,0.3333333333333333,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.6666666666666666,0.0,0.3333333333333333,0.8888888888888888,Is there a way to read a column in the ShapeFile / layer without first converting it to an mdb file?,"My ShapeFile has many fields, such as roadname and street number. Is there a way to implement these features without first converting shapefiles to feature classes (MDBs)? Sometimes conversion is a time-consuming operation.","Yes, a shapefile in this context is a feature class just like any other feature class, regardless where it resides, be it folder-based (shapefiles), geodatabase or SDE workspace. There is no need for any conversion.

Just open the shapefile feature class from the workspace and access the Fields property on the shapefile table. If you need to query for the actual data, you can use (for example) the IFeatureClass.Search method.
"
2019,2019,3219,Why does Wizards of the Coast print terrible MTG cards?,"I understand that there needs to be a wide variety of power levels in Magic: The Gathering. Even bad cards will see play in limited formats, some because they fill a specific niche (flying removal, fat colorless flyer, providing a counter to certain decks), and others because those decks can't afford to be too picky. However, some cards are just unforgivably terrible. I'm talking about cards that you would only run in sealed if you had absolutely no other options:

Mindless Null: Black 2/2 for 3 with a big disadvantage

Defensive Stance: literally does nothing in exchange for you getting card disadvantage 

Merfolk of the Depths: Would still be bad if it only costed 5...

Archangel's Light: 8 mana just to gain some life and put cheap cards back into your deck. And it's a mythic rare....

There are many more examples, but I think these best illustrate my case. Obviously I'd rather have these cards in the game than not have them at all, but I feel like Wizards of the Coast could have made Magic a more enjoyable game just by keeping the flavor and making all of these cards a tiny bit better...yet they didn't. Why?
",Gordon Gustafson,https://boardgames.stackexchange.com/users/191,"Unforseen interaction. I have looked at the comments on gatherer for each of your examples and have come up with specific instances where they would interact positively.

Defensive stance seems to work pretty well with:
Aura Gnarlid
It could be useful against weenie infect/wither/deathtouch creatures

Mindless Null: is immune to lure/forced blocking and at the same cost as scathe zombies.

Merfolk of the Depth: Suprise blocker that can trigger your evolve cards.

Archangel's light: I can see this really pissing off someone playing a mill deck. It would also combo decent with threshold cards.
",Colin D,https://boardgames.stackexchange.com/users/3128,http://boardgames.stackexchange.com/questions/11473/why-does-wizards-of-the-coast-print-terrible-mtg-cards,CULTURE,boardgames.stackexchange.com,0.8888888888888888,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.6666666666666666,0.5555555555555556,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.7333333333333333,0.0,0.0,1.0,0.8888888888888888,Why do wizards along the coast print bad MTG cards?,"I understand that there needs to be a wide variety of power levels in Magic: The Gathering. Even bad cards will see play in limited formats, some because they fill a specific niche (flying removal, fat colorless flyer, providing a counter to certain decks), and others because those decks can't afford to be too picky. However, some cards are just unforgivably terrible. I'm talking about cards that you would only run in sealed if you had absolutely no other options:

Mindless Null: Black 2/2 for 3 with a big disadvantage

Defensive Stance: literally does nothing in exchange for you getting card disadvantage 

Merfolk of the Depths: Would still be bad if it only costed 5...

Archangel's Light: 8 mana just to gain some life and put cheap cards back into your deck. And it's a mythic rare....

There are many more examples, but I think these best illustrate my case. Obviously I'd rather have these cards in the game than not have them at all, but I feel like Wizards of the Coast could have made Magic a more enjoyable game just by keeping the flavor and making all of these cards a tiny bit better...yet they didn't. Why?
","Unforseen interaction. I have looked at the comments on gatherer for each of your examples and have come up with specific instances where they would interact positively.

Defensive stance seems to work pretty well with:
Aura Gnarlid
It could be useful against weenie infect/wither/deathtouch creatures

Mindless Null: is immune to lure/forced blocking and at the same cost as scathe zombies.

Merfolk of the Depth: Suprise blocker that can trigger your evolve cards.

Archangel's light: I can see this really pissing off someone playing a mill deck. It would also combo decent with threshold cards.
"
413,413,643,Is this formula in predicate logic a tautology?,"$\left(\forall x \cdot p(X) \Rightarrow q(X)\right) \wedge p(Y) \Rightarrow q(Y)$

At first glance this seems like a tautlogy and that's what my notes say. But an interpretation where $p$ is always true and $q$ is always false seems to be a counterexample.

Can someone confirm this or show me where I've gone wrong? 

Thanks.
",mmgro27,https://math.stackexchange.com/users/213003,"It is valid; after restoring the parentheses for better readibility, we have :


  $(∀x[p(x) \to q(x)] ∧ p(y)) \to q(y)$.


Proof

1) $∀x[p(x) \to q(x)] ∧ p(y)$ --- assumed

2) $∀x[p(x) \to q(x)]$ --- from 1) by b$\land$-elimination

3) $p(y)$ --- from 1) by b$\land$-elimination

4) $p(y) \to q(y)$ --- from 2) by $\forall$-elimination

5) $q(y)$ --- from 3) and 4) by $\to$-elimination


  6) $(∀x[p(x) \to q(x)] ∧ p(y)) \to q(y)$ --- from 1) and 5) by $\to$-introduction.

",Mauro ALLEGRANZA,https://math.stackexchange.com/users/108274,http://math.stackexchange.com/questions/1153095/is-this-formula-in-predicate-logic-a-tautology,SCIENCE,math.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.6666666666666666,0.0,1.0,1.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.3333333333333333,0.3333333333333333,0.6666666666666666,1.0,Is this formula tautology in predicate logic?,"$\left(\forall x \cdot p(X) \Rightarrow q(X)\right) \wedge p(Y) \Rightarrow q(Y)$

At first glance this seems like a tautlogy and that's what my notes say. But an interpretation where $p$ is always true and $q$ is always false seems to be a counterexample.

Can someone confirm this or show me where I've gone wrong? 

Thanks.
","It is valid; after restoring the parentheses for better readibility, we have :


  $(∀x[p(x) \to q(x)] ∧ p(y)) \to q(y)$.


Proof

1) $∀x[p(x) \to q(x)] ∧ p(y)$ --- assumed

2) $∀x[p(x) \to q(x)]$ --- from 1) by b$\land$-elimination

3) $p(y)$ --- from 1) by b$\land$-elimination

4) $p(y) \to q(y)$ --- from 2) by $\forall$-elimination

5) $q(y)$ --- from 3) and 4) by $\to$-elimination


  6) $(∀x[p(x) \to q(x)] ∧ p(y)) \to q(y)$ --- from 1) and 5) by $\to$-introduction.

"
6054,6054,9609,"Sharing JavaScript model code between server and client, is this approach valid?","I'm beginning learning Node.js and Backbone. I'd like to share some code between the server and the client (related to [1] and [2]). More in deep:


Share defaults values for a model. Defaults are used to populate forms (client-side), while they are enforced server-side
Share validation rules in order to be DRY and perform client/server validation
Share instance methods


So my idea is to use a factory object to encapsulate common code (defaults, validation rules, public instance methods) and adapt the factory object based on the environment (Node.js or AMD module).

This code is quick&amp;dirty and may not work. Is this a good approach or just a waste of time?

(function (factory) {
    if (typeof exports === 'object') { // Node.js
        var config    = require('../config/config.json'),
            Sequelize = require('sequelize'),
                    _ = require('underscore');

        var User = {
            receiveSms: {
                type: Sequelize.BOOLEAN, allowNull: false
            },
            receiveNewsletter: {
                type: Sequelize.BOOLEAN, allowNull: false
            }
        };

        // Add defaultValue for each returned by 
        _.each(factory.defaults, function (value, key) {
            if(_.has(User, key)) {
                User[key].defaultValue = value;
            }
        });

        module.exports = function () {
            (new Sequelize(config.database, config.username, config.password))
                .define('User', User);
        };
    } else if (typeof define === 'function' &amp;&amp; define.amd) { // AMD
        define(['backbone', 'uderscore'], function (Backbone, _) {
            return Backbone.Model.extend(factory);
        });
    }
}(function () {
    return { // To be adapted
        defaults: {
            receiveSms: false,
            receiveNewsletter: true
        }
    }
}));

",gremo,https://stackoverflow.com/users/220180,"Personally, I would steer away from requirejs as it requires you to rewrite your modules to fit their spec, which will eventually become defunct as the Ecmascript standard evolves. 

For the time being, I would advise looking into the 'gulp' streaming build system. Using it, you'll find it extremely easy to pipe your shared js scripts into a publicly accessible directory, which can then be loaded from the client-side. A common technique for converting node js modules into browser scripts is using 'browserify' - magic! 

Process: gulp.src > gulp-browserify > gulp.dest > ??? > Profit. 

Further reading: http://viget.com/extend/gulp-browserify-starter-faq
",Vix,https://stackoverflow.com/users/4216053,http://stackoverflow.com/questions/14789183/sharing-javascript-model-code-between-server-and-client-is-this-approach-valid,STACKOVERFLOW,stackoverflow.com,1.0,0.4444444444444444,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.8888888888888888,1.0,0.7777777777777778,1.0,1.0,0.9333333333333332,0.6666666666666666,0.3333333333333333,0.6666666666666666,1.0,Is it effective to share JavaScript model code between the server and the client?,"I'm beginning learning Node.js and Backbone. I'd like to share some code between the server and the client (related to [1] and [2]). More in deep:


Share defaults values for a model. Defaults are used to populate forms (client-side), while they are enforced server-side
Share validation rules in order to be DRY and perform client/server validation
Share instance methods


So my idea is to use a factory object to encapsulate common code (defaults, validation rules, public instance methods) and adapt the factory object based on the environment (Node.js or AMD module).

This code is quick&amp;dirty and may not work. Is this a good approach or just a waste of time?

(function (factory) {
    if (typeof exports === 'object') { // Node.js
        var config    = require('../config/config.json'),
            Sequelize = require('sequelize'),
                    _ = require('underscore');

        var User = {
            receiveSms: {
                type: Sequelize.BOOLEAN, allowNull: false
            },
            receiveNewsletter: {
                type: Sequelize.BOOLEAN, allowNull: false
            }
        };

        // Add defaultValue for each returned by 
        _.each(factory.defaults, function (value, key) {
            if(_.has(User, key)) {
                User[key].defaultValue = value;
            }
        });

        module.exports = function () {
            (new Sequelize(config.database, config.username, config.password))
                .define('User', User);
        };
    } else if (typeof define === 'function' &amp;&amp; define.amd) { // AMD
        define(['backbone', 'uderscore'], function (Backbone, _) {
            return Backbone.Model.extend(factory);
        });
    }
}(function () {
    return { // To be adapted
        defaults: {
            receiveSms: false,
            receiveNewsletter: true
        }
    }
}));

","Personally, I would steer away from requirejs as it requires you to rewrite your modules to fit their spec, which will eventually become defunct as the Ecmascript standard evolves. 

For the time being, I would advise looking into the 'gulp' streaming build system. Using it, you'll find it extremely easy to pipe your shared js scripts into a publicly accessible directory, which can then be loaded from the client-side. A common technique for converting node js modules into browser scripts is using 'browserify' - magic! 

Process: gulp.src > gulp-browserify > gulp.dest > ??? > Profit. 

Further reading: http://viget.com/extend/gulp-browserify-starter-faq
"
864,864,1372,"Why is MapReduce in CouchDB called ""incremental""?","I am reading the O'Reilly CouchDB book. I am puzzled by the reduce/re-reduce/incremental-MapReduce part on page 64. Too much is left to rhetory in the O'Reilly book with the sentence


  If you're interested in pushing the ede of CouchDB's incremental reduce functionality, have a look at Google's paper on Sawzall, ...


If I understand the word ""incremental"" correctly, it refers to some sort of addition -operation in the B-tree data structure. I cannot yet see why it is somehow special over typical map-reduce, probably not yet understanding it. In CouchDB, it mentions that there is no side-effects with map function - does that hold true with reduce too?

Why is MapReduce in CouchDB is called ""incremental""?

Helper questions


Explain the quote about incremental MapReduce with Sawzall.
Why two terms for the same thing i.e. reduction? Reduce and re-reduce?


References


A Google paper about Sawzall.
Introduction to CouchDB views in the CouchDB wiki and a lot of blurry blog references.
CouchDB O'Reilly book

",hhh,https://stackoverflow.com/users/164148,"Just to add slightly to what user1087981 said, the reduce functionality is incremental because of the way the reduce process is performed by CouchDB.

CouchDB uses the B-Tree that it creates from the view function, and in essence it performs the reduce calculations in clumps of values.  Here's a very simple mockup of a B-Tree from the O'Reilly Guide showing the leaf nodes for the example in the section you quoted from.



So, why is this incremental?  Well, the final reduce is only performed at query time and all the reduce calculations are stored in the B-Tree view index.  So, let's say that you add a new value to your DB that is another ""fr"" value.  The calculations for the 1st, 2nd and 4th nodes above don't need to be redone.  The new ""fr"" value is added, and the reduce function is re-calculated only for that 3rd leaf node.

Then at query time the final (rereduce=true) calculation is performed on the indexed values, and the final value returned.  You can see that this incremental nature of reduce allows the time taken to recalculate relative only to the new values being added, not to the size of the existing data set.

Having no side-effects is another important part of this process.  If, for example, your reduce functions relied on some other state being maintained as you walked through all the values, then that might work for the very first run, but then when a new value is added and an incremental reduce calculation is made it wouldn't have that same state available to it - and so it would fail to result in the correct result.  This is why reduce functions need to be side-effect free, or as user1087981 puts it ""referentially transparent""
",smathy,https://stackoverflow.com/users/152786,http://stackoverflow.com/questions/11236676/why-is-mapreduce-in-couchdb-called-incremental,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.6666666666666666,0.0,0.3333333333333333,1.0,1.0,0.4444444444444444,0.3333333333333333,0.6666666666666666,0.0,0.0,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,0.8888888888888888,0.8666666666666666,0.0,0.3333333333333333,1.0,0.7777777777777778,"Why is MapReduce in CouchDB called ""incremental""?","I am reading the O'Reilly CouchDB book. I am puzzled by the reduce/re-reduce/incremental-MapReduce part on page 64. Too much is left to rhetory in the O'Reilly book with the sentence


  If you're interested in pushing the ede of CouchDB's incremental reduce functionality, have a look at Google's paper on Sawzall, ...


If I understand the word ""incremental"" correctly, it refers to some sort of addition -operation in the B-tree data structure. I cannot yet see why it is somehow special over typical map-reduce, probably not yet understanding it. In CouchDB, it mentions that there is no side-effects with map function - does that hold true with reduce too?

Why is MapReduce in CouchDB is called ""incremental""?

Helper questions


Explain the quote about incremental MapReduce with Sawzall.
Why two terms for the same thing i.e. reduction? Reduce and re-reduce?


References


A Google paper about Sawzall.
Introduction to CouchDB views in the CouchDB wiki and a lot of blurry blog references.
CouchDB O'Reilly book

","Just to add slightly to what user1087981 said, the reduce functionality is incremental because of the way the reduce process is performed by CouchDB.

CouchDB uses the B-Tree that it creates from the view function, and in essence it performs the reduce calculations in clumps of values.  Here's a very simple mockup of a B-Tree from the O'Reilly Guide showing the leaf nodes for the example in the section you quoted from.



So, why is this incremental?  Well, the final reduce is only performed at query time and all the reduce calculations are stored in the B-Tree view index.  So, let's say that you add a new value to your DB that is another ""fr"" value.  The calculations for the 1st, 2nd and 4th nodes above don't need to be redone.  The new ""fr"" value is added, and the reduce function is re-calculated only for that 3rd leaf node.

Then at query time the final (rereduce=true) calculation is performed on the indexed values, and the final value returned.  You can see that this incremental nature of reduce allows the time taken to recalculate relative only to the new values being added, not to the size of the existing data set.

Having no side-effects is another important part of this process.  If, for example, your reduce functions relied on some other state being maintained as you walked through all the values, then that might work for the very first run, but then when a new value is added and an incremental reduce calculation is made it wouldn't have that same state available to it - and so it would fail to result in the correct result.  This is why reduce functions need to be side-effect free, or as user1087981 puts it ""referentially transparent""
"
4550,4550,7209,How do I reference (what is the syntax I have to use) to get the data of my Profile2 custom fields?,"I have used the Profile2 module (D7) and created some custom fields for my users. One of those fields (for example) is ""field_company"" with the label ""Company.""

Now I am using a computed field (Company) on a content type (Games). When user creates a Game, I want my computed field Company to be computed/populated automatically, based on the ""field_company"" field I have set in my profile2. 

I am trying to find how to get that information. This is as far I got, so far, but it doesn't work. 

$entity_field[0]['value'] = """";
$name=$profile2-&gt;field_onoma[LANGUAGE_NONE][0]['value']; 
$entity_field[0]['value'] = $name;

",Achilles,https://drupal.stackexchange.com/users/4296,"You should use the field_view_field() function. Have a look at the follwing page for more information:
http://coder1.com/articles/printing-or-rendering-node-field-or-profile2-field-drupal-7 
",Lance,https://drupal.stackexchange.com/users/2280,http://drupal.stackexchange.com/questions/16582/how-do-i-reference-what-is-the-syntax-i-have-to-use-to-get-the-data-of-my-prof,TECHNOLOGY,drupal.stackexchange.com,1.0,0.6666666666666666,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,1.0,How do I reference (what syntax do I need) to get the data for the profile2 custom field?,"I have used the Profile2 module (D7) and created some custom fields for my users. One of those fields (for example) is ""field_company"" with the label ""Company.""

Now I am using a computed field (Company) on a content type (Games). When user creates a Game, I want my computed field Company to be computed/populated automatically, based on the ""field_company"" field I have set in my profile2. 

I am trying to find how to get that information. This is as far I got, so far, but it doesn't work. 

$entity_field[0]['value'] = """";
$name=$profile2-&gt;field_onoma[LANGUAGE_NONE][0]['value']; 
$entity_field[0]['value'] = $name;

","You should use the field? View? Field() function. For more information, see the following pages:"
1337,1337,2108,Integrating expressions with several terms and delta functions,"So I want to integrate an expression that looks something like this:

Integrate[f[x]+DiracDelta[x-y]g[x],{x,-Infinity,Infinity}]


With some more terms added with delta functions after g[x]. Even after expanding and simplifying Mathematica won't break up the expression and evaluate the delta function, it just leaves it in exactly the form I have above. How do I make Mathematica evaluate the integral term by term?

Cheers :)
",Spamuel Needbeef,https://mathematica.stackexchange.com/users/27899,"I would try to see if you can use Distribute for this:

Distribute@
 Integrate[f[x] + DiracDelta[x - y] g[x], {x, -Infinity, Infinity}]



  


Unlike Map, Distribute is especially (though not exclusively) intended for use with sums.
",Jens,https://mathematica.stackexchange.com/users/245,http://mathematica.stackexchange.com/questions/80343/integrating-expressions-with-several-terms-and-delta-functions,TECHNOLOGY,mathematica.stackexchange.com,0.6666666666666666,0.6666666666666666,0.0,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,0.8333333333333334,0.8,1.0,0.0,1.0,0.6666666666666666,Integral expression of delta function with some terms,"So I want to integrate an expression that looks something like this:

Integrate[f[x]+DiracDelta[x-y]g[x],{x,-Infinity,Infinity}]


With some more terms added with delta functions after g[x]. Even after expanding and simplifying Mathematica won't break up the expression and evaluate the delta function, it just leaves it in exactly the form I have above. How do I make Mathematica evaluate the integral term by term?

Cheers :)
","I would try to see if you can use Distribute for this:

Distribute@
 Integrate[f[x] + DiracDelta[x - y] g[x], {x, -Infinity, Infinity}]



  


Unlike Map, Distribute is especially (though not exclusively) intended for use with sums.
"
5914,5914,9369,up sample and down sample,"Let's say that I have a sampled signal x[n], it is being, in this exact order, up sampled by 2, down sampled by4, up sampled by 4 and down sampled by 2 to produce y[n].

It seems to me that it should be pretty self evident that since we up sampled the signal by 2 and down sampled it by 2, then up sampled it by 4 and down sampled by 4, I should just get the original x[n] back. 

Am I right?

So the real question is, can the various up/down sampling pieces be readily swapped?
",D.Zou,https://dsp.stackexchange.com/users/11151,"You will only get an approximation to your original signal.  By the time you have upsampled by 2 and downsampled by 4, you have an overall downsample of 2.  That means you have thrown away half your original data.  No amount of upsampling will perfectly re-construct that lost data.
",Simon B,https://dsp.stackexchange.com/users/11040,http://dsp.stackexchange.com/questions/18737/up-sample-and-down-sample,TECHNOLOGY,dsp.stackexchange.com,0.6666666666666666,0.3333333333333333,0.0,0.0,1.0,1.0,0.6666666666666666,0.6666666666666666,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.6666666666666666,1.0,0.8,0.0,0.0,1.0,1.0,Sample under sampling,"Let's say that I have a sampled signal x[n], it is being, in this exact order, up sampled by 2, down sampled by4, up sampled by 4 and down sampled by 2 to produce y[n].

It seems to me that it should be pretty self evident that since we up sampled the signal by 2 and down sampled it by 2, then up sampled it by 4 and down sampled by 4, I should just get the original x[n] back. 

Am I right?

So the real question is, can the various up/down sampling pieces be readily swapped?
","You will only get an approximation of your original signal. When you upsample 2 and downsample 4, your overall downsample is 2. That means you've already thrown away half of the raw data. No amount of up sampling can perfectly reconstruct the lost data."
3656,3656,5831,Wordpress and Apache 2.4 installation troubles: Cannot Serve Directory,"I'm having a devil of a time getting Wordpress going on my webhost. When I try to access my virtualhost, I get a ""403 Forbidden You don't have permission to access / on this server."" error and a ""Cannot serve directory..."" error in my error_log (see below). Why am I getting ""403 Forbidden""? I am missing something, hopefully obvious to you (not to me, naturally). Thanks for any help.

I installed a minimal install of Fedora 20 (ie, no Gnome/KDE but plenty of php packages [710] so it's not that skinny). Then I installed Apache, and followed up with the Wordpress install as per http://codex.wordpress.org/Installing_WordPress#Famous_5-Minute_Install . Since then, I have been hacking around in /etc/httpd trying to find the issue.

I have version 2.4 of Apache, php 5.5.18, Fedora 20, and Wordpress 4.0-1.

I have created my Virtualhost in Apache, and here is the error in my error log (all on one line):

[Sat Nov 15 20:38:16.067198 2014] [autoindex:error] [pid 6745] 
[client XX.XX.XX.XX:48419] AH01276: Cannot serve directory /usr/share/wordpress/: 
No matching DirectoryIndex (index.html) found, and server-generated directory
index forbidden by Options directive


I have been hacking and hacking the httpd.conf file and my Virtual host's file (found in /etc/httpd/conf.d/myhostname.conf) to no avail. Any ideas? I include a (shortened) copy of my httpd.conf and my virtual host's conf file. First, the virtual host:

&lt;VirtualHost *:80&gt;
        ServerName virtual1.myhost.com
        ServerAlias virtual1
        DocumentRoot /usr/share/wordpress
        ErrorLog logs/virtual1_error
        CustomLog logs/virtual1_access common
&lt;/VirtualHost&gt;

&lt;Directory /&gt;
  Require all granted
  AllowOverride None
  &lt;IfModule mod_rewrite.so&gt;
        RewriteEngine On
        RewriteBase /
        RewriteRule ^index\.php$ - [L]
        RewriteCond %{REQUEST_FILENAME} !-f
        RewriteCond %{REQUEST_FILENAME} !-d
        RewriteRule . /index.php [L]
  &lt;/IfModule&gt;
&lt;/Directory&gt;

&lt;Directory /usr/share/wordpress&gt;
  Require all granted
  &lt;IfModule mod_rewrite.c&gt;
        RewriteEngine On
        RewriteBase /
        RewriteRule ^index\.php$ - [L]
        RewriteCond %{REQUEST_FILENAME} !-f
        RewriteCond %{REQUEST_FILENAME} !-d
        RewriteRule . /index.php [L]
  &lt;/IfModule&gt;
  Options FollowSymLinks
  AllowOverride None
#  &lt;IfModule mod_authz_core.c&gt;
#    # Apache 2.4
#    Require local
#  &lt;/IfModule&gt;
#  &lt;IfModule !mod_authz_core.c&gt;
#    # Apache 2.4
#    Require all granted
#    AllowOverride None
# &lt;/IfModule&gt;
&lt;/Directory&gt;

&lt;Directory /usr/share/wordpress/wp-content/plugins/akismet&gt;
  &lt;FilesMatch ""\.(php|txt)$""&gt;
    Require all granted
    AllowOverride None
  &lt;/FilesMatch&gt;
&lt;/Directory&gt;


Now, the httpd.conf:

#
ServerRoot ""/etc/httpd""

Listen 80
Include conf.modules.d/*.conf
User apache
Group apache
ServerAdmin root@localhost
&lt;Directory /&gt;
    AllowOverride none
    Require all granted
&lt;/Directory&gt;
DocumentRoot ""/var/www/html""
&lt;Directory ""/var/www""&gt;
    AllowOverride None
    # Allow open access:
    Require all granted
&lt;/Directory&gt;
&lt;Directory ""/var/www/html""&gt;
    Require all granted
    Options Indexes FollowSymLinks
    AllowOverride None
&lt;/Directory&gt;
&lt;IfModule dir_module&gt;
    DirectoryIndex index.html
&lt;/IfModule&gt;
#
&lt;Files "".ht*""&gt;
    Require all denied
&lt;/Files&gt;
ErrorLog ""logs/error_log""
LogLevel warn
&lt;IfModule log_config_module&gt;
    LogFormat ""%h %l %u %t \""%r\"" %&gt;s %b \""%{Referer}i\"" \""%{User-Agent}i\"""" combined
    LogFormat ""%h %l %u %t \""%r\"" %&gt;s %b"" common
    &lt;IfModule logio_module&gt;
      # You need to enable mod_logio.c to use %I and %O
      LogFormat ""%h %l %u %t \""%r\"" %&gt;s %b \""%{Referer}i\"" \""%{User-Agent}i\"" %I %O"" combinedio
    &lt;/IfModule&gt;
    CustomLog ""logs/access_log"" combined
&lt;/IfModule&gt;

&lt;IfModule alias_module&gt;
    ScriptAlias /cgi-bin/ ""/var/www/cgi-bin/""
&lt;/IfModule&gt;
&lt;Directory ""/var/www/cgi-bin""&gt;
    AllowOverride None
    Options None
    Require all granted
&lt;/Directory&gt;
&lt;IfModule mime_module&gt;
    TypesConfig /etc/mime.types
    AddType application/x-compress .Z
    AddType application/x-gzip .gz .tgz
    AddType text/html .shtml
    AddOutputFilter INCLUDES .shtml
&lt;/IfModule&gt;
AddDefaultCharset UTF-8

&lt;IfModule mime_magic_module&gt;
    MIMEMagicFile conf/magic
&lt;/IfModule&gt;
EnableSendfile on

NameVirtualHost *:80
&lt;VirtualHost *:80&gt;
    ServerName www.myhost.com
    ServerAlias www
    ServerAdmin root@myhost.com
    DocumentRoot /var/www/html
    ErrorLog logs/error_log
    CustomLog logs/access_log common
&lt;/VirtualHost&gt;

IncludeOptional conf.d/*.conf

",Mike S,https://serverfault.com/users/63931,"It looks like you have forgotten DirectoryIndex.

This should be added to the &lt;VirtualHost&gt; serving WordPress.

DirectoryIndex index.php

",Michael Hampton,https://serverfault.com/users/126632,http://serverfault.com/questions/644639,TECHNOLOGY,serverfault.com,1.0,0.3333333333333333,0.0,1.0,1.0,0.0,1.0,1.0,1.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,1.0,1.0,WordPress and Apache 2.4 installation problem: unable to provide directory,"I'm having a devil of a time getting Wordpress going on my webhost. When I try to access my virtualhost, I get a ""403 Forbidden You don't have permission to access / on this server."" error and a ""Cannot serve directory..."" error in my error_log (see below). Why am I getting ""403 Forbidden""? I am missing something, hopefully obvious to you (not to me, naturally). Thanks for any help.

I installed a minimal install of Fedora 20 (ie, no Gnome/KDE but plenty of php packages [710] so it's not that skinny). Then I installed Apache, and followed up with the Wordpress install as per http://codex.wordpress.org/Installing_WordPress#Famous_5-Minute_Install . Since then, I have been hacking around in /etc/httpd trying to find the issue.

I have version 2.4 of Apache, php 5.5.18, Fedora 20, and Wordpress 4.0-1.

I have created my Virtualhost in Apache, and here is the error in my error log (all on one line):

[Sat Nov 15 20:38:16.067198 2014] [autoindex:error] [pid 6745] 
[client XX.XX.XX.XX:48419] AH01276: Cannot serve directory /usr/share/wordpress/: 
No matching DirectoryIndex (index.html) found, and server-generated directory
index forbidden by Options directive


I have been hacking and hacking the httpd.conf file and my Virtual host's file (found in /etc/httpd/conf.d/myhostname.conf) to no avail. Any ideas? I include a (shortened) copy of my httpd.conf and my virtual host's conf file. First, the virtual host:

&lt;VirtualHost *:80&gt;
        ServerName virtual1.myhost.com
        ServerAlias virtual1
        DocumentRoot /usr/share/wordpress
        ErrorLog logs/virtual1_error
        CustomLog logs/virtual1_access common
&lt;/VirtualHost&gt;

&lt;Directory /&gt;
  Require all granted
  AllowOverride None
  &lt;IfModule mod_rewrite.so&gt;
        RewriteEngine On
        RewriteBase /
        RewriteRule ^index\.php$ - [L]
        RewriteCond %{REQUEST_FILENAME} !-f
        RewriteCond %{REQUEST_FILENAME} !-d
        RewriteRule . /index.php [L]
  &lt;/IfModule&gt;
&lt;/Directory&gt;

&lt;Directory /usr/share/wordpress&gt;
  Require all granted
  &lt;IfModule mod_rewrite.c&gt;
        RewriteEngine On
        RewriteBase /
        RewriteRule ^index\.php$ - [L]
        RewriteCond %{REQUEST_FILENAME} !-f
        RewriteCond %{REQUEST_FILENAME} !-d
        RewriteRule . /index.php [L]
  &lt;/IfModule&gt;
  Options FollowSymLinks
  AllowOverride None
#  &lt;IfModule mod_authz_core.c&gt;
#    # Apache 2.4
#    Require local
#  &lt;/IfModule&gt;
#  &lt;IfModule !mod_authz_core.c&gt;
#    # Apache 2.4
#    Require all granted
#    AllowOverride None
# &lt;/IfModule&gt;
&lt;/Directory&gt;

&lt;Directory /usr/share/wordpress/wp-content/plugins/akismet&gt;
  &lt;FilesMatch ""\.(php|txt)$""&gt;
    Require all granted
    AllowOverride None
  &lt;/FilesMatch&gt;
&lt;/Directory&gt;


Now, the httpd.conf:

#
ServerRoot ""/etc/httpd""

Listen 80
Include conf.modules.d/*.conf
User apache
Group apache
ServerAdmin root@localhost
&lt;Directory /&gt;
    AllowOverride none
    Require all granted
&lt;/Directory&gt;
DocumentRoot ""/var/www/html""
&lt;Directory ""/var/www""&gt;
    AllowOverride None
    # Allow open access:
    Require all granted
&lt;/Directory&gt;
&lt;Directory ""/var/www/html""&gt;
    Require all granted
    Options Indexes FollowSymLinks
    AllowOverride None
&lt;/Directory&gt;
&lt;IfModule dir_module&gt;
    DirectoryIndex index.html
&lt;/IfModule&gt;
#
&lt;Files "".ht*""&gt;
    Require all denied
&lt;/Files&gt;
ErrorLog ""logs/error_log""
LogLevel warn
&lt;IfModule log_config_module&gt;
    LogFormat ""%h %l %u %t \""%r\"" %&gt;s %b \""%{Referer}i\"" \""%{User-Agent}i\"""" combined
    LogFormat ""%h %l %u %t \""%r\"" %&gt;s %b"" common
    &lt;IfModule logio_module&gt;
      # You need to enable mod_logio.c to use %I and %O
      LogFormat ""%h %l %u %t \""%r\"" %&gt;s %b \""%{Referer}i\"" \""%{User-Agent}i\"" %I %O"" combinedio
    &lt;/IfModule&gt;
    CustomLog ""logs/access_log"" combined
&lt;/IfModule&gt;

&lt;IfModule alias_module&gt;
    ScriptAlias /cgi-bin/ ""/var/www/cgi-bin/""
&lt;/IfModule&gt;
&lt;Directory ""/var/www/cgi-bin""&gt;
    AllowOverride None
    Options None
    Require all granted
&lt;/Directory&gt;
&lt;IfModule mime_module&gt;
    TypesConfig /etc/mime.types
    AddType application/x-compress .Z
    AddType application/x-gzip .gz .tgz
    AddType text/html .shtml
    AddOutputFilter INCLUDES .shtml
&lt;/IfModule&gt;
AddDefaultCharset UTF-8

&lt;IfModule mime_magic_module&gt;
    MIMEMagicFile conf/magic
&lt;/IfModule&gt;
EnableSendfile on

NameVirtualHost *:80
&lt;VirtualHost *:80&gt;
    ServerName www.myhost.com
    ServerAlias www
    ServerAdmin root@myhost.com
    DocumentRoot /var/www/html
    ErrorLog logs/error_log
    CustomLog logs/access_log common
&lt;/VirtualHost&gt;

IncludeOptional conf.d/*.conf

","It looks like you have forgotten DirectoryIndex.

This should be added to the &lt;VirtualHost&gt; serving WordPress.

DirectoryIndex index.php

"
1215,1215,1908,What Defines Opponent Behaviour in 'Quick Battle'?,"When I play the 'quick battle' offline mode of Soul Calibur V, I get the impression that I'm fighting real player's characters being controlled by the game's AI, based on the character names, and costumes.  Some of these characters behave wildly different from one another, to the point that it almost feels like I'm fighting actual human players (impossible, as I don't have Xbox Live Gold). Some of these characters are much more 'skilled' than others, as well.

What defines the behaviour of someone's character in quick-play mode?  Does the game 'watch' them play, and then try to use the same combos the player used in their games?
",GnomeSlice,https://gaming.stackexchange.com/users/3114,"I doubt that the computer copies players from elsewhere. Maybe the A.I. is varied to the point that it imitates varying types of players.
",Bryce,https://gaming.stackexchange.com/users/20794,http://gaming.stackexchange.com/questions/52979/what-defines-opponent-behaviour-in-quick-battle,CULTURE,gaming.stackexchange.com,1.0,0.8888888888888888,0.0,1.0,1.0,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,1.0,0.7777777777777778,0.4444444444444444,0.7777777777777778,0.8888888888888888,0.6,0.0,0.6666666666666666,0.3333333333333333,0.7777777777777778,"What defines adversary behavior in ""fast combat""?","When I play the ""fast fight"" offline mode of soul caliber V, I get the impression that I am fighting the real player's role, controlled by the game's AI, based on character names and costumes. Some of the characters behave so differently that it almost feels like I'm fighting real human players (impossible, because I don't have Xbox LIVE gold). Some of these characters are also ""more proficient"" than others.","I doubt that the computer copies players from elsewhere. Maybe the A.I. is varied to the point that it imitates varying types of players.
"
2686,2686,4283,House rules to make the cloister less of a game winning tile in Carcassonne?,"In my experience, cloister tiles in Carcassonne are often ""too lucky"". If you draw a cloister tile in the beginning of the game, it will typically still require an investment of quite a bit of ""meeple"" time to obtain the full 9 points, which makes it a fair trade-off. However, after about half of the game, it's relatively likely that you can ""parachute"" a cloister tile in some spot and get 8 or 9 points immediately. This adds a lot of randomness to the game.

What house rules work well to diminish this effect?
",Erik P.,https://boardgames.stackexchange.com/users/30,"Knowing that cloisters can have this effect is half the battle.

Rather than adding a house rule to a very popular game I would advise you to alter your strategy a bit to account for future cloisters that you may not control.

Examples:


Leave a good cloister spot next to an open road that you own.  
When considering placing a tile between two relatively equal spots determine if one or the other creates a better cloister opportunity.
Keep track of how many have been played!  If you get down to 10 tiles left and 4 of them are cloisters, make sure you have the meeples available to use them.  Alternatively, keep your opponent from freeing his meeples from the board.

",Pat Ludwig,https://boardgames.stackexchange.com/users/40,http://boardgames.stackexchange.com/questions/8/house-rules-to-make-the-cloister-less-of-a-game-winning-tile-in-carcassonne,CULTURE,boardgames.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.3333333333333333,0.6666666666666666,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.8888888888888888,"In karkasson, let the cloister be less like the winning tile house rule?","In my experience, Carlsson's cloister tiles are usually ""too lucky."". If you draw a cloister tile at the beginning of the game, it usually still takes quite a lot of time to get a full score of 9, which is a fair trade-off. However, after about half of the game, you are likely to ""parachute"" a cloister tile somewhere and get 8 or 9 points immediately. This adds a lot of randomness to the game.","Knowing that cloisters can have this effect is half the battle.

Rather than adding a house rule to a very popular game I would advise you to alter your strategy a bit to account for future cloisters that you may not control.

Examples:


Leave a good cloister spot next to an open road that you own.  
When considering placing a tile between two relatively equal spots determine if one or the other creates a better cloister opportunity.
Keep track of how many have been played!  If you get down to 10 tiles left and 4 of them are cloisters, make sure you have the meeples available to use them.  Alternatively, keep your opponent from freeing his meeples from the board.

"
1829,1829,2900,How can I open a window on a different monitor?,"With multiple monitors, I have so far been dragging windows manually around. Is there a way to make a window open on a specific screen in a dual-head setup? (Not to be confused with multiple X server displays.)

Something like: SCREEN=2 firefox or open-in-screen 2 firefox.

If it matters, my environment is KDE using the KWin window manager. KWin window rules can only match some properties like title, but I could not find an environment variable as filter.

The secondary display extends the primary screen:

$ xrandr -q
Screen 0: minimum 320 x 200, current 3520 x 1080, maximum 32767 x 32767
LVDS1 connected 1600x900+0+0 (normal left inverted right x axis y axis) 382mm x 214mm
   1600x900       60.1*+
   1024x768       60.0  
   800x600        60.3     56.2  
   640x480        59.9  
VGA1 disconnected (normal left inverted right x axis y axis)
HDMI1 connected 1920x1080+1600+0 (normal left inverted right x axis y axis) 477mm x 268mm
   1920x1080      60.0*    50.0     59.9  
   1920x1080i     60.1     50.0     60.0  
   1680x1050      59.9  
   1280x1024      75.0     60.0  
   1440x900       59.9  
   1280x960       60.0  
   1280x720       60.0     50.0     59.9  
   1024x768       75.1     70.1     60.0  
   832x624        74.6  
   800x600        72.2     75.0     60.3     56.2  
   720x576        50.0  
   720x480        60.0     59.9  
   640x480        75.0     72.8     66.7     60.0     59.9  
   720x400        70.1  
DP1 disconnected (normal left inverted right x axis y axis)

",Lekensteyn,https://unix.stackexchange.com/users/8250,"No, you can't do that directly. In the X architecture, the two physical monitors you see are not discernible by applications. You can only work your way around this abstraction, by determining which areas of the visible workspace correspond to which monitor and then place windows at the correct offset.

Sensible toolkits support a -geometry option, which allows your application to request being placed at a specific position. If you don't have this option available, you can use wmctrl if you have an EWMH/NetWM compatible X Window Manager to move and resize already existing windows (see wmctrl (1), you need options -r and -e). I use devilspie to force placement of some windows and of course your window manager of choice may have its own facility to force window placement.

devilspie allows to apply certain actions on X windows and can use X window properties to discern different windows and applications. The key rule for you would be geometry ""&lt;width&gt;x&lt;height&gt;+&lt;xoffset&gt;+&lt;yoffset&gt;"".

Yet, you always need to do the calculations of when and where another physical monitor begins yourself. But this is not too hard and xrandr does tell you how and where it uses monitors in the form of ""&lt;width&gt;x&lt;height&gt;+&lt;xoffset&gt;+&lt;yoffset&gt; on each line staring with an output name.

There is not the foolproof-it-will-just-work way, because implementations may (and do!) vary. wmctrl usually works on the window title to identify the target. devilspie can also refer to its class, yet, I am not aware of any toolkit that lets you specify a X windows class but not its geometry.

Of course you could always start two xephyr instances and make one fill your left screen and the other your right screen and then address screens via the DISPLAY environment variable, but this solution has other downsides.

In theory, the authority to govern window placement is the window manager. Consequently, if you want stuff your window manager can't to, it will be hacky and it's also the reason why there is no generic way to accomplish this.

Yet, if your concrete use case is your android emulator ... which is very different from asking for the option to specify SCREEN=n fooapp on the shell, then devilspie may be what you are looking for. Hint: I found it's best to identify applications by their window class.
",Bananguin,https://unix.stackexchange.com/users/19575,http://unix.stackexchange.com/questions/106793/how-can-i-open-a-window-on-a-different-monitor,TECHNOLOGY,unix.stackexchange.com,1.0,0.7777777777777778,0.0,1.0,0.6666666666666666,1.0,0.5555555555555556,0.5555555555555556,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.8888888888888888,1.0,0.7777777777777778,1.0,1.0,0.9333333333333332,1.0,0.0,0.6666666666666666,1.0,How to open windows on different monitors?,"With multiple monitors, I have so far been dragging windows manually around. Is there a way to make a window open on a specific screen in a dual-head setup? (Not to be confused with multiple X server displays.)

Something like: SCREEN=2 firefox or open-in-screen 2 firefox.

If it matters, my environment is KDE using the KWin window manager. KWin window rules can only match some properties like title, but I could not find an environment variable as filter.

The secondary display extends the primary screen:

$ xrandr -q
Screen 0: minimum 320 x 200, current 3520 x 1080, maximum 32767 x 32767
LVDS1 connected 1600x900+0+0 (normal left inverted right x axis y axis) 382mm x 214mm
   1600x900       60.1*+
   1024x768       60.0  
   800x600        60.3     56.2  
   640x480        59.9  
VGA1 disconnected (normal left inverted right x axis y axis)
HDMI1 connected 1920x1080+1600+0 (normal left inverted right x axis y axis) 477mm x 268mm
   1920x1080      60.0*    50.0     59.9  
   1920x1080i     60.1     50.0     60.0  
   1680x1050      59.9  
   1280x1024      75.0     60.0  
   1440x900       59.9  
   1280x960       60.0  
   1280x720       60.0     50.0     59.9  
   1024x768       75.1     70.1     60.0  
   832x624        74.6  
   800x600        72.2     75.0     60.3     56.2  
   720x576        50.0  
   720x480        60.0     59.9  
   640x480        75.0     72.8     66.7     60.0     59.9  
   720x400        70.1  
DP1 disconnected (normal left inverted right x axis y axis)

","No, you can't do that directly. In the X architecture, the two physical monitors you see are not discernible by applications. You can only work your way around this abstraction, by determining which areas of the visible workspace correspond to which monitor and then place windows at the correct offset.

Sensible toolkits support a -geometry option, which allows your application to request being placed at a specific position. If you don't have this option available, you can use wmctrl if you have an EWMH/NetWM compatible X Window Manager to move and resize already existing windows (see wmctrl (1), you need options -r and -e). I use devilspie to force placement of some windows and of course your window manager of choice may have its own facility to force window placement.

devilspie allows to apply certain actions on X windows and can use X window properties to discern different windows and applications. The key rule for you would be geometry ""&lt;width&gt;x&lt;height&gt;+&lt;xoffset&gt;+&lt;yoffset&gt;"".

Yet, you always need to do the calculations of when and where another physical monitor begins yourself. But this is not too hard and xrandr does tell you how and where it uses monitors in the form of ""&lt;width&gt;x&lt;height&gt;+&lt;xoffset&gt;+&lt;yoffset&gt; on each line staring with an output name.

There is not the foolproof-it-will-just-work way, because implementations may (and do!) vary. wmctrl usually works on the window title to identify the target. devilspie can also refer to its class, yet, I am not aware of any toolkit that lets you specify a X windows class but not its geometry.

Of course you could always start two xephyr instances and make one fill your left screen and the other your right screen and then address screens via the DISPLAY environment variable, but this solution has other downsides.

In theory, the authority to govern window placement is the window manager. Consequently, if you want stuff your window manager can't to, it will be hacky and it's also the reason why there is no generic way to accomplish this.

Yet, if your concrete use case is your android emulator ... which is very different from asking for the option to specify SCREEN=n fooapp on the shell, then devilspie may be what you are looking for. Hint: I found it's best to identify applications by their window class.
"
3882,3882,6185,How can I open a window on a different monitor?,"With multiple monitors, I have so far been dragging windows manually around. Is there a way to make a window open on a specific screen in a dual-head setup? (Not to be confused with multiple X server displays.)

Something like: SCREEN=2 firefox or open-in-screen 2 firefox.

If it matters, my environment is KDE using the KWin window manager. KWin window rules can only match some properties like title, but I could not find an environment variable as filter.

The secondary display extends the primary screen:

$ xrandr -q
Screen 0: minimum 320 x 200, current 3520 x 1080, maximum 32767 x 32767
LVDS1 connected 1600x900+0+0 (normal left inverted right x axis y axis) 382mm x 214mm
   1600x900       60.1*+
   1024x768       60.0  
   800x600        60.3     56.2  
   640x480        59.9  
VGA1 disconnected (normal left inverted right x axis y axis)
HDMI1 connected 1920x1080+1600+0 (normal left inverted right x axis y axis) 477mm x 268mm
   1920x1080      60.0*    50.0     59.9  
   1920x1080i     60.1     50.0     60.0  
   1680x1050      59.9  
   1280x1024      75.0     60.0  
   1440x900       59.9  
   1280x960       60.0  
   1280x720       60.0     50.0     59.9  
   1024x768       75.1     70.1     60.0  
   832x624        74.6  
   800x600        72.2     75.0     60.3     56.2  
   720x576        50.0  
   720x480        60.0     59.9  
   640x480        75.0     72.8     66.7     60.0     59.9  
   720x400        70.1  
DP1 disconnected (normal left inverted right x axis y axis)

",Lekensteyn,https://unix.stackexchange.com/users/8250,"Had a similar problem. Found the following:


Right click on the window titlebar and select ""More Actions"" -> ""Window Manager Settings"".
There choose ""Focus"" in the column to the left. 
Toggle option ""Active screen follows mouse"".


If no other defaults are specified, windows appear on the currently active screen.
With the procedure described above, mouse position defines this active screen.
",BiberBb,https://unix.stackexchange.com/users/66162,http://unix.stackexchange.com/questions/106793/how-can-i-open-a-window-on-a-different-monitor,TECHNOLOGY,unix.stackexchange.com,1.0,0.5555555555555556,0.0,0.0,1.0,0.5,0.5555555555555556,0.4444444444444444,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.3333333333333333,0.0,0.0,0.7777777777777778,0.7777777777777778,0.6666666666666666,0.8888888888888888,1.0,0.9,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.7777777777777778,How to open windows on different monitors?,"With multiple monitors, I have so far been dragging windows manually around. Is there a way to make a window open on a specific screen in a dual-head setup? (Not to be confused with multiple X server displays.)

Something like: SCREEN=2 firefox or open-in-screen 2 firefox.

If it matters, my environment is KDE using the KWin window manager. KWin window rules can only match some properties like title, but I could not find an environment variable as filter.

The secondary display extends the primary screen:

$ xrandr -q
Screen 0: minimum 320 x 200, current 3520 x 1080, maximum 32767 x 32767
LVDS1 connected 1600x900+0+0 (normal left inverted right x axis y axis) 382mm x 214mm
   1600x900       60.1*+
   1024x768       60.0  
   800x600        60.3     56.2  
   640x480        59.9  
VGA1 disconnected (normal left inverted right x axis y axis)
HDMI1 connected 1920x1080+1600+0 (normal left inverted right x axis y axis) 477mm x 268mm
   1920x1080      60.0*    50.0     59.9  
   1920x1080i     60.1     50.0     60.0  
   1680x1050      59.9  
   1280x1024      75.0     60.0  
   1440x900       59.9  
   1280x960       60.0  
   1280x720       60.0     50.0     59.9  
   1024x768       75.1     70.1     60.0  
   832x624        74.6  
   800x600        72.2     75.0     60.3     56.2  
   720x576        50.0  
   720x480        60.0     59.9  
   640x480        75.0     72.8     66.7     60.0     59.9  
   720x400        70.1  
DP1 disconnected (normal left inverted right x axis y axis)

","Had a similar problem. Found the following:


Right click on the window titlebar and select ""More Actions"" -> ""Window Manager Settings"".
There choose ""Focus"" in the column to the left. 
Toggle option ""Active screen follows mouse"".


If no other defaults are specified, windows appear on the currently active screen.
With the procedure described above, mouse position defines this active screen.
"
5345,5345,8487,Why is my fuse board buzzing when I'm using the shower?,"I have used an electric shower for years no problems, but all of a sudden my fuse board started buzzing when I use the shower. I replaced the shower with the same size unit and it still makes a buzzing noise.

I have checked all the wires and they are tight and well connected. I changed the old cartridge fuse for an mcb 40amp fuse, and still it makes a buzzing noise.

Is this a sign that my wylex fuse board needs changing?
",Gerry Cheverton,https://diy.stackexchange.com/users/9251,"It could be a loose connection behind the board. Also, wylex boards used to have a din rail in the board to mount door bell transformers at the end - the rail or door bell transformer could be vibrating.
",parkbench,https://diy.stackexchange.com/users/4049,http://diy.stackexchange.com/questions/20894/why-is-my-fuse-board-buzzing-when-im-using-the-shower,LIFE_ARTS,diy.stackexchange.com,1.0,0.5555555555555556,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.4444444444444444,0.0,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,1.0,1.0,0.9,0.0,0.0,1.0,0.8888888888888888,Why is the fuse panel buzzing when I take a bath?,"I have used an electric shower for years no problems, but all of a sudden my fuse board started buzzing when I use the shower. I replaced the shower with the same size unit and it still makes a buzzing noise.

I have checked all the wires and they are tight and well connected. I changed the old cartridge fuse for an mcb 40amp fuse, and still it makes a buzzing noise.

Is this a sign that my wylex fuse board needs changing?
","The connection at the back of the circuit board may be loose. In addition, wylex boards used to have a doorbell transformer installed on the board at the end of the track or doorbell transformer may be vibrating."
5783,5783,9164,How can I find out what plugins I installed for Nautilus?,"I have, over time, installed a number of Nautilus-related packages. Today I've started having issues with a Nautilus feature.

I don't remember what I've installed now so is it possible to get a list of the Nautilus-related packages what I've installed in the past?
",M R R,https://askubuntu.com/users/181205,"If all what you need is a list of nautilus related packages, you can get it very easily with:

$ dpkg -l | grep nautilus


E.g for me it returns:

ii  gir1.2-nautilus-3.0                                   1:3.10.1-0ubuntu9.2                                 amd64        libraries for nautilus components - gir bindings
ii  libnautilus-extension1a                               1:3.10.1-0ubuntu9.1                                 amd64        libraries for nautilus components - runtime version
ii  nautilus                                              1:3.10.1-0ubuntu9.1                                 amd64        file manager and graphical shell for GNOME
ii  nautilus-data                                         1:3.10.1-0ubuntu9.1                                 all          data files for nautilus
ii  nautilus-open-terminal                                0.20-1                                              amd64        nautilus plugin for opening terminals in arbitrary paths
ii  nautilus-pyextensions                                 3.0-1                                               all          Handler of the Nautilus Python Extensions
ii  nautilus-sendto                                       3.6.1-2ubuntu1                                      amd64        integrates Evolution and Pidgin into the Nautilus file manager
ii  nautilus-sendto-empathy                               3.8.6-0ubuntu9.1                                    amd64        GNOME multi-protocol chat and call client (nautilus-sendto plugin)
ii  nautilus-share                                        0.7.3-1ubuntu5                                      amd64        Nautilus extension to share folder using Samba
ii  python-nautilus                                       1.1-4                                               amd64        Python binding for Nautilus components
ii  seahorse-nautilus                                     3.8.0-0ubuntu2                                      amd64        seahorse plugins and utilities for encryption in GNOME


Trying to guess which ones are plugins or extension is a bit more complex:

dpkg -l | egrep -i 'nautilus.* (extension|plugin)'


This time it returns:

ii  nautilus-open-terminal                                0.20-1                                              amd64        nautilus plugin for opening terminals in arbitrary paths
ii  nautilus-pyextensions                                 3.0-1                                               all          Handler of the Nautilus Python Extensions
ii  nautilus-sendto-empathy                               3.8.6-0ubuntu9.1                                    amd64        GNOME multi-protocol chat and call client (nautilus-sendto plugin)
ii  nautilus-share                                        0.7.3-1ubuntu5                                      amd64        Nautilus extension to share folder using Samba
ii  seahorse-nautilus                                     3.8.0-0ubuntu2                                      amd64        seahorse plugins and utilities for encryption in GNOME

",Sylvain Pineau,https://askubuntu.com/users/32239,http://askubuntu.com/questions/500641/how-can-i-find-out-what-plugins-i-installed-for-nautilus,TECHNOLOGY,askubuntu.com,1.0,1.0,0.0,1.0,1.0,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,1.0,0.7777777777777778,1.0,1.0,1.0,1.0,0.0,0.0,1.0,How can I find the plug-in I installed for Nautilus?,"I have, over time, installed a number of Nautilus-related packages. Today I've started having issues with a Nautilus feature.

I don't remember what I've installed now so is it possible to get a list of the Nautilus-related packages what I've installed in the past?
","If all what you need is a list of nautilus related packages, you can get it very easily with:

$ dpkg -l | grep nautilus


E.g for me it returns:

ii  gir1.2-nautilus-3.0                                   1:3.10.1-0ubuntu9.2                                 amd64        libraries for nautilus components - gir bindings
ii  libnautilus-extension1a                               1:3.10.1-0ubuntu9.1                                 amd64        libraries for nautilus components - runtime version
ii  nautilus                                              1:3.10.1-0ubuntu9.1                                 amd64        file manager and graphical shell for GNOME
ii  nautilus-data                                         1:3.10.1-0ubuntu9.1                                 all          data files for nautilus
ii  nautilus-open-terminal                                0.20-1                                              amd64        nautilus plugin for opening terminals in arbitrary paths
ii  nautilus-pyextensions                                 3.0-1                                               all          Handler of the Nautilus Python Extensions
ii  nautilus-sendto                                       3.6.1-2ubuntu1                                      amd64        integrates Evolution and Pidgin into the Nautilus file manager
ii  nautilus-sendto-empathy                               3.8.6-0ubuntu9.1                                    amd64        GNOME multi-protocol chat and call client (nautilus-sendto plugin)
ii  nautilus-share                                        0.7.3-1ubuntu5                                      amd64        Nautilus extension to share folder using Samba
ii  python-nautilus                                       1.1-4                                               amd64        Python binding for Nautilus components
ii  seahorse-nautilus                                     3.8.0-0ubuntu2                                      amd64        seahorse plugins and utilities for encryption in GNOME


Trying to guess which ones are plugins or extension is a bit more complex:

dpkg -l | egrep -i 'nautilus.* (extension|plugin)'


This time it returns:

ii  nautilus-open-terminal                                0.20-1                                              amd64        nautilus plugin for opening terminals in arbitrary paths
ii  nautilus-pyextensions                                 3.0-1                                               all          Handler of the Nautilus Python Extensions
ii  nautilus-sendto-empathy                               3.8.6-0ubuntu9.1                                    amd64        GNOME multi-protocol chat and call client (nautilus-sendto plugin)
ii  nautilus-share                                        0.7.3-1ubuntu5                                      amd64        Nautilus extension to share folder using Samba
ii  seahorse-nautilus                                     3.8.0-0ubuntu2                                      amd64        seahorse plugins and utilities for encryption in GNOME

"
4174,4174,6662,wpa_supplicant: connect to WLAN in the background (during boot),"I am using manual configuration to connect to my WLAN. In my wpa_supplicant.conf, I have something like this:

network={
    ssid=""mywifi""
    key_management=WPA-EAP
    ...
}


and then, in my /etc/network/interfaces I have 

auto wlan0
    iface wlan0 inet dhcp


When I start my laptop, the connection to my WLAN is established automatically. The problem is, it takes sometimes 10 - 15 seconds until the connection is established and the whole boot process is blocked and waiting. 

I was wondering whether it is possible to configure, so that the connection is established in the background, so that the boot process can go on booting, without waiting for the WLAN to be ready.

I am using Debian Wheezy
",Martin Vegter,https://unix.stackexchange.com/users/43007,"This is probably your dhcp client blocking until it the interface has an address.  The exact answer will depend on what init system you use and what dhcp client you use.  For dhcpcd, for example, you want to make sure the init script that launches it is called with the -b flag (background immediately), and if it has the -w flag (wait), to erase it.

One caveat is that if you have services starting after this interface is launched that depend on it having an IP address, this could cause problems if they start in the few seconds before an IP is secured.  Keep that in mind if you encounter any oddities.
",casey,https://unix.stackexchange.com/users/53706,http://unix.stackexchange.com/questions/104893/wpa-supplicant-connect-to-wlan-in-the-background-during-boot,TECHNOLOGY,unix.stackexchange.com,0.6666666666666666,0.6666666666666666,0.0,1.0,1.0,1.0,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.0,0.6666666666666666,0.8888888888888888,WPA uurequestor: connect to WLAN in the background (during boot),"I am using manual configuration to connect to my WLAN. In my wpa_supplicant.conf, I have something like this:

network={
    ssid=""mywifi""
    key_management=WPA-EAP
    ...
}


and then, in my /etc/network/interfaces I have 

auto wlan0
    iface wlan0 inet dhcp


When I start my laptop, the connection to my WLAN is established automatically. The problem is, it takes sometimes 10 - 15 seconds until the connection is established and the whole boot process is blocked and waiting. 

I was wondering whether it is possible to configure, so that the connection is established in the background, so that the boot process can go on booting, without waiting for the WLAN to be ready.

I am using Debian Wheezy
","Before the interface has an address, this may be your DHCP client blocking. The exact answer will depend on the init system you are using and the DHCP client you are using. For example, for dhcpcd, you need to make sure that you start its init script with the - B flag (background immediate) call and clear it if it uses the - W flag (wait)."
951,951,1507,Negatively curved metrics minimizing the length of a homotopy class of simple closed curves,"Good afternoon everyone !

I have the following question of Riemannian geometry :

Let $M$ be a smooth closed orientable manifold of dimension at least $3$, and let $\mathcal{T} = \{ $ smooth Riemannian metric on $M$ with sectional curvature pinched between $-1- \epsilon$ and $-1$ $\}$ where $\epsilon$ is an arbitrary positive number. Assume that $\mathcal{T}$ is non-empty.

Let $\gamma $ be a simple closed curve in $M$. It is classical that for every negatively curved metric $g$ there is a unique closed curve in the free homotopy class of $\gamma$ that is length minimizing. Note $L_g(\gamma)$ the length of such a curve.

1) Is it known whether $ \inf_{g \in \mathcal{T} }{L_g(\gamma)}$ is positive or zero ?

2) Is it known whether $ \sup_{g \in \mathcal{T} }{L_g(\gamma)}$ is finite or infinite ? 

3) Can one say more in specific cases, say when $M$ is hyperbolic ?

Obviously in dimension 2 Fenchel Nielsen coordinates show that $ \inf_{g \in \mathcal{T} }{L_g(\gamma)}$ is zero and  $ \sup_{g \in \mathcal{T} }{L_g(\gamma)}$ is infinite. Nonetheless, the lack of topological symmetries for higher-dimensional hyperbolic manifolds make me hope that the opposite might be true.

Thanks for your attention !
",Selim G,https://mathoverflow.net/users/25511,"A very partial answer: by the results of Richard Bamler, bounds on Ricci curvature (which is less than what you are requiring here) and diameter (more than you are requiring), implies that the metric is Lipschitz close to an Einstein metric. In three dimension, this means that the length of the homotopy class is close to that of the hyperbolic manifold. In higher dimension, if your manifold is (topologically) hyperbolic, then the Einstein metric is actually hyperbolic (Leung, 1997), so same as above. 

PS Of course, if you have a diameter bound, then your lengths are bounded below in the two-dimensional case (by the collar lemma, if you like).
",Igor Rivin,https://mathoverflow.net/users/11142,http://mathoverflow.net/questions/203422,SCIENCE,mathoverflow.net,0.7777777777777778,0.3333333333333333,0.0,0.5,1.0,1.0,0.5555555555555556,0.4444444444444444,0.6666666666666666,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.0,0.6666666666666666,0.8888888888888888,0.3333333333333333,1.0,1.0,0.7,0.3333333333333333,0.3333333333333333,1.0,0.8888888888888888,A negative curve measure to minimize the homotopy length of a class of simple closed curves,"Good afternoon everyone !

I have the following question of Riemannian geometry :

Let $M$ be a smooth closed orientable manifold of dimension at least $3$, and let $\mathcal{T} = \{ $ smooth Riemannian metric on $M$ with sectional curvature pinched between $-1- \epsilon$ and $-1$ $\}$ where $\epsilon$ is an arbitrary positive number. Assume that $\mathcal{T}$ is non-empty.

Let $\gamma $ be a simple closed curve in $M$. It is classical that for every negatively curved metric $g$ there is a unique closed curve in the free homotopy class of $\gamma$ that is length minimizing. Note $L_g(\gamma)$ the length of such a curve.

1) Is it known whether $ \inf_{g \in \mathcal{T} }{L_g(\gamma)}$ is positive or zero ?

2) Is it known whether $ \sup_{g \in \mathcal{T} }{L_g(\gamma)}$ is finite or infinite ? 

3) Can one say more in specific cases, say when $M$ is hyperbolic ?

Obviously in dimension 2 Fenchel Nielsen coordinates show that $ \inf_{g \in \mathcal{T} }{L_g(\gamma)}$ is zero and  $ \sup_{g \in \mathcal{T} }{L_g(\gamma)}$ is infinite. Nonetheless, the lack of topological symmetries for higher-dimensional hyperbolic manifolds make me hope that the opposite might be true.

Thanks for your attention !
","A very partial answer: by the results of Richard Bamler, bounds on Ricci curvature (which is less than what you are requiring here) and diameter (more than you are requiring), implies that the metric is Lipschitz close to an Einstein metric. In three dimension, this means that the length of the homotopy class is close to that of the hyperbolic manifold. In higher dimension, if your manifold is (topologically) hyperbolic, then the Einstein metric is actually hyperbolic (Leung, 1997), so same as above. 

PS Of course, if you have a diameter bound, then your lengths are bounded below in the two-dimensional case (by the collar lemma, if you like).
"
257,257,415,Direction of Tefillin Winding,"Why do some people have the custom to wind the Tefillin-Shel-Yad towards themselves, while others wind it away from themselves? What is the reason behind these two customs, and which sects of Judaism generally follow which method?
",yydl,https://judaism.stackexchange.com/users/128,"In my (predominantly Ashkenazi) school where we learned about Tefillin, we were taught that the reason for wrapping inwards is that it is towards your heart, thereby making a statement (over the top...) of the love that you (... towards your heart) has for the mitzvah of Tefillin.
",Ask613,https://judaism.stackexchange.com/users/8930,http://judaism.stackexchange.com/questions/8308/direction-of-tefillin-winding,CULTURE,judaism.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,0.6666666666666666,1.0,0.6666666666666666,0.5555555555555556,0.4444444444444444,1.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.3333333333333333,0.0,0.0,1.0,0.0,0.4444444444444444,0.8888888888888888,0.4444444444444444,1.0,1.0,0.6666666666666667,0.0,0.0,1.0,0.8888888888888888,Twining direction of Teflon,"Why do some people have the habit of rolling Teflon on themselves, while others do? What are the reasons behind these two customs? Which denominations of Judaism usually follow which method?","In my (mainly Ashkenazi) school, we learned about Teflon, and we were taught that the reason to wrap it in is because it's facing your heart, so (top...) Make a statement about your love... To your heart) for Teflon's rite of passage."
3791,3791,6028,asynchronously loaded images in uitableview disappear on scrolling up,"i am able to fetch images asynchronously on to uitableview.i am fetching these images are from a url.on scrolling up uitableview these images disappear and  they take time to load again and sometimes they dont load at all.i dont want to use any 3rd party libraries.i dont want to go with synchronous approach.please suggest any correct approach to improve performance.thanks for help in advance.my code is below:

- (UITableViewCell *)tableView:(UITableView *)tableView cellForRowAtIndexPath:(NSIndexPath *)indexPath{
static NSString *identifier=@""cell"";
UITableViewCell *cell = [tableView dequeueReusableCellWithIdentifier:identifier];
if (cell == nil) {
    cell = [[UITableViewCell alloc] initWithStyle:UITableViewCellStyleSubtitle reuseIdentifier:@""identifier""];
}
UIImageView *imgVw=[[UIImageView alloc]initWithFrame:CGRectMake(250, 10, 40, 30)];
[cell.contentView addSubview:imgVw];
Attributes *att = [listOfObjects objectAtIndex:indexPath.row];
strImgUrl=@""http:image url"";
strImgName=att.classifiedImg;
if (strImgName == nil) {
    UIImage *myImg=[UIImage imageNamed:@""user_circle.png""];
    imgVw.image=myImg;
}
else{
    strImg=[strImgUrl stringByAppendingString:strImgName];
}
dispatch_async(dispatch_get_global_queue(0,0), ^{
    NSData *data = [[NSData alloc] initWithContentsOfURL: [NSURL URLWithString:strImg]];
    if ( data == nil )
        return;
    dispatch_async(dispatch_get_main_queue(), ^{

        UIImage *img=[UIImage imageWithData: data];
        imgVw.image=img;
    });

});



return cell;
}

",user2552751,https://stackoverflow.com/users/2552751,"UITableViews are designed to reuse cells. When you scroll up for example the first cell might get reused to show the 5th cell since the 1st one is now off screen. When you scroll back up cellForRowAtIndexPath is called again, and you are async downloading the same image again. If you want to have it load instantly you will need to cache the images after downloading them the first time so the next time that image is needed you can directly pull it from the cache.

Many third party libraries do this (AFNetworking), but if you don't want to use them, you will have to cache the images manually.
",Eric,https://stackoverflow.com/users/904355,http://stackoverflow.com/questions/21013058/asynchronously-loaded-images-in-uitableview-disappear-on-scrolling-up,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.4444444444444444,0.0,0.6666666666666666,1.0,0.6666666666666666,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.6666666666666666,0.3333333333333333,0.6666666666666666,1.0,"When scrolling up, the image loaded asynchronously in uitableview disappears","i am able to fetch images asynchronously on to uitableview.i am fetching these images are from a url.on scrolling up uitableview these images disappear and  they take time to load again and sometimes they dont load at all.i dont want to use any 3rd party libraries.i dont want to go with synchronous approach.please suggest any correct approach to improve performance.thanks for help in advance.my code is below:

- (UITableViewCell *)tableView:(UITableView *)tableView cellForRowAtIndexPath:(NSIndexPath *)indexPath{
static NSString *identifier=@""cell"";
UITableViewCell *cell = [tableView dequeueReusableCellWithIdentifier:identifier];
if (cell == nil) {
    cell = [[UITableViewCell alloc] initWithStyle:UITableViewCellStyleSubtitle reuseIdentifier:@""identifier""];
}
UIImageView *imgVw=[[UIImageView alloc]initWithFrame:CGRectMake(250, 10, 40, 30)];
[cell.contentView addSubview:imgVw];
Attributes *att = [listOfObjects objectAtIndex:indexPath.row];
strImgUrl=@""http:image url"";
strImgName=att.classifiedImg;
if (strImgName == nil) {
    UIImage *myImg=[UIImage imageNamed:@""user_circle.png""];
    imgVw.image=myImg;
}
else{
    strImg=[strImgUrl stringByAppendingString:strImgName];
}
dispatch_async(dispatch_get_global_queue(0,0), ^{
    NSData *data = [[NSData alloc] initWithContentsOfURL: [NSURL URLWithString:strImg]];
    if ( data == nil )
        return;
    dispatch_async(dispatch_get_main_queue(), ^{

        UIImage *img=[UIImage imageWithData: data];
        imgVw.image=img;
    });

});



return cell;
}

","UITableViews are designed to reuse cells. When you scroll up for example the first cell might get reused to show the 5th cell since the 1st one is now off screen. When you scroll back up cellForRowAtIndexPath is called again, and you are async downloading the same image again. If you want to have it load instantly you will need to cache the images after downloading them the first time so the next time that image is needed you can directly pull it from the cache.

Many third party libraries do this (AFNetworking), but if you don't want to use them, you will have to cache the images manually.
"
5306,5306,8429,Best beginning programming language for someone interested in IT security,"Backstory:

At the moment I'm someone with very limited knowledge on computers and programming, but I would like to change that. I have discovered that I'm mainly interested in IT security and that I would especially like to learn more about that (not going to deny that Skyfall didn't have a part in this, but that's certainly not the main reason) as opposed to for example game/app development and such. I don't know exactly why, maybe it has something to do with the fact that I myself have been a victim of viruses and phising a couple of times.

Question itself:  

I have recently decided that I would like to learn my first programming language. This decision is seperate from my interest in IT security, but I would like my first language to be the language most useful for someone who wants to learn more about IT security. I feel this would be killing 2 birds with 1 stone. What would this language be and why?
",OmnipresentAbsence,https://security.stackexchange.com/users/20877,"To really understand IT security (and, more generally, computers), you will have to know how things go inside, so, sooner or later, you will have to learn assembly for one or two architectures (preferably more than two). The low-level exploit codes (e.g. for buffer overflows) don't make sense unless you know assembly. Then move on to C, which is very widespread and a usual target for such exploits. C is easy to learn if you know assembly. Once you know assembly and C, you can learn more complex languages (e.g. C# or Java); your understanding of the inner workings of the machine will guide you through the most ""magical looking"" features of such advanced languages. Following this path, you may then try scripting languages, where each language element hides an awful lot of computations.

This learning order, from low-level to high-level, is an ideal; I have yet to meet a single person who strictly adhered to it. In my own learning path, I started with Basic (""version 1.0"", from 1984) and then switched to assembly (on a 6809E CPU) because Basic was really too slow on my machine (a 1 MHz CPU does not have a lot of muscle). Later on, I learned Pascal, then C, and some more assembly. Afterwards, I did a lot of C, I touched many other languages (e.g. Caml, PostScript, Prolog, Objective-C, C++), some scripting (Unix sh, Perl...) and even more assembly (on several distinct architectures). Even later on, I did a lot of Java. Also tried Forth, Scheme, some more assembly. Lately, I have done some C# (which is very similar to Java), PowerShell, and suffered from an outbreak of VB.

What is to remember is that every language has its quirks; you will achieve the programming equivalent of enlightenment if you can see beyond the particularities of any specific language, and concentrate on the underlying algorithmics. Knowing a lot of languages and architectures will help you greatly. It will also highlight what language features are especially ""dangerous"" to use, by which I mean prone to trigger exploitable weaknesses. Conversely, if you stick to a single language, then you will only be a mediocre practitioner of programming and IT security.

Other learning paths exist and some people are happy with them. Many apprentice programmers begin with something high-level like Python and only later on try to see ""under the hood"" how the computer really does things. I tend to favour the low-to-high path because it is similar to the path that I followed myself, but there is no absolute necessity in that.
",Thomas Pornin,https://security.stackexchange.com/users/655,http://security.stackexchange.com/questions/31045/best-beginning-programming-language-for-someone-interested-in-it-security,TECHNOLOGY,security.stackexchange.com,1.0,0.8888888888888888,0.0,0.0,0.3333333333333333,0.5,0.8888888888888888,0.6666666666666666,0.6666666666666666,0.0,1.0,0.0,1.0,0.0,0.0,0.3333333333333333,0.0,0.0,1.0,0.0,0.8888888888888888,1.0,0.7777777777777778,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,0.8888888888888888,The best entry programming language for people interested in IT Security,"Backstory:

At the moment I'm someone with very limited knowledge on computers and programming, but I would like to change that. I have discovered that I'm mainly interested in IT security and that I would especially like to learn more about that (not going to deny that Skyfall didn't have a part in this, but that's certainly not the main reason) as opposed to for example game/app development and such. I don't know exactly why, maybe it has something to do with the fact that I myself have been a victim of viruses and phising a couple of times.

Question itself:  

I have recently decided that I would like to learn my first programming language. This decision is seperate from my interest in IT security, but I would like my first language to be the language most useful for someone who wants to learn more about IT security. I feel this would be killing 2 birds with 1 stone. What would this language be and why?
","To really understand IT security (and, more generally, computers), you will have to know how things go inside, so, sooner or later, you will have to learn assembly for one or two architectures (preferably more than two). The low-level exploit codes (e.g. for buffer overflows) don't make sense unless you know assembly. Then move on to C, which is very widespread and a usual target for such exploits. C is easy to learn if you know assembly. Once you know assembly and C, you can learn more complex languages (e.g. C# or Java); your understanding of the inner workings of the machine will guide you through the most ""magical looking"" features of such advanced languages. Following this path, you may then try scripting languages, where each language element hides an awful lot of computations.

This learning order, from low-level to high-level, is an ideal; I have yet to meet a single person who strictly adhered to it. In my own learning path, I started with Basic (""version 1.0"", from 1984) and then switched to assembly (on a 6809E CPU) because Basic was really too slow on my machine (a 1 MHz CPU does not have a lot of muscle). Later on, I learned Pascal, then C, and some more assembly. Afterwards, I did a lot of C, I touched many other languages (e.g. Caml, PostScript, Prolog, Objective-C, C++), some scripting (Unix sh, Perl...) and even more assembly (on several distinct architectures). Even later on, I did a lot of Java. Also tried Forth, Scheme, some more assembly. Lately, I have done some C# (which is very similar to Java), PowerShell, and suffered from an outbreak of VB.

What is to remember is that every language has its quirks; you will achieve the programming equivalent of enlightenment if you can see beyond the particularities of any specific language, and concentrate on the underlying algorithmics. Knowing a lot of languages and architectures will help you greatly. It will also highlight what language features are especially ""dangerous"" to use, by which I mean prone to trigger exploitable weaknesses. Conversely, if you stick to a single language, then you will only be a mediocre practitioner of programming and IT security.

Other learning paths exist and some people are happy with them. Many apprentice programmers begin with something high-level like Python and only later on try to see ""under the hood"" how the computer really does things. I tend to favour the low-to-high path because it is similar to the path that I followed myself, but there is no absolute necessity in that.
"
2025,2025,3230,Reftex \cite command binding,"I have a computer where the char [ is made with AltGr+è so I can't use the command Ctrl+[ of RefTeX. Is there a solution to this?
",Alessandro,https://tex.stackexchange.com/users/25121,"I'm moving my comment here as it gives me more space:

But then again, there are quite a lot of Emacs + reftex users reading this site as well. C-c [, runs reftex-citation, you you could just define your own short cut. Here is what I would do

; unset C-z, to be used to make my own C-z prefix
(global-unset-key [(control z)])
(global-set-key [(control z) (c)] 'reftex-citation)


(untested)

The above is how I normally add my own short cuts. By using C-z as a prefix, I'm usually not messing with some existing ones.
",daleif,https://tex.stackexchange.com/users/3929,http://tex.stackexchange.com/questions/95680/reftex-cite-command-binding,TECHNOLOGY,tex.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,0.6666666666666666,1.0,0.6666666666666666,0.4444444444444444,0.4444444444444444,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9,0.6666666666666666,0.3333333333333333,0.0,0.8333333333333334,Reftex \ cite command binding,"I have a computer that generates char with altgr + è, so I can't use reftex's Ctrl + [command. Is there a solution?","I'm moving my comment here as it gives me more space:

But then again, there are quite a lot of Emacs + reftex users reading this site as well. C-c [, runs reftex-citation, you you could just define your own short cut. Here is what I would do

; unset C-z, to be used to make my own C-z prefix
(global-unset-key [(control z)])
(global-set-key [(control z) (c)] 'reftex-citation)


(untested)

The above is how I normally add my own short cuts. By using C-z as a prefix, I'm usually not messing with some existing ones.
"
5467,5467,8682,What's a common mechanism for emailing in the background?,"When users sign up to my site, the connection from my server to our 3rd-party SMTP provider is very bad and the app takes from a few seconds to a few minutes to connect. While it is trying to connect and send, users are forced to wait there and sometimes they would just give up and leave the site.

This is horrible user experience. What is a good way to make this seem instantaneous (having to host our own mailserver is not an option at this point)? Some way to execute this in the background? Maybe using some type of queuing mechanism?

I'm using the LNAMP stack on a CentOS 5 x64 machine. App is using CodeIgniter.

EDIT:

It seems using a local mailserver to use as a relay is a common solution. But how does one log or track whether or not email was delivered correctly by using this method? 

Sidenote: Some ESPs provide a REST API for email delivery (ours do too). We currently use SMTP and not their REST API. 
",lamp_scaler,https://serverfault.com/users/87326,"You can use Postfix as a nullmailer (relay only to ISP). This is nothing more than a four-liner:

main.cf

myorigin = $mydomain
relayhost = $mydomain
inet_interfaces = loopback-only
local_transport = error:local delivery is disabled


Reference: http://www.postfix.org/STANDARD_CONFIGURATION_README.html#null_client
",mailq,https://serverfault.com/users/75291,http://serverfault.com/questions/318374,TECHNOLOGY,serverfault.com,1.0,0.7777777777777778,0.0,0.6666666666666666,1.0,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.6666666666666666,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.3333333333333333,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.3333333333333333,0.0,1.0,What is the common mechanism for sending mail in the background?,"When users sign up to my site, the connection from my server to our 3rd-party SMTP provider is very bad and the app takes from a few seconds to a few minutes to connect. While it is trying to connect and send, users are forced to wait there and sometimes they would just give up and leave the site.

This is horrible user experience. What is a good way to make this seem instantaneous (having to host our own mailserver is not an option at this point)? Some way to execute this in the background? Maybe using some type of queuing mechanism?

I'm using the LNAMP stack on a CentOS 5 x64 machine. App is using CodeIgniter.

EDIT:

It seems using a local mailserver to use as a relay is a common solution. But how does one log or track whether or not email was delivered correctly by using this method? 

Sidenote: Some ESPs provide a REST API for email delivery (ours do too). We currently use SMTP and not their REST API. 
","You can use Postfix as a nullmailer (relay only to ISP). This is nothing more than a four-liner:

main.cf

myorigin = $mydomain
relayhost = $mydomain
inet_interfaces = loopback-only
local_transport = error:local delivery is disabled


Reference: http://www.postfix.org/STANDARD_CONFIGURATION_README.html#null_client
"
1050,1050,1651,Is it reasonable to use Javascript MVC Frameworks for closed source paid web applications?,"I am wondering if it is reasonable to write closed source, paid web apps in Javascript (JS MVC Frameworks like AngularJS, Backbone, Knockout, ...)? I'm concerned because in this type of frameworks you use typically a REST backend for CRUD operations and the majority of business and application logic happens in Javascript which can be looked up by anyone using my app. He can see how i do things. 

When I use for example PHP or Java (Wicket) most of the logic is happening on the server and so a lot less of my source code is exposed. This seems to me a lot safer if I want to have an edge over my competitors, so potentially I earn more money.

So is it reasonable to use JavaScript MVC Frameworks for paid applications? Does it depend on something and if yes on what? 
",Robert Niestroj,https://programmers.stackexchange.com/users/80370,"There is at least one major error in your question: In an REST backend the business logic still is on the server. It has to and having business logic in the browser would be pure madness.

From there we can go on and see that the most complex part of any serious web app rests on the server anyway. The browser can only take the View part of the MVC, maybe a few elements from Controllers. Main Controller functionality and especially Model are just to security relevant.

Beyond that: What do you want to write as web apps? If I want to do something smart, I don't look at my competitors, I use Google and StackExchange to find that it was done before a hundred times or at least something similar. There are libraries for mostly everything. The times when keeping your code a trade secret are gone, at least when we are talking about the user interface.
",thorsten müller,https://programmers.stackexchange.com/users/13866,http://programmers.stackexchange.com/questions/194845/is-it-reasonable-to-use-javascript-mvc-frameworks-for-closed-source-paid-web-app,TECHNOLOGY,programmers.stackexchange.com,1.0,0.8888888888888888,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.3333333333333333,1.0,1.0,Is it reasonable to use JavaScript MVC framework for closed source paid web applications?,"I want to know how to use JavaScript (JS MVC framework, such as angularjs, backbone, knockout,...) Is it reasonable to write closed source paid web applications? My concern is that in such frameworks, you usually use the rest backend to perform CRUD operations, while most business and application logic occurs in JavaScript, which can be found by anyone who uses my application. He knows how I do things.","There is at least one major error in your question: In an REST backend the business logic still is on the server. It has to and having business logic in the browser would be pure madness.

From there we can go on and see that the most complex part of any serious web app rests on the server anyway. The browser can only take the View part of the MVC, maybe a few elements from Controllers. Main Controller functionality and especially Model are just to security relevant.

Beyond that: What do you want to write as web apps? If I want to do something smart, I don't look at my competitors, I use Google and StackExchange to find that it was done before a hundred times or at least something similar. There are libraries for mostly everything. The times when keeping your code a trade secret are gone, at least when we are talking about the user interface.
"
5335,5335,8475,Do you keep your project code names the same in the source tree?,"Sometimes when I start working on a project, I just can't think of a good name, or think of a good name that isn't already taken. As a result, I'll end up picking some sort of code name for the project.

My question is, how do you handle name changes in your source code once you find a real name for your project? Should you continue to refer to the code name in your source tree, namespaces, binaries, etc?
",QAH,https://programmers.stackexchange.com/users/18490,"In my experience, it is extremely common that the name used to market a product is completely different from the name used internally for that product by the developers. Most often, because marketing has not decided on a name yet when development starts.

Whenever a project or product name is used in the internal documentation, file hierarchy, etc., it has been the practice to keep using the internal code-name, even after marketing has decided on the official product name. Only in documentation that is meant for the end-users is the product referred to with its official marketing name.
Usually, there is significant cost and no benefit in renaming everything.
",Bart van Ingen Schenau,https://programmers.stackexchange.com/users/5099,http://programmers.stackexchange.com/questions/208576/do-you-keep-your-project-code-names-the-same-in-the-source-tree,TECHNOLOGY,programmers.stackexchange.com,1.0,0.4444444444444444,0.6666666666666666,1.0,0.3333333333333333,0.5,0.4444444444444444,0.4444444444444444,0.6666666666666666,0.0,1.0,1.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,0.8888888888888888,Keep the project code name the same in the source tree?,"Sometimes when I start working on a project, I just can't think of a good name, or think of a good name that isn't already taken. As a result, I'll end up picking some sort of code name for the project.

My question is, how do you handle name changes in your source code once you find a real name for your project? Should you continue to refer to the code name in your source tree, namespaces, binaries, etc?
","In my experience, it is extremely common that the name used to market a product is completely different from the name used internally for that product by the developers. Most often, because marketing has not decided on a name yet when development starts.

Whenever a project or product name is used in the internal documentation, file hierarchy, etc., it has been the practice to keep using the internal code-name, even after marketing has decided on the official product name. Only in documentation that is meant for the end-users is the product referred to with its official marketing name.
Usually, there is significant cost and no benefit in renaming everything.
"
1151,1151,1806,how can i use regex to get a certain string of a file,"with linux bash shell , how can i use regex to get a certain string of a file

by example:

for filename *.tgz
do 

""get the certain string of filename (in my case, get 2010.04.12 of file 2010.01.12myfile.tgz)""

done  

or should I turn to perl

Merci

frank
",chun,https://stackoverflow.com/users/304910,"with bash, for the simplest case, if you know what you want to get is a date stamp, you can just use shell expansion

#!/bin/bash

for file in 20[0-9][0-9].[01][0-9].[0-9][0-9]*tgz
do
 echo $file
done


else, if its anything before the first alphabet, 

for file in *tgz
do
 echo ${file%%[a-zA-Z]*}
done


otherwise, you should spell out your criteria for the search.
",ghostdog74,https://stackoverflow.com/users/131527,http://stackoverflow.com/questions/2673919/how-can-i-use-regex-to-get-a-certain-string-of-a-file,STACKOVERFLOW,stackoverflow.com,1.0,0.8888888888888888,0.0,0.6666666666666666,0.3333333333333333,1.0,0.4444444444444444,0.4444444444444444,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,0.0,0.8888888888888888,How to use regex to get specific strings of files,"with linux bash shell , how can i use regex to get a certain string of a file

by example:

for filename *.tgz
do 

""get the certain string of filename (in my case, get 2010.04.12 of file 2010.01.12myfile.tgz)""

done  

or should I turn to perl

Merci

frank
","with bash, for the simplest case, if you know what you want to get is a date stamp, you can just use shell expansion

#!/bin/bash

for file in 20[0-9][0-9].[01][0-9].[0-9][0-9]*tgz
do
 echo $file
done


else, if its anything before the first alphabet, 

for file in *tgz
do
 echo ${file%%[a-zA-Z]*}
done


otherwise, you should spell out your criteria for the search.
"
5106,5106,8123,Convert XML to PSObject,"Note: I'm using ConvertTo-XML and cannot use Export-Clixml:

I create a simple PSObject:

$a = New-Object PSObject -Property @{
    Name='New'
    Server = $null
    Database = $null
    UserName = $null
    Password = $null
}


I then convert it into XML using ConvertTo-XML:

$b = $a | Convertto-XML -NoTypeInformation


The XML looks like this:

&lt;?xml version=""1.0""?&gt;
&lt;Objects&gt;
  &lt;Object&gt;
    &lt;Property Name=""Password"" /&gt;
    &lt;Property Name=""Name""&gt;New&lt;/Property&gt;
    &lt;Property Name=""Server"" /&gt;
    &lt;Property Name=""UserName"" /&gt;
    &lt;Property Name=""Database"" /&gt;
  &lt;/Object&gt;
&lt;/Objects&gt;


I'm having trouble figuring out the dot notation or XPath query to extract the attributes/elements and convert $b back to the original PSObject.
",Chad Miller,https://stackoverflow.com/users/135965,"You can do this pretty easily with XPath. Although PowerShell usually makes working with XML pretty simple, in this case I think the format using strictly PowerShell syntax would be pretty gross.

filter XmlProperty([String]$Property) {
    $_.SelectSingleNode(""/Objects/Object/Property[@Name='$Property']"").InnerText
}

$Name = $b | Xmlproperty Name
$Server = $b | XmlProperty Server
# etc...


EDIT: To generically do this for an XML document that contains one or more Object elements, you can do something like this:

function ConvertFrom-Xml($XML) {
    foreach ($Object in @($XML.Objects.Object)) {
        $PSObject = New-Object PSObject
        foreach ($Property in @($Object.Property)) {
            $PSObject | Add-Member NoteProperty $Property.Name $Property.InnerText
        }
        $PSObject
    }
}

ConvertFrom-Xml $b

",Josh,https://stackoverflow.com/users/81769,http://stackoverflow.com/questions/3242995/convert-xml-to-psobject,STACKOVERFLOW,stackoverflow.com,1.0,0.3333333333333333,0.0,0.0,1.0,0.5,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,1.0,Convert XML to psobject,"Note: I'm using ConvertTo-XML and cannot use Export-Clixml:

I create a simple PSObject:

$a = New-Object PSObject -Property @{
    Name='New'
    Server = $null
    Database = $null
    UserName = $null
    Password = $null
}


I then convert it into XML using ConvertTo-XML:

$b = $a | Convertto-XML -NoTypeInformation


The XML looks like this:

&lt;?xml version=""1.0""?&gt;
&lt;Objects&gt;
  &lt;Object&gt;
    &lt;Property Name=""Password"" /&gt;
    &lt;Property Name=""Name""&gt;New&lt;/Property&gt;
    &lt;Property Name=""Server"" /&gt;
    &lt;Property Name=""UserName"" /&gt;
    &lt;Property Name=""Database"" /&gt;
  &lt;/Object&gt;
&lt;/Objects&gt;


I'm having trouble figuring out the dot notation or XPath query to extract the attributes/elements and convert $b back to the original PSObject.
","You can do this pretty easily with XPath. Although PowerShell usually makes working with XML pretty simple, in this case I think the format using strictly PowerShell syntax would be pretty gross.

filter XmlProperty([String]$Property) {
    $_.SelectSingleNode(""/Objects/Object/Property[@Name='$Property']"").InnerText
}

$Name = $b | Xmlproperty Name
$Server = $b | XmlProperty Server
# etc...


EDIT: To generically do this for an XML document that contains one or more Object elements, you can do something like this:

function ConvertFrom-Xml($XML) {
    foreach ($Object in @($XML.Objects.Object)) {
        $PSObject = New-Object PSObject
        foreach ($Property in @($Object.Property)) {
            $PSObject | Add-Member NoteProperty $Property.Name $Property.InnerText
        }
        $PSObject
    }
}

ConvertFrom-Xml $b

"
2764,2764,4405,IIS 7 email forwarding,"We have set up an IIS7 box in our company as a hosting server.
Some clients want their email addressed with their domain name forwarded to their respected email addresses (like, johndoe@domain.com -> forward -> bob@yahoo.com).

How can this be accomplished? it should be for several domains on the server and the mails should be forwarded to various other domains and email providers.

Thanks,
roman
",roman,https://serverfault.com/users/68023,"If this is a windows hosting platform you need to follow the SPLA guidleines on how a hosted IIS or EMAIl service should be set up.  You should have gotten access to that documentation when you signed up for the SPLA license. (it's behind the partner protal or I'd provide the link) SPLA is the ONLY way you can license microsoft products for a hosted environment, luckily it's actually less expensive than buying the actual products.  See this link for more details
",Jim B,https://serverfault.com/users/3528,http://serverfault.com/questions/97596,TECHNOLOGY,serverfault.com,0.8888888888888888,0.4444444444444444,0.0,0.3333333333333333,1.0,1.0,0.8888888888888888,0.5555555555555556,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.7777777777777778,0.7777777777777778,0.5555555555555556,1.0,0.8888888888888888,0.7333333333333333,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.8888888888888888,IIS 7 email forwarding,"We have set up an IIS7 box in our company as a hosting server.
Some clients want their email addressed with their domain name forwarded to their respected email addresses (like, johndoe@domain.com -> forward -> bob@yahoo.com).

How can this be accomplished? it should be for several domains on the server and the mails should be forwarded to various other domains and email providers.

Thanks,
roman
","If this is a windows hosting platform you need to follow the SPLA guidleines on how a hosted IIS or EMAIl service should be set up.  You should have gotten access to that documentation when you signed up for the SPLA license. (it's behind the partner protal or I'd provide the link) SPLA is the ONLY way you can license microsoft products for a hosted environment, luckily it's actually less expensive than buying the actual products.  See this link for more details
"
5505,5505,8736,When to use layoutSubview in iOS,"I am writing iOS application for iPad that require custom layout.

The layout from portrait and landscape are totally difference, so it can't be solve by using UIAutoResizingMask.

I try to use the layoutSubview Method, but I detected that layout subview is called a lot (from UIScrollView).
How can i reduce the layoutSubview call to optimize the code , or I should call it by my self when ever the device is rotated. 

Thank.
",Isara Rungvitayakul,https://stackoverflow.com/users/475479,"The fact that layoutSubviews gets called by a child UIScrollView is very unfortunate, but there's an (ugly) workaround:

@interface MyClass : UIView {
    BOOL reallyNeedsLayout_;
}
@end

@implementation MyClass

- (void)setNeedsLayout
{
    [super setNeedLayout];
    reallyNeedsLayout_ = YES;
}

- (void)setFrame:(CGRect)rect
{
    [super setFrame:rect];
    reallyNeedsLayout_ = YES;
}

- (void)layoutSubviews
{
    if (!reallyNeedsLayout_) return;
    reallyNeedsLayout_ = NO;

    // Do layouting.
}
@end


Not the best solution but seems to work reasonably well.
",DarkDust,https://stackoverflow.com/users/400056,http://stackoverflow.com/questions/6953373/when-to-use-layoutsubview-in-ios,STACKOVERFLOW,stackoverflow.com,1.0,0.6666666666666666,0.0,1.0,0.6666666666666666,1.0,0.6666666666666666,0.5555555555555556,0.3333333333333333,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,0.8888888888888888,When to use layoutsubview in IOS,"I am writing iOS application for iPad that require custom layout.

The layout from portrait and landscape are totally difference, so it can't be solve by using UIAutoResizingMask.

I try to use the layoutSubview Method, but I detected that layout subview is called a lot (from UIScrollView).
How can i reduce the layoutSubview call to optimize the code , or I should call it by my self when ever the device is rotated. 

Thank.
","The fact that layoutSubviews gets called by a child UIScrollView is very unfortunate, but there's an (ugly) workaround:

@interface MyClass : UIView {
    BOOL reallyNeedsLayout_;
}
@end

@implementation MyClass

- (void)setNeedsLayout
{
    [super setNeedLayout];
    reallyNeedsLayout_ = YES;
}

- (void)setFrame:(CGRect)rect
{
    [super setFrame:rect];
    reallyNeedsLayout_ = YES;
}

- (void)layoutSubviews
{
    if (!reallyNeedsLayout_) return;
    reallyNeedsLayout_ = NO;

    // Do layouting.
}
@end


Not the best solution but seems to work reasonably well.
"
3407,3407,5429,how to identify IC codes?,"I want to buy a LM4558N ,which is unavailable in the local store.  

I found  similar ones online but not sure if they are the same ones i need.

1)Manufacturer:     TEXAS INSTRUMENTS

Man. Part No.:  RC4558P

2)Part No: MC4558CN 

FOC Code: 1467662

Manufacturer: STMICROELECTRONICS

3)Manufacturer:  TEXAS INSTRUMENTS

Man. Part No.:  RC4558IP 

Are this the same ones with different names or completely different?
",Metalhead1247,https://electronics.stackexchange.com/users/25960,"I don't know if this qualifies as an answer, but to be sure you will have to take a look at the manufacturer data-sheet.

There should be a section named similar ""Marking information"" or ""Part labeling"" or ""Package marking"".

Example:


",Rev1.0,https://electronics.stackexchange.com/users/16051,http://electronics.stackexchange.com/questions/76278/how-to-identify-ic-codes,TECHNOLOGY,electronics.stackexchange.com,1.0,0.8888888888888888,0.0,0.3333333333333333,1.0,1.0,0.5555555555555556,0.5555555555555556,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.0,0.0,0.7777777777777778,0.6666666666666666,0.5555555555555556,0.7777777777777778,0.7777777777777778,0.4666666666666667,1.0,0.0,0.0,0.7777777777777778,How to identify IC code?,"I want to buy a LM4558N ,which is unavailable in the local store.  

I found  similar ones online but not sure if they are the same ones i need.

1)Manufacturer:     TEXAS INSTRUMENTS

Man. Part No.:  RC4558P

2)Part No: MC4558CN 

FOC Code: 1467662

Manufacturer: STMICROELECTRONICS

3)Manufacturer:  TEXAS INSTRUMENTS

Man. Part No.:  RC4558IP 

Are this the same ones with different names or completely different?
","I don't know if this qualifies as an answer, but to be sure you will have to take a look at the manufacturer data-sheet.

There should be a section named similar ""Marking information"" or ""Part labeling"" or ""Package marking"".

Example:


"
1616,1616,2536,What is the best introductory Bayesian statistics textbook?,"Which is the best introductory textbook for Bayesian statistics?

One book per answer, please.
",Shane,https://stats.stackexchange.com/users/5,"I am now reading : From Algorithm to Z-Scores: Probabilistic and Statistical Modeling in Computer Science by Norm Matloff, UC Davis, freely available for download.

My two cents.
",Fabio,https://stats.stackexchange.com/users/40316,http://stats.stackexchange.com/questions/125/what-is-the-best-introductory-bayesian-statistics-textbook,SCIENCE,stats.stackexchange.com,1.0,1.0,0.6666666666666666,1.0,1.0,0.0,0.4444444444444444,0.5555555555555556,0.0,0.0,1.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,1.0,0.5555555555555556,0.4444444444444444,1.0,0.8888888888888888,0.6666666666666667,0.0,0.0,0.0,0.7777777777777778,What is the best introduction to Bayesian statistics?,Which is the best introduction to Bayesian statistics?,"I am now reading : From Algorithm to Z-Scores: Probabilistic and Statistical Modeling in Computer Science by Norm Matloff, UC Davis, freely available for download.

My two cents.
"
5083,5083,8088,WordPress Internal @ Mentions,"I'm looking for a way to link to author pages within one WordPress install simply by putting the @ symbol in front of a person's username in a post.... just like on twitter.

Example:

If the username is ""Bill256"" and I write ""@Bill256"" it will be linked to his author page.
",AndrettiMilas,https://wordpress.stackexchange.com/users/5205,"Look at the P2 theme. It does this, calling them ""Mentions"".

http://themes.svn.wordpress.org/p2/1.4.2/inc/mentions.php
",Otto,https://wordpress.stackexchange.com/users/2232,http://wordpress.stackexchange.com/questions/77234/wordpress-internal-mentions,TECHNOLOGY,wordpress.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,0.0,1.0,1.0,0.6666666666666666,0.8888888888888888,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.0,0.0,1.0,WordPress internal @ mentioned,I'm looking for a way to link to the author's page in a WordPress installation by simply putting the @ symbol in front of a person's user name in the post.... It's like on twitter.,"Take a look at the P2 theme. It does so, calling it ""mention.""."
1642,1642,2578,How do you prove $S=-\sum p\ln p$?,"How does one prove the formula for entropy $S=-\sum p\ln p$?
Obviously systems on the microscopic level are fully determined by the microscopic equations of motion. So if you want to introduce a law on top of that, you have to prove consistency, i.e. entropy cannot be a postulate.
I can imagine that it is derived from probability theory for general system. Do you know such a line?

Once you have such a reasoning, what are the assumptions to it?
Can these assumptions be invalid for special systems? Would these system not obey thermodynamics, statistical mechanics and not have any sort of temperature no matter how general?

If therodynamics/statmech are completely general, how would you apply them the system where one point particle orbits another?
",Gerenuk,https://physics.stackexchange.com/users/5152,"Approaching this from a purely Physics perspective, this is the Gibbs entropy of a system. Firstly, although the concept of entropy can be extended we are usually discussing equilibrium thermodynamics, and this is certainly where the Gibbs entropy is first introduced.

You are of course right that technically the dynamics could be fully described by their equations of motion, but then there wouldn't really be much need for the subject of thermodynamics. I mean thermodynamics in some ways is not as ""fundamental"" as other subjects in physics, in that it does not try to give a complete description of everything about the system you're studying. You're usually discussing large systems (and so looking for macroscopic properties), or small systems interacting with a large environment. (for example, it doesn't make a huge amount of sense to talk about the temperature of an electron) In reality it is entirely impractical to search for a deterministic description of such systems (even without Chaos theory and quantum mechanics the number of equations would just be too enormous) and so you use thermodynamics.

With equilibrium statistical thermodynamics (which is looking for a justification of classical thermodynamics based on averages of a microscopic description), you start with the principle of equal a priori probabilities which says for an isolated system which has been left alone for along time (vague, but basically that it's in equilibrium) every microstate available to the system is equally likely to be occupied. This is a big assumption, and there are a lot of people who would like to be able to justify it properly, but it's often argued on symmetry (with the information you have there is no reason to assume one particular microstate would be more likely than any other). More than that, it just works. 

The entropy of an isolated system was then postulated to be $S=k \ ln(\Omega)$ by Boltzmann where $\Omega$ is the number of microstates available to the system (it's easier to build this up assuming a discrete number of microstates, especially if you are talking about Boltzmann/Gibbs entropy). It's a postulate, but it needs to be consistent with the classical thermodynamic entropy. The Gibbs entropy is a natural extension of this when you consider systems which are in thermal contact with an environment and the microstate probabilities are no longer equal. You can show that it is consistent with the classical thermodynamic entropy for a number of systems, and really shows how entropy can be considered to be a measure of uncertainty about the microscopic details of the system.
",Henry,https://physics.stackexchange.com/users/37775,http://physics.stackexchange.com/questions/14436/how-do-you-prove-s-sum-p-ln-p,SCIENCE,physics.stackexchange.com,0.7777777777777778,0.5555555555555556,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.3333333333333333,1.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.0,0.7777777777777778,0.7777777777777778,0.7777777777777778,0.7777777777777778,1.0,0.8666666666666666,0.0,0.3333333333333333,1.0,0.8888888888888888,How to prove $s = - \ sum P \ ln p $?,"How does one prove the formula for entropy $S=-\sum p\ln p$?
Obviously systems on the microscopic level are fully determined by the microscopic equations of motion. So if you want to introduce a law on top of that, you have to prove consistency, i.e. entropy cannot be a postulate.
I can imagine that it is derived from probability theory for general system. Do you know such a line?

Once you have such a reasoning, what are the assumptions to it?
Can these assumptions be invalid for special systems? Would these system not obey thermodynamics, statistical mechanics and not have any sort of temperature no matter how general?

If therodynamics/statmech are completely general, how would you apply them the system where one point particle orbits another?
","Approaching this from a purely Physics perspective, this is the Gibbs entropy of a system. Firstly, although the concept of entropy can be extended we are usually discussing equilibrium thermodynamics, and this is certainly where the Gibbs entropy is first introduced.

You are of course right that technically the dynamics could be fully described by their equations of motion, but then there wouldn't really be much need for the subject of thermodynamics. I mean thermodynamics in some ways is not as ""fundamental"" as other subjects in physics, in that it does not try to give a complete description of everything about the system you're studying. You're usually discussing large systems (and so looking for macroscopic properties), or small systems interacting with a large environment. (for example, it doesn't make a huge amount of sense to talk about the temperature of an electron) In reality it is entirely impractical to search for a deterministic description of such systems (even without Chaos theory and quantum mechanics the number of equations would just be too enormous) and so you use thermodynamics.

With equilibrium statistical thermodynamics (which is looking for a justification of classical thermodynamics based on averages of a microscopic description), you start with the principle of equal a priori probabilities which says for an isolated system which has been left alone for along time (vague, but basically that it's in equilibrium) every microstate available to the system is equally likely to be occupied. This is a big assumption, and there are a lot of people who would like to be able to justify it properly, but it's often argued on symmetry (with the information you have there is no reason to assume one particular microstate would be more likely than any other). More than that, it just works. 

The entropy of an isolated system was then postulated to be $S=k \ ln(\Omega)$ by Boltzmann where $\Omega$ is the number of microstates available to the system (it's easier to build this up assuming a discrete number of microstates, especially if you are talking about Boltzmann/Gibbs entropy). It's a postulate, but it needs to be consistent with the classical thermodynamic entropy. The Gibbs entropy is a natural extension of this when you consider systems which are in thermal contact with an environment and the microstate probabilities are no longer equal. You can show that it is consistent with the classical thermodynamic entropy for a number of systems, and really shows how entropy can be considered to be a measure of uncertainty about the microscopic details of the system.
"
61,61,95,Exchange 2003 internal to external,"SBS exchange 2003 

An internal user is trying to send an email to another user on the same domain but the 2nd user in not in the AD or in exchange but exchange gives a NDR without sending the email to the mail provider.

How can i get exchange to send the email to the mailprovider without adding the 2nd user to the AD and/or exchange?
",koen broumels,https://serverfault.com/users/139803,"You'll need to set up SMTP namespace sharing. Here's an article that explains how to do it in Exchange Server 2003:

http://www.msexchange.org/tutorials/exchange-2003-smtp-namespace-sharing.html
",joeqwerty,https://serverfault.com/users/19152,http://serverfault.com/questions/435242,TECHNOLOGY,serverfault.com,1.0,0.3333333333333333,0.0,0.0,1.0,1.0,0.8333333333333334,0.8333333333333334,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,0.0,1.0,Exchange 2003 internal to external,"SBS exchange 2003 

An internal user is trying to send an email to another user on the same domain but the 2nd user in not in the AD or in exchange but exchange gives a NDR without sending the email to the mail provider.

How can i get exchange to send the email to the mailprovider without adding the 2nd user to the AD and/or exchange?
",You need to set up the SMTP namespace share. Here is an article on how to do this in Exchange Server 2003:
5986,5986,9490,inserting period after every 3 chars in a string,"I have this:

from __future__ import print_function

def f_comma(p_string):
   v_string = p_string
   if (type(v_string) == type(int()) or type(v_string) == type(long()) or  
       type(v_string) == type(float())):
      v_string = str(v_string)
   else:   
      l_string = list(v_string)
      for v_index in range(3, len(l_string), 4):
         l_string.insert(v_index, ',')
      v_result = ''.join(l_string)
   return (v_result)

print (f_comma('qwertyuiopaq'))


It seems that i can't figure it out why if i use a string longer than 11 chars the period stops inserting, but with only 11 chars it works fine. What i'm doing wrong in this piece?
",udarH3,https://stackoverflow.com/users/4257949,"Here's why it doesn't work. (Rather than solving your method which is a pretty inefficient one, as others have shown.)

When you .insert() something into your list, every element gets shifted forward a position to make room.

The indexes you calculated earlier with range(3, len(l_string), 4) are then no longer what you want them to be.
",LondonRob,https://stackoverflow.com/users/2071807,http://stackoverflow.com/questions/30919275/inserting-period-after-every-3-chars-in-a-string,STACKOVERFLOW,stackoverflow.com,1.0,0.3333333333333333,0.0,1.0,1.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,1.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,1.0,0.6,0.0,0.0,1.0,1.0,Inserts a period after every three characters in a string,"I have this:

from __future__ import print_function

def f_comma(p_string):
   v_string = p_string
   if (type(v_string) == type(int()) or type(v_string) == type(long()) or  
       type(v_string) == type(float())):
      v_string = str(v_string)
   else:   
      l_string = list(v_string)
      for v_index in range(3, len(l_string), 4):
         l_string.insert(v_index, ',')
      v_result = ''.join(l_string)
   return (v_result)

print (f_comma('qwertyuiopaq'))


It seems that i can't figure it out why if i use a string longer than 11 chars the period stops inserting, but with only 11 chars it works fine. What i'm doing wrong in this piece?
","Here's why it doesn't work. (Rather than solving your method which is a pretty inefficient one, as others have shown.)

When you .insert() something into your list, every element gets shifted forward a position to make room.

The indexes you calculated earlier with range(3, len(l_string), 4) are then no longer what you want them to be.
"
2218,2218,3537,Isomorphism between quotient groups with normal subgroups,"I'm looking at a problem in my textbook and it says:

Let $ψ : G_1 → G_2$ be a surjective group homomorphism. Let $H_1$ be a normal subgroup of $G_1$ and suppose that $ψ(H_1) = H_2$. Prove or disprove that $G_1/H_1$ is isomorphic $G_2/H_2$.

So far, I know that since $H_1$ is normal in $G_1$, $H_2$ is also normal in $G_2$. I'm unsure how to proceed from here though, can someone give me a hint?
",jstnchng,https://math.stackexchange.com/users/185638,"This only holds if $ψ^{-1}(H_2)=H_1$, then use the isomorphism theorem:

$G_1 \to G_2 \to G_2/H_2$ is surjective. The kernel of the composition is then $H_1$. Now apply the isomorphism theorem and you're done.

Otherwise you could take for example $Z\times Z \to Z$ by $(1,1)\mapsto 1$ then the kernel is generated by $(1,-1)$ and you could take $H_1 = 0 \times Z$, but $Z \neq 0$.
",Daniel Valenzuela,https://math.stackexchange.com/users/156302,http://math.stackexchange.com/questions/986251/isomorphism-between-quotient-groups-with-normal-subgroups,SCIENCE,math.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.6666666666666666,0.3333333333333333,0.3333333333333333,1.0,Isomorphism of quotient groups of normal subgroups,"I'm looking at a problem in my textbook and it says:

Let $ψ : G_1 → G_2$ be a surjective group homomorphism. Let $H_1$ be a normal subgroup of $G_1$ and suppose that $ψ(H_1) = H_2$. Prove or disprove that $G_1/H_1$ is isomorphic $G_2/H_2$.

So far, I know that since $H_1$ is normal in $G_1$, $H_2$ is also normal in $G_2$. I'm unsure how to proceed from here though, can someone give me a hint?
","This only holds if $ψ^{-1}(H_2)=H_1$, then use the isomorphism theorem:

$G_1 \to G_2 \to G_2/H_2$ is surjective. The kernel of the composition is then $H_1$. Now apply the isomorphism theorem and you're done.

Otherwise you could take for example $Z\times Z \to Z$ by $(1,1)\mapsto 1$ then the kernel is generated by $(1,-1)$ and you could take $H_1 = 0 \times Z$, but $Z \neq 0$.
"
3608,3608,5760,iPhone app - Persistent hamburger menu vs last page visited,"I'm wondering which option is best for an iPhone app using a hamburger menu (placed at the top left):


The menu is persistent on every single page even when the user goes
to a sub-level.
When the user goes to a sub-level, the hamburger menu is replaced by a back button or a button whose label is the name of last page visited.
Both. The menu is persistent on every page and a back button appears when needed.


Thanks for your help :)
",Leo,https://ux.stackexchange.com/users/25518,"Use ""back"" button on sub-level pages and make menu accessible for the users with swipe gesture on all pages.
",matejceh,https://ux.stackexchange.com/users/62898,http://ux.stackexchange.com/questions/74551/iphone-app-persistent-hamburger-menu-vs-last-page-visited,TECHNOLOGY,ux.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.0,0.0,0.8888888888888888,IPhone app - persistent hamburger menu vs. last visited page,"I'm wondering which option is best for an iPhone app using a hamburger menu (placed at the top left):


The menu is persistent on every single page even when the user goes
to a sub-level.
When the user goes to a sub-level, the hamburger menu is replaced by a back button or a button whose label is the name of last page visited.
Both. The menu is persistent on every page and a back button appears when needed.


Thanks for your help :)
","Use ""back"" button on sub-level pages and make menu accessible for the users with swipe gesture on all pages.
"
528,528,832,What Defines Opponent Behaviour in 'Quick Battle'?,"When I play the 'quick battle' offline mode of Soul Calibur V, I get the impression that I'm fighting real player's characters being controlled by the game's AI, based on the character names, and costumes.  Some of these characters behave wildly different from one another, to the point that it almost feels like I'm fighting actual human players (impossible, as I don't have Xbox Live Gold). Some of these characters are much more 'skilled' than others, as well.

What defines the behaviour of someone's character in quick-play mode?  Does the game 'watch' them play, and then try to use the same combos the player used in their games?
",GnomeSlice,https://gaming.stackexchange.com/users/3114,"No the Ai sets a difficulty and the characters you face are not other people's cumstomized characters its precreated characters made by the developers. Like the developer of Tekken has created his own character in there aswell which is useing Devel-Jin's moveset. 

Difficulty however is set by the Ai you can see the difficulty by looking at the rank at the character your facing. Ofcourse the original characters have the best titels and the hardest difficulty. 

However the hardest Ai becomes so futile to fight against cause it pretty much fights acordingly to your fighting style preventing you from doing almost anything, you can never win by the same move cause the Ai knows what to do to counter, so basicly the Ai is set by your previous fights, not others.
",Zargon,https://gaming.stackexchange.com/users/21633,http://gaming.stackexchange.com/questions/52979/what-defines-opponent-behaviour-in-quick-battle,CULTURE,gaming.stackexchange.com,0.7777777777777778,0.8888888888888888,0.0,1.0,0.6666666666666666,1.0,0.7777777777777778,0.3333333333333333,0.6666666666666666,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,1.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,0.8888888888888888,"What defines adversary behavior in ""fast combat""?","When I play the ""fast fight"" offline mode of soul caliber V, I get the impression that I am fighting the real player's role, controlled by the game's AI, based on character names and costumes. Some of the characters behave so differently that it almost feels like I'm fighting real human players (impossible, because I don't have Xbox LIVE gold). Some of these characters are also ""more proficient"" than others.","No the Ai sets a difficulty and the characters you face are not other people's cumstomized characters its precreated characters made by the developers. Like the developer of Tekken has created his own character in there aswell which is useing Devel-Jin's moveset. 

Difficulty however is set by the Ai you can see the difficulty by looking at the rank at the character your facing. Ofcourse the original characters have the best titels and the hardest difficulty. 

However the hardest Ai becomes so futile to fight against cause it pretty much fights acordingly to your fighting style preventing you from doing almost anything, you can never win by the same move cause the Ai knows what to do to counter, so basicly the Ai is set by your previous fights, not others.
"
3476,3476,5543,What is the best introductory Bayesian statistics textbook?,"Which is the best introductory textbook for Bayesian statistics?

One book per answer, please.
",Shane,https://stats.stackexchange.com/users/5,"Sivia and Skilling, Data analysis: a Bayesian tutorial (2ed) 2006 246p 0198568320
books.goo:


  Statistics lectures have been a source
  of much bewilderment and frustration
  for generations of students. This book
  attempts to remedy the situation by
  expounding a logical and unified
  approach to the whole subject of data
  analysis. This text is intended as a
  tutorial guide for senior
  undergraduates and research students
  in science and engineering ...


I don't know the other recommendations though.
",denis,https://stats.stackexchange.com/users/557,http://stats.stackexchange.com/questions/125/what-is-the-best-introductory-bayesian-statistics-textbook,SCIENCE,stats.stackexchange.com,1.0,1.0,0.0,1.0,1.0,1.0,0.5,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.8333333333333334,1.0,0.6666666666666666,1.0,1.0,0.8,0.0,0.0,0.6666666666666666,1.0,What is the best introduction to Bayesian statistics?,Which is the best introduction to Bayesian statistics?,"Sivia and Skilling, Data analysis: a Bayesian tutorial (2ed) 2006 246p 0198568320
books.goo:


  Statistics lectures have been a source
  of much bewilderment and frustration
  for generations of students. This book
  attempts to remedy the situation by
  expounding a logical and unified
  approach to the whole subject of data
  analysis. This text is intended as a
  tutorial guide for senior
  undergraduates and research students
  in science and engineering ...


I don't know the other recommendations though.
"
3685,3685,5874,Should I avoid credit card use to improve our debt-to-income ratio?,"We put all our expenses on a credit card and pay it off every month in order to get maximize our cash back.  We never charge more than we have in the checking account, so we always pay it off.  Should we reconsider doing this in order to improve our debt-to-income ratio?

Our goal is to be in the best position possible to get a mortgage in the next 3-12 months.
",JHFB,https://money.stackexchange.com/users/6182,"For scoring purposes, having a DTI between 1-19% is ideal. 

From Credit Karma:



That being said, depending on the loan type you looking at receiving (FHA, VA, Conventional, etc), there are certain max DTIs that you want to stay away from. As a rule, for VA, you want to try to stay away from 41% DTI. Exceptions are made for people with sufficient funds in the bank (3-9 months) to go to higher DTIs. If you keep a 19% utilization overall, that will get you a higher score but it will also show that you have a monthly payment on a particular revolving credit account. While the difference between 729 and 745 seems like a lot of points, there are rules as to how the interest rates are determined. So you will find that many banks have the same or similar rates due to recent legislation in Dodd-Frank. In the days of subprime mortgages, this was not the case. Adjustable rate mortgages did not necessarily go away, the servicer just has to make sure that the buyer can weather the full amount once it reaches maturity, not the lower amount. That is what got a lot of people in trouble.

From ""how interest rates are set"":


  Before quoting you an interest rate, the loan officer will add on how
  much he and his branch want to earn. The branch or company sets a
  policy on how little that can be (the minimum amount the loan officer
  adds on to his cost) but does not want to overcharge borrowers either
  (so they set a maximum the loan officer can charge) Between that
  minimum and maximum, the loan officer has a great deal of flexibility.
  
  For example, say the loan officer decides he and his branch are going
  to earn one point. When you call and ask for a rate quote, he will add
  one point to the cost of the loan and quote you that rate. According
  to the rate sheet above, seven percent will cost you zero points. Six
  and three-quarters percent will cost you one point.
  
  In our example, at 7.125% the loan officer and branch would earn one
  point and have some money left over. This could be used to pay some of
  the fees (processing, documents, etc), which is how you get a ""no fees
  -no points"" mortgage. You just pay a higher interest rate.


Where this scoring helps you is in credit card interest rates and auto loan and personal loan rates, which have different rate structures. 

My personal opinion is to avoid the use of the credit cards. Playing games to try to maximize your score in this situation won't help you when you are talking about 20 points potentially. If you were at the bottom level and were trying to meet a minimum score to qualify, then I would recommend you try to game this scoring system. Take the extra money you would put on a credit card and save it for housing expenses. Taking the Dave Ramsey approach, you should have at least $1000 in emergency funds as most problems you encounter will be less than $1000. That advice rings true. 
",Brian,https://money.stackexchange.com/users/897,http://money.stackexchange.com/questions/30939/should-i-avoid-credit-card-use-to-improve-our-debt-to-income-ratio,LIFE_ARTS,money.stackexchange.com,1.0,0.8888888888888888,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.7777777777777778,0.8888888888888888,0.0,0.0,1.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8,0.0,0.0,1.0,1.0,Should I avoid using credit cards to increase our debt to income ratio?,"We spend all our expenses on credit cards and pay them monthly to maximize our cash. We never charge more than a checking account, so we always pay it off. Should we reconsider this to improve our debt to income ratio?","For scoring purposes, having a DTI between 1-19% is ideal. 

From Credit Karma:



That being said, depending on the loan type you looking at receiving (FHA, VA, Conventional, etc), there are certain max DTIs that you want to stay away from. As a rule, for VA, you want to try to stay away from 41% DTI. Exceptions are made for people with sufficient funds in the bank (3-9 months) to go to higher DTIs. If you keep a 19% utilization overall, that will get you a higher score but it will also show that you have a monthly payment on a particular revolving credit account. While the difference between 729 and 745 seems like a lot of points, there are rules as to how the interest rates are determined. So you will find that many banks have the same or similar rates due to recent legislation in Dodd-Frank. In the days of subprime mortgages, this was not the case. Adjustable rate mortgages did not necessarily go away, the servicer just has to make sure that the buyer can weather the full amount once it reaches maturity, not the lower amount. That is what got a lot of people in trouble.

From ""how interest rates are set"":


  Before quoting you an interest rate, the loan officer will add on how
  much he and his branch want to earn. The branch or company sets a
  policy on how little that can be (the minimum amount the loan officer
  adds on to his cost) but does not want to overcharge borrowers either
  (so they set a maximum the loan officer can charge) Between that
  minimum and maximum, the loan officer has a great deal of flexibility.
  
  For example, say the loan officer decides he and his branch are going
  to earn one point. When you call and ask for a rate quote, he will add
  one point to the cost of the loan and quote you that rate. According
  to the rate sheet above, seven percent will cost you zero points. Six
  and three-quarters percent will cost you one point.
  
  In our example, at 7.125% the loan officer and branch would earn one
  point and have some money left over. This could be used to pay some of
  the fees (processing, documents, etc), which is how you get a ""no fees
  -no points"" mortgage. You just pay a higher interest rate.


Where this scoring helps you is in credit card interest rates and auto loan and personal loan rates, which have different rate structures. 

My personal opinion is to avoid the use of the credit cards. Playing games to try to maximize your score in this situation won't help you when you are talking about 20 points potentially. If you were at the bottom level and were trying to meet a minimum score to qualify, then I would recommend you try to game this scoring system. Take the extra money you would put on a credit card and save it for housing expenses. Taking the Dave Ramsey approach, you should have at least $1000 in emergency funds as most problems you encounter will be less than $1000. That advice rings true. 
"
5875,5875,9309,nm: how to show object file of a symbol in a shared library?,"I have 25 object files which are combined to form one shared library. I have generated the shared library with gcc and while I was looking for exposed symbols with nm -D libmylib.so, I found two undesirable exposed symbols with the name of i and y which are in .bss section. I have tried to find them in my source files but i cant find them so if anyone can tell me whether there is some way to find that which .o file exactly has these undesired exposed symbols? Can I do it with nm or do I need another tool?

Any help would be appreciated.
",Jewel Thief,https://stackoverflow.com/users/495590,"Once the shared library is linked, you can no longer tell which parts of it came from which object file.

You can search the individual objects from which you build the library:

find . -name '*.o' -print0 | xargs -0 nm -A | egrep ' (i|y)$'


You can ask the linker to tell you when they are defined:

$(CC) -fPIC -shared -o libmy.so $(OBJS) -Wl,-y,i,-y,y


If you built the library from objects compiled with -g, you may ask GDB where i and y came from:

gdb -q libmy.so
(gdb) info var ^i$
(gdb) info var ^y$

",Employed Russian,https://stackoverflow.com/users/50617,http://stackoverflow.com/questions/13365347/nm-how-to-show-object-file-of-a-symbol-in-a-shared-library,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.5555555555555556,0.0,1.0,1.0,1.0,0.4444444444444444,0.4444444444444444,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,1.0,0.3333333333333333,0.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.3333333333333333,1.0,0.8888888888888888,Nm: how to display symbol object files in shared libraries?,"I have 25 object files combined into a shared library. I've generated a shared library with GCC, and when I look for public symbols with nm-d libmylib.so, I find two unpopular public symbols named I and Y in the. BSS section. I tried to find them in my source file, but I couldn't find them, so if someone could tell me if there was some way to find which. O file exactly had these unwanted exposure symbols? Can I use nanometers or do I need another tool?","Once the shared library is linked, you can no longer tell which parts of it came from which object file.

You can search the individual objects from which you build the library:

find . -name '*.o' -print0 | xargs -0 nm -A | egrep ' (i|y)$'


You can ask the linker to tell you when they are defined:

$(CC) -fPIC -shared -o libmy.so $(OBJS) -Wl,-y,i,-y,y


If you built the library from objects compiled with -g, you may ask GDB where i and y came from:

gdb -q libmy.so
(gdb) info var ^i$
(gdb) info var ^y$

"
3676,3676,5860,Setting up a food pantry/orphanage?,"I can't find much on how to set up any kind of establishments that are for charity. HOw would I go about this? Acquiring a building, a few volunteers, how much to run it per day, ect? Anyone have any experience in this? My character is a NG Druid, who had never been to a city and saw the poverty and lack of food and housing for people. He wants to help! But I have no idea on how to establish a continual act of help. Buying food for the town and stuff, one time is easy to figure out. How many people * ammount of food needed is the price. But for bigger acts of continual charity, who knows? 

EDIT:
So, it was suggested that I make an eco orphanage in a forest. I accidently doomed the continent with demons, so that won't work. (Wish spell to get rid of orcs, things went horribly wrong) NO one knows it was me though! :D 

I don't want the leadership feat cause I need my 6th level feat for a prestige class.

Also, I don't want to donate to the churches in this city, I'm finding a lot of corruption in some of these churches, especially this city, so I want something more controllable by me. 
",samuraiseoul,https://rpg.stackexchange.com/users/10381,"Strangely enough I recommend taking the Leadership feat once you reach the proper level and all the followers you get would be dedicated to the running of the building but that might come off a bit heavy handed.  

After all, diplomacy and profession checks when buying regular supplies (in bulk?) would be the way to go and then it really depends on the economy of the world your DM created.  Are there bulk rates? What availability is there at those numbers? Moreover, your DM has to determine what demand is going to be had for your services and thus the whole supply/demand issue comes into play in any realistic game.  

For example, just going with core information, it's 5sp for one days worth of good quality food.  3sp for common quality, and 1sp for poor.  That's standard price for one person.  Nothing however stops you from haggling via Diplomacy. Profession(Host) or something like that would raise you money.

As for building houses, I refer to this question and this one as well which point you to the Stronghold Builder's Guide for the prices of construction of any type of structure, although comparing to the ship costs, a small house would likely cost 5k-10k in gp.

Edit 1: Another issue you may face with a stationary location is bandits, vermin, and/or spoilage as depreciation factors thus putting good money to waste.  Especially if you buy a cheaper product.

Edit 2: 
 - In SBG, it says a basic residential 'stronghold' is 12k in gp for a 30 person building complete with two kitchen servants (6gp a month salary).
 - A basic Tavern seats 20 if you want to do a ""soup kitchen"" for only 900gp, same servant price.

If you find a copy of this book (I found a readable PDF with a basic search) it breaks down what each room costs for a building in a table on SBG page 15 as a modular system for a larger stronghold/castle/keep/etc. but essentially parts of it can easily be their own buildings or parts of more commonplace structures.
",CatLord,https://rpg.stackexchange.com/users/3273,http://rpg.stackexchange.com/questions/32292/setting-up-a-food-pantry-orphanage,CULTURE,rpg.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,1.0,0.6666666666666666,1.0,0.6666666666666666,0.4444444444444444,0.3333333333333333,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.3333333333333333,0.3333333333333333,1.0,Food storage / orphanage?,"I can't find much on how to set up any kind of establishments that are for charity. HOw would I go about this? Acquiring a building, a few volunteers, how much to run it per day, ect? Anyone have any experience in this? My character is a NG Druid, who had never been to a city and saw the poverty and lack of food and housing for people. He wants to help! But I have no idea on how to establish a continual act of help. Buying food for the town and stuff, one time is easy to figure out. How many people * ammount of food needed is the price. But for bigger acts of continual charity, who knows? 

EDIT:
So, it was suggested that I make an eco orphanage in a forest. I accidently doomed the continent with demons, so that won't work. (Wish spell to get rid of orcs, things went horribly wrong) NO one knows it was me though! :D 

I don't want the leadership feat cause I need my 6th level feat for a prestige class.

Also, I don't want to donate to the churches in this city, I'm finding a lot of corruption in some of these churches, especially this city, so I want something more controllable by me. 
","Strangely enough I recommend taking the Leadership feat once you reach the proper level and all the followers you get would be dedicated to the running of the building but that might come off a bit heavy handed.  

After all, diplomacy and profession checks when buying regular supplies (in bulk?) would be the way to go and then it really depends on the economy of the world your DM created.  Are there bulk rates? What availability is there at those numbers? Moreover, your DM has to determine what demand is going to be had for your services and thus the whole supply/demand issue comes into play in any realistic game.  

For example, just going with core information, it's 5sp for one days worth of good quality food.  3sp for common quality, and 1sp for poor.  That's standard price for one person.  Nothing however stops you from haggling via Diplomacy. Profession(Host) or something like that would raise you money.

As for building houses, I refer to this question and this one as well which point you to the Stronghold Builder's Guide for the prices of construction of any type of structure, although comparing to the ship costs, a small house would likely cost 5k-10k in gp.

Edit 1: Another issue you may face with a stationary location is bandits, vermin, and/or spoilage as depreciation factors thus putting good money to waste.  Especially if you buy a cheaper product.

Edit 2: 
 - In SBG, it says a basic residential 'stronghold' is 12k in gp for a 30 person building complete with two kitchen servants (6gp a month salary).
 - A basic Tavern seats 20 if you want to do a ""soup kitchen"" for only 900gp, same servant price.

If you find a copy of this book (I found a readable PDF with a basic search) it breaks down what each room costs for a building in a table on SBG page 15 as a modular system for a larger stronghold/castle/keep/etc. but essentially parts of it can easily be their own buildings or parts of more commonplace structures.
"
1200,1200,1884,StackOverflow code snippet horizontal scrolling broken WebKit,"Seems the problem is localized to WebKit

Anybody else notice this?

All code snippets, not just a particular post;

http://stackoverflow.com/questions/2350874/ysod-yellow-screen-of-death-javascript-regexp-syntax-error

http://stackoverflow.com/questions/2481664/pass-array-to-client-side-for-display/2483402#2483402

are just a couple..
",Sky Sanders,https://meta.stackexchange.com/users/144906,"I made the word-wrap: break-word; style apply to the child &lt;p&gt; element of .post-text rather than the whole thing.
",Jeff Atwood,https://meta.stackexchange.com/users/1,http://meta.stackexchange.com/questions/43039/stackoverflow-code-snippet-horizontal-scrolling-broken-webkit,TECHNOLOGY,meta.stackexchange.com,0.7777777777777778,0.6666666666666666,0.0,0.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,1.0,Stackoverflow code snippet horizontal scrolling broken WebKit,"Seems the problem is localized to WebKit

Anybody else notice this?

All code snippets, not just a particular post;

http://stackoverflow.com/questions/2350874/ysod-yellow-screen-of-death-javascript-regexp-syntax-error

http://stackoverflow.com/questions/2481664/pass-array-to-client-side-for-display/2483402#2483402

are just a couple..
","I made the word-wrap: break-word; style apply to the child &lt;p&gt; element of .post-text rather than the whole thing.
"
3129,3129,4983,Alternatives of 'a snowball's chance in hell',"I am looking for a different, common English idiom that expresses the same thing as a snowball's chance in hell.  My teacher says I use this expression too much, and that it is not appropriate for every essay. I need a same meaning like something very cold in a hot place to have a little chance.
",The Beefer Fan,https://english.stackexchange.com/users/83537,"If You're in the Northern Hemisphere, ""... a blizzard in July""; if you're in the Southern Hemisphere, change ""July"" to ""January"". But I have a hunch that if you use the same idiomatic expression in every essay, adding one, two, or even three alternatives into a rotation is not going to satisfy the teacher for very long. Any of the likely alternatives to the idiom are going to be somewhat informal, so in more formal writing you might want to use a phrase like ""highly unlikley"" or some of the choices of Armen.
",brasshat,https://english.stackexchange.com/users/78569,http://english.stackexchange.com/questions/184377/alternatives-of-a-snowballs-chance-in-hell,CULTURE,english.stackexchange.com,1.0,1.0,0.3333333333333333,1.0,0.6666666666666666,0.0,0.7777777777777778,1.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.8888888888888888,1.0,1.0,1.0,1.0,0.9333333333333332,0.0,0.0,0.6666666666666666,1.0,"Alternative to ""snowball opportunity in hell""","I am looking for a different, common English idiom that expresses the same thing as snowball opportunities in hell. My teacher said that I used the word too much, not suitable for every article. I need a bit of opportunity for something that means the same, like being cold in a hot place.","If You're in the Northern Hemisphere, ""... a blizzard in July""; if you're in the Southern Hemisphere, change ""July"" to ""January"". But I have a hunch that if you use the same idiomatic expression in every essay, adding one, two, or even three alternatives into a rotation is not going to satisfy the teacher for very long. Any of the likely alternatives to the idiom are going to be somewhat informal, so in more formal writing you might want to use a phrase like ""highly unlikley"" or some of the choices of Armen.
"
3033,3033,4833,What should I look for in a recording microphone for personal use?,"I was browsing through mics on Amazon and quickly realized I was out of my depth.  There are a couple closely related questions I am wondering about:


Are there different types of mics for (1) singing into at a concert, (2) singing into in a quiet room, and (3) picking up sound at more of a distance (e.g., singing and playing guitar and having both recorded with the one mic)?  What are they?
I'm most interested in a mic for case (3).  This is obviously not professional, I just want something with passable quality and not too much noise considering I'll be in a random room in a house or apartment.  What kind of things should I look for in a mic to achieve that?  What are the factors that most depend on price?  (If it's feasible I'd like to try to fit it into my $50 contest reward.)
There are a few terms I saw like ""moving coil"", ""condenser"", and ""dynamic"" that I saw used to describe mics.  If you could touch on these and any other relevant terminology that would be awesome.

",Matthew Read,https://music.stackexchange.com/users/28,"Guitar-and-vocal studio and live micing has been studied heavily, yet while there are a lot of recommendations, perhaps the foremost among them is ""experiment"". Now, that advice is generally aimed at the professional recording engineer or home studio enthusiast, with a locker full of microphones to choose from. Someone looking to buy their first mike, like yourself, is going to need a good way forward, so the mikes you buy will be well-suited to the task.

Probably the most common technique for studio recording of a guitar, because it's very simple, is to take one large-diaphragm side-address cardioid condenser microphone, like an AT4040 (about $300, well-known and respected among pros), and position it between 6 inches and a foot away from the guitar, pointed somewhere between the neck/body joint and the octave marker on the fretboard:



This is a single ""close-mic"" approach; it'll get you a bit of everything, from the actual strings' brightness to the deep resonance of the body chamber, to the sounds of you actually playing the thing, moving your hands and fingers around. You can experiment with exactly where the mic is; in the image, it's moved up in the direction of the neck, but still pointed at the neck/body joint. This gets the mic out of the way of the performer and anyone who may be watching his hands.

You can do the same thing with a small-diaphragm condenser as well, but the large-diaphragm will be more sensitive, so you can back it away and reduce the proximity effect and the amount of string noise, while still getting a sound that fills your ear instead of sounding like the microphone's all the way across the room.

Another very common technique is the XY-pair. This approach is designed to mimic the way your ears would hear the guitar if you stood in front of it. Same basic placement, but instead of one large-diaphragm condenser, use two small-diaphragm ""cigar mikes"", like Rode NT5s ($430 for a matched pair; generally well-liked in their price range though there are many others to choose from), arranged at 90* to each other and 45* offset from whatever you're pointing it at:



This arrangement is the most straightforward way to get a stereo recording of just about anything; one mike is your left ear, the other is your right, and there will be a natural amount of crossover between the two, which you can play with using the channels' pan knobs on the mixer to create a ""wide"" (""left"" mic panned hard left, ""right"" mic panned hard right) or ""narrow"" ( both mics close to center) stereo image.

The nice thing about either of these setups is that these mikes are just as good for the human voice as they are for guitar; they need to capture all the same frequencies in about the same overall balance, at about the same dynamic levels. So, once you have the mikes positioned well for the guitar, just start singing, and make minute adjustments as needed to get more or less of your voice. 

You can provide another condenser of just about any type (side-address, handheld, cigar) specifically for vocals. However, caveat soundman; first, the more mikes you have, the more effort you spend and the less success you have isolating their sound sources (the vocal mike will pick up some guitar and the guitar mike will pick up some vocals). Second, more mikes == more $$$. I'm recommending mikes that are expensive but a good value; you want these mikes, and not their cheaper lookalikes, but the money will mean that you get fewer of them, so I'm encouraging you to use fewer mikes for more purposes, instead of buying a cheap-sounding mike to point at everything you might ever want to record separately.

There are other, slightly more esoteric setups for micing. You may hear of the ""mid-side"" setup; it's one cardioid cigar mike pointed at the neck joint, with a second side-address mic with a ""figure-8"" pattern right underneath or behind it, with the travel of the diaphragm positioned parallel to the fretboard. The figure-8 pattern mic's signal is then split into two channels, one out-of-phase with the other, and when you bring it all back together in the mixer, the result is a stereo image that you can ""narrow"" or ""widen"" by adjusting the out-of-phase channel's fader. Other setups find ""sweet spots"" on the surface of the guitar's soundboard and close-mic them with cigar mikes, or seek to capture what the guitarist hears from his/her instrument with an ""over-the-shoulder"" mic (hey, if the guitar didn't sound good to you while you played it in the store, you wouldn't have bought it, right?), all very similar to approaches seen for other instruments.

Exactly what you want to do will determine the mics you will want to use to do it. Personally, I would go with a pair of cigar mikes, because they're extremely versatile; they can go places a larger mike can't, and you can point them at almost anything and get a good sound. Most of the common mic setups use at least one cigar mic. In addition, they're commonly used for all sorts of acoustic instrument recording, from guitars to solo strings and winds, and they also work well for drums. 

The side-address condenser would have many of the same purposes, but with only one mic, you're recording in mono; however, that same single mike would be better than the cigar mikes for solo voice in a studio environment, and many side-address mikes can be set to different response patterns such as cardioid, figure-8 or omni. So, if you want one single do-it-all for home recording, I'd choose a side-address.

Now, for live amplification, these same techniques won't be as useful; they may still work if you're careful, but a sensitive studio condenser mic will start giving you problems when you put it in the same room as the speakers hooked up to the mixer. Such is the nature of live sound; your subject is no longer sitting in an isolated, reverb-dampened booth, but on an open stage, with main and monitor speakers, and the walls of the venue, sending his sound right back at him. In these situations, usually a sound engineer's primary concern is getting the volume he needs out of the mains without feedback, and that means rejecting ""off-axis"" sound sources using narrower mic response patterns like cardioid/supercardioid, or less sensitive microphones like dynamic mikes or small-diaphragm condensers as compared to side-address mikes.
",KeithS,https://music.stackexchange.com/users/766,http://music.stackexchange.com/questions/8312/what-should-i-look-for-in-a-recording-microphone-for-personal-use,LIFE_ARTS,music.stackexchange.com,1.0,0.7777777777777778,0.0,0.3333333333333333,0.3333333333333333,0.0,0.7777777777777778,0.7777777777777778,0.6666666666666666,0.0,1.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,1.0,1.0,0.8888888888888888,1.0,1.0,0.9333333333333332,0.3333333333333333,0.0,0.3333333333333333,1.0,What should I find in the recording microphone for personal use?,"I was browsing through mics on Amazon and quickly realized I was out of my depth.  There are a couple closely related questions I am wondering about:


Are there different types of mics for (1) singing into at a concert, (2) singing into in a quiet room, and (3) picking up sound at more of a distance (e.g., singing and playing guitar and having both recorded with the one mic)?  What are they?
I'm most interested in a mic for case (3).  This is obviously not professional, I just want something with passable quality and not too much noise considering I'll be in a random room in a house or apartment.  What kind of things should I look for in a mic to achieve that?  What are the factors that most depend on price?  (If it's feasible I'd like to try to fit it into my $50 contest reward.)
There are a few terms I saw like ""moving coil"", ""condenser"", and ""dynamic"" that I saw used to describe mics.  If you could touch on these and any other relevant terminology that would be awesome.

","Guitar-and-vocal studio and live micing has been studied heavily, yet while there are a lot of recommendations, perhaps the foremost among them is ""experiment"". Now, that advice is generally aimed at the professional recording engineer or home studio enthusiast, with a locker full of microphones to choose from. Someone looking to buy their first mike, like yourself, is going to need a good way forward, so the mikes you buy will be well-suited to the task.

Probably the most common technique for studio recording of a guitar, because it's very simple, is to take one large-diaphragm side-address cardioid condenser microphone, like an AT4040 (about $300, well-known and respected among pros), and position it between 6 inches and a foot away from the guitar, pointed somewhere between the neck/body joint and the octave marker on the fretboard:



This is a single ""close-mic"" approach; it'll get you a bit of everything, from the actual strings' brightness to the deep resonance of the body chamber, to the sounds of you actually playing the thing, moving your hands and fingers around. You can experiment with exactly where the mic is; in the image, it's moved up in the direction of the neck, but still pointed at the neck/body joint. This gets the mic out of the way of the performer and anyone who may be watching his hands.

You can do the same thing with a small-diaphragm condenser as well, but the large-diaphragm will be more sensitive, so you can back it away and reduce the proximity effect and the amount of string noise, while still getting a sound that fills your ear instead of sounding like the microphone's all the way across the room.

Another very common technique is the XY-pair. This approach is designed to mimic the way your ears would hear the guitar if you stood in front of it. Same basic placement, but instead of one large-diaphragm condenser, use two small-diaphragm ""cigar mikes"", like Rode NT5s ($430 for a matched pair; generally well-liked in their price range though there are many others to choose from), arranged at 90* to each other and 45* offset from whatever you're pointing it at:



This arrangement is the most straightforward way to get a stereo recording of just about anything; one mike is your left ear, the other is your right, and there will be a natural amount of crossover between the two, which you can play with using the channels' pan knobs on the mixer to create a ""wide"" (""left"" mic panned hard left, ""right"" mic panned hard right) or ""narrow"" ( both mics close to center) stereo image.

The nice thing about either of these setups is that these mikes are just as good for the human voice as they are for guitar; they need to capture all the same frequencies in about the same overall balance, at about the same dynamic levels. So, once you have the mikes positioned well for the guitar, just start singing, and make minute adjustments as needed to get more or less of your voice. 

You can provide another condenser of just about any type (side-address, handheld, cigar) specifically for vocals. However, caveat soundman; first, the more mikes you have, the more effort you spend and the less success you have isolating their sound sources (the vocal mike will pick up some guitar and the guitar mike will pick up some vocals). Second, more mikes == more $$$. I'm recommending mikes that are expensive but a good value; you want these mikes, and not their cheaper lookalikes, but the money will mean that you get fewer of them, so I'm encouraging you to use fewer mikes for more purposes, instead of buying a cheap-sounding mike to point at everything you might ever want to record separately.

There are other, slightly more esoteric setups for micing. You may hear of the ""mid-side"" setup; it's one cardioid cigar mike pointed at the neck joint, with a second side-address mic with a ""figure-8"" pattern right underneath or behind it, with the travel of the diaphragm positioned parallel to the fretboard. The figure-8 pattern mic's signal is then split into two channels, one out-of-phase with the other, and when you bring it all back together in the mixer, the result is a stereo image that you can ""narrow"" or ""widen"" by adjusting the out-of-phase channel's fader. Other setups find ""sweet spots"" on the surface of the guitar's soundboard and close-mic them with cigar mikes, or seek to capture what the guitarist hears from his/her instrument with an ""over-the-shoulder"" mic (hey, if the guitar didn't sound good to you while you played it in the store, you wouldn't have bought it, right?), all very similar to approaches seen for other instruments.

Exactly what you want to do will determine the mics you will want to use to do it. Personally, I would go with a pair of cigar mikes, because they're extremely versatile; they can go places a larger mike can't, and you can point them at almost anything and get a good sound. Most of the common mic setups use at least one cigar mic. In addition, they're commonly used for all sorts of acoustic instrument recording, from guitars to solo strings and winds, and they also work well for drums. 

The side-address condenser would have many of the same purposes, but with only one mic, you're recording in mono; however, that same single mike would be better than the cigar mikes for solo voice in a studio environment, and many side-address mikes can be set to different response patterns such as cardioid, figure-8 or omni. So, if you want one single do-it-all for home recording, I'd choose a side-address.

Now, for live amplification, these same techniques won't be as useful; they may still work if you're careful, but a sensitive studio condenser mic will start giving you problems when you put it in the same room as the speakers hooked up to the mixer. Such is the nature of live sound; your subject is no longer sitting in an isolated, reverb-dampened booth, but on an open stage, with main and monitor speakers, and the walls of the venue, sending his sound right back at him. In these situations, usually a sound engineer's primary concern is getting the volume he needs out of the mains without feedback, and that means rejecting ""off-axis"" sound sources using narrower mic response patterns like cardioid/supercardioid, or less sensitive microphones like dynamic mikes or small-diaphragm condensers as compared to side-address mikes.
"
3527,3527,5624,How do I make certain areas editable?,"I'm new to wordpress and I'm currently converting an HTML/CSS site I made to wordpress to make it easier for my client to edit it from the admin panel.

I have provided 3 screenshots and I'll refer to them here.

The first screenshot shows how my website looks so far. It's using a template I made called homepage.php (see screenshot 3 for code). The template includes header.php which contains the logo, navigation menu etc. It has the image banner and finally includes footer.php. I want the ""Our Values"" part to be editable so that my client can change the text any time they need to. 

Currently, they can edit the top part which says ""PROtential Coaching"" and that's because it's included on the page within the admin panel and not in the template. I want the bottom part including""Our Values"" to be editable from that panel too, is there a way to do this or does this content have to be static and within the template? ""Our Values"" and ""Our People"" are in a dynamic secondary navigation menu which my client can add items to if they want to, however they can't change the content for the menu item.

Images:
http://imgur.com/yq9y8SQ,5IqOPzr,SHkzrFz

Please help me out guys, I've been looking all over the place for days to get this done.
",Jamie O'Hanlon,https://wordpress.stackexchange.com/users/31205,"These links should help you:
http://codex.wordpress.org/The_Loop

http://codex.wordpress.org/Function_Reference/wp_get_nav_menu_items

with this two techniks you can give your client the ability to change the content and the navigation. For these you have to edit your theme and insert the snippets on the placese you want to output your contents....

For the footer you can use a custom page  maybe footer 

    $loop = new WP_Query( 'pagename=footer' );
    while ( $loop-&gt;have_posts() ) : $loop-&gt;the_post();
        the_content(); 
    endwhile;

",user1606423,https://wordpress.stackexchange.com/users/19511,http://wordpress.stackexchange.com/questions/95182/how-do-i-make-certain-areas-editable,TECHNOLOGY,wordpress.stackexchange.com,1.0,0.5555555555555556,0.0,0.0,1.0,0.0,0.5555555555555556,0.5555555555555556,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,1.0,0.3333333333333333,1.0,1.0,0.6,1.0,0.0,0.0,1.0,How do I make certain areas editable?,"I'm new to wordpress and I'm currently converting an HTML/CSS site I made to wordpress to make it easier for my client to edit it from the admin panel.

I have provided 3 screenshots and I'll refer to them here.

The first screenshot shows how my website looks so far. It's using a template I made called homepage.php (see screenshot 3 for code). The template includes header.php which contains the logo, navigation menu etc. It has the image banner and finally includes footer.php. I want the ""Our Values"" part to be editable so that my client can change the text any time they need to. 

Currently, they can edit the top part which says ""PROtential Coaching"" and that's because it's included on the page within the admin panel and not in the template. I want the bottom part including""Our Values"" to be editable from that panel too, is there a way to do this or does this content have to be static and within the template? ""Our Values"" and ""Our People"" are in a dynamic secondary navigation menu which my client can add items to if they want to, however they can't change the content for the menu item.

Images:
http://imgur.com/yq9y8SQ,5IqOPzr,SHkzrFz

Please help me out guys, I've been looking all over the place for days to get this done.
","These links should help you:
http://codex.wordpress.org/The_Loop

http://codex.wordpress.org/Function_Reference/wp_get_nav_menu_items

with this two techniks you can give your client the ability to change the content and the navigation. For these you have to edit your theme and insert the snippets on the placese you want to output your contents....

For the footer you can use a custom page  maybe footer 

    $loop = new WP_Query( 'pagename=footer' );
    while ( $loop-&gt;have_posts() ) : $loop-&gt;the_post();
        the_content(); 
    endwhile;

"
5526,5526,8775,Which color to choose for food?,"I'm building an Online Food Ordering website, where users can order food from their favourite restaurants. I'm confused in selecting the colors for the website, can any one help me with it. 


Which colors should I use for website background or should I put delicious food images?
Which colors to use for the text?


I have read some article that Red, Green, Oranges are good options for food related websites.
",user92961,https://ux.stackexchange.com/users/35092,"For starters, I recommend looking at the answers to this question, which colors make you hungry as that can give you some inputs about what colors to for your site assuming you already dont have a defined branding guideline in place.

With regards to whether you should use color or pictures, that would eventually depend on the the design of the site but since the objective of your site is to allow users to order from online restaurants,your objective is to get them excited and hungry. Research has shown that pictures of food do make people hungry as quoted in this study


  Max Planck researchers have proven something scientifically for the
  first time that laypeople have always known: the mere sight of
  delicious food stimulates the appetite. A study on healthy young men
  has documented that the amount of the neurosecretory protein hormone
  ghrelin in the blood increases as a result of visual stimulation
  through images of food.


The combination of pictures and colors can help you come up with a design which should be focussed on informing users about the choices available and the primary call to action. Here are some good examples of sites who do it well by both using colors and pictures well.

Seattle - Eat 24 hours



Food panda



Quick Burp


",Mervin Johnsingh,https://ux.stackexchange.com/users/5113,http://ux.stackexchange.com/questions/44277/which-color-to-choose-for-food,TECHNOLOGY,ux.stackexchange.com,1.0,0.5555555555555556,0.0,0.6666666666666666,0.0,0.0,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.0,1.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.6666666666666666,0.7777777777777778,0.8888888888888888,1.0,0.8888888888888888,0.8666666666666666,0.0,0.0,0.6666666666666666,1.0,What color do you eat?,"I'm building an Online Food Ordering website, where users can order food from their favourite restaurants. I'm confused in selecting the colors for the website, can any one help me with it. 


Which colors should I use for website background or should I put delicious food images?
Which colors to use for the text?


I have read some article that Red, Green, Oranges are good options for food related websites.
","For starters, I recommend looking at the answers to this question, which colors make you hungry as that can give you some inputs about what colors to for your site assuming you already dont have a defined branding guideline in place.

With regards to whether you should use color or pictures, that would eventually depend on the the design of the site but since the objective of your site is to allow users to order from online restaurants,your objective is to get them excited and hungry. Research has shown that pictures of food do make people hungry as quoted in this study


  Max Planck researchers have proven something scientifically for the
  first time that laypeople have always known: the mere sight of
  delicious food stimulates the appetite. A study on healthy young men
  has documented that the amount of the neurosecretory protein hormone
  ghrelin in the blood increases as a result of visual stimulation
  through images of food.


The combination of pictures and colors can help you come up with a design which should be focussed on informing users about the choices available and the primary call to action. Here are some good examples of sites who do it well by both using colors and pictures well.

Seattle - Eat 24 hours



Food panda



Quick Burp


"
4195,4195,6689,How is this site different from Stack Overflow?,"I've decided to check this site out since it was tweeted by the great Jeff Atwood himself. The first question I saw was ""Advice on making ruby code more ruby-like"", which is the kind of question I see all the time on Stack Overflow.

So what is the difference between the questions on SO and the questions here? It seems to me there is enough overlap between the two that the difference is not clear, and I may not be alone in feeling this.  So far this site seems redundant.
",alimbada,https://meta.codereview.stackexchange.com/users/1037,"I've just asked a Perl coding question here that I would be embarrassed to put on SO. Seems to be SO is good for 'how it works' questions, whereas CR is for 'how it codes / reads / looks'.

I'm delighted, by the way, that CR has come into existence. Thanks for taking the time!
",bugmagnet,https://meta.codereview.stackexchange.com/users/520,http://meta.codereview.stackexchange.com/questions/138/how-is-this-site-different-from-stack-overflow,TECHNOLOGY,meta.codereview.stackexchange.com,0.8888888888888888,0.7777777777777778,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.0,0.4444444444444444,0.3333333333333333,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,0.6666666666666666,1.0,How is this site different from a stack overflow?,"I've decided to check this site out since it was tweeted by the great Jeff Atwood himself. The first question I saw was ""Advice on making ruby code more ruby-like"", which is the kind of question I see all the time on Stack Overflow.

So what is the difference between the questions on SO and the questions here? It seems to me there is enough overlap between the two that the difference is not clear, and I may not be alone in feeling this.  So far this site seems redundant.
","I just asked a Perl coding question here. It would be embarrassing if I said that. It seems good for the ""how it works"" problem, but good for the ""how it encodes / reads / looks"" problem."
3437,3437,5464,Combined gas law in an open atmosphere,"The question was asked about pressure vs. Volume increasing in an ideal gas as temperature is increased. My question then is this. What is the formula to determine how much volume and pressure will increase as temperature is increased?

Let me frame the question this way. PV/T=P2V2/T2 this formula works for a controlled system where more than one of these values can be maintained. If we apply a known amount of heat, say n, to the atmosphere, what formula would be used to calculate volume and pressure as the temperature is increased?
",Diamondhills,https://physics.stackexchange.com/users/27405,"At first I wanted to say that you should use the first law of thermodynamics. However both $P$, $V$ and $T$ are unknown if you would add a certain amount energy to an atmosphere.

I agree with udiboy that you should threat the atmosphere as an non-viscous fluid, which allows you to determine the pressure as a function of altitude. However for this to give an unique solution you still need to make some more assumptions, such as the temperature distribution, the molar mass of the gas, how fast the planet and atmosphere are rotating, ect.
",fibonatic,https://physics.stackexchange.com/users/23741,http://physics.stackexchange.com/questions/72613/combined-gas-law-in-an-open-atmosphere,SCIENCE,physics.stackexchange.com,1.0,0.3333333333333333,0.0,1.0,1.0,1.0,0.8888888888888888,0.5555555555555556,0.3333333333333333,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.0,0.8888888888888888,0.8888888888888888,0.5555555555555556,1.0,1.0,0.7333333333333333,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.7777777777777778,The law of combined gases in open atmosphere,"The question was asked about pressure vs. Volume increasing in an ideal gas as temperature is increased. My question then is this. What is the formula to determine how much volume and pressure will increase as temperature is increased?

Let me frame the question this way. PV/T=P2V2/T2 this formula works for a controlled system where more than one of these values can be maintained. If we apply a known amount of heat, say n, to the atmosphere, what formula would be used to calculate volume and pressure as the temperature is increased?
","At first I wanted to say that you should use the first law of thermodynamics. However both $P$, $V$ and $T$ are unknown if you would add a certain amount energy to an atmosphere.

I agree with udiboy that you should threat the atmosphere as an non-viscous fluid, which allows you to determine the pressure as a function of altitude. However for this to give an unique solution you still need to make some more assumptions, such as the temperature distribution, the molar mass of the gas, how fast the planet and atmosphere are rotating, ect.
"
1758,1758,2786,How to hide a DIV element when I click outside,"I have a div and want to hide it when I click outside. My code is:

&lt;div id=""mydiv""&gt;The div must be above button&lt;/div&gt;

    $('#mydiv').click(function(e) {
        e.stopPropagation();
    });

    $(document).click(function() {
        $('#mydiv').fadeOut(300);
    });


But it is not working for me ...

UPDATE

Full code is presented below. When I click on a button it shows a div above, so I need to hide this div when I click outside.

DEMO

&lt;div id=""but"" style=""text-align: right;""&gt;&lt;button type=""button""&gt;Show Div!&lt;/button&gt;&lt;/div&gt;
&lt;div id=""mydiv"" style=""display:none;""&gt;The div must be above button&lt;/div&gt;

$(""#but button"").click(function(){
  var pos = $(this).offset(),
      div = $(""#mydiv"");

  // Make it visible off-page so
  // we can measure it
  div.css({
    ""display"": ""block"",
    ""border"": ""1px solid black"",
    ""position"": ""absolute"",
    ""left"": -10000,
    ""top"": 0
  });

  // Move it where we want it to be
  div.css({
    ""left"": pos.left - 40,
    ""top"":  pos.top - div.height() - 10
  });
});

$('#myDiv').click(function(e) {
    e.stopPropagation();
});
$(document).click(function() {
    $('#mydiv').fadeOut(300);
});

",andys,https://stackoverflow.com/users/1139767,"Better than binding click event to document, you can use this kind of snippet:

SEE DEMO

$('#mydiv').click(function(e) {
        e.stopPropagation();
    })
    .css({outline:0})
    .focusout(function(){
         $(this).fadeOut(300);  
    }).focus();

",A. Wolff,https://stackoverflow.com/users/1414562,http://stackoverflow.com/questions/13892375/how-to-hide-a-div-element-when-i-click-outside,STACKOVERFLOW,stackoverflow.com,0.6666666666666666,0.8333333333333334,0.0,0.5,1.0,1.0,0.6666666666666666,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.5,0.0,0.0,1.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,1.0,0.8,1.0,0.0,0.0,1.0,How to hide div elements when you click external,"I have a div and want to hide it when I click outside. My code is:

&lt;div id=""mydiv""&gt;The div must be above button&lt;/div&gt;

    $('#mydiv').click(function(e) {
        e.stopPropagation();
    });

    $(document).click(function() {
        $('#mydiv').fadeOut(300);
    });


But it is not working for me ...

UPDATE

Full code is presented below. When I click on a button it shows a div above, so I need to hide this div when I click outside.

DEMO

&lt;div id=""but"" style=""text-align: right;""&gt;&lt;button type=""button""&gt;Show Div!&lt;/button&gt;&lt;/div&gt;
&lt;div id=""mydiv"" style=""display:none;""&gt;The div must be above button&lt;/div&gt;

$(""#but button"").click(function(){
  var pos = $(this).offset(),
      div = $(""#mydiv"");

  // Make it visible off-page so
  // we can measure it
  div.css({
    ""display"": ""block"",
    ""border"": ""1px solid black"",
    ""position"": ""absolute"",
    ""left"": -10000,
    ""top"": 0
  });

  // Move it where we want it to be
  div.css({
    ""left"": pos.left - 40,
    ""top"":  pos.top - div.height() - 10
  });
});

$('#myDiv').click(function(e) {
    e.stopPropagation();
});
$(document).click(function() {
    $('#mydiv').fadeOut(300);
});

","Better than binding click event to document, you can use this kind of snippet:

SEE DEMO

$('#mydiv').click(function(e) {
        e.stopPropagation();
    })
    .css({outline:0})
    .focusout(function(){
         $(this).fadeOut(300);  
    }).focus();

"
2026,2026,3231,inserting period after every 3 chars in a string,"I have this:

from __future__ import print_function

def f_comma(p_string):
   v_string = p_string
   if (type(v_string) == type(int()) or type(v_string) == type(long()) or  
       type(v_string) == type(float())):
      v_string = str(v_string)
   else:   
      l_string = list(v_string)
      for v_index in range(3, len(l_string), 4):
         l_string.insert(v_index, ',')
      v_result = ''.join(l_string)
   return (v_result)

print (f_comma('qwertyuiopaq'))


It seems that i can't figure it out why if i use a string longer than 11 chars the period stops inserting, but with only 11 chars it works fine. What i'm doing wrong in this piece?
",udarH3,https://stackoverflow.com/users/4257949,"You can insert a comma after every nth character like this:

&gt;&gt;&gt; my_str = 'qwertyuiopaq'
&gt;&gt;&gt; ','.join(my_str[i:i+3] for i in range(0, len(my_str), 3))
'qwe,rty,uio,paq'


This should work for any arbitrary length of strings too.

Edit: Written as a function in a similar style to @mhawke's answer, with an option to change the grouping/characters.

&gt;&gt;&gt; def f_comma(my_str, group=3, char=','):
...     my_str = str(my_str)
...     return char.join(my_str[i:i+group] for i in range(0, len(my_str), group))
... 
&gt;&gt;&gt; f_comma('qwertyuiopaq')
'qwe,rty,uio,paq'
&gt;&gt;&gt; f_comma('qwertyuiopaq', group=2)
'qw,er,ty,ui,op,aq'
&gt;&gt;&gt; f_comma('qwertyuiopaq', group=2, char='.')
'qw.er.ty.ui.op.aq'

",Nitzle,https://stackoverflow.com/users/1303955,http://stackoverflow.com/questions/30919275/inserting-period-after-every-3-chars-in-a-string,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.3333333333333333,0.0,1.0,1.0,0.3333333333333333,0.6666666666666666,0.5555555555555556,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.0,0.0,1.0,Inserts a period after every three characters in a string,"I have this:

from __future__ import print_function

def f_comma(p_string):
   v_string = p_string
   if (type(v_string) == type(int()) or type(v_string) == type(long()) or  
       type(v_string) == type(float())):
      v_string = str(v_string)
   else:   
      l_string = list(v_string)
      for v_index in range(3, len(l_string), 4):
         l_string.insert(v_index, ',')
      v_result = ''.join(l_string)
   return (v_result)

print (f_comma('qwertyuiopaq'))


It seems that i can't figure it out why if i use a string longer than 11 chars the period stops inserting, but with only 11 chars it works fine. What i'm doing wrong in this piece?
","You can insert a comma after every nth character like this:

&gt;&gt;&gt; my_str = 'qwertyuiopaq'
&gt;&gt;&gt; ','.join(my_str[i:i+3] for i in range(0, len(my_str), 3))
'qwe,rty,uio,paq'


This should work for any arbitrary length of strings too.

Edit: Written as a function in a similar style to @mhawke's answer, with an option to change the grouping/characters.

&gt;&gt;&gt; def f_comma(my_str, group=3, char=','):
...     my_str = str(my_str)
...     return char.join(my_str[i:i+group] for i in range(0, len(my_str), group))
... 
&gt;&gt;&gt; f_comma('qwertyuiopaq')
'qwe,rty,uio,paq'
&gt;&gt;&gt; f_comma('qwertyuiopaq', group=2)
'qw,er,ty,ui,op,aq'
&gt;&gt;&gt; f_comma('qwertyuiopaq', group=2, char='.')
'qw.er.ty.ui.op.aq'

"
4573,4573,7244,What is difference between SPContext.Current.Web.URL and SPContext.Current.Site when using SPSite object?,"SPSite spsite1=new SPSite(SPContext.Current.Web.URL);

SPSite spsite2=SPContext.Current.Site;


What is the difference and when do we decide which one to use?

I feel both give us the site collection object.

Example: SPWeb spweb=spsite1.RootWeb; will mean same as spsite2.RootWeb;  Then why are there 2 ways to do it?
",variable,https://sharepoint.stackexchange.com/users/21463,"The both site1 and site2 returns the same site collection (SPSite) object.
By calling RootWeb property on both objects, We can get the same top-level web site (SPWeb) object.

Instruction1: SPSite spsite1=new SPSite(SPContext.Current.Web.URL);

Process: If we are in subsite and we are calling the above code, first it get the current subsite web url and pass it to SPSite constructor to get the current Site Collection object.

Instruction2: SPSite spsite2 = SPContext.Current.Site;

Process: Now we are in subsite and we are calling the above code, which directly retrives the Site Collection object. There is no looking for web url parameter to get the SiteCollection.

Result:

spsite1.RootWeb and spsite2.RootWeb returns the same Top-Level web SPWeb object.

spsite1.OpenWeb() returns the subsite (SPWeb) object if we are in subsite.
spsite2.OpenWeb() returns the top-level site (SPWeb) object, even we are in subsite.

For the spsite1, we have to call dispose method to dispose the SPSite object. But for the spsite2, the sharepoint will take care on disposing of SPSite object.
",Shantha Kumar Thambidurai,https://sharepoint.stackexchange.com/users/2907,http://sharepoint.stackexchange.com/questions/95812/what-is-difference-between-spcontext-current-web-url-and-spcontext-current-site,TECHNOLOGY,sharepoint.stackexchange.com,1.0,0.7777777777777778,0.0,0.3333333333333333,1.0,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.6666666666666666,0.0,0.3333333333333333,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.3333333333333333,0.0,1.0,1.0,What is the difference between spcontext.current.web.url and spcontext.current.site when using spsite objects?,"SPSite spsite1=new SPSite(SPContext.Current.Web.URL);

SPSite spsite2=SPContext.Current.Site;


What is the difference and when do we decide which one to use?

I feel both give us the site collection object.

Example: SPWeb spweb=spsite1.RootWeb; will mean same as spsite2.RootWeb;  Then why are there 2 ways to do it?
","The both site1 and site2 returns the same site collection (SPSite) object.
By calling RootWeb property on both objects, We can get the same top-level web site (SPWeb) object.

Instruction1: SPSite spsite1=new SPSite(SPContext.Current.Web.URL);

Process: If we are in subsite and we are calling the above code, first it get the current subsite web url and pass it to SPSite constructor to get the current Site Collection object.

Instruction2: SPSite spsite2 = SPContext.Current.Site;

Process: Now we are in subsite and we are calling the above code, which directly retrives the Site Collection object. There is no looking for web url parameter to get the SiteCollection.

Result:

spsite1.RootWeb and spsite2.RootWeb returns the same Top-Level web SPWeb object.

spsite1.OpenWeb() returns the subsite (SPWeb) object if we are in subsite.
spsite2.OpenWeb() returns the top-level site (SPWeb) object, even we are in subsite.

For the spsite1, we have to call dispose method to dispose the SPSite object. But for the spsite2, the sharepoint will take care on disposing of SPSite object.
"
1207,1207,1897,How do I create a great fantasy villain that inspires the party to rally against them?,"In my early years of GMing it was simple enough to say that the badguys were evil and that was all the justification we needed.  They are attacking the village because they are evil, they are stealing the princess because they are evil, etc.

Over time, my group needs have grown to need more complicated and detailed villains. It is important to consider motives.  What is it that defines them as 'evil' to the party?  In terms of a fantasy setting, what would you consider to be an interesting villain?

What qualities make a villain that inspires your party to rally against him?  What kind of villains have worked for your games in the past?

Example:


  A member of nobility is using trade connections to move valuable pieces of art into another country that is secretly paying him quite well and is framing a member of the party to take the fall.  In addition, someone important to the party member has been taken hostage with a promise of release once they party member takes the blame for the crime.

",Maximillian,https://rpg.stackexchange.com/users/18,"An interesting villain has:


Motivations for doing what he does. There's this cliche, ""nobody thinks of themselves as evil."" That's not true for all settings, but I think it is fair to say that very few villains are just evil for the sake of cackling. So you should figure out what's driving your bad guys.
Shades of grey. The degree depends, again, on the setting and the genre. However, if you want your players to really think about the villain, there ought to be a few things about him that don't meet their expectations. Maybe the example noble wants to both make money and save the art from danger.
Reasons to interact with the characters. Faceless villains only go so far. Villains who don't talk to characters don't get very interesting -- speculation only goes so far. Interaction can be non-verbal, although that's harder. 


Rob Donoghue wrote an excellent series on this topic: Helping Players Hate the Villain; Hate the Villain, not the GM; and The Villain's Monologue.
",Bryant,https://rpg.stackexchange.com/users/24,http://rpg.stackexchange.com/questions/584/how-do-i-create-a-great-fantasy-villain-that-inspires-the-party-to-rally-against,CULTURE,rpg.stackexchange.com,0.8888888888888888,0.6666666666666666,0.0,0.0,0.0,0.0,0.6666666666666666,0.6666666666666666,1.0,0.0,1.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.8,0.0,0.6666666666666666,0.6666666666666666,1.0,How can I create a great fantasy villain to inspire the party to unite against them?,"In my early years of GMing it was simple enough to say that the badguys were evil and that was all the justification we needed.  They are attacking the village because they are evil, they are stealing the princess because they are evil, etc.

Over time, my group needs have grown to need more complicated and detailed villains. It is important to consider motives.  What is it that defines them as 'evil' to the party?  In terms of a fantasy setting, what would you consider to be an interesting villain?

What qualities make a villain that inspires your party to rally against him?  What kind of villains have worked for your games in the past?

Example:


  A member of nobility is using trade connections to move valuable pieces of art into another country that is secretly paying him quite well and is framing a member of the party to take the fall.  In addition, someone important to the party member has been taken hostage with a promise of release once they party member takes the blame for the crime.

","An interesting villain has:


Motivations for doing what he does. There's this cliche, ""nobody thinks of themselves as evil."" That's not true for all settings, but I think it is fair to say that very few villains are just evil for the sake of cackling. So you should figure out what's driving your bad guys.
Shades of grey. The degree depends, again, on the setting and the genre. However, if you want your players to really think about the villain, there ought to be a few things about him that don't meet their expectations. Maybe the example noble wants to both make money and save the art from danger.
Reasons to interact with the characters. Faceless villains only go so far. Villains who don't talk to characters don't get very interesting -- speculation only goes so far. Interaction can be non-verbal, although that's harder. 


Rob Donoghue wrote an excellent series on this topic: Helping Players Hate the Villain; Hate the Villain, not the GM; and The Villain's Monologue.
"
1973,1973,3143,Issue while deploying Spring MVC application | no matching editors or conversion strategy found,"I am facing a deployment issue while trying to deploy my application in oracle weblogic 12c server. While deploying, I get below error:

java.lang.Exception: Exception received from deployment driver. See Error Log view for more detail.
    at oracle.eclipse.tools.weblogic.server.internal.DeploymentProgressListener.watch(DeploymentProgressListener.java:190)
    at oracle.eclipse.tools.weblogic.server.internal.WlsJ2EEDeploymentHelper.deploy(WlsJ2EEDeploymentHelper.java:510)
    at oracle.eclipse.tools.weblogic.server.internal.WeblogicServerBehaviour.publishWeblogicModules(WeblogicServerBehaviour.java:1501)
    at oracle.eclipse.tools.weblogic.server.internal.WeblogicServerBehaviour.publishToServer(WeblogicServerBehaviour.java:920)
    at oracle.eclipse.tools.weblogic.server.internal.WeblogicServerBehaviour.publishOnce(WeblogicServerBehaviour.java:708)
    at oracle.eclipse.tools.weblogic.server.internal.WeblogicServerBehaviour.publish(WeblogicServerBehaviour.java:555)
    at org.eclipse.wst.server.core.model.ServerBehaviourDelegate.publish(ServerBehaviourDelegate.java:774)
    at org.eclipse.wst.server.core.internal.Server.publishImpl(Server.java:3108)
    at org.eclipse.wst.server.core.internal.Server$PublishJob.run(Server.java:345)
    at org.eclipse.core.internal.jobs.Worker.run(Worker.java:53)
Caused by: weblogic.application.ModuleException: java.lang.IllegalStateException: Cannot convert value of type [$Proxy214 implementing org.springframework.web.accept.ContentNegotiationStrategy,org.springframework.web.accept.MediaTypeFileExtensionResolver,org.springframework.aop.SpringProxy,org.springframework.aop.framework.Advised] to required type [org.springframework.web.accept.ContentNegotiationManager] for property 'contentNegotiationManager': no matching editors or conversion strategy found
    at weblogic.application.internal.ExtensibleModuleWrapper.start(ExtensibleModuleWrapper.java:140)
    at weblogic.application.internal.flow.ModuleListenerInvoker.start(ModuleListenerInvoker.java:124)
    at weblogic.application.internal.flow.ModuleStateDriver$3.next(ModuleStateDriver.java:213)
    at weblogic.application.internal.flow.ModuleStateDriver$3.next(ModuleStateDriver.java:208)
    at weblogic.application.utils.StateMachineDriver.nextState(StateMachineDriver.java:42)
    at weblogic.application.internal.flow.ModuleStateDriver.start(ModuleStateDriver.java:70)
    at weblogic.application.internal.flow.StartModulesFlow.activate(StartModulesFlow.java:24)
    at weblogic.application.internal.BaseDeployment$2.next(BaseDeployment.java:729)
    at weblogic.application.utils.StateMachineDriver.nextState(StateMachineDriver.java:42)
    at weblogic.application.internal.BaseDeployment.activate(BaseDeployment.java:258)
    at weblogic.application.internal.SingleModuleDeployment.activate(SingleModuleDeployment.java:48)
    at weblogic.application.internal.DeploymentStateChecker.activate(DeploymentStateChecker.java:165)
    at weblogic.deploy.internal.targetserver.AppContainerInvoker.activate(AppContainerInvoker.java:80)
    at weblogic.deploy.internal.targetserver.operations.AbstractOperation.activate(AbstractOperation.java:586)
    at weblogic.deploy.internal.targetserver.operations.ActivateOperation.activateDeployment(ActivateOperation.java:148)
    at weblogic.deploy.internal.targetserver.operations.ActivateOperation.doCommit(ActivateOperation.java:114)
    at weblogic.deploy.internal.targetserver.operations.AbstractOperation.commit(AbstractOperation.java:339)
    at weblogic.deploy.internal.targetserver.DeploymentManager.handleDeploymentCommit(DeploymentManager.java:846)
    at weblogic.deploy.internal.targetserver.DeploymentManager.activateDeploymentList(DeploymentManager.java:1275)
    at weblogic.deploy.internal.targetserver.DeploymentManager.handleCommit(DeploymentManager.java:442)
    at weblogic.deploy.internal.targetserver.DeploymentServiceDispatcher.commit(DeploymentServiceDispatcher.java:176)
    at weblogic.deploy.service.internal.targetserver.DeploymentReceiverCallbackDeliverer.doCommitCallback(DeploymentReceiverCallbackDeliverer.java:195)
    at weblogic.deploy.service.internal.targetserver.DeploymentReceiverCallbackDeliverer.access$100(DeploymentReceiverCallbackDeliverer.java:13)
    at weblogic.deploy.service.internal.targetserver.DeploymentReceiverCallbackDeliverer$2.run(DeploymentReceiverCallbackDeliverer.java:68)
    at weblogic.work.SelfTuningWorkManagerImpl$WorkAdapterImpl.run(SelfTuningWorkManagerImpl.java:550)
    at weblogic.work.ExecuteThread.execute(ExecuteThread.java:295)
    at weblogic.work.ExecuteThread.run(ExecuteThread.java:254)
Caused by: java.lang.IllegalStateException: Cannot convert value of type [$Proxy214 implementing org.springframework.web.accept.ContentNegotiationStrategy,org.springframework.web.accept.MediaTypeFileExtensionResolver,org.springframework.aop.SpringProxy,org.springframework.aop.framework.Advised] to required type [org.springframework.web.accept.ContentNegotiationManager] for property 'contentNegotiationManager': no matching editors or conversion strategy found

    at org.springframework.beans.TypeConverterDelegate.convertIfNecessary(TypeConverterDelegate.java:264)
    at org.springframework.beans.BeanWrapperImpl.convertIfNecessary(BeanWrapperImpl.java:450)
    at org.springframework.beans.BeanWrapperImpl.convertForProperty(BeanWrapperImpl.java:496)
    at org.springframework.beans.BeanWrapperImpl.convertForProperty(BeanWrapperImpl.java:490)
    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.convertForProperty(AbstractAutowireCapableBeanFactory.java:1437)
    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyPropertyValues(AbstractAutowireCapableBeanFactory.java:1396)
    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1132)
    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:522)
    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:461)
    at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:295)
    at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:223)
    at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:292)
    at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:194)
    at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:607)
    at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:932)
    at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:479)
    at org.springframework.web.servlet.FrameworkServlet.configureAndRefreshWebApplicationContext(FrameworkServlet.java:647)
    at org.springframework.web.servlet.FrameworkServlet.createWebApplicationContext(FrameworkServlet.java:598)
    at org.springframework.web.servlet.FrameworkServlet.createWebApplicationContext(FrameworkServlet.java:661)
    at org.springframework.web.servlet.FrameworkServlet.initWebApplicationContext(FrameworkServlet.java:517)
    at org.springframework.web.servlet.FrameworkServlet.initServletBean(FrameworkServlet.java:458)
    at org.springframework.web.servlet.HttpServletBean.init(HttpServletBean.java:138)
    at javax.servlet.GenericServlet.init(GenericServlet.java:240)
    at weblogic.servlet.internal.StubSecurityHelper$ServletInitAction.run(StubSecurityHelper.java:337)
    at weblogic.servlet.internal.StubSecurityHelper$ServletInitAction.run(StubSecurityHelper.java:288)
    at weblogic.security.acl.internal.AuthenticatedSubject.doAs(AuthenticatedSubject.java:321)
    at weblogic.security.service.SecurityManager.runAs(SecurityManager.java:120)


The main part of the exception stack trace is:

weblogic.application.ModuleException: java.lang.IllegalStateException: Cannot convert value of type [$Proxy214 implementing 
    org.springframework.web.accept.ContentNegotiationStrategy,org.springframework.web.accept.MediaTypeFileExtensionResolver,org.springframework.aop.SpringProxy,org.springframework.aop.framework.Advised] to required type 
    [org.springframework.web.accept.ContentNegotiationManager] for property 'contentNegotiationManager': no matching editors or conversion strategy found


I have not defined any 'contentNegotiationManager' in my mvc config xml. Please help!
",Ankit,https://stackoverflow.com/users/810176,"This was because I did put my AOP configuration in MVC configuration file and AOP was trying to create proxies for Spring MVC classes. Placing AOP config in a separate file solved the problem.
",Ankit,https://stackoverflow.com/users/810176,http://stackoverflow.com/questions/25175430/issue-while-deploying-spring-mvc-application-no-matching-editors-or-conversion,STACKOVERFLOW,stackoverflow.com,0.8333333333333334,0.5,0.0,1.0,1.0,1.0,0.5,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.5,1.0,0.0,0.8333333333333334,1.0,0.6666666666666666,1.0,1.0,1.0,0.5,0.5,0.5,0.8333333333333334,Problem deploying spring MVC application | no matching editor or transformation policy found,"I am facing a deployment issue while trying to deploy my application in oracle weblogic 12c server. While deploying, I get below error:

java.lang.Exception: Exception received from deployment driver. See Error Log view for more detail.
    at oracle.eclipse.tools.weblogic.server.internal.DeploymentProgressListener.watch(DeploymentProgressListener.java:190)
    at oracle.eclipse.tools.weblogic.server.internal.WlsJ2EEDeploymentHelper.deploy(WlsJ2EEDeploymentHelper.java:510)
    at oracle.eclipse.tools.weblogic.server.internal.WeblogicServerBehaviour.publishWeblogicModules(WeblogicServerBehaviour.java:1501)
    at oracle.eclipse.tools.weblogic.server.internal.WeblogicServerBehaviour.publishToServer(WeblogicServerBehaviour.java:920)
    at oracle.eclipse.tools.weblogic.server.internal.WeblogicServerBehaviour.publishOnce(WeblogicServerBehaviour.java:708)
    at oracle.eclipse.tools.weblogic.server.internal.WeblogicServerBehaviour.publish(WeblogicServerBehaviour.java:555)
    at org.eclipse.wst.server.core.model.ServerBehaviourDelegate.publish(ServerBehaviourDelegate.java:774)
    at org.eclipse.wst.server.core.internal.Server.publishImpl(Server.java:3108)
    at org.eclipse.wst.server.core.internal.Server$PublishJob.run(Server.java:345)
    at org.eclipse.core.internal.jobs.Worker.run(Worker.java:53)
Caused by: weblogic.application.ModuleException: java.lang.IllegalStateException: Cannot convert value of type [$Proxy214 implementing org.springframework.web.accept.ContentNegotiationStrategy,org.springframework.web.accept.MediaTypeFileExtensionResolver,org.springframework.aop.SpringProxy,org.springframework.aop.framework.Advised] to required type [org.springframework.web.accept.ContentNegotiationManager] for property 'contentNegotiationManager': no matching editors or conversion strategy found
    at weblogic.application.internal.ExtensibleModuleWrapper.start(ExtensibleModuleWrapper.java:140)
    at weblogic.application.internal.flow.ModuleListenerInvoker.start(ModuleListenerInvoker.java:124)
    at weblogic.application.internal.flow.ModuleStateDriver$3.next(ModuleStateDriver.java:213)
    at weblogic.application.internal.flow.ModuleStateDriver$3.next(ModuleStateDriver.java:208)
    at weblogic.application.utils.StateMachineDriver.nextState(StateMachineDriver.java:42)
    at weblogic.application.internal.flow.ModuleStateDriver.start(ModuleStateDriver.java:70)
    at weblogic.application.internal.flow.StartModulesFlow.activate(StartModulesFlow.java:24)
    at weblogic.application.internal.BaseDeployment$2.next(BaseDeployment.java:729)
    at weblogic.application.utils.StateMachineDriver.nextState(StateMachineDriver.java:42)
    at weblogic.application.internal.BaseDeployment.activate(BaseDeployment.java:258)
    at weblogic.application.internal.SingleModuleDeployment.activate(SingleModuleDeployment.java:48)
    at weblogic.application.internal.DeploymentStateChecker.activate(DeploymentStateChecker.java:165)
    at weblogic.deploy.internal.targetserver.AppContainerInvoker.activate(AppContainerInvoker.java:80)
    at weblogic.deploy.internal.targetserver.operations.AbstractOperation.activate(AbstractOperation.java:586)
    at weblogic.deploy.internal.targetserver.operations.ActivateOperation.activateDeployment(ActivateOperation.java:148)
    at weblogic.deploy.internal.targetserver.operations.ActivateOperation.doCommit(ActivateOperation.java:114)
    at weblogic.deploy.internal.targetserver.operations.AbstractOperation.commit(AbstractOperation.java:339)
    at weblogic.deploy.internal.targetserver.DeploymentManager.handleDeploymentCommit(DeploymentManager.java:846)
    at weblogic.deploy.internal.targetserver.DeploymentManager.activateDeploymentList(DeploymentManager.java:1275)
    at weblogic.deploy.internal.targetserver.DeploymentManager.handleCommit(DeploymentManager.java:442)
    at weblogic.deploy.internal.targetserver.DeploymentServiceDispatcher.commit(DeploymentServiceDispatcher.java:176)
    at weblogic.deploy.service.internal.targetserver.DeploymentReceiverCallbackDeliverer.doCommitCallback(DeploymentReceiverCallbackDeliverer.java:195)
    at weblogic.deploy.service.internal.targetserver.DeploymentReceiverCallbackDeliverer.access$100(DeploymentReceiverCallbackDeliverer.java:13)
    at weblogic.deploy.service.internal.targetserver.DeploymentReceiverCallbackDeliverer$2.run(DeploymentReceiverCallbackDeliverer.java:68)
    at weblogic.work.SelfTuningWorkManagerImpl$WorkAdapterImpl.run(SelfTuningWorkManagerImpl.java:550)
    at weblogic.work.ExecuteThread.execute(ExecuteThread.java:295)
    at weblogic.work.ExecuteThread.run(ExecuteThread.java:254)
Caused by: java.lang.IllegalStateException: Cannot convert value of type [$Proxy214 implementing org.springframework.web.accept.ContentNegotiationStrategy,org.springframework.web.accept.MediaTypeFileExtensionResolver,org.springframework.aop.SpringProxy,org.springframework.aop.framework.Advised] to required type [org.springframework.web.accept.ContentNegotiationManager] for property 'contentNegotiationManager': no matching editors or conversion strategy found

    at org.springframework.beans.TypeConverterDelegate.convertIfNecessary(TypeConverterDelegate.java:264)
    at org.springframework.beans.BeanWrapperImpl.convertIfNecessary(BeanWrapperImpl.java:450)
    at org.springframework.beans.BeanWrapperImpl.convertForProperty(BeanWrapperImpl.java:496)
    at org.springframework.beans.BeanWrapperImpl.convertForProperty(BeanWrapperImpl.java:490)
    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.convertForProperty(AbstractAutowireCapableBeanFactory.java:1437)
    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyPropertyValues(AbstractAutowireCapableBeanFactory.java:1396)
    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1132)
    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:522)
    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:461)
    at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:295)
    at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:223)
    at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:292)
    at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:194)
    at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:607)
    at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:932)
    at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:479)
    at org.springframework.web.servlet.FrameworkServlet.configureAndRefreshWebApplicationContext(FrameworkServlet.java:647)
    at org.springframework.web.servlet.FrameworkServlet.createWebApplicationContext(FrameworkServlet.java:598)
    at org.springframework.web.servlet.FrameworkServlet.createWebApplicationContext(FrameworkServlet.java:661)
    at org.springframework.web.servlet.FrameworkServlet.initWebApplicationContext(FrameworkServlet.java:517)
    at org.springframework.web.servlet.FrameworkServlet.initServletBean(FrameworkServlet.java:458)
    at org.springframework.web.servlet.HttpServletBean.init(HttpServletBean.java:138)
    at javax.servlet.GenericServlet.init(GenericServlet.java:240)
    at weblogic.servlet.internal.StubSecurityHelper$ServletInitAction.run(StubSecurityHelper.java:337)
    at weblogic.servlet.internal.StubSecurityHelper$ServletInitAction.run(StubSecurityHelper.java:288)
    at weblogic.security.acl.internal.AuthenticatedSubject.doAs(AuthenticatedSubject.java:321)
    at weblogic.security.service.SecurityManager.runAs(SecurityManager.java:120)


The main part of the exception stack trace is:

weblogic.application.ModuleException: java.lang.IllegalStateException: Cannot convert value of type [$Proxy214 implementing 
    org.springframework.web.accept.ContentNegotiationStrategy,org.springframework.web.accept.MediaTypeFileExtensionResolver,org.springframework.aop.SpringProxy,org.springframework.aop.framework.Advised] to required type 
    [org.springframework.web.accept.ContentNegotiationManager] for property 'contentNegotiationManager': no matching editors or conversion strategy found


I have not defined any 'contentNegotiationManager' in my mvc config xml. Please help!
","This was because I did put my AOP configuration in MVC configuration file and AOP was trying to create proxies for Spring MVC classes. Placing AOP config in a separate file solved the problem.
"
1852,1852,2938,Replacing the thermocouple for a multimeter?,"I bought a no-name but decent multimeter, and it came with a thermocouple. Let's say I broke it in some way. Can I just replace it with any other thermocouple, or is each thermocouple calibrated for one specific model of a multimeter?

I have been looking at thermocouples, eg on eBay, e.g. this one. They write some specs but they don't write which multimeter it fits with?

So does any thermocouple fit with any multimeter (or digital thermometer)?
",Mads Skjern,https://electronics.stackexchange.com/users/35827,"In general any thermocouple can be used with any meter that handles thermocouples as long as they are compatible.  That means that a K type thermocouple must be paired with a meter that is calibrated for K type thermocouples. K type thermocouples are the most common so it is very likely that your meter can handle the one you looked at on Ebay which is a K type. However there are much cheaper K types available than that one which is specified for very high tempertures. As far as calibration goes, there are standard tables of thermocouple voltage versus temperature for each type of thermocouple. This is possible because each type of thermocouple uses the same composition of wires.  Thus your multimeter would have been designed to use the table for K type thermocouples.  The actual accuracy you can achieve is determined by the specified accuracy of the thermocouple and how well the meter conforms to the standard table values which are nonlinear.
",Barry,https://electronics.stackexchange.com/users/10016,http://electronics.stackexchange.com/questions/132748/replacing-the-thermocouple-for-a-multimeter,TECHNOLOGY,electronics.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,1.0,1.0,1.0,0.6666666666666666,0.4444444444444444,0.6666666666666666,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,1.0,1.0,0.7777777777777778,1.0,1.0,0.7333333333333333,0.3333333333333333,0.0,0.6666666666666666,0.8888888888888888,Change thermocouple to multimeter?,"I bought a no-name but decent multimeter, and it came with a thermocouple. Let's say I broke it in some way. Can I just replace it with any other thermocouple, or is each thermocouple calibrated for one specific model of a multimeter?

I have been looking at thermocouples, eg on eBay, e.g. this one. They write some specs but they don't write which multimeter it fits with?

So does any thermocouple fit with any multimeter (or digital thermometer)?
","In general any thermocouple can be used with any meter that handles thermocouples as long as they are compatible.  That means that a K type thermocouple must be paired with a meter that is calibrated for K type thermocouples. K type thermocouples are the most common so it is very likely that your meter can handle the one you looked at on Ebay which is a K type. However there are much cheaper K types available than that one which is specified for very high tempertures. As far as calibration goes, there are standard tables of thermocouple voltage versus temperature for each type of thermocouple. This is possible because each type of thermocouple uses the same composition of wires.  Thus your multimeter would have been designed to use the table for K type thermocouples.  The actual accuracy you can achieve is determined by the specified accuracy of the thermocouple and how well the meter conforms to the standard table values which are nonlinear.
"
3497,3497,5578,Is this formula in predicate logic a tautology?,"$\left(\forall x \cdot p(X) \Rightarrow q(X)\right) \wedge p(Y) \Rightarrow q(Y)$

At first glance this seems like a tautlogy and that's what my notes say. But an interpretation where $p$ is always true and $q$ is always false seems to be a counterexample.

Can someone confirm this or show me where I've gone wrong? 

Thanks.
",mmgro27,https://math.stackexchange.com/users/213003,"It is not a counterexample. In the case where $p$ is always true and $q$ is always false you have
$$(\forall X ,p(X) \Rightarrow q(X)) \qquad \mbox{ false}$$
$$(\forall X ,p(X) \Rightarrow q(X)) \wedge p(Y)\qquad \mbox{ false}$$
$$(\forall X ,p(X) \Rightarrow q(X)) \wedge p(Y) \Rightarrow q(Y)\qquad \mbox{ true}$$
since $\mbox{ false} \Rightarrow \mbox{ true}$ is true.
",Crostul,https://math.stackexchange.com/users/160300,http://math.stackexchange.com/questions/1153095/is-this-formula-in-predicate-logic-a-tautology,SCIENCE,math.stackexchange.com,1.0,0.5555555555555556,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,1.0,1.0,0.9333333333333332,0.3333333333333333,0.0,0.6666666666666666,0.8888888888888888,Is this formula tautology in predicate logic?,"$\left(\forall x \cdot p(X) \Rightarrow q(X)\right) \wedge p(Y) \Rightarrow q(Y)$

At first glance this seems like a tautlogy and that's what my notes say. But an interpretation where $p$ is always true and $q$ is always false seems to be a counterexample.

Can someone confirm this or show me where I've gone wrong? 

Thanks.
","It is not a counterexample. In the case where $p$ is always true and $q$ is always false you have
$$(\forall X ,p(X) \Rightarrow q(X)) \qquad \mbox{ false}$$
$$(\forall X ,p(X) \Rightarrow q(X)) \wedge p(Y)\qquad \mbox{ false}$$
$$(\forall X ,p(X) \Rightarrow q(X)) \wedge p(Y) \Rightarrow q(Y)\qquad \mbox{ true}$$
since $\mbox{ false} \Rightarrow \mbox{ true}$ is true.
"
4476,4476,7099,"Loading and unloading ""chunks"" of tiles in a 2d tile engine with 2d camera","I am making a 2d tile based game in C# and XNA 4.0. I am having trouble loading and unloading ""chunks"" of tiles(blocks). The whole world is randomly generated and is infinate on both axis. How would I go about loading and unloading chunks of tile data in the camera's view?

A pastebin to the pastebin links(I still have the 2 link cap):

http://pastebin.com/9PYr8cvC
",ceriosNerd,https://gamedev.stackexchange.com/users/14120,"Find out how large your screen is and only render tiles that fall within that range. You might need a camera object to keep track of this data and some sort of x &amp; y offset variables to keep track of movement around the world.

if(tile is inside of the window)
    render;

",LightLabyrinth,https://gamedev.stackexchange.com/users/14147,http://gamedev.stackexchange.com/questions/25030/loading-and-unloading-chunks-of-tiles-in-a-2d-tile-engine-with-2d-camera,TECHNOLOGY,gamedev.stackexchange.com,1.0,0.3333333333333333,0.0,1.0,1.0,1.0,0.5,0.5,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.5,0.5,0.0,0.0,0.8333333333333334,0.6666666666666666,0.6666666666666666,1.0,1.0,0.6,1.0,0.0,0.0,1.0,Using a 2D camera to load and unload block tiling in the 2D tiling engine,"I'm making a two-dimensional tile based game in C and XNA 4.0. I have problems loading and unloading ""block"" tiles (blocks). The whole world is randomly generated and infinite on both axes. How do I load and unload block tile data in camera view?","Find out how big your screen is and render only tiles in that range. You may need a camera object to track this data, as well as some X & Y offset variables to track movements around the world."
1177,1177,1850,1/4 to 1/8 jack problem,"I was planning to record months ago, with my electric guitar, and yesterday I got myself a guitar rig software and bought some 1/4 to 1/8 adapter jack so that I can plug in unto my laptop's mic hole.

Whenever I plug my guitar cable to the 1/4 to 1/8 adapter then to the laptop I can't hear any sound (past the clicking sound you hear) but when I plug the cable almost halfway of the adapter's body (before the clicking sound) I can hear sound when I play and there's some loud buzzing sound involved.

Any explanations as to why this is happening? 
",user3736846,https://music.stackexchange.com/users/13524,"
  when I plug the cable almost halfway of the adapter's body I can hear sound when I play


Sounds like (haw!) a mono-to-stereo problem. Look at the 1/4 inch plug. How many parts? The tip connector and the sleeve right behind the tip? Now look at the 1/8 inch plug. Two sleeves?

If yes, you are shorting out one of the channels. Go back to the shop and look for a 1/4 mono to 1/8 stereo adapter, preferably with a short cord to take the load off the laptop's input.
",paul,https://music.stackexchange.com/users/13463,http://music.stackexchange.com/questions/25070/1-4-to-1-8-jack-problem,LIFE_ARTS,music.stackexchange.com,0.8888888888888888,0.4444444444444444,0.0,0.5,1.0,1.0,0.6666666666666666,0.4444444444444444,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,1.0,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,0.8888888888888888,0.8888888888888888,1.0,0.3333333333333333,0.3333333333333333,1.0,0.8888888888888888,1 / 4 to 1 / 8 Jack problem,"I was planning to record months ago, with my electric guitar, and yesterday I got myself a guitar rig software and bought some 1/4 to 1/8 adapter jack so that I can plug in unto my laptop's mic hole.

Whenever I plug my guitar cable to the 1/4 to 1/8 adapter then to the laptop I can't hear any sound (past the clicking sound you hear) but when I plug the cable almost halfway of the adapter's body (before the clicking sound) I can hear sound when I play and there's some loud buzzing sound involved.

Any explanations as to why this is happening? 
","
  when I plug the cable almost halfway of the adapter's body I can hear sound when I play


Sounds like (haw!) a mono-to-stereo problem. Look at the 1/4 inch plug. How many parts? The tip connector and the sleeve right behind the tip? Now look at the 1/8 inch plug. Two sleeves?

If yes, you are shorting out one of the channels. Go back to the shop and look for a 1/4 mono to 1/8 stereo adapter, preferably with a short cord to take the load off the laptop's input.
"
5807,5807,9200,Combined gas law in an open atmosphere,"The question was asked about pressure vs. Volume increasing in an ideal gas as temperature is increased. My question then is this. What is the formula to determine how much volume and pressure will increase as temperature is increased?

Let me frame the question this way. PV/T=P2V2/T2 this formula works for a controlled system where more than one of these values can be maintained. If we apply a known amount of heat, say n, to the atmosphere, what formula would be used to calculate volume and pressure as the temperature is increased?
",Diamondhills,https://physics.stackexchange.com/users/27405,"Technically speaking, If you managed to create a planet with an ideal gas atmosphere, the atmosphere would just float away. Why?

One of the approximations of an ideal gas is 


  
  There are no attractive or repulsive forces between the molecules or the surroundings
  


This means that the gas wouldn't feel the force of gravity!
So if I had a jar of ideal gas, the pressure wouldn't increase as I went to a greater depth in the jar(It does increase in gasses too, just like it does in liquids).

I know this sounds strange but all it really means is that you cannot apply the ideal gas approximation to a system the size of our atmosphere. This approximation works well for small systems(A jar of ideal gas), because the effects of gravity are pretty negligible.

So to analyse effects of change in temperature on the whole atmosphere, you'll need a better model. Maybe considering the atmosphere a non-viscous fluid can help, I don't know. You should research on this.

Note that other approximations like the Van der Waals equation wouldn't help too because they too neglect the effect of gravity.
",udiboy1209,https://physics.stackexchange.com/users/10896,http://physics.stackexchange.com/questions/72613/combined-gas-law-in-an-open-atmosphere,SCIENCE,physics.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,0.3333333333333333,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.4444444444444444,1.0,0.5555555555555556,1.0,0.7777777777777778,0.5333333333333333,0.3333333333333333,0.0,1.0,0.8888888888888888,The law of combined gases in open atmosphere,"The question was asked about pressure vs. Volume increasing in an ideal gas as temperature is increased. My question then is this. What is the formula to determine how much volume and pressure will increase as temperature is increased?

Let me frame the question this way. PV/T=P2V2/T2 this formula works for a controlled system where more than one of these values can be maintained. If we apply a known amount of heat, say n, to the atmosphere, what formula would be used to calculate volume and pressure as the temperature is increased?
","Technically speaking, If you managed to create a planet with an ideal gas atmosphere, the atmosphere would just float away. Why?

One of the approximations of an ideal gas is 


  
  There are no attractive or repulsive forces between the molecules or the surroundings
  


This means that the gas wouldn't feel the force of gravity!
So if I had a jar of ideal gas, the pressure wouldn't increase as I went to a greater depth in the jar(It does increase in gasses too, just like it does in liquids).

I know this sounds strange but all it really means is that you cannot apply the ideal gas approximation to a system the size of our atmosphere. This approximation works well for small systems(A jar of ideal gas), because the effects of gravity are pretty negligible.

So to analyse effects of change in temperature on the whole atmosphere, you'll need a better model. Maybe considering the atmosphere a non-viscous fluid can help, I don't know. You should research on this.

Note that other approximations like the Van der Waals equation wouldn't help too because they too neglect the effect of gravity.
"
4041,4041,6452,Keyword not supported in SQL Server CE connection string,"I'm trying to connect to a SQL Server CE database in a C# web application (VB 2012) using this connection string:

using (SqlCeConnection conn = new SqlCeConnection(@""Data Source|DataDirectory|\MyData.sdf; Persist Security Info=False;""))


The problem is that I am getting an exception that the data source|datadirectory is not a supported keyword. I attempted to change this string to:

Data Source=MainDb.sdf;Persist Security Info=False;


But then I get an error that the Db cannot be found. The database is located in the App_Data folder. Any ideas?
",E Crux,https://stackoverflow.com/users/2407018,"The syntax seems to be incorrect - it should look something like this:


  using (SqlCeConnection conn = new SqlCeConnection(@""Data Source =
  |DataDirectory|\MyData.sdf; Persist Security Info=False;""))

",OnoSendai,https://stackoverflow.com/users/1845714,http://stackoverflow.com/questions/16697086/keyword-not-supported-in-sql-server-ce-connection-string,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.5555555555555556,0.0,1.0,0.6666666666666666,1.0,0.4444444444444444,0.4444444444444444,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.0,0.6666666666666666,0.8888888888888888,Keyword is not supported in SQL Server CE connection string,"I'm trying to connect to a SQL Server CE database in a C# web application (VB 2012) using this connection string:

using (SqlCeConnection conn = new SqlCeConnection(@""Data Source|DataDirectory|\MyData.sdf; Persist Security Info=False;""))


The problem is that I am getting an exception that the data source|datadirectory is not a supported keyword. I attempted to change this string to:

Data Source=MainDb.sdf;Persist Security Info=False;


But then I get an error that the Db cannot be found. The database is located in the App_Data folder. Any ideas?
","The syntax seems to be incorrect - it should look something like this:


  using (SqlCeConnection conn = new SqlCeConnection(@""Data Source =
  |DataDirectory|\MyData.sdf; Persist Security Info=False;""))

"
2210,2210,3519,Direction of Tefillin Winding,"Why do some people have the custom to wind the Tefillin-Shel-Yad towards themselves, while others wind it away from themselves? What is the reason behind these two customs, and which sects of Judaism generally follow which method?
",yydl,https://judaism.stackexchange.com/users/128,"It's pretty much a question of which eida you come from:  

Ashkenazim wind inwards, Sfaradim wind outwards.
(And, confusingly, right-handed ashkenazi using left-handed ashkenazi tfillin would also be winding backwards...)   

The link that @jake posted in comments illustrates this very nicely - it depends on which eida's minhag you use.   

(Sorry, I don't know the reasoning behind the different minhagim - though I find it likely that each do it that way, because thats the way they do it...)
",AviD,https://judaism.stackexchange.com/users/459,http://judaism.stackexchange.com/questions/8308/direction-of-tefillin-winding,CULTURE,judaism.stackexchange.com,1.0,0.3333333333333333,0.0,0.3333333333333333,1.0,1.0,0.4444444444444444,0.5555555555555556,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,1.0,0.0,0.4444444444444444,1.0,0.5555555555555556,1.0,1.0,0.7333333333333333,0.0,0.0,1.0,0.8888888888888888,Twining direction of Teflon,"Why do some people have the habit of rolling Teflon on themselves, while others do? What are the reasons behind these two customs? Which denominations of Judaism usually follow which method?","It's pretty much a question of which eida you come from:  

Ashkenazim wind inwards, Sfaradim wind outwards.
(And, confusingly, right-handed ashkenazi using left-handed ashkenazi tfillin would also be winding backwards...)   

The link that @jake posted in comments illustrates this very nicely - it depends on which eida's minhag you use.   

(Sorry, I don't know the reasoning behind the different minhagim - though I find it likely that each do it that way, because thats the way they do it...)
"
875,875,1388,How can I prevent a faucet retaining nut from freezing to a steel washer?,"My real question, after several hours spent removing the old faucet (progressing from tapping the basin wrench with a mallet, to an overnight soak in penetrating oil, to cutting it off with an air grinder) is ""what idiot engineer uses a mild steel washer in a wet environment?"" But it looks like they all do, or at least the ones who designed the new faucet do, so ...

On the assumption that I or someone else will someday want to change the faucet, what can I use to prevent the nut from freezing to either the washer or the faucet body? If I were working on a car, I'd use thread sealing compound. Does that make sense in this application? Or are there any professional tricks that aren't quite as messy?
",kdgregory,https://diy.stackexchange.com/users/3944,"Anti-Seize Lubricating Compound 

Make sure it's waterproof



Pipe Dope

Make sure it's Anti-seize



I do not specifically recommend nor endorse either product, they are only used as examples.  
",Tester101,https://diy.stackexchange.com/users/33,http://diy.stackexchange.com/questions/10841/how-can-i-prevent-a-faucet-retaining-nut-from-freezing-to-a-steel-washer,LIFE_ARTS,diy.stackexchange.com,1.0,0.5555555555555556,0.0,1.0,1.0,1.0,0.5555555555555556,0.4444444444444444,0.6666666666666666,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.0,1.0,0.7777777777777778,0.4444444444444444,0.7777777777777778,1.0,0.7333333333333333,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,How to prevent the fixing nut of the faucet from freezing to the steel washer?,"My real question, after several hours spent removing the old faucet (progressing from tapping the basin wrench with a mallet, to an overnight soak in penetrating oil, to cutting it off with an air grinder) is ""what idiot engineer uses a mild steel washer in a wet environment?"" But it looks like they all do, or at least the ones who designed the new faucet do, so ...

On the assumption that I or someone else will someday want to change the faucet, what can I use to prevent the nut from freezing to either the washer or the faucet body? If I were working on a car, I'd use thread sealing compound. Does that make sense in this application? Or are there any professional tricks that aren't quite as messy?
","Anti-Seize Lubricating Compound 

Make sure it's waterproof



Pipe Dope

Make sure it's Anti-seize



I do not specifically recommend nor endorse either product, they are only used as examples.  
"
2955,2955,4702,How can I bypass double quotes in a attribute based xss attack,"The code that I have is:

&lt;input type=""text"" name=""some_name"" value=""&lt;?php echo CHtml::encode($str); ?&gt;"" /&gt;


$str is the input data. 'CHtml::encode()' is Yii's way of encoding special characters into HTML entities. Can this be bypassed? 

I know it can be broken if I do not put those double quotes around the input. But I do not think just by putting double quotes around will make it unbreakable. 
",kumar,https://security.stackexchange.com/users/53928,"The encode() method HTML encodes characters, which is the correct XSS prevention method in this context.

So if a "" character was inserted inside of $str to try and break out of the HTML attribute context, this would be converted to &amp;quot; or &amp;#34; which is the HTML representation.

Therefore it is not possible to inject script here, assuming encode does not have any flaws itself that allows this to happen.
",SilverlightFox,https://security.stackexchange.com/users/8340,http://security.stackexchange.com/questions/65526/how-can-i-bypass-double-quotes-in-a-attribute-based-xss-attack,TECHNOLOGY,security.stackexchange.com,0.6666666666666666,0.6666666666666666,0.0,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,1.0,0.6,1.0,0.0,1.0,1.0,How to bypass double quotes in attribute based XSS attacks,"The code that I have is:

&lt;input type=""text"" name=""some_name"" value=""&lt;?php echo CHtml::encode($str); ?&gt;"" /&gt;


$str is the input data. 'CHtml::encode()' is Yii's way of encoding special characters into HTML entities. Can this be bypassed? 

I know it can be broken if I do not put those double quotes around the input. But I do not think just by putting double quotes around will make it unbreakable. 
","The encode() method HTML encodes characters, which is the correct XSS prevention method in this context.

So if a "" character was inserted inside of $str to try and break out of the HTML attribute context, this would be converted to &amp;quot; or &amp;#34; which is the HTML representation.

Therefore it is not possible to inject script here, assuming encode does not have any flaws itself that allows this to happen.
"
3062,3062,4876,Native Browser Automation using Appium 1.2.0.1 on Windows 7 Android real device: Could not find a connected Android device,"I have looked many forums for this issue, there are quite a few answers on this topic but none of these have worked for me/match my criteria.

I recently took up Mobile Automation task and hence am completely new  to Appium. I am working with Appium 1.2.0.1 on Windows 7 and trying to automate the native Android Browser(not Chrome or an App) on an Android v4.3 real device. 
I have installed everything according to the instructions. I am using Selenium in Maven Build in JUnit Framework to execute the scripts through Appium. I use Appuim.exe in Admin mode and use the GUI to start the node. Then I run my scripts. 

My issue is that when I try ""adb devices"" in cmd, I am able to see the device. Whereas, during execution, Appium is throwing an Error ""Failed to start an Appium session, err was: Error: Could not find a connected Android device."" I tried many troubleshooting options and verified if everything is in place. No luck. Please help.

Below is the trace of Error:

&gt; Checking if an update is available
&gt; Update not available
&gt; Starting Node Server
&gt; info: Welcome to Appium v1.2.0 (REV e53f49c706a25242e66d36685c268b599cc18da5)
&gt; debug: Non-default server args: {""address"":""127.0.0.1"",""fullReset"":true,""logNoColors"":true,""platformName"":""Android"",""platformVersion"":""18"",""automationName"":""Appium"",""browserName"":""Browser""}
&gt; info: Appium REST http interface listener started on 127.0.0.1:4723
&gt; info: LogLevel: debug
&gt; info: --&gt; POST /wd/hub/session {""desiredCapabilities"":{""platformVersion"":""4.3"",""browserName"":""Browser"",""platformName"":""Android"",""device"":""Android"",""deviceName"":""Android""}}
&gt; debug: Appium request initiated at /wd/hub/session
&gt; info: Retrieving device
&gt; warn:  code=ENOENT, errno=ENOENT, syscall=spawn
&gt; debug: Request received with params: {""desiredCapabilities"":{""platformVersion"":""4.3"",""browserName"":""Browser"",""platformName"":""Android"",""device"":""Android"",""deviceName"":""Android""}}
&gt; debug: The following desired capabilities were provided, but not recognized by appium. They will be passed on to any other services running on this server. : device
&gt; debug: Looks like we want chrome on android
&gt; debug: Creating new appium session fa19e382-c178-4e6b-8150-a386a51bee39
&gt; debug: Preparing device for session
&gt; debug: Not checking whether app is present since we are assuming it's already on the device
&gt; debug: Checking whether adb is present
&gt; debug: Using adb from C:\Android\android-sdk\platform-tools\adb.exe
&gt; debug: Trying to find a connected android device
&gt; debug: Getting connected devices...
&gt; debug: executing: ""C:\Android\android-sdk\platform-tools\adb.exe"" devices
&gt; debug: Could not find devices, restarting adb server...
&gt; debug: executing: ""C:\Android\android-sdk\platform-tools\adb.exe"" kill-server
&gt; warn:  code=ENOENT, errno=ENOENT, syscall=spawn
&gt; warn:  code=ENOENT, errno=ENOENT, syscall=spawn
&gt; debug: Getting connected devices...
&gt; debug: executing: ""C:\Android\android-sdk\platform-tools\adb.exe"" devices
&gt; debug: Could not find devices, restarting adb server...
&gt; debug: executing: ""C:\Android\android-sdk\platform-tools\adb.exe"" kill-server
&gt; error: Error killing ADB server, going to see if it's online anyway
&gt; debug: Getting connected devices...
&gt; debug: executing: ""C:\Android\android-sdk\platform-tools\adb.exe"" devices
&gt; debug: Could not find devices, restarting adb server...
&gt; warn:  code=ENOENT, errno=ENOENT, syscall=spawn
&gt; warn:  code=ENOENT, errno=ENOENT, syscall=spawn
&gt; debug: executing: ""C:\Android\android-sdk\platform-tools\adb.exe"" kill-server
&gt; warn:  code=ENOENT, errno=ENOENT, syscall=spawn
&gt; error: Error killing ADB server, going to see if it's online anyway
&gt; warn:  code=ENOENT, errno=ENOENT, syscall=spawn
&gt; info: &lt;-- POST /wd/hub/session 500 20314.056 ms - 206 
&gt; debug: Getting connected devices...
&gt; debug: executing: ""C:\Android\android-sdk\platform-tools\adb.exe"" devices
&gt; debug: Cleaning up appium session
&gt; error: Failed to start an Appium session, err was: Error: Could not find a connected Android device.
&gt; debug: Error: Could not find a connected Android device.
&gt;     at ADB.getDevicesWithRetry (C:\Selenium\AppiumForWindows-1.2.0.1\Appium\node_modules\appium\node_modules\appium-adb\lib\adb.js:600:15)
&gt;     at androidCommon.prepareActiveDevice (C:\Selenium\AppiumForWindows-1.2.0.1\Appium\node_modules\appium\lib\devices\android\android-common.js:349:12)
&gt;     at null.&lt;anonymous&gt; (C:\Selenium\AppiumForWindows-1.2.0.1\Appium\node_modules\appium\lib\devices\android\android-common.js:289:26)
&gt;     at C:\Selenium\AppiumForWindows-1.2.0.1\Appium\node_modules\appium\node_modules\async\lib\async.js:610:21
&gt;     at C:\Selenium\AppiumForWindows-1.2.0.1\Appium\node_modules\appium\node_modules\async\lib\async.js:249:17
&gt;     at iterate (C:\Selenium\AppiumForWindows-1.2.0.1\Appium\node_modules\appium\node_modules\async\lib\async.js:149:13)
&gt;     at C:\Selenium\AppiumForWindows-1.2.0.1\Appium\node_modules\appium\node_modules\async\lib\async.js:160:25
&gt;     at C:\Selenium\AppiumForWindows-1.2.0.1\Appium\node_modules\appium\node_modules\async\lib\async.js:251:21
&gt;     at C:\Selenium\AppiumForWindows-1.2.0.1\Appium\node_modules\appium\node_modules\async\lib\async.js:615:34
&gt;     at androidCommon.prepareEmulator (C:\Selenium\AppiumForWindows-1.2.0.1\Appium\node_modules\appium\lib\devices\android\android-common.js:339:5)
&gt; debug: Responding to client with error: {""status"":33,""value"":{""message"":""A new session could not be created. (Original error: Could not find a connected Android device.)"",""origValue"":""Could not find a connected Android device.""},""sessionId"":null}


And here is my code:

if (runEnv.equals(""Android"")) 
        {
            DesiredCapabilities capabilities = new DesiredCapabilities();
              capabilities.setCapability(""device"",""Android"");
              capabilities.setCapability(""deviceName"",""Android"");
              capabilities.setCapability(""platformName"",""Android"");
              capabilities.setCapability(""browserName"", ""Browser"");
              capabilities.setCapability(""platformVersion"", ""4.3"");

              try {
                driver = new RemoteWebDriver(new URL(""http://127.0.0.1:4723/wd/hub""), capabilities);
            } catch (MalformedURLException e) {
                e.printStackTrace();
            }

            driver.manage().timeouts().implicitlyWait(80, TimeUnit.SECONDS);
        }


Please help!

Thanks,
Arpitha
",Arpitha Keshav,https://stackoverflow.com/users/4017740,"In the deviceName field copy and paste the id given in the cmd window when you run the adb devies command.
",Ram,https://stackoverflow.com/users/2899195,http://stackoverflow.com/questions/25717961/native-browser-automation-using-appium-1-2-0-1-on-windows-7-android-real-device,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.5555555555555556,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.7777777777777778,0.8888888888888888,0.5555555555555556,1.0,1.0,0.8,1.0,0.0,0.0,0.7777777777777778,Native browser automation using appium 1.2.0.1 on Windows 7 Android real devices: no connected Android devices found,"I have looked many forums for this issue, there are quite a few answers on this topic but none of these have worked for me/match my criteria.

I recently took up Mobile Automation task and hence am completely new  to Appium. I am working with Appium 1.2.0.1 on Windows 7 and trying to automate the native Android Browser(not Chrome or an App) on an Android v4.3 real device. 
I have installed everything according to the instructions. I am using Selenium in Maven Build in JUnit Framework to execute the scripts through Appium. I use Appuim.exe in Admin mode and use the GUI to start the node. Then I run my scripts. 

My issue is that when I try ""adb devices"" in cmd, I am able to see the device. Whereas, during execution, Appium is throwing an Error ""Failed to start an Appium session, err was: Error: Could not find a connected Android device."" I tried many troubleshooting options and verified if everything is in place. No luck. Please help.

Below is the trace of Error:

&gt; Checking if an update is available
&gt; Update not available
&gt; Starting Node Server
&gt; info: Welcome to Appium v1.2.0 (REV e53f49c706a25242e66d36685c268b599cc18da5)
&gt; debug: Non-default server args: {""address"":""127.0.0.1"",""fullReset"":true,""logNoColors"":true,""platformName"":""Android"",""platformVersion"":""18"",""automationName"":""Appium"",""browserName"":""Browser""}
&gt; info: Appium REST http interface listener started on 127.0.0.1:4723
&gt; info: LogLevel: debug
&gt; info: --&gt; POST /wd/hub/session {""desiredCapabilities"":{""platformVersion"":""4.3"",""browserName"":""Browser"",""platformName"":""Android"",""device"":""Android"",""deviceName"":""Android""}}
&gt; debug: Appium request initiated at /wd/hub/session
&gt; info: Retrieving device
&gt; warn:  code=ENOENT, errno=ENOENT, syscall=spawn
&gt; debug: Request received with params: {""desiredCapabilities"":{""platformVersion"":""4.3"",""browserName"":""Browser"",""platformName"":""Android"",""device"":""Android"",""deviceName"":""Android""}}
&gt; debug: The following desired capabilities were provided, but not recognized by appium. They will be passed on to any other services running on this server. : device
&gt; debug: Looks like we want chrome on android
&gt; debug: Creating new appium session fa19e382-c178-4e6b-8150-a386a51bee39
&gt; debug: Preparing device for session
&gt; debug: Not checking whether app is present since we are assuming it's already on the device
&gt; debug: Checking whether adb is present
&gt; debug: Using adb from C:\Android\android-sdk\platform-tools\adb.exe
&gt; debug: Trying to find a connected android device
&gt; debug: Getting connected devices...
&gt; debug: executing: ""C:\Android\android-sdk\platform-tools\adb.exe"" devices
&gt; debug: Could not find devices, restarting adb server...
&gt; debug: executing: ""C:\Android\android-sdk\platform-tools\adb.exe"" kill-server
&gt; warn:  code=ENOENT, errno=ENOENT, syscall=spawn
&gt; warn:  code=ENOENT, errno=ENOENT, syscall=spawn
&gt; debug: Getting connected devices...
&gt; debug: executing: ""C:\Android\android-sdk\platform-tools\adb.exe"" devices
&gt; debug: Could not find devices, restarting adb server...
&gt; debug: executing: ""C:\Android\android-sdk\platform-tools\adb.exe"" kill-server
&gt; error: Error killing ADB server, going to see if it's online anyway
&gt; debug: Getting connected devices...
&gt; debug: executing: ""C:\Android\android-sdk\platform-tools\adb.exe"" devices
&gt; debug: Could not find devices, restarting adb server...
&gt; warn:  code=ENOENT, errno=ENOENT, syscall=spawn
&gt; warn:  code=ENOENT, errno=ENOENT, syscall=spawn
&gt; debug: executing: ""C:\Android\android-sdk\platform-tools\adb.exe"" kill-server
&gt; warn:  code=ENOENT, errno=ENOENT, syscall=spawn
&gt; error: Error killing ADB server, going to see if it's online anyway
&gt; warn:  code=ENOENT, errno=ENOENT, syscall=spawn
&gt; info: &lt;-- POST /wd/hub/session 500 20314.056 ms - 206 
&gt; debug: Getting connected devices...
&gt; debug: executing: ""C:\Android\android-sdk\platform-tools\adb.exe"" devices
&gt; debug: Cleaning up appium session
&gt; error: Failed to start an Appium session, err was: Error: Could not find a connected Android device.
&gt; debug: Error: Could not find a connected Android device.
&gt;     at ADB.getDevicesWithRetry (C:\Selenium\AppiumForWindows-1.2.0.1\Appium\node_modules\appium\node_modules\appium-adb\lib\adb.js:600:15)
&gt;     at androidCommon.prepareActiveDevice (C:\Selenium\AppiumForWindows-1.2.0.1\Appium\node_modules\appium\lib\devices\android\android-common.js:349:12)
&gt;     at null.&lt;anonymous&gt; (C:\Selenium\AppiumForWindows-1.2.0.1\Appium\node_modules\appium\lib\devices\android\android-common.js:289:26)
&gt;     at C:\Selenium\AppiumForWindows-1.2.0.1\Appium\node_modules\appium\node_modules\async\lib\async.js:610:21
&gt;     at C:\Selenium\AppiumForWindows-1.2.0.1\Appium\node_modules\appium\node_modules\async\lib\async.js:249:17
&gt;     at iterate (C:\Selenium\AppiumForWindows-1.2.0.1\Appium\node_modules\appium\node_modules\async\lib\async.js:149:13)
&gt;     at C:\Selenium\AppiumForWindows-1.2.0.1\Appium\node_modules\appium\node_modules\async\lib\async.js:160:25
&gt;     at C:\Selenium\AppiumForWindows-1.2.0.1\Appium\node_modules\appium\node_modules\async\lib\async.js:251:21
&gt;     at C:\Selenium\AppiumForWindows-1.2.0.1\Appium\node_modules\appium\node_modules\async\lib\async.js:615:34
&gt;     at androidCommon.prepareEmulator (C:\Selenium\AppiumForWindows-1.2.0.1\Appium\node_modules\appium\lib\devices\android\android-common.js:339:5)
&gt; debug: Responding to client with error: {""status"":33,""value"":{""message"":""A new session could not be created. (Original error: Could not find a connected Android device.)"",""origValue"":""Could not find a connected Android device.""},""sessionId"":null}


And here is my code:

if (runEnv.equals(""Android"")) 
        {
            DesiredCapabilities capabilities = new DesiredCapabilities();
              capabilities.setCapability(""device"",""Android"");
              capabilities.setCapability(""deviceName"",""Android"");
              capabilities.setCapability(""platformName"",""Android"");
              capabilities.setCapability(""browserName"", ""Browser"");
              capabilities.setCapability(""platformVersion"", ""4.3"");

              try {
                driver = new RemoteWebDriver(new URL(""http://127.0.0.1:4723/wd/hub""), capabilities);
            } catch (MalformedURLException e) {
                e.printStackTrace();
            }

            driver.manage().timeouts().implicitlyWait(80, TimeUnit.SECONDS);
        }


Please help!

Thanks,
Arpitha
","In the deviceName field copy and paste the id given in the cmd window when you run the adb devies command.
"
840,840,1337,Google Apps login in wordpress,"I manage a google apps domain with plenty of users;

I would like to join Google apps with a Wordpress based intranet app we're creating. 

Which level of integration could I expect to achieve?

Our hope is to create users in wordpress using their google apps email and let them login using their google apps password, so that they don't need to remember two different passwords.

How would you suggest we should implement this?
",Bakaburg,https://wordpress.stackexchange.com/users/10100,"This question was asked a while ago, but for anyone else facing this problem, we have developed a plugin that allows users to login using the latest Google OAuth2 without needing a separate WordPress password.

Google Apps Login is designed specifically for intranets (or any WordPress site) where the organization is running their email entirely on Google Apps.

http://wordpress.org/plugins/google-apps-login/

The plugin is fully supported, through support licenses and a premium version which can save you a lot of time on user management - domain admins no longer need to separately manage WordPress user accounts.
",Dan Lester,https://wordpress.stackexchange.com/users/44605,http://wordpress.stackexchange.com/questions/47265/google-apps-login-in-wordpress,TECHNOLOGY,wordpress.stackexchange.com,1.0,0.4444444444444444,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.5555555555555556,1.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.6666666666666666,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.6666666666666666,0.3333333333333333,0.6666666666666666,1.0,Google App log in to WordPress,"I manage a google apps domain with plenty of users;

I would like to join Google apps with a Wordpress based intranet app we're creating. 

Which level of integration could I expect to achieve?

Our hope is to create users in wordpress using their google apps email and let them login using their google apps password, so that they don't need to remember two different passwords.

How would you suggest we should implement this?
","This question was asked a while ago, but for anyone else facing this problem, we have developed a plugin that allows users to login using the latest Google OAuth2 without needing a separate WordPress password.

Google Apps Login is designed specifically for intranets (or any WordPress site) where the organization is running their email entirely on Google Apps.

http://wordpress.org/plugins/google-apps-login/

The plugin is fully supported, through support licenses and a premium version which can save you a lot of time on user management - domain admins no longer need to separately manage WordPress user accounts.
"
1423,1423,2235,Could Belief in Little Fears: Nightmare Edition cause the dark side of the moon to really be dark?,"I'm writing an episode which involves a plot by the monster Vanish involving possessing the dark side of the moon (if you don't know, his power is to possess shadows). I was going with the fact that the term ""the dark side of the moon"" would cause enough children to believe that it really was dark for Belief to make it so, but I'm not entirely sure that Belief works that way. Does it?
",Ness Gardna,https://rpg.stackexchange.com/users/7726,"It's been a long while since I played Little Fears and I never did GM it, but from what I remember Belief was a child's main defensive thing.  It also had it's negative side such as holding your breath when riding through a tunnel, or lifting your feet when riding over rail road tracks, or not stepping on cracks in the sidewalk.  All of which have some form of negative consequence which can have a regional component in some cases.

Judging by your wording of the question, ""would cause enough children to believe that"", it sounds you may want to impose a threshold of some kind on the plot.  From what I remember, you don't need to go that far.  Only one believer would be needed to make it happen.  But children that didn't believe, say because they never heard of the possibility, would not be subject to the effect.  The beautiful thing is that once a group of children hear about something, some of them will believe.  A real life example of that being a young sibling of my friend believed I had a battery in my big toe.  Why?  I said I did.  It was that simple.  In the same way, agents of Closetland could spread negative believes that serve one of the seven kings or whatever master the agent follows.  If you get to them young enough they will believe some really wild stories.  

Have fun with Little Fears, I may have to go looking for it again.
",Leezard,https://rpg.stackexchange.com/users/5759,http://rpg.stackexchange.com/questions/23028/could-belief-in-little-fears-nightmare-edition-cause-the-dark-side-of-the-moon,CULTURE,rpg.stackexchange.com,0.7777777777777778,0.6666666666666666,0.0,1.0,0.3333333333333333,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,1.0,Believe in a little fear: will the nightmare version really darken the dark side of the moon?,"I'm writing an episode where a monster disappears, including having the dark side of the moon (if you don't know, his power is to have shadows). I think the word ""dark side of the moon"" will convince enough children that it's really dark for faith, but I'm not sure that faith works that way. Is it?","It's been a long while since I played Little Fears and I never did GM it, but from what I remember Belief was a child's main defensive thing.  It also had it's negative side such as holding your breath when riding through a tunnel, or lifting your feet when riding over rail road tracks, or not stepping on cracks in the sidewalk.  All of which have some form of negative consequence which can have a regional component in some cases.

Judging by your wording of the question, ""would cause enough children to believe that"", it sounds you may want to impose a threshold of some kind on the plot.  From what I remember, you don't need to go that far.  Only one believer would be needed to make it happen.  But children that didn't believe, say because they never heard of the possibility, would not be subject to the effect.  The beautiful thing is that once a group of children hear about something, some of them will believe.  A real life example of that being a young sibling of my friend believed I had a battery in my big toe.  Why?  I said I did.  It was that simple.  In the same way, agents of Closetland could spread negative believes that serve one of the seven kings or whatever master the agent follows.  If you get to them young enough they will believe some really wild stories.  

Have fun with Little Fears, I may have to go looking for it again.
"
2578,2578,4104,"Difference in ""capable"" and ""able""","What is the difference in being physically capable and physically able?

When would one choose one over the other?
",Homer,https://english.stackexchange.com/users/21117,"They mean the same thing, but when there's a further qualifier, capable is preferred, whereas able is usually by itself:


  He is physically able. — [normal]
  
  He is physically able to lift 200 kg. — [OK, not that unusual]
  
  He is physically capable. — [unusual, but not wrong]
  
  He is physically capable of lifting 200 kg. — [normal]

",Daniel,https://english.stackexchange.com/users/10041,http://english.stackexchange.com/questions/75010/difference-in-capable-and-able,CULTURE,english.stackexchange.com,1.0,0.7777777777777778,0.0,1.0,1.0,1.0,0.8888888888888888,0.7777777777777778,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,0.0,1.0,"The difference between ""capable"" and ""capable""",What's the difference between physical strength and physical strength?,"They mean the same thing, but when there's a further qualifier, capable is preferred, whereas able is usually by itself:


  He is physically able. — [normal]
  
  He is physically able to lift 200 kg. — [OK, not that unusual]
  
  He is physically capable. — [unusual, but not wrong]
  
  He is physically capable of lifting 200 kg. — [normal]

"
3652,3652,5827,Inserting a blank line in vim?,"I quite often find I have a need to insert a blank line either below or above the current line when editing in vim. o and O will do this, but they subsequently switch into insert mode, which is annoying. Is there any built-in command to do this which will remain in normal mode?
",Andrew Ferrier,https://superuser.com/users/3021,"Yet another way to insert lines above or below:

nnoremap &lt;Enter&gt; :call append(line('.'), '')&lt;CR&gt;
nnoremap &lt;S-Enter&gt; :call append(line('.')-1, '')&lt;CR&gt;


Note that the solution from romainl and Mr Shunz will move the cursor to the newly inserted line, whereas this and also the one from Ingo Karkat will keep the cursor at the same spot.
",taketwo,https://superuser.com/users/210066,http://superuser.com/questions/607163,TECHNOLOGY,superuser.com,1.0,0.6666666666666666,0.0,1.0,1.0,1.0,0.5,0.5,0.0,0.0,0.5,1.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9,1.0,0.0,0.0,0.8333333333333334,Insert empty row in VIM?,"When editing in VIM, I often find it necessary to insert an empty row below or above the current row. O and o do this, but they then switch to insert mode, which is annoying. Is there any built-in command to do this, which will remain in normal mode?","Yet another way to insert lines above or below:

nnoremap &lt;Enter&gt; :call append(line('.'), '')&lt;CR&gt;
nnoremap &lt;S-Enter&gt; :call append(line('.')-1, '')&lt;CR&gt;


Note that the solution from romainl and Mr Shunz will move the cursor to the newly inserted line, whereas this and also the one from Ingo Karkat will keep the cursor at the same spot.
"
3958,3958,6316,How to Implement composite primary key with Hibernate Annonations,"I would like to know how to create a Composite Combination through Hibernate annotation method. 

I have 3 tables Employee, Department &amp; Employee-Department-Juntion

Since I want to make Employee and Department as individual table, i created a Junction Table in order maintain the Many-to-Many relationship.

I would like to know how to Create Composite Primary Key for the Department Table
For the column Center_Code &amp; Depart_Code through Hibernate Annotations.

Could you please somebody help me how to solve this issue.

Below Here I also attached the Table Relation Ship and the Java POJO Class.

Table Relationship



JAVA POJO CLASS

package com.hibernate;

import java.util.Objects;
import javax.persistence.Entity;
import javax.persistence.Id;

/**
 *
 * @author SPAR
 */
@Entity
public class Department {

    @Id
    private String cost_Center_Code;
    private String dep_Code;
    private String department;
    private String sub_Department;
    private String division;

    public String getDepartment() {
        return department;
    }

    public void setDepartment(String department) {
        this.department = department;
    }

    public String getDep_Code() {
        return dep_Code;
    }

    public void setDep_Code(String dep_Code) {
        this.dep_Code = dep_Code;
    }

    public String getCost_Center_Code() {
        return cost_Center_Code;
    }

    public void setCost_Center_Code(String cost_Center_Code) {
        this.cost_Center_Code = cost_Center_Code;
    }

    public String getDivision() {
        return division;
    }

    public void setDivision(String division) {
        this.division = division;
    }

    public String getSub_Department() {
        return sub_Department;
    }

    public void setSub_Department(String sub_Department) {
        this.sub_Department = sub_Department;
    }

    @Override
    public String toString() {
        return ""Department{"" + ""cost_Center_Code="" + cost_Center_Code + "", dep_Code="" + dep_Code + "", department="" + department + "", sub_Department="" + sub_Department + "", division="" + division + '}';
    }

    @Override
    public int hashCode() {
        int hash = 7;
        hash = 79 * hash + Objects.hashCode(this.cost_Center_Code);
        hash = 79 * hash + Objects.hashCode(this.dep_Code);
        return hash;
    }

    @Override
    public boolean equals(Object obj) {
        if (obj == null) {
            return false;
        }
        if (getClass() != obj.getClass()) {
            return false;
        }
        final Department other = (Department) obj;
        if (!Objects.equals(this.cost_Center_Code, other.cost_Center_Code)) {
            return false;
        }
        if (!Objects.equals(this.dep_Code, other.dep_Code)) {
            return false;
        }
        return true;
    }

}

",Arun,https://stackoverflow.com/users/2535203,"I think,what you are looking for is EmbeddedId,You can do something like below.


First take out these column from your Department class,and create a new class like below.  

    @Embeddable    
    class CenterDeptId{

       @Column(name = ""center_code"")
       private String cost_Center_Code;

       @Column(name = ""dep_code"")
       private String dep_Code;

       // getter &amp;&amp; setter 

   }

Use the above class in your Department class

@Entity    
public class Department {

    @EmbeddedId
    private CenterDeptId centerDeptId;
    private String department;
    private String sub_Department;
    private String division;

  //getter &amp;&amp; setter

}


",RE350,https://stackoverflow.com/users/1206653,http://stackoverflow.com/questions/27666707/how-to-implement-composite-primary-key-with-hibernate-annonations,STACKOVERFLOW,stackoverflow.com,1.0,0.4444444444444444,0.0,1.0,0.3333333333333333,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,1.0,How to realize compound primary key with hibernate annotation,"I would like to know how to create a Composite Combination through Hibernate annotation method. 

I have 3 tables Employee, Department &amp; Employee-Department-Juntion

Since I want to make Employee and Department as individual table, i created a Junction Table in order maintain the Many-to-Many relationship.

I would like to know how to Create Composite Primary Key for the Department Table
For the column Center_Code &amp; Depart_Code through Hibernate Annotations.

Could you please somebody help me how to solve this issue.

Below Here I also attached the Table Relation Ship and the Java POJO Class.

Table Relationship



JAVA POJO CLASS

package com.hibernate;

import java.util.Objects;
import javax.persistence.Entity;
import javax.persistence.Id;

/**
 *
 * @author SPAR
 */
@Entity
public class Department {

    @Id
    private String cost_Center_Code;
    private String dep_Code;
    private String department;
    private String sub_Department;
    private String division;

    public String getDepartment() {
        return department;
    }

    public void setDepartment(String department) {
        this.department = department;
    }

    public String getDep_Code() {
        return dep_Code;
    }

    public void setDep_Code(String dep_Code) {
        this.dep_Code = dep_Code;
    }

    public String getCost_Center_Code() {
        return cost_Center_Code;
    }

    public void setCost_Center_Code(String cost_Center_Code) {
        this.cost_Center_Code = cost_Center_Code;
    }

    public String getDivision() {
        return division;
    }

    public void setDivision(String division) {
        this.division = division;
    }

    public String getSub_Department() {
        return sub_Department;
    }

    public void setSub_Department(String sub_Department) {
        this.sub_Department = sub_Department;
    }

    @Override
    public String toString() {
        return ""Department{"" + ""cost_Center_Code="" + cost_Center_Code + "", dep_Code="" + dep_Code + "", department="" + department + "", sub_Department="" + sub_Department + "", division="" + division + '}';
    }

    @Override
    public int hashCode() {
        int hash = 7;
        hash = 79 * hash + Objects.hashCode(this.cost_Center_Code);
        hash = 79 * hash + Objects.hashCode(this.dep_Code);
        return hash;
    }

    @Override
    public boolean equals(Object obj) {
        if (obj == null) {
            return false;
        }
        if (getClass() != obj.getClass()) {
            return false;
        }
        final Department other = (Department) obj;
        if (!Objects.equals(this.cost_Center_Code, other.cost_Center_Code)) {
            return false;
        }
        if (!Objects.equals(this.dep_Code, other.dep_Code)) {
            return false;
        }
        return true;
    }

}

","I think,what you are looking for is EmbeddedId,You can do something like below.


First take out these column from your Department class,and create a new class like below.  

    @Embeddable    
    class CenterDeptId{

       @Column(name = ""center_code"")
       private String cost_Center_Code;

       @Column(name = ""dep_code"")
       private String dep_Code;

       // getter &amp;&amp; setter 

   }

Use the above class in your Department class

@Entity    
public class Department {

    @EmbeddedId
    private CenterDeptId centerDeptId;
    private String department;
    private String sub_Department;
    private String division;

  //getter &amp;&amp; setter

}


"
190,190,304,How do you prove $S=-\sum p\ln p$?,"How does one prove the formula for entropy $S=-\sum p\ln p$?
Obviously systems on the microscopic level are fully determined by the microscopic equations of motion. So if you want to introduce a law on top of that, you have to prove consistency, i.e. entropy cannot be a postulate.
I can imagine that it is derived from probability theory for general system. Do you know such a line?

Once you have such a reasoning, what are the assumptions to it?
Can these assumptions be invalid for special systems? Would these system not obey thermodynamics, statistical mechanics and not have any sort of temperature no matter how general?

If therodynamics/statmech are completely general, how would you apply them the system where one point particle orbits another?
",Gerenuk,https://physics.stackexchange.com/users/5152,"The theorem is called the noiseless coding theorem, and it is often proven in clunky ways in information theory books. The point of the theorem is to calculate the minimum number of bits per variable you need to encode the values of N identical random variables chosen from $1...K$ whose probabilities of having a value $i$ between $1$ and $K$ is $p_i$. The minimum number of bits you need on average per variable in the large N limit is defined to be the information in the random variable. It is the minimum number of bits of information per variable you need to record in a computer so as to remember the values of the N copies with perfect fidelity.

If the variables are uniformly distributed, the answer is obvious: there are $K^N$ possiblities for N throws, and $2^{CN}$ possiblities for $CN$ bits, so $C=\log_2(k)$ for large N. Any less than CN bits, and you will not be able to encode the values of the random variables, because they are all equally likely. Any more than this, you will have extra room. This is the information in a uniform random variable.

For a general distribution, you can get the answer with a little bit of law of large numbers. If you have many copies of the random variable, the sum of the probabilities is equal to 1,

$$ P(n_1, n_2, ... , n_k) = \prod_{j=1}^N p_{n_j}$$

This probability is dominated for large N by those configurations where the number of values of type i is equal to $Np_i$, since this is the mean number of the type i's. So that the P value on any typical configuration is:

$$ P(n_1,...,n_k) = \prod_{i=1}^k p_i^{Np_i} = e^{N\sum p_i \log(p_i)}$$

So for those possibilities where the probability is not extremely small, the probability is more or less constant and equal to the above value. The total number M(N) of these not-exceedingly unlikely possibilities is what is required to make the sum of probabilities equal to 1.

$$M(N) \propto e^{ - N \sum p_i \log(p_i)}$$

To encode which of the M(N) possiblities is realized in each N picks, you therefore need a number of bits B(N) which is enough to encode all these possibilities:

$$2^{B(N)} \propto e^{ - N \sum p_i \log(p_i)}$$

which means that

$${B(N)\over N} =  - \sum p_i \log_2(p_i)$$

And all subleading constants are washed out by the large N limit. This is the information, and the asymptotic equality above is the Shannon noiseless coding theorem. To make it rigorous, all you need are some careful bounds on the large number estimates.

Replica coincidences

There is another interpretation of the Shannon entropy in terms of coincidences which is interesting. Consider the probability that you pick two values of the random variable, and you get the same value twice:

$$P_2 = \sum p_i^2$$

This is clearly an estimate of how many different values there are to select from. If you ask what is the probability that you get the same value k-times in k-throws, it is

$$P_k = \sum p_i p_i^{k-1}$$

If you ask, what is the probability of a coincidence after $k=1+\epsilon$ throws, you get the Shannon entropy. This is like the replica trick, so I think it is good to keep in mind.

Entropy from information

To recover statistical mechanics from the Shannon information, you are given:


the values of the macroscopic conserved quantities (or their thermodynamic conjugates), energy, momentum, angular momentum, charge, and particle number
the macroscopic constraints (or their thermodynaic conjugates) volume, positions of macroscopic objects, etc.


Then the statistical distribution of the microscopic configuration is the maximum entropy distribution (as little information known to you as possible) on phase space satisfying the constraint that the quantities match the macroscopic quantities.
",Ron Maimon,https://physics.stackexchange.com/users/4864,http://physics.stackexchange.com/questions/14436/how-do-you-prove-s-sum-p-ln-p,SCIENCE,physics.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,0.5,1.0,1.0,0.5555555555555556,0.5555555555555556,0.6666666666666666,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.6666666666666666,0.3333333333333333,1.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.8888888888888888,How to prove $s = - \ sum P \ ln p $?,"How does one prove the formula for entropy $S=-\sum p\ln p$?
Obviously systems on the microscopic level are fully determined by the microscopic equations of motion. So if you want to introduce a law on top of that, you have to prove consistency, i.e. entropy cannot be a postulate.
I can imagine that it is derived from probability theory for general system. Do you know such a line?

Once you have such a reasoning, what are the assumptions to it?
Can these assumptions be invalid for special systems? Would these system not obey thermodynamics, statistical mechanics and not have any sort of temperature no matter how general?

If therodynamics/statmech are completely general, how would you apply them the system where one point particle orbits another?
","The theorem is called the noiseless coding theorem, and it is often proven in clunky ways in information theory books. The point of the theorem is to calculate the minimum number of bits per variable you need to encode the values of N identical random variables chosen from $1...K$ whose probabilities of having a value $i$ between $1$ and $K$ is $p_i$. The minimum number of bits you need on average per variable in the large N limit is defined to be the information in the random variable. It is the minimum number of bits of information per variable you need to record in a computer so as to remember the values of the N copies with perfect fidelity.

If the variables are uniformly distributed, the answer is obvious: there are $K^N$ possiblities for N throws, and $2^{CN}$ possiblities for $CN$ bits, so $C=\log_2(k)$ for large N. Any less than CN bits, and you will not be able to encode the values of the random variables, because they are all equally likely. Any more than this, you will have extra room. This is the information in a uniform random variable.

For a general distribution, you can get the answer with a little bit of law of large numbers. If you have many copies of the random variable, the sum of the probabilities is equal to 1,

$$ P(n_1, n_2, ... , n_k) = \prod_{j=1}^N p_{n_j}$$

This probability is dominated for large N by those configurations where the number of values of type i is equal to $Np_i$, since this is the mean number of the type i's. So that the P value on any typical configuration is:

$$ P(n_1,...,n_k) = \prod_{i=1}^k p_i^{Np_i} = e^{N\sum p_i \log(p_i)}$$

So for those possibilities where the probability is not extremely small, the probability is more or less constant and equal to the above value. The total number M(N) of these not-exceedingly unlikely possibilities is what is required to make the sum of probabilities equal to 1.

$$M(N) \propto e^{ - N \sum p_i \log(p_i)}$$

To encode which of the M(N) possiblities is realized in each N picks, you therefore need a number of bits B(N) which is enough to encode all these possibilities:

$$2^{B(N)} \propto e^{ - N \sum p_i \log(p_i)}$$

which means that

$${B(N)\over N} =  - \sum p_i \log_2(p_i)$$

And all subleading constants are washed out by the large N limit. This is the information, and the asymptotic equality above is the Shannon noiseless coding theorem. To make it rigorous, all you need are some careful bounds on the large number estimates.

Replica coincidences

There is another interpretation of the Shannon entropy in terms of coincidences which is interesting. Consider the probability that you pick two values of the random variable, and you get the same value twice:

$$P_2 = \sum p_i^2$$

This is clearly an estimate of how many different values there are to select from. If you ask what is the probability that you get the same value k-times in k-throws, it is

$$P_k = \sum p_i p_i^{k-1}$$

If you ask, what is the probability of a coincidence after $k=1+\epsilon$ throws, you get the Shannon entropy. This is like the replica trick, so I think it is good to keep in mind.

Entropy from information

To recover statistical mechanics from the Shannon information, you are given:


the values of the macroscopic conserved quantities (or their thermodynamic conjugates), energy, momentum, angular momentum, charge, and particle number
the macroscopic constraints (or their thermodynaic conjugates) volume, positions of macroscopic objects, etc.


Then the statistical distribution of the microscopic configuration is the maximum entropy distribution (as little information known to you as possible) on phase space satisfying the constraint that the quantities match the macroscopic quantities.
"
2760,2760,4398,Repair wood floor damage,"I just moved into a new house.  I have never had wooden floors until now.  Today, we moved a box and saw a strange waxy looking white gunk on the floor after moving a box.  Unknowingly, I scraped it off with my fingernails.  Now, I am pretty sure I scraped off the top layer of my wood floors finish.

I read about wood floor finishes.  Some say I should try to match the floor's finish, but I don't know what it is.  Others have said polyurathane can just be brushed on.  

The wood and stain appear to be fine, but this waxy stuff on top I destroyed.  Its about a 36sq in area that I destroyed.  

Damaged Floor 

Good Floor 


What can I do to fix this?  Do I need a professional?
",P.Brian.Mackey,https://diy.stackexchange.com/users/1707,"This is an educated guess only because I can't really see or feel what you are describing.  This may be old floor wax that has had something damp left sitting on it. Often in older homes folks would use old fashion floor waxes that will discolor or turn white with age, water, friction or heat.  You may first try using a little mineral spirits or a mild cleaning agent with a polishing compound, such as Bar Keepers Friend with a soft cloth on a small spot to see if it will remove the white residue. If in fact this floor has been treated with a wax product, the entire floor would have to be stripped of wax, perhaps buff sanded and restained, then protected with a few coats of Urethane. Don't attempt to apply urethane until you have determined what is causing the white waxy residue. Putting any coating such as urethane over a waxed floor will bubble, peel, and create a mess to clean up. another test you could do would be to gently scrape a very small section of the white stain with a putty knife. If the material comes off easily it may be wax.  it may be old varnish, but that would not feel waxy, but not out of the question.  Let us know what you find, and we can go from there.  Good Luck 
",shirlock homes,https://diy.stackexchange.com/users/386,http://diy.stackexchange.com/questions/6151/repair-wood-floor-damage,LIFE_ARTS,diy.stackexchange.com,1.0,0.5555555555555556,0.0,0.6666666666666666,1.0,0.6666666666666666,0.5555555555555556,0.5555555555555556,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,1.0,1.0,0.7777777777777778,0.8888888888888888,1.0,0.9333333333333332,1.0,0.3333333333333333,0.6666666666666666,1.0,Repair wood floor damage,"I just moved into a new house.  I have never had wooden floors until now.  Today, we moved a box and saw a strange waxy looking white gunk on the floor after moving a box.  Unknowingly, I scraped it off with my fingernails.  Now, I am pretty sure I scraped off the top layer of my wood floors finish.

I read about wood floor finishes.  Some say I should try to match the floor's finish, but I don't know what it is.  Others have said polyurathane can just be brushed on.  

The wood and stain appear to be fine, but this waxy stuff on top I destroyed.  Its about a 36sq in area that I destroyed.  

Damaged Floor 

Good Floor 


What can I do to fix this?  Do I need a professional?
","This is an educated guess only because I can't really see or feel what you are describing.  This may be old floor wax that has had something damp left sitting on it. Often in older homes folks would use old fashion floor waxes that will discolor or turn white with age, water, friction or heat.  You may first try using a little mineral spirits or a mild cleaning agent with a polishing compound, such as Bar Keepers Friend with a soft cloth on a small spot to see if it will remove the white residue. If in fact this floor has been treated with a wax product, the entire floor would have to be stripped of wax, perhaps buff sanded and restained, then protected with a few coats of Urethane. Don't attempt to apply urethane until you have determined what is causing the white waxy residue. Putting any coating such as urethane over a waxed floor will bubble, peel, and create a mess to clean up. another test you could do would be to gently scrape a very small section of the white stain with a putty knife. If the material comes off easily it may be wax.  it may be old varnish, but that would not feel waxy, but not out of the question.  Let us know what you find, and we can go from there.  Good Luck 
"
686,686,1083,What should I look for in a recording microphone for personal use?,"I was browsing through mics on Amazon and quickly realized I was out of my depth.  There are a couple closely related questions I am wondering about:


Are there different types of mics for (1) singing into at a concert, (2) singing into in a quiet room, and (3) picking up sound at more of a distance (e.g., singing and playing guitar and having both recorded with the one mic)?  What are they?
I'm most interested in a mic for case (3).  This is obviously not professional, I just want something with passable quality and not too much noise considering I'll be in a random room in a house or apartment.  What kind of things should I look for in a mic to achieve that?  What are the factors that most depend on price?  (If it's feasible I'd like to try to fit it into my $50 contest reward.)
There are a few terms I saw like ""moving coil"", ""condenser"", and ""dynamic"" that I saw used to describe mics.  If you could touch on these and any other relevant terminology that would be awesome.

",Matthew Read,https://music.stackexchange.com/users/28,"Great question.  What all this really boils down to is the polar pattern or pickup pattern of the microphone.  Some mics will pick up more sound from the front and less from the sides and rear.  Mics that are extremely directional are good for rejecting the loud drums behind you and also rejecting the sound from a PA speaker that might be right in front of you.  Many handheld mics have this type of cardioid or supercardioid pattern.  Other specialty mics have different patterns that may pick up from all around or just from the front or back.  These may be options for you, but won't be as flexible in the long run.  

Once you decide on a pickup pattern for your needs, you can start looking at the mechanics of how the mic works - condenser, dynamic, ribbon ... all that stuff.  You could stick a dynamic in front of you and your guitar and end up with a passable result.  Personally, I'd go for a large diaphragm condenser since they seem to pick up a bit more of the bass and give a nice sound in a solo context.  The range of choices is dizzying, so nail down a price range and pick one based on reviews and whatever else matters to you.  More expensive mics have higher quality components that will produce a better sound.  Audio equipment gets expensive fast and there's not much payoff over a certain level.  You also have to think about WHERE you are recording, as room acoustics can 'cheapen' your sound.

You need to have something to plug this microphone into - typically called a preamplifier or preamp.  These are built into mixers, computer audio interfaces or stand alone units.  A shure 57 or 58 can really shine with a good preamp.  If you plug it into a low quality preamp, you'll get a low signal, a noisy signal or a quiet/noisy signal - yuck.  If you have a condenser microphone, the preamp will need phantom power in order for the microphone to work.

Some other ideas for you...

Another option might be a hand held recorder which can be carted around, run off battery power and then transferred to your computer for editing and distribution.  Super easy and cheap.  And you don't need a computer with you - which is always nice.  Other options are recording with a phone using some kind of USB microphone.

I have a video demonstrating polar patterns here:  
            
                
                    
                    
                    
                    
                    
                
            
",Sam,https://music.stackexchange.com/users/3537,http://music.stackexchange.com/questions/8312/what-should-i-look-for-in-a-recording-microphone-for-personal-use,LIFE_ARTS,music.stackexchange.com,1.0,0.4444444444444444,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.4444444444444444,0.3333333333333333,0.0,0.6666666666666666,0.0,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,0.8888888888888888,What should I find in the recording microphone for personal use?,"I was browsing through mics on Amazon and quickly realized I was out of my depth.  There are a couple closely related questions I am wondering about:


Are there different types of mics for (1) singing into at a concert, (2) singing into in a quiet room, and (3) picking up sound at more of a distance (e.g., singing and playing guitar and having both recorded with the one mic)?  What are they?
I'm most interested in a mic for case (3).  This is obviously not professional, I just want something with passable quality and not too much noise considering I'll be in a random room in a house or apartment.  What kind of things should I look for in a mic to achieve that?  What are the factors that most depend on price?  (If it's feasible I'd like to try to fit it into my $50 contest reward.)
There are a few terms I saw like ""moving coil"", ""condenser"", and ""dynamic"" that I saw used to describe mics.  If you could touch on these and any other relevant terminology that would be awesome.

","Great question.  What all this really boils down to is the polar pattern or pickup pattern of the microphone.  Some mics will pick up more sound from the front and less from the sides and rear.  Mics that are extremely directional are good for rejecting the loud drums behind you and also rejecting the sound from a PA speaker that might be right in front of you.  Many handheld mics have this type of cardioid or supercardioid pattern.  Other specialty mics have different patterns that may pick up from all around or just from the front or back.  These may be options for you, but won't be as flexible in the long run.  

Once you decide on a pickup pattern for your needs, you can start looking at the mechanics of how the mic works - condenser, dynamic, ribbon ... all that stuff.  You could stick a dynamic in front of you and your guitar and end up with a passable result.  Personally, I'd go for a large diaphragm condenser since they seem to pick up a bit more of the bass and give a nice sound in a solo context.  The range of choices is dizzying, so nail down a price range and pick one based on reviews and whatever else matters to you.  More expensive mics have higher quality components that will produce a better sound.  Audio equipment gets expensive fast and there's not much payoff over a certain level.  You also have to think about WHERE you are recording, as room acoustics can 'cheapen' your sound.

You need to have something to plug this microphone into - typically called a preamplifier or preamp.  These are built into mixers, computer audio interfaces or stand alone units.  A shure 57 or 58 can really shine with a good preamp.  If you plug it into a low quality preamp, you'll get a low signal, a noisy signal or a quiet/noisy signal - yuck.  If you have a condenser microphone, the preamp will need phantom power in order for the microphone to work.

Some other ideas for you...

Another option might be a hand held recorder which can be carted around, run off battery power and then transferred to your computer for editing and distribution.  Super easy and cheap.  And you don't need a computer with you - which is always nice.  Other options are recording with a phone using some kind of USB microphone.

I have a video demonstrating polar patterns here:  
            
                
                    
                    
                    
                    
                    
                
            
"
2850,2850,4535,"Does the Canon *.CR2/CRW format contain ""truly RAW"" data?","In my work I am dealing with *.CR2 raw images taken by a Canon DSLR in raw mode.
When I read about the format here, I was surprised to find that it has 4 TIFF IFDs which contain a) Original Size JPEG Image b) Thumbnail JPEG image c) Uncompressed RGB data d) Lossless JPEG image.

My impression until now was any camera captured RAW image file would have Raw Bayer Data i.e. R,Gr,B,Gb kind of bayer data, and some EXIF data about camera capture settings etc.

But after reading this CR2 specification I am slightly confused as to how can it have a RGB data or even surprisingly JPEG data. This seems to be the data after demosaicing(obtaining the missing R/G/B pixel data for the original sensor Bayer pattern). If thats the case I would not consider *.CR2 as ""truly raw"" data. It has done demosaicing before dumping the socalled raw file.

Am I missing something?

Does any other Camera Raw formats(e.g. Nikon - *.NEF, Kodac - *.kdc, Pentax - *.ptx/pef,...) have real raw bayer data without any processing done?
",goldenmean,https://photo.stackexchange.com/users/2438,"I think you are most definitely missing something. Consider: JPG is used to store (and usually compress, lossy) images. Any image. What is an image? It is a great big bundle of pixels, when all is said and done.

The output from the camera sensor is a great big bundle of pixels, too. They just happen not to be full-colour RGB pixels, they are monochrome pixels - whether any individual pixel represents R G or B depends on its location on the image sensor, which is known. But their monochrome, colour-given-by-position nature does not mean that they cannot be usefully stored in the JPG way. A bundle of pixels is a bundle of pixels, and why reinvent the wheel?

Look more closely at the document. ""So with a BAYER grid of RG/GB, the even rows has interleaved HuffCode/Diff data for ...RGRGRG..., while the odd rows it is ...GBGBGB..."". So, the raw Bayer output is stored in a JPG format. Lossless, it is stated (otherwise we'd have a problem!) and presumably in more than 8 bits' depth. You have too cook this quite a lot to get a useful photo from it. 

The other JPG images are used for in-camera preview, histogram and such. It makes good sense to cook these once and for all as the image is taken, rather than having to do it on the fly each and every time you want to look at them. This also means that the computer can fish these out for thumbnail purposes once you unload the camera into the PC.

* I can't add a comment for some reason, so this goes here:
Goldenmean, what makes you think that there is a problem that you don't have full RGB info for each pixel? Assuming that you are creating a RAW format and have a measurement of 128 from a ""red"" sensor cell; you can either choose to store this as 128,0,0 or 128,128,128 or, of you are feeling clever, 128,""data from next cell"", ""data from the cell after that"" to save some space. Doesn't matter really. It's the RAW converter's job to keep track of this (though I'm sure the programmers would appreciate it if you documented how you chose to store your sensor data) and make an actual picture from it.
",Staale S,https://photo.stackexchange.com/users/3458,http://photo.stackexchange.com/questions/10440/does-the-canon-cr2-crw-format-contain-truly-raw-data,LIFE_ARTS,photo.stackexchange.com,0.8888888888888888,0.8888888888888888,0.0,0.5,1.0,1.0,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.3333333333333333,0.0,0.3333333333333333,1.0,0.0,0.7777777777777778,0.8888888888888888,0.7777777777777778,1.0,0.8888888888888888,0.8,0.0,0.6666666666666666,1.0,0.7777777777777778,"Does Canon *. CR2 / CRW format contain ""real raw"" data?","In my work I am dealing with *.CR2 raw images taken by a Canon DSLR in raw mode.
When I read about the format here, I was surprised to find that it has 4 TIFF IFDs which contain a) Original Size JPEG Image b) Thumbnail JPEG image c) Uncompressed RGB data d) Lossless JPEG image.

My impression until now was any camera captured RAW image file would have Raw Bayer Data i.e. R,Gr,B,Gb kind of bayer data, and some EXIF data about camera capture settings etc.

But after reading this CR2 specification I am slightly confused as to how can it have a RGB data or even surprisingly JPEG data. This seems to be the data after demosaicing(obtaining the missing R/G/B pixel data for the original sensor Bayer pattern). If thats the case I would not consider *.CR2 as ""truly raw"" data. It has done demosaicing before dumping the socalled raw file.

Am I missing something?

Does any other Camera Raw formats(e.g. Nikon - *.NEF, Kodac - *.kdc, Pentax - *.ptx/pef,...) have real raw bayer data without any processing done?
","I think you are most definitely missing something. Consider: JPG is used to store (and usually compress, lossy) images. Any image. What is an image? It is a great big bundle of pixels, when all is said and done.

The output from the camera sensor is a great big bundle of pixels, too. They just happen not to be full-colour RGB pixels, they are monochrome pixels - whether any individual pixel represents R G or B depends on its location on the image sensor, which is known. But their monochrome, colour-given-by-position nature does not mean that they cannot be usefully stored in the JPG way. A bundle of pixels is a bundle of pixels, and why reinvent the wheel?

Look more closely at the document. ""So with a BAYER grid of RG/GB, the even rows has interleaved HuffCode/Diff data for ...RGRGRG..., while the odd rows it is ...GBGBGB..."". So, the raw Bayer output is stored in a JPG format. Lossless, it is stated (otherwise we'd have a problem!) and presumably in more than 8 bits' depth. You have too cook this quite a lot to get a useful photo from it. 

The other JPG images are used for in-camera preview, histogram and such. It makes good sense to cook these once and for all as the image is taken, rather than having to do it on the fly each and every time you want to look at them. This also means that the computer can fish these out for thumbnail purposes once you unload the camera into the PC.

* I can't add a comment for some reason, so this goes here:
Goldenmean, what makes you think that there is a problem that you don't have full RGB info for each pixel? Assuming that you are creating a RAW format and have a measurement of 128 from a ""red"" sensor cell; you can either choose to store this as 128,0,0 or 128,128,128 or, of you are feeling clever, 128,""data from next cell"", ""data from the cell after that"" to save some space. Doesn't matter really. It's the RAW converter's job to keep track of this (though I'm sure the programmers would appreciate it if you documented how you chose to store your sensor data) and make an actual picture from it.
"
1667,1667,2636,My.Computer.FileSystem.DeleteDirectory() with read only files?,"I recently came across a problem with My.Computer.FileSystem.DeleteDirectory(). It will not delete read only files.

I found out by Googling that I could delete the read only files by changing the file attributes to 'Normal'. So I wrote a recursive function, as below.

Private Sub DeleteDir(ByVal dir As DirectoryInfo)

    For Each d In dir.GetDirectories
        DeleteDir(d)
    Next
    For Each f In dir.GetFiles
        Try
            f.Attributes = FileAttributes.Normal
            f.Delete()
        Catch ex As Exception
            Log(ex.Message)
        End Try
    Next
    dir.Delete(True)
End Sub


It seems to work fine, but it would be nice if My.Computer.FileSystem.DeleteDirectory() had another parameter to delete read only files, or there was an easier way to do this.
",Rots,https://stackoverflow.com/users/455770,"The short answer is there isn't a method provided in the framework. You have to develop your own. What you have written is good. I prefer the following as it make use of extension methods and more clearly describes what the method does.

Imports System
Imports System.IO
Imports System.Runtime.CompilerServices
Imports System.Linq

Public Module DirectoryExtensions

    &lt;Extension()&gt;
    Public Sub Delete(directory As DirectoryInfo, 
                      recursive As Boolean, 
                      forceReadOnlyDelete As Boolean
    )
        directory.ForceDelete()
    End Sub

    &lt;Extension()&gt;
    Public Sub ForceDelete(ByVal directory As DirectoryInfo)

        directory.RemoveReadOnlyAttributeFromFiles(True)
        directory.Delete(True)

    End Sub

    &lt;Extension()&gt;
    Public Sub RemoveReadOnlyAttributeFromFiles(ByVal directory As DirectoryInfo, ByVal recursive As Boolean)

        Dim readOnlyFiles = From f In directory.GetFiles()
            Where (f.Attributes And FileAttributes.ReadOnly) = FileAttributes.ReadOnly

        For Each file In readOnlyFiles
            file.Attributes = FileAttributes.Normal
        Next

        If recursive Then

            For Each subDirectory In directory.GetDirectories()
                subDirectory.RemoveReadOnlyAttributeFromFiles(True)
            Next

        End If

    End Sub

End Module

",Tim Murphy,https://stackoverflow.com/users/22941,http://stackoverflow.com/questions/3775471/my-computer-filesystem-deletedirectory-with-read-only-files,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.4444444444444444,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.0,0.3333333333333333,0.8888888888888888,Does my. Computer. Filesystem. Deletedirectory() contain read-only files?,"I recently came across a problem with My.Computer.FileSystem.DeleteDirectory(). It will not delete read only files.

I found out by Googling that I could delete the read only files by changing the file attributes to 'Normal'. So I wrote a recursive function, as below.

Private Sub DeleteDir(ByVal dir As DirectoryInfo)

    For Each d In dir.GetDirectories
        DeleteDir(d)
    Next
    For Each f In dir.GetFiles
        Try
            f.Attributes = FileAttributes.Normal
            f.Delete()
        Catch ex As Exception
            Log(ex.Message)
        End Try
    Next
    dir.Delete(True)
End Sub


It seems to work fine, but it would be nice if My.Computer.FileSystem.DeleteDirectory() had another parameter to delete read only files, or there was an easier way to do this.
","The short answer is there isn't a method provided in the framework. You have to develop your own. What you have written is good. I prefer the following as it make use of extension methods and more clearly describes what the method does.

Imports System
Imports System.IO
Imports System.Runtime.CompilerServices
Imports System.Linq

Public Module DirectoryExtensions

    &lt;Extension()&gt;
    Public Sub Delete(directory As DirectoryInfo, 
                      recursive As Boolean, 
                      forceReadOnlyDelete As Boolean
    )
        directory.ForceDelete()
    End Sub

    &lt;Extension()&gt;
    Public Sub ForceDelete(ByVal directory As DirectoryInfo)

        directory.RemoveReadOnlyAttributeFromFiles(True)
        directory.Delete(True)

    End Sub

    &lt;Extension()&gt;
    Public Sub RemoveReadOnlyAttributeFromFiles(ByVal directory As DirectoryInfo, ByVal recursive As Boolean)

        Dim readOnlyFiles = From f In directory.GetFiles()
            Where (f.Attributes And FileAttributes.ReadOnly) = FileAttributes.ReadOnly

        For Each file In readOnlyFiles
            file.Attributes = FileAttributes.Normal
        Next

        If recursive Then

            For Each subDirectory In directory.GetDirectories()
                subDirectory.RemoveReadOnlyAttributeFromFiles(True)
            Next

        End If

    End Sub

End Module

"
1123,1123,1763,Finding out which version PHP a remote server is running,"I can't imagine this is possible but maybe there's some novel way. I'm developing an app which will require a few php files to be deployed and run on the clients' webservers. I'm not particularly interested in targeting clients who are still running pre version 5 versions of PHP.

So is there any way one can tell which version of PHP a remote webserver has running?
",jontyc,https://serverfault.com/users/77339,"You can use a site to view http headers such as http://web-sniffer.net/

Some sites will return the PHP version in the server section of the header for example here's a response from a site I just tested:

Server: Apache/2.2.14 (Unix) mod_ssl/2.2.14 OpenSSL/0.9.8e-fips-rhel5 
mod_auth_passthrough/2.1 mod_bwlimited/1.4 FrontPage/5.0.2.2635 PHP/5.2.12


This is more likely to work on sites hosted on a standard shared hosting platform such as cPanel.
",Darryl at NetHosted,https://serverfault.com/users/78405,http://serverfault.com/questions/268096,TECHNOLOGY,serverfault.com,0.4444444444444444,0.8888888888888888,0.0,1.0,1.0,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.8888888888888888,0.6666666666666666,0.6666666666666666,1.0,1.0,0.8,0.3333333333333333,0.6666666666666666,0.0,1.0,Find out which version of PHP the remote server is running,"I can't imagine it is possible, but there may be some novel ways. I am developing an application that needs to deploy and run some PHP files on the client's web server. I'm not particularly interested in target customers who are still running pre version 5 of PHP.","You can use a site to view http headers such as http://web-sniffer.net/

Some sites will return the PHP version in the server section of the header for example here's a response from a site I just tested:

Server: Apache/2.2.14 (Unix) mod_ssl/2.2.14 OpenSSL/0.9.8e-fips-rhel5 
mod_auth_passthrough/2.1 mod_bwlimited/1.4 FrontPage/5.0.2.2635 PHP/5.2.12


This is more likely to work on sites hosted on a standard shared hosting platform such as cPanel.
"
3502,3502,5583,How was the sword of Gryffindor pulled from the hat a second time?,"Spoilers follow, and this is from the books (not the movies)...

In The Chamber of Secrets:


   Harry retrieves Goderic Gryffindor's sword from the sorting hat during the confrontation with the basilisk. After this Dumbledore keeps hold of the sword in a glass case in his office. 


Then in The Deathly Hallows:


   Harry and Ron do a deal with Griphook to return Gryffindor's sword to the goblins after they have retrieved Hufflepuff's cup, planning to partially double cross him by holding on to it until all the horcruxes have been destroyed. However Griphook double crosses them first, and keeps hold of the sword.


Then, in the battle at the end of the book:


   Voldemort puts the sorting hat on Neville Longbottom's head and sets him on fire. Instead of burning Neville pulls Gryffindor's sword out of the sorting hat and beheads Nagini, destroying Voldemort's last horcrux.


However, if the sword could always be pulled out of the hat by someone sufficiently heroic then why the need to:


   Create a copy of the sword to fool Bellatrix Lestrange into thinking she had the real one in Gringott's vault? Why forge a copy and risk Snape placing it in the lake if it could always have been pulled from the sorting hat, regardless of where it was or how it was protected?


How was Gryffindor's sword pulled from the hat the second time? Surely it was beyond the reach of accio or any other charms once returned to its goblin creators?
",Keith,https://scifi.stackexchange.com/users/2154,"Perhaps the Sorting Hat is the sheath for the Sword of Gryffindor, like how in 'Percy Jackson and the Lightning Thief',


  the backpack Ares gave Percy was the sheath for Zeus's Master Bolt.

",Keeper of the Fandom,https://scifi.stackexchange.com/users/21824,http://scifi.stackexchange.com/questions/34005/how-was-the-sword-of-gryffindor-pulled-from-the-hat-a-second-time,LIFE_ARTS,scifi.stackexchange.com,1.0,0.5555555555555556,0.6666666666666666,0.0,0.3333333333333333,0.0,1.0,0.8888888888888888,1.0,0.0,1.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.6666666666666666,0.4444444444444444,0.6666666666666666,0.6666666666666666,0.6,0.0,0.0,1.0,0.7777777777777778,How did Gryffindor's sword come out of his hat?,"Spoilers follow, and this is from the books (not the movies)...

In The Chamber of Secrets:


   Harry retrieves Goderic Gryffindor's sword from the sorting hat during the confrontation with the basilisk. After this Dumbledore keeps hold of the sword in a glass case in his office. 


Then in The Deathly Hallows:


   Harry and Ron do a deal with Griphook to return Gryffindor's sword to the goblins after they have retrieved Hufflepuff's cup, planning to partially double cross him by holding on to it until all the horcruxes have been destroyed. However Griphook double crosses them first, and keeps hold of the sword.


Then, in the battle at the end of the book:


   Voldemort puts the sorting hat on Neville Longbottom's head and sets him on fire. Instead of burning Neville pulls Gryffindor's sword out of the sorting hat and beheads Nagini, destroying Voldemort's last horcrux.


However, if the sword could always be pulled out of the hat by someone sufficiently heroic then why the need to:


   Create a copy of the sword to fool Bellatrix Lestrange into thinking she had the real one in Gringott's vault? Why forge a copy and risk Snape placing it in the lake if it could always have been pulled from the sorting hat, regardless of where it was or how it was protected?


How was Gryffindor's sword pulled from the hat the second time? Surely it was beyond the reach of accio or any other charms once returned to its goblin creators?
","Perhaps the Sorting Hat is the sheath for the Sword of Gryffindor, like how in 'Percy Jackson and the Lightning Thief',


  the backpack Ares gave Percy was the sheath for Zeus's Master Bolt.

"
1370,1370,2155,Idolatry in churches allowed?,"It is very frequent to see idols of Jesus or any biblical entities in  a Church , So is such idolatry allowed by  the bible,considering the following verses?


  ""You must not make for yourself an idol of any kind or an image of anything in the heavens or on the earth or in the sea"".
  Exodus 20:4


History tells us that:


  sometimes objects that God instructed to be made were turned into
  idols by the Israelites. The Book of Numbers contains a narrative in
  which God instructed Moses to make a bronze snake as part of
  addressing a plague of venomous snakes that had broken out among the
  Israelites as a punishment for sin. The bronze snake is mentioned
  again in 2 Kings 18; however, rather than remaining a memorial of
  God's providence, it became an idol that the people named and
  worshiped. Thus the bronze snake was destroyed in King Hezekiah's
  reforms.


More specifically in India I see Christians carry idols of Jesus and other biblical  entities with them kiss them and revere them too. Infact they allow the Hindus in the Church and let them perform worship in their way(Like putting incense sticks, offering flowers , foodstuff to the Idol of Jesus etc) as shown below a very common view in India. I studied in a Christian school for 10 years and i am yet to see Christians not doing these things.

I have seen the same on TV and in videos of people venerating the Idol of biblical entities.


",JesusBoughtIslam,https://christianity.stackexchange.com/users/3812,"You're operating under a misconception that these are idols. Most Christians don't worship these images, statues, etc. Instead, they are considered art, something that we  create because we love the subject, not the work of art.

Asking your question is like asking if looking at a painting of my wife means that I am allowed to cheat on her by devoting my affection to an image of her. I love her, not the painting of her. Christians love Jesus, not the statues of Him.

So, the answer id no, idolatry isn't allowed in Churches.  

Addressing the updates to the question, the things that people are ""venerating"" are likely ""Sacrementals"".


  Sacramentals are material objects, things or actions (sacramentalia) set apart or blessed by the Roman and Eastern Catholic
  Churches, the Eastern and Oriental Orthodox Churches, the Church of
  the East, the Anglican Churches, the Independent and Old Catholic
  Churches, and the Lutheran Churches to manifest the respect due to the
  sacraments, and so to excite good thoughts and to increase devotion,
  and through these movements of the heart to remit venial sin,
  according to the Council of Trent (Session XXII, 15).
  
  In Roman Catholicism, sacramentals such as Holy water, the crucifix or
  the Saint Benedict Medal are recommended as a means of protection
  against evil.


Again, the devotion is not to these things, but to the God they represent. There are, those that do worship them like idols, and many view the idea that these could protect us from evil as superstitious, the point remains that officially, these aren't idols. They aren't to be worshiped. They are reminders of the one we should be worshiping.
",David Stratton,https://christianity.stackexchange.com/users/721,http://christianity.stackexchange.com/questions/14615/idolatry-in-churches-allowed,CULTURE,christianity.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,0.3333333333333333,0.6666666666666666,0.0,0.5555555555555556,0.5555555555555556,0.0,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,1.0,Are idolatry allowed in church?,"It is very frequent to see idols of Jesus or any biblical entities in  a Church , So is such idolatry allowed by  the bible,considering the following verses?


  ""You must not make for yourself an idol of any kind or an image of anything in the heavens or on the earth or in the sea"".
  Exodus 20:4


History tells us that:


  sometimes objects that God instructed to be made were turned into
  idols by the Israelites. The Book of Numbers contains a narrative in
  which God instructed Moses to make a bronze snake as part of
  addressing a plague of venomous snakes that had broken out among the
  Israelites as a punishment for sin. The bronze snake is mentioned
  again in 2 Kings 18; however, rather than remaining a memorial of
  God's providence, it became an idol that the people named and
  worshiped. Thus the bronze snake was destroyed in King Hezekiah's
  reforms.


More specifically in India I see Christians carry idols of Jesus and other biblical  entities with them kiss them and revere them too. Infact they allow the Hindus in the Church and let them perform worship in their way(Like putting incense sticks, offering flowers , foodstuff to the Idol of Jesus etc) as shown below a very common view in India. I studied in a Christian school for 10 years and i am yet to see Christians not doing these things.

I have seen the same on TV and in videos of people venerating the Idol of biblical entities.


","You're operating under a misconception that these are idols. Most Christians don't worship these images, statues, etc. Instead, they are considered art, something that we  create because we love the subject, not the work of art.

Asking your question is like asking if looking at a painting of my wife means that I am allowed to cheat on her by devoting my affection to an image of her. I love her, not the painting of her. Christians love Jesus, not the statues of Him.

So, the answer id no, idolatry isn't allowed in Churches.  

Addressing the updates to the question, the things that people are ""venerating"" are likely ""Sacrementals"".


  Sacramentals are material objects, things or actions (sacramentalia) set apart or blessed by the Roman and Eastern Catholic
  Churches, the Eastern and Oriental Orthodox Churches, the Church of
  the East, the Anglican Churches, the Independent and Old Catholic
  Churches, and the Lutheran Churches to manifest the respect due to the
  sacraments, and so to excite good thoughts and to increase devotion,
  and through these movements of the heart to remit venial sin,
  according to the Council of Trent (Session XXII, 15).
  
  In Roman Catholicism, sacramentals such as Holy water, the crucifix or
  the Saint Benedict Medal are recommended as a means of protection
  against evil.


Again, the devotion is not to these things, but to the God they represent. There are, those that do worship them like idols, and many view the idea that these could protect us from evil as superstitious, the point remains that officially, these aren't idols. They aren't to be worshiped. They are reminders of the one we should be worshiping.
"
1772,1772,2814,Fast multi-tag search plus result ordering and paging?,"Can somebody explain how StackOverflow search works? I would like to add same features to a project I'm working on.

In SO, it's possible to filter the questions by multiple tags (e.g. c#, java) and get results sorted/paged by date or number of votes?

I realize that RDBMS with full-text engine can be used to filter and sort the questions but I'm not sure if that's the best solution? 

Is it possible to somehow get top N ordered results from a full-text index?

Maybe Lucene.NET or Redis or something similar is used?
",Marko,https://stackoverflow.com/users/230279,"
As of April 2011, Stackoverflow uses Lucene.NET. 



  Source: (Jeff Atwood) http://blog.stackoverflow.com/2011/01/stack-overflow-search-now-81-less-crappy/



Their old method was Homebrew + Full Text SQL 
How to search by tags in Lucene
Top N with Lucene
Paging with Lucene

",Brian Webster,https://stackoverflow.com/users/127880,http://stackoverflow.com/questions/6089441/fast-multi-tag-search-plus-result-ordering-and-paging,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.3333333333333333,0.0,1.0,1.0,1.0,0.5555555555555556,0.5555555555555556,0.6666666666666666,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.5555555555555556,0.7777777777777778,0.4444444444444444,1.0,0.8888888888888888,0.6,0.0,0.3333333333333333,0.0,0.7777777777777778,Fast multi label search with result sorting and paging?,"Can somebody explain how StackOverflow search works? I would like to add same features to a project I'm working on.

In SO, it's possible to filter the questions by multiple tags (e.g. c#, java) and get results sorted/paged by date or number of votes?

I realize that RDBMS with full-text engine can be used to filter and sort the questions but I'm not sure if that's the best solution? 

Is it possible to somehow get top N ordered results from a full-text index?

Maybe Lucene.NET or Redis or something similar is used?
","
As of April 2011, Stackoverflow uses Lucene.NET. 



  Source: (Jeff Atwood) http://blog.stackoverflow.com/2011/01/stack-overflow-search-now-81-less-crappy/



Their old method was Homebrew + Full Text SQL 
How to search by tags in Lucene
Top N with Lucene
Paging with Lucene

"
3842,3842,6108,SQL Help in Access – Looking for the Absence of Data,"I am trying to find the fastest way to find all of the records in a parent table that do not have certain records in a child table. For example, I want the query to return all of the family records where there are no male children or no children at all. 

Example 1

This is painfully slow:

SELECT * FROM Families
WHERE Families.FamilyID NOT IN(SELECT FamilyID FROM Children WHERE Children.Gender=""m"")

Example 2

This is faster:

SELECT * FROM Families
WHERE NOT EXISTS(SELECT * FROM Children WHERE Children.Gender=""m"" AND Children.FamilyID = Families.FamilyID)

Example 3

This is the fastest, but I'm worried about investing in it because I can't find any documentation on it. I don't even know what it's called. For want of a better term, we have been calling it an ""anonymous query"". 

SELECT * FROM Families
LEFT JOIN
[SELECT * FROM Children WHERE Gender=""m""]. AS AliasChildren
ON Families.FamilyID=AliasChildren.FamilyID
WHERE AliasChildren.FamilyID IS NULL

So my question is this:


What is this thing called in example 3?
Is it a ""mainstream"" feature of Access that
will be supported in the future?
Where can I find documentation on
it (this might be easier once I know what it's called)?


Thanks!
",Shane Miskin,https://stackoverflow.com/users/16415,"I think you could also try something like this:

SELECT * 
FROM Families 
WHERE Families.FamilyID IN (
  SELECT Children.FamilyID
  FROM Children
  WHERE Children.Gender&lt;>'m'
  GROUP BY Children.FamilyID
)
",aintnoprophet,https://stackoverflow.com/users/90332,http://stackoverflow.com/questions/752048/sql-help-in-access-looking-for-the-absence-of-data,STACKOVERFLOW,stackoverflow.com,1.0,0.3333333333333333,0.0,0.6666666666666666,0.3333333333333333,1.0,0.4444444444444444,0.3333333333333333,0.6666666666666666,0.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.6666666666666666,0.0,0.5555555555555556,0.8888888888888888,0.4444444444444444,1.0,0.8888888888888888,0.7333333333333333,1.0,0.0,0.0,0.8888888888888888,SQL help in access - finding missing data,"I am trying to find the fastest way to find all of the records in a parent table that do not have certain records in a child table. For example, I want the query to return all of the family records where there are no male children or no children at all. 

Example 1

This is painfully slow:

SELECT * FROM Families
WHERE Families.FamilyID NOT IN(SELECT FamilyID FROM Children WHERE Children.Gender=""m"")

Example 2

This is faster:

SELECT * FROM Families
WHERE NOT EXISTS(SELECT * FROM Children WHERE Children.Gender=""m"" AND Children.FamilyID = Families.FamilyID)

Example 3

This is the fastest, but I'm worried about investing in it because I can't find any documentation on it. I don't even know what it's called. For want of a better term, we have been calling it an ""anonymous query"". 

SELECT * FROM Families
LEFT JOIN
[SELECT * FROM Children WHERE Gender=""m""]. AS AliasChildren
ON Families.FamilyID=AliasChildren.FamilyID
WHERE AliasChildren.FamilyID IS NULL

So my question is this:


What is this thing called in example 3?
Is it a ""mainstream"" feature of Access that
will be supported in the future?
Where can I find documentation on
it (this might be easier once I know what it's called)?


Thanks!
","I think you could also try something like this:

SELECT * 
FROM Families 
WHERE Families.FamilyID IN (
  SELECT Children.FamilyID
  FROM Children
  WHERE Children.Gender&lt;>'m'
  GROUP BY Children.FamilyID
)
"
1891,1891,3011,What is it called when a music has two concurrent tempos,"I've recently watched a BBC documentary about the history of music and recall an episode where they talk about music that has two distinct tempos (and possibly time signatures) at the same time for different sets of instruments.

Still, I can't remember how this is called and who are the famous composers that composed that way (Stravinsky?).
",Arthur Rizzo,https://music.stackexchange.com/users/16830,"There is both polymeter and polyrhythm.


  Polymeter is sometimes referred to as ""tactus-preserving polymeter."" The measure size differs, the beat is the same. Since the beat is the same, the various meters eventually agree.


https://en.wikipedia.org/wiki/Meter_%28music%29#Polymeter

A good example of polymeter is the Tala which is an extream form of complex time.


  Polyrhythm is the simultaneous use of two or more conflicting rhythms, that are not readily perceived as deriving from one another, or as simple manifestations of the same meter. The rhythmic conflict may be the basis of an entire piece of music (cross-rhythm), or a momentary disruption. Polyrhythms can be distinguished from irrational rhythms, which can occur within the context of a single part; polyrhythms require at least two rhythms to be played concurrently, one of which is typically an irrational rhythm.


https://en.wikipedia.org/wiki/Polyrhythm

Commonly used in modren Jazz.  See: Mongo Santamaria and Elvin Jones.
",J. A. Streich,https://music.stackexchange.com/users/15415,http://music.stackexchange.com/questions/30524/what-is-it-called-when-a-music-has-two-concurrent-tempos,LIFE_ARTS,music.stackexchange.com,1.0,0.6666666666666666,0.0,1.0,1.0,1.0,0.6666666666666666,0.7777777777777778,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,0.7777777777777778,1.0,0.5555555555555556,1.0,0.8888888888888888,0.8666666666666666,0.0,0.0,0.3333333333333333,0.8888888888888888,What is the name of a music when it has two simultaneous rhythms,"I recently watched a BBC Documentary on the history of music, and I recall an episode in which they talked about music that has two different rhythms (and possibly time characteristics) in different instrument combinations.","There is both polymeter and polyrhythm.


  Polymeter is sometimes referred to as ""tactus-preserving polymeter."" The measure size differs, the beat is the same. Since the beat is the same, the various meters eventually agree.


https://en.wikipedia.org/wiki/Meter_%28music%29#Polymeter

A good example of polymeter is the Tala which is an extream form of complex time.


  Polyrhythm is the simultaneous use of two or more conflicting rhythms, that are not readily perceived as deriving from one another, or as simple manifestations of the same meter. The rhythmic conflict may be the basis of an entire piece of music (cross-rhythm), or a momentary disruption. Polyrhythms can be distinguished from irrational rhythms, which can occur within the context of a single part; polyrhythms require at least two rhythms to be played concurrently, one of which is typically an irrational rhythm.


https://en.wikipedia.org/wiki/Polyrhythm

Commonly used in modren Jazz.  See: Mongo Santamaria and Elvin Jones.
"
2281,2281,3636,Permissions changing on few files under /etc/,"It appears that new permissions on /etc/issue and /etc/motd are reverting back to the original even if we change them. This is on systems running RHEL 5 and RHEL 6.  Is there any rc script which controls the permissions on /etc files?
",user67186,https://unix.stackexchange.com/users/67186,"Debian

If you're using a Debian based distro then this is likely what's causing your issue.


motd - Debian Wiki


excerpt


  /etc/motd in Debian
  
  Debian has a peculiar way of handling /etc/motd. The motd is updated at every reboot, in a boot script (/etc/init.d/bootmisc.sh in lenny and below, /etc/init.d/bootlogs in squeeze and above), which basically runs the following:

   uname -snrvm &gt; /var/run/motd
   [ -f /etc/motd.tail ] &amp;&amp; cat /etc/motd.tail &gt;&gt; /var/run/motd

  
  Since /etc/motd is a symlink to /var/run/motd in Debian, this works.
  
  How to update your /etc/motd
  
  Since /etc/motd basically gets overwritten at every reboot, you need to instead update /etc/motd.tail and either reboot (!!) or also edit /etc/motd.tail or run the above commands. There is a bug report (437176) to provide an easier command to allow you to update only /etc/motd.tail.


Red Hat based distros (Fedora/CentOS/RHEL)

For these types of distros I'm not aware of any automated system that would revert these files back to known versions as part of a reboot. These files are often times statically included on these systems in RPM packages such as these:

CentOS 5.x

$ rpm -qf /etc/issue /etc/motd
centos-release-5-9.el5.centos.1
setup-2.5.58-9.el5


CentOS 6.x

$ rpm -qf /etc/issue /etc/motd 
centos-release-6-5.el6.centos.11.2.x86_64
setup-2.8.14-20.el6_4.1.noarch


Fedora 19

$ rpm -qf /etc/issue /etc/motd 
fedora-release-19-8.noarch
setup-2.8.71-1.fc19.noarch


Further more a simple search for /etc/issue or /etc/motd within /etc turns up no such mechanism.

$ sudo grep -r /etc/issue /etc/*

",slm,https://unix.stackexchange.com/users/7453,http://unix.stackexchange.com/questions/137164/permissions-changing-on-few-files-under-etc,TECHNOLOGY,unix.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.3333333333333333,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.0,1.0,0.8888888888888888,Permission to change a few files under / etc/,"It seems that the new permissions on / etc / issue and / etc / MOTD are reverting to the original permissions, even if we change them. This is on systems running RHEL 5 and RHEL 6. Is there an RC script that controls the permissions of the / etc file?","Debian

If you're using a Debian based distro then this is likely what's causing your issue.


motd - Debian Wiki


excerpt


  /etc/motd in Debian
  
  Debian has a peculiar way of handling /etc/motd. The motd is updated at every reboot, in a boot script (/etc/init.d/bootmisc.sh in lenny and below, /etc/init.d/bootlogs in squeeze and above), which basically runs the following:

   uname -snrvm &gt; /var/run/motd
   [ -f /etc/motd.tail ] &amp;&amp; cat /etc/motd.tail &gt;&gt; /var/run/motd

  
  Since /etc/motd is a symlink to /var/run/motd in Debian, this works.
  
  How to update your /etc/motd
  
  Since /etc/motd basically gets overwritten at every reboot, you need to instead update /etc/motd.tail and either reboot (!!) or also edit /etc/motd.tail or run the above commands. There is a bug report (437176) to provide an easier command to allow you to update only /etc/motd.tail.


Red Hat based distros (Fedora/CentOS/RHEL)

For these types of distros I'm not aware of any automated system that would revert these files back to known versions as part of a reboot. These files are often times statically included on these systems in RPM packages such as these:

CentOS 5.x

$ rpm -qf /etc/issue /etc/motd
centos-release-5-9.el5.centos.1
setup-2.5.58-9.el5


CentOS 6.x

$ rpm -qf /etc/issue /etc/motd 
centos-release-6-5.el6.centos.11.2.x86_64
setup-2.8.14-20.el6_4.1.noarch


Fedora 19

$ rpm -qf /etc/issue /etc/motd 
fedora-release-19-8.noarch
setup-2.8.71-1.fc19.noarch


Further more a simple search for /etc/issue or /etc/motd within /etc turns up no such mechanism.

$ sudo grep -r /etc/issue /etc/*

"
5614,5614,8907,asynchronously loaded images in uitableview disappear on scrolling up,"i am able to fetch images asynchronously on to uitableview.i am fetching these images are from a url.on scrolling up uitableview these images disappear and  they take time to load again and sometimes they dont load at all.i dont want to use any 3rd party libraries.i dont want to go with synchronous approach.please suggest any correct approach to improve performance.thanks for help in advance.my code is below:

- (UITableViewCell *)tableView:(UITableView *)tableView cellForRowAtIndexPath:(NSIndexPath *)indexPath{
static NSString *identifier=@""cell"";
UITableViewCell *cell = [tableView dequeueReusableCellWithIdentifier:identifier];
if (cell == nil) {
    cell = [[UITableViewCell alloc] initWithStyle:UITableViewCellStyleSubtitle reuseIdentifier:@""identifier""];
}
UIImageView *imgVw=[[UIImageView alloc]initWithFrame:CGRectMake(250, 10, 40, 30)];
[cell.contentView addSubview:imgVw];
Attributes *att = [listOfObjects objectAtIndex:indexPath.row];
strImgUrl=@""http:image url"";
strImgName=att.classifiedImg;
if (strImgName == nil) {
    UIImage *myImg=[UIImage imageNamed:@""user_circle.png""];
    imgVw.image=myImg;
}
else{
    strImg=[strImgUrl stringByAppendingString:strImgName];
}
dispatch_async(dispatch_get_global_queue(0,0), ^{
    NSData *data = [[NSData alloc] initWithContentsOfURL: [NSURL URLWithString:strImg]];
    if ( data == nil )
        return;
    dispatch_async(dispatch_get_main_queue(), ^{

        UIImage *img=[UIImage imageWithData: data];
        imgVw.image=img;
    });

});



return cell;
}

",user2552751,https://stackoverflow.com/users/2552751,"It seems like your reuse code contains bug, which causes everytime to create new cells. The following code uses reuseIdentifier as @""identifier""

if (cell == nil) {
   cell = [[UITableViewCell alloc] initWithStyle:UITableViewCellStyleSubtitle reuseIdentifier:@""identifier""];
}


Change it to: 

if (cell == nil) {
   cell = [[UITableViewCell alloc] initWithStyle:UITableViewCellStyleSubtitle reuseIdentifier:identifier];
}


EDIT:

On reusing tableView cells, you dont need to create and add subviews to cell each time. Instead, just create the subview when creating cell and then if cell is reusing, just get the subview using tag and update your content from datasource.

Your code can be modified like below:

if (cell == nil) {
   cell = [[UITableViewCell alloc] initWithStyle:UITableViewCellStyleSubtitle reuseIdentifier:identifier];
   UIImageView *imgVw=[[UIImageView alloc]initWithFrame:CGRectMake(250, 10, 40, 30)];
   imgVw.tag = indexPath.row;
   [cell.contentView addSubview:imgVw];
}
UIImageView imgVw = (UIImageView*)[cell.contentView viewWithTag:indexPath.row];
//Rest is same as you posted.


Hope this will fix the issue.
",HRM,https://stackoverflow.com/users/1672927,http://stackoverflow.com/questions/21013058/asynchronously-loaded-images-in-uitableview-disappear-on-scrolling-up,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.4444444444444444,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.7777777777777778,"When scrolling up, the image loaded asynchronously in uitableview disappears","i am able to fetch images asynchronously on to uitableview.i am fetching these images are from a url.on scrolling up uitableview these images disappear and  they take time to load again and sometimes they dont load at all.i dont want to use any 3rd party libraries.i dont want to go with synchronous approach.please suggest any correct approach to improve performance.thanks for help in advance.my code is below:

- (UITableViewCell *)tableView:(UITableView *)tableView cellForRowAtIndexPath:(NSIndexPath *)indexPath{
static NSString *identifier=@""cell"";
UITableViewCell *cell = [tableView dequeueReusableCellWithIdentifier:identifier];
if (cell == nil) {
    cell = [[UITableViewCell alloc] initWithStyle:UITableViewCellStyleSubtitle reuseIdentifier:@""identifier""];
}
UIImageView *imgVw=[[UIImageView alloc]initWithFrame:CGRectMake(250, 10, 40, 30)];
[cell.contentView addSubview:imgVw];
Attributes *att = [listOfObjects objectAtIndex:indexPath.row];
strImgUrl=@""http:image url"";
strImgName=att.classifiedImg;
if (strImgName == nil) {
    UIImage *myImg=[UIImage imageNamed:@""user_circle.png""];
    imgVw.image=myImg;
}
else{
    strImg=[strImgUrl stringByAppendingString:strImgName];
}
dispatch_async(dispatch_get_global_queue(0,0), ^{
    NSData *data = [[NSData alloc] initWithContentsOfURL: [NSURL URLWithString:strImg]];
    if ( data == nil )
        return;
    dispatch_async(dispatch_get_main_queue(), ^{

        UIImage *img=[UIImage imageWithData: data];
        imgVw.image=img;
    });

});



return cell;
}

","It seems like your reuse code contains bug, which causes everytime to create new cells. The following code uses reuseIdentifier as @""identifier""

if (cell == nil) {
   cell = [[UITableViewCell alloc] initWithStyle:UITableViewCellStyleSubtitle reuseIdentifier:@""identifier""];
}


Change it to: 

if (cell == nil) {
   cell = [[UITableViewCell alloc] initWithStyle:UITableViewCellStyleSubtitle reuseIdentifier:identifier];
}


EDIT:

On reusing tableView cells, you dont need to create and add subviews to cell each time. Instead, just create the subview when creating cell and then if cell is reusing, just get the subview using tag and update your content from datasource.

Your code can be modified like below:

if (cell == nil) {
   cell = [[UITableViewCell alloc] initWithStyle:UITableViewCellStyleSubtitle reuseIdentifier:identifier];
   UIImageView *imgVw=[[UIImageView alloc]initWithFrame:CGRectMake(250, 10, 40, 30)];
   imgVw.tag = indexPath.row;
   [cell.contentView addSubview:imgVw];
}
UIImageView imgVw = (UIImageView*)[cell.contentView viewWithTag:indexPath.row];
//Rest is same as you posted.


Hope this will fix the issue.
"
2137,2137,3404,WYSIWYG HTML / CSS builder,"Maybe it is to much to ask...

I want to make a online WYSIWYG HTML / CSS builder where the graphic designer can build a website template without knowing CSS /HTML. For that purpose there should be a GUI to build a website template.

That means HTML and CSS are created out of the choices selected in the GUI.

http://www.constructyourcss.com kinda does what I want. But I can't set width/height etc + I need to integrate it into my system (I use PHP, MySQL,jQuery)

Question:
Do you know any html/css builder tools like ala jquery sortables?
",Cudos,https://stackoverflow.com/users/104833,"I don't know of any online tools, but I really like the way this standalone program called Stylizer enables users who don't know CSS very well to modify web site layouts. But honestly, there's no way I'd pay $89 for it. I recommended it to some friends to use it for the trial period, but learn how to use Firebug as well.

That being said, I tend to agree with the comments above. A designer is more likely to learn CSS/HTML and do it themselves or pay a service to convert their pdf into a page.
",Mottie,https://stackoverflow.com/users/145346,http://stackoverflow.com/questions/2396042/wysiwyg-html-css-builder,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.3333333333333333,0.0,1.0,0.6666666666666666,0.6666666666666666,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.4444444444444444,1.0,0.7777777777777778,1.0,1.0,0.8,0.3333333333333333,0.0,0.3333333333333333,1.0,WYSIWYG HTML / CSS generator,"Maybe it is to much to ask...

I want to make a online WYSIWYG HTML / CSS builder where the graphic designer can build a website template without knowing CSS /HTML. For that purpose there should be a GUI to build a website template.

That means HTML and CSS are created out of the choices selected in the GUI.

http://www.constructyourcss.com kinda does what I want. But I can't set width/height etc + I need to integrate it into my system (I use PHP, MySQL,jQuery)

Question:
Do you know any html/css builder tools like ala jquery sortables?
","I don't know of any online tools, but I really like the way this standalone program called Stylizer enables users who don't know CSS very well to modify web site layouts. But honestly, there's no way I'd pay $89 for it. I recommended it to some friends to use it for the trial period, but learn how to use Firebug as well.

That being said, I tend to agree with the comments above. A designer is more likely to learn CSS/HTML and do it themselves or pay a service to convert their pdf into a page.
"
5304,5304,8423,"What is the difference between ""section"" and ""part""?","What is the difference between ""section"" and ""part""?  

The Longman Dictionary of Contemporary English says for ""section"":  


  one of the parts that something such as an object or place is divided into


and says for ""part"":  


  a piece or feature of something such as an object, area, event, or period of time


I know that ""section"" is smaller than ""part"" in size, but I'm totally confused about their usage in sentences. For example, is ""the front section of the car was damaged"" correct grammatically? Or is ""in sections of Canada, French is the first language""  correct?
",Vahid Damanafshan,https://english.stackexchange.com/users/31675,"Just to add an example in which you use them differently: In latex, you can divide a document (or a presentation) in several parts, and each part has its own chapters, sections and subsections. So, in this particular case, part is more general. See more about sectioning in latex 
",Digna,https://english.stackexchange.com/users/35797,http://english.stackexchange.com/questions/100285/what-is-the-difference-between-section-and-part,CULTURE,english.stackexchange.com,1.0,1.0,0.0,0.6666666666666666,1.0,1.0,0.5555555555555556,0.7777777777777778,0.3333333333333333,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.8888888888888888,0.4444444444444444,1.0,0.7777777777777778,0.4666666666666667,0.0,0.0,0.0,1.0,"What's the difference between ""part"" and ""part""?","What is the difference between ""section"" and ""part""?  

The Longman Dictionary of Contemporary English says for ""section"":  


  one of the parts that something such as an object or place is divided into


and says for ""part"":  


  a piece or feature of something such as an object, area, event, or period of time


I know that ""section"" is smaller than ""part"" in size, but I'm totally confused about their usage in sentences. For example, is ""the front section of the car was damaged"" correct grammatically? Or is ""in sections of Canada, French is the first language""  correct?
","Just add a different example: in latex, you can divide a document (or presentation) into sections, each with its own chapters, sections, and sections. So, in this particular case, part of it is more general. More about latex sectioning"
3053,3053,4863,How to remove the “ .0” in Decimal format and convert 1.01 to 1 in java,"My application deals with prices, I am facing a small problem here. I will explain it clearly in steps.

Following are my inputs and OutPut should be.


  input  1.01  =  output 1 
  
  input 1.748  = output 1.75
  
  input 1.98  =output 2
  
  input 1.49 = output 1.5
  
  input 20.0 = output 2


0

I have used the following code but I can't achieve it

    double calc = 1.98;
            DecimalFormat df = new DecimalFormat(""#.##"");  
            calc = Double.valueOf(df.format(calc));
            System.out.println(String.valueOf(calc).replaceAll(""([0-9])\\.0+([^0-9]|$)"", ""$1$2""));

::&gt; output is 1.98 which should be 2

double calc = 20.0;
        DecimalFormat df = new DecimalFormat(""#.#"");  
        calc = Double.valueOf(df.format(calc));
        System.out.println(String.valueOf(calc).replaceAll(""([0-9])\\.0+([^0-9]|$)"", ""$1$2""));

 ::&gt; output is 20 this is correct for me.

double calc = 2.01;
        DecimalFormat df = new DecimalFormat(""#.##"");  
        calc = Double.valueOf(df.format(calc));
        System.out.println(String.valueOf(calc).replaceAll(""([0-9])\\.0+([^0-9]|$)"", ""$1$2""));

::&gt; output is 2.01  Which should be 2.


following code which I have tried.
",Nikhilreddy Gujjula,https://stackoverflow.com/users/1010854,"Try this. I hope it handles all your requirements.

public static void main(String[] args) {
    double d = 20.0;
    int decimalPlaces = getDecimalPlaces(d) - 1;
    double res = Math.round(d * Math.pow(10, decimalPlaces))/Math.pow(10, decimalPlaces); // Rounding
    String text = Double.toString(Math.abs(res));
    int integerPlaces = text.indexOf('.');
    if (getDecimalPlaces(res) == 1 &amp;&amp; text.charAt(integerPlaces + 1) == '0') 
        System.out.println((int)res);
    else
        System.out.println(res);
}

private static int getDecimalPlaces(double d) {
    String text = Double.toString(Math.abs(d));
    int integerPlaces = text.indexOf('.');
    int decimalPlaces = text.length() - integerPlaces - 1; // To Round
    return decimalPlaces;
}

",Christian,https://stackoverflow.com/users/2670792,http://stackoverflow.com/questions/19721584/how-to-remove-the-0-in-decimal-format-and-convert-1-01-to-1-in-java,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.6666666666666666,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,1.0,1.0,0.0,0.0,0.8888888888888888,"How to delete "". 0"" in decimal format and convert 1.01 to 1 in Java","My application deals with prices, I am facing a small problem here. I will explain it clearly in steps.

Following are my inputs and OutPut should be.


  input  1.01  =  output 1 
  
  input 1.748  = output 1.75
  
  input 1.98  =output 2
  
  input 1.49 = output 1.5
  
  input 20.0 = output 2


0

I have used the following code but I can't achieve it

    double calc = 1.98;
            DecimalFormat df = new DecimalFormat(""#.##"");  
            calc = Double.valueOf(df.format(calc));
            System.out.println(String.valueOf(calc).replaceAll(""([0-9])\\.0+([^0-9]|$)"", ""$1$2""));

::&gt; output is 1.98 which should be 2

double calc = 20.0;
        DecimalFormat df = new DecimalFormat(""#.#"");  
        calc = Double.valueOf(df.format(calc));
        System.out.println(String.valueOf(calc).replaceAll(""([0-9])\\.0+([^0-9]|$)"", ""$1$2""));

 ::&gt; output is 20 this is correct for me.

double calc = 2.01;
        DecimalFormat df = new DecimalFormat(""#.##"");  
        calc = Double.valueOf(df.format(calc));
        System.out.println(String.valueOf(calc).replaceAll(""([0-9])\\.0+([^0-9]|$)"", ""$1$2""));

::&gt; output is 2.01  Which should be 2.


following code which I have tried.
","Try this. I hope it handles all your requirements.

public static void main(String[] args) {
    double d = 20.0;
    int decimalPlaces = getDecimalPlaces(d) - 1;
    double res = Math.round(d * Math.pow(10, decimalPlaces))/Math.pow(10, decimalPlaces); // Rounding
    String text = Double.toString(Math.abs(res));
    int integerPlaces = text.indexOf('.');
    if (getDecimalPlaces(res) == 1 &amp;&amp; text.charAt(integerPlaces + 1) == '0') 
        System.out.println((int)res);
    else
        System.out.println(res);
}

private static int getDecimalPlaces(double d) {
    String text = Double.toString(Math.abs(d));
    int integerPlaces = text.indexOf('.');
    int decimalPlaces = text.length() - integerPlaces - 1; // To Round
    return decimalPlaces;
}

"
2616,2616,4161,"Given Ohm's law, how can current increase if voltage increases, given fixed resistance?","According to Ohm's law, V=IR (voltage equals current times resistance).

So if the voltage increases, then the current increases provided that the resistance remains constant.

I know that Voltage or potential difference means work done per unit positive charge in bringing that charge from one point to another.

So according to Ohm's law, if the work done per unit charge increases then current will increase. How can this be true? Point out my mistakes.
",Souhardya Mondal,https://physics.stackexchange.com/users/62308,"I think you've answered that yourself.  If you are putting more work into moving unit of charge, then that unit of charge is going to move faster (all else being constant).  Current is the flow electric charge across a surface at specific rate (1 ampere = 1 coulomb per second) and hence - more voltage, more work, faster flow (rate), higher current.
",Bruford,https://physics.stackexchange.com/users/62309,http://physics.stackexchange.com/questions/141786/given-ohms-law-how-can-current-increase-if-voltage-increases-given-fixed-resi,SCIENCE,physics.stackexchange.com,1.0,1.0,0.0,0.6666666666666666,1.0,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,1.0,"Given Ohm's law, given a fixed resistance, if the voltage increases, how does the current increase?","According to Ohm's law, V=IR (voltage equals current times resistance).

So if the voltage increases, then the current increases provided that the resistance remains constant.

I know that Voltage or potential difference means work done per unit positive charge in bringing that charge from one point to another.

So according to Ohm's law, if the work done per unit charge increases then current will increase. How can this be true? Point out my mistakes.
","I think you've answered that yourself.  If you are putting more work into moving unit of charge, then that unit of charge is going to move faster (all else being constant).  Current is the flow electric charge across a surface at specific rate (1 ampere = 1 coulomb per second) and hence - more voltage, more work, faster flow (rate), higher current.
"
4168,4168,6642,How can natural selection occur at species level whilst not occuring at the individual level?,"The chapter by Douglas Futuyma in 'Evolution' (Losos et al 2013, Princeton) states that natural selection can occur at the species level. Futuyma states that if natural selection occurs at the species level it does not occur at the individual level: 


  Neither gene selection nor species selection has molded the advantageous characteristics of individual organisms; rather, they have affected properties at the gene level or at the species level. 


But how does natural selection occuring at the species level not affect individuals? Surely any selective advantage of a particular species must occur among particular individuals of that species. For example, if Species A is selected because it is browner than Species B, this will be because individuals of Species A are browner than individuals of Species B. 
",luciano,https://biology.stackexchange.com/users/1216,"I think you have misunderstood the passage. Here is a larger section (found at google books):


  Natural selection can also occur at the level of species, for certain characteristics enhance the rate of origin of new species or diminish the likelihood of species extinction. For instance, the number of species in lineages of herbivorous insects has generally increased faster than in closely related lineages that have other feeding habits. Neither gene selection nor species selection has molded the advantageous characteristics of individual organisms; rather, they have affected properties at the gene level or at the species level. But individual selection, selection among individual organisms within populations, is at the center of evolutionary theory. It is at this level that selection explains most of the adaptive features of organisms.


Going through this part-by-part; the first two sentences state that lineage/species selection can occur, in the sense that species traits can enhance the speciation rate of a lineage or decrease their risk of extinction, relative to other lineages (e.g. in herbivorous insects). 

He is then saying that the traits that are the target of this selection are not traits of individuals but traits/properties of the species/lineage. 

An example might help to explain the point. For instance, it has been argued that pelagic larvae in sessile ocean species will lead to higher dispersal rates, which means that species can colonize new environments, and this can lead to speciation through adaptive radiation (Jablonski &amp; Hunt, 2006). A larger range will also correspond to lower extinction rates (everything else equal). The trait might also be fixed within a lineage (so there is no variance at the individual level within-species), and if so, this lineage as a whole could have higher speciation rates and lower extinction rates compared to a sister lineage that lacks pelagic larvae. 

The individuals within species will naturally have the underlying traits (pelagic larvae), but the traits that are selected at the lineage level (extinction risk &amp; speciation rate) are not properties of individuals but are traits of the lineage/species. 

He then ends by continuing with ""normal"" individual selection, and states that processes at this level is responsible for most adaptive features of organisms. It should also be noted that lineage selection is still considered controversial, and it has been shown that it is inherently much weaker than selection at the individual level. Personally, I think there are some very good examples of how species/lineage selection can function, but to what extent it is an important process for species and organisms is an open empirical question. If you are interested to look further, Jablonski (2008) and Okasha (2007) are two good starting points.
",fileunderwater,https://biology.stackexchange.com/users/3624,http://biology.stackexchange.com/questions/24312/how-can-natural-selection-occur-at-species-level-whilst-not-occuring-at-the-indi,SCIENCE,biology.stackexchange.com,1.0,1.0,0.0,0.6666666666666666,1.0,1.0,0.5555555555555556,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.0,1.0,1.0,How can natural selection occur at the species level rather than at the individual level?,"The chapter by Douglas Futuyma in 'Evolution' (Losos et al 2013, Princeton) states that natural selection can occur at the species level. Futuyma states that if natural selection occurs at the species level it does not occur at the individual level: 


  Neither gene selection nor species selection has molded the advantageous characteristics of individual organisms; rather, they have affected properties at the gene level or at the species level. 


But how does natural selection occuring at the species level not affect individuals? Surely any selective advantage of a particular species must occur among particular individuals of that species. For example, if Species A is selected because it is browner than Species B, this will be because individuals of Species A are browner than individuals of Species B. 
","I think you have misunderstood the passage. Here is a larger section (found at google books):


  Natural selection can also occur at the level of species, for certain characteristics enhance the rate of origin of new species or diminish the likelihood of species extinction. For instance, the number of species in lineages of herbivorous insects has generally increased faster than in closely related lineages that have other feeding habits. Neither gene selection nor species selection has molded the advantageous characteristics of individual organisms; rather, they have affected properties at the gene level or at the species level. But individual selection, selection among individual organisms within populations, is at the center of evolutionary theory. It is at this level that selection explains most of the adaptive features of organisms.


Going through this part-by-part; the first two sentences state that lineage/species selection can occur, in the sense that species traits can enhance the speciation rate of a lineage or decrease their risk of extinction, relative to other lineages (e.g. in herbivorous insects). 

He is then saying that the traits that are the target of this selection are not traits of individuals but traits/properties of the species/lineage. 

An example might help to explain the point. For instance, it has been argued that pelagic larvae in sessile ocean species will lead to higher dispersal rates, which means that species can colonize new environments, and this can lead to speciation through adaptive radiation (Jablonski &amp; Hunt, 2006). A larger range will also correspond to lower extinction rates (everything else equal). The trait might also be fixed within a lineage (so there is no variance at the individual level within-species), and if so, this lineage as a whole could have higher speciation rates and lower extinction rates compared to a sister lineage that lacks pelagic larvae. 

The individuals within species will naturally have the underlying traits (pelagic larvae), but the traits that are selected at the lineage level (extinction risk &amp; speciation rate) are not properties of individuals but are traits of the lineage/species. 

He then ends by continuing with ""normal"" individual selection, and states that processes at this level is responsible for most adaptive features of organisms. It should also be noted that lineage selection is still considered controversial, and it has been shown that it is inherently much weaker than selection at the individual level. Personally, I think there are some very good examples of how species/lineage selection can function, but to what extent it is an important process for species and organisms is an open empirical question. If you are interested to look further, Jablonski (2008) and Okasha (2007) are two good starting points.
"
2141,2141,3411,Google Apps login in wordpress,"I manage a google apps domain with plenty of users;

I would like to join Google apps with a Wordpress based intranet app we're creating. 

Which level of integration could I expect to achieve?

Our hope is to create users in wordpress using their google apps email and let them login using their google apps password, so that they don't need to remember two different passwords.

How would you suggest we should implement this?
",Bakaburg,https://wordpress.stackexchange.com/users/10100,"I would say Using OAuth would be your best bet. Making it so that the users can login only with gmail by removing all the WordPress registration and login. 

http://wordpress.org/extend/plugins/oauth-provider/
",BandonRandon,https://wordpress.stackexchange.com/users/2204,http://wordpress.stackexchange.com/questions/47265/google-apps-login-in-wordpress,TECHNOLOGY,wordpress.stackexchange.com,0.8888888888888888,0.4444444444444444,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.4444444444444444,1.0,0.5555555555555556,1.0,1.0,0.8,1.0,0.0,0.0,0.8888888888888888,Google App log in to WordPress,"I manage a google apps domain with plenty of users;

I would like to join Google apps with a Wordpress based intranet app we're creating. 

Which level of integration could I expect to achieve?

Our hope is to create users in wordpress using their google apps email and let them login using their google apps password, so that they don't need to remember two different passwords.

How would you suggest we should implement this?
","I would say Using OAuth would be your best bet. Making it so that the users can login only with gmail by removing all the WordPress registration and login. 

http://wordpress.org/extend/plugins/oauth-provider/
"
5053,5053,8038,Why a Transistor is considered to be an active device?,"How it a Transistor an active device? Because it it not producing energy. We just feed it with energy and it amplifies it and that too not on his own but using a bias battery. So how it is considered to be an active device? Please can anyone provide full explanation?
",radiantshaw,https://electronics.stackexchange.com/users/34847,"Basically, An active device is any type of circuit component with the ability to electrically control electron flow (electricity controlling electricity). Thus, transistor is an active device. 

Note that active device doesn't mean it just produces energy.

All active devices control the flow of electrons through them. Some active devices allow a voltage to control this current while other active devices allow another current to do the job. 

Devices utilizing a static voltage as the controlling signal are called voltage-controlled devices. 

Devices working on the principle of one current controlling another current are known as current-controlled devices.

BJT is current controlled, while FET is voltage controlled active device.
",yuvi,https://electronics.stackexchange.com/users/35874,http://electronics.stackexchange.com/questions/98151/why-a-transistor-is-considered-to-be-an-active-device,TECHNOLOGY,electronics.stackexchange.com,1.0,0.8888888888888888,0.0,1.0,1.0,1.0,0.5555555555555556,0.5555555555555556,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,0.8888888888888888,Why are transistors considered active devices?,"How do transistors become active devices? Because it doesn't produce energy. We just give it energy, it enlarges it, not by itself, but by using a bias battery. So how is it considered an active device? Can anyone provide a complete explanation?","Basically, An active device is any type of circuit component with the ability to electrically control electron flow (electricity controlling electricity). Thus, transistor is an active device. 

Note that active device doesn't mean it just produces energy.

All active devices control the flow of electrons through them. Some active devices allow a voltage to control this current while other active devices allow another current to do the job. 

Devices utilizing a static voltage as the controlling signal are called voltage-controlled devices. 

Devices working on the principle of one current controlling another current are known as current-controlled devices.

BJT is current controlled, while FET is voltage controlled active device.
"
1304,1304,2052,Daydream with transparent background,"I'm trying to implement a daydream service with a transparent background.

I wrote the following code:

public void onAttachedToWindow() {
    super.onAttachedToWindow();
    setContentView(R.layout.mydream);
    getWindow().setBackgroundDrawable(new ColorDrawable(0));
    .
    .
    .
}


But when I start up the daydream, the background is only transparent for 1 second. After that it turns to black background.

Can anyone help me with this?
",0s0ft,https://stackoverflow.com/users/610839,"Luckily you can access the window of the DreamService. So what you can do in your DreamService class is the following:

 @Override
    public void onAttachedToWindow() {
        super.onAttachedToWindow();
        setInteractive(true);
        setContentView(R.layout.dream_service);
        getWindow().setBackgroundDrawable(new ColorDrawable(Color.parseColor(""#00FFFFFF"")));
    }


Make sure your layout of the DreamService has a transparent background ;-)
",user3389215,https://stackoverflow.com/users/3389215,http://stackoverflow.com/questions/16822410/daydream-with-transparent-background,STACKOVERFLOW,stackoverflow.com,1.0,0.3333333333333333,0.0,0.6666666666666666,0.3333333333333333,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.4444444444444444,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.0,0.0,0.8888888888888888,Daydream on transparent background,"I'm trying to implement a daydream service with a transparent background.

I wrote the following code:

public void onAttachedToWindow() {
    super.onAttachedToWindow();
    setContentView(R.layout.mydream);
    getWindow().setBackgroundDrawable(new ColorDrawable(0));
    .
    .
    .
}


But when I start up the daydream, the background is only transparent for 1 second. After that it turns to black background.

Can anyone help me with this?
","Luckily you can access the window of the DreamService. So what you can do in your DreamService class is the following:

 @Override
    public void onAttachedToWindow() {
        super.onAttachedToWindow();
        setInteractive(true);
        setContentView(R.layout.dream_service);
        getWindow().setBackgroundDrawable(new ColorDrawable(Color.parseColor(""#00FFFFFF"")));
    }


Make sure your layout of the DreamService has a transparent background ;-)
"
352,352,559,XSLT Sort with variable select,"I have a HTML select dropdown:

                &lt;select name=""sortby""&gt;
                    &lt;option value=""""&gt;&lt;/option&gt;
                    &lt;option value=""onenightavg""&gt;Price: High to Low&lt;/option&gt;
                    &lt;option value=""number_bedrooms""&gt;Bedrooms: High to Low&lt;/option&gt;
                    &lt;option value=""number_bathrooms""&gt;Bathrooms: High to Low&lt;/option&gt;
                    &lt;option value=""max_sleeps""&gt;Sleeps: High to Low&lt;/option&gt;
                &lt;/select&gt;


When the user submits this it sends a URL query string to the page and it gets added to the XML of the page:

&lt;querystring&gt;
 &lt;sortby&gt;number_bathrooms&lt;/sortby&gt;
&lt;/querystring&gt;


I then set an XSL variable in my XSLT: 

        &lt;xsl:variable name=""sortby""&gt;
            &lt;xsl:choose&gt;
                &lt;xsl:when test=""/querystring/sortby != ''""&gt;
                    &lt;xsl:value-of select=""/querystring/sortby"" /&gt;
                &lt;/xsl:when&gt;
                &lt;xsl:otherwise&gt;
                    &lt;xsl:value-of select=""'onenightavg'"" /&gt;
                &lt;/xsl:otherwise&gt;
            &lt;/xsl:choose&gt;
        &lt;/xsl:variable&gt;


In the above XST I am setting a variable called $sortby and testing whether the querystring exists.  If it does exist then set the variable to its value.  If it doesn't exist then default it to ""onenightavg"".

Then I use that variable in my sort:

&lt;xsl:sort data-type=""number"" order=""ascending"" select=""$sortby"" /&gt;


This doesn't work.  It doesn't sort my items, but when I hardcode the select to any one of the values like this it works:

&lt;xsl:sort data-type=""number"" order=""ascending"" select=""onenightavg"" /&gt;


I would like to be able to dynamically sort based on an the value of the selected option in the dropdown.
",Amir,https://stackoverflow.com/users/168309,"How about this:

&lt;xsl:sort data-type=""number"" order=""ascending"" select=""*[local-name() = $sortby]"" /&gt;

",JLRishe,https://stackoverflow.com/users/1945651,http://stackoverflow.com/questions/14221870/xslt-sort-with-variable-select,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.3333333333333333,0.0,1.0,0.3333333333333333,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,0.0,1.0,The sort of XSLT with variable select,"I have a HTML select dropdown:

                &lt;select name=""sortby""&gt;
                    &lt;option value=""""&gt;&lt;/option&gt;
                    &lt;option value=""onenightavg""&gt;Price: High to Low&lt;/option&gt;
                    &lt;option value=""number_bedrooms""&gt;Bedrooms: High to Low&lt;/option&gt;
                    &lt;option value=""number_bathrooms""&gt;Bathrooms: High to Low&lt;/option&gt;
                    &lt;option value=""max_sleeps""&gt;Sleeps: High to Low&lt;/option&gt;
                &lt;/select&gt;


When the user submits this it sends a URL query string to the page and it gets added to the XML of the page:

&lt;querystring&gt;
 &lt;sortby&gt;number_bathrooms&lt;/sortby&gt;
&lt;/querystring&gt;


I then set an XSL variable in my XSLT: 

        &lt;xsl:variable name=""sortby""&gt;
            &lt;xsl:choose&gt;
                &lt;xsl:when test=""/querystring/sortby != ''""&gt;
                    &lt;xsl:value-of select=""/querystring/sortby"" /&gt;
                &lt;/xsl:when&gt;
                &lt;xsl:otherwise&gt;
                    &lt;xsl:value-of select=""'onenightavg'"" /&gt;
                &lt;/xsl:otherwise&gt;
            &lt;/xsl:choose&gt;
        &lt;/xsl:variable&gt;


In the above XST I am setting a variable called $sortby and testing whether the querystring exists.  If it does exist then set the variable to its value.  If it doesn't exist then default it to ""onenightavg"".

Then I use that variable in my sort:

&lt;xsl:sort data-type=""number"" order=""ascending"" select=""$sortby"" /&gt;


This doesn't work.  It doesn't sort my items, but when I hardcode the select to any one of the values like this it works:

&lt;xsl:sort data-type=""number"" order=""ascending"" select=""onenightavg"" /&gt;


I would like to be able to dynamically sort based on an the value of the selected option in the dropdown.
","How about this:

&lt;xsl:sort data-type=""number"" order=""ascending"" select=""*[local-name() = $sortby]"" /&gt;

"
305,305,493,Expectation of drawing the second color from an urn,"My urn contains 3 red, 2 green and 1 white ball. I pick a ball with replacement until I pick the second color. 

What is the average number of picks for picking the second color?

With the expected value formula I got the following.

$EX=\sum\limits_{k=2}^\infty k[\frac{1}{2}r^{k-1}+\frac{2}{3}g^{k-1}+\frac{5}{6}w^{k-1}]$

Where r, g and w are the probabilites of drawing a red, green, or white ball.

I don't know how to calculate this sum, and I am not sure this is the right way to solve this excercise.
",user010010001,https://math.stackexchange.com/users/137425,"I assume you're interested in the expected number of picks after the first.  In that case the answer is

$${1\over6}\cdot{6\over5}+{2\over6}\cdot{6\over4}+{3\over6}\cdot{6\over3}={1\over5}+{1\over2}+1={17\over10}$$

The reasoning is simple:  In general, if an event happens with probability $p$, the expected number of trials it takes for it to occur is $1/p$.  With probability $1/6$, the event of interest is picking a non-white ball, which occurs with probability $5/6$; with probability $2/6$, the event is picking a non-green ball, which occurs with probability $4/6$; and with probability $3/6$, the event is picking a non-red ball, which occurs with probability $3/6$.

If you are counting the first pick as well, the answer is simply $1+{17\over10}={27\over10}$.

To prove the general fact that $E(p)=1/p$, you can either set up and sum the infinite series $\sum_{k=1}^\infty kp(1-p)^{k-1}$ or use the fact that after the first pick you're either done in one round, which happens with probability $p$, or, with probability $1-p$, you're back where you started, but with one round under you're belt, i.e.,

$$E(p)=p\cdot1+(1-p)(1+E(p))$$
",Barry Cipra,https://math.stackexchange.com/users/86747,http://math.stackexchange.com/questions/970034/expectation-of-drawing-the-second-color-from-an-urn,SCIENCE,math.stackexchange.com,1.0,0.5555555555555556,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.5555555555555556,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.6666666666666666,0.8888888888888888,Expectation of painting the second color from the urn,"My urn contains 3 red, 2 green and 1 white ball. I pick a ball with replacement until I pick the second color. 

What is the average number of picks for picking the second color?

With the expected value formula I got the following.

$EX=\sum\limits_{k=2}^\infty k[\frac{1}{2}r^{k-1}+\frac{2}{3}g^{k-1}+\frac{5}{6}w^{k-1}]$

Where r, g and w are the probabilites of drawing a red, green, or white ball.

I don't know how to calculate this sum, and I am not sure this is the right way to solve this excercise.
","I assume you're interested in the expected number of picks after the first.  In that case the answer is

$${1\over6}\cdot{6\over5}+{2\over6}\cdot{6\over4}+{3\over6}\cdot{6\over3}={1\over5}+{1\over2}+1={17\over10}$$

The reasoning is simple:  In general, if an event happens with probability $p$, the expected number of trials it takes for it to occur is $1/p$.  With probability $1/6$, the event of interest is picking a non-white ball, which occurs with probability $5/6$; with probability $2/6$, the event is picking a non-green ball, which occurs with probability $4/6$; and with probability $3/6$, the event is picking a non-red ball, which occurs with probability $3/6$.

If you are counting the first pick as well, the answer is simply $1+{17\over10}={27\over10}$.

To prove the general fact that $E(p)=1/p$, you can either set up and sum the infinite series $\sum_{k=1}^\infty kp(1-p)^{k-1}$ or use the fact that after the first pick you're either done in one round, which happens with probability $p$, or, with probability $1-p$, you're back where you started, but with one round under you're belt, i.e.,

$$E(p)=p\cdot1+(1-p)(1+E(p))$$
"
4955,4955,7891,Is Start & Stop technology good or bad for my car? (Alfa MiTO),"I was recently in the lucky position to obtain an (almost brand new) Alfa Romeo MiTo, Progression. Like many new cars coming out these days, it has ""Start &amp; Stop"" technology that turns the engine off when the car is stationary and is put in neutral and the clutch is released. When putting down the clutch again the engine fires back up.

My question then is this: 

a) Is start-stop technology bad for my engine in any way? 

b) What impact might start-stop have on my battery? I.e. won't it deteriorate battery life with the constant turning on and off? (The radio, fans and lights remain on whilst in ""stop""-mode, but not things like the aircon.)

c) Will this technology really benefit me that much with regards to fuel-consumption? I can imagine it will be more economic when stops in heavy traffic become really long or traffic lights are red for long periods, but for the most part when driving the car doesn't turn off for longer than a minute at most before I have to ""start"" it up again.

As many new cars lately have this technology I imagine that it can't be that bad, but I'm curious as to it's actual real benefits. I can turn this feature off, but I have to do so every time I start my car up for the first time and then I'm stuck with this glaring orange light in my dash, letting me know it's turned off.
",DeVil,https://mechanics.stackexchange.com/users/538,"I would imagine that this sort of technology would lead to increased wear on your starter motor, as it is being used far more than it would normally be, however I would hope that they would have anticipated this and designed the starter to be more robust than a traditional one.

The battery should be able to cope with it fine all the time it is in good condition. Batteries do, however, deteriorate over time, with a usual life of around 8-10 years at most. I suspect that as your battery starts to deteriorate, it won't be able to cope as well with the increased drain, leading to the car failing to re-start with traditional flat-battery symptoms. How well the electronics cope with this remains to be seen!

As to your third question, I doubt it will help much at all. Getting an engine started needs quite a lot of energy (hence the big chunky battery), and the only way to get that energy is to burn fuel, through your alternator sapping power as it recharges the battery. I don't know the exact figures, but I suspect you'd have to have the engine off for a fair while to save enough fuel to offset the cost of starting it again.
",Nick C,https://mechanics.stackexchange.com/users/373,http://mechanics.stackexchange.com/questions/825/is-start-stop-technology-good-or-bad-for-my-car-alfa-mito/827,CULTURE,mechanics.stackexchange.com,0.8888888888888888,0.4444444444444444,0.0,0.0,0.6666666666666666,1.0,0.7777777777777778,0.6666666666666666,0.6666666666666666,0.0,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,0.3333333333333333,1.0,Is start stop technology good or bad for my car? (alpha mitto),"I was recently in the lucky position to obtain an (almost brand new) Alfa Romeo MiTo, Progression. Like many new cars coming out these days, it has ""Start &amp; Stop"" technology that turns the engine off when the car is stationary and is put in neutral and the clutch is released. When putting down the clutch again the engine fires back up.

My question then is this: 

a) Is start-stop technology bad for my engine in any way? 

b) What impact might start-stop have on my battery? I.e. won't it deteriorate battery life with the constant turning on and off? (The radio, fans and lights remain on whilst in ""stop""-mode, but not things like the aircon.)

c) Will this technology really benefit me that much with regards to fuel-consumption? I can imagine it will be more economic when stops in heavy traffic become really long or traffic lights are red for long periods, but for the most part when driving the car doesn't turn off for longer than a minute at most before I have to ""start"" it up again.

As many new cars lately have this technology I imagine that it can't be that bad, but I'm curious as to it's actual real benefits. I can turn this feature off, but I have to do so every time I start my car up for the first time and then I'm stuck with this glaring orange light in my dash, letting me know it's turned off.
","I would imagine that this sort of technology would lead to increased wear on your starter motor, as it is being used far more than it would normally be, however I would hope that they would have anticipated this and designed the starter to be more robust than a traditional one.

The battery should be able to cope with it fine all the time it is in good condition. Batteries do, however, deteriorate over time, with a usual life of around 8-10 years at most. I suspect that as your battery starts to deteriorate, it won't be able to cope as well with the increased drain, leading to the car failing to re-start with traditional flat-battery symptoms. How well the electronics cope with this remains to be seen!

As to your third question, I doubt it will help much at all. Getting an engine started needs quite a lot of energy (hence the big chunky battery), and the only way to get that energy is to burn fuel, through your alternator sapping power as it recharges the battery. I don't know the exact figures, but I suspect you'd have to have the engine off for a fair while to save enough fuel to offset the cost of starting it again.
"
4681,4681,7418,Link_to Routing Issue With Nested Resources,"I have two models Jobs and Questions. A job has many questions and questions belong to a job. 
I've set up the resources in the model, as well as the routes. I am having an issue trying to link_to the Show method of the questions controller on the questions#index page. My rake routes say that the path should be job_question_path with the two necessary :id's being :job_id and :id , so I tried:

&lt;td&gt;&lt;%= link_to 'Show', job_question_path(@job, question) %&gt;&lt;/td&gt;


 

and got the error:

No route matches {:action=&gt;""show"", :controller=&gt;""questions"", :job_id=&gt;nil, :id=&gt;#&lt;Question id: 1, job_id: 1, question1: ""sfsdfssfs"", question2: ""sfsdfs"", question3: ""sfsdf"", question4: ""sfsdfsf"", question5: ""sfsfsfs"", created_at: ""2011-06-21 03:25:12"", updated_at: ""2011-06-21 03:25:12""&gt;}


I've tried multiple other combos and nothing is seeming to work, I keep getting:

No route matches {:action=&gt;""show"", :controller=&gt;""questions"", :job_id=&gt;nil } 


or some combination of that.

The part I don't get is that I can put in the url /jobs/1/questions/1 and it takes me to the show page, so I am assuming that my questions#show methods are ok. See below for the rest of my code. 

Questions#index view

&lt;% @questions.each do |question| %&gt;
 &lt;tr&gt;
  &lt;td&gt;&lt;%= question.question1 %&gt;&lt;/td&gt;
  &lt;td&gt;&lt;%= question.question2 %&gt;&lt;/td&gt;
  &lt;td&gt;&lt;%= question.question3 %&gt;&lt;/td&gt;
  &lt;td&gt;&lt;%= question.question4 %&gt;&lt;/td&gt;
  &lt;td&gt;&lt;%= question.question5 %&gt;&lt;/td&gt;
  &lt;td&gt;&lt;%= link_to 'Show', job_question_path(@job, question) %&gt;&lt;/td&gt;
&lt;/tr&gt;


&lt;% end %>

Questions Controller

def index
 @questions = Question.all

 respond_to do |format|
  format.html # index.html.erb
  format.xml  { render :xml =&gt; @questions }
 end
end

def show
  @job = Job.find(params[:job_id])
  @question = @job.questions.find(params[:id])

 respond_to do |format|
  format.html # show.html.erb
  format.xml  { render :xml =&gt; @question }
 end
end


Models

class Job &lt; ActiveRecord::Base
 has_many :questions

class Question &lt; ActiveRecord::Base
  belongs_to :job


Routes.rb

 root :to =&gt; ""pages#home""

 resources :jobs do
  resources :questions
 end

 get ""pages/home""
 get ""pages/about""
 get ""pages/contact""


See this https://gist.github.com/1032734 for my rake routes. 

Thanks for any help in advance, i've been at this for a while now and just can't figure out the solution. Please let me know if you need any more info. 
",Igrabes,https://stackoverflow.com/users/583964,"may be so?

Questions#index view

&lt;% @questions.each do |question| %&gt;
 &lt;tr&gt;
  &lt;td&gt;&lt;%= question.question1 %&gt;&lt;/td&gt;
  &lt;td&gt;&lt;%= question.question2 %&gt;&lt;/td&gt;
  &lt;td&gt;&lt;%= question.question3 %&gt;&lt;/td&gt;
  &lt;td&gt;&lt;%= question.question4 %&gt;&lt;/td&gt;
  &lt;td&gt;&lt;%= question.question5 %&gt;&lt;/td&gt;
  &lt;%= link_to 'Show', job_question_path(question.job_id, question.id) %&gt;
&lt;/tr&gt;


It have to work. Or haven't you 'job_id' field in Questions table ?
",makrusak,https://stackoverflow.com/users/790791,http://stackoverflow.com/questions/6421078/link-to-routing-issue-with-nested-resources,STACKOVERFLOW,stackoverflow.com,0.6666666666666666,0.4444444444444444,0.0,1.0,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,0.0,0.6666666666666666,0.8888888888888888,0.5,0.8888888888888888,1.0,0.6,1.0,0.0,0.5,0.6666666666666666,Routing problems linked to nested resources,"I have two models Jobs and Questions. A job has many questions and questions belong to a job. 
I've set up the resources in the model, as well as the routes. I am having an issue trying to link_to the Show method of the questions controller on the questions#index page. My rake routes say that the path should be job_question_path with the two necessary :id's being :job_id and :id , so I tried:

&lt;td&gt;&lt;%= link_to 'Show', job_question_path(@job, question) %&gt;&lt;/td&gt;


 

and got the error:

No route matches {:action=&gt;""show"", :controller=&gt;""questions"", :job_id=&gt;nil, :id=&gt;#&lt;Question id: 1, job_id: 1, question1: ""sfsdfssfs"", question2: ""sfsdfs"", question3: ""sfsdf"", question4: ""sfsdfsf"", question5: ""sfsfsfs"", created_at: ""2011-06-21 03:25:12"", updated_at: ""2011-06-21 03:25:12""&gt;}


I've tried multiple other combos and nothing is seeming to work, I keep getting:

No route matches {:action=&gt;""show"", :controller=&gt;""questions"", :job_id=&gt;nil } 


or some combination of that.

The part I don't get is that I can put in the url /jobs/1/questions/1 and it takes me to the show page, so I am assuming that my questions#show methods are ok. See below for the rest of my code. 

Questions#index view

&lt;% @questions.each do |question| %&gt;
 &lt;tr&gt;
  &lt;td&gt;&lt;%= question.question1 %&gt;&lt;/td&gt;
  &lt;td&gt;&lt;%= question.question2 %&gt;&lt;/td&gt;
  &lt;td&gt;&lt;%= question.question3 %&gt;&lt;/td&gt;
  &lt;td&gt;&lt;%= question.question4 %&gt;&lt;/td&gt;
  &lt;td&gt;&lt;%= question.question5 %&gt;&lt;/td&gt;
  &lt;td&gt;&lt;%= link_to 'Show', job_question_path(@job, question) %&gt;&lt;/td&gt;
&lt;/tr&gt;


&lt;% end %>

Questions Controller

def index
 @questions = Question.all

 respond_to do |format|
  format.html # index.html.erb
  format.xml  { render :xml =&gt; @questions }
 end
end

def show
  @job = Job.find(params[:job_id])
  @question = @job.questions.find(params[:id])

 respond_to do |format|
  format.html # show.html.erb
  format.xml  { render :xml =&gt; @question }
 end
end


Models

class Job &lt; ActiveRecord::Base
 has_many :questions

class Question &lt; ActiveRecord::Base
  belongs_to :job


Routes.rb

 root :to =&gt; ""pages#home""

 resources :jobs do
  resources :questions
 end

 get ""pages/home""
 get ""pages/about""
 get ""pages/contact""


See this https://gist.github.com/1032734 for my rake routes. 

Thanks for any help in advance, i've been at this for a while now and just can't figure out the solution. Please let me know if you need any more info. 
","may be so?

Questions#index view

&lt;% @questions.each do |question| %&gt;
 &lt;tr&gt;
  &lt;td&gt;&lt;%= question.question1 %&gt;&lt;/td&gt;
  &lt;td&gt;&lt;%= question.question2 %&gt;&lt;/td&gt;
  &lt;td&gt;&lt;%= question.question3 %&gt;&lt;/td&gt;
  &lt;td&gt;&lt;%= question.question4 %&gt;&lt;/td&gt;
  &lt;td&gt;&lt;%= question.question5 %&gt;&lt;/td&gt;
  &lt;%= link_to 'Show', job_question_path(question.job_id, question.id) %&gt;
&lt;/tr&gt;


It have to work. Or haven't you 'job_id' field in Questions table ?
"
3124,3124,4977,Where are good photography spots in Malaysia?,"I am from Sweden and I've been in Kuala Lumpur for some time now and I wonder where I can find some good spots for shooting pictures. I've already been to Zoo Negara, but are there any other kind of places to visit? 

I will stay in Kuala Lumpur until December, feel free to make suggestions. I'm much into photographing people and life.
",Michail,https://photo.stackexchange.com/users/13326,"What subject areas do you want to photograph? 

KL has lots to see but is also an excellent gateway for short quick cheap (or cheapish) trips to elsewhere. 

Cameron highlands (daytrip) worthwhile. 

Malacca !!! - VERY good. LONG day trip possible but go for a weekend. Bus trip cheapish and not very long. Hostels cheap. Old history, people, architecture. (Tourists!). 

FRIM   (North KL). Good. Canopy walkway if open - ring and check explictly - internet news may be out of date.  

If you have a little free $ and a few days (more is better) I'd greatly recommend a quick trip to Yogyakarta in Indonesia. A few hours flight. Air Asia does some ultra-low-cost flights if you book ahead and accept strange travel hours. Substantially cheaper than Malaysia. (I can recommend a superb and well priced guide if interested.)
 Stay in one of many many grotty dirt-cheap fun hostels off Malioboro St.
  Visit Borubadur !!!! - about as must-see as a photo site can get.
Prambanan    - would be stunning if Borubadur was not there. 
Dieng PLateau - VERY LONG day trip - the journey itself is a stunning photo opportunity - one of the most amazing day drives of my life. Area is v good as well. 

Mt Merapi - volcano with attitude - and worthwhile even when quiet. Pillion motorcyle ride part way up the mountain. Sobering. Plus Merbabu near behind. 

And much more ...

Note that airfares to a range of other Asian countries may cost well under $US100 - sometimes as low as about $US30 to eg Vietnam. Almost worth a weekend in a number of  other countries depending on finances. 



If question moved to 'Travel"" this answer could be taken with it.
",Russell McMahon,https://photo.stackexchange.com/users/6263,http://photo.stackexchange.com/questions/29402/where-are-good-photography-spots-in-malaysia,LIFE_ARTS,photo.stackexchange.com,1.0,1.0,0.6666666666666666,1.0,0.0,0.5,0.6666666666666666,0.6666666666666666,0.0,0.0,1.0,0.0,0.6666666666666666,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.7777777777777778,1.0,0.8888888888888888,1.0,1.0,0.8666666666666666,0.0,0.3333333333333333,0.0,0.7777777777777778,Where is a good photography spot in Malaysia?,"I'm from Sweden and have been in Kuala Lumpur for a while. I want to know where I can find some good shooting places. I've been to the South Gala zoo, but is there any other place to visit?","What subject areas do you want to photograph? 

KL has lots to see but is also an excellent gateway for short quick cheap (or cheapish) trips to elsewhere. 

Cameron highlands (daytrip) worthwhile. 

Malacca !!! - VERY good. LONG day trip possible but go for a weekend. Bus trip cheapish and not very long. Hostels cheap. Old history, people, architecture. (Tourists!). 

FRIM   (North KL). Good. Canopy walkway if open - ring and check explictly - internet news may be out of date.  

If you have a little free $ and a few days (more is better) I'd greatly recommend a quick trip to Yogyakarta in Indonesia. A few hours flight. Air Asia does some ultra-low-cost flights if you book ahead and accept strange travel hours. Substantially cheaper than Malaysia. (I can recommend a superb and well priced guide if interested.)
 Stay in one of many many grotty dirt-cheap fun hostels off Malioboro St.
  Visit Borubadur !!!! - about as must-see as a photo site can get.
Prambanan    - would be stunning if Borubadur was not there. 
Dieng PLateau - VERY LONG day trip - the journey itself is a stunning photo opportunity - one of the most amazing day drives of my life. Area is v good as well. 

Mt Merapi - volcano with attitude - and worthwhile even when quiet. Pillion motorcyle ride part way up the mountain. Sobering. Plus Merbabu near behind. 

And much more ...

Note that airfares to a range of other Asian countries may cost well under $US100 - sometimes as low as about $US30 to eg Vietnam. Almost worth a weekend in a number of  other countries depending on finances. 



If question moved to 'Travel"" this answer could be taken with it.
"
2494,2494,3978,What exactly is the difference between Unreal Development Kit and Uunreal Engine 4?,"I want to start learning game development and I would obviously come across this tool. So every where I went people mentioned Unreal Engine 4 to be a viable choice, I've tried a bit of Unity and now I want to try Unreal. Only issue I came across UDK and UE4, I downloaded UDK which turns out to be different from tutorials and I can't seem to find any info on that and besides I could only run the software once because after the first time it starts a game, I re-installed UDK I still get the issue, but anyways that's a different topic, what I want to know is whether UDK and UE4 are different and if they are, where do i get UE4, becauuse when I down UE4 (from - https://www.unrealengine.com/dashboard), it downloads a game launcher and no development tool. In case they are same, why is my version of UDK different fr
",Swapnil Rastogi,https://gamedev.stackexchange.com/users/59539,"According to this link


  WHAT IS UDK?
  
  Unreal Development Kit was the free edition of Unreal Engine 3. It remains available for teams completing projects in UE3. Get UDK (February 2015 UDK).


So you want to avoid using UDK and use Unreal Engine 4
",Soapy,https://gamedev.stackexchange.com/users/12546,http://gamedev.stackexchange.com/questions/102603/what-exactly-is-the-difference-between-unreal-development-kit-and-uunreal-engine,TECHNOLOGY,gamedev.stackexchange.com,1.0,0.6666666666666666,0.0,1.0,0.6666666666666666,1.0,0.5555555555555556,0.3333333333333333,0.6666666666666666,0.0,0.3333333333333333,0.0,1.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,1.0,1.0,0.5555555555555556,1.0,1.0,0.9333333333333332,0.3333333333333333,0.0,0.3333333333333333,1.0,What is the difference between the unreal development kit and the uunreal engine 4?,"I want to start learning about game development, and obviously I will encounter this tool. So everywhere I go, people talk about virtual engine 4 as a viable option, I tried some unity, and now I want to try virtual. The only problem I encountered was UDK and UE4. I downloaded UDK and found that it was different from the tutorial. I couldn't seem to find any information about it. Moreover, I could only run the software once, because after it started the game for the first time, I reinstalled UDK. I still got this problem, but anyway, this is a different topic. What I want to know is that UDK and UE4 are different Yes, if they are, where do I get UE4, because when I close UE4 (from - https://www.unrealengine.com/dashboard), it will download a game launcher without development tools. If they are the same, why is my UDK version different from fr","According to this link


  WHAT IS UDK?
  
  Unreal Development Kit was the free edition of Unreal Engine 3. It remains available for teams completing projects in UE3. Get UDK (February 2015 UDK).


So you want to avoid using UDK and use Unreal Engine 4
"
5320,5320,8451,Take quick notes without interrupting current activity,"When I’m in the middle of something and get an idea, I want to note it down without interrupting what I’m doing.

Desired workflow: adding a note


I press a key (or a key combo).
(should work everywhere: while browsing, while writing, while watching a video, etc.)
A note window opens.
(just a single text field, no title/category/etc.)
(it must be empty)
(doesn’t have to be a GUI)
I enter my note.
I press, e.g. Enter to save the note.
(the window must close automatically)


Browsing notes


Just a simple list/table of all saved notes.

Especially not just text files which I’d have to open separately to read their content.

Should display the date/time when a note was saved.
Should offer a quick way to delete notes.
No need for editing notes.


Formal requirements

A solution must be FLOSS and run natively on GNU/Linux.
",unor,https://softwarerecs.stackexchange.com/users/60,"It sounds to me like Tomboy would definitely do the job.  Excerpt from the website:


  Tomboy is a desktop note-taking application for Linux, Unix, Windows, and Mac OS X. Simple and easy to use, but with potential to help you organize the ideas and information you deal with every day.
  
  Notable Features
  
  
  Highlighting text
  Inline spelll checking
  Auto-linking web &amp; email addresses
  Undo/redo
  Font styling &amp; sizing
  Bulleted lists
  Note synchronization across several computers 
  


Emacs-style binding can be used, and it has several plugins.  As for the list without need of opening the notes, all notes can be exported to an HTML page.  This whole thing may however be too fancy for your needs.
",Michaël,https://softwarerecs.stackexchange.com/users/12692,http://softwarerecs.stackexchange.com/questions/2224/take-quick-notes-without-interrupting-current-activity,SCIENCE,softwarerecs.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.5555555555555556,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.8666666666666666,0.0,0.0,0.6666666666666666,0.8888888888888888,Take notes quickly without interrupting the current activity,"When I’m in the middle of something and get an idea, I want to note it down without interrupting what I’m doing.

Desired workflow: adding a note


I press a key (or a key combo).
(should work everywhere: while browsing, while writing, while watching a video, etc.)
A note window opens.
(just a single text field, no title/category/etc.)
(it must be empty)
(doesn’t have to be a GUI)
I enter my note.
I press, e.g. Enter to save the note.
(the window must close automatically)


Browsing notes


Just a simple list/table of all saved notes.

Especially not just text files which I’d have to open separately to read their content.

Should display the date/time when a note was saved.
Should offer a quick way to delete notes.
No need for editing notes.


Formal requirements

A solution must be FLOSS and run natively on GNU/Linux.
","It sounds to me like Tomboy would definitely do the job.  Excerpt from the website:


  Tomboy is a desktop note-taking application for Linux, Unix, Windows, and Mac OS X. Simple and easy to use, but with potential to help you organize the ideas and information you deal with every day.
  
  Notable Features
  
  
  Highlighting text
  Inline spelll checking
  Auto-linking web &amp; email addresses
  Undo/redo
  Font styling &amp; sizing
  Bulleted lists
  Note synchronization across several computers 
  


Emacs-style binding can be used, and it has several plugins.  As for the list without need of opening the notes, all notes can be exported to an HTML page.  This whole thing may however be too fancy for your needs.
"
4831,4831,7679,How can I speed up the rate at which putty dries?,"We're (slowly) renovating the sash windows in our house and the current window is causing problems. What should have been a quick job (especially at this time of year!) has turned into a marathon because the putty won't dry.

We had to replace a couple of panes of glass (one was cracked and we broke another when using a heat gun to remove the paint) so we knew it would take a little while. On a previous window the putty took over three weeks to dry enough to paint partly because (as we thought) there was too much oil. So this time we rolled the putty on newspaper first to try to remove the excess oil. It seemed to work, but after two weeks the putty is still soft to the touch.

We've tried standing the windows next to a radiator but all that seemed to do was make it softer (which was obviously going to happen in hindsight).

So given that we don't want to reputty the windows what can we do to speed up the drying process.

We've had to seal off the room and cover the window as best we can in the meantime.

I've found this advice on DoItYourself.com which doesn't really help as it says use other materials!

The answers to this post on DIY-Forums are confusing at best and possibly contradictory as one recommends exposing the putty to moisture(!) to speed the drying process.
",ChrisF,https://diy.stackexchange.com/users/194,"I always use DAP glazing compound and have never had a problem being able to paint it 24 hours later.  I think you may have a bad or old lot there. Go to the latex based products and you will not have the same problem again.  good luck.
",shirlock homes,https://diy.stackexchange.com/users/386,http://diy.stackexchange.com/questions/3022/how-can-i-speed-up-the-rate-at-which-putty-dries,LIFE_ARTS,diy.stackexchange.com,1.0,0.7777777777777778,0.0,1.0,0.3333333333333333,1.0,0.4444444444444444,0.5555555555555556,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,1.0,0.7777777777777778,0.4444444444444444,0.8888888888888888,1.0,0.7333333333333333,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.7777777777777778,How can I speed up the drying of putty?,"We're (slowly) renovating the sash windows in our house and the current window is causing problems. What should have been a quick job (especially at this time of year!) has turned into a marathon because the putty won't dry.

We had to replace a couple of panes of glass (one was cracked and we broke another when using a heat gun to remove the paint) so we knew it would take a little while. On a previous window the putty took over three weeks to dry enough to paint partly because (as we thought) there was too much oil. So this time we rolled the putty on newspaper first to try to remove the excess oil. It seemed to work, but after two weeks the putty is still soft to the touch.

We've tried standing the windows next to a radiator but all that seemed to do was make it softer (which was obviously going to happen in hindsight).

So given that we don't want to reputty the windows what can we do to speed up the drying process.

We've had to seal off the room and cover the window as best we can in the meantime.

I've found this advice on DoItYourself.com which doesn't really help as it says use other materials!

The answers to this post on DIY-Forums are confusing at best and possibly contradictory as one recommends exposing the putty to moisture(!) to speed the drying process.
",I always use DAP glass compound and never have a problem being able to draw it 24 hours later. I think you may have a bad or old lot. You won't have the same problem with latex based products. Good luck.
873,873,1386,What is it called when a music has two concurrent tempos,"I've recently watched a BBC documentary about the history of music and recall an episode where they talk about music that has two distinct tempos (and possibly time signatures) at the same time for different sets of instruments.

Still, I can't remember how this is called and who are the famous composers that composed that way (Stravinsky?).
",Arthur Rizzo,https://music.stackexchange.com/users/16830,"The answer here is deceptively simple: Polytempo.  There are other names, such as multi-tempo, polytemporal, and others, but they all describe the same phenomena.

Here is a link for further reading on Wikipedia.

For a list of composers that have used this technique, as well as the pieces in which this technique was used, check out this page and look under ""Compositions"".



I want to clarify for everyone that Polyrhythm and Polymetric are both incorrect here.  Polyrhythms are multiple, independent rhythmic lines (typically ostinatos) that can form a hemiola or hemiola-like effect in music.  Polymeters are ways of organizing the beat.  Tempo is the speed of the beat, not how it is organized, or the rhythms that it defines.

Here is a wonderful Q/A from this very website that addresses the difference: Polymeter vs Polyrhythm 
",jjmusicnotes,https://music.stackexchange.com/users/3518,http://music.stackexchange.com/questions/30524/what-is-it-called-when-a-music-has-two-concurrent-tempos,LIFE_ARTS,music.stackexchange.com,1.0,0.7777777777777778,0.0,1.0,1.0,1.0,0.5555555555555556,0.5555555555555556,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,0.7777777777777778,1.0,0.7777777777777778,1.0,1.0,1.0,0.0,0.0,0.3333333333333333,0.8888888888888888,What is the name of a music when it has two simultaneous rhythms,"I recently watched a BBC Documentary on the history of music, and I recall an episode in which they talked about music that has two different rhythms (and possibly time characteristics) in different instrument combinations.","The answer here is deceptively simple: Polytempo.  There are other names, such as multi-tempo, polytemporal, and others, but they all describe the same phenomena.

Here is a link for further reading on Wikipedia.

For a list of composers that have used this technique, as well as the pieces in which this technique was used, check out this page and look under ""Compositions"".



I want to clarify for everyone that Polyrhythm and Polymetric are both incorrect here.  Polyrhythms are multiple, independent rhythmic lines (typically ostinatos) that can form a hemiola or hemiola-like effect in music.  Polymeters are ways of organizing the beat.  Tempo is the speed of the beat, not how it is organized, or the rhythms that it defines.

Here is a wonderful Q/A from this very website that addresses the difference: Polymeter vs Polyrhythm 
"
5634,5634,8931,AES 256 Encryption - Is it really easy to decrypt if you have the key?,"So this might sound like a crazy question but bear with me for a minute. I can't find any info on the internet and so am here, although this might have been a good place to start.

I've recently developed an encryption engine using the .net's AES managed classes. I use a 256 bit key generated by the Rfc2898DeriveBytes function. The key is generated from a pass phrase that is at least 40 characters long. The IV is also generated from this pass phrase. The encryption class uses a CypherMode of CBC and a padding mode of PKCS7. There is a static salt that is 8 bytes long. 

The key is stored in a separate database to the data and is itself encrypted using a certificate based on the database master key.

So, my question is: is it really easy to decrypt the data if the attacker has the key? I'm not talking about the Chinese government (or even GHCQ given recent headlines), I'm talking about an attacker who steals both databases. 

What would be the steps they have to follow and/or how can I stop them on their path? The reason I ask this is that I want to know how feasible it is. Is it something that can be done in minutes or does it fall into the bracket of being infeasible? Do they have to calculate all of the parameters used when encrypting?
",bhs,https://crypto.stackexchange.com/users/7684,"I assume you follow Kerckhoff's principle so the attacker knows the padding scheme and derivation function so the answer is yes, it only takes a few seconds to decrypt and anyone can do it. 

If he doesn't know these things, he can find them by trial and error (assuming he can get his hands on a valid ciphertext).

The IV can be sent in the clear so making it depend on the key reveals some information on the key. It should also be unique for each session so I'm a bit worried about it. It should be OK if the KDF you're using is non-deterministic, which implies it uses its own IV so the problem remains. See this question for more on IVs.



Edit based on comments:
The cracking procedure is the following: 
$a$ is the number of all modern ciphers. Let's set this to 100. $m$ is the number of modes per cipher, set it to 6. $k=100$ is the number of key derivation functions, $p=100$ are the padding schemes. The values are arbitrary. So we have $(p*k*m*a*c)/n = 6*10^6$ which equals to approx. 69 days with $c=1$ second and $n=1$ processor. 

Your adversary will solve the problem in $69/2=34.5$ days. Not as practical but definitely feasible, especially if you throw extra processors at it. This solution is completly brute-force, it makes no attempt at distinguishing and pre-eliminating ciphers.

Since non-indistinguishability is a business requirement (really?) you could just get away with using ECB instead of any other mode.
",rath,https://crypto.stackexchange.com/users/5231,http://crypto.stackexchange.com/questions/9276/aes-256-encryption-is-it-really-easy-to-decrypt-if-you-have-the-key,TECHNOLOGY,crypto.stackexchange.com,1.0,0.3333333333333333,0.0,0.0,1.0,0.0,0.7777777777777778,0.7777777777777778,1.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.3333333333333333,0.0,1.0,1.0,"Aes256 encryption - if you have a key, is decryption really easy?","So this might sound like a crazy question but bear with me for a minute. I can't find any info on the internet and so am here, although this might have been a good place to start.

I've recently developed an encryption engine using the .net's AES managed classes. I use a 256 bit key generated by the Rfc2898DeriveBytes function. The key is generated from a pass phrase that is at least 40 characters long. The IV is also generated from this pass phrase. The encryption class uses a CypherMode of CBC and a padding mode of PKCS7. There is a static salt that is 8 bytes long. 

The key is stored in a separate database to the data and is itself encrypted using a certificate based on the database master key.

So, my question is: is it really easy to decrypt the data if the attacker has the key? I'm not talking about the Chinese government (or even GHCQ given recent headlines), I'm talking about an attacker who steals both databases. 

What would be the steps they have to follow and/or how can I stop them on their path? The reason I ask this is that I want to know how feasible it is. Is it something that can be done in minutes or does it fall into the bracket of being infeasible? Do they have to calculate all of the parameters used when encrypting?
","I assume you follow Kerckhoff's principle so the attacker knows the padding scheme and derivation function so the answer is yes, it only takes a few seconds to decrypt and anyone can do it. 

If he doesn't know these things, he can find them by trial and error (assuming he can get his hands on a valid ciphertext).

The IV can be sent in the clear so making it depend on the key reveals some information on the key. It should also be unique for each session so I'm a bit worried about it. It should be OK if the KDF you're using is non-deterministic, which implies it uses its own IV so the problem remains. See this question for more on IVs.



Edit based on comments:
The cracking procedure is the following: 
$a$ is the number of all modern ciphers. Let's set this to 100. $m$ is the number of modes per cipher, set it to 6. $k=100$ is the number of key derivation functions, $p=100$ are the padding schemes. The values are arbitrary. So we have $(p*k*m*a*c)/n = 6*10^6$ which equals to approx. 69 days with $c=1$ second and $n=1$ processor. 

Your adversary will solve the problem in $69/2=34.5$ days. Not as practical but definitely feasible, especially if you throw extra processors at it. This solution is completly brute-force, it makes no attempt at distinguishing and pre-eliminating ciphers.

Since non-indistinguishability is a business requirement (really?) you could just get away with using ECB instead of any other mode.
"
1607,1607,2525,Grapple + Totemic Attunement (Eagle) = Zangief's Spinning Atomic Piledriver?,"Could a Barbarian with Totemic Attunement (eagle) use grapple to perform the iconic move by dragging the enemy straight up as far as the fly speed allows and ending the turn in the air? If so, who would take fall damage?
",ZHDarkstar,https://rpg.stackexchange.com/users/16224,"You can give fall damage by jumping in the air while grapling. You both would recieve fall damage and be prone unless an ability like slow fall or feather fall says otherwise. 

However, the barbarian is not best way to achieve your goal.  The best way to pull off a pile driver like you are describing would be with a Monk/Druid.  You only need to multiclass one level of Druid at level 2 in order to get access to helpful spells like longstrider, jump, and Guidance. The Monk gives you useful features like Slow Fall(reduce fall damage), Step of the Wind (use dash as a bonus action), and Extra Attack. Be a human, so you can get a bonus feat as a level one monk (if your DM allows). I would get the Athlete feat to start with and grab the Mobile feat at level 5 (remember you have to wait cause of the one level of multiclass into druid at level 2)

Here is the full pile driver combo,you grapple a target and then make a standing high jump. At the top of your jump, you hurl them to the ground, deal damage to them from the fall, knock them prone with no save, and then just re-grapple them in the same turn. This works by using the Jump spell to triple your jump distance, Step of the Wind to double it, and then stacking move speed bonuses so you can get to maximum height even with half move speed. Here's how it works assuming a base speed of 50 (30 + Longstrider 10 + unarmored Monk 10) and assuming you have Extra Attack.

Start next to your opponent and grapple them with the attack action (attack #1).

Take the Step of the Wind bonus action to Dash and to double your jump distance. Your move speed is now 50 for the turn (50 base / 2 grappled * 2 Dash).

Take a 5 foot step (45 remaining) to trigger Athletic.

LEAP FOR THE HEAVENS. Your jump height is massive at 36 (3 base + 3 strength = 6 * 3 Jump = 18 * 2 Step = 36 feet). Carry your opponent with you as you jump straight up.

At the top of your arc, release the grapple. And by ""release the grapple"", I mean hurl that poor guy back to the ground with a mighty heave.

Opponent falls and takes 3d6 damage, landing prone with no save.

You fall and take 3d6 - 5x Monk Level damage (assuming Slow Fall at level 4).

If you take no damage, use your remaining attack action from Extra Attack to re-grapple the prone target (attack #2)

If you take damage and land prone, use 5 feet of movement to stand from Athletic, and then regrapple the prone target.

BONUS: If your DM lets you, just land on your target; he should take 3d6 damage again from your fall.

I got this combo from the WotC Forums. The guide is called the Grappler's Manual. 
http://community.wizards.com/forum/player-help/threads/4142801
",psychoed42,https://rpg.stackexchange.com/users/16331,http://rpg.stackexchange.com/questions/49223/grapple-totemic-attunement-eagle-zangiefs-spinning-atomic-piledriver,CULTURE,rpg.stackexchange.com,0.6666666666666666,0.5555555555555556,0.3333333333333333,0.6666666666666666,0.6666666666666666,1.0,0.6666666666666666,0.5555555555555556,1.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.6666666666666666,0.0,0.8888888888888888,1.0,0.7777777777777778,1.0,0.8888888888888888,0.9333333333333332,0.3333333333333333,0.3333333333333333,1.0,0.7777777777777778,Fight + totem tuning (hawk) = Zanger's rotating atom stacker?,"Can a barbarian (hawk) with totem modulation use a grapple to complete a symbolic movement? As long as the flight speed allows, drag the enemy straight up and end the turn in the air? If so, who will take the fall damage?","You can give fall damage by jumping in the air while grapling. You both would recieve fall damage and be prone unless an ability like slow fall or feather fall says otherwise. 

However, the barbarian is not best way to achieve your goal.  The best way to pull off a pile driver like you are describing would be with a Monk/Druid.  You only need to multiclass one level of Druid at level 2 in order to get access to helpful spells like longstrider, jump, and Guidance. The Monk gives you useful features like Slow Fall(reduce fall damage), Step of the Wind (use dash as a bonus action), and Extra Attack. Be a human, so you can get a bonus feat as a level one monk (if your DM allows). I would get the Athlete feat to start with and grab the Mobile feat at level 5 (remember you have to wait cause of the one level of multiclass into druid at level 2)

Here is the full pile driver combo,you grapple a target and then make a standing high jump. At the top of your jump, you hurl them to the ground, deal damage to them from the fall, knock them prone with no save, and then just re-grapple them in the same turn. This works by using the Jump spell to triple your jump distance, Step of the Wind to double it, and then stacking move speed bonuses so you can get to maximum height even with half move speed. Here's how it works assuming a base speed of 50 (30 + Longstrider 10 + unarmored Monk 10) and assuming you have Extra Attack.

Start next to your opponent and grapple them with the attack action (attack #1).

Take the Step of the Wind bonus action to Dash and to double your jump distance. Your move speed is now 50 for the turn (50 base / 2 grappled * 2 Dash).

Take a 5 foot step (45 remaining) to trigger Athletic.

LEAP FOR THE HEAVENS. Your jump height is massive at 36 (3 base + 3 strength = 6 * 3 Jump = 18 * 2 Step = 36 feet). Carry your opponent with you as you jump straight up.

At the top of your arc, release the grapple. And by ""release the grapple"", I mean hurl that poor guy back to the ground with a mighty heave.

Opponent falls and takes 3d6 damage, landing prone with no save.

You fall and take 3d6 - 5x Monk Level damage (assuming Slow Fall at level 4).

If you take no damage, use your remaining attack action from Extra Attack to re-grapple the prone target (attack #2)

If you take damage and land prone, use 5 feet of movement to stand from Athletic, and then regrapple the prone target.

BONUS: If your DM lets you, just land on your target; he should take 3d6 damage again from your fall.

I got this combo from the WotC Forums. The guide is called the Grappler's Manual. 
http://community.wizards.com/forum/player-help/threads/4142801
"
2836,2836,4512,Slowdown in large perl array,"I'm currently running a perl program where I have to take a 1 million line text file, break it down into chunks (anywhere between 50 and 50,000 lines per chunk), and run some calculations and such on them.  Right now, I load all of the data into array1.  I take array2 and use it to pull just the chunks of data I need.  I then do what I need to perform on array 2, and then go back and grab the next set.

example data

A, blah1, blah2

A, blah6, blah7

A, blah4, blah5

B, blah2, blah2

So I would grab the first three into array 2, sort them, then move on to the next set. My program works pretty well and efficiently to begin with, but it experiences a severe slowdown later on.

50K takes 50 seconds, 100k takes 184 seconds, 150k takes 360 seconds, 200k takes 581 seconds, and it only gets exponentially worse as the program continues (4500 seconds at line 500k)

No, I cannot use a database for this project, any suggestions?

my @Rows1=&lt;FILE&gt;;
my $temp = @Rows1;
for($k = 0; $k &lt; $temp; $k++)
{
    my @temp2array = ();
    my $temp2count = 0;
    my $thisrow = $Rows1[$k];
    my @thisarray = split(',', $thisrow);
    my $currcode = $thisarray[0];
    my $flag123 = 0;
    $temp2array[$temp2count] = $thisrow;
    $temp2count++;
    while ($flag123 == 0)
    {
        $nextrow = $tuRows1[$k + 1];
        @nextarray = split(',', $nextrow);
        if ($currcode eq $nextarray[0])
        {
            $temp2array[$temp2count] = $nextrow;
            $k++;
            $temp2count++;
        }
        else
        {
            $flag123 = 1;
        }
    }
}


I have edited my code to more resemble the answer below, and I've got these times:

50k = 42, 100k = 133, 150k = 280, 200k = 467, 250k = 699, 300k = 978, 350k = 1313

Its not exactly keeping linear, and by this trend, this prog will still take 14000+ seconds.  I'll investigate other parts of the code
",ThePirateSheep,https://stackoverflow.com/users/590982,"Does just running the code you show have the slowdown?  If not, the problem is in the code that actually processes each @temp2array chunk, perhaps some variable(s) still having data left over from previous chunks.
",ysth,https://stackoverflow.com/users/17389,http://stackoverflow.com/questions/4807740/slowdown-in-large-perl-array,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.4444444444444444,0.8888888888888888,0.5555555555555556,1.0,1.0,0.6666666666666667,0.3333333333333333,0.0,0.6666666666666666,0.8888888888888888,Large Perl arrays slow down,"I'm currently running a perl program where I have to take a 1 million line text file, break it down into chunks (anywhere between 50 and 50,000 lines per chunk), and run some calculations and such on them.  Right now, I load all of the data into array1.  I take array2 and use it to pull just the chunks of data I need.  I then do what I need to perform on array 2, and then go back and grab the next set.

example data

A, blah1, blah2

A, blah6, blah7

A, blah4, blah5

B, blah2, blah2

So I would grab the first three into array 2, sort them, then move on to the next set. My program works pretty well and efficiently to begin with, but it experiences a severe slowdown later on.

50K takes 50 seconds, 100k takes 184 seconds, 150k takes 360 seconds, 200k takes 581 seconds, and it only gets exponentially worse as the program continues (4500 seconds at line 500k)

No, I cannot use a database for this project, any suggestions?

my @Rows1=&lt;FILE&gt;;
my $temp = @Rows1;
for($k = 0; $k &lt; $temp; $k++)
{
    my @temp2array = ();
    my $temp2count = 0;
    my $thisrow = $Rows1[$k];
    my @thisarray = split(',', $thisrow);
    my $currcode = $thisarray[0];
    my $flag123 = 0;
    $temp2array[$temp2count] = $thisrow;
    $temp2count++;
    while ($flag123 == 0)
    {
        $nextrow = $tuRows1[$k + 1];
        @nextarray = split(',', $nextrow);
        if ($currcode eq $nextarray[0])
        {
            $temp2array[$temp2count] = $nextrow;
            $k++;
            $temp2count++;
        }
        else
        {
            $flag123 = 1;
        }
    }
}


I have edited my code to more resemble the answer below, and I've got these times:

50k = 42, 100k = 133, 150k = 280, 200k = 467, 250k = 699, 300k = 978, 350k = 1313

Its not exactly keeping linear, and by this trend, this prog will still take 14000+ seconds.  I'll investigate other parts of the code
","Does just running the code you show have the slowdown?  If not, the problem is in the code that actually processes each @temp2array chunk, perhaps some variable(s) still having data left over from previous chunks.
"
2174,2174,3466,Change published date to 12 hour time,"Right now my nodes say published by ""author name 19:02"". How can I change it to display 12 hour time 7:02?
",Matthew Hui,https://drupal.stackexchange.com/users/1170,"In Drupal there are specific theming functions to customize this:

This is the default (for nodes):

function theme_node_submitted($node) {
  return t('Submitted by !username on @datetime',
    array(
      '!username' =&gt; theme('username', $node),
      '@datetime' =&gt; format_date($node-&gt;created),
    ));
}


This is the default for comments:

function theme_comment_submitted($comment) {
  return t('Submitted by !username on @datetime.',
    array(
      '!username' =&gt; theme('username', $comment),
      '@datetime' =&gt; format_date($comment-&gt;timestamp)
    ));
}


To override them, add these functions in your template.tpl.php of your theme, and change the name to MYTHEME_node_submitted. And now you can customize it:

Drupal 6 uses by default the format 'D, m/d/Y - H:i' , to understand the meaning of these letters, see full PHP doc here

To display in 12 hour format, replace H by h like this:

format_date($node-&gt;created, 'custom', 'D, m/d/Y - h:i');


API reference about format_date()
",corbacho,https://drupal.stackexchange.com/users/392,http://drupal.stackexchange.com/questions/6693/change-published-date-to-12-hour-time,TECHNOLOGY,drupal.stackexchange.com,1.0,0.3333333333333333,0.0,1.0,1.0,1.0,1.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.9,1.0,0.0,0.0,0.8333333333333334,Change release date to 12 hours,"Now my node is published by ""author name 19:02"". How do I change it to show 12 hours at 7:02?","In Drupal there are specific theming functions to customize this:

This is the default (for nodes):

function theme_node_submitted($node) {
  return t('Submitted by !username on @datetime',
    array(
      '!username' =&gt; theme('username', $node),
      '@datetime' =&gt; format_date($node-&gt;created),
    ));
}


This is the default for comments:

function theme_comment_submitted($comment) {
  return t('Submitted by !username on @datetime.',
    array(
      '!username' =&gt; theme('username', $comment),
      '@datetime' =&gt; format_date($comment-&gt;timestamp)
    ));
}


To override them, add these functions in your template.tpl.php of your theme, and change the name to MYTHEME_node_submitted. And now you can customize it:

Drupal 6 uses by default the format 'D, m/d/Y - H:i' , to understand the meaning of these letters, see full PHP doc here

To display in 12 hour format, replace H by h like this:

format_date($node-&gt;created, 'custom', 'D, m/d/Y - h:i');


API reference about format_date()
"
310,310,499,Is it possible to add house numbers using the Mapbox Street Vector Tiles source in Tilemill2?,"Title says it all. Does anyony know if the house number is included in Mapbox’ vector tiles, and if so how to access it for styling? Thanks for any advice!
",Alexander Rutz,https://gis.stackexchange.com/users/27171,"As far as I know, house numbers are not currently included in MapBox's vector tiles.

If you need to render a small region, you can get them in GeoJSON with Overpass Turbo (press ""Run"", then ""Export"" and ""geoJSON""), which you can use in TileMill as a layer. For bigger regions you might need to process planet extracts or the planet file itself.
",Ilja Zverev,https://gis.stackexchange.com/users/30197,http://gis.stackexchange.com/questions/95071/is-it-possible-to-add-house-numbers-using-the-mapbox-street-vector-tiles-source,TECHNOLOGY,gis.stackexchange.com,1.0,0.6666666666666666,0.0,0.3333333333333333,1.0,1.0,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.6666666666666666,0.0,0.8888888888888888,Can I use the mapbox Street vector tiles source in tilemil2 to add a house number?,"The title says everything. Does anyone know if the house number is included in the vector block of the map box, and if so, how to access it for styling? Thank you for your advice!","As far as I know, house numbers are not currently included in MapBox's vector tiles.

If you need to render a small region, you can get them in GeoJSON with Overpass Turbo (press ""Run"", then ""Export"" and ""geoJSON""), which you can use in TileMill as a layer. For bigger regions you might need to process planet extracts or the planet file itself.
"
1448,1448,2282,can´t save new field in magento(1.9) customer registration checkout form,"I followed the instructions to add a new field in customer registration from add new field in magento(1.9) customer registration, works perfect!

I need help to add this field to customer registration on checkout page also.

I added this to my module xml (ea_dni is the name of my module):

&lt;checkout_onepage_index&gt;
    &lt;reference name=""checkout.onepage.billing""&gt;
        &lt;action method=""setTemplate""&gt;
            &lt;template&gt;ea_dni/billing.phtml&lt;/template&gt;
        &lt;/action&gt;
    &lt;/reference&gt;
&lt;/checkout_onepage_index&gt;


And I added the field in billing.phtml

            &lt;li&gt;
                &lt;label for=""eadni""&gt;&lt;?php echo $this-&gt;__('DNI') ?&gt;&lt;/label&gt;
                &lt;div class=""input-box""&gt;
                    &lt;input type=""text"" name=""eadni"" id=""eadni"" value=""&lt;?php echo $this-&gt;htmlEscape($this-&gt;getCustomer()-&gt;getDNI()) ?&gt;"" title=""&lt;?php echo $this-&gt;__('DNI') ?&gt;"" class=""input-text"" /&gt;
                &lt;/div&gt;
            &lt;/li&gt;


So, I see the new field in checkout registration form, but this field is not saving to the database!

This is my install-1.0.0.php

&lt;?php

$this-&gt;addAttribute('customer', 'eadni', array(
    'type'      =&gt; 'varchar',
    'label'     =&gt; 'DNI',
    'input'     =&gt; 'text',
    'position'  =&gt; 120,
    'required'  =&gt; false,//or true
    'is_system' =&gt; 0,
));
$attribute = Mage::getSingleton('eav/config')-&gt;getAttribute('customer', 'eadni');
$attribute-&gt;setData('used_in_forms', array(
    'adminhtml_customer',
    'checkout_register',
    'customer_account_create',
    'customer_account_edit',
));
$attribute-&gt;setData('is_user_defined', 0);
$attribute-&gt;save();


Can you help me? What am I missing?

Here is my app/code/local/EA/DNI/config.xml

&lt;?xml version=""1.0""?&gt;
&lt;config&gt;
    &lt;modules&gt;
        &lt;EA_DNI&gt;
            &lt;version&gt;1.0.0&lt;/version&gt;
        &lt;/EA_DNI&gt;
    &lt;/modules&gt;
    &lt;global&gt;
        &lt;helpers&gt;
            &lt;ea_dni&gt;
                &lt;class&gt;EA_DNI_Helper&lt;/class&gt;
            &lt;/ea_dni&gt;
        &lt;/helpers&gt;
        &lt;resources&gt;
            &lt;ea_dni_setup&gt;
                &lt;setup&gt;
                    &lt;module&gt;EA_DNI&lt;/module&gt;
                    &lt;class&gt;Mage_Customer_Model_Resource_Setup&lt;/class&gt;
                &lt;/setup&gt;
            &lt;/ea_dni_setup&gt;
        &lt;/resources&gt;
    &lt;/global&gt;
    &lt;frontend&gt;
        &lt;layout&gt;
            &lt;updates&gt;
                &lt;ea_dni&gt;
                    &lt;file&gt;ea_dni.xml&lt;/file&gt;
                &lt;/ea_dni&gt;
            &lt;/updates&gt;
        &lt;/layout&gt;
        &lt;translate&gt;
            &lt;modules&gt;
                &lt;EA_DNI&gt;
                    &lt;files&gt;
                        &lt;default&gt;EA_DNI.csv&lt;/default&gt;
                    &lt;/files&gt;
                &lt;/EA_DNI&gt;
            &lt;/modules&gt;
        &lt;/translate&gt;
    &lt;/frontend&gt;
&lt;/config&gt;

",elismoran,https://magento.stackexchange.com/users/27241,"Seems to be a similar issue. You can see my suggested solution here: Custom Attribute Not saved in Checkout Register Form - Magento
",Johny,https://magento.stackexchange.com/users/27369,http://magento.stackexchange.com/questions/71579/can%C2%B4t-save-new-field-in-magento1-9-customer-registration-checkout-form,TECHNOLOGY,magento.stackexchange.com,1.0,0.4444444444444444,0.0,1.0,1.0,1.0,0.5555555555555556,0.5555555555555556,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.6666666666666666,0.0,0.7777777777777778,0.7777777777777778,0.5,0.7777777777777778,0.8333333333333334,0.7,0.5,0.5,0.0,0.8888888888888888,Unable to save new fields in the Magento (1.9) customer registration checkout form,"I followed the instructions to add a new field in customer registration from add new field in magento(1.9) customer registration, works perfect!

I need help to add this field to customer registration on checkout page also.

I added this to my module xml (ea_dni is the name of my module):

&lt;checkout_onepage_index&gt;
    &lt;reference name=""checkout.onepage.billing""&gt;
        &lt;action method=""setTemplate""&gt;
            &lt;template&gt;ea_dni/billing.phtml&lt;/template&gt;
        &lt;/action&gt;
    &lt;/reference&gt;
&lt;/checkout_onepage_index&gt;


And I added the field in billing.phtml

            &lt;li&gt;
                &lt;label for=""eadni""&gt;&lt;?php echo $this-&gt;__('DNI') ?&gt;&lt;/label&gt;
                &lt;div class=""input-box""&gt;
                    &lt;input type=""text"" name=""eadni"" id=""eadni"" value=""&lt;?php echo $this-&gt;htmlEscape($this-&gt;getCustomer()-&gt;getDNI()) ?&gt;"" title=""&lt;?php echo $this-&gt;__('DNI') ?&gt;"" class=""input-text"" /&gt;
                &lt;/div&gt;
            &lt;/li&gt;


So, I see the new field in checkout registration form, but this field is not saving to the database!

This is my install-1.0.0.php

&lt;?php

$this-&gt;addAttribute('customer', 'eadni', array(
    'type'      =&gt; 'varchar',
    'label'     =&gt; 'DNI',
    'input'     =&gt; 'text',
    'position'  =&gt; 120,
    'required'  =&gt; false,//or true
    'is_system' =&gt; 0,
));
$attribute = Mage::getSingleton('eav/config')-&gt;getAttribute('customer', 'eadni');
$attribute-&gt;setData('used_in_forms', array(
    'adminhtml_customer',
    'checkout_register',
    'customer_account_create',
    'customer_account_edit',
));
$attribute-&gt;setData('is_user_defined', 0);
$attribute-&gt;save();


Can you help me? What am I missing?

Here is my app/code/local/EA/DNI/config.xml

&lt;?xml version=""1.0""?&gt;
&lt;config&gt;
    &lt;modules&gt;
        &lt;EA_DNI&gt;
            &lt;version&gt;1.0.0&lt;/version&gt;
        &lt;/EA_DNI&gt;
    &lt;/modules&gt;
    &lt;global&gt;
        &lt;helpers&gt;
            &lt;ea_dni&gt;
                &lt;class&gt;EA_DNI_Helper&lt;/class&gt;
            &lt;/ea_dni&gt;
        &lt;/helpers&gt;
        &lt;resources&gt;
            &lt;ea_dni_setup&gt;
                &lt;setup&gt;
                    &lt;module&gt;EA_DNI&lt;/module&gt;
                    &lt;class&gt;Mage_Customer_Model_Resource_Setup&lt;/class&gt;
                &lt;/setup&gt;
            &lt;/ea_dni_setup&gt;
        &lt;/resources&gt;
    &lt;/global&gt;
    &lt;frontend&gt;
        &lt;layout&gt;
            &lt;updates&gt;
                &lt;ea_dni&gt;
                    &lt;file&gt;ea_dni.xml&lt;/file&gt;
                &lt;/ea_dni&gt;
            &lt;/updates&gt;
        &lt;/layout&gt;
        &lt;translate&gt;
            &lt;modules&gt;
                &lt;EA_DNI&gt;
                    &lt;files&gt;
                        &lt;default&gt;EA_DNI.csv&lt;/default&gt;
                    &lt;/files&gt;
                &lt;/EA_DNI&gt;
            &lt;/modules&gt;
        &lt;/translate&gt;
    &lt;/frontend&gt;
&lt;/config&gt;

","Seems to be a similar issue. You can see my suggested solution here: Custom Attribute Not saved in Checkout Register Form - Magento
"
3464,3464,5517,nm: how to show object file of a symbol in a shared library?,"I have 25 object files which are combined to form one shared library. I have generated the shared library with gcc and while I was looking for exposed symbols with nm -D libmylib.so, I found two undesirable exposed symbols with the name of i and y which are in .bss section. I have tried to find them in my source files but i cant find them so if anyone can tell me whether there is some way to find that which .o file exactly has these undesired exposed symbols? Can I do it with nm or do I need another tool?

Any help would be appreciated.
",Jewel Thief,https://stackoverflow.com/users/495590,"In the directory with your object files you can run:

find . -name '*.o' -exec nm -D {} \; -print


This should print symbols and then file name
",Kylo,https://stackoverflow.com/users/173967,http://stackoverflow.com/questions/13365347/nm-how-to-show-object-file-of-a-symbol-in-a-shared-library,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.6666666666666666,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,1.0,Nm: how to display symbol object files in shared libraries?,"I have 25 object files combined into a shared library. I've generated a shared library with GCC, and when I look for public symbols with nm-d libmylib.so, I find two unpopular public symbols named I and Y in the. BSS section. I tried to find them in my source file, but I couldn't find them, so if someone could tell me if there was some way to find which. O file exactly had these unwanted exposure symbols? Can I use nanometers or do I need another tool?","In the directory with your object files you can run:

find . -name '*.o' -exec nm -D {} \; -print


This should print symbols and then file name
"
4379,4379,6966,How does owning a home and paying on a mortgage fit into family savings and investment?,"I'm in my mid-20's, and so I am aiming at long-term growth with higher risk in my portfolio.  My financial adviser is showing me some investment allocations that put my money in some growth, mid, and value-retention locations.  He doesn't seem to be taking into the equation the fact that I am putting a huge percentage of my paycheck into my home.

I know home values fluctuate, but long term, it seems to be a pretty good way to at least retain value, and at best make a small return.  If I am already contributing so much to my ""home"" investment, why would I also invest in stocks or bonds with a low rate of return, even though they are considered a ""safe"" part of my portfolio?

Update: I think the question really has two parts.

1) How does owning a home fit into my financial portfolio?  Most seem to agree that at best it is a hedge against rent or dollar inflation, and at worst it should be viewed as a liability, and has no place alongside other real investments.

2) How should one view payments on a home mortgage?  How are they similar or different to investing in low-risk low-reward investments?
",Cory Klein,https://money.stackexchange.com/users/6310,"
  1) How does owning a home fit into my financial portfolio? Most seem to agree that at best it is a hedge against rent or dollar inflation, and at worst it should be viewed as a liability, and has no place alongside other real investments.


Periods of high inflation are generally accompanied with high(er) interest rates. Any home is a liability, as has been pointed out in other answers; it costs money to live in, it costs money to keep in good shape, and it offers you no return unless you sell it for more than you have paid for it in total (in fact, as long as you have an outstanding mortgage, it actually costs you money to own, even when not considering things like property taxes, utilities etc.).

The only way to make a home an investment is to rent it out for more than it costs you in total to own, but then you can't live in it instead.


  2) How should one view payments on a home mortgage? How are they similar or different to investing in low-risk low-reward investments?


Like JoeTaxpayer said in a comment, paying off your mortgage should be considered the same as putting money into a certificate of deposit with a term and return equivalent to your mortgage interest cost (adjusting for tax effects). What is important to remember about paying off a mortgage, besides the simple and not so unimportant fact that it lowers your financial risk over time, is that over time it improves your cash flow.

If interest rates don't change (unlikely), then as long as you keep paying the interest vigilantly but don't pay down the principal (assuming that the bank is happy with such an arrangement), your monthly cost remains the same and will do so in perpetuity. You currently have a cash flow that enables you to pay down the principal on the loan, and are putting some fairly significant amount of money towards that end. Now, suppose that you were to lose your job, which means a significant cut in the household income. If this cut means that you can't afford paying down the mortgage at the same rate as before, you can always call the bank and tell them to stop the extra payments until you get your ducks back in the proverbial row. It's also possible, with a long history of paying on time and a loan significantly smaller than what the house would bring in in a sale, that you could renegotiate the loan with an extended term, which depending on the exact terms may lower your monthly cost further. If the size of the loan is largely the same as or perhaps even exceeds the market value of the house, the bank would be a lot more unlikely to cooperate in such a scenario.

It's also a good idea to at the very least aim to be free of debt by the time you retire. Even if one assumes that the pension systems will be the same by then as they are now (some don't, but that's a completely different question), you are likely to see a significant cut in cash flow on retirement day. Any fixed expenses which cannot easily be cut if needed are going to become a lot more of a liability when you are actually at least in part living off your savings rather than contributing to them.

The earlier you get the mortgage paid off, the earlier you will have the freedom to put into other forms of savings the money which is now going not just to principal but to interest as well. What is important to consider is that paying off a mortgage is a very illiquid form of savings; on the other hand, money in stocks, bonds, various mutual funds, and savings accounts, tends to be highly liquid. It is always a good idea to have some savings in easily accessible form, some of it in very low-risk investments such as a simple interest-bearing savings account or government bonds (despite their low rate of return) before you start to aggressively pay down loans, because (particularly when you own a home) you never know when something might come up that ends up costing a fair chunk of money.
",Michael Kjörling,https://money.stackexchange.com/users/3546,http://money.stackexchange.com/questions/16077/how-does-owning-a-home-and-paying-on-a-mortgage-fit-into-family-savings-and-inve,LIFE_ARTS,money.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,0.0,1.0,1.0,0.8333333333333334,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,1.0,0.0,0.6666666666666666,0.7777777777777778,0.7777777777777778,1.0,1.0,0.5333333333333333,0.0,0.0,1.0,0.4444444444444444,How does owning a house and paying for a mortgage fit with household savings and investment?,"I'm in my mid-20's, and so I am aiming at long-term growth with higher risk in my portfolio.  My financial adviser is showing me some investment allocations that put my money in some growth, mid, and value-retention locations.  He doesn't seem to be taking into the equation the fact that I am putting a huge percentage of my paycheck into my home.

I know home values fluctuate, but long term, it seems to be a pretty good way to at least retain value, and at best make a small return.  If I am already contributing so much to my ""home"" investment, why would I also invest in stocks or bonds with a low rate of return, even though they are considered a ""safe"" part of my portfolio?

Update: I think the question really has two parts.

1) How does owning a home fit into my financial portfolio?  Most seem to agree that at best it is a hedge against rent or dollar inflation, and at worst it should be viewed as a liability, and has no place alongside other real investments.

2) How should one view payments on a home mortgage?  How are they similar or different to investing in low-risk low-reward investments?
","
  1) How does owning a home fit into my financial portfolio? Most seem to agree that at best it is a hedge against rent or dollar inflation, and at worst it should be viewed as a liability, and has no place alongside other real investments.


Periods of high inflation are generally accompanied with high(er) interest rates. Any home is a liability, as has been pointed out in other answers; it costs money to live in, it costs money to keep in good shape, and it offers you no return unless you sell it for more than you have paid for it in total (in fact, as long as you have an outstanding mortgage, it actually costs you money to own, even when not considering things like property taxes, utilities etc.).

The only way to make a home an investment is to rent it out for more than it costs you in total to own, but then you can't live in it instead.


  2) How should one view payments on a home mortgage? How are they similar or different to investing in low-risk low-reward investments?


Like JoeTaxpayer said in a comment, paying off your mortgage should be considered the same as putting money into a certificate of deposit with a term and return equivalent to your mortgage interest cost (adjusting for tax effects). What is important to remember about paying off a mortgage, besides the simple and not so unimportant fact that it lowers your financial risk over time, is that over time it improves your cash flow.

If interest rates don't change (unlikely), then as long as you keep paying the interest vigilantly but don't pay down the principal (assuming that the bank is happy with such an arrangement), your monthly cost remains the same and will do so in perpetuity. You currently have a cash flow that enables you to pay down the principal on the loan, and are putting some fairly significant amount of money towards that end. Now, suppose that you were to lose your job, which means a significant cut in the household income. If this cut means that you can't afford paying down the mortgage at the same rate as before, you can always call the bank and tell them to stop the extra payments until you get your ducks back in the proverbial row. It's also possible, with a long history of paying on time and a loan significantly smaller than what the house would bring in in a sale, that you could renegotiate the loan with an extended term, which depending on the exact terms may lower your monthly cost further. If the size of the loan is largely the same as or perhaps even exceeds the market value of the house, the bank would be a lot more unlikely to cooperate in such a scenario.

It's also a good idea to at the very least aim to be free of debt by the time you retire. Even if one assumes that the pension systems will be the same by then as they are now (some don't, but that's a completely different question), you are likely to see a significant cut in cash flow on retirement day. Any fixed expenses which cannot easily be cut if needed are going to become a lot more of a liability when you are actually at least in part living off your savings rather than contributing to them.

The earlier you get the mortgage paid off, the earlier you will have the freedom to put into other forms of savings the money which is now going not just to principal but to interest as well. What is important to consider is that paying off a mortgage is a very illiquid form of savings; on the other hand, money in stocks, bonds, various mutual funds, and savings accounts, tends to be highly liquid. It is always a good idea to have some savings in easily accessible form, some of it in very low-risk investments such as a simple interest-bearing savings account or government bonds (despite their low rate of return) before you start to aggressively pay down loans, because (particularly when you own a home) you never know when something might come up that ends up costing a fair chunk of money.
"
3451,3451,5492,Where does the Bible say to read itself?,"It seems rather basic, but I'm having trouble finding verses that say to read God's Word often. It seems like something that Paul said quite a few times, and it's obviously a good thing, but I can't find any specific verses. Can someone help me?
",Ullallulloo,https://christianity.stackexchange.com/users/103,"Study to show thyself approved to God, a worker who needed not be ashamed. Rightly divided the word of truth. 

II Timothy 2:15
",user21444,https://christianity.stackexchange.com/users/21444,http://christianity.stackexchange.com/questions/5520/where-does-the-bible-say-to-read-itself,CULTURE,christianity.stackexchange.com,1.0,1.0,0.0,1.0,1.0,1.0,0.6666666666666666,0.7777777777777778,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,0.8888888888888888,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,0.0,0.8888888888888888,Where does the Bible say to read?,"It seems to be very basic, but I find it hard to find scriptures that read God's word often. Paul seems to have said it many times, which is obviously a good thing, but I can't find the specific verse. Can someone help me?","Study to show thyself approved to God, a worker who needed not be ashamed. Rightly divided the word of truth. 

II Timothy 2:15
"
5310,5310,8433,"Difference in ""capable"" and ""able""","What is the difference in being physically capable and physically able?

When would one choose one over the other?
",Homer,https://english.stackexchange.com/users/21117,"Capable is more of a mentality. Able is more of a physical idea. You can be mentally capable of describing the object in front of you; you can be able to lift the 100 lb weights. However, the words are nearly interchangeable anywhere. Even in the examples I gave, the other fits, but one seems more appropriate than the other commonly.
",Alex,https://english.stackexchange.com/users/116855,http://english.stackexchange.com/questions/75010/difference-in-capable-and-able,CULTURE,english.stackexchange.com,0.7777777777777778,0.8888888888888888,0.0,1.0,1.0,1.0,0.5555555555555556,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.6666666666666666,0.0,0.6666666666666666,0.0,0.0,0.0,0.3333333333333333,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,0.8888888888888888,0.8888888888888888,0.9,0.0,0.0,0.3333333333333333,0.8888888888888888,"The difference between ""capable"" and ""capable""",What's the difference between physical strength and physical strength?,"To be able is more of a mentality. Ability is more of a physical concept. You can mentally describe the object in front of you; you can lift 100 pounds. However, these words can be interchanged almost anywhere. Even in the examples I give, there are other fits, but one seems to fit better than the other."
2175,2175,3467,How to change all the blue colors of RWD theme to another color?,"How to change all the blue colors of RWD theme to another color?Actually this question may be duplicate but please help me none of the methods worked for me in Google or in MSE.
",dhoni7,https://magento.stackexchange.com/users/16373,"To do it properly, you should have compass &amp; sass installed, navigate to the sass folder with your terminal (skin/frontend/rwd/default/scss), run 

compass watch . 


and then edit _var.scss and change the value for the $c-blue variable.

Upon save, compass will regenerate the complete css files.
",tecjam,https://magento.stackexchange.com/users/5769,http://magento.stackexchange.com/questions/44440/how-to-change-all-the-blue-colors-of-rwd-theme-to-another-color,TECHNOLOGY,magento.stackexchange.com,1.0,1.0,0.0,0.0,1.0,1.0,0.6666666666666666,0.8333333333333334,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,0.8333333333333334,0.8,1.0,0.0,0.0,1.0,How do I change all the blue of RWD themes to another color?,"How do I change all the blue of RWD themes to another color? In fact, this problem may be repetitive, but please help me no way to work for me in Google or small and medium enterprises.","To do it properly, you should have compass &amp; sass installed, navigate to the sass folder with your terminal (skin/frontend/rwd/default/scss), run 

compass watch . 


and then edit _var.scss and change the value for the $c-blue variable.

Upon save, compass will regenerate the complete css files.
"
4991,4991,7946,Return value in bash script,"I am working with a bash script and I want to execute a function to print a return value:

function fun1(){
  return 34
}
function fun2(){
  local res=$(fun1)
  echo $res
}


when I execute func2 it does not print ""34"". Can anybody help me?
",mindia,https://stackoverflow.com/users/2496202,"Functions in Bash are not functions like in other language; they're actually commands. So functions are used as if they were binaries or scripts fetched from your path.  From the perspective of your program logic there should be really no difference. 

Shell commands are connected by pipes (aka streams), and not fundamental or user-defined data types, as in ""real"" programming languages. There is no such thing like a return value for a command, maybe mostly because there's no real way to declare it. It could occur on the man-page, or the --help output of the command, but both are only human-readable and hence are written to the wind. 

When a command wants to get input it reads it from its input stream, or the argument list. In both cases text strings have to be parsed.

When a command wants to return something it has to echo it to its output stream. Another oftenly practiced way is to store the return value in dedicated, global variables. Writing to the output stream is clearer and more flexible, because it can take also binary data. For example, you can return a BLOB easily:

encrypt() {
    gpg -c -o- $1 # encrypt data in filename to stdout (asks for a passphrase)
}

encrypt public.dat &gt; private.dat # write function result to file


As others have written in this thread, the caller can also use command substitution $() to capture the output.

Parallely, the function would ""return"" the exit code of gpg (GnuPG). Think of the exit code as a bonus that other languages don't have, or, depending on your temperament, as a ""Schmutzeffekt"" of shell functions. This status is, by convention, 0 on success or an integer in the range 1-255 for something else. To make this clear: return (like exit) can only take a value from 0-255, and values other than 0 are not necessarily errors, as is often asserted.

When you don't provide an explicit value with return the status is taken from the last command in a Bash statement/function/command and so forth. So there is always a status, and return is just an easy way to provide it.
",Andreas Spindler,https://stackoverflow.com/users/887771,http://stackoverflow.com/questions/17336915/return-value-in-bash-script,STACKOVERFLOW,stackoverflow.com,1.0,0.3333333333333333,0.0,1.0,1.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.5,0.0,0.8333333333333334,1.0,0.8333333333333334,1.0,1.0,1.0,0.5,0.5,1.0,1.0,Return value in Bash script,"I am working with a bash script and I want to execute a function to print a return value:

function fun1(){
  return 34
}
function fun2(){
  local res=$(fun1)
  echo $res
}


when I execute func2 it does not print ""34"". Can anybody help me?
","Functions in Bash are not functions like in other language; they're actually commands. So functions are used as if they were binaries or scripts fetched from your path.  From the perspective of your program logic there should be really no difference. 

Shell commands are connected by pipes (aka streams), and not fundamental or user-defined data types, as in ""real"" programming languages. There is no such thing like a return value for a command, maybe mostly because there's no real way to declare it. It could occur on the man-page, or the --help output of the command, but both are only human-readable and hence are written to the wind. 

When a command wants to get input it reads it from its input stream, or the argument list. In both cases text strings have to be parsed.

When a command wants to return something it has to echo it to its output stream. Another oftenly practiced way is to store the return value in dedicated, global variables. Writing to the output stream is clearer and more flexible, because it can take also binary data. For example, you can return a BLOB easily:

encrypt() {
    gpg -c -o- $1 # encrypt data in filename to stdout (asks for a passphrase)
}

encrypt public.dat &gt; private.dat # write function result to file


As others have written in this thread, the caller can also use command substitution $() to capture the output.

Parallely, the function would ""return"" the exit code of gpg (GnuPG). Think of the exit code as a bonus that other languages don't have, or, depending on your temperament, as a ""Schmutzeffekt"" of shell functions. This status is, by convention, 0 on success or an integer in the range 1-255 for something else. To make this clear: return (like exit) can only take a value from 0-255, and values other than 0 are not necessarily errors, as is often asserted.

When you don't provide an explicit value with return the status is taken from the last command in a Bash statement/function/command and so forth. So there is always a status, and return is just an easy way to provide it.
"
5865,5865,9285,Why ducklings are yellow?,"Why ducklings are yellow, what the evolutionary background for this? How could it help to survive?

UPDATE 

I agree with comment below,
I did remember then that ducks are wild animals too (when I asked the question I imagined domesticated ducklings as widely pictured in media), but anyway it is interesting to know why the domesticated ducklings are yellow now. What is the reason of selection drove such coloration to young ducks or yellow pigment is just a side effect?
",rook,https://biology.stackexchange.com/users/4123,"It doesn't need to help it survive, evolution has no intent and not all traits are advantageous. It might just be random, genetic drift or something, a bottleneck effect, any of these things.

In the wild the yellow ones will hardly live long enough to reproduce though.
",Dan Horvat,https://biology.stackexchange.com/users/6003,http://biology.stackexchange.com/questions/10008/why-ducklings-are-yellow,SCIENCE,biology.stackexchange.com,1.0,1.0,0.0,0.5,1.0,1.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.7777777777777778,0.7777777777777778,0.5555555555555556,0.7777777777777778,1.0,0.6666666666666667,0.0,0.0,1.0,0.8888888888888888,Why is the duckling yellow?,"Why ducklings are yellow, what the evolutionary background for this? How could it help to survive?

UPDATE 

I agree with comment below,
I did remember then that ducks are wild animals too (when I asked the question I imagined domesticated ducklings as widely pictured in media), but anyway it is interesting to know why the domesticated ducklings are yellow now. What is the reason of selection drove such coloration to young ducks or yellow pigment is just a side effect?
","It doesn't need to help it survive, evolution has no intention, and not all features are favorable. It could just be random, gene drift or something, bottleneck effect, anything."
3334,3334,5323,EE control panel dashboard search field,"the search field in EE's dashboard doesn't seem to find anything. what is this field supposed to search?
",P..,https://expressionengine.stackexchange.com/users/1962,"It searches for (some) settings in the control panel. So you could search for file, and you should get a result/link to the file manager. Similarly, searches for category, channel, username should all return results with links to the respective areas of the CP.

However, the search results aren't consistent. Search for security and you don't get any results, yet a search for session gives a result for the Security and Session Preferences.

I'd say its there for someone who has limited knowledge of EE general options and wants to access some of the preferences, but can't find them.

Not entirely useful though!
",Andrew Armitage,https://expressionengine.stackexchange.com/users/1287,http://expressionengine.stackexchange.com/questions/21510/ee-control-panel-dashboard-search-field,TECHNOLOGY,expressionengine.stackexchange.com,1.0,0.4444444444444444,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,0.8888888888888888,EE control panel search fields,The search field in the EE dashboard does not appear to find anything. What should this field search for?,"It searches for (some) settings in the control panel. So you could search for file, and you should get a result/link to the file manager. Similarly, searches for category, channel, username should all return results with links to the respective areas of the CP.

However, the search results aren't consistent. Search for security and you don't get any results, yet a search for session gives a result for the Security and Session Preferences.

I'd say its there for someone who has limited knowledge of EE general options and wants to access some of the preferences, but can't find them.

Not entirely useful though!
"
6065,6065,9624,My.Computer.FileSystem.DeleteDirectory() with read only files?,"I recently came across a problem with My.Computer.FileSystem.DeleteDirectory(). It will not delete read only files.

I found out by Googling that I could delete the read only files by changing the file attributes to 'Normal'. So I wrote a recursive function, as below.

Private Sub DeleteDir(ByVal dir As DirectoryInfo)

    For Each d In dir.GetDirectories
        DeleteDir(d)
    Next
    For Each f In dir.GetFiles
        Try
            f.Attributes = FileAttributes.Normal
            f.Delete()
        Catch ex As Exception
            Log(ex.Message)
        End Try
    Next
    dir.Delete(True)
End Sub


It seems to work fine, but it would be nice if My.Computer.FileSystem.DeleteDirectory() had another parameter to delete read only files, or there was an easier way to do this.
",Rots,https://stackoverflow.com/users/455770,"My understanding is that the classes in the My namespace are partly meant as a crutch to new developers (possibly with a VB6 background) that finds the .Net framework a bit overwhelming. If they made the My namespace too big, I think it would defeat that purpose of being easier to find things in. I would also assume that they probably had limited resources to build that namespace and had to be quite selective.

The solution is for you to do as you've done and write your own method, which you could then put in a class library or similar together with other helpful helper functions that you can then easily include in all your projects.

Btw, remember that dir.Delete(True) can throw exceptions as well.
",Hans Olsson,https://stackoverflow.com/users/306651,http://stackoverflow.com/questions/3775471/my-computer-filesystem-deletedirectory-with-read-only-files,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.6666666666666666,0.0,0.5,1.0,1.0,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8666666666666666,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.8888888888888888,Does my. Computer. Filesystem. Deletedirectory() contain read-only files?,"I recently came across a problem with My.Computer.FileSystem.DeleteDirectory(). It will not delete read only files.

I found out by Googling that I could delete the read only files by changing the file attributes to 'Normal'. So I wrote a recursive function, as below.

Private Sub DeleteDir(ByVal dir As DirectoryInfo)

    For Each d In dir.GetDirectories
        DeleteDir(d)
    Next
    For Each f In dir.GetFiles
        Try
            f.Attributes = FileAttributes.Normal
            f.Delete()
        Catch ex As Exception
            Log(ex.Message)
        End Try
    Next
    dir.Delete(True)
End Sub


It seems to work fine, but it would be nice if My.Computer.FileSystem.DeleteDirectory() had another parameter to delete read only files, or there was an easier way to do this.
","My understanding is that the classes in my namespace are to some extent the backbone of new developers (who may have VB6 backgrounds) who find the. Net framework a little bit overwhelming. If they set ""My namespace"" too large, I think it will frustrate the purpose of finding content more easily. I also assume that they may have limited resources to build this namespace, and that they must be very selective."
5122,5122,8144,Android- R.java file not found,"While working with an android project .I'm stuck with R.java file which is not found even I clean the project(project---->clean).But that file still not found .Even I create a new project the same problem occurs .
what I need to do ? I'm expecting the valuable replies from which I could overcome this problem 
",Rakesh L,https://stackoverflow.com/users/1870586,"Have you checked that your builders are set up correct? To have the R.java file generated there's a need that the Android Pre-Compiler has processed all the resources. 

In Eclipse go to ""Project --> Properties"" and select ""Builders"" from the list. 



Only if these builders are set, the R file can be generated.
",GeneSys,https://stackoverflow.com/users/172525,http://stackoverflow.com/questions/15201166/android-r-java-file-not-found,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.4444444444444444,0.0,0.0,1.0,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.5555555555555556,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.9,0.6666666666666666,0.3333333333333333,1.0,0.8888888888888888,Android-r.java file not found,"When dealing with an Android project, I am stuck by the r.java file. Even if I clean the project (Project -- > clean), I can't find the file. Even if I create a new project, the same problem will occur.","Have you checked that your builders are set up correct? To have the R.java file generated there's a need that the Android Pre-Compiler has processed all the resources. 

In Eclipse go to ""Project --> Properties"" and select ""Builders"" from the list. 



Only if these builders are set, the R file can be generated.
"
2752,2752,4386,Convert linked html files into a pdf file?,"I would like to convert an online book (linked html files) into a pdf file.

I tried the two-step way in http://kmkeen.com/mirror/2009-02-05-14-00-00.html


First, download the html files by

wget -nd -mk http://www.unknownroad.com/rtfm/gdbtut/


But it has downloaded a lot of nonrelated files. So I have to remove
the unrelated files.
Then, I try to convert the downloaded html book into a pdf file:

htmldoc --webpage -f gdb.pdf html/index.html html/*.html


but the order of pages in the pdf file isn't correct.


I wonder what good way to download and convert an online book (linked html files) into a pdf file?

My OS is Ubuntu 12.04.
",Tim,https://unix.stackexchange.com/users/674,"As mentioned in the instructions you linked:


  The default glob expansion puts the pages in alphabetical order.


The index page links to nine different documents, whose names aren't in alphabetical order. When you say htmldoc ... *.html, the tools sees them in that order and puts the pages into the document alphabetically. You need to list the files on the command line in the order you want htmldoc to process them.

In this specific case you can produce an ordered list of filenames as they're linked in the index with:

awk '/http:|\.\./ {next}; /&lt;a href.*\.html/ { gsub(/.*href=""/, """") ; gsub("".html.*"", "".html"") ; print }' index.html | uniq


so

htmldoc --webpage -f gdb.pdf index.html $(awk '/http:|\.\./ {next}; /&lt;a href.*\.html/ { gsub(/.*href=""/, """") ; gsub("".html.*"", "".html"") ; print }' index.html | uniq)


will have the effect you want.
",Michael Homer,https://unix.stackexchange.com/users/73093,http://unix.stackexchange.com/questions/151065/convert-linked-html-files-into-a-pdf-file,TECHNOLOGY,unix.stackexchange.com,1.0,0.7777777777777778,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.3333333333333333,0.3333333333333333,1.0,Do you want to convert the linked HTML file to a PDF file?,"I would like to convert an online book (linked html files) into a pdf file.

I tried the two-step way in http://kmkeen.com/mirror/2009-02-05-14-00-00.html


First, download the html files by

wget -nd -mk http://www.unknownroad.com/rtfm/gdbtut/


But it has downloaded a lot of nonrelated files. So I have to remove
the unrelated files.
Then, I try to convert the downloaded html book into a pdf file:

htmldoc --webpage -f gdb.pdf html/index.html html/*.html


but the order of pages in the pdf file isn't correct.


I wonder what good way to download and convert an online book (linked html files) into a pdf file?

My OS is Ubuntu 12.04.
","As mentioned in the instructions you linked:


  The default glob expansion puts the pages in alphabetical order.


The index page links to nine different documents, whose names aren't in alphabetical order. When you say htmldoc ... *.html, the tools sees them in that order and puts the pages into the document alphabetically. You need to list the files on the command line in the order you want htmldoc to process them.

In this specific case you can produce an ordered list of filenames as they're linked in the index with:

awk '/http:|\.\./ {next}; /&lt;a href.*\.html/ { gsub(/.*href=""/, """") ; gsub("".html.*"", "".html"") ; print }' index.html | uniq


so

htmldoc --webpage -f gdb.pdf index.html $(awk '/http:|\.\./ {next}; /&lt;a href.*\.html/ { gsub(/.*href=""/, """") ; gsub("".html.*"", "".html"") ; print }' index.html | uniq)


will have the effect you want.
"
1811,1811,2874,How can I speed up the rate at which putty dries?,"We're (slowly) renovating the sash windows in our house and the current window is causing problems. What should have been a quick job (especially at this time of year!) has turned into a marathon because the putty won't dry.

We had to replace a couple of panes of glass (one was cracked and we broke another when using a heat gun to remove the paint) so we knew it would take a little while. On a previous window the putty took over three weeks to dry enough to paint partly because (as we thought) there was too much oil. So this time we rolled the putty on newspaper first to try to remove the excess oil. It seemed to work, but after two weeks the putty is still soft to the touch.

We've tried standing the windows next to a radiator but all that seemed to do was make it softer (which was obviously going to happen in hindsight).

So given that we don't want to reputty the windows what can we do to speed up the drying process.

We've had to seal off the room and cover the window as best we can in the meantime.

I've found this advice on DoItYourself.com which doesn't really help as it says use other materials!

The answers to this post on DIY-Forums are confusing at best and possibly contradictory as one recommends exposing the putty to moisture(!) to speed the drying process.
",ChrisF,https://diy.stackexchange.com/users/194,"Wipe down the putty with mineral spirits, this should remove some of the oils and help it cure faster.
",Tester101,https://diy.stackexchange.com/users/33,http://diy.stackexchange.com/questions/3022/how-can-i-speed-up-the-rate-at-which-putty-dries,LIFE_ARTS,diy.stackexchange.com,0.8888888888888888,0.8888888888888888,0.0,1.0,1.0,0.6666666666666666,0.4444444444444444,0.5555555555555556,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.6666666666666667,1.0,0.0,0.0,0.8888888888888888,How can I speed up the drying of putty?,"We're (slowly) renovating the sash windows in our house and the current window is causing problems. What should have been a quick job (especially at this time of year!) has turned into a marathon because the putty won't dry.

We had to replace a couple of panes of glass (one was cracked and we broke another when using a heat gun to remove the paint) so we knew it would take a little while. On a previous window the putty took over three weeks to dry enough to paint partly because (as we thought) there was too much oil. So this time we rolled the putty on newspaper first to try to remove the excess oil. It seemed to work, but after two weeks the putty is still soft to the touch.

We've tried standing the windows next to a radiator but all that seemed to do was make it softer (which was obviously going to happen in hindsight).

So given that we don't want to reputty the windows what can we do to speed up the drying process.

We've had to seal off the room and cover the window as best we can in the meantime.

I've found this advice on DoItYourself.com which doesn't really help as it says use other materials!

The answers to this post on DIY-Forums are confusing at best and possibly contradictory as one recommends exposing the putty to moisture(!) to speed the drying process.
","Wipe down the putty with mineral spirits, this should remove some of the oils and help it cure faster.
"
5768,5768,9139,jQueryUI Spinner widget with knockout,"How can I use a jQuery UI Spinner widget in Knockout bound input?

    &lt;tbody data-bind=""foreach: orders""&gt;
        &lt;tr&gt;
            &lt;td data-bind=""text: Name""&gt;&lt;/td&gt;
            &lt;td&gt;&lt;input type=""number"" style=""width: 100px;"" data-bind=""value: Price"" /&gt;&lt;/td&gt;
            &lt;td&gt;&lt;input type=""number"" style=""width: 50px;"" data-bind=""value: VAT"" /&gt;&lt;/td&gt;
            &lt;td&gt;&lt;input type=""number"" style=""width: 50px;"" data-bind=""value: Number"" /&gt;&lt;/td&gt;
            &lt;td data-bind=""text: Final()""&gt;&lt;/td&gt;
            &lt;td&gt;&lt;a href=""javascript:void(0);"" data-bind=""click: $root.removeOrder""&gt;Remove&lt;/a&gt;&lt;/td&gt;
        &lt;/tr&gt;    
    &lt;/tbody&gt;

",Omid Mafakher,https://stackoverflow.com/users/993369,"The answers on this page are correct and helpful. I found, however, that I was getting bad behaviour when someone was typing a value in the field. Each key press seems to fire a ""spinstop"" event too. Further, the keypresses were bypassing the field formatting and options.step. Fortunately we can examine the incoming event to see what's actually happening. There may be better ways but I thought I'd share anyway.

// Abstract to a function to allow for multiple binding types
function createSpinner(defaultOptions) {
    return {
        init: function (element, valueAccessor, allBindingsAccessor) {
            var options = $.extend(true, {}, allBindingsAccessor().spinnerOptions, defaultOptions);
            var widget = $(element);
            var observable = valueAccessor();

            widget.spinner(options);

            // handle field changes onblur [copies field -&gt; model]
            ko.utils.registerEventHandler(element, ""blur"", function (event) {
                var inputValue = Number(widget.spinner(""value""));
                var modelValue = observable();
                if (inputValue !== modelValue) {
                    // Set the widget (this forces formatting and rounding) - does not fire events
                    widget.spinner(""value"", inputValue);
                    // Read the value back out (saves us rounding)
                    var numberValue = Number(widget.spinner(""value""));
                    // Set the observable
                    observable(numberValue);
                }
            });

            // handle other field changes
            ko.utils.registerEventHandler(element, ""spinstop"", function (event) {
                // jQuery.spinner spinstop is a bit overzealous with its spinstop event.
                if (event.keyCode !== undefined) {
                    // If it has a keyCode someone is typing... so don't interfere
                } else if (event.originalEvent &amp;&amp; event.originalEvent.type === ""mouseup"") {
                    // This is an *actual* spinstop
                    var numberValue = Number(widget.spinner(""value""));
                    observable(numberValue);
                }
            });

            // handle disposal
            ko.utils.domNodeDisposal.addDisposeCallback(element, function () {
                widget.spinner(""destroy"");
            });
        },
        update: function (element, valueAccessor) {
            // [copies model -&gt; field]
            var widget = $(element);
            var observable = valueAccessor();
            var inputValue = Number(widget.spinner(""value""));
            var modelValue = observable();
            if (inputValue !== modelValue) {
                widget.spinner(""value"", modelValue);
            }
        }
    };
}
ko.bindingHandlers.moneyspin = createSpinner({ numberFormat: 'C0', culture: 'en-GB', min: 0, incremental: true });
ko.bindingHandlers.intspin = createSpinner({ numberFormat: 'n0', culture: 'en-GB' });

",Sam Strachan,https://stackoverflow.com/users/1229065,http://stackoverflow.com/questions/12929801/jqueryui-spinner-widget-with-knockout,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.4444444444444444,0.0,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,1.0,0.8333333333333334,0.6666666666666666,1.0,1.0,0.7,0.3333333333333333,0.3333333333333333,1.0,1.0,JQuery UI spinner widget with knockout,"How can I use a jQuery UI Spinner widget in Knockout bound input?

    &lt;tbody data-bind=""foreach: orders""&gt;
        &lt;tr&gt;
            &lt;td data-bind=""text: Name""&gt;&lt;/td&gt;
            &lt;td&gt;&lt;input type=""number"" style=""width: 100px;"" data-bind=""value: Price"" /&gt;&lt;/td&gt;
            &lt;td&gt;&lt;input type=""number"" style=""width: 50px;"" data-bind=""value: VAT"" /&gt;&lt;/td&gt;
            &lt;td&gt;&lt;input type=""number"" style=""width: 50px;"" data-bind=""value: Number"" /&gt;&lt;/td&gt;
            &lt;td data-bind=""text: Final()""&gt;&lt;/td&gt;
            &lt;td&gt;&lt;a href=""javascript:void(0);"" data-bind=""click: $root.removeOrder""&gt;Remove&lt;/a&gt;&lt;/td&gt;
        &lt;/tr&gt;    
    &lt;/tbody&gt;

","The answers on this page are correct and helpful. I found, however, that I was getting bad behaviour when someone was typing a value in the field. Each key press seems to fire a ""spinstop"" event too. Further, the keypresses were bypassing the field formatting and options.step. Fortunately we can examine the incoming event to see what's actually happening. There may be better ways but I thought I'd share anyway.

// Abstract to a function to allow for multiple binding types
function createSpinner(defaultOptions) {
    return {
        init: function (element, valueAccessor, allBindingsAccessor) {
            var options = $.extend(true, {}, allBindingsAccessor().spinnerOptions, defaultOptions);
            var widget = $(element);
            var observable = valueAccessor();

            widget.spinner(options);

            // handle field changes onblur [copies field -&gt; model]
            ko.utils.registerEventHandler(element, ""blur"", function (event) {
                var inputValue = Number(widget.spinner(""value""));
                var modelValue = observable();
                if (inputValue !== modelValue) {
                    // Set the widget (this forces formatting and rounding) - does not fire events
                    widget.spinner(""value"", inputValue);
                    // Read the value back out (saves us rounding)
                    var numberValue = Number(widget.spinner(""value""));
                    // Set the observable
                    observable(numberValue);
                }
            });

            // handle other field changes
            ko.utils.registerEventHandler(element, ""spinstop"", function (event) {
                // jQuery.spinner spinstop is a bit overzealous with its spinstop event.
                if (event.keyCode !== undefined) {
                    // If it has a keyCode someone is typing... so don't interfere
                } else if (event.originalEvent &amp;&amp; event.originalEvent.type === ""mouseup"") {
                    // This is an *actual* spinstop
                    var numberValue = Number(widget.spinner(""value""));
                    observable(numberValue);
                }
            });

            // handle disposal
            ko.utils.domNodeDisposal.addDisposeCallback(element, function () {
                widget.spinner(""destroy"");
            });
        },
        update: function (element, valueAccessor) {
            // [copies model -&gt; field]
            var widget = $(element);
            var observable = valueAccessor();
            var inputValue = Number(widget.spinner(""value""));
            var modelValue = observable();
            if (inputValue !== modelValue) {
                widget.spinner(""value"", modelValue);
            }
        }
    };
}
ko.bindingHandlers.moneyspin = createSpinner({ numberFormat: 'C0', culture: 'en-GB', min: 0, incremental: true });
ko.bindingHandlers.intspin = createSpinner({ numberFormat: 'n0', culture: 'en-GB' });

"
5893,5893,9334,How to work with large projects,"I am working on a project and i want to slim it down a litle so please help me with the
following. I have a document structure like this:

/DocumentRoot
 |-main.tex
 |-title.tex
 |
 |-/chapter-1
 |  |-/images
 |  |-chapter-1.tex
 |
 |-/chapter-2
    |-/images
    |-chapter-2.tex


My document is like this:

\begin{document}
\include{./title}
\include{./chapter-1/chapter-1}
\include{./chapter-2/chapter-2}
\include{./chapter-3/chapter-3}
\end{document}


in my chapters i use both some images and some heavy tikz plots so i use externalize and 
draft options for quicker compilation. But i want the images to be placed in the respective
chapter folders but for example in chapter 3 this works:

\includegraphics[width=\linewidth]{./chapter-3/images/img.jpg}


and this doesn't

\includegraphics[width=\linewidth]{./images/img.jpg}


for some reason xelatex has problems with the relative paths of included chapters. I also want to control the location output and the naming of the externalized tikz documents. Any help with that? I am working with miktex and texworks.
",msmechanized,https://tex.stackexchange.com/users/16233,"The idea is simple, just prepare directory paths (to import both chapter files and images files) whenever you include a new chapter.

Main.tex

\documentclass{book}
\usepackage{graphicx}

\def\Include#1{%
        \def\ChapterPath{#1/}%
        \def\GraphicsPath{\ChapterPath Images/}%
        \include{\ChapterPath#1}}

\newcommand\IncludeGraphics[2][width=\linewidth]{%
    \includegraphics[#1]{\GraphicsPath #2}}    

\begin{document}
    \Include{Chapter-1}
\end{document}


Chapter-1.tex

\chapter{Chapter One}


\IncludeGraphics[width=0.5\linewidth]{Tulips}


Remarks:


Folder Chapter-1 is in Docoment-Root folder.
Chapter-1.tex is in folder Chapter-1. 
Tulips.jpg is in  folder Chapter-1/Images. 


Tips


If your TikZ code is not ""linked"" to the text with nodes, for example, then put such TikZ code into a separate, compilable input file. Use article document class plus preview to get a tight PDF output. You can also use standalone document class instead.
If you table is not long enough to span across multiple pages, then put it into a separate, compilable input file to get a tight PDF output.
It is better not to specify the image extension explicitly when invoking \includegraphics. 
Define macros for often-used materials and put them into a package such that you can change their definition later in one place and the changes effect the whole document.

",kiss my armpit,https://tex.stackexchange.com/users/19356,http://tex.stackexchange.com/questions/64199/how-to-work-with-large-projects,TECHNOLOGY,tex.stackexchange.com,1.0,0.3333333333333333,0.0,0.5,1.0,0.5,0.4444444444444444,0.5555555555555556,0.6666666666666666,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.6666666666666666,0.0,0.8888888888888888,How to deal with large projects,"I am working on a project and i want to slim it down a litle so please help me with the
following. I have a document structure like this:

/DocumentRoot
 |-main.tex
 |-title.tex
 |
 |-/chapter-1
 |  |-/images
 |  |-chapter-1.tex
 |
 |-/chapter-2
    |-/images
    |-chapter-2.tex


My document is like this:

\begin{document}
\include{./title}
\include{./chapter-1/chapter-1}
\include{./chapter-2/chapter-2}
\include{./chapter-3/chapter-3}
\end{document}


in my chapters i use both some images and some heavy tikz plots so i use externalize and 
draft options for quicker compilation. But i want the images to be placed in the respective
chapter folders but for example in chapter 3 this works:

\includegraphics[width=\linewidth]{./chapter-3/images/img.jpg}


and this doesn't

\includegraphics[width=\linewidth]{./images/img.jpg}


for some reason xelatex has problems with the relative paths of included chapters. I also want to control the location output and the naming of the externalized tikz documents. Any help with that? I am working with miktex and texworks.
","The idea is simple, just prepare directory paths (to import both chapter files and images files) whenever you include a new chapter.

Main.tex

\documentclass{book}
\usepackage{graphicx}

\def\Include#1{%
        \def\ChapterPath{#1/}%
        \def\GraphicsPath{\ChapterPath Images/}%
        \include{\ChapterPath#1}}

\newcommand\IncludeGraphics[2][width=\linewidth]{%
    \includegraphics[#1]{\GraphicsPath #2}}    

\begin{document}
    \Include{Chapter-1}
\end{document}


Chapter-1.tex

\chapter{Chapter One}


\IncludeGraphics[width=0.5\linewidth]{Tulips}


Remarks:


Folder Chapter-1 is in Docoment-Root folder.
Chapter-1.tex is in folder Chapter-1. 
Tulips.jpg is in  folder Chapter-1/Images. 


Tips


If your TikZ code is not ""linked"" to the text with nodes, for example, then put such TikZ code into a separate, compilable input file. Use article document class plus preview to get a tight PDF output. You can also use standalone document class instead.
If you table is not long enough to span across multiple pages, then put it into a separate, compilable input file to get a tight PDF output.
It is better not to specify the image extension explicitly when invoking \includegraphics. 
Define macros for often-used materials and put them into a package such that you can change their definition later in one place and the changes effect the whole document.

"
4876,4876,7761,what is exactly the difference between the Selberg class and the set of Artin L-functions?,"The question is in the title: from what I read in the answer to another question, Artin L-functions are conjecturally cuspidal automorphic L-functions for some algebraic group that can be transfered to $GL_{n}$. On the other hand, elements of the Selberg class are widely believed to be (cuspidal?) automorphic L-functions for $GL_{n}$. So where exactly lies the difference between those two sets of L-functions?
Thanks in advance.
",Sylvain JULIEN,https://mathoverflow.net/users/13625,"We talk about three rather different but not unrelated conjectures here:

(1) Artin $L$-functions are automorphic $L$-functions;

(2) automorphic $L$-functions belong to the Selberg class;

(3) the Selberg class consists of automorphic $L$-functions.

The three families of $L$-functions occurring here are defined very differently. Artin $L$-functions are defined in terms of Galois representations, automorphic $L$-functions are defined in terms of automorphic representations, while the Selberg class is defined via natural axioms of an analytic nature. Conjectures (1) and (2) are instances of the Langlands conjectures, while (3) strengthens the idea that sufficiently nice analytic properties of a Dirichlet series are always ""caused by"" an automorphic form (or automorphic representation) behind the Dirichlet series.
",GH from MO,https://mathoverflow.net/users/11919,http://mathoverflow.net/questions/207306,SCIENCE,mathoverflow.net,1.0,0.7777777777777778,0.0,0.5,1.0,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,0.3333333333333333,1.0,What is the difference between Selberg class and Artin L-function set?,"Question in the title: according to what I read in the answer to another question, Artin L-functions are some creepy self-sustaining L-functions of algebraic groups that can be transferred to $GL {n} $. On the other hand, it is generally believed that Selberg elements are (creepy?) The automorphic L-function of $GL {n} $. So what's the difference between these two sets of L-functions?","We talk about three rather different but not unrelated conjectures here:

(1) Artin $L$-functions are automorphic $L$-functions;

(2) automorphic $L$-functions belong to the Selberg class;

(3) the Selberg class consists of automorphic $L$-functions.

The three families of $L$-functions occurring here are defined very differently. Artin $L$-functions are defined in terms of Galois representations, automorphic $L$-functions are defined in terms of automorphic representations, while the Selberg class is defined via natural axioms of an analytic nature. Conjectures (1) and (2) are instances of the Langlands conjectures, while (3) strengthens the idea that sufficiently nice analytic properties of a Dirichlet series are always ""caused by"" an automorphic form (or automorphic representation) behind the Dirichlet series.
"
2304,2304,3670,Finding out which version PHP a remote server is running,"I can't imagine this is possible but maybe there's some novel way. I'm developing an app which will require a few php files to be deployed and run on the clients' webservers. I'm not particularly interested in targeting clients who are still running pre version 5 versions of PHP.

So is there any way one can tell which version of PHP a remote webserver has running?
",jontyc,https://serverfault.com/users/77339,"In fiddler, go to the compose tab and type in the web address and send a GET request. Then when the response pops up in the left window, double click on it. On the right side it'll showt he request and response details. In the response details (bottom right), click the RAW or HEADERS tab and take a look at the headers. The server info will be next to the Server: header
",Sinaesthetic,https://serverfault.com/users/168961,http://serverfault.com/questions/268096,TECHNOLOGY,serverfault.com,1.0,0.8333333333333334,0.0,1.0,1.0,1.0,0.5,0.5,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9,1.0,0.0,0.0,1.0,Find out which version of PHP the remote server is running,"I can't imagine it is possible, but there may be some novel ways. I am developing an application that needs to deploy and run some PHP files on the client's web server. I'm not particularly interested in target customers who are still running pre version 5 of PHP.","In fiddler, go to the compose tab and type in the web address and send a GET request. Then when the response pops up in the left window, double click on it. On the right side it'll showt he request and response details. In the response details (bottom right), click the RAW or HEADERS tab and take a look at the headers. The server info will be next to the Server: header
"
1884,1884,2995,Kyoto Cabinet / Berkeley DB : Hash table size limitations,"I am having a hard time storing hundreds of millions of key/value pairs of 16/32bytes with a hash array on my SSD.

With Kyoto Cabinet: When it works fine, it inserts at 70000 record/s. Once it drops, it goes down to 10-500 records/s. With the default settings, the drop happens after around a million records. Looking at the documentation, that is the default number of buckets in the array, so it makes sense. I increased this number to 25 millions and indeed, it works fine until around 25 millions records. Problem is, as soon as I push the number of buckets to 30 millions or over, the insert rate is down to 10-500 records/s from the beginning. Kyoto Cabinet is not designed to increase the number of bucket after the database is created, so I cannot insert more than 25 millions records.

1/ Why would KC's insert rate get very low once the bucket number exceeds 25M ?

With Berkeley DB: The best speed I got is slightly lower than KC, closer to 50000 record/s, but still ok. With the default settings, just like KC, the speed drops suddenly after around a million records. I know BDB is designed to extend gradually its number of buckets. Regardless of that, It tried to increase the initial number, playing with HashNumElements and FillFactor, but any of these attempts made the situation worst. So I still cannot insert over 1-2 millions records with DBD. I tried activating non-synchronized transactions, tried different rates of checkpoints, increased caches. Nothing improves the drop down.

2/ What could cause BDB's insert rate to drop after 1-2 million inserts ?

Note: I'm working with java, and when the speed is dropping, the CPU usage lowers to 0-30% while at 100% when working at correct speed.
Note: Stopping the process and resuming the insertion changes nothing. So I don't think that is related to memory limits or garbage collection.

Thx.
",Kai Elvin,https://stackoverflow.com/users/1767126,"Below is how I managed to store billions of records despite the writing limitations encountered with KC.

With much effort, I still haven't solved the problem for neither Kyoto Cabinet nor Berkeley DB. However I came up with an interesting workaround using Kyoto Cabinet.

I noticed I cannot write more than 25M records on one KC file, but read has no such limitation −it is always fast, regardless of the size of the database. The solution I found is to create a new KC file (a new database) for every 25M new records. That way the reading happens on many KC files and is still fast, and the writing happens only on the last created file and is fast as well. Only remaining problem was to allow update/deletion of the records on the previous files. For that, I copied the SSTables approach, which is :


All the 0 to N-1 files are read-only, file N is read+write.
Any insert/update/deletion is written in file N.
Reads look into files N to 0, and return the first-seen/last-written insertion/update/deletion.
A bloom filter is attached to each file to avoid accessing a file that doesn't have the wanted record.
As soon as file N reaches 25M records, it becomes read-only and file N+1 is created.


Notes :


Just like with SSTables, If a lot of updates/deletions are performed, we might want to perform compaction. However contrary to SSTables, compaction here doesn't require to rewrite the file. Outdated records are simply removed from the KC files, and if a KC file gets very small, it can be either removed −reinserting the records in file N− or reopenned for new insertions −provided the next files are compact.
A deletion does not delete the record, but write a special value that identifies the record as deleted. During compaction, deleted records are removed for real.
Checking if a record exists usually requires to look into the database. Thanks to the bloom filters, most of the negative answers can be given without any disk access.

",Kai Elvin,https://stackoverflow.com/users/1767126,http://stackoverflow.com/questions/13054852/kyoto-cabinet-berkeley-db-hash-table-size-limitations,STACKOVERFLOW,stackoverflow.com,0.6666666666666666,0.3333333333333333,0.0,1.0,0.6666666666666666,1.0,0.5555555555555556,0.3333333333333333,0.6666666666666666,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.4444444444444444,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8666666666666666,0.6666666666666666,0.0,1.0,1.0,Kyoto cabinet / Berkeley database: hash table size limit,"I am having a hard time storing hundreds of millions of key/value pairs of 16/32bytes with a hash array on my SSD.

With Kyoto Cabinet: When it works fine, it inserts at 70000 record/s. Once it drops, it goes down to 10-500 records/s. With the default settings, the drop happens after around a million records. Looking at the documentation, that is the default number of buckets in the array, so it makes sense. I increased this number to 25 millions and indeed, it works fine until around 25 millions records. Problem is, as soon as I push the number of buckets to 30 millions or over, the insert rate is down to 10-500 records/s from the beginning. Kyoto Cabinet is not designed to increase the number of bucket after the database is created, so I cannot insert more than 25 millions records.

1/ Why would KC's insert rate get very low once the bucket number exceeds 25M ?

With Berkeley DB: The best speed I got is slightly lower than KC, closer to 50000 record/s, but still ok. With the default settings, just like KC, the speed drops suddenly after around a million records. I know BDB is designed to extend gradually its number of buckets. Regardless of that, It tried to increase the initial number, playing with HashNumElements and FillFactor, but any of these attempts made the situation worst. So I still cannot insert over 1-2 millions records with DBD. I tried activating non-synchronized transactions, tried different rates of checkpoints, increased caches. Nothing improves the drop down.

2/ What could cause BDB's insert rate to drop after 1-2 million inserts ?

Note: I'm working with java, and when the speed is dropping, the CPU usage lowers to 0-30% while at 100% when working at correct speed.
Note: Stopping the process and resuming the insertion changes nothing. So I don't think that is related to memory limits or garbage collection.

Thx.
","Below is how I managed to store billions of records despite the writing limitations encountered with KC.

With much effort, I still haven't solved the problem for neither Kyoto Cabinet nor Berkeley DB. However I came up with an interesting workaround using Kyoto Cabinet.

I noticed I cannot write more than 25M records on one KC file, but read has no such limitation −it is always fast, regardless of the size of the database. The solution I found is to create a new KC file (a new database) for every 25M new records. That way the reading happens on many KC files and is still fast, and the writing happens only on the last created file and is fast as well. Only remaining problem was to allow update/deletion of the records on the previous files. For that, I copied the SSTables approach, which is :


All the 0 to N-1 files are read-only, file N is read+write.
Any insert/update/deletion is written in file N.
Reads look into files N to 0, and return the first-seen/last-written insertion/update/deletion.
A bloom filter is attached to each file to avoid accessing a file that doesn't have the wanted record.
As soon as file N reaches 25M records, it becomes read-only and file N+1 is created.


Notes :


Just like with SSTables, If a lot of updates/deletions are performed, we might want to perform compaction. However contrary to SSTables, compaction here doesn't require to rewrite the file. Outdated records are simply removed from the KC files, and if a KC file gets very small, it can be either removed −reinserting the records in file N− or reopenned for new insertions −provided the next files are compact.
A deletion does not delete the record, but write a special value that identifies the record as deleted. During compaction, deleted records are removed for real.
Checking if a record exists usually requires to look into the database. Thanks to the bloom filters, most of the negative answers can be given without any disk access.

"
5424,5424,8612,Apache won't allow multiple name-based virtual hosts,"Here's the problem I'm facing: I've added multiple virtual hosts(name based) to apache yet still only one is loaded.

For example I have two domains with different contents.
Site1 Domain -> Site1 Content 
Site2 Domain -> Site1 Content aswell..
I've included the httpd-vhosts file in the httpd config file, and I've edited it to match what it asks me to do on their documentation yet still only one folder of contents is served.

Here is my httpd-vhosts file, the httpd file I assume doesn't need posting but if required I shall:

NameVirtualHost *
&lt;Directory ""C:/www/""&gt;
    Options Indexes FollowSymLinks
    AllowOverride None
    Order allow,deny
    Allow from all

&lt;/Directory&gt;
&lt;VirtualHost *&gt;
    ServerName www.*****.com
    DocumentRoot ""C:\www*****""
&lt;/VirtualHost&gt;

&lt;VirtualHost *&gt;
    ServerName ****.co.cc
    DocumentRoot ""C:\www\****""
&lt;/VirtualHost&gt;


ofcourse I removed the unnecessary comments and my domains names(private reasons). Oh yeah, and my server is hosted on Windows Server 2008 Standard
",Harry,https://serverfault.com/users/81138,"
  For example I have two domains with
  different contents.
  
  Site1 Domain -> Site1 Content Site2
  Domain -> Site1 Content aswell..


So which is it? Different content or the same content for both domains?

If its the same content then the correct way is to use the serveralias option:

&lt;VirtualHost *&gt;
    ServerName www.firstdomain.com
serveralias firstdomain.com www.seconddomain.com seconddomain.com
    DocumentRoot ""C:\www*****""
&lt;/VirtualHost&gt;


Now you can serve the same content in the manner YOU were trying to do as well. You just have to set the correct document root for domain number 2. In your example the doc root contains a backslash that it shouldn't if the idea is to serve the same content as domain 1. 
",Abdussamad,https://serverfault.com/users/58522,http://serverfault.com/questions/268626,TECHNOLOGY,serverfault.com,0.6666666666666666,0.6666666666666666,0.0,0.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,1.0,1.0,Apache does not allow multiple name based virtual hosts,"Here's the problem I'm facing: I've added multiple virtual hosts(name based) to apache yet still only one is loaded.

For example I have two domains with different contents.
Site1 Domain -> Site1 Content 
Site2 Domain -> Site1 Content aswell..
I've included the httpd-vhosts file in the httpd config file, and I've edited it to match what it asks me to do on their documentation yet still only one folder of contents is served.

Here is my httpd-vhosts file, the httpd file I assume doesn't need posting but if required I shall:

NameVirtualHost *
&lt;Directory ""C:/www/""&gt;
    Options Indexes FollowSymLinks
    AllowOverride None
    Order allow,deny
    Allow from all

&lt;/Directory&gt;
&lt;VirtualHost *&gt;
    ServerName www.*****.com
    DocumentRoot ""C:\www*****""
&lt;/VirtualHost&gt;

&lt;VirtualHost *&gt;
    ServerName ****.co.cc
    DocumentRoot ""C:\www\****""
&lt;/VirtualHost&gt;


ofcourse I removed the unnecessary comments and my domains names(private reasons). Oh yeah, and my server is hosted on Windows Server 2008 Standard
","
  For example I have two domains with
  different contents.
  
  Site1 Domain -> Site1 Content Site2
  Domain -> Site1 Content aswell..


So which is it? Different content or the same content for both domains?

If its the same content then the correct way is to use the serveralias option:

&lt;VirtualHost *&gt;
    ServerName www.firstdomain.com
serveralias firstdomain.com www.seconddomain.com seconddomain.com
    DocumentRoot ""C:\www*****""
&lt;/VirtualHost&gt;


Now you can serve the same content in the manner YOU were trying to do as well. You just have to set the correct document root for domain number 2. In your example the doc root contains a backslash that it shouldn't if the idea is to serve the same content as domain 1. 
"
5760,5760,9128,What is the kernel doing when I bring a TUN/TAP interface up,"I'm playing around with the TUN/TAP device on Linux.
I've created a simple program that creates a TAP interface and prints anything that is sent through it.
When I bring the interface up with

ip link set tap1 up


six frames are sent through it. What are these frames?

I've pasted them here
",Shum,https://unix.stackexchange.com/users/7314,"OK, I can't get the packet imported into Wireshark (there must be some headers extra or missing, not bothering to figure that out) but, this is IPv6. From your first frame, you see ff 02 00 00 00 00 00 00 00 00 00 00 00 00 00 16. That's the IPv6 address ff02::16, used for MLDv2. 

Edit: from your first frame, here is the IPv6 part in a format Wireshark can understand when you select ""File->Import"" and pick Encapsulation type of Raw IP or Raw IPv6 (this starts after 36 octets of other headers):

0000   60 00 00 00 00 24 00 01 00 00 00 00 00 00 00 00
0010   00 00 00 00 00 00 00 00 ff 02 00 00 00 00 00 00
0020   00 00 00 00 00 00 00 16 3a 00 05 02 00 00 01 00
0030   8f 00 d1 ff 00 00 00 01 04 00 00 00 ff 02 00 00
0040   00 00 00 00 00 00 00 01 ff ea 9c a0 00 00 


Edit(2): If you trim off the leading 4 octets 00 00 86 dd, then it decodes properly as an Ethernet frame.

Edit(3): Here is your whole capture, with those 4 octets removed from each packet and massaged so Wireshark can import it (encapsulation Ethernet): http://pastebin.com/sUfCfPC4
",derobert,https://unix.stackexchange.com/users/977,http://unix.stackexchange.com/questions/26250/what-is-the-kernel-doing-when-i-bring-a-tun-tap-interface-up,TECHNOLOGY,unix.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,0.3333333333333333,1.0,0.6666666666666666,0.7777777777777778,0.4444444444444444,0.3333333333333333,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,1.0,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.7333333333333333,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.7777777777777778,What is the kernel doing when I open the Tun / tap interface,"I'm playing around with the TUN/TAP device on Linux.
I've created a simple program that creates a TAP interface and prints anything that is sent through it.
When I bring the interface up with

ip link set tap1 up


six frames are sent through it. What are these frames?

I've pasted them here
","OK, I can't get the packet imported into Wireshark (there must be some headers extra or missing, not bothering to figure that out) but, this is IPv6. From your first frame, you see ff 02 00 00 00 00 00 00 00 00 00 00 00 00 00 16. That's the IPv6 address ff02::16, used for MLDv2. 

Edit: from your first frame, here is the IPv6 part in a format Wireshark can understand when you select ""File->Import"" and pick Encapsulation type of Raw IP or Raw IPv6 (this starts after 36 octets of other headers):

0000   60 00 00 00 00 24 00 01 00 00 00 00 00 00 00 00
0010   00 00 00 00 00 00 00 00 ff 02 00 00 00 00 00 00
0020   00 00 00 00 00 00 00 16 3a 00 05 02 00 00 01 00
0030   8f 00 d1 ff 00 00 00 01 04 00 00 00 ff 02 00 00
0040   00 00 00 00 00 00 00 01 ff ea 9c a0 00 00 


Edit(2): If you trim off the leading 4 octets 00 00 86 dd, then it decodes properly as an Ethernet frame.

Edit(3): Here is your whole capture, with those 4 octets removed from each packet and massaged so Wireshark can import it (encapsulation Ethernet): http://pastebin.com/sUfCfPC4
"
3594,3594,5739,How much of the universe is observable at visible wavelengths?,"Knowing that:


The Zone of Avoidance (Looking towards the center of the Milky Way) blocks roughly 20%
Each Milky Way star has an angular size, depending on proximity, that obscures a certain percentage of our optical view.
Each Galaxy has an angular size, depending on proximity, that obscures a certain percentage of our optical view.


And so on through Galaxy Clusters, Superstructures, etc...

What percentage of our universe can we not see at visible wavelengths?
",PJL71,https://physics.stackexchange.com/users/16638,"Suppose that we had a Super Hubble Space Telescope available. An optical telescope with diffraction-limited optics and enough aperture to image individual stars in distant galaxies. What fraction of the sky would be observed to be dark? 

It would certainly be more than 99%. If, hypothetically, 0% of the sky would be dark, all objects would on average heat up to about 3,000 K (estimate for the average temperature of thermal radiation from stars, taking into account average redshifts according to the so-called cosmic time–redshift relation). Given that dwarf planet Eris reaches a surface temperature of 30 K, it must be that less than 1% of the lines of sight from Eris hit a star. 

This is of course a loose upper bound, as Eris is very close to the star called Sun. In other words, the temperature of 30 K is almost entirely due to the relatively large portion of the Eridian sky being covered by the sun. 

If you go to the Wikipedia page dedicated to Olbers' paradox, you can read similar reasoning leading to the conclusion:


  ""the sky is about fifty billion times darker than it would be if the
  universe were neither expanding nor too young to have reached
  equilibrium yet""


Which translates into roughly 99.999999998% of the sky being dark. Our universe is a cold and empty place.
",Johannes,https://physics.stackexchange.com/users/1268,http://physics.stackexchange.com/questions/46189/how-much-of-the-universe-is-observable-at-visible-wavelengths,SCIENCE,physics.stackexchange.com,1.0,1.0,0.0,1.0,1.0,1.0,0.7777777777777778,0.8888888888888888,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.7777777777777778,0.8888888888888888,0.5555555555555556,1.0,0.8888888888888888,0.8666666666666666,0.0,0.3333333333333333,0.6666666666666666,0.8888888888888888,How much of the universe can be observed in visible light?,"Knowing that:


The Zone of Avoidance (Looking towards the center of the Milky Way) blocks roughly 20%
Each Milky Way star has an angular size, depending on proximity, that obscures a certain percentage of our optical view.
Each Galaxy has an angular size, depending on proximity, that obscures a certain percentage of our optical view.


And so on through Galaxy Clusters, Superstructures, etc...

What percentage of our universe can we not see at visible wavelengths?
","Suppose that we had a Super Hubble Space Telescope available. An optical telescope with diffraction-limited optics and enough aperture to image individual stars in distant galaxies. What fraction of the sky would be observed to be dark? 

It would certainly be more than 99%. If, hypothetically, 0% of the sky would be dark, all objects would on average heat up to about 3,000 K (estimate for the average temperature of thermal radiation from stars, taking into account average redshifts according to the so-called cosmic time–redshift relation). Given that dwarf planet Eris reaches a surface temperature of 30 K, it must be that less than 1% of the lines of sight from Eris hit a star. 

This is of course a loose upper bound, as Eris is very close to the star called Sun. In other words, the temperature of 30 K is almost entirely due to the relatively large portion of the Eridian sky being covered by the sun. 

If you go to the Wikipedia page dedicated to Olbers' paradox, you can read similar reasoning leading to the conclusion:


  ""the sky is about fifty billion times darker than it would be if the
  universe were neither expanding nor too young to have reached
  equilibrium yet""


Which translates into roughly 99.999999998% of the sky being dark. Our universe is a cold and empty place.
"
3672,3672,5855,Eclipse Java EE Indigo 's XML formatting is suddenly screwed up,"A few days ago it was just fine. I haven't made any change to the IDE or anything else in the preferences.

Looks like random instability, but I hope I'm wrong, I don't want to go through the IDE setup again.......

Here are two screenshots to tell the story:

Before Ctrl+Shift+F (format):


After (format results):


What can I do about it?

I've tried comparing settings in another Eclipse setup that I have which has XML formatting working properly. (Window -> Preferences -> XML -> XML Files -> Editor). Also (Structured Text Editors).
",Poni,https://stackoverflow.com/users/286260,"You can revert the default editor for XML files to be the original XML Editor at Preferences / General / Editors / File Associations:


",Frigo,https://stackoverflow.com/users/801651,http://stackoverflow.com/questions/10941447/eclipse-java-ee-indigo-s-xml-formatting-is-suddenly-screwed-up,STACKOVERFLOW,stackoverflow.com,1.0,0.3333333333333333,0.0,0.6666666666666666,0.3333333333333333,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.5555555555555556,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.8666666666666666,1.0,0.0,0.0,0.8888888888888888,The XML format of eclipse Java EE indigo was suddenly messed up,"A few days ago it was just fine. I haven't made any change to the IDE or anything else in the preferences.

Looks like random instability, but I hope I'm wrong, I don't want to go through the IDE setup again.......

Here are two screenshots to tell the story:

Before Ctrl+Shift+F (format):


After (format results):


What can I do about it?

I've tried comparing settings in another Eclipse setup that I have which has XML formatting working properly. (Window -> Preferences -> XML -> XML Files -> Editor). Also (Structured Text Editors).
","You can revert the default editor for XML files to be the original XML Editor at Preferences / General / Editors / File Associations:


"
3205,3205,5108,Return value in bash script,"I am working with a bash script and I want to execute a function to print a return value:

function fun1(){
  return 34
}
function fun2(){
  local res=$(fun1)
  echo $res
}


when I execute func2 it does not print ""34"". Can anybody help me?
",mindia,https://stackoverflow.com/users/2496202,"I like to do the following if running in a script where the function is defined:

POINTER= # used for function return values

my_function() {
    # do stuff
    POINTER=""my_function_return""
}

my_other_function() {
    # do stuff
    POINTER=""my_other_function_return""
}

my_function
RESULT=""$POINTER""

my_other_function
RESULT=""$POINTER""


I like this, becase I can then include echo statements in my functions if I want

my_function() {
    echo ""-&gt; my_function()""
    # do stuff
    POINTER=""my_function_return""
    echo ""&lt;- my_function. $POINTER""
}

",doc,https://stackoverflow.com/users/844123,http://stackoverflow.com/questions/17336915/return-value-in-bash-script,STACKOVERFLOW,stackoverflow.com,0.6666666666666666,0.6666666666666666,0.0,0.5,0.5,1.0,0.6666666666666666,0.3333333333333333,0.5,0.0,0.5,0.5,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.6666666666666666,1.0,0.9,1.0,0.0,0.0,0.5,Return value in Bash script,"I am working with a bash script and I want to execute a function to print a return value:

function fun1(){
  return 34
}
function fun2(){
  local res=$(fun1)
  echo $res
}


when I execute func2 it does not print ""34"". Can anybody help me?
","I like to do the following if running in a script where the function is defined:

POINTER= # used for function return values

my_function() {
    # do stuff
    POINTER=""my_function_return""
}

my_other_function() {
    # do stuff
    POINTER=""my_other_function_return""
}

my_function
RESULT=""$POINTER""

my_other_function
RESULT=""$POINTER""


I like this, becase I can then include echo statements in my functions if I want

my_function() {
    echo ""-&gt; my_function()""
    # do stuff
    POINTER=""my_function_return""
    echo ""&lt;- my_function. $POINTER""
}

"
4184,4184,6674,Is there a way to read the columns in a shapefile / layer without converting it first to an MDB file?,"My shapefile has a number of fields, like roadname, and street number.  Is there a way to get at these without converting the shapefile first into a featureclass (mdb)?  Sometimes the conversion is a time consuming operation.

I'm using ArcEngine 10 C# with VS2010
",patrick,https://gis.stackexchange.com/users/733,"Are you opposed to using open source libraries?  There are quite a few .NET options for dealing with Shapefiles.  I've had very good results with the OGR (C# bindings) and SharpMap.  A quick search on google yields many more options.
",user890,https://gis.stackexchange.com/users/890,http://gis.stackexchange.com/questions/4619/is-there-a-way-to-read-the-columns-in-a-shapefile-layer-without-converting-it,TECHNOLOGY,gis.stackexchange.com,1.0,0.7777777777777778,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.0,0.0,1.0,Is there a way to read a column in the ShapeFile / layer without first converting it to an mdb file?,"My ShapeFile has many fields, such as roadname and street number. Is there a way to implement these features without first converting shapefiles to feature classes (MDBs)? Sometimes conversion is a time-consuming operation.",Are you against using open source libraries? There are many. Net options for handling shapefiles. I use ogr (C bindings) and sharpmap to achieve good results. A quick search on Google results in more options.
4338,4338,6910,Unit test with HttpWebClient or RestSharp,"I am trying to find a way to write the unit test for the ""CheckSomething"" method, but i am having a very difficult time figuring out what to do with the RestClient object i am instantiating in the method. 

Should I abstract away the RestClient, and put the Interface dependency at the class level and injected from withint he constructor?? If i go with this route, does that mean I have to interface out all the dependencies ??

public class SomeRepository : IXRepository
{
    public SomeRepository()
    {
    }

    public bool CheckSomething()
    {
        var client = new RestClient(""someurl"");

        var request = new RestRequest(""resourceX/{name}"", Method.GET);
        request.AddUrlSegment(""name"", ""ABC"");
        var response = client.Execute(request);

        if (response.StatusCode == HttpStatusCode.NotFound) return false;
        if (response.StatusCode == HttpStatusCode.OK) return true;

        throw new Exception(""Something is messed up"");
    }
}

",Eatdoku,https://stackoverflow.com/users/83181,"If you don't want a class level RestClient field in SomeRepository, you can use method injection, and add a RestClient parameter to the CheckSomething method. You can then mock the RestClient for your unit tests.

public bool CheckSomething(RestClient restClient)
{
    var request = new RestRequest(""resourceX/{name}"", Method.GET);
    request.AddUrlSegment(""name"", ""ABC"");
    var response = client.Execute(request);

    if (response.StatusCode == HttpStatusCode.NotFound) return false;
    if (response.StatusCode == HttpStatusCode.OK) return true;

    throw new Exception(""Something is messed up"");
}


If that were my code, I would want to test the following things:


Has the RestRequest that was passed into the RestClient.Execute method been properly setup.
Does the method return true or false based on the response.StatusCode
Does any other status code result in an exception being thrown.


If that is all you need to test, then the only thing you need to mock is the RestClient, which means you could easily just use method injection, or constructor or property injection.
",seth flowers,https://stackoverflow.com/users/444610,http://stackoverflow.com/questions/12430998/unit-test-with-httpwebclient-or-restsharp,STACKOVERFLOW,stackoverflow.com,0.6666666666666666,0.3333333333333333,0.0,1.0,0.6666666666666666,1.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,0.8888888888888888,Unit test with httpwebclient or restsharp,"I am trying to find a way to write the unit test for the ""CheckSomething"" method, but i am having a very difficult time figuring out what to do with the RestClient object i am instantiating in the method. 

Should I abstract away the RestClient, and put the Interface dependency at the class level and injected from withint he constructor?? If i go with this route, does that mean I have to interface out all the dependencies ??

public class SomeRepository : IXRepository
{
    public SomeRepository()
    {
    }

    public bool CheckSomething()
    {
        var client = new RestClient(""someurl"");

        var request = new RestRequest(""resourceX/{name}"", Method.GET);
        request.AddUrlSegment(""name"", ""ABC"");
        var response = client.Execute(request);

        if (response.StatusCode == HttpStatusCode.NotFound) return false;
        if (response.StatusCode == HttpStatusCode.OK) return true;

        throw new Exception(""Something is messed up"");
    }
}

","If you don't want a class level RestClient field in SomeRepository, you can use method injection, and add a RestClient parameter to the CheckSomething method. You can then mock the RestClient for your unit tests.

public bool CheckSomething(RestClient restClient)
{
    var request = new RestRequest(""resourceX/{name}"", Method.GET);
    request.AddUrlSegment(""name"", ""ABC"");
    var response = client.Execute(request);

    if (response.StatusCode == HttpStatusCode.NotFound) return false;
    if (response.StatusCode == HttpStatusCode.OK) return true;

    throw new Exception(""Something is messed up"");
}


If that were my code, I would want to test the following things:


Has the RestRequest that was passed into the RestClient.Execute method been properly setup.
Does the method return true or false based on the response.StatusCode
Does any other status code result in an exception being thrown.


If that is all you need to test, then the only thing you need to mock is the RestClient, which means you could easily just use method injection, or constructor or property injection.
"
2245,2245,3580,Displaying images in draft mode for books,"I am writing my thesis in draft mode. 

\documentclass[dissertation,draft]{univthesis}


The univthesis is a dissertation template like a book. However, when I include figures, I only see the figure name and box enclosing it. When draft mode is removed, I get what I want. So, I was wondering if there is a way to display images even in draft mode. I have both .eps and .pdf files in the current directory.
",discipulus,https://tex.stackexchange.com/users/102941,"Try using the following setup:

\RequirePackage{graphicx}
\documentclass[dissertation,draft]{univthesis}


This loads graphicx before the draft option is set. Alternatively (preferred), don't load graphicx but reset the package option using

\setkeys{Gin}{draft=false}


Gin contains the family of keys associated with graphics/graphicx.
",Werner,https://tex.stackexchange.com/users/5764,http://tex.stackexchange.com/questions/162387/displaying-images-in-draft-mode-for-books,TECHNOLOGY,tex.stackexchange.com,0.8333333333333334,0.8333333333333334,0.0,1.0,1.0,1.0,0.8333333333333334,1.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.8333333333333334,0.8333333333333334,0.6666666666666666,0.8333333333333334,1.0,0.9,1.0,0.0,0.0,1.0,Show book image in draft mode,"I am writing my thesis in draft mode. 

\documentclass[dissertation,draft]{univthesis}


The univthesis is a dissertation template like a book. However, when I include figures, I only see the figure name and box enclosing it. When draft mode is removed, I get what I want. So, I was wondering if there is a way to display images even in draft mode. I have both .eps and .pdf files in the current directory.
","Try using the following setup:

\RequirePackage{graphicx}
\documentclass[dissertation,draft]{univthesis}


This loads graphicx before the draft option is set. Alternatively (preferred), don't load graphicx but reset the package option using

\setkeys{Gin}{draft=false}


Gin contains the family of keys associated with graphics/graphicx.
"
549,549,864,How can I get my SSL certificate signed by an CA for web application that runs on localhost,"I have a web application that runs on localhost. I have a self-signed certificate for tomcat configured but when loading the website on firefox, I get a security exception. Can I get a CA to sign my SSL certificate so that this error is not thrown?
",Questioner,https://security.stackexchange.com/users/47553,"You can't and you absolutely SHOULD NOT!

The main feature of X509 certificate signature in SSL/TLS is that a third party guarantees that you're actually connecting to a system that has been approved by the owner of a domain name (it is the assumption that you already know the relation between the domain name and the actual entity you're trying to interact with).

Issuing a certificate for a name that isn't uniquely linked to an entity does not allow that validation to take place: such a signed certificate wouldn't carry any guarantee.

The bright point, however, is that if the only way you're using SSL is to validate the server identity, then it simply it doesn't matter if the certificate is signed by a trusted CA: you should be using certificate pinning in any case (not that it matters much, mind you, since you can assume that if someone can hijack your service listening on the loopback address, he can also grab the private key associated with the certificate).
",Stephane,https://security.stackexchange.com/users/20934,http://security.stackexchange.com/questions/59049/how-can-i-get-my-ssl-certificate-signed-by-an-ca-for-web-application-that-runs-o,TECHNOLOGY,security.stackexchange.com,1.0,0.7777777777777778,0.0,1.0,1.0,1.0,0.6666666666666666,0.5555555555555556,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.7777777777777778,0.8333333333333334,0.6666666666666666,0.8333333333333334,0.8888888888888888,0.8,0.3333333333333333,0.0,1.0,0.8888888888888888,How to obtain SSL certificate signed by CA for web application running on local host,"I have a web application running on a local host. I've configured a self signed certificate for tomcat, but a security exception occurred while loading the website on Firefox. Can I have a CA sign my SSL certificate so that this error is not thrown?","You can't and you absolutely SHOULD NOT!

The main feature of X509 certificate signature in SSL/TLS is that a third party guarantees that you're actually connecting to a system that has been approved by the owner of a domain name (it is the assumption that you already know the relation between the domain name and the actual entity you're trying to interact with).

Issuing a certificate for a name that isn't uniquely linked to an entity does not allow that validation to take place: such a signed certificate wouldn't carry any guarantee.

The bright point, however, is that if the only way you're using SSL is to validate the server identity, then it simply it doesn't matter if the certificate is signed by a trusted CA: you should be using certificate pinning in any case (not that it matters much, mind you, since you can assume that if someone can hijack your service listening on the loopback address, he can also grab the private key associated with the certificate).
"
751,751,1187,Parsing Ids from a string to create detail objects,"I am building a Flow that takes a user through a wizard to create a custom contract object with detail objects that represent the products on that contract (stored as a junction object).  An issue I ran into is that Flow has a known limitation where if you use a Dynamic Choice (i.e. creating a dynamic set of checkboxes to choose Products from based on records from the Product object) it can only store the choices as a long semicolon delimited string in a variable; it cannot create detail objects based on your dynamic selection (even using a loop).

To get around this, I want the flow to just create the parent Contract, then I want an after insert Apex trigger to parse the field where the long string of semicolon separated Product Ids are stored.  The trigger would need to take the string and find each Id to store in a List.  Once I had the List made from the text field I could insert the Product detail records to the parent Contract.

I am very new to Apex, mostly just a point and click admin here.  I am struggling with how to use RIGHT and LEFT to loop through the string field.

trigger AddProductstoSOW on PS_Contract__c (after insert) {
        for(PS_Contract__c c:Trigger.new){
        List&lt;Id&gt; ProductsToInsert = new List&lt;Id&gt;;
        integer n = LEN(c.Initial_Services_Products__c);
      for(p=15,p&lt;n,p+17){
    //How to iterate through Initial_Products_Selected__c?
        thisId = LEFT(p);
        Id product = Id.valueOf(thisId);
        ProductsToInsert.add(product);
        }
    }
    insert ProductsToInsert;
}


Any help is very appreciated.
",Tyler Whitesides,https://salesforce.stackexchange.com/users/16691,"Thank you for the assistance.  I was able to resolve the issue.  Though with .split() you also seem to need an upper limit parameter.  Took a little struggling to figure this out but here it is:

trigger AddProductstoSOW on PS_Contract__c (after insert) {
try{
for(PS_Contract__c c : Trigger.new){
    List&lt;String&gt; strProductIds = c.Initial_Services_Selected__c.split('; ', 1000);
    System.debug(strProductIds);
    List&lt;SOW_Task__c&gt; tasks = new List&lt;SOW_Task__c&gt;();
        for(String i : strProductIds){
        SOW_Task__c s = new SOW_Task__c();
        s.PS_ServiceNo__c = i;
        s.PS_Contract__c = c.Id;
        tasks.add(s);
        }
     insert tasks;
    }
}
catch(DmlException e) {
System.debug('An unexpected error has occurred: ' + e.getMessage());
}
    }

",Tyler Whitesides,https://salesforce.stackexchange.com/users/16691,http://salesforce.stackexchange.com/questions/66539/parsing-ids-from-a-string-to-create-detail-objects,TECHNOLOGY,salesforce.stackexchange.com,0.8888888888888888,0.4444444444444444,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.9,1.0,0.0,0.5,1.0,Parsing ID from string to create detail object,"I am building a Flow that takes a user through a wizard to create a custom contract object with detail objects that represent the products on that contract (stored as a junction object).  An issue I ran into is that Flow has a known limitation where if you use a Dynamic Choice (i.e. creating a dynamic set of checkboxes to choose Products from based on records from the Product object) it can only store the choices as a long semicolon delimited string in a variable; it cannot create detail objects based on your dynamic selection (even using a loop).

To get around this, I want the flow to just create the parent Contract, then I want an after insert Apex trigger to parse the field where the long string of semicolon separated Product Ids are stored.  The trigger would need to take the string and find each Id to store in a List.  Once I had the List made from the text field I could insert the Product detail records to the parent Contract.

I am very new to Apex, mostly just a point and click admin here.  I am struggling with how to use RIGHT and LEFT to loop through the string field.

trigger AddProductstoSOW on PS_Contract__c (after insert) {
        for(PS_Contract__c c:Trigger.new){
        List&lt;Id&gt; ProductsToInsert = new List&lt;Id&gt;;
        integer n = LEN(c.Initial_Services_Products__c);
      for(p=15,p&lt;n,p+17){
    //How to iterate through Initial_Products_Selected__c?
        thisId = LEFT(p);
        Id product = Id.valueOf(thisId);
        ProductsToInsert.add(product);
        }
    }
    insert ProductsToInsert;
}


Any help is very appreciated.
","Thank you for the assistance.  I was able to resolve the issue.  Though with .split() you also seem to need an upper limit parameter.  Took a little struggling to figure this out but here it is:

trigger AddProductstoSOW on PS_Contract__c (after insert) {
try{
for(PS_Contract__c c : Trigger.new){
    List&lt;String&gt; strProductIds = c.Initial_Services_Selected__c.split('; ', 1000);
    System.debug(strProductIds);
    List&lt;SOW_Task__c&gt; tasks = new List&lt;SOW_Task__c&gt;();
        for(String i : strProductIds){
        SOW_Task__c s = new SOW_Task__c();
        s.PS_ServiceNo__c = i;
        s.PS_Contract__c = c.Id;
        tasks.add(s);
        }
     insert tasks;
    }
}
catch(DmlException e) {
System.debug('An unexpected error has occurred: ' + e.getMessage());
}
    }

"
784,784,1246,Can I connect iPad to computer so I can use iPad as a keyboard?,"The computer keys seem to be stuck after coffee was spilt. Only a mouthful but that seems to have done it. The computer switches on all right, but the keyboard doesn't work.

Can I use my I pad as a keyboard until I can check out the problem on laptop as I need to print off from my laptop.
",Paula marks,https://superuser.com/users/291789,"There are a few applications which can installed to use your iPad as a keyboard, however this requires the application to be installed on both the iPad and your PC (assuming you can't do this due to the keyboard not working).

I'd suggest leaving the laptop off until it's 100% COMPLETELY dry and obtaining a USB keyboard to use.

If you are still interested in applications to use with your iPad, here are a few:


http://www.airkeyboardapp.com/
http://www.remotemouse.net/
http://www.mobilemouse.com/ (Link given by @gparyani)


Please note, I have not used or tested the above applications.
",Joe S,https://superuser.com/users/95184,http://superuser.com/questions/704557,TECHNOLOGY,superuser.com,1.0,1.0,0.0,1.0,1.0,1.0,0.7777777777777778,0.6666666666666666,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.3333333333333333,0.0,0.0,1.0,Can I connect the iPad to the computer so that I can use the iPad as a keyboard?,"The computer key seems to be stuck after the coffee is spilt. Only one bite, but it seems to have been done. The computer is OK, but the keyboard is broken.","There are a few applications which can installed to use your iPad as a keyboard, however this requires the application to be installed on both the iPad and your PC (assuming you can't do this due to the keyboard not working).

I'd suggest leaving the laptop off until it's 100% COMPLETELY dry and obtaining a USB keyboard to use.

If you are still interested in applications to use with your iPad, here are a few:


http://www.airkeyboardapp.com/
http://www.remotemouse.net/
http://www.mobilemouse.com/ (Link given by @gparyani)


Please note, I have not used or tested the above applications.
"
4326,4326,6891,how can i use regex to get a certain string of a file,"with linux bash shell , how can i use regex to get a certain string of a file

by example:

for filename *.tgz
do 

""get the certain string of filename (in my case, get 2010.04.12 of file 2010.01.12myfile.tgz)""

done  

or should I turn to perl

Merci

frank
",chun,https://stackoverflow.com/users/304910,"FILE=2010.01.12myfile.tgz

echo ${FILE:0:10}


gives

2010.01.12

",fpmurphy1,https://stackoverflow.com/users/127259,http://stackoverflow.com/questions/2673919/how-can-i-use-regex-to-get-a-certain-string-of-a-file,STACKOVERFLOW,stackoverflow.com,1.0,0.5555555555555556,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.4444444444444444,0.4444444444444444,0.3333333333333333,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,0.7777777777777778,0.5,1.0,1.0,0.9,1.0,0.0,0.0,0.6666666666666666,How to use regex to get specific strings of files,"with linux bash shell , how can i use regex to get a certain string of a file

by example:

for filename *.tgz
do 

""get the certain string of filename (in my case, get 2010.04.12 of file 2010.01.12myfile.tgz)""

done  

or should I turn to perl

Merci

frank
","FILE=2010.01.12myfile.tgz

echo ${FILE:0:10}


gives

2010.01.12

"
4695,4695,7445,iPhone app - Persistent hamburger menu vs last page visited,"I'm wondering which option is best for an iPhone app using a hamburger menu (placed at the top left):


The menu is persistent on every single page even when the user goes
to a sub-level.
When the user goes to a sub-level, the hamburger menu is replaced by a back button or a button whose label is the name of last page visited.
Both. The menu is persistent on every page and a back button appears when needed.


Thanks for your help :)
",Leo,https://ux.stackexchange.com/users/25518,"Always have your navigation persistent.

But that doesn't mean you can't have a ""back"" button in place when it's needed when you dig deeper on portions of the site.







download bmml source &ndash; Wireframes created with Balsamiq Mockups

Now this is just for the sake of your answer, but I highly suggest against the hamburger menu. Many products (twitter and Facebook to name a few) have moved away from the hamburger menu because of various reasons:


Discoverability was at an all time low
Not a lot of people understood what the hamburger menu was


They all placed a navigation element that was persistent on the bottom of the page, where people could toggle between what they knew were big hit points on the site (timeline, discover, messages, etc).

Some examples:




",Majo0od,https://ux.stackexchange.com/users/22695,http://ux.stackexchange.com/questions/74551/iphone-app-persistent-hamburger-menu-vs-last-page-visited,TECHNOLOGY,ux.stackexchange.com,1.0,0.4444444444444444,0.6666666666666666,1.0,0.0,0.5,0.4444444444444444,0.4444444444444444,0.0,0.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.0,0.3333333333333333,0.0,0.6666666666666666,0.8888888888888888,0.7777777777777778,0.8888888888888888,1.0,1.0,0.6666666666666666,0.0,1.0,0.8888888888888888,IPhone app - persistent hamburger menu vs. last visited page,"I'm wondering which option is best for an iPhone app using a hamburger menu (placed at the top left):


The menu is persistent on every single page even when the user goes
to a sub-level.
When the user goes to a sub-level, the hamburger menu is replaced by a back button or a button whose label is the name of last page visited.
Both. The menu is persistent on every page and a back button appears when needed.


Thanks for your help :)
","Always have your navigation persistent.

But that doesn't mean you can't have a ""back"" button in place when it's needed when you dig deeper on portions of the site.







download bmml source &ndash; Wireframes created with Balsamiq Mockups

Now this is just for the sake of your answer, but I highly suggest against the hamburger menu. Many products (twitter and Facebook to name a few) have moved away from the hamburger menu because of various reasons:


Discoverability was at an all time low
Not a lot of people understood what the hamburger menu was


They all placed a navigation element that was persistent on the bottom of the page, where people could toggle between what they knew were big hit points on the site (timeline, discover, messages, etc).

Some examples:




"
1647,1647,2591,What is the best introductory Bayesian statistics textbook?,"Which is the best introductory textbook for Bayesian statistics?

One book per answer, please.
",Shane,https://stats.stackexchange.com/users/5,"My favorite is ""Bayesian Data Analysis"" by Gelman, et al.
",Shane,https://stats.stackexchange.com/users/5,http://stats.stackexchange.com/questions/125/what-is-the-best-introductory-bayesian-statistics-textbook,SCIENCE,stats.stackexchange.com,1.0,1.0,1.0,1.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,0.0,1.0,What is the best introduction to Bayesian statistics?,Which is the best introduction to Bayesian statistics?,"My favorite is ""Bayesian Data Analysis"" by Gelman, et al.
"
130,130,207,Can't ping host in OpenVPN Site-to-Site VPN,"My logs say that a connection has been established but I cant ping the host.

Here are my logs. 

Firewall 1 Logs:

May 24 10:42:57 openvpn[9163]: /etc/rc.filter_configure tun0 1500 1544 10.0.8.1 10.0.8.2 init  
May 24 10:42:57 openvpn[9163]: SIGTERM[hard,] received, process exiting  
May 24 10:42:59 openvpn[9742]: OpenVPN 2.0.6 i386-portbld-freebsd7.2 [SSL] [LZO] built on Dec 4 2009  
May 24 10:42:59 openvpn[9742]: WARNING: file '/var/etc/openvpn_server0.key' is group or others accessible  
May 24 10:42:59 openvpn[9742]: gw 112.202.0.1  
May 24 10:42:59 openvpn[9742]: TUN/TAP device /dev/tun0 opened  
May 24 10:42:59 openvpn[9742]: /sbin/ifconfig tun0 10.0.8.1 10.0.8.2 mtu 1500 netmask 255.255.255.255 up  
May 24 10:42:59 openvpn[9742]: /etc/rc.filter_configure tun0 1500 1544 10.0.8.1 10.0.8.2 init  
May 24 10:43:00 openvpn[9757]: Listening for incoming TCP connection on [undef]:1194  
May 24 10:43:00 openvpn[9757]: TCPv4_SERVER link local (bound): [undef]:1194  
May 24 10:43:00 openvpn[9757]: TCPv4_SERVER link remote: [undef]  
May 24 10:43:00 openvpn[9757]: Initialization Sequence Completed  
May 24 10:43:02 openvpn[9757]: Re-using SSL/TLS context  
May 24 10:43:02 openvpn[9757]: LZO compression initialized  
May 24 10:43:02 openvpn[9757]: TCP connection established with 119.93.150.4:47750  
May 24 10:43:02 openvpn[9757]: TCPv4_SERVER link local: [undef]  
May 24 10:43:02 openvpn[9757]: TCPv4_SERVER link remote: 119.93.150.4:47750  
May 24 10:43:06 openvpn[9757]: 119.93.150.4:47750 [client] Peer Connection Initiated with 119.93.150.4:47750  


Firewall 2 Logs:

May 24 10:42:57 openvpn[7489]: Connection reset, restarting [0]  
May 24 10:42:57 openvpn[7489]: SIGUSR1[soft,connection-reset] received, process restarting  
May 24 10:43:02 openvpn[7489]: WARNING: No server certificate verification method has been enabled. See http://openvpn.net/howto.html#mitm for more info.  
May 24 10:43:02 openvpn[7489]: Re-using SSL/TLS context  
May 24 10:43:02 openvpn[7489]: LZO compression initialized  
May 24 10:43:02 openvpn[7489]: Attempting to establish TCP connection with 112.202.103.45:1194  
May 24 10:43:02 openvpn[7489]: TCP connection established with 112.202.103.45:1194  
May 24 10:43:02 openvpn[7489]: TCPv4_CLIENT link local: [undef]  
May 24 10:43:02 openvpn[7489]: TCPv4_CLIENT link remote: 112.202.103.45:1194  
May 24 10:43:06 openvpn[7489]: [server] Peer Connection Initiated with 112.202.103.45:1194  
May 24 10:43:08 openvpn[7489]: Options error: Unrecognized option or missing parameter(s) in [PUSH-OPTIONS]:1: 112.202.103.45 (2.0.6)  
May 24 10:43:08 openvpn[7489]: Preserving previous TUN/TAP instance: tun0  
May 24 10:43:08 openvpn[7489]: Initialization Sequence Completed  


What could the problem be?
",vrynxzent,https://serverfault.com/users/82348,"Aside from the push, which probably isn't enough to break the connection, the logs look normal. You're likely missing a route, or have the route wrong, on one or both ends. 
",Chris Buechler,https://serverfault.com/users/19233,http://serverfault.com/questions/273101,TECHNOLOGY,serverfault.com,1.0,0.6666666666666666,0.0,0.5,0.5,1.0,0.5,0.3333333333333333,0.5,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,0.8333333333333334,0.6666666666666666,1.0,0.8333333333333334,0.8333333333333334,0.7,0.0,0.0,1.0,0.8333333333333334,Unable to Ping OpenVPN site to host in site VPN,"My logs say that a connection has been established but I cant ping the host.

Here are my logs. 

Firewall 1 Logs:

May 24 10:42:57 openvpn[9163]: /etc/rc.filter_configure tun0 1500 1544 10.0.8.1 10.0.8.2 init  
May 24 10:42:57 openvpn[9163]: SIGTERM[hard,] received, process exiting  
May 24 10:42:59 openvpn[9742]: OpenVPN 2.0.6 i386-portbld-freebsd7.2 [SSL] [LZO] built on Dec 4 2009  
May 24 10:42:59 openvpn[9742]: WARNING: file '/var/etc/openvpn_server0.key' is group or others accessible  
May 24 10:42:59 openvpn[9742]: gw 112.202.0.1  
May 24 10:42:59 openvpn[9742]: TUN/TAP device /dev/tun0 opened  
May 24 10:42:59 openvpn[9742]: /sbin/ifconfig tun0 10.0.8.1 10.0.8.2 mtu 1500 netmask 255.255.255.255 up  
May 24 10:42:59 openvpn[9742]: /etc/rc.filter_configure tun0 1500 1544 10.0.8.1 10.0.8.2 init  
May 24 10:43:00 openvpn[9757]: Listening for incoming TCP connection on [undef]:1194  
May 24 10:43:00 openvpn[9757]: TCPv4_SERVER link local (bound): [undef]:1194  
May 24 10:43:00 openvpn[9757]: TCPv4_SERVER link remote: [undef]  
May 24 10:43:00 openvpn[9757]: Initialization Sequence Completed  
May 24 10:43:02 openvpn[9757]: Re-using SSL/TLS context  
May 24 10:43:02 openvpn[9757]: LZO compression initialized  
May 24 10:43:02 openvpn[9757]: TCP connection established with 119.93.150.4:47750  
May 24 10:43:02 openvpn[9757]: TCPv4_SERVER link local: [undef]  
May 24 10:43:02 openvpn[9757]: TCPv4_SERVER link remote: 119.93.150.4:47750  
May 24 10:43:06 openvpn[9757]: 119.93.150.4:47750 [client] Peer Connection Initiated with 119.93.150.4:47750  


Firewall 2 Logs:

May 24 10:42:57 openvpn[7489]: Connection reset, restarting [0]  
May 24 10:42:57 openvpn[7489]: SIGUSR1[soft,connection-reset] received, process restarting  
May 24 10:43:02 openvpn[7489]: WARNING: No server certificate verification method has been enabled. See http://openvpn.net/howto.html#mitm for more info.  
May 24 10:43:02 openvpn[7489]: Re-using SSL/TLS context  
May 24 10:43:02 openvpn[7489]: LZO compression initialized  
May 24 10:43:02 openvpn[7489]: Attempting to establish TCP connection with 112.202.103.45:1194  
May 24 10:43:02 openvpn[7489]: TCP connection established with 112.202.103.45:1194  
May 24 10:43:02 openvpn[7489]: TCPv4_CLIENT link local: [undef]  
May 24 10:43:02 openvpn[7489]: TCPv4_CLIENT link remote: 112.202.103.45:1194  
May 24 10:43:06 openvpn[7489]: [server] Peer Connection Initiated with 112.202.103.45:1194  
May 24 10:43:08 openvpn[7489]: Options error: Unrecognized option or missing parameter(s) in [PUSH-OPTIONS]:1: 112.202.103.45 (2.0.6)  
May 24 10:43:08 openvpn[7489]: Preserving previous TUN/TAP instance: tun0  
May 24 10:43:08 openvpn[7489]: Initialization Sequence Completed  


What could the problem be?
","Except for push (which may not be enough to disconnect), the log looks normal. You are likely to miss a route at one or both ends, or the route is wrong."
3405,3405,5427,Should I avoid credit card use to improve our debt-to-income ratio?,"We put all our expenses on a credit card and pay it off every month in order to get maximize our cash back.  We never charge more than we have in the checking account, so we always pay it off.  Should we reconsider doing this in order to improve our debt-to-income ratio?

Our goal is to be in the best position possible to get a mortgage in the next 3-12 months.
",JHFB,https://money.stackexchange.com/users/6182,"If you pay it off before the cycle closes it will look like you have 100% available credit.  

So if you credit card statement closes on the 7th pay it off on the 6th in full don't pay it when its due 2/3 weeks later.

Then after three months of doing that your credit score will go up based on the fact that your debt ratio is so low.  That ratio is 30% of your credit score.  It will help quite alot.
",Mark Monforti,https://money.stackexchange.com/users/19218,http://money.stackexchange.com/questions/30939/should-i-avoid-credit-card-use-to-improve-our-debt-to-income-ratio,LIFE_ARTS,money.stackexchange.com,1.0,0.8888888888888888,0.6666666666666666,0.5,0.3333333333333333,0.0,0.8888888888888888,0.7777777777777778,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.3333333333333333,0.0,1.0,1.0,Should I avoid using credit cards to increase our debt to income ratio?,"We spend all our expenses on credit cards and pay them monthly to maximize our cash. We never charge more than a checking account, so we always pay it off. Should we reconsider this to improve our debt to income ratio?","If you pay it off before the cycle closes it will look like you have 100% available credit.  

So if you credit card statement closes on the 7th pay it off on the 6th in full don't pay it when its due 2/3 weeks later.

Then after three months of doing that your credit score will go up based on the fact that your debt ratio is so low.  That ratio is 30% of your credit score.  It will help quite alot.
"
5107,5107,8125,Difference between Across the Line and Line to Earth,"I have to make a reverse engineering. I have two different type of capacitors. What do the Across-The-Line X2 and Line-To-Earth Y2 mean? And what are the differences between them. I searched it but i couldn't find a certain answer.
",Thereturn,https://electronics.stackexchange.com/users/78102,"X type capacitors are designed not to fail short circuit and hence cause a massive curent flow and risk of fail. Y type caps are there for personal safety and should not fail and thus cause risk to anyone touching the chassis of some equipment: -



X2 and Y2 are a bit smaller and cheaper than the original X and Y capacitors. Here is a fairly user-friendy site that gives more details.
",Andy aka,https://electronics.stackexchange.com/users/20218,http://electronics.stackexchange.com/questions/174235/difference-between-across-the-line-and-line-to-earth,SCIENCE,electronics.stackexchange.com,1.0,0.5555555555555556,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.6666666666666666,0.0,0.3333333333333333,0.0,0.6666666666666666,0.0,0.6666666666666666,0.0,0.0,0.0,0.6666666666666666,0.0,0.5555555555555556,1.0,0.5555555555555556,1.0,1.0,0.8,0.3333333333333333,0.0,0.6666666666666666,1.0,Line crossing and ground difference,"I have to do a reverse engineering. I have two different types of capacitors. What does line x2 and line Y2 mean to the ground? What's the difference between them. I searched, but couldn't find the exact answer.","The design of the type X capacitor will not lead to short circuit fault, so it will lead to a lot of current and fault risk. The y-cover is for personal safety and shall not fail, thus causing danger to any person contacting the chassis of some equipment:-"
4774,4774,7582,Birthday paradox: meaning of random,"In the wikipedia page (http://en.wikipedia.org/wiki/Birthday_problem) on birthday paradox the following statement has been said : ""the probability that, in a set of $n$ ""randomly chosen"" people, some pair of them will have the same birthday. We assume that that each day of the year is equally probable for a birthday.""

My question is what is the meaning of ""randomly chosen"" here ? Is the assumption of equally probable for a birthday needed separately ? Does not the word ""randomly chosen"" imply the equal probability ? 
",RIchard Williams,https://math.stackexchange.com/users/21982,"As in the comment from Alex, the problem assumes a discrete uniform distribution.  The word uniform means that each possible outcome is equally likely.

To help clarify the distinction with the word random, consider the following random variable.  You flip a quarter, dime, and nickel and record the total number of heads as the variable $H$.  The possible values of $H$ are $\{0, 1, 2, 3\}$.  The results of flipping the coins is certainly random and the distribution is discrete.

However, the different outcomes are not equally likely.  In fact the probabilities are as follows.  (This is an example of the binomial distribution.)
$$
\begin{array}{c*{3}{|c}}
h &amp; 0 &amp; 1 &amp; 2 &amp; 3 \\
\hline
P(H=h) &amp; \tfrac{1}{8} &amp; \tfrac{3}{8} &amp; \tfrac{3}{8} &amp; \tfrac{1}{8}
\end{array}
$$
",Sammy Black,https://math.stackexchange.com/users/6509,http://math.stackexchange.com/questions/370570/birthday-paradox-meaning-of-random,SCIENCE,math.stackexchange.com,1.0,0.5555555555555556,0.0,1.0,1.0,1.0,0.4444444444444444,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.0,0.8888888888888888,0.8333333333333334,0.5555555555555556,1.0,0.8888888888888888,0.7,0.0,0.0,1.0,1.0,Birthday paradox: the significance of randomness,"In the wikipedia page (http://en.wikipedia.org/wiki/Birthday_problem) on birthday paradox the following statement has been said : ""the probability that, in a set of $n$ ""randomly chosen"" people, some pair of them will have the same birthday. We assume that that each day of the year is equally probable for a birthday.""

My question is what is the meaning of ""randomly chosen"" here ? Is the assumption of equally probable for a birthday needed separately ? Does not the word ""randomly chosen"" imply the equal probability ? 
","As in the comment from Alex, the problem assumes a discrete uniform distribution.  The word uniform means that each possible outcome is equally likely.

To help clarify the distinction with the word random, consider the following random variable.  You flip a quarter, dime, and nickel and record the total number of heads as the variable $H$.  The possible values of $H$ are $\{0, 1, 2, 3\}$.  The results of flipping the coins is certainly random and the distribution is discrete.

However, the different outcomes are not equally likely.  In fact the probabilities are as follows.  (This is an example of the binomial distribution.)
$$
\begin{array}{c*{3}{|c}}
h &amp; 0 &amp; 1 &amp; 2 &amp; 3 \\
\hline
P(H=h) &amp; \tfrac{1}{8} &amp; \tfrac{3}{8} &amp; \tfrac{3}{8} &amp; \tfrac{1}{8}
\end{array}
$$
"
1253,1253,1971,"CS paper rejected for lack of technical contribution; what does this mean, and how can I fix it?","I recently got two papers rejected with the reviewers asserting a lack of technical contribution. They contained good ideas, at least in my eyes, and used common methodologies in the experimentation. So my question related to the CS field is, what is the difference between a good idea that was tested and a technical contribution? What should an idea have to become a technical contribution?

Another observation I had is that other papers, that got accepted, were actually worse from the research methodologies and were previously published in similar form (so the idea was not very original) at that conference, so the “contribution” of these papers is much lower than mine would have been (again it’s just from my perspective). So I don’t understand why those papers got accepted and if the reviewer’s decisions actually make sense, what is it that makes such papers accepted? I aim at enhancing my now rejected papers because I still think they contain original ideas that should be published, I just don’t know where to start.
",user09123789542,https://academia.stackexchange.com/users/20106,"Since you ask those questions, I assume you are relatively new to CS research. I do not know if you have previous research experience in any other scientific area, but let's assume you are new to research all together. Correct me if I am wrong.

When your paper gets rejected, the feeling of rejection sucks. It sucks a lot. But in research you have to deal with this rejection and move-on. It does not matter if other people's works that you consider worse have been accepted. Maybe they are better than yours maybe not. But that is really irrelevant. Focus on your work and how to improve it. 

The questions you should be asking:


Is this problem you are trying to solve interesting? 
Is your solution substantially better than previous state-of-the-art? 
Are you certain that you described related and recent literature thoroughly? Are you up-to-date on related literature?
Did you make clear the benefits on your approach? 
Is your paper well presented  and written? Have you explained your approach thoroughly (with pseudocode, figures) and not just with words?
Were your experiments thorough? Did you use many datasets for your experiments? Have you used the datasets that the related papers use or at least similar if not bigger in size and scope? Have you compared your results with previous approaches? Have you many charts demonstrating the various aspects of your solution?
Have you advertised your work by finding many test-cases for your problem? 


If any of those answer is NO, then you must turn them to YES, before resubmitting your work. You must understand that if your paper or the problem you try to solve is boring, then it gets rejected. It is as simple as that. In that cases, the most usual reason for rejection is ""not enough contribution"". So, probably it is also your presentation that needs to be fixed.

Also, it seems rather strange that although you are probably new to research, you have submitted two papers at the same time. Perhaps this is too ambitious and it would be better to focus on one of them, improve it and resubmit it. Perhaps, they should be sent to different venues that are more tailored for each one of them. 

And last but not least. Do not worry. It gets better with time. Both the way you handle rejection and the way you write papers. So, improve what needs to be fixed and everything will work out.  
",Alexandros,https://academia.stackexchange.com/users/10042,http://academia.stackexchange.com/questions/26701/cs-paper-rejected-for-lack-of-technical-contribution-what-does-this-mean-and-h,LIFE_ARTS,academia.stackexchange.com,1.0,0.5555555555555556,0.0,0.0,0.0,0.3333333333333333,0.4444444444444444,0.3333333333333333,1.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.0,1.0,0.0,1.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.8,0.0,1.0,0.6666666666666666,1.0,CS documents are rejected for lack of technical contribution; what does this mean? How can I fix it?,"I recently got two papers rejected with the reviewers asserting a lack of technical contribution. They contained good ideas, at least in my eyes, and used common methodologies in the experimentation. So my question related to the CS field is, what is the difference between a good idea that was tested and a technical contribution? What should an idea have to become a technical contribution?

Another observation I had is that other papers, that got accepted, were actually worse from the research methodologies and were previously published in similar form (so the idea was not very original) at that conference, so the “contribution” of these papers is much lower than mine would have been (again it’s just from my perspective). So I don’t understand why those papers got accepted and if the reviewer’s decisions actually make sense, what is it that makes such papers accepted? I aim at enhancing my now rejected papers because I still think they contain original ideas that should be published, I just don’t know where to start.
","Since you ask those questions, I assume you are relatively new to CS research. I do not know if you have previous research experience in any other scientific area, but let's assume you are new to research all together. Correct me if I am wrong.

When your paper gets rejected, the feeling of rejection sucks. It sucks a lot. But in research you have to deal with this rejection and move-on. It does not matter if other people's works that you consider worse have been accepted. Maybe they are better than yours maybe not. But that is really irrelevant. Focus on your work and how to improve it. 

The questions you should be asking:


Is this problem you are trying to solve interesting? 
Is your solution substantially better than previous state-of-the-art? 
Are you certain that you described related and recent literature thoroughly? Are you up-to-date on related literature?
Did you make clear the benefits on your approach? 
Is your paper well presented  and written? Have you explained your approach thoroughly (with pseudocode, figures) and not just with words?
Were your experiments thorough? Did you use many datasets for your experiments? Have you used the datasets that the related papers use or at least similar if not bigger in size and scope? Have you compared your results with previous approaches? Have you many charts demonstrating the various aspects of your solution?
Have you advertised your work by finding many test-cases for your problem? 


If any of those answer is NO, then you must turn them to YES, before resubmitting your work. You must understand that if your paper or the problem you try to solve is boring, then it gets rejected. It is as simple as that. In that cases, the most usual reason for rejection is ""not enough contribution"". So, probably it is also your presentation that needs to be fixed.

Also, it seems rather strange that although you are probably new to research, you have submitted two papers at the same time. Perhaps this is too ambitious and it would be better to focus on one of them, improve it and resubmit it. Perhaps, they should be sent to different venues that are more tailored for each one of them. 

And last but not least. Do not worry. It gets better with time. Both the way you handle rejection and the way you write papers. So, improve what needs to be fixed and everything will work out.  
"
3488,3488,5567,Is it possible to add house numbers using the Mapbox Street Vector Tiles source in Tilemill2?,"Title says it all. Does anyony know if the house number is included in Mapbox’ vector tiles, and if so how to access it for styling? Thanks for any advice!
",Alexander Rutz,https://gis.stackexchange.com/users/27171,"Version 5 of the Mapbox Streets vector tiles includes the house number in a new layer.

I used the following to add them to the starting style:

#housenum_label {
  text-name: '[house_num]';
  text-face-name: @sans;
  text-fill: darken(#cde, 20%);
  text-size: 9;
}

",asherkin,https://gis.stackexchange.com/users/32966,http://gis.stackexchange.com/questions/95071/is-it-possible-to-add-house-numbers-using-the-mapbox-street-vector-tiles-source,TECHNOLOGY,gis.stackexchange.com,1.0,1.0,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,0.8888888888888888,Can I use the mapbox Street vector tiles source in tilemil2 to add a house number?,"The title says everything. Does anyone know if the house number is included in the vector block of the map box, and if so, how to access it for styling? Thank you for your advice!","Version 5 of the Mapbox Streets vector tiles includes the house number in a new layer.

I used the following to add them to the starting style:

#housenum_label {
  text-name: '[house_num]';
  text-face-name: @sans;
  text-fill: darken(#cde, 20%);
  text-size: 9;
}

"
1499,1499,2361,What is difference between SPContext.Current.Web.URL and SPContext.Current.Site when using SPSite object?,"SPSite spsite1=new SPSite(SPContext.Current.Web.URL);

SPSite spsite2=SPContext.Current.Site;


What is the difference and when do we decide which one to use?

I feel both give us the site collection object.

Example: SPWeb spweb=spsite1.RootWeb; will mean same as spsite2.RootWeb;  Then why are there 2 ways to do it?
",variable,https://sharepoint.stackexchange.com/users/21463,"SPSite spsite1=new SPSite(SPContext.Current.Web.Url); will give you SPSite object. But it will be site collection object only when SPContext.Current.Web.Url is that of root web. If the web object is that of a sub site then SPSite object won't be a site collection object. The second statement SPSite spsite2=new SPSite(SPContext.Current.Site); is wrong because there is no overload of SPSite which has SPSite as parameter.   

UPDATE

If the intention is to get the rootweb then second is a better way of doing it as you are not instantiating a new SPSite object. Moreover, in the first case you will need to dispose SPSite object as you are creating a new one compared to second in which SPSite is retrieved through SPContext which should not be disposed explicitly.
",Nadeem Yousuf,https://sharepoint.stackexchange.com/users/9472,http://sharepoint.stackexchange.com/questions/95812/what-is-difference-between-spcontext-current-web-url-and-spcontext-current-site,TECHNOLOGY,sharepoint.stackexchange.com,1.0,0.8888888888888888,0.0,1.0,1.0,1.0,0.5555555555555556,0.5555555555555556,0.3333333333333333,0.0,0.3333333333333333,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.3333333333333333,1.0,0.8888888888888888,What is the difference between spcontext.current.web.url and spcontext.current.site when using spsite objects?,"SPSite spsite1=new SPSite(SPContext.Current.Web.URL);

SPSite spsite2=SPContext.Current.Site;


What is the difference and when do we decide which one to use?

I feel both give us the site collection object.

Example: SPWeb spweb=spsite1.RootWeb; will mean same as spsite2.RootWeb;  Then why are there 2 ways to do it?
","SPSite spsite1=new SPSite(SPContext.Current.Web.Url); will give you SPSite object. But it will be site collection object only when SPContext.Current.Web.Url is that of root web. If the web object is that of a sub site then SPSite object won't be a site collection object. The second statement SPSite spsite2=new SPSite(SPContext.Current.Site); is wrong because there is no overload of SPSite which has SPSite as parameter.   

UPDATE

If the intention is to get the rootweb then second is a better way of doing it as you are not instantiating a new SPSite object. Moreover, in the first case you will need to dispose SPSite object as you are creating a new one compared to second in which SPSite is retrieved through SPContext which should not be disposed explicitly.
"
1033,1033,1625,Does the a gasoline or diesel engine appy fuel at high speeds when not pressing the pedal and more,"Let say I directly connect a small engine to my bicycle, and that I'm superman who can overcome any force.
Then I start cycling (using my legs...) - the engine starts to rotate, even though I haven't ""started it"" using the switch.

Does it mean that if I press the pedal (or whatever) of the engine, it will apply force? Either on a diesel or a gasoline engine.

Another question: Lets say I'm driving down a hill in a relatively high speed in a car, and I'm not pressing the gas pedal at all. Does the engine burn fuel at all, in both diesel and gas? If I (while in gear) turn off the engine, will something actually happen? If I would press the pedal after turning it off (while it still rotates) - will it apply force? (in both diesel and gas).

If, while driving, I disconnected the idler (i.e the engine won't apply any force if I'm not pressing the pedal at any RPM and pressing the clutch will take it to zero RPM) and press the brake until I get to a complete stop, will the engine ""stall""? If I'm doing it in a hill facing down, after releasing the brakes I'd accelerate and the engine would gain RPMs, will it be able to continue applying force?

Finally: What's the difference between a ""running engine"" and one thats not running, assuming both are rotating?

I'm sorry if I'm asking too much so if you would at least explain the principle I'd be very happy. Thank you!
",Mark Segal,https://mechanics.stackexchange.com/users/3112,"I will explain it for an EFI engine with a manual transmission because it might not be as straight forward with a carbureted engine or automatic.

For ease of explaining this I will consider the engine as ""on"" whenever the ignition switch is set to the ""on"" state. This means that the ECU is on and is monitoring the engine state and controlling it's behavior. 

For the bicycle example with an EFI engine if you had your ""ignition"" to on while you started cycling then the ecu would start to inject fuel and cause spark so yes it would apply force and use fuel. If the ignition were off then the ecu would be off and you wouldn't get any fuel or spark so no you won't get any force if you apply the accelerator.

Going downhill not pressing the accelerator with the ignition on will use significantly less fuel (not sure if the ecu uses zero fuel though) and the engine will still be sparking for sure. If you were to turn the ignition to accessory while coasting downhill the ecu will shut off and you will stop injecting fuel and stop spark as well so the accelerator would no longer do anything.

If you have the clutch in and you stop the engine will stop. If you then release the brakes and roll down a hill then one of two things will happen.

1) if your ecu is on (ingition on) then the engine will start to use fuel and spark. (It will be really rough until it gets to ~700rpm)
2) if your ecu is off then the engine will rotate but no fuel or spark so therefore no acceleration.

Finally the difference between a running engine and not if they are both spinning :

A running engine is one which can continue to run from the energy it is producing without an external force. Modern engines require fuel air and spark to satisfy this requirement. eg. ECU on and rotating

An engine is off if when all external forces are removed then engine would stop. eg. the ecu is off so the engine isn't producing any of its own power and is only spinning because it is connected to wheels that are being accelerated by gravity.

Hope this clarifies it somewhat....
",Mike Saull,https://mechanics.stackexchange.com/users/2895,http://mechanics.stackexchange.com/questions/6612/does-the-a-gasoline-or-diesel-engine-appy-fuel-at-high-speeds-when-not-pressing,CULTURE,mechanics.stackexchange.com,0.7777777777777778,0.5555555555555556,0.0,0.3333333333333333,1.0,1.0,0.7777777777777778,0.6666666666666666,0.6666666666666666,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.7777777777777778,0.8888888888888888,0.8333333333333334,0.8888888888888888,1.0,1.0,0.0,0.0,1.0,1.0,"Whether the gasoline engine or diesel engine refuels at high speed without stepping on the pedal, etc","Let say I directly connect a small engine to my bicycle, and that I'm superman who can overcome any force.
Then I start cycling (using my legs...) - the engine starts to rotate, even though I haven't ""started it"" using the switch.

Does it mean that if I press the pedal (or whatever) of the engine, it will apply force? Either on a diesel or a gasoline engine.

Another question: Lets say I'm driving down a hill in a relatively high speed in a car, and I'm not pressing the gas pedal at all. Does the engine burn fuel at all, in both diesel and gas? If I (while in gear) turn off the engine, will something actually happen? If I would press the pedal after turning it off (while it still rotates) - will it apply force? (in both diesel and gas).

If, while driving, I disconnected the idler (i.e the engine won't apply any force if I'm not pressing the pedal at any RPM and pressing the clutch will take it to zero RPM) and press the brake until I get to a complete stop, will the engine ""stall""? If I'm doing it in a hill facing down, after releasing the brakes I'd accelerate and the engine would gain RPMs, will it be able to continue applying force?

Finally: What's the difference between a ""running engine"" and one thats not running, assuming both are rotating?

I'm sorry if I'm asking too much so if you would at least explain the principle I'd be very happy. Thank you!
","I will explain it for an EFI engine with a manual transmission because it might not be as straight forward with a carbureted engine or automatic.

For ease of explaining this I will consider the engine as ""on"" whenever the ignition switch is set to the ""on"" state. This means that the ECU is on and is monitoring the engine state and controlling it's behavior. 

For the bicycle example with an EFI engine if you had your ""ignition"" to on while you started cycling then the ecu would start to inject fuel and cause spark so yes it would apply force and use fuel. If the ignition were off then the ecu would be off and you wouldn't get any fuel or spark so no you won't get any force if you apply the accelerator.

Going downhill not pressing the accelerator with the ignition on will use significantly less fuel (not sure if the ecu uses zero fuel though) and the engine will still be sparking for sure. If you were to turn the ignition to accessory while coasting downhill the ecu will shut off and you will stop injecting fuel and stop spark as well so the accelerator would no longer do anything.

If you have the clutch in and you stop the engine will stop. If you then release the brakes and roll down a hill then one of two things will happen.

1) if your ecu is on (ingition on) then the engine will start to use fuel and spark. (It will be really rough until it gets to ~700rpm)
2) if your ecu is off then the engine will rotate but no fuel or spark so therefore no acceleration.

Finally the difference between a running engine and not if they are both spinning :

A running engine is one which can continue to run from the energy it is producing without an external force. Modern engines require fuel air and spark to satisfy this requirement. eg. ECU on and rotating

An engine is off if when all external forces are removed then engine would stop. eg. the ecu is off so the engine isn't producing any of its own power and is only spinning because it is connected to wheels that are being accelerated by gravity.

Hope this clarifies it somewhat....
"
3028,3028,4827,The graph has an Euler tour iff in-degree($v$)=out-degree($v$),"I am looking at the proof that $G$ has an Euler tour iff in-degree($v$)=out-degree($v$), that I found at this site: www.cs.duke.edu/courses/fall09/cps230/hws/hw3/headsol.pdf  (Problem 2)

A simple cycle is a path in a graph that starts and ends at the same vertex without passing through the same vertex more than once.

A complex cycle is a cycle that passes through the same vertex more than once. We can easily decompose a complex cycle to a set of simple cycles by breaking up the cycle at those points where the cycle passes through the same vertex more than once.

As the first part of our proof, we will prove that if $G$ has an Euler tour, in-degree($v$)=out-degree($v$) for each vertex $v \in V$.

We have already established that a complex cycle can be decomposed to a collection of simple cycles. However vertices on a simple cycle have in-degree($v$)=out-degree($v$)=1.

Since each vertex in a complex cycle, and therefore in an Euler tour, is part of one or more simple cycles it will have in-degree($v$)=out-degree($v$).


Could you give me an example of a complex cycle that is decomposed to a set of simple cycles, where we can see that in-degree($v$)=out-degree($v$)?


The second part of our proof requires us to prove that if in-degree($v$)=out-degree($v$) for each vertex $v \in V$, $G$ has an Euler-tour.

Let $C$ be the complex cycle involving the most edges in $G$.

In order for $G$ not to be an Euler tour, there must be some vertices that $C$ passes through ( since the graph is connected ) but does not exhaust all edges. We have already established that the vertices of a complex cycle have the property that in-degree($v$)=out-degree($v$). Therefore $G'=G-C$ will also have that property. If a connected component in a graph has in-degree($v$)=out-degree($v$) then it contains at least one cycle $C'$. However this contradicts our initial hypothesis that $C$ is the cycle involving the most edges in $G$ since we would construct a larger cycle by starting at some common vertex of $C$ and $C'$, traversing all of $C$s edges and then $C'$s edges. Therefore $C$ is an Euler tour.


First of all, it says that ""In order for $G$ not to be an Euler tour, there must be some vertices that $C$ passes through ( since the graph is connected ) but does not exhaust all edges. "" 


I haven't understood why we have to show that $G$ does not exhaust all edges. In order for $G$ not to be an Euler tour, couldn't it also hold that  $G$ traverses an edge more than once?

Then it says that ""We have already established that the vertices of a complex cycle have the property that in-degree($v$)=out-degree($v$). Therefore $G'=G-C$ will also have that property.""

Why will $G'=G-C$ be a complex cycle, although $G$ isn't necessarily?

Also, could you explain me why it holds that: "" If a connected component in a graph has in-degree($v$)=out-degree($v$) then it contains at least one cycle $C'$.""

Finally, could you explain me the contradiction?

EDIT: I also want to describe an algorithm that runs in time $O(E)$ and finds an Euler tour of $G$, if it exists. (Hint: Merge edge-disjoint cycles.) 
If we apply DFS, we will get a set of cycles formed by disjoint sets of edges, right? But how can we know if it holds that in-degree(v)=out-degree(v), for all vertices in $V$?

Do we have to do something like that?  algorithm
",evinda,https://math.stackexchange.com/users/75843,"In a simple cycle the in degree and the out degree are both one, so if we add to some simple cycle another simple cycle at some vertex, the in degree and the out degree of the vertex will increase both by 1. 

You got some wrong concept on $G'$, it is not a complex cycle in fact it doesn't even need to be connected. As we defined cycles in my (algorithmic) dicrete math classes we said that every edge may be traversed at most once so it is not possible that $C$ is a complex cycle which traverses one edge more than once. 

So the idea is more that there must be some complex cycle which passes trough every vertex, because your graph is connected, and if uses every edge it is an euler tour. So we take the complex cycle with most edges, and look at $G'=G-C$, as the in degree of some vertex in $G'$ is the in degree of the vertex in $G$ minus the in degree of the vertex in $C$ and the same for the out degrees the graph $G'$ does still have the property, that the in degrees coincide with the out degrees. But if those degrees aren't all $0$ we could add some cycle to $C$ which would result in some complex cycle with more edges, which is some contradiction to our assumption, that $C$ does have the most edges.
",Dominic Michaelis,https://math.stackexchange.com/users/62278,http://math.stackexchange.com/questions/1249979/the-graph-has-an-euler-tour-iff-in-degreev-out-degreev,SCIENCE,math.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.4444444444444444,1.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,1.0,0.0,0.6666666666666666,1.0,0.5555555555555556,1.0,1.0,0.8666666666666666,0.0,0.0,1.0,1.0,The graph has an Euler tour IFF in degree ($V $) = out degree ($V $),"I am looking at the proof that $G$ has an Euler tour iff in-degree($v$)=out-degree($v$), that I found at this site: www.cs.duke.edu/courses/fall09/cps230/hws/hw3/headsol.pdf  (Problem 2)

A simple cycle is a path in a graph that starts and ends at the same vertex without passing through the same vertex more than once.

A complex cycle is a cycle that passes through the same vertex more than once. We can easily decompose a complex cycle to a set of simple cycles by breaking up the cycle at those points where the cycle passes through the same vertex more than once.

As the first part of our proof, we will prove that if $G$ has an Euler tour, in-degree($v$)=out-degree($v$) for each vertex $v \in V$.

We have already established that a complex cycle can be decomposed to a collection of simple cycles. However vertices on a simple cycle have in-degree($v$)=out-degree($v$)=1.

Since each vertex in a complex cycle, and therefore in an Euler tour, is part of one or more simple cycles it will have in-degree($v$)=out-degree($v$).


Could you give me an example of a complex cycle that is decomposed to a set of simple cycles, where we can see that in-degree($v$)=out-degree($v$)?


The second part of our proof requires us to prove that if in-degree($v$)=out-degree($v$) for each vertex $v \in V$, $G$ has an Euler-tour.

Let $C$ be the complex cycle involving the most edges in $G$.

In order for $G$ not to be an Euler tour, there must be some vertices that $C$ passes through ( since the graph is connected ) but does not exhaust all edges. We have already established that the vertices of a complex cycle have the property that in-degree($v$)=out-degree($v$). Therefore $G'=G-C$ will also have that property. If a connected component in a graph has in-degree($v$)=out-degree($v$) then it contains at least one cycle $C'$. However this contradicts our initial hypothesis that $C$ is the cycle involving the most edges in $G$ since we would construct a larger cycle by starting at some common vertex of $C$ and $C'$, traversing all of $C$s edges and then $C'$s edges. Therefore $C$ is an Euler tour.


First of all, it says that ""In order for $G$ not to be an Euler tour, there must be some vertices that $C$ passes through ( since the graph is connected ) but does not exhaust all edges. "" 


I haven't understood why we have to show that $G$ does not exhaust all edges. In order for $G$ not to be an Euler tour, couldn't it also hold that  $G$ traverses an edge more than once?

Then it says that ""We have already established that the vertices of a complex cycle have the property that in-degree($v$)=out-degree($v$). Therefore $G'=G-C$ will also have that property.""

Why will $G'=G-C$ be a complex cycle, although $G$ isn't necessarily?

Also, could you explain me why it holds that: "" If a connected component in a graph has in-degree($v$)=out-degree($v$) then it contains at least one cycle $C'$.""

Finally, could you explain me the contradiction?

EDIT: I also want to describe an algorithm that runs in time $O(E)$ and finds an Euler tour of $G$, if it exists. (Hint: Merge edge-disjoint cycles.) 
If we apply DFS, we will get a set of cycles formed by disjoint sets of edges, right? But how can we know if it holds that in-degree(v)=out-degree(v), for all vertices in $V$?

Do we have to do something like that?  algorithm
","In a simple cycle the in degree and the out degree are both one, so if we add to some simple cycle another simple cycle at some vertex, the in degree and the out degree of the vertex will increase both by 1. 

You got some wrong concept on $G'$, it is not a complex cycle in fact it doesn't even need to be connected. As we defined cycles in my (algorithmic) dicrete math classes we said that every edge may be traversed at most once so it is not possible that $C$ is a complex cycle which traverses one edge more than once. 

So the idea is more that there must be some complex cycle which passes trough every vertex, because your graph is connected, and if uses every edge it is an euler tour. So we take the complex cycle with most edges, and look at $G'=G-C$, as the in degree of some vertex in $G'$ is the in degree of the vertex in $G$ minus the in degree of the vertex in $C$ and the same for the out degrees the graph $G'$ does still have the property, that the in degrees coincide with the out degrees. But if those degrees aren't all $0$ we could add some cycle to $C$ which would result in some complex cycle with more edges, which is some contradiction to our assumption, that $C$ does have the most edges.
"
2789,2789,4446,"Do Jews view Scripture as the ""word of God""?","I am curious whether Jews view Scripture (i.e. the Tanach) as ""the word of God,"" and if so, in what way? Is it ""inspired"" by God? Is it a ""product of the Spirit of God""? Is God the ""Author""? [etc.]

In other words, what was God's role in the production of Scripture from a Jewish perspective?
",Jas 3.1,https://judaism.stackexchange.com/users/2657,"The traditional view:

The Jewish Scripture, i.e. Tanakh, is made of 3 parts.

The first part is the ""Chumash"", the five books of Moses. They were dictated word-by-word from G-d, and Moses wrote them down. (Now most of Deuteronomy is a big speech of Moses, but even so, after the fact that's what he was ordered to transcribe.) The last few verses describe Moses' death; either G-d dictated them to Joshua (Moses' successor), or Moses had to write them in advance (which must not have been fun).

Just because they are the word of G-d does not mean they were intended literally; some legal material was left unclear and was accompanied by an oral interpretation, and some of the stories involving angels may have occurred during dreams or prophetic experiences. That doesn't make it any less divine.

The Prophets (Joshua, Judges, Isaiah, Jeremiah, etc.) had a lower level of prophecy than Moses. Often it would involve a vision that they had to interpret; the Talmud observes that two prophets could have the same prophecy and while the overall message they would convey would be the same, the choice of words they would use would be different. Thus we would view the words of Isaiah as sacred and the message as being from G-d, but not the same word-for-word ""authorship"" compared to the first five books.

The other Writings (Psalms, Proverbs, Song of Songs, etc.) were the product of divine inspiration, but not above the threshold of what we'd call ""prophecy."" (~2000 years ago it was even debated whether Ecclesiastes was truly divinely inspired or simply a great work of wisdom. It got the upvote in the end and it's included in Tanakh!)
",Shalom,https://judaism.stackexchange.com/users/21,http://judaism.stackexchange.com/questions/29780/do-jews-view-scripture-as-the-word-of-god,CULTURE,judaism.stackexchange.com,1.0,0.7777777777777778,0.0,1.0,1.0,0.6666666666666666,0.5555555555555556,0.6666666666666666,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,0.8888888888888888,"Do Jews think the Bible is ""the way of God""?","I wonder if Jews think the Bible (i.e. tanaceh) is ""the word of God."" if so, in what way? Is it God's ""Revelation""? Is it the product of the spirit of God? Is God the author? [etc.]","The traditional view:

The Jewish Scripture, i.e. Tanakh, is made of 3 parts.

The first part is the ""Chumash"", the five books of Moses. They were dictated word-by-word from G-d, and Moses wrote them down. (Now most of Deuteronomy is a big speech of Moses, but even so, after the fact that's what he was ordered to transcribe.) The last few verses describe Moses' death; either G-d dictated them to Joshua (Moses' successor), or Moses had to write them in advance (which must not have been fun).

Just because they are the word of G-d does not mean they were intended literally; some legal material was left unclear and was accompanied by an oral interpretation, and some of the stories involving angels may have occurred during dreams or prophetic experiences. That doesn't make it any less divine.

The Prophets (Joshua, Judges, Isaiah, Jeremiah, etc.) had a lower level of prophecy than Moses. Often it would involve a vision that they had to interpret; the Talmud observes that two prophets could have the same prophecy and while the overall message they would convey would be the same, the choice of words they would use would be different. Thus we would view the words of Isaiah as sacred and the message as being from G-d, but not the same word-for-word ""authorship"" compared to the first five books.

The other Writings (Psalms, Proverbs, Song of Songs, etc.) were the product of divine inspiration, but not above the threshold of what we'd call ""prophecy."" (~2000 years ago it was even debated whether Ecclesiastes was truly divinely inspired or simply a great work of wisdom. It got the upvote in the end and it's included in Tanakh!)
"
3588,3588,5730,Is a Photoshop EPS file a vector format?,"If I save my file from Photoshop as a Photoshop EPS is that going to be okay as a vector across the board (ie will it be resizeable in whatever it's opened in)? I know if you open a .psd in Photoshop and resize the image, it holds it's quality, so that's fine, but when people need an EPS file because they might want to print it on the side of a building one day (or whatever) is a Photoshop EPS going to be okay? Or is there something else I need to be doing? 

All my designs are always vectors within Photoshop, so text/shapes/designs done with the pen tool - I just need to know that they'll still be a vector for people who don't have Photoshop and can't open it in there to resize it.
",Willow,https://graphicdesign.stackexchange.com/users/3494,"To a degree.....

With the exception of Live Type, Photoshop creates vector containers with raster fills. What this means is the edges of shape layers will remain crisp and clear when resized because the shape/vector layer edge is saved as a vector and it is recalculated when resized.

However, what is inside the shape layer is not vector. For example, if you create a shape/vector layer and then apply a pattern overlay, an inner glow, and a drop shadow, all those layer styles are not vector and will not scale infinitely. Layer styles are always raster and are bound by raster limitations.

Live type is vector and will remain vector and scalable when used in a Photoshop file and saved as an EPS. However, at times live type can be converted to outlines in eps files to maintain appearance. When converted to outlines, the type loses it's hinting properties and although it is vector, it may not look ideal at smaller sizes. Type is generally not a problem for anything above 12-14 points though.

As DA01 pointed out, eps is merely a file wrapper. Simply saving as an eps does not mean something is vector. EPS can contain 100% raster content or 100% vector content or a mix of the two. When using Photoshop, you always get a mix of the two if you have type and/or shape/vector layers. It is not possible to create a true vector file with any version Photoshop regardless of what you do.
",Scott,https://graphicdesign.stackexchange.com/users/3270,http://graphicdesign.stackexchange.com/questions/7726/is-a-photoshop-eps-file-a-vector-format,LIFE_ARTS,graphicdesign.stackexchange.com,1.0,0.4444444444444444,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.5555555555555556,0.6666666666666666,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,0.6666666666666666,1.0,Is Photoshop EPS file in vector format?,"If I save the files in Photoshop as Photoshop's EPS, then, as a vector, can it be resized in all open files? I know if you open a. PSD in Photoshop and resize the image, it will keep the quality of the image, so that's good, but when people need an EPS file, because they may want to print it one day on one side of the building (or somewhere else), will Photoshop EPS be good? Or do I have anything else to do?","To a degree.....

With the exception of Live Type, Photoshop creates vector containers with raster fills. What this means is the edges of shape layers will remain crisp and clear when resized because the shape/vector layer edge is saved as a vector and it is recalculated when resized.

However, what is inside the shape layer is not vector. For example, if you create a shape/vector layer and then apply a pattern overlay, an inner glow, and a drop shadow, all those layer styles are not vector and will not scale infinitely. Layer styles are always raster and are bound by raster limitations.

Live type is vector and will remain vector and scalable when used in a Photoshop file and saved as an EPS. However, at times live type can be converted to outlines in eps files to maintain appearance. When converted to outlines, the type loses it's hinting properties and although it is vector, it may not look ideal at smaller sizes. Type is generally not a problem for anything above 12-14 points though.

As DA01 pointed out, eps is merely a file wrapper. Simply saving as an eps does not mean something is vector. EPS can contain 100% raster content or 100% vector content or a mix of the two. When using Photoshop, you always get a mix of the two if you have type and/or shape/vector layers. It is not possible to create a true vector file with any version Photoshop regardless of what you do.
"
5913,5913,9368,Why is my fuse board buzzing when I'm using the shower?,"I have used an electric shower for years no problems, but all of a sudden my fuse board started buzzing when I use the shower. I replaced the shower with the same size unit and it still makes a buzzing noise.

I have checked all the wires and they are tight and well connected. I changed the old cartridge fuse for an mcb 40amp fuse, and still it makes a buzzing noise.

Is this a sign that my wylex fuse board needs changing?
",Gerry Cheverton,https://diy.stackexchange.com/users/9251,"Any time you have buzzing coming out of a fuse panel or breaker panel, you need to get a qualified electrician in immediately to find out what's going on. 

These things contain large buss bars and depending on your local electrical code, unfused power entry. Any minor loss of connection integrity that causes a loose connection anywhere whether it's inside a breaker, where the breaker/fuse attaches to the buss bars, broken buss bar insulation stand-offs or in the cable connection to the bars can unleash an arc in the 8000-10000 degree F range that burns through metal and instantly sets fire to any wood surrounds that heat gets transmitted into.

The best demonstration of the power of 220V (which did not blow the 50A range fuse) was a cook stove that had a weak spot develop in the element. It glowed bright orange in the break, burst into arc and burnt through the muffin tin my mother threw on it to contain the arc flame. The ion plume reached the ceiling and scorched a 3"" dia area black. A water heater pulls enough current to cause such an arc wherever there's a loose connection.
",Fiasco Labs,https://diy.stackexchange.com/users/7020,http://diy.stackexchange.com/questions/20894/why-is-my-fuse-board-buzzing-when-im-using-the-shower,LIFE_ARTS,diy.stackexchange.com,1.0,0.7777777777777778,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.4444444444444444,0.6666666666666666,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.6666666666666666,0.0,1.0,1.0,Why is the fuse panel buzzing when I take a bath?,"I have used an electric shower for years no problems, but all of a sudden my fuse board started buzzing when I use the shower. I replaced the shower with the same size unit and it still makes a buzzing noise.

I have checked all the wires and they are tight and well connected. I changed the old cartridge fuse for an mcb 40amp fuse, and still it makes a buzzing noise.

Is this a sign that my wylex fuse board needs changing?
","Any time you have buzzing coming out of a fuse panel or breaker panel, you need to get a qualified electrician in immediately to find out what's going on. 

These things contain large buss bars and depending on your local electrical code, unfused power entry. Any minor loss of connection integrity that causes a loose connection anywhere whether it's inside a breaker, where the breaker/fuse attaches to the buss bars, broken buss bar insulation stand-offs or in the cable connection to the bars can unleash an arc in the 8000-10000 degree F range that burns through metal and instantly sets fire to any wood surrounds that heat gets transmitted into.

The best demonstration of the power of 220V (which did not blow the 50A range fuse) was a cook stove that had a weak spot develop in the element. It glowed bright orange in the break, burst into arc and burnt through the muffin tin my mother threw on it to contain the arc flame. The ion plume reached the ceiling and scorched a 3"" dia area black. A water heater pulls enough current to cause such an arc wherever there's a loose connection.
"
3288,3288,5241,What is the likelihood of ever discovering the graviton?,"How would one look for and confirm existence of a graviton?

Someone was speaking to me about perhaps one day discovering the graviton, but to me it seems unlikely, although I'm young and essentially quite naive, so am coming to you physicists to ask 


What actually is the likelihood of finding it? 
How would we find it?

",ODP,https://physics.stackexchange.com/users/8082,"Unfortunately, no physically reasonable detector could ever detect gravitons.  For example, a detector with the mass of Jupiter placed in close orbit around a neutron star would only be expected to observe one graviton every 10 years (see the below paper). The few that would be detected would be indistinguishable from the background 'noise', i.e. neutrinos.

See here:

http://arxiv.org/abs/gr-qc/0601043

Even though we can't detect individual gravitons, gravitational wave detectors may shed some light on them, since the graviton is the quantum of the gravitational wave (similar to how early 20th century physicists studied the nature of the photon based on properties of light, such as the photoelectric effect.).
",Mark M,https://physics.stackexchange.com/users/11176,http://physics.stackexchange.com/questions/34118/what-is-the-likelihood-of-ever-discovering-the-graviton,SCIENCE,physics.stackexchange.com,0.7777777777777778,0.8888888888888888,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,0.7777777777777778,0.6666666666666666,1.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,1.0,How likely is it to find a graviton?,"How would one look for and confirm existence of a graviton?

Someone was speaking to me about perhaps one day discovering the graviton, but to me it seems unlikely, although I'm young and essentially quite naive, so am coming to you physicists to ask 


What actually is the likelihood of finding it? 
How would we find it?

","Unfortunately, no physically reasonable detector could ever detect gravitons.  For example, a detector with the mass of Jupiter placed in close orbit around a neutron star would only be expected to observe one graviton every 10 years (see the below paper). The few that would be detected would be indistinguishable from the background 'noise', i.e. neutrinos.

See here:

http://arxiv.org/abs/gr-qc/0601043

Even though we can't detect individual gravitons, gravitational wave detectors may shed some light on them, since the graviton is the quantum of the gravitational wave (similar to how early 20th century physicists studied the nature of the photon based on properties of light, such as the photoelectric effect.).
"
5395,5395,8570,Identify my Motobécane racing bike,"I bought a Motobécane last year (pics below), and now that the bottom bracket is broken, I really need to know the model of the bike, to help me change that piece.

It would also be helpful if someone could redirect me to the Motobécane catalogs of the years 82, 83, I can't find them, and I suspect my bike is from this period.

Technical specifications:


frame color: green and black (How customizable was that? I think they didn't sell the same colors each year)
frame: tubing inexternal 707, ""trainer"" (I don't find the appropriate info about it)
brakes: Weinmann
derailleur: Sachs - Huret. 12 gears
Wheel: Maillard
Bottom Crank: ?? width of the shell: 74mm. From this page http://sheldonbrown.com/vrbn-g-n.html, the old french ones have special dimensions. Also on Motobécane, they are swiss type (left-threaded). I don't know if this is a cotterless one, shimano octalink, or if I can put something more standard?


[EDIT: As suggested by @Blam, I took the bottom bracket out.
First mistake: shell width doesn't correspond to the red line on the pic, but less, so width should be 68mm, I'll double check on the bike.
The Brand is Stronglight, french brand, but the threading is the normal one (left-threaded on the right side, and right-threaded on the left side).
The axle is 120mm long, tapered square. Like this model: http://www.ebay.com/itm/VP-Components-Bottom-Bracket-120mm-Square-Taper-Unsealed-Bike-NEW-/311359596201?pt=LH_DefaultDomain_0&amp;hash=item487e7a66a9

But anyway, I'm still interested in knowing the model of this bike, and/or finding the Motobécane catalogues of years 1982-83]

Important Note: The rear wheel is not the original (was broken). I also changed the part of the crank where I put the feet when I bought it (maybe I shouldn't have...). 

Sorry if it looks quite dirty, I didn't have time to clean.

Pics:











",PlasmaBinturong,https://bicycles.stackexchange.com/users/19414,"Small correction, my mistake should have read "" ""MBK Trainer"" on the down tube "" .. (but with a Motobecane Badge on the Steerer, some also with Motobecane in smaller letters on the top tube). Checked a couple of the searches I had, you truly have a confounding model. Hi-Ten, Cro-Mo, Motolite, 2040, one states Vitus tubes, but I can't read the sticker to verify it. Some with proper lugs on the steerer, some with ""inexternal"". I wonder if they were using up stock, after many of the older established models were discontinued after 84. 

Fwiw, as long as you are happy with the weight and feel of the bike, nothing wrong with Hi-Ten. As long as I'm only on paved surfaces, I still enjoy loaded touring with a 76 Super Mirage with lowly 1020 tubing. The only bike I've always kept, still very comfortable at the end of long days in the saddle.

Motobecane stared phasing out the Swiss BBs in the early eighties, you are lucky not to have one, tough to find and expensive, the Mirage unfortunately does. Many report good result with the BSA BBs for stripped threads. Mine was in need and was lucky and found one incorrectly listed as French on the bay, I hope I will never need another. 

Geo
",Geo,https://bicycles.stackexchange.com/users/20354,http://bicycles.stackexchange.com/questions/30473/identify-my-motob%C3%A9cane-racing-bike,CULTURE,bicycles.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.4444444444444444,0.6666666666666666,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.8333333333333334,0.8888888888888888,0.7,0.0,0.0,0.0,0.8888888888888888,Identify my motorcycle,"I bought a Motobécane last year (pics below), and now that the bottom bracket is broken, I really need to know the model of the bike, to help me change that piece.

It would also be helpful if someone could redirect me to the Motobécane catalogs of the years 82, 83, I can't find them, and I suspect my bike is from this period.

Technical specifications:


frame color: green and black (How customizable was that? I think they didn't sell the same colors each year)
frame: tubing inexternal 707, ""trainer"" (I don't find the appropriate info about it)
brakes: Weinmann
derailleur: Sachs - Huret. 12 gears
Wheel: Maillard
Bottom Crank: ?? width of the shell: 74mm. From this page http://sheldonbrown.com/vrbn-g-n.html, the old french ones have special dimensions. Also on Motobécane, they are swiss type (left-threaded). I don't know if this is a cotterless one, shimano octalink, or if I can put something more standard?


[EDIT: As suggested by @Blam, I took the bottom bracket out.
First mistake: shell width doesn't correspond to the red line on the pic, but less, so width should be 68mm, I'll double check on the bike.
The Brand is Stronglight, french brand, but the threading is the normal one (left-threaded on the right side, and right-threaded on the left side).
The axle is 120mm long, tapered square. Like this model: http://www.ebay.com/itm/VP-Components-Bottom-Bracket-120mm-Square-Taper-Unsealed-Bike-NEW-/311359596201?pt=LH_DefaultDomain_0&amp;hash=item487e7a66a9

But anyway, I'm still interested in knowing the model of this bike, and/or finding the Motobécane catalogues of years 1982-83]

Important Note: The rear wheel is not the original (was broken). I also changed the part of the crank where I put the feet when I bought it (maybe I shouldn't have...). 

Sorry if it looks quite dirty, I didn't have time to clean.

Pics:











","Small correction, my mistake should have read "" ""MBK Trainer"" on the down tube "" .. (but with a Motobecane Badge on the Steerer, some also with Motobecane in smaller letters on the top tube). Checked a couple of the searches I had, you truly have a confounding model. Hi-Ten, Cro-Mo, Motolite, 2040, one states Vitus tubes, but I can't read the sticker to verify it. Some with proper lugs on the steerer, some with ""inexternal"". I wonder if they were using up stock, after many of the older established models were discontinued after 84. 

Fwiw, as long as you are happy with the weight and feel of the bike, nothing wrong with Hi-Ten. As long as I'm only on paved surfaces, I still enjoy loaded touring with a 76 Super Mirage with lowly 1020 tubing. The only bike I've always kept, still very comfortable at the end of long days in the saddle.

Motobecane stared phasing out the Swiss BBs in the early eighties, you are lucky not to have one, tough to find and expensive, the Mirage unfortunately does. Many report good result with the BSA BBs for stripped threads. Mine was in need and was lucky and found one incorrectly listed as French on the bay, I hope I will never need another. 

Geo
"
4492,4492,7122,"How do indirect, session-specific resource tokens increase security?","The OWASP web site recommends this:


Use per user or session indirect object references. This prevents attackers from directly targeting unauthorized resources. For example, instead of using the resource’s database key, a drop down list of six resources authorized for the current user could use the numbers 1 to 6 to indicate which value the user selected. [italics mine]
Check access. Each use of a direct object reference from an untrusted source must include an access control check to ensure the user is authorized for the requested object. [italics mine]


So if a user doesn't have access to the requested resource, how does obfuscating the direct object reference improve security?

Given the increased complexity that, say, an ASP.NET MVC site would accrue, is this worth the additional trouble for anything but banking sites?
",Robert Harvey,https://security.stackexchange.com/users/2709,"I think you defined a reference object as an absolute and associated with finance. How about the following: You are a software vendor, your sw if sold online after a visitor purchases it. Wouldn't you prefer that ONLY the purchaser be able to access a hyperlink for your product?

Forget the financial (banking sites) or even software, what about say a social network. ""Back in the days"" if you sniffed the wire, it was a known fact you could pull out the URIs from the tcp capture, open it in a browser, and you had instant access to email, social network components, etc.

There are plenty of different scenarios you'd need it. Think about it for what it is: ""Insecure Direct Object"" an object directly accessible and cannot be secured for whatever reason. We need to secure it by assigning it a ""reference"" so it can never be ""directly named.""
",munkeyoto,https://security.stackexchange.com/users/26299,http://security.stackexchange.com/questions/38777/how-do-indirect-session-specific-resource-tokens-increase-security,TECHNOLOGY,security.stackexchange.com,1.0,0.4444444444444444,0.0,1.0,1.0,1.0,0.5555555555555556,0.6666666666666666,0.6666666666666666,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,1.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.3333333333333333,1.0,0.8888888888888888,"How can indirect, session specific resource tokens improve security?","The OWASP web site recommends this:


Use per user or session indirect object references. This prevents attackers from directly targeting unauthorized resources. For example, instead of using the resource’s database key, a drop down list of six resources authorized for the current user could use the numbers 1 to 6 to indicate which value the user selected. [italics mine]
Check access. Each use of a direct object reference from an untrusted source must include an access control check to ensure the user is authorized for the requested object. [italics mine]


So if a user doesn't have access to the requested resource, how does obfuscating the direct object reference improve security?

Given the increased complexity that, say, an ASP.NET MVC site would accrue, is this worth the additional trouble for anything but banking sites?
","I think you defined a reference object as an absolute and associated with finance. How about the following: You are a software vendor, your sw if sold online after a visitor purchases it. Wouldn't you prefer that ONLY the purchaser be able to access a hyperlink for your product?

Forget the financial (banking sites) or even software, what about say a social network. ""Back in the days"" if you sniffed the wire, it was a known fact you could pull out the URIs from the tcp capture, open it in a browser, and you had instant access to email, social network components, etc.

There are plenty of different scenarios you'd need it. Think about it for what it is: ""Insecure Direct Object"" an object directly accessible and cannot be secured for whatever reason. We need to secure it by assigning it a ""reference"" so it can never be ""directly named.""
"
1158,1158,1818,How to hide a DIV element when I click outside,"I have a div and want to hide it when I click outside. My code is:

&lt;div id=""mydiv""&gt;The div must be above button&lt;/div&gt;

    $('#mydiv').click(function(e) {
        e.stopPropagation();
    });

    $(document).click(function() {
        $('#mydiv').fadeOut(300);
    });


But it is not working for me ...

UPDATE

Full code is presented below. When I click on a button it shows a div above, so I need to hide this div when I click outside.

DEMO

&lt;div id=""but"" style=""text-align: right;""&gt;&lt;button type=""button""&gt;Show Div!&lt;/button&gt;&lt;/div&gt;
&lt;div id=""mydiv"" style=""display:none;""&gt;The div must be above button&lt;/div&gt;

$(""#but button"").click(function(){
  var pos = $(this).offset(),
      div = $(""#mydiv"");

  // Make it visible off-page so
  // we can measure it
  div.css({
    ""display"": ""block"",
    ""border"": ""1px solid black"",
    ""position"": ""absolute"",
    ""left"": -10000,
    ""top"": 0
  });

  // Move it where we want it to be
  div.css({
    ""left"": pos.left - 40,
    ""top"":  pos.top - div.height() - 10
  });
});

$('#myDiv').click(function(e) {
    e.stopPropagation();
});
$(document).click(function() {
    $('#mydiv').fadeOut(300);
});

",andys,https://stackoverflow.com/users/1139767,"try .blur(), and like this:

$('#mydiv').blur(function(e) {
    $(this).fadeOut(300);
});


Hope it help
",Michael Antonius,https://stackoverflow.com/users/1466229,http://stackoverflow.com/questions/13892375/how-to-hide-a-div-element-when-i-click-outside,STACKOVERFLOW,stackoverflow.com,0.6666666666666666,0.5555555555555556,0.0,0.0,1.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.9,1.0,0.0,0.0,0.6666666666666666,How to hide div elements when you click external,"I have a div and want to hide it when I click outside. My code is:

&lt;div id=""mydiv""&gt;The div must be above button&lt;/div&gt;

    $('#mydiv').click(function(e) {
        e.stopPropagation();
    });

    $(document).click(function() {
        $('#mydiv').fadeOut(300);
    });


But it is not working for me ...

UPDATE

Full code is presented below. When I click on a button it shows a div above, so I need to hide this div when I click outside.

DEMO

&lt;div id=""but"" style=""text-align: right;""&gt;&lt;button type=""button""&gt;Show Div!&lt;/button&gt;&lt;/div&gt;
&lt;div id=""mydiv"" style=""display:none;""&gt;The div must be above button&lt;/div&gt;

$(""#but button"").click(function(){
  var pos = $(this).offset(),
      div = $(""#mydiv"");

  // Make it visible off-page so
  // we can measure it
  div.css({
    ""display"": ""block"",
    ""border"": ""1px solid black"",
    ""position"": ""absolute"",
    ""left"": -10000,
    ""top"": 0
  });

  // Move it where we want it to be
  div.css({
    ""left"": pos.left - 40,
    ""top"":  pos.top - div.height() - 10
  });
});

$('#myDiv').click(function(e) {
    e.stopPropagation();
});
$(document).click(function() {
    $('#mydiv').fadeOut(300);
});

","try .blur(), and like this:

$('#mydiv').blur(function(e) {
    $(this).fadeOut(300);
});


Hope it help
"
2159,2159,3443,ERR_SSL_PROTOCOL_ERROR in chrome 39 and 40 but works in chrome 36.Help fix in chrome 39,"I am able to access a URL in Chrome 36 and IE8 but in Chrome 39 or 40 or Firefox 35 it throws the error:


  Unable to make a secure connection to the server.  This may be a
  problem with the server, or it may be requiring a client
  authentication certificate that you don't have.
  
  Error code: ERR_SSL_PROTOCOL_ERROR}. 


It seems that it is an issue related to the SSL certificate. How can I fix this?
",Swati Mishra,https://stackoverflow.com/users/4468846,"Try this. In Chrome, enter ""chrome://flags/#enable-quic"" without the quotes as a URL. CTRL + F to search for ""quic"", at which point you'll find...

Experimental QUIC protocol. Mac, Windows, Linux, Chrome OS, Android
Enable experimental QUIC protocol support. #enable-quic

Turn that to disabled, and let it restart your browser when prompted below. 
",user1054583,https://stackoverflow.com/users/1054583,http://stackoverflow.com/questions/28019407/err-ssl-protocol-error-in-chrome-39-and-40-but-works-in-chrome-36-help-fix-in-ch,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.8888888888888888,0.0,1.0,1.0,1.0,0.6666666666666666,0.5555555555555556,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.7333333333333333,0.6666666666666666,0.3333333333333333,0.3333333333333333,1.0,"Err? SSL? Protocol? Error in chrome 39 and chrome 40, but valid in chrome 36. Help fix in chrome 39","I am able to access a URL in Chrome 36 and IE8 but in Chrome 39 or 40 or Firefox 35 it throws the error:


  Unable to make a secure connection to the server.  This may be a
  problem with the server, or it may be requiring a client
  authentication certificate that you don't have.
  
  Error code: ERR_SSL_PROTOCOL_ERROR}. 


It seems that it is an issue related to the SSL certificate. How can I fix this?
","Try this. In Chrome, enter ""chrome://flags/#enable-quic"" without the quotes as a URL. CTRL + F to search for ""quic"", at which point you'll find...

Experimental QUIC protocol. Mac, Windows, Linux, Chrome OS, Android
Enable experimental QUIC protocol support. #enable-quic

Turn that to disabled, and let it restart your browser when prompted below. 
"
503,503,784,How do I list all files a given grunt task depends on for a Makefile?,"As Grunt doesn't support only rebuilding what has changed, I'd like to wrap a Makefile around it, to just compute the set of ""input"" files and not invoke grunt at all, unless any of them have changed since last build.

Can you tell grunt to just list what files a given task would depend on on stdout somehow?
",ecmanaut,https://stackoverflow.com/users/1130377,"You could do this with a custom task though it would still be wrapped by normal grunt output.

grunt.registerTask('src', function(){
  var taskConfig = grunt.config(this.args.join('.'));
  var expanded = grunt.task.normalizeMultiTaskFiles(taskConfig);
  expanded.forEach(function(files){
    files.src.forEach(function(file) {
      console.log(file);
    });
  });
});


Command line syntax to list all files for, say, a subtask for jshint called ""myFiles"" would be grunt src:jshint:myFiles

$ grunt src:jshint:myFiles
Running ""src:jshint:myFiles"" (src) task
file1.js
file2.js
dir/file3.js

Done, without errors.

",jsoverson,https://stackoverflow.com/users/60737,http://stackoverflow.com/questions/18647056/how-do-i-list-all-files-a-given-grunt-task-depends-on-for-a-makefile,STACKOVERFLOW,stackoverflow.com,1.0,0.7777777777777778,0.0,0.6666666666666666,0.3333333333333333,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,1.0,0.6666666666666666,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,0.0,0.8888888888888888,How do I list all the files of the makefile that a given grunt task depends on?,"Since grunt does not support rebuilding only what has changed, I want to wrap a makefile around it so that only the input file set is evaluated, and grunt is not called, unless any of them have changed since the last build.","You could do this with a custom task though it would still be wrapped by normal grunt output.

grunt.registerTask('src', function(){
  var taskConfig = grunt.config(this.args.join('.'));
  var expanded = grunt.task.normalizeMultiTaskFiles(taskConfig);
  expanded.forEach(function(files){
    files.src.forEach(function(file) {
      console.log(file);
    });
  });
});


Command line syntax to list all files for, say, a subtask for jshint called ""myFiles"" would be grunt src:jshint:myFiles

$ grunt src:jshint:myFiles
Running ""src:jshint:myFiles"" (src) task
file1.js
file2.js
dir/file3.js

Done, without errors.

"
2994,2994,4774,When to use layoutSubview in iOS,"I am writing iOS application for iPad that require custom layout.

The layout from portrait and landscape are totally difference, so it can't be solve by using UIAutoResizingMask.

I try to use the layoutSubview Method, but I detected that layout subview is called a lot (from UIScrollView).
How can i reduce the layoutSubview call to optimize the code , or I should call it by my self when ever the device is rotated. 

Thank.
",Isara Rungvitayakul,https://stackoverflow.com/users/475479,"Speaking from experience I would personally only adjust your layout based upon deviceDidRotateSelector notifications.
I have an updatePortrait method and an updateLandscape method and call whichever is necessary.
",ader,https://stackoverflow.com/users/348985,http://stackoverflow.com/questions/6953373/when-to-use-layoutsubview-in-ios,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.4444444444444444,0.0,1.0,0.6666666666666666,1.0,0.4444444444444444,0.4444444444444444,0.0,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.0,0.3333333333333333,0.8888888888888888,When to use layoutsubview in IOS,"I am writing iOS application for iPad that require custom layout.

The layout from portrait and landscape are totally difference, so it can't be solve by using UIAutoResizingMask.

I try to use the layoutSubview Method, but I detected that layout subview is called a lot (from UIScrollView).
How can i reduce the layoutSubview call to optimize the code , or I should call it by my self when ever the device is rotated. 

Thank.
","Speaking from experience I would personally only adjust your layout based upon deviceDidRotateSelector notifications.
I have an updatePortrait method and an updateLandscape method and call whichever is necessary.
"
6010,6010,9531,Grapple + Totemic Attunement (Eagle) = Zangief's Spinning Atomic Piledriver?,"Could a Barbarian with Totemic Attunement (eagle) use grapple to perform the iconic move by dragging the enemy straight up as far as the fly speed allows and ending the turn in the air? If so, who would take fall damage?
",ZHDarkstar,https://rpg.stackexchange.com/users/16224,"Yes, you can do this. No you won't get very far, and I'd definitely rule that both of you take the falling damage.

First, yes you are allowed to move a target you are grabbing. So you can feasibly grab them with your action, then use your movement to fly with them.

However, since you are moving with a grabbed target, your movement speed is halved, so you only get 15 feet up. This means that the falling damage is at most 2d6 damage (though some DMs may rule it to be 1d6, I'd be inclined to) and you'll be prone..

Ultimately, it looks like you both fall. I'd definitely rule that since you're falling the grab is up. And, since there is not a direct way to negate falling damage, unless your caster friend is shooting feather fall as a reaction, you're both taking damage here.

If I may editorialize here: this is not a good strategy. It consumes your action with the grab which is then most likely broken, and only does 1d6, maybe 2d6 damage, which is what your weapon does, and it's likely less reliable since it relies on an opposed check rather than an attack against AC. Stick to what you're good at: hitting things with metal attached to sticks.
",wax eagle,https://rpg.stackexchange.com/users/1084,http://rpg.stackexchange.com/questions/49223/grapple-totemic-attunement-eagle-zangiefs-spinning-atomic-piledriver,CULTURE,rpg.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,1.0,1.0,1.0,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.0,0.3333333333333333,1.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.8888888888888888,Fight + totem tuning (hawk) = Zanger's rotating atom stacker?,"Can a barbarian (hawk) with totem modulation use a grapple to complete a symbolic movement? As long as the flight speed allows, drag the enemy straight up and end the turn in the air? If so, who will take the fall damage?","Yes, you can do this. No you won't get very far, and I'd definitely rule that both of you take the falling damage.

First, yes you are allowed to move a target you are grabbing. So you can feasibly grab them with your action, then use your movement to fly with them.

However, since you are moving with a grabbed target, your movement speed is halved, so you only get 15 feet up. This means that the falling damage is at most 2d6 damage (though some DMs may rule it to be 1d6, I'd be inclined to) and you'll be prone..

Ultimately, it looks like you both fall. I'd definitely rule that since you're falling the grab is up. And, since there is not a direct way to negate falling damage, unless your caster friend is shooting feather fall as a reaction, you're both taking damage here.

If I may editorialize here: this is not a good strategy. It consumes your action with the grab which is then most likely broken, and only does 1d6, maybe 2d6 damage, which is what your weapon does, and it's likely less reliable since it relies on an opposed check rather than an attack against AC. Stick to what you're good at: hitting things with metal attached to sticks.
"
3295,3295,5256,Transform a Binary Search Tree into a Greater Sum Tree,"Given a Binary Search Tree (where all nodes on the left child branch are less than the node), and all nodes to the right are greater/equal to the node), transform it into a Greater Sum Tree where each node contains sum of it together with all nodes greater than that node. Example diagram is here:



Looking for code review, optimizations and best practices.

public class GreaterSumTree implements Iterable {

    private TreeNode root;

    public GreaterSumTree(List&lt;Integer&gt; list) {
        create(list);
    }

    private void create (List&lt;Integer&gt; items) {
        root = new TreeNode(items.get(0));

        final Queue&lt;TreeNode&gt; queue = new LinkedList&lt;TreeNode&gt;();
        queue.add(root);

        final int half = items.size() / 2;

        for (int i = 0; i &lt; half; i++) {
            if (items.get(i) != null) {
                final TreeNode current = queue.poll();
                final int left = 2 * i + 1;
                final int right = 2 * i + 2;

                if (items.get(left) != null) {
                    current.left = new TreeNode(items.get(left));
                    queue.add(current.left);
                }
                if (right &lt; items.size() &amp;&amp; items.get(right) != null) {
                    current.right = new TreeNode(items.get(right));
                    queue.add(current.right);
                }
            }
        }
    }

    public static class TreeNode {
        private TreeNode left;
        private int item;
        private TreeNode right;

        TreeNode(int item) {
            this.item = item;
        }
    }


    public static class IntObject {
        private int sum;
    }

    /**
     * Computes the greater sum, provided the tree is BST.
     * If tree is not BST, then results are unpredictable.
     */
    public void greaterSumTree() {
        if (root == null) {
            throw new IllegalArgumentException(""root is null"");
        }
        computeSum (root, new IntObject());
    }


    private void computeSum(TreeNode node, IntObject intObj) {
        if (node != null) {
            computeSum(node.right, intObj);
            int temp = node.item;
            node.item = intObj.sum;
            intObj.sum = intObj.sum + temp;
            computeSum(node.left, intObj);
        }
    }

    /**
     * Returns the preorder representation for the given tree.
     * 
     * @return  the iterator for preorder traversal
     */
    @Override
    public Iterator iterator () {
        return new PreOrderItr();
    }

    private class PreOrderItr implements Iterator {
        private final Stack&lt;TreeNode&gt; stack;

        public PreOrderItr() {
            stack = new Stack&lt;TreeNode&gt;();
            stack.add(root);
        }

        @Override
        public boolean hasNext() {
            return !stack.isEmpty();
        }

        @Override
        public Integer next() {
            if (!hasNext()) throw new NoSuchElementException(""No more nodes remain to iterate"");

            final TreeNode node = stack.pop();           

            if (node.right != null) stack.push(node.right);
            if (node.left != null) stack.push(node.left);

            return node.item;
        }

        @Override
        public void remove() {
            throw new UnsupportedOperationException(""Invalid operation for pre-order iterator."");
        }
    }
}


Here is a test case:

public class GreaterSumTreeTest {

    @Test
    public void test() {
        Integer[] a = {1, 2, 7, 11, 15, 29, 35};
        GreaterSumTree greaterSumTree = new GreaterSumTree(Arrays.asList(a));
        greaterSumTree.greaterSumTree();

        int[] expected = {71, 87, 89, 72, 35, 42, 0};
        int[] actual = new int[a.length];
        int counter = 0;
        Iterator itr = greaterSumTree.iterator();
        while (itr.hasNext()) {
           actual[counter++] = (Integer) itr.next();
        }
        assertTrue(Arrays.equals(expected, actual));
    }

}

",JavaDeveloper,https://codereview.stackexchange.com/users/28539,"A minor bug: You get an IndexOutOfBoundsException for an empty list in GreaterSumTree.create(List&lt;Integer&gt; items). You don't have a comment stating you need to input a list containing at least something. Consider returning IllegalArgumentException and adding a comment.



/**
 * Computes the greater sum, provided the tree is BST.
 * If tree is not BST, then results are unpredictable.
 */
public void greaterSumTree() {
    if (root == null) {
        throw new IllegalArgumentException(""root is null"");
    }
    computeSum (root, new IntObject());
}


You should use IllegalStateException here. IllegalArgumentException is for when the arguments are bad. What's bad here is the internal state of your object. Alternatively, remove the check here and put it in the create function. That way you don't get bad internal states.
",Pimgd,https://codereview.stackexchange.com/users/49350,http://codereview.stackexchange.com/questions/55966/transform-a-binary-search-tree-into-a-greater-sum-tree,TECHNOLOGY,codereview.stackexchange.com,0.6666666666666666,0.3333333333333333,0.0,1.0,1.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,1.0,1.0,Convert binary search tree to large sum tree,"Given a Binary Search Tree (where all nodes on the left child branch are less than the node), and all nodes to the right are greater/equal to the node), transform it into a Greater Sum Tree where each node contains sum of it together with all nodes greater than that node. Example diagram is here:



Looking for code review, optimizations and best practices.

public class GreaterSumTree implements Iterable {

    private TreeNode root;

    public GreaterSumTree(List&lt;Integer&gt; list) {
        create(list);
    }

    private void create (List&lt;Integer&gt; items) {
        root = new TreeNode(items.get(0));

        final Queue&lt;TreeNode&gt; queue = new LinkedList&lt;TreeNode&gt;();
        queue.add(root);

        final int half = items.size() / 2;

        for (int i = 0; i &lt; half; i++) {
            if (items.get(i) != null) {
                final TreeNode current = queue.poll();
                final int left = 2 * i + 1;
                final int right = 2 * i + 2;

                if (items.get(left) != null) {
                    current.left = new TreeNode(items.get(left));
                    queue.add(current.left);
                }
                if (right &lt; items.size() &amp;&amp; items.get(right) != null) {
                    current.right = new TreeNode(items.get(right));
                    queue.add(current.right);
                }
            }
        }
    }

    public static class TreeNode {
        private TreeNode left;
        private int item;
        private TreeNode right;

        TreeNode(int item) {
            this.item = item;
        }
    }


    public static class IntObject {
        private int sum;
    }

    /**
     * Computes the greater sum, provided the tree is BST.
     * If tree is not BST, then results are unpredictable.
     */
    public void greaterSumTree() {
        if (root == null) {
            throw new IllegalArgumentException(""root is null"");
        }
        computeSum (root, new IntObject());
    }


    private void computeSum(TreeNode node, IntObject intObj) {
        if (node != null) {
            computeSum(node.right, intObj);
            int temp = node.item;
            node.item = intObj.sum;
            intObj.sum = intObj.sum + temp;
            computeSum(node.left, intObj);
        }
    }

    /**
     * Returns the preorder representation for the given tree.
     * 
     * @return  the iterator for preorder traversal
     */
    @Override
    public Iterator iterator () {
        return new PreOrderItr();
    }

    private class PreOrderItr implements Iterator {
        private final Stack&lt;TreeNode&gt; stack;

        public PreOrderItr() {
            stack = new Stack&lt;TreeNode&gt;();
            stack.add(root);
        }

        @Override
        public boolean hasNext() {
            return !stack.isEmpty();
        }

        @Override
        public Integer next() {
            if (!hasNext()) throw new NoSuchElementException(""No more nodes remain to iterate"");

            final TreeNode node = stack.pop();           

            if (node.right != null) stack.push(node.right);
            if (node.left != null) stack.push(node.left);

            return node.item;
        }

        @Override
        public void remove() {
            throw new UnsupportedOperationException(""Invalid operation for pre-order iterator."");
        }
    }
}


Here is a test case:

public class GreaterSumTreeTest {

    @Test
    public void test() {
        Integer[] a = {1, 2, 7, 11, 15, 29, 35};
        GreaterSumTree greaterSumTree = new GreaterSumTree(Arrays.asList(a));
        greaterSumTree.greaterSumTree();

        int[] expected = {71, 87, 89, 72, 35, 42, 0};
        int[] actual = new int[a.length];
        int counter = 0;
        Iterator itr = greaterSumTree.iterator();
        while (itr.hasNext()) {
           actual[counter++] = (Integer) itr.next();
        }
        assertTrue(Arrays.equals(expected, actual));
    }

}

","A minor bug: You get an IndexOutOfBoundsException for an empty list in GreaterSumTree.create(List&lt;Integer&gt; items). You don't have a comment stating you need to input a list containing at least something. Consider returning IllegalArgumentException and adding a comment.



/**
 * Computes the greater sum, provided the tree is BST.
 * If tree is not BST, then results are unpredictable.
 */
public void greaterSumTree() {
    if (root == null) {
        throw new IllegalArgumentException(""root is null"");
    }
    computeSum (root, new IntObject());
}


You should use IllegalStateException here. IllegalArgumentException is for when the arguments are bad. What's bad here is the internal state of your object. Alternatively, remove the check here and put it in the create function. That way you don't get bad internal states.
"
3772,3772,6005,Is apt-get upgrade a dangerous command?,"When I use apt-get update and apt-get upgrade,there are some packages should installed in newest version,like below:

The following packages will be upgraded:
  accountsservice apparmor apport apt apt-transport-https apt-utils binutils
  cloud-init cpp-4.8 dpkg fuse g++-4.8 gcc-4.8 gcc-4.8-base gdisk gnupg gpgv
  grub-common grub-legacy-ec2 grub-pc grub-pc-bin grub2-common initscripts
  isc-dhcp-client isc-dhcp-common libaccountsservice0 libapparmor-perl
  libapparmor1 libapt-inst1.5 libapt-pkg4.12 libasan0 libatomic1 libbsd0
  libcurl3-gnutls libdrm2 libedit2 libfuse2 libgcc-4.8-dev libgd3 libgomp1
  libitm1 libjson-c2 libjson0 libnuma1 libpam-systemd libpolkit-agent-1-0
  libpolkit-backend-1-0 libpolkit-gobject-1-0 libquadmath0 libstdc++-4.8-dev
  libstdc++6 libsystemd-daemon0 libsystemd-login0 libtsan0 libudev1 libxext6
  linux-libc-dev ntpdate openssl overlayroot patch policykit-1 ppp
  python-urllib3 python3-apport python3-problem-report python3-update-manager
  rsyslog systemd-services sysv-rc sysvinit-utils tcpdump tzdata udev
  update-manager-core
75 upgraded, 0 newly installed, 0 to remove and 4 not upgraded.


If I didn't know every one of there packages what will happen if there update in newest version.I shouldn't execute this command(apt-get upgrade).

For example:

This php version is before I upgrade

yzxu@ubuntu:/tmp/git-2.1.2$ php --version
PHP 5.6.6-1+deb.sury.org~precise+1 (cli) 
Copyright (c) 1997-2015 The PHP Group
Zend Engine v2.6.0, Copyright (c) 1998-2015 Zend Technologies
    with Zend OPcache v7.0.6-dev, Copyright (c) 1999-2015, by Zend Technologies


and after I upgrade:

yzxu@ubuntu:/tmp/git-2.1.2$ php --version
PHP 5.6.10-1+deb.sury.org~precise+1 (cli) 
Copyright (c) 1997-2015 The PHP Group
Zend Engine v2.6.0, Copyright (c) 1998-2015 Zend Technologies
    with Zend OPcache v7.0.6-dev, Copyright (c) 1999-2015, by Zend Technologies


The php version is changed.And if I didn't what what was change in two version,should I upgrade it?Is it will influence product?
",大易归真,https://askubuntu.com/users/422775,"apt-get update


Refreshes the repositories and fetches information about packages that are available online.

apt-get upgrade


Downloads and installs updates for all installed packages - as long as it doesn't bother dependencies (install new packages, remove old ones or crosses a repo source (switch a package from one repo to another)).

apt-get dist-upgrade


Does the same as ""upgrade"" but upgrades a package also when dependencies or sources are changed (something you want to avoid on servers without further testing).

To conclude - an update can break things but it is necessary!
So if you are on a desktop you should normally do a: 

sudo apt-get update &amp;&amp; sudo apt-get dist-upgrade


Without destroying something.

On a server most of the times a: 

sudo apt-get update &amp;&amp; sudo apt-get upgrade


should be enough AND security updates should be installed automatically (on servers and desktops)

TL;DR!

Yes you should update php in this example - cause it is a security fix (what can be seen through the numbering scheme of php and else it would not have been pushed into the ""upgrade"" branch of ubuntu...
",Mr.Gosh,https://askubuntu.com/users/410337,http://askubuntu.com/questions/639822/is-apt-get-upgrade-a-dangerous-command/639838,TECHNOLOGY,askubuntu.com,0.6666666666666666,1.0,0.0,1.0,1.0,0.5,0.6666666666666666,0.3333333333333333,0.5,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.6666666666666666,1.0,0.8,0.0,0.0,1.0,0.6666666666666666,Is apt get upgrade a dangerous command?,"When I use apt-get update and apt-get upgrade,there are some packages should installed in newest version,like below:

The following packages will be upgraded:
  accountsservice apparmor apport apt apt-transport-https apt-utils binutils
  cloud-init cpp-4.8 dpkg fuse g++-4.8 gcc-4.8 gcc-4.8-base gdisk gnupg gpgv
  grub-common grub-legacy-ec2 grub-pc grub-pc-bin grub2-common initscripts
  isc-dhcp-client isc-dhcp-common libaccountsservice0 libapparmor-perl
  libapparmor1 libapt-inst1.5 libapt-pkg4.12 libasan0 libatomic1 libbsd0
  libcurl3-gnutls libdrm2 libedit2 libfuse2 libgcc-4.8-dev libgd3 libgomp1
  libitm1 libjson-c2 libjson0 libnuma1 libpam-systemd libpolkit-agent-1-0
  libpolkit-backend-1-0 libpolkit-gobject-1-0 libquadmath0 libstdc++-4.8-dev
  libstdc++6 libsystemd-daemon0 libsystemd-login0 libtsan0 libudev1 libxext6
  linux-libc-dev ntpdate openssl overlayroot patch policykit-1 ppp
  python-urllib3 python3-apport python3-problem-report python3-update-manager
  rsyslog systemd-services sysv-rc sysvinit-utils tcpdump tzdata udev
  update-manager-core
75 upgraded, 0 newly installed, 0 to remove and 4 not upgraded.


If I didn't know every one of there packages what will happen if there update in newest version.I shouldn't execute this command(apt-get upgrade).

For example:

This php version is before I upgrade

yzxu@ubuntu:/tmp/git-2.1.2$ php --version
PHP 5.6.6-1+deb.sury.org~precise+1 (cli) 
Copyright (c) 1997-2015 The PHP Group
Zend Engine v2.6.0, Copyright (c) 1998-2015 Zend Technologies
    with Zend OPcache v7.0.6-dev, Copyright (c) 1999-2015, by Zend Technologies


and after I upgrade:

yzxu@ubuntu:/tmp/git-2.1.2$ php --version
PHP 5.6.10-1+deb.sury.org~precise+1 (cli) 
Copyright (c) 1997-2015 The PHP Group
Zend Engine v2.6.0, Copyright (c) 1998-2015 Zend Technologies
    with Zend OPcache v7.0.6-dev, Copyright (c) 1999-2015, by Zend Technologies


The php version is changed.And if I didn't what what was change in two version,should I upgrade it?Is it will influence product?
","apt-get update


Refreshes the repositories and fetches information about packages that are available online.

apt-get upgrade


Downloads and installs updates for all installed packages - as long as it doesn't bother dependencies (install new packages, remove old ones or crosses a repo source (switch a package from one repo to another)).

apt-get dist-upgrade


Does the same as ""upgrade"" but upgrades a package also when dependencies or sources are changed (something you want to avoid on servers without further testing).

To conclude - an update can break things but it is necessary!
So if you are on a desktop you should normally do a: 

sudo apt-get update &amp;&amp; sudo apt-get dist-upgrade


Without destroying something.

On a server most of the times a: 

sudo apt-get update &amp;&amp; sudo apt-get upgrade


should be enough AND security updates should be installed automatically (on servers and desktops)

TL;DR!

Yes you should update php in this example - cause it is a security fix (what can be seen through the numbering scheme of php and else it would not have been pushed into the ""upgrade"" branch of ubuntu...
"
3664,3664,5844,"Strategy for hosting 700+ domains names, each with a static HTML site","I have a portfolio of more than 700 domain names, and ideally I'd like to put up a single-page HTML/CSS/JavaScript webpage for each domain. Is there a system/strategy/workflow that will allow me to:


Automate the deployment of new websites, quickly and easily without having to manually initiate each new website in an admin panel. For instance, I've seen dropbox-based solutions that claim to make it simple to setup new websites on your dropbox account, but you still have to set each one up in an admin interface first. It would be so much easier to have a folder naming convention that allowed the user to easily clone/copy/duplicate sites inside their Dropbox App folder (https://www.dropbox.com/developers/blog/23) to create new ones. Sounds interesting, however...
It's easy to manage CNAMEs on the registrar-side, but is there a way to quickly associate CNAMEs with new websites (on the hosting side), maybe using the method offered by gh-pages-style (https://help.github.com/articles/setting-up-a-custom-domain-with-pages)? With GitHub's gh-pages, all you have to do is drop a file called CNAME into your repo, with the domain name you want associated with the repo inside the file. gh-pages isn't a good solution for what I'm doing though unfortunately.


I'm also a front-end developer, specializing in rapid web development and ""front-end build systems"", so I building and maintaining static assets for hundreds of sites is no problem. It's the hosting-side that I really struggle with. Any suggestions?

Edit: I should also mention that managing my own servers is not an option. As a last resort I might look to build a 3rd party service on top of AWS, Azure etc. but managing servers directly is exactly what I'm trying to get away from.
",jonschlinkert,https://webmasters.stackexchange.com/users/20163,"@jonschlinkert setting up CNAMES has nothing to do with adding a single HTML page to 700 domains. CNAME's won't help any with SEO. If you're creating a single HTML page for each of your domains why not build an HTML template. I don't think you'll find any good method of inserting the copy into each page since you'll have to write the content at some point you may as well do it into the HTML pages themselves.

There are a few applications which let you manage multiple WordPress sites from a single dashboard that my be useful to you.
",Anagio,https://webmasters.stackexchange.com/users/10527,http://webmasters.stackexchange.com/questions/38230/strategy-for-hosting-700-domains-names-each-with-a-static-html-site,TECHNOLOGY,webmasters.stackexchange.com,0.7777777777777778,0.5555555555555556,0.0,0.6666666666666666,1.0,1.0,0.5555555555555556,0.4444444444444444,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.7777777777777778,0.6666666666666666,0.5,0.8888888888888888,0.7777777777777778,0.7,0.6666666666666666,0.0,0.6666666666666666,0.8888888888888888,"The policy of hosting more than 700 domain names, each with a static HTML site","I have a portfolio of more than 700 domain names, and ideally I'd like to put up a single-page HTML/CSS/JavaScript webpage for each domain. Is there a system/strategy/workflow that will allow me to:


Automate the deployment of new websites, quickly and easily without having to manually initiate each new website in an admin panel. For instance, I've seen dropbox-based solutions that claim to make it simple to setup new websites on your dropbox account, but you still have to set each one up in an admin interface first. It would be so much easier to have a folder naming convention that allowed the user to easily clone/copy/duplicate sites inside their Dropbox App folder (https://www.dropbox.com/developers/blog/23) to create new ones. Sounds interesting, however...
It's easy to manage CNAMEs on the registrar-side, but is there a way to quickly associate CNAMEs with new websites (on the hosting side), maybe using the method offered by gh-pages-style (https://help.github.com/articles/setting-up-a-custom-domain-with-pages)? With GitHub's gh-pages, all you have to do is drop a file called CNAME into your repo, with the domain name you want associated with the repo inside the file. gh-pages isn't a good solution for what I'm doing though unfortunately.


I'm also a front-end developer, specializing in rapid web development and ""front-end build systems"", so I building and maintaining static assets for hundreds of sites is no problem. It's the hosting-side that I really struggle with. Any suggestions?

Edit: I should also mention that managing my own servers is not an option. As a last resort I might look to build a 3rd party service on top of AWS, Azure etc. but managing servers directly is exactly what I'm trying to get away from.
","@jonschlinkert setting up CNAMES has nothing to do with adding a single HTML page to 700 domains. CNAME's won't help any with SEO. If you're creating a single HTML page for each of your domains why not build an HTML template. I don't think you'll find any good method of inserting the copy into each page since you'll have to write the content at some point you may as well do it into the HTML pages themselves.

There are a few applications which let you manage multiple WordPress sites from a single dashboard that my be useful to you.
"
3034,3034,4838,jQueryUI Spinner widget with knockout,"How can I use a jQuery UI Spinner widget in Knockout bound input?

    &lt;tbody data-bind=""foreach: orders""&gt;
        &lt;tr&gt;
            &lt;td data-bind=""text: Name""&gt;&lt;/td&gt;
            &lt;td&gt;&lt;input type=""number"" style=""width: 100px;"" data-bind=""value: Price"" /&gt;&lt;/td&gt;
            &lt;td&gt;&lt;input type=""number"" style=""width: 50px;"" data-bind=""value: VAT"" /&gt;&lt;/td&gt;
            &lt;td&gt;&lt;input type=""number"" style=""width: 50px;"" data-bind=""value: Number"" /&gt;&lt;/td&gt;
            &lt;td data-bind=""text: Final()""&gt;&lt;/td&gt;
            &lt;td&gt;&lt;a href=""javascript:void(0);"" data-bind=""click: $root.removeOrder""&gt;Remove&lt;/a&gt;&lt;/td&gt;
        &lt;/tr&gt;    
    &lt;/tbody&gt;

",Omid Mafakher,https://stackoverflow.com/users/993369,"The best way is to create custom binding to bind spinner to the input:

ko.bindingHandlers.spinner = {
    init: function(element, valueAccessor, allBindingsAccessor) {
        //initialize datepicker with some optional options
        var options = allBindingsAccessor().spinnerOptions || {};
        $(element).spinner(options);

        //handle the field changing
        ko.utils.registerEventHandler(element, ""spinchange"", function () {
            var observable = valueAccessor();
            observable($(element).spinner(""value""));
        });

        //handle disposal (if KO removes by the template binding)
        ko.utils.domNodeDisposal.addDisposeCallback(element, function() {
            $(element).spinner(""destroy"");
        });

    },
    update: function(element, valueAccessor) {
        var value = ko.utils.unwrapObservable(valueAccessor()),
            current = $(element).spinner(""value"");

        if (value !== current) {
            $(element).spinner(""value"", value);
        }
    }
};


And then just use it instead of value binding:

&lt;input
    type=""number""
    style=""width: 100px;""
    data-bind=""spinner: Price, spinnerOptions: { min: 0 } "" /&gt;


Here is working fiddle: http://jsfiddle.net/vyshniakov/SwKGb/
",Artem Vyshniakov,https://stackoverflow.com/users/1022007,http://stackoverflow.com/questions/12929801/jqueryui-spinner-widget-with-knockout,STACKOVERFLOW,stackoverflow.com,0.6666666666666666,0.3333333333333333,0.0,0.0,1.0,1.0,0.5,0.8333333333333334,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,1.0,JQuery UI spinner widget with knockout,"How can I use a jQuery UI Spinner widget in Knockout bound input?

    &lt;tbody data-bind=""foreach: orders""&gt;
        &lt;tr&gt;
            &lt;td data-bind=""text: Name""&gt;&lt;/td&gt;
            &lt;td&gt;&lt;input type=""number"" style=""width: 100px;"" data-bind=""value: Price"" /&gt;&lt;/td&gt;
            &lt;td&gt;&lt;input type=""number"" style=""width: 50px;"" data-bind=""value: VAT"" /&gt;&lt;/td&gt;
            &lt;td&gt;&lt;input type=""number"" style=""width: 50px;"" data-bind=""value: Number"" /&gt;&lt;/td&gt;
            &lt;td data-bind=""text: Final()""&gt;&lt;/td&gt;
            &lt;td&gt;&lt;a href=""javascript:void(0);"" data-bind=""click: $root.removeOrder""&gt;Remove&lt;/a&gt;&lt;/td&gt;
        &lt;/tr&gt;    
    &lt;/tbody&gt;

","The best way is to create custom binding to bind spinner to the input:

ko.bindingHandlers.spinner = {
    init: function(element, valueAccessor, allBindingsAccessor) {
        //initialize datepicker with some optional options
        var options = allBindingsAccessor().spinnerOptions || {};
        $(element).spinner(options);

        //handle the field changing
        ko.utils.registerEventHandler(element, ""spinchange"", function () {
            var observable = valueAccessor();
            observable($(element).spinner(""value""));
        });

        //handle disposal (if KO removes by the template binding)
        ko.utils.domNodeDisposal.addDisposeCallback(element, function() {
            $(element).spinner(""destroy"");
        });

    },
    update: function(element, valueAccessor) {
        var value = ko.utils.unwrapObservable(valueAccessor()),
            current = $(element).spinner(""value"");

        if (value !== current) {
            $(element).spinner(""value"", value);
        }
    }
};


And then just use it instead of value binding:

&lt;input
    type=""number""
    style=""width: 100px;""
    data-bind=""spinner: Price, spinnerOptions: { min: 0 } "" /&gt;


Here is working fiddle: http://jsfiddle.net/vyshniakov/SwKGb/
"
3385,3385,5395,How to grep words in a file?,"
  Possible Duplicate:
  Regex for &ldquo;or&rdquo; in grep  




How can I grep for lines with either 'disable' or 'enable' in my file?

I tried 
 $ grep   ""disable|enable"" fail.log 

but that shows up nothing.
",michael,https://superuser.com/users/31500,"You need the -P switch for Perl Compatible Regular Expressions (PCRE).

Try:

grep -P ""disable|enable"" fail.log


Without it, grep uses POSIX Basic Regular Expressions, which have inconsistent escaping and less features.
",Dennis,https://superuser.com/users/101836,http://superuser.com/questions/436426,TECHNOLOGY,superuser.com,0.6666666666666666,0.6666666666666666,0.0,1.0,1.0,1.0,0.5555555555555556,0.5555555555555556,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.8888888888888888,How do I add words to a file?,"
  Possible Duplicate:
  Regex for &ldquo;or&rdquo; in grep  




How can I grep for lines with either 'disable' or 'enable' in my file?

I tried 
 $ grep   ""disable|enable"" fail.log 

but that shows up nothing.
","You need the -P switch for Perl Compatible Regular Expressions (PCRE).

Try:

grep -P ""disable|enable"" fail.log


Without it, grep uses POSIX Basic Regular Expressions, which have inconsistent escaping and less features.
"
2269,2269,3616,What exactly is the difference between Unreal Development Kit and Uunreal Engine 4?,"I want to start learning game development and I would obviously come across this tool. So every where I went people mentioned Unreal Engine 4 to be a viable choice, I've tried a bit of Unity and now I want to try Unreal. Only issue I came across UDK and UE4, I downloaded UDK which turns out to be different from tutorials and I can't seem to find any info on that and besides I could only run the software once because after the first time it starts a game, I re-installed UDK I still get the issue, but anyways that's a different topic, what I want to know is whether UDK and UE4 are different and if they are, where do i get UE4, becauuse when I down UE4 (from - https://www.unrealengine.com/dashboard), it downloads a game launcher and no development tool. In case they are same, why is my version of UDK different fr
",Swapnil Rastogi,https://gamedev.stackexchange.com/users/59539,"You download the Launcher (which is not a game launcher - it's Epic Games Launcher, because the company is called Epic Games), and from within the launcher you can download UE4. This should be trivial to find out though.
",Christian,https://gamedev.stackexchange.com/users/19525,http://gamedev.stackexchange.com/questions/102603/what-exactly-is-the-difference-between-unreal-development-kit-and-uunreal-engine,TECHNOLOGY,gamedev.stackexchange.com,0.8333333333333334,0.6666666666666666,0.0,1.0,1.0,1.0,0.5,0.6666666666666666,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.5,0.5,0.5,0.5,0.0,0.8333333333333334,1.0,0.6666666666666666,1.0,0.8333333333333334,0.7,0.5,0.0,0.5,0.8333333333333334,What is the difference between the unreal development kit and the uunreal engine 4?,"I want to start learning about game development, and obviously I will encounter this tool. So everywhere I go, people talk about virtual engine 4 as a viable option, I tried some unity, and now I want to try virtual. The only problem I encountered was UDK and UE4. I downloaded UDK and found that it was different from the tutorial. I couldn't seem to find any information about it. Moreover, I could only run the software once, because after it started the game for the first time, I reinstalled UDK. I still got this problem, but anyway, this is a different topic. What I want to know is that UDK and UE4 are different Yes, if they are, where do I get UE4, because when I close UE4 (from - https://www.unrealengine.com/dashboard), it will download a game launcher without development tools. If they are the same, why is my UDK version different from fr","You download the Launcher (which is not a game launcher - it's Epic Games Launcher, because the company is called Epic Games), and from within the launcher you can download UE4. This should be trivial to find out though.
"
1426,1426,2238,"How can I organise photos on a network storage device, and what software can help me?","I have a recently bought a NAS and am in the process of transferring my photo collection onto it. I probably have over 300GB of pictures (many in various RAW formats). At the moment these are just organized in “old fashioned” file structures but I have am hoping to improve this to a some sort of cross referenced tagging system. So far though I am running into a few problems and any help would be appreciated. I have tried using the following software:


Windows photo gallery - and this appears to rapidly retrieve photos from the NAS based on chose tag words. The main down side that I have found so far is that the windows camera codec does not yet support my S95 RAW files and so they are not visible. 
Picasa – this looks as though it might work well on a local drive (and certainly get good reviews) but I am finding it very slow when scanning the photo library on the NAS (even when left for a number of hours the scan in only approx. 5% complete!). I can live with a bit of a delay when using the NAS but this is unworkable - am I getting something wrong?
Various other photo viewers - Although they allow me to see my RAW files do not appear to support tagging and the development of a cross referenced library. 


I am also considering looking at getting Lightroom but don’t want to shell out the money only to find it is as slow as Picasa.

Finally, my ideal would be to have different layers of tags so for example I could tag all my pictures from the “Lake District” but then also have the option of sub dividing within this category based on the valley etc. Without different levels of tagging I risk winding up with an unwieldy list of tag words. I do not know if this is possible/normal but if anyone has any points about what software packages support this arrangement that would also be appreciated. 
",Colin,https://photo.stackexchange.com/users/7943,"Lightroom is the way to go. Download the trial and give it a try, though I do recommend reading a bit or watching a few videos first to get the most out of your trial. 

Lightroom will let you do whatever you wish on the file system side, and then offer flexibility beyond it. This is important, because this NAS won't be your last, and in fact, you may have more than one eventually.  Lightroom does not care where your images are, and even functions with them offline (though not as well).

By arranging things on your harddrive, you are providing information about your images that will be lost when your images are separated from your hardrive, such as posting onto Flickr. The info is useful to you...I do understand that. However, the fact that the image came from ""2010/Christmas2010"" will not transfer to your Flickr upload, so it is important that you leverage something else, in particular keywords and tags that can be embedded into the image.

You can arrange your photos however you wish on the hard drive (date, event, or one big directory if you wish) and then in Lightroom create collections, tags, keywords and even what are called 'smart collections' that dynamically add images. You can tag images with keywords that will write to EXIF/IPTC, and use Lightroom's filters and search to show you related images. However it can be a bit of a pain to constantly search and filter, so Lightroom offers Collections, which are 'virtual directories' that contain images you have assigned to them. Of course, these have no relation to the actual directories on your hard drive, which is nice...you no longer have to worry about this aspect of organizing. And finally, there are Smart Collections, or virtual directories that are dynamic and automatic, so for example, you can create a Smart Collection based on certain keywords. Every new image with that keyword will be automatically added to the Smart Collection.

I find it helpful to have my images in directories related to year, then by day that I took the image: (2010/2010-12-25), because I recall when I took photos. Lightroom does this for me with its import utility. I simply tell Lightroom how I want to import, and it does automatically every time. Then, I tag images with keywords, typically related to events or subjects. If I have a particular event or project, I will create a collection to make it easy to return to (vs searching or filtering the view). For some items I create smart collections that are dynamic, such as images of family members.

When I upload to Smugmug, all the tags and keywords stay with the image, and they are easy to find on Smugmug as well.

Give Lightroom a try.
",cmason,https://photo.stackexchange.com/users/4880,http://photo.stackexchange.com/questions/18792/how-can-i-organise-photos-on-a-network-storage-device-and-what-software-can-hel,LIFE_ARTS,photo.stackexchange.com,1.0,0.5555555555555556,0.0,0.5,0.6666666666666666,0.0,0.6666666666666666,0.5555555555555556,0.3333333333333333,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,0.8888888888888888,1.0,0.9333333333333332,0.3333333333333333,0.3333333333333333,1.0,1.0,How to organize photos on network storage devices and what software can help me?,"I have a recently bought a NAS and am in the process of transferring my photo collection onto it. I probably have over 300GB of pictures (many in various RAW formats). At the moment these are just organized in “old fashioned” file structures but I have am hoping to improve this to a some sort of cross referenced tagging system. So far though I am running into a few problems and any help would be appreciated. I have tried using the following software:


Windows photo gallery - and this appears to rapidly retrieve photos from the NAS based on chose tag words. The main down side that I have found so far is that the windows camera codec does not yet support my S95 RAW files and so they are not visible. 
Picasa – this looks as though it might work well on a local drive (and certainly get good reviews) but I am finding it very slow when scanning the photo library on the NAS (even when left for a number of hours the scan in only approx. 5% complete!). I can live with a bit of a delay when using the NAS but this is unworkable - am I getting something wrong?
Various other photo viewers - Although they allow me to see my RAW files do not appear to support tagging and the development of a cross referenced library. 


I am also considering looking at getting Lightroom but don’t want to shell out the money only to find it is as slow as Picasa.

Finally, my ideal would be to have different layers of tags so for example I could tag all my pictures from the “Lake District” but then also have the option of sub dividing within this category based on the valley etc. Without different levels of tagging I risk winding up with an unwieldy list of tag words. I do not know if this is possible/normal but if anyone has any points about what software packages support this arrangement that would also be appreciated. 
","Lightroom is the way to go. Download the trial and give it a try, though I do recommend reading a bit or watching a few videos first to get the most out of your trial. 

Lightroom will let you do whatever you wish on the file system side, and then offer flexibility beyond it. This is important, because this NAS won't be your last, and in fact, you may have more than one eventually.  Lightroom does not care where your images are, and even functions with them offline (though not as well).

By arranging things on your harddrive, you are providing information about your images that will be lost when your images are separated from your hardrive, such as posting onto Flickr. The info is useful to you...I do understand that. However, the fact that the image came from ""2010/Christmas2010"" will not transfer to your Flickr upload, so it is important that you leverage something else, in particular keywords and tags that can be embedded into the image.

You can arrange your photos however you wish on the hard drive (date, event, or one big directory if you wish) and then in Lightroom create collections, tags, keywords and even what are called 'smart collections' that dynamically add images. You can tag images with keywords that will write to EXIF/IPTC, and use Lightroom's filters and search to show you related images. However it can be a bit of a pain to constantly search and filter, so Lightroom offers Collections, which are 'virtual directories' that contain images you have assigned to them. Of course, these have no relation to the actual directories on your hard drive, which is nice...you no longer have to worry about this aspect of organizing. And finally, there are Smart Collections, or virtual directories that are dynamic and automatic, so for example, you can create a Smart Collection based on certain keywords. Every new image with that keyword will be automatically added to the Smart Collection.

I find it helpful to have my images in directories related to year, then by day that I took the image: (2010/2010-12-25), because I recall when I took photos. Lightroom does this for me with its import utility. I simply tell Lightroom how I want to import, and it does automatically every time. Then, I tag images with keywords, typically related to events or subjects. If I have a particular event or project, I will create a collection to make it easy to return to (vs searching or filtering the view). For some items I create smart collections that are dynamic, such as images of family members.

When I upload to Smugmug, all the tags and keywords stay with the image, and they are easy to find on Smugmug as well.

Give Lightroom a try.
"
4188,4188,6680,"Is it awkward to say ""Good morning"" to roommate every day?","I know it is a bit weird to ask this question, yet in the country I am staying, China, people love to say ""Good morning"" to everyone every morning.

I have never been to other countries except China and I am going to study abroad in America.

Is this social etiquette the same in America and American people say ""Good morning"" to their roommate every day?
",Deniz Çağlayan,https://ell.stackexchange.com/users/10931,"
  Is this social etiquette the same in America and American people say
  ""Good morning"" to their roommate everyday?


It depends. Some people aren't morning people at all. They usually don't care for good mornings because it makes them upset that they are awake and still not sleeping. 

However, as long as the roommates aren't totally awkward with each other, I'd say it's OK. 

Remember the rule that ""what words you say generally don't matter, it's HOW you say it, and how it makes people feel that matter"".

So use a good, polite, energetic (but not fake enthusiastic) tone when saying good morning.

Sometimes a person may just be unhappy in general, like having depression, which is very common in America. Do not worry about this though. Still be polite, happy, and real to them and say what you want. Use good tone and manners. In time, they will hopefully be able to become happy again, and be glad it's a new morning.
",CRABOLO,https://ell.stackexchange.com/users/8858,http://ell.stackexchange.com/questions/35464/is-it-awkward-to-say-good-morning-to-roommate-every-day,CULTURE,ell.stackexchange.com,1.0,0.7777777777777778,0.3333333333333333,0.6666666666666666,0.0,0.3333333333333333,0.7777777777777778,0.7777777777777778,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,0.7777777777777778,"Is it embarrassing to say ""good morning"" to your roommate every day?","I know it is a bit weird to ask this question, yet in the country I am staying, China, people love to say ""Good morning"" to everyone every morning.

I have never been to other countries except China and I am going to study abroad in America.

Is this social etiquette the same in America and American people say ""Good morning"" to their roommate every day?
","
  Is this social etiquette the same in America and American people say
  ""Good morning"" to their roommate everyday?


It depends. Some people aren't morning people at all. They usually don't care for good mornings because it makes them upset that they are awake and still not sleeping. 

However, as long as the roommates aren't totally awkward with each other, I'd say it's OK. 

Remember the rule that ""what words you say generally don't matter, it's HOW you say it, and how it makes people feel that matter"".

So use a good, polite, energetic (but not fake enthusiastic) tone when saying good morning.

Sometimes a person may just be unhappy in general, like having depression, which is very common in America. Do not worry about this though. Still be polite, happy, and real to them and say what you want. Use good tone and manners. In time, they will hopefully be able to become happy again, and be glad it's a new morning.
"
2586,2586,4113,Native Browser Automation using Appium 1.2.0.1 on Windows 7 Android real device: Could not find a connected Android device,"I have looked many forums for this issue, there are quite a few answers on this topic but none of these have worked for me/match my criteria.

I recently took up Mobile Automation task and hence am completely new  to Appium. I am working with Appium 1.2.0.1 on Windows 7 and trying to automate the native Android Browser(not Chrome or an App) on an Android v4.3 real device. 
I have installed everything according to the instructions. I am using Selenium in Maven Build in JUnit Framework to execute the scripts through Appium. I use Appuim.exe in Admin mode and use the GUI to start the node. Then I run my scripts. 

My issue is that when I try ""adb devices"" in cmd, I am able to see the device. Whereas, during execution, Appium is throwing an Error ""Failed to start an Appium session, err was: Error: Could not find a connected Android device."" I tried many troubleshooting options and verified if everything is in place. No luck. Please help.

Below is the trace of Error:

&gt; Checking if an update is available
&gt; Update not available
&gt; Starting Node Server
&gt; info: Welcome to Appium v1.2.0 (REV e53f49c706a25242e66d36685c268b599cc18da5)
&gt; debug: Non-default server args: {""address"":""127.0.0.1"",""fullReset"":true,""logNoColors"":true,""platformName"":""Android"",""platformVersion"":""18"",""automationName"":""Appium"",""browserName"":""Browser""}
&gt; info: Appium REST http interface listener started on 127.0.0.1:4723
&gt; info: LogLevel: debug
&gt; info: --&gt; POST /wd/hub/session {""desiredCapabilities"":{""platformVersion"":""4.3"",""browserName"":""Browser"",""platformName"":""Android"",""device"":""Android"",""deviceName"":""Android""}}
&gt; debug: Appium request initiated at /wd/hub/session
&gt; info: Retrieving device
&gt; warn:  code=ENOENT, errno=ENOENT, syscall=spawn
&gt; debug: Request received with params: {""desiredCapabilities"":{""platformVersion"":""4.3"",""browserName"":""Browser"",""platformName"":""Android"",""device"":""Android"",""deviceName"":""Android""}}
&gt; debug: The following desired capabilities were provided, but not recognized by appium. They will be passed on to any other services running on this server. : device
&gt; debug: Looks like we want chrome on android
&gt; debug: Creating new appium session fa19e382-c178-4e6b-8150-a386a51bee39
&gt; debug: Preparing device for session
&gt; debug: Not checking whether app is present since we are assuming it's already on the device
&gt; debug: Checking whether adb is present
&gt; debug: Using adb from C:\Android\android-sdk\platform-tools\adb.exe
&gt; debug: Trying to find a connected android device
&gt; debug: Getting connected devices...
&gt; debug: executing: ""C:\Android\android-sdk\platform-tools\adb.exe"" devices
&gt; debug: Could not find devices, restarting adb server...
&gt; debug: executing: ""C:\Android\android-sdk\platform-tools\adb.exe"" kill-server
&gt; warn:  code=ENOENT, errno=ENOENT, syscall=spawn
&gt; warn:  code=ENOENT, errno=ENOENT, syscall=spawn
&gt; debug: Getting connected devices...
&gt; debug: executing: ""C:\Android\android-sdk\platform-tools\adb.exe"" devices
&gt; debug: Could not find devices, restarting adb server...
&gt; debug: executing: ""C:\Android\android-sdk\platform-tools\adb.exe"" kill-server
&gt; error: Error killing ADB server, going to see if it's online anyway
&gt; debug: Getting connected devices...
&gt; debug: executing: ""C:\Android\android-sdk\platform-tools\adb.exe"" devices
&gt; debug: Could not find devices, restarting adb server...
&gt; warn:  code=ENOENT, errno=ENOENT, syscall=spawn
&gt; warn:  code=ENOENT, errno=ENOENT, syscall=spawn
&gt; debug: executing: ""C:\Android\android-sdk\platform-tools\adb.exe"" kill-server
&gt; warn:  code=ENOENT, errno=ENOENT, syscall=spawn
&gt; error: Error killing ADB server, going to see if it's online anyway
&gt; warn:  code=ENOENT, errno=ENOENT, syscall=spawn
&gt; info: &lt;-- POST /wd/hub/session 500 20314.056 ms - 206 
&gt; debug: Getting connected devices...
&gt; debug: executing: ""C:\Android\android-sdk\platform-tools\adb.exe"" devices
&gt; debug: Cleaning up appium session
&gt; error: Failed to start an Appium session, err was: Error: Could not find a connected Android device.
&gt; debug: Error: Could not find a connected Android device.
&gt;     at ADB.getDevicesWithRetry (C:\Selenium\AppiumForWindows-1.2.0.1\Appium\node_modules\appium\node_modules\appium-adb\lib\adb.js:600:15)
&gt;     at androidCommon.prepareActiveDevice (C:\Selenium\AppiumForWindows-1.2.0.1\Appium\node_modules\appium\lib\devices\android\android-common.js:349:12)
&gt;     at null.&lt;anonymous&gt; (C:\Selenium\AppiumForWindows-1.2.0.1\Appium\node_modules\appium\lib\devices\android\android-common.js:289:26)
&gt;     at C:\Selenium\AppiumForWindows-1.2.0.1\Appium\node_modules\appium\node_modules\async\lib\async.js:610:21
&gt;     at C:\Selenium\AppiumForWindows-1.2.0.1\Appium\node_modules\appium\node_modules\async\lib\async.js:249:17
&gt;     at iterate (C:\Selenium\AppiumForWindows-1.2.0.1\Appium\node_modules\appium\node_modules\async\lib\async.js:149:13)
&gt;     at C:\Selenium\AppiumForWindows-1.2.0.1\Appium\node_modules\appium\node_modules\async\lib\async.js:160:25
&gt;     at C:\Selenium\AppiumForWindows-1.2.0.1\Appium\node_modules\appium\node_modules\async\lib\async.js:251:21
&gt;     at C:\Selenium\AppiumForWindows-1.2.0.1\Appium\node_modules\appium\node_modules\async\lib\async.js:615:34
&gt;     at androidCommon.prepareEmulator (C:\Selenium\AppiumForWindows-1.2.0.1\Appium\node_modules\appium\lib\devices\android\android-common.js:339:5)
&gt; debug: Responding to client with error: {""status"":33,""value"":{""message"":""A new session could not be created. (Original error: Could not find a connected Android device.)"",""origValue"":""Could not find a connected Android device.""},""sessionId"":null}


And here is my code:

if (runEnv.equals(""Android"")) 
        {
            DesiredCapabilities capabilities = new DesiredCapabilities();
              capabilities.setCapability(""device"",""Android"");
              capabilities.setCapability(""deviceName"",""Android"");
              capabilities.setCapability(""platformName"",""Android"");
              capabilities.setCapability(""browserName"", ""Browser"");
              capabilities.setCapability(""platformVersion"", ""4.3"");

              try {
                driver = new RemoteWebDriver(new URL(""http://127.0.0.1:4723/wd/hub""), capabilities);
            } catch (MalformedURLException e) {
                e.printStackTrace();
            }

            driver.manage().timeouts().implicitlyWait(80, TimeUnit.SECONDS);
        }


Please help!

Thanks,
Arpitha
",Arpitha Keshav,https://stackoverflow.com/users/4017740,"Please modify your code with the below one, hope so it works

DesiredCapabilities capabilities = new DesiredCapabilities();
   capabilities.setCapability(CapabilityType.BROWSER_NAME, """");
   capabilities.setCapability(""deviceName"",""sony xperia Z"");
   capabilities.setCapability(""platformVersion"", ""4.4"");
   capabilities.setCapability(""platformName"",""Android"");
   capabilities.setCapability(""appPackage"", ""com.android.calculator2"");
   capabilities.setCapability(""appActivity"", ""com.android.calculator2.Calculator"");
   driver = new AppiumDriver(new URL(""http://127.0.0.1:4723/wd/hub""), capabilities);

",Vignesh,https://stackoverflow.com/users/3668078,http://stackoverflow.com/questions/25717961/native-browser-automation-using-appium-1-2-0-1-on-windows-7-android-real-device,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.6666666666666666,0.0,1.0,1.0,1.0,0.4444444444444444,0.4444444444444444,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,1.0,0.0,0.7777777777777778,0.8888888888888888,0.5555555555555556,0.8888888888888888,1.0,0.9,1.0,0.0,0.0,0.7777777777777778,Native browser automation using appium 1.2.0.1 on Windows 7 Android real devices: no connected Android devices found,"I have looked many forums for this issue, there are quite a few answers on this topic but none of these have worked for me/match my criteria.

I recently took up Mobile Automation task and hence am completely new  to Appium. I am working with Appium 1.2.0.1 on Windows 7 and trying to automate the native Android Browser(not Chrome or an App) on an Android v4.3 real device. 
I have installed everything according to the instructions. I am using Selenium in Maven Build in JUnit Framework to execute the scripts through Appium. I use Appuim.exe in Admin mode and use the GUI to start the node. Then I run my scripts. 

My issue is that when I try ""adb devices"" in cmd, I am able to see the device. Whereas, during execution, Appium is throwing an Error ""Failed to start an Appium session, err was: Error: Could not find a connected Android device."" I tried many troubleshooting options and verified if everything is in place. No luck. Please help.

Below is the trace of Error:

&gt; Checking if an update is available
&gt; Update not available
&gt; Starting Node Server
&gt; info: Welcome to Appium v1.2.0 (REV e53f49c706a25242e66d36685c268b599cc18da5)
&gt; debug: Non-default server args: {""address"":""127.0.0.1"",""fullReset"":true,""logNoColors"":true,""platformName"":""Android"",""platformVersion"":""18"",""automationName"":""Appium"",""browserName"":""Browser""}
&gt; info: Appium REST http interface listener started on 127.0.0.1:4723
&gt; info: LogLevel: debug
&gt; info: --&gt; POST /wd/hub/session {""desiredCapabilities"":{""platformVersion"":""4.3"",""browserName"":""Browser"",""platformName"":""Android"",""device"":""Android"",""deviceName"":""Android""}}
&gt; debug: Appium request initiated at /wd/hub/session
&gt; info: Retrieving device
&gt; warn:  code=ENOENT, errno=ENOENT, syscall=spawn
&gt; debug: Request received with params: {""desiredCapabilities"":{""platformVersion"":""4.3"",""browserName"":""Browser"",""platformName"":""Android"",""device"":""Android"",""deviceName"":""Android""}}
&gt; debug: The following desired capabilities were provided, but not recognized by appium. They will be passed on to any other services running on this server. : device
&gt; debug: Looks like we want chrome on android
&gt; debug: Creating new appium session fa19e382-c178-4e6b-8150-a386a51bee39
&gt; debug: Preparing device for session
&gt; debug: Not checking whether app is present since we are assuming it's already on the device
&gt; debug: Checking whether adb is present
&gt; debug: Using adb from C:\Android\android-sdk\platform-tools\adb.exe
&gt; debug: Trying to find a connected android device
&gt; debug: Getting connected devices...
&gt; debug: executing: ""C:\Android\android-sdk\platform-tools\adb.exe"" devices
&gt; debug: Could not find devices, restarting adb server...
&gt; debug: executing: ""C:\Android\android-sdk\platform-tools\adb.exe"" kill-server
&gt; warn:  code=ENOENT, errno=ENOENT, syscall=spawn
&gt; warn:  code=ENOENT, errno=ENOENT, syscall=spawn
&gt; debug: Getting connected devices...
&gt; debug: executing: ""C:\Android\android-sdk\platform-tools\adb.exe"" devices
&gt; debug: Could not find devices, restarting adb server...
&gt; debug: executing: ""C:\Android\android-sdk\platform-tools\adb.exe"" kill-server
&gt; error: Error killing ADB server, going to see if it's online anyway
&gt; debug: Getting connected devices...
&gt; debug: executing: ""C:\Android\android-sdk\platform-tools\adb.exe"" devices
&gt; debug: Could not find devices, restarting adb server...
&gt; warn:  code=ENOENT, errno=ENOENT, syscall=spawn
&gt; warn:  code=ENOENT, errno=ENOENT, syscall=spawn
&gt; debug: executing: ""C:\Android\android-sdk\platform-tools\adb.exe"" kill-server
&gt; warn:  code=ENOENT, errno=ENOENT, syscall=spawn
&gt; error: Error killing ADB server, going to see if it's online anyway
&gt; warn:  code=ENOENT, errno=ENOENT, syscall=spawn
&gt; info: &lt;-- POST /wd/hub/session 500 20314.056 ms - 206 
&gt; debug: Getting connected devices...
&gt; debug: executing: ""C:\Android\android-sdk\platform-tools\adb.exe"" devices
&gt; debug: Cleaning up appium session
&gt; error: Failed to start an Appium session, err was: Error: Could not find a connected Android device.
&gt; debug: Error: Could not find a connected Android device.
&gt;     at ADB.getDevicesWithRetry (C:\Selenium\AppiumForWindows-1.2.0.1\Appium\node_modules\appium\node_modules\appium-adb\lib\adb.js:600:15)
&gt;     at androidCommon.prepareActiveDevice (C:\Selenium\AppiumForWindows-1.2.0.1\Appium\node_modules\appium\lib\devices\android\android-common.js:349:12)
&gt;     at null.&lt;anonymous&gt; (C:\Selenium\AppiumForWindows-1.2.0.1\Appium\node_modules\appium\lib\devices\android\android-common.js:289:26)
&gt;     at C:\Selenium\AppiumForWindows-1.2.0.1\Appium\node_modules\appium\node_modules\async\lib\async.js:610:21
&gt;     at C:\Selenium\AppiumForWindows-1.2.0.1\Appium\node_modules\appium\node_modules\async\lib\async.js:249:17
&gt;     at iterate (C:\Selenium\AppiumForWindows-1.2.0.1\Appium\node_modules\appium\node_modules\async\lib\async.js:149:13)
&gt;     at C:\Selenium\AppiumForWindows-1.2.0.1\Appium\node_modules\appium\node_modules\async\lib\async.js:160:25
&gt;     at C:\Selenium\AppiumForWindows-1.2.0.1\Appium\node_modules\appium\node_modules\async\lib\async.js:251:21
&gt;     at C:\Selenium\AppiumForWindows-1.2.0.1\Appium\node_modules\appium\node_modules\async\lib\async.js:615:34
&gt;     at androidCommon.prepareEmulator (C:\Selenium\AppiumForWindows-1.2.0.1\Appium\node_modules\appium\lib\devices\android\android-common.js:339:5)
&gt; debug: Responding to client with error: {""status"":33,""value"":{""message"":""A new session could not be created. (Original error: Could not find a connected Android device.)"",""origValue"":""Could not find a connected Android device.""},""sessionId"":null}


And here is my code:

if (runEnv.equals(""Android"")) 
        {
            DesiredCapabilities capabilities = new DesiredCapabilities();
              capabilities.setCapability(""device"",""Android"");
              capabilities.setCapability(""deviceName"",""Android"");
              capabilities.setCapability(""platformName"",""Android"");
              capabilities.setCapability(""browserName"", ""Browser"");
              capabilities.setCapability(""platformVersion"", ""4.3"");

              try {
                driver = new RemoteWebDriver(new URL(""http://127.0.0.1:4723/wd/hub""), capabilities);
            } catch (MalformedURLException e) {
                e.printStackTrace();
            }

            driver.manage().timeouts().implicitlyWait(80, TimeUnit.SECONDS);
        }


Please help!

Thanks,
Arpitha
","Please modify your code with the below one, hope so it works

DesiredCapabilities capabilities = new DesiredCapabilities();
   capabilities.setCapability(CapabilityType.BROWSER_NAME, """");
   capabilities.setCapability(""deviceName"",""sony xperia Z"");
   capabilities.setCapability(""platformVersion"", ""4.4"");
   capabilities.setCapability(""platformName"",""Android"");
   capabilities.setCapability(""appPackage"", ""com.android.calculator2"");
   capabilities.setCapability(""appActivity"", ""com.android.calculator2.Calculator"");
   driver = new AppiumDriver(new URL(""http://127.0.0.1:4723/wd/hub""), capabilities);

"
4298,4298,6850,Idolatry in churches allowed?,"It is very frequent to see idols of Jesus or any biblical entities in  a Church , So is such idolatry allowed by  the bible,considering the following verses?


  ""You must not make for yourself an idol of any kind or an image of anything in the heavens or on the earth or in the sea"".
  Exodus 20:4


History tells us that:


  sometimes objects that God instructed to be made were turned into
  idols by the Israelites. The Book of Numbers contains a narrative in
  which God instructed Moses to make a bronze snake as part of
  addressing a plague of venomous snakes that had broken out among the
  Israelites as a punishment for sin. The bronze snake is mentioned
  again in 2 Kings 18; however, rather than remaining a memorial of
  God's providence, it became an idol that the people named and
  worshiped. Thus the bronze snake was destroyed in King Hezekiah's
  reforms.


More specifically in India I see Christians carry idols of Jesus and other biblical  entities with them kiss them and revere them too. Infact they allow the Hindus in the Church and let them perform worship in their way(Like putting incense sticks, offering flowers , foodstuff to the Idol of Jesus etc) as shown below a very common view in India. I studied in a Christian school for 10 years and i am yet to see Christians not doing these things.

I have seen the same on TV and in videos of people venerating the Idol of biblical entities.


",JesusBoughtIslam,https://christianity.stackexchange.com/users/3812,"It is right to warn people against the sin of idolatry when they are committing it. But calling Christians idolaters  because they have images of Christ and the saints is based on misunderstanding or ignorance of what Bible says about the purpose and uses(both good and bad) of statues.   

Idolatry is forbidden in Bible in verses Ex. 20:4-5 and Ex.32:3. God forbad the worship of statues, but he did not forbid the religious use of statues.   

The use of objects for religious purpose is commanded by God as in Ex. 25:18-19:  


  Ex. 25:18 You are to make two cherubim of gold; you are to make them of hammered metal on the two ends of the atonement lid. 25:19 Make one cherub on one end and one cherub on the other end; from the atonement lid you are to make the cherubim on the two ends.   


Similar commands are also at 1Chr.28:18-19 and Ezekiel 41:17-18. In Num.21:8-9 God told Moses to make [a statue of] a fiery serpent, and set it on a pole; and everyone who is bitten, when he sees it, shall live.’ So Moses made a bronze serpent, and set it on a pole; and if serpent bit any man, he would look at the bronze serpent and live.  One had to look at the bronze statue of the serpent to be healed, which shows that statues could be used ritually, not merely as religious decorations.  

So God does not forbid the ritual use of religious images. the statues, paintings and other relics are mediums to recall the person or thing depicted and it helps to recall the life and examples of saints by looking at their pictures.   

All the three Abrahamic religions one way or the other use these mediums to strengthen their faith in one almighty God without breaking any of the command given by Him. As a corollary in other major  Abrahamic  religion i.e. Islam where it is strongly opposed to use of statues and pictures of Mohammed, it is an accepted practice to pray at Tombs of the saints (Pirs). Other acts like the use of pictures of religious shrines like Mecca and Rock of Dome is not at all considered as idolatry. Use of Moon and Star as a symbol of Islam and as also no:786 is very common in Islam. Even the veneration of printed verses from Koran is a common feature in Islamic faith. Many would also categorise the black stone in kaaba as the idol worship very much akin to Shiv lingam of Hinduism but it not taken as idol at all.  

It is when people begin to adore a statue or any of these mediums as god that the Lord becomes angry. Thus when people did start to worship the bronze serpent as a snake-god(whom they named “Nehushtan”), the righteous King Hezekiah had it destroyed (2Kings 18:4)   
",Seek forgiveness,https://christianity.stackexchange.com/users/2018,http://christianity.stackexchange.com/questions/14615/idolatry-in-churches-allowed,CULTURE,christianity.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,0.0,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.5555555555555556,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,0.8888888888888888,Are idolatry allowed in church?,"It is very frequent to see idols of Jesus or any biblical entities in  a Church , So is such idolatry allowed by  the bible,considering the following verses?


  ""You must not make for yourself an idol of any kind or an image of anything in the heavens or on the earth or in the sea"".
  Exodus 20:4


History tells us that:


  sometimes objects that God instructed to be made were turned into
  idols by the Israelites. The Book of Numbers contains a narrative in
  which God instructed Moses to make a bronze snake as part of
  addressing a plague of venomous snakes that had broken out among the
  Israelites as a punishment for sin. The bronze snake is mentioned
  again in 2 Kings 18; however, rather than remaining a memorial of
  God's providence, it became an idol that the people named and
  worshiped. Thus the bronze snake was destroyed in King Hezekiah's
  reforms.


More specifically in India I see Christians carry idols of Jesus and other biblical  entities with them kiss them and revere them too. Infact they allow the Hindus in the Church and let them perform worship in their way(Like putting incense sticks, offering flowers , foodstuff to the Idol of Jesus etc) as shown below a very common view in India. I studied in a Christian school for 10 years and i am yet to see Christians not doing these things.

I have seen the same on TV and in videos of people venerating the Idol of biblical entities.


","It is right to warn people against the sin of idolatry when they are committing it. But calling Christians idolaters  because they have images of Christ and the saints is based on misunderstanding or ignorance of what Bible says about the purpose and uses(both good and bad) of statues.   

Idolatry is forbidden in Bible in verses Ex. 20:4-5 and Ex.32:3. God forbad the worship of statues, but he did not forbid the religious use of statues.   

The use of objects for religious purpose is commanded by God as in Ex. 25:18-19:  


  Ex. 25:18 You are to make two cherubim of gold; you are to make them of hammered metal on the two ends of the atonement lid. 25:19 Make one cherub on one end and one cherub on the other end; from the atonement lid you are to make the cherubim on the two ends.   


Similar commands are also at 1Chr.28:18-19 and Ezekiel 41:17-18. In Num.21:8-9 God told Moses to make [a statue of] a fiery serpent, and set it on a pole; and everyone who is bitten, when he sees it, shall live.’ So Moses made a bronze serpent, and set it on a pole; and if serpent bit any man, he would look at the bronze serpent and live.  One had to look at the bronze statue of the serpent to be healed, which shows that statues could be used ritually, not merely as religious decorations.  

So God does not forbid the ritual use of religious images. the statues, paintings and other relics are mediums to recall the person or thing depicted and it helps to recall the life and examples of saints by looking at their pictures.   

All the three Abrahamic religions one way or the other use these mediums to strengthen their faith in one almighty God without breaking any of the command given by Him. As a corollary in other major  Abrahamic  religion i.e. Islam where it is strongly opposed to use of statues and pictures of Mohammed, it is an accepted practice to pray at Tombs of the saints (Pirs). Other acts like the use of pictures of religious shrines like Mecca and Rock of Dome is not at all considered as idolatry. Use of Moon and Star as a symbol of Islam and as also no:786 is very common in Islam. Even the veneration of printed verses from Koran is a common feature in Islamic faith. Many would also categorise the black stone in kaaba as the idol worship very much akin to Shiv lingam of Hinduism but it not taken as idol at all.  

It is when people begin to adore a statue or any of these mediums as god that the Lord becomes angry. Thus when people did start to worship the bronze serpent as a snake-god(whom they named “Nehushtan”), the righteous King Hezekiah had it destroyed (2Kings 18:4)   
"
2457,2457,3920,Isomorphism between quotient groups with normal subgroups,"I'm looking at a problem in my textbook and it says:

Let $ψ : G_1 → G_2$ be a surjective group homomorphism. Let $H_1$ be a normal subgroup of $G_1$ and suppose that $ψ(H_1) = H_2$. Prove or disprove that $G_1/H_1$ is isomorphic $G_2/H_2$.

So far, I know that since $H_1$ is normal in $G_1$, $H_2$ is also normal in $G_2$. I'm unsure how to proceed from here though, can someone give me a hint?
",jstnchng,https://math.stackexchange.com/users/185638,"The statement is wrong. Just take $G_1=\mathbb{Z}_2$, $H_1=\{0\}$, $G_2=\{0\}$. Then $H_2=\{0\}$ and $G_1/H_1=\mathbb{Z}_2$ is not isomorphic to $G_2/H_2=\{0\}$.
",user2097,https://math.stackexchange.com/users/170091,http://math.stackexchange.com/questions/986251/isomorphism-between-quotient-groups-with-normal-subgroups,SCIENCE,math.stackexchange.com,0.6666666666666666,0.3333333333333333,0.0,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.3333333333333333,0.0,0.5555555555555556,0.8888888888888888,0.7777777777777778,1.0,1.0,0.9333333333333332,1.0,0.0,0.3333333333333333,0.8888888888888888,Isomorphism of quotient groups of normal subgroups,"I'm looking at a problem in my textbook and it says:

Let $ψ : G_1 → G_2$ be a surjective group homomorphism. Let $H_1$ be a normal subgroup of $G_1$ and suppose that $ψ(H_1) = H_2$. Prove or disprove that $G_1/H_1$ is isomorphic $G_2/H_2$.

So far, I know that since $H_1$ is normal in $G_1$, $H_2$ is also normal in $G_2$. I'm unsure how to proceed from here though, can someone give me a hint?
","The statement is wrong. Just take $G_1=\mathbb{Z}_2$, $H_1=\{0\}$, $G_2=\{0\}$. Then $H_2=\{0\}$ and $G_1/H_1=\mathbb{Z}_2$ is not isomorphic to $G_2/H_2=\{0\}$.
"
3343,3343,5335,Increasing the search query limit (Apache Solr),"We want to create a search page with Apache Solr with an increased query limit. I was reading that using hook_search_execute was not a recommended way to do this.

Is this statement correct? What would be the recommended way to go about this?

Apache Solr Views module?

Some other solution?

The page absolutely has to have more than 10 search results, and no pager.
",Andrew Alexander,https://drupal.stackexchange.com/users/6491,"There is apparently a setting for this in the Apache Solr module itself.

Go to the specific search that you want to modify, and edit the ""Advanced Search Page Options"" value.
",Andrew Alexander,https://drupal.stackexchange.com/users/6491,http://drupal.stackexchange.com/questions/102365/increasing-the-search-query-limit-apache-solr,TECHNOLOGY,drupal.stackexchange.com,0.8888888888888888,0.4444444444444444,0.0,1.0,1.0,1.0,0.4444444444444444,0.4444444444444444,1.0,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.3333333333333333,1.0,0.6666666666666666,0.3333333333333333,0.0,0.8888888888888888,1.0,0.5555555555555556,1.0,1.0,0.9333333333333332,0.6666666666666666,0.3333333333333333,0.3333333333333333,1.0,Add search query restrictions (APACHE Solr),"We want to create a search page with Apache Solr with an increased query limit. I was reading that using hook_search_execute was not a recommended way to do this.

Is this statement correct? What would be the recommended way to go about this?

Apache Solr Views module?

Some other solution?

The page absolutely has to have more than 10 search results, and no pager.
","There is apparently a setting for this in the Apache Solr module itself.

Go to the specific search that you want to modify, and edit the ""Advanced Search Page Options"" value.
"
3371,3371,5379,How to use the displaymath environment within a table?,"I am trying to use the cases construct within a table. I tried to follow this example. When I copy paste the entire example, it compiles without an error. 

But when I try to reproduce it, I get immediately into trouble:

\documentclass{article}

\begin{document}

\begin{table}
\begin{tabular}{c}
\hline
\[ e \]    \\
\hline
\end{tabular}
\end{table}

\end{document}



  Bad math environment delimiter [ e ].


What am I doing wrong?
",Martin Drozdik,https://tex.stackexchange.com/users/17444,"The difference between your example and the one you refer to from how-to-add-equation-with-cases-inside-the-table is that you are trying to put a displayed equation into a ""centred"" table cell whereas the example puts one inside a ""paragraph"" in a tabular environment.

You either need to use a p-cell in your tabular environment:

\begin{tabular}{p{5cm}}
\hline
\[ e \]    \\
\hline
\end{tabular}


OR you can use a normal (centred) cell with in-line mathematics that you explicitly typeset in \displaystyle:

\begin{tabular}{c}
\hline
\(\displaystyle f(x)=\begin{cases}1,&amp;\text{if }x=1,\\0,&amp;\text{otherwise}\end{cases}\)
\hline
\end{tabular}


Of course, you could also leave the \displaystyle out here.

(Btw, here I am assuming that you have loaded the amsmath package for the \text command.)
",Andrew,https://tex.stackexchange.com/users/30471,http://tex.stackexchange.com/questions/208366/how-to-use-the-displaymath-environment-within-a-table,TECHNOLOGY,tex.stackexchange.com,0.8888888888888888,0.6666666666666666,0.0,1.0,1.0,1.0,0.6666666666666666,0.4444444444444444,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,1.0,0.8888888888888888,How to use the displaymath environment in tables?,"I am trying to use the cases construct within a table. I tried to follow this example. When I copy paste the entire example, it compiles without an error. 

But when I try to reproduce it, I get immediately into trouble:

\documentclass{article}

\begin{document}

\begin{table}
\begin{tabular}{c}
\hline
\[ e \]    \\
\hline
\end{tabular}
\end{table}

\end{document}



  Bad math environment delimiter [ e ].


What am I doing wrong?
","The difference between your example and the one you refer to from how-to-add-equation-with-cases-inside-the-table is that you are trying to put a displayed equation into a ""centred"" table cell whereas the example puts one inside a ""paragraph"" in a tabular environment.

You either need to use a p-cell in your tabular environment:

\begin{tabular}{p{5cm}}
\hline
\[ e \]    \\
\hline
\end{tabular}


OR you can use a normal (centred) cell with in-line mathematics that you explicitly typeset in \displaystyle:

\begin{tabular}{c}
\hline
\(\displaystyle f(x)=\begin{cases}1,&amp;\text{if }x=1,\\0,&amp;\text{otherwise}\end{cases}\)
\hline
\end{tabular}


Of course, you could also leave the \displaystyle out here.

(Btw, here I am assuming that you have loaded the amsmath package for the \text command.)
"
4175,4175,6663,Too many compound paths in illustrator.. need to merge and delete from an object,"Hello everyone I had been trying to cut out many paths from a single layer in Illustrator. I was trying to convert an anchor point so I could move it but apparently I have ran into a problem.. My image that was previously cut out from a white circle disappeared. 

I am transferring from photoshop but never had this problem before. I have many paths that are overlapped since I was trying to cut them all out from one layer.

Can I get any help on this? I can't seem to merge all the paths or compound shapes.. but everything that is within a path I want to delete from this white circle.

The layer that the paths are on is empty by the way 


",Kyle Ng,https://graphicdesign.stackexchange.com/users/29907,"
Move the circle below the other art. (optional but will help this make more sense)
Change the fill color of the circle to anything different than the other artwork (You can change it back later)
Select the circle and other art
Click the Merge button on the Pathfinder Panel
Choose Object &gt; Ungroup from the menu (optional but often helpful)
Use the Direct Selection Tool (white arrow) and click part of the circle.
Choose Select &gt; Same &gt; Fill &amp; Stroke from the menu
Choose Object &gt; Lock from the menu
Still using the Direct Selection Tool, click-drag a selection to encompass everything.
Hit the Delete key twice
Choose Object &gt; Unlock All from the menu
Change the fill color back to white


This should work. To assist any further I'd need access to the actual file.
",Scott,https://graphicdesign.stackexchange.com/users/3270,http://graphicdesign.stackexchange.com/questions/38609/too-many-compound-paths-in-illustrator-need-to-merge-and-delete-from-an-object,LIFE_ARTS,graphicdesign.stackexchange.com,0.8888888888888888,0.4444444444444444,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.4444444444444444,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.0,0.0,0.8888888888888888,Too many composite paths in illustrator.. Need to merge and delete from object,"Hello everyone I had been trying to cut out many paths from a single layer in Illustrator. I was trying to convert an anchor point so I could move it but apparently I have ran into a problem.. My image that was previously cut out from a white circle disappeared. 

I am transferring from photoshop but never had this problem before. I have many paths that are overlapped since I was trying to cut them all out from one layer.

Can I get any help on this? I can't seem to merge all the paths or compound shapes.. but everything that is within a path I want to delete from this white circle.

The layer that the paths are on is empty by the way 


","
Move the circle below the other art. (optional but will help this make more sense)
Change the fill color of the circle to anything different than the other artwork (You can change it back later)
Select the circle and other art
Click the Merge button on the Pathfinder Panel
Choose Object &gt; Ungroup from the menu (optional but often helpful)
Use the Direct Selection Tool (white arrow) and click part of the circle.
Choose Select &gt; Same &gt; Fill &amp; Stroke from the menu
Choose Object &gt; Lock from the menu
Still using the Direct Selection Tool, click-drag a selection to encompass everything.
Hit the Delete key twice
Choose Object &gt; Unlock All from the menu
Change the fill color back to white


This should work. To assist any further I'd need access to the actual file.
"
5587,5587,8867,What is the best introductory Bayesian statistics textbook?,"Which is the best introductory textbook for Bayesian statistics?

One book per answer, please.
",Shane,https://stats.stackexchange.com/users/5,"Not strictly Bayesian Statistics as such, but I can strongly recommend ""A First Course on Machine Learning"" by Rogers and Girolami, which is essentially an introduction to Bayesian approaches to machine learning.  Its very well structured and clear and aimed at students without a strong mathematical background.  This means it is a pretty good first introduction to Bayesian ideas.  There is also MATLAB/OCTAVE code which is a nice feature.
",Dikran Marsupial,https://stats.stackexchange.com/users/887,http://stats.stackexchange.com/questions/125/what-is-the-best-introductory-bayesian-statistics-textbook,SCIENCE,stats.stackexchange.com,1.0,1.0,0.6666666666666666,1.0,0.6666666666666666,0.0,0.5555555555555556,0.5555555555555556,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.3333333333333333,0.0,1.0,0.8888888888888888,0.6666666666666666,1.0,0.8888888888888888,0.8,0.0,0.0,1.0,1.0,What is the best introduction to Bayesian statistics?,Which is the best introduction to Bayesian statistics?,"It's not strictly Bayesian statistics, but I can strongly recommend ""the first course of machine learning"" by Rogers and Gilardi, which is basically an introduction to Bayesian methods of machine learning. It has a clear structure and aims at students without strong mathematical background. This means that this is the first introduction of a good Bayesian idea. Another good feature is Matlab / octave code."
1645,1645,2588,How can I get my SSL certificate signed by an CA for web application that runs on localhost,"I have a web application that runs on localhost. I have a self-signed certificate for tomcat configured but when loading the website on firefox, I get a security exception. Can I get a CA to sign my SSL certificate so that this error is not thrown?
",Questioner,https://security.stackexchange.com/users/47553,"You can create your own CA certificate, add that as a root CA on your machine then use that CA to sign your SSL certificate. http://msdn.microsoft.com/en-us/library/ms733813.aspx

Alternatively, assuming you own a domain name of some form, you could probably create an A record for localhost.yourdomain.com and point it to 127.0.0.1. You should then be able to get an SSL certificate signed for localhost.yourdomain.com, which you can then use instead of localhost (albeit only from your machine).
",thexacre,https://security.stackexchange.com/users/45850,http://security.stackexchange.com/questions/59049/how-can-i-get-my-ssl-certificate-signed-by-an-ca-for-web-application-that-runs-o,TECHNOLOGY,security.stackexchange.com,0.8888888888888888,0.7777777777777778,0.0,1.0,1.0,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9,1.0,0.0,0.0,0.8888888888888888,How to obtain SSL certificate signed by CA for web application running on local host,"I have a web application running on a local host. I've configured a self signed certificate for tomcat, but a security exception occurred while loading the website on Firefox. Can I have a CA sign my SSL certificate so that this error is not thrown?","You can create your own CA certificate, add that as a root CA on your machine then use that CA to sign your SSL certificate. http://msdn.microsoft.com/en-us/library/ms733813.aspx

Alternatively, assuming you own a domain name of some form, you could probably create an A record for localhost.yourdomain.com and point it to 127.0.0.1. You should then be able to get an SSL certificate signed for localhost.yourdomain.com, which you can then use instead of localhost (albeit only from your machine).
"
5944,5944,9418,Shared memory: shmget fails: No space left on device -- how to increase limits?,"I call shmget many times in my program, to get shm of of average size 85840 bytes. I obtain about 32771 shm ok, then shmget doesn't return a shm, but the error: ""No space left on device"".

I have increased the kernel limits to:

$ sysctl -A|grep shm
kernel.shmmax = 33554432
kernel.shmall = 1677721600
kernel.shmmni = 409600


But still get the issue. Why?

Do I have to put something into /etc/security/limits.conf too? I only have
""user             -       nofile          1000000""
because the program also opens about as many files as shms.

This is the output of free

$ free
          total       used       free     shared    buffers     cached
Mem:       8150236    7261676     888560          0     488100    3270792
-/+ buffers/cache:    3502784    4647452 
Swap:     12287992     554692   11733300


And ipcs

$ ipcs -lm                                                                         

------ Shared Memory Limits --------
max number of segments = 409600
max seg size (kbytes) = 1638400
max total shared memory (kbytes) = 6710886400
min seg size (bytes) = 1


Since I assume shm is capable of being swapped out, there should be enough space.
",j13r,https://serverfault.com/users/64249,"Use ipcs -l to check the limits actually in force, and ipcs -a and ipcs -m to see what is in use, so you can compare the output. Look at the nattch column: are there segments with no processes attached that were not removed when processes exited (which normally means the program crashed)? ipcrm can clear them, although if this is a test machine, a reboot is quicker (and will make sure your changes to limits are picked up).

Your kernel parameters seem odd. In particular, shmall is a count of pages, not bytes, and 4kB is the default page size (run getconf PAGESIZE to check what you are using). How many terabytes of RAM do you have? 

Now, you say you get about 32771 shared memory segments, which is also about 32768 (or 2 to the 15) which suggests a signed 16-bit int is the limiting factor. And what kernel are you running (as this will have its own limits)? The two may be related.
",ramruma,https://serverfault.com/users/28126,http://serverfault.com/questions/371068,TECHNOLOGY,serverfault.com,0.7777777777777778,0.5555555555555556,0.0,0.0,1.0,0.6666666666666666,0.6666666666666666,0.4444444444444444,0.6666666666666666,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,1.0,0.0,0.5555555555555556,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.8666666666666666,1.0,0.3333333333333333,0.6666666666666666,0.8888888888888888,Shared memory: shmget failed: there is no space left on the device -- how to increase the limit?,"I call shmget many times in my program, to get shm of of average size 85840 bytes. I obtain about 32771 shm ok, then shmget doesn't return a shm, but the error: ""No space left on device"".

I have increased the kernel limits to:

$ sysctl -A|grep shm
kernel.shmmax = 33554432
kernel.shmall = 1677721600
kernel.shmmni = 409600


But still get the issue. Why?

Do I have to put something into /etc/security/limits.conf too? I only have
""user             -       nofile          1000000""
because the program also opens about as many files as shms.

This is the output of free

$ free
          total       used       free     shared    buffers     cached
Mem:       8150236    7261676     888560          0     488100    3270792
-/+ buffers/cache:    3502784    4647452 
Swap:     12287992     554692   11733300


And ipcs

$ ipcs -lm                                                                         

------ Shared Memory Limits --------
max number of segments = 409600
max seg size (kbytes) = 1638400
max total shared memory (kbytes) = 6710886400
min seg size (bytes) = 1


Since I assume shm is capable of being swapped out, there should be enough space.
","Use ipcs -l to check the limits actually in force, and ipcs -a and ipcs -m to see what is in use, so you can compare the output. Look at the nattch column: are there segments with no processes attached that were not removed when processes exited (which normally means the program crashed)? ipcrm can clear them, although if this is a test machine, a reboot is quicker (and will make sure your changes to limits are picked up).

Your kernel parameters seem odd. In particular, shmall is a count of pages, not bytes, and 4kB is the default page size (run getconf PAGESIZE to check what you are using). How many terabytes of RAM do you have? 

Now, you say you get about 32771 shared memory segments, which is also about 32768 (or 2 to the 15) which suggests a signed 16-bit int is the limiting factor. And what kernel are you running (as this will have its own limits)? The two may be related.
"
3200,3200,5099,Hexagon with exscribed triangle,"I am learning tikz now, it is painfully slow, but I am slowly learning. I am trying to reproduce the image below.



Here is my code so far. This is basically a rip of from the pgf manual. 

\documentclass[10pt,a4paper]{article}
\usepackage{mathtools}
\usepackage{tikz}
\usetikzlibrary{calc}
\usetikzlibrary{backgrounds}
\usepgflibrary{shapes}
\usetikzlibrary{through}

\begin{document}

\begin{figure}[!htpb] \centering
\begin{tikzpicture}
\foreach \a in {5,...,5}{
 \draw[blue, dashed] (\a*2,0) circle(0.5cm);
\node[regular polygon, regular polygon sides=\a, minimum size=1cm, draw] at    (\a*2,0) {};
}
\end{tikzpicture}
\end{figure}
\end{document}


Some problems with this code


How do i scale this image?
How do I label each side ?
Once again, how do I make that pesky angle ? 
Is there a way to do this for a n-gon?


When I scaled the image using simply \begin{tikzpicture}[scale=3]... only the circle grew. Labeling each point manually is sort of tedious.. =(



EDIT: I DID IT WOEEE Code us ugly though... :D:DD:

\documentclass[10pt,a4paper]{article}
\usepackage{mathtools}
\usepackage{tikz}
\usetikzlibrary{calc}
\usetikzlibrary{backgrounds}
\usepgflibrary{shapes}
\usetikzlibrary{through}

\pgfdeclarelayer{background}
\pgfdeclarelayer{foreground}
\pgfsetlayers{background,main,foreground}

\begin{document}

\begin{figure}[!htbp]
\centering
\Large 
\begin{tikzpicture}[scale=1]
\node (A) [draw,thick,regular polygon, regular polygon sides=6, minimum     size=7cm,outer sep=0pt,fill=gray!20] {};
\node at (A.corner 1) [anchor=360/6*(1-1)+270] {$D$};
\node at (A.corner 2) [anchor=360/6*(2-1)+270] {$E$};
\node at (A.corner 3) [anchor=360/6*(3-1)+270] {$F$};
\node at (A.corner 4) [anchor=360/6*(4-1)+270] {$A$};
\node at (A.corner 5) [anchor=360/6*(5-1)+270] {$B$};
\node at (A.corner 6) [anchor=360/6*(5-1)+270] {$C$};
\node at (A.corner 4) [right,above] {\hspace{3.5cm}$AB=16$cm};
\coordinate [label=above:\textcolor{blue}{$S$}] (S) at (0.95,1);
\draw[gray, thick, dashed] (0,0) circle(3.52cm);
\path[draw] (0.7,-0.3) node {$\alpha$};
{
\begin{pgfonlayer}{foreground}
\draw[gray,thick, dashed] (A.corner 4) -- (S) -- (A.corner 5);
\end{pgfonlayer}
}

\begin{scope}
  \path[clip] (S) -- (A.corner 4) -- (A.corner 5) -- cycle;
  \draw [red, fill=red!20] (S) circle (30pt);
  \draw [black] (S) circle (30pt);
\end{scope}
\end{tikzpicture}
\end{figure}
\end{document}

",N3buchadnezzar,https://tex.stackexchange.com/users/8306,"For scaling, add the transform shape option. That might not look too great though. You are probably better off modifying the minimum size and the circle. To label the sides you can use distance modifiers on the anchors, same for the corner points. For the angle you can either use tkz-euclid or (if you know the angle (or are willing to guess it like me)) you can just draw an arc. To generalize this to an n-gon, use a parameter instead of the for-loop (which does nothing now...) and draw using that. Of course the angle and the corresponging AB line won't be correct anymore, but the labelling will. This is what the code would look like:

\documentclass[10pt,a4paper]{article}
\usepackage{mathtools}
\usepackage{tikz}
\usetikzlibrary{calc}
\usetikzlibrary{backgrounds}
\usepgflibrary{shapes}
\usetikzlibrary{through}
\begin{document}
\begin{figure}[!htpb] \centering
\begin{tikzpicture}
\pgfmathsetmacro{\a}{6}
\newcounter{temp}
\draw[dashed] (\a*2,0) circle(3cm);
\node[regular polygon, regular polygon sides=\a, minimum size=6cm, draw, blue, fill=blue!20] (poly) at (\a*2,0) {};
\foreach [count=\side] \siide in {2,3,...,\a,1}{
  \pgfmathtruncatemacro{\opp}{mod(\side+\a/2,\a)}
  \pgfmathtruncatemacro{\opp}{ifthenelse(equal(\opp,0),\a,\opp)}
  \pgfmathtruncatemacro{\opi}{ifthenelse(equal(mod(\a,2),0),1,0)}
  \def\oppp{\ifnum\opi=0 poly.side \opp\else poly.corner \opp\fi}
  \node at ($(poly.side \side)!.15!270:(poly.corner \siide)$)  {\side};
  \node at ($(\oppp)!1.05!(poly.corner \side)$) {\setcounter{temp}{\side}\Alph{temp}};
}
\coordinate (S) at ($(poly.corner 5) + (100:3)$);
\begin{scope}
  \path[clip] (poly.corner 4) -- (S) -- (poly.corner 5) -- cycle;
  \path[draw,blue,fill=blue!50] (S) circle[radius=.4];
  \path (S) ++(255:.6) node {$\alpha$};
\end{scope}
\node at ($(poly.corner 4)!.5!(poly.corner 5)$) [above] {$DE = 16$cm};
\node at (S) [above] {S};
\path[draw,dashed] (poly.corner 5) -- (S) -- (poly.corner 4);
\end{tikzpicture}
\end{figure}
\end{document}


To clarify the code a little bit, the distance modifiers work as follows: (A)!x!a:(B) means take the point that is factor x on the line from A to B, then rotate it by a degrees around A. This allows us to place the labels roughly where we want them, without having to explicitly set them (the angles might need slight adjusting for larger polygons).

And the resulting output:



EDIT: Changed the code to place the labels to use the opposite corner. It uses the opposite side if the number of sides is odd. This way the placement of the labels will work for n-gons for pretty much any value of n. I also changed the angle to use the clipping approach instead of estimating it. Finally, I changed the way the node is drawn on the line, to ensure there is no difference in colour.

That makes the result looks like this, showing the normal hexagon and a 9-gon:


",Roelof Spijker,https://tex.stackexchange.com/users/8344,http://tex.stackexchange.com/questions/35266/hexagon-with-exscribed-triangle,TECHNOLOGY,tex.stackexchange.com,1.0,0.3333333333333333,0.0,0.0,1.0,1.0,0.5555555555555556,0.4444444444444444,1.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.8888888888888888,1.0,0.7777777777777778,0.8888888888888888,1.0,1.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,1.0,Circumscribed triangle hexagon,"I am learning tikz now, it is painfully slow, but I am slowly learning. I am trying to reproduce the image below.



Here is my code so far. This is basically a rip of from the pgf manual. 

\documentclass[10pt,a4paper]{article}
\usepackage{mathtools}
\usepackage{tikz}
\usetikzlibrary{calc}
\usetikzlibrary{backgrounds}
\usepgflibrary{shapes}
\usetikzlibrary{through}

\begin{document}

\begin{figure}[!htpb] \centering
\begin{tikzpicture}
\foreach \a in {5,...,5}{
 \draw[blue, dashed] (\a*2,0) circle(0.5cm);
\node[regular polygon, regular polygon sides=\a, minimum size=1cm, draw] at    (\a*2,0) {};
}
\end{tikzpicture}
\end{figure}
\end{document}


Some problems with this code


How do i scale this image?
How do I label each side ?
Once again, how do I make that pesky angle ? 
Is there a way to do this for a n-gon?


When I scaled the image using simply \begin{tikzpicture}[scale=3]... only the circle grew. Labeling each point manually is sort of tedious.. =(



EDIT: I DID IT WOEEE Code us ugly though... :D:DD:

\documentclass[10pt,a4paper]{article}
\usepackage{mathtools}
\usepackage{tikz}
\usetikzlibrary{calc}
\usetikzlibrary{backgrounds}
\usepgflibrary{shapes}
\usetikzlibrary{through}

\pgfdeclarelayer{background}
\pgfdeclarelayer{foreground}
\pgfsetlayers{background,main,foreground}

\begin{document}

\begin{figure}[!htbp]
\centering
\Large 
\begin{tikzpicture}[scale=1]
\node (A) [draw,thick,regular polygon, regular polygon sides=6, minimum     size=7cm,outer sep=0pt,fill=gray!20] {};
\node at (A.corner 1) [anchor=360/6*(1-1)+270] {$D$};
\node at (A.corner 2) [anchor=360/6*(2-1)+270] {$E$};
\node at (A.corner 3) [anchor=360/6*(3-1)+270] {$F$};
\node at (A.corner 4) [anchor=360/6*(4-1)+270] {$A$};
\node at (A.corner 5) [anchor=360/6*(5-1)+270] {$B$};
\node at (A.corner 6) [anchor=360/6*(5-1)+270] {$C$};
\node at (A.corner 4) [right,above] {\hspace{3.5cm}$AB=16$cm};
\coordinate [label=above:\textcolor{blue}{$S$}] (S) at (0.95,1);
\draw[gray, thick, dashed] (0,0) circle(3.52cm);
\path[draw] (0.7,-0.3) node {$\alpha$};
{
\begin{pgfonlayer}{foreground}
\draw[gray,thick, dashed] (A.corner 4) -- (S) -- (A.corner 5);
\end{pgfonlayer}
}

\begin{scope}
  \path[clip] (S) -- (A.corner 4) -- (A.corner 5) -- cycle;
  \draw [red, fill=red!20] (S) circle (30pt);
  \draw [black] (S) circle (30pt);
\end{scope}
\end{tikzpicture}
\end{figure}
\end{document}

","For scaling, add the transform shape option. That might not look too great though. You are probably better off modifying the minimum size and the circle. To label the sides you can use distance modifiers on the anchors, same for the corner points. For the angle you can either use tkz-euclid or (if you know the angle (or are willing to guess it like me)) you can just draw an arc. To generalize this to an n-gon, use a parameter instead of the for-loop (which does nothing now...) and draw using that. Of course the angle and the corresponging AB line won't be correct anymore, but the labelling will. This is what the code would look like:

\documentclass[10pt,a4paper]{article}
\usepackage{mathtools}
\usepackage{tikz}
\usetikzlibrary{calc}
\usetikzlibrary{backgrounds}
\usepgflibrary{shapes}
\usetikzlibrary{through}
\begin{document}
\begin{figure}[!htpb] \centering
\begin{tikzpicture}
\pgfmathsetmacro{\a}{6}
\newcounter{temp}
\draw[dashed] (\a*2,0) circle(3cm);
\node[regular polygon, regular polygon sides=\a, minimum size=6cm, draw, blue, fill=blue!20] (poly) at (\a*2,0) {};
\foreach [count=\side] \siide in {2,3,...,\a,1}{
  \pgfmathtruncatemacro{\opp}{mod(\side+\a/2,\a)}
  \pgfmathtruncatemacro{\opp}{ifthenelse(equal(\opp,0),\a,\opp)}
  \pgfmathtruncatemacro{\opi}{ifthenelse(equal(mod(\a,2),0),1,0)}
  \def\oppp{\ifnum\opi=0 poly.side \opp\else poly.corner \opp\fi}
  \node at ($(poly.side \side)!.15!270:(poly.corner \siide)$)  {\side};
  \node at ($(\oppp)!1.05!(poly.corner \side)$) {\setcounter{temp}{\side}\Alph{temp}};
}
\coordinate (S) at ($(poly.corner 5) + (100:3)$);
\begin{scope}
  \path[clip] (poly.corner 4) -- (S) -- (poly.corner 5) -- cycle;
  \path[draw,blue,fill=blue!50] (S) circle[radius=.4];
  \path (S) ++(255:.6) node {$\alpha$};
\end{scope}
\node at ($(poly.corner 4)!.5!(poly.corner 5)$) [above] {$DE = 16$cm};
\node at (S) [above] {S};
\path[draw,dashed] (poly.corner 5) -- (S) -- (poly.corner 4);
\end{tikzpicture}
\end{figure}
\end{document}


To clarify the code a little bit, the distance modifiers work as follows: (A)!x!a:(B) means take the point that is factor x on the line from A to B, then rotate it by a degrees around A. This allows us to place the labels roughly where we want them, without having to explicitly set them (the angles might need slight adjusting for larger polygons).

And the resulting output:



EDIT: Changed the code to place the labels to use the opposite corner. It uses the opposite side if the number of sides is odd. This way the placement of the labels will work for n-gons for pretty much any value of n. I also changed the angle to use the clipping approach instead of estimating it. Finally, I changed the way the node is drawn on the line, to ensure there is no difference in colour.

That makes the result looks like this, showing the normal hexagon and a 9-gon:


"
903,903,1435,High ping on games while streaming,"I'm streaming with Elgato Capture Card to Twitch. I get high pings on games while streaming (1700kbps). How can I decrease pings while streaming? Here is my bandwidth:


",WalkerJetBat,https://gaming.stackexchange.com/users/76837,"The problem is you upload speed =(. When you are streaming, you are sending a lot of data, so your ping will get highter. You may call to your internet service provider (ISP) to ask if they can raise your upload speed.

Also try to decrease the quality of your stream. By quality I mean, for example, from 720p to 480p.
",Seva,https://gaming.stackexchange.com/users/63405,http://gaming.stackexchange.com/questions/168457/high-ping-on-games-while-streaming,CULTURE,gaming.stackexchange.com,1.0,0.5,0.0,1.0,1.0,1.0,0.5,0.3333333333333333,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,1.0,0.5,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,1.0,0.5,0.5,1.0,0.8333333333333334,High Ping of games in streaming media,I'm twitching with the elgato capture card. I get high Ping when playing streaming (1700kbps). How to reduce Ping during streaming? This is my bandwidth:,"The problem is you upload speed =(. When you are streaming, you are sending a lot of data, so your ping will get highter. You may call to your internet service provider (ISP) to ask if they can raise your upload speed.

Also try to decrease the quality of your stream. By quality I mean, for example, from 720p to 480p.
"
3823,3823,6081,Changing PhD topic and effect on career,"I'm a PhD student in my third year (4-6 is common in my country) and seriously consider abandoning my current topic. 
The new topic is in the same general field (CS related), yet in a vastly different domain and would need a quite different methods. My advisor suggested this switch, he could keep me funded in both cases, yet probably better with the new topic.

Arguments for switching are both personal interest in the new topic (it's recently trending, I was interested from the beginning, yet few positions were available) and lack of progress in the current area:


I could produce some publications, yet not up to my advisors expectations (should be easier with the new topic, given the impact factors of the journals my advisor suggested)
For the last 6-8 month I made barely any progress (lots of failed experiments)
I would probably have to abandon my current methods anyway due to 1./2., so half a year or so will be lost learning new methods no matter how I decide


Yet I shy away from switching, mainly due to already being quite old (combination of personal problems and a switch of my major as an undergraduate) and fearing how my C.V. would look if I did take about a year longer and had this second switch...

Thanks for any input.
",throwAway,https://academia.stackexchange.com/users/35361,"
  For the last 6-8 month I made barely any progress (lots of failed
  experiments)


This sounds like you have not treated your prelims as a contract negotiation. 

The best advice I've received is that when you pitch your thesis topic to the committee, make sure that everyone agrees on the structure and methodologies involved. That way, if your work falters or your experiments fail, but you followed the guidance outlined by your committee, then you have still earned a pass.

Another piece of great advice is this: nobody is going to read your thesis. 

Do not switch your program and do not start over, just complete the tasks you were given and move on. If you decide to switch fields later on, fine... that's normal, reasonable, and expected.

And just because you're studying one thing in school doesn't mean that's what you have to do for the rest of your life. There have been plenty of PhDs that completely jumped fields of study, out of CS and into sociology for example... or vice versa. Besides, the latest rage these days is adding ""multi-disciplinary"" to your grant proposals.
",Twitch,https://academia.stackexchange.com/users/10817,http://academia.stackexchange.com/questions/46479/changing-phd-topic-and-effect-on-career,LIFE_ARTS,academia.stackexchange.com,1.0,0.5555555555555556,0.6666666666666666,0.0,0.0,0.0,0.6666666666666666,0.7777777777777778,0.0,0.0,1.0,0.6666666666666666,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,0.7777777777777778,0.8,0.0,0.0,1.0,1.0,The change of doctoral topic and its influence on career,"I'm a PhD student in my third year (4-6 is common in my country) and seriously consider abandoning my current topic. 
The new topic is in the same general field (CS related), yet in a vastly different domain and would need a quite different methods. My advisor suggested this switch, he could keep me funded in both cases, yet probably better with the new topic.

Arguments for switching are both personal interest in the new topic (it's recently trending, I was interested from the beginning, yet few positions were available) and lack of progress in the current area:


I could produce some publications, yet not up to my advisors expectations (should be easier with the new topic, given the impact factors of the journals my advisor suggested)
For the last 6-8 month I made barely any progress (lots of failed experiments)
I would probably have to abandon my current methods anyway due to 1./2., so half a year or so will be lost learning new methods no matter how I decide


Yet I shy away from switching, mainly due to already being quite old (combination of personal problems and a switch of my major as an undergraduate) and fearing how my C.V. would look if I did take about a year longer and had this second switch...

Thanks for any input.
","
  For the last 6-8 month I made barely any progress (lots of failed
  experiments)


This sounds like you have not treated your prelims as a contract negotiation. 

The best advice I've received is that when you pitch your thesis topic to the committee, make sure that everyone agrees on the structure and methodologies involved. That way, if your work falters or your experiments fail, but you followed the guidance outlined by your committee, then you have still earned a pass.

Another piece of great advice is this: nobody is going to read your thesis. 

Do not switch your program and do not start over, just complete the tasks you were given and move on. If you decide to switch fields later on, fine... that's normal, reasonable, and expected.

And just because you're studying one thing in school doesn't mean that's what you have to do for the rest of your life. There have been plenty of PhDs that completely jumped fields of study, out of CS and into sociology for example... or vice versa. Besides, the latest rage these days is adding ""multi-disciplinary"" to your grant proposals.
"
3397,3397,5416,what is exactly the difference between the Selberg class and the set of Artin L-functions?,"The question is in the title: from what I read in the answer to another question, Artin L-functions are conjecturally cuspidal automorphic L-functions for some algebraic group that can be transfered to $GL_{n}$. On the other hand, elements of the Selberg class are widely believed to be (cuspidal?) automorphic L-functions for $GL_{n}$. So where exactly lies the difference between those two sets of L-functions?
Thanks in advance.
",Sylvain JULIEN,https://mathoverflow.net/users/13625,"The essential answer has already been given but here are a few extra thoughts.

Artin L-functions are defined from a representation of a Galois group on a compex vector space, wheras Hasse--Weil (which are motivic) L-functions are defined by a Galois action on an l-adic one. In the former case, for topological reasons a complex representation of the infinite Galois group Gal$(\overline{\mathbb{Q}}/\mathbb{Q})$ factors through the Galois group of a finite extension $K/\mathbb{Q}$. This is not so for the $l$-adic representations. Hasse--Weil $L$-functions, much like Artin's, are expected to be the $L$-functions of cuspidal automorphic representations.

I notice you query the word ""cuspidal"" in your question. There are automorphic forms, such as Eisenstein series, which are not cuspidal. Basically this means there is a non-zero constant term in the Fourier expansion. This constant term is closely related to a pole of the $L$-function. To see this, all one needs is Mellin inversion and the residue theorem. Artin $L$-functions can be easily proved meromorphic, as a simple application of the Brauer induction theorem, but they are expected to moreover be holomorphic, and this is not known in generality. This holomorphy is crucial in the application of the so-called converse theorems which would give automorphy of Artin $L$-functions.
",Tom163,https://mathoverflow.net/users/36282,http://mathoverflow.net/questions/207306,SCIENCE,mathoverflow.net,0.6666666666666666,0.8333333333333334,0.0,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.6666666666666666,0.8333333333333334,1.0,0.8333333333333334,0.6,0.0,0.0,0.5,0.8333333333333334,What is the difference between Selberg class and Artin L-function set?,"Question in the title: according to what I read in the answer to another question, Artin L-functions are some creepy self-sustaining L-functions of algebraic groups that can be transferred to $GL {n} $. On the other hand, it is generally believed that Selberg elements are (creepy?) The automorphic L-function of $GL {n} $. So what's the difference between these two sets of L-functions?","The essential answer has already been given but here are a few extra thoughts.

Artin L-functions are defined from a representation of a Galois group on a compex vector space, wheras Hasse--Weil (which are motivic) L-functions are defined by a Galois action on an l-adic one. In the former case, for topological reasons a complex representation of the infinite Galois group Gal$(\overline{\mathbb{Q}}/\mathbb{Q})$ factors through the Galois group of a finite extension $K/\mathbb{Q}$. This is not so for the $l$-adic representations. Hasse--Weil $L$-functions, much like Artin's, are expected to be the $L$-functions of cuspidal automorphic representations.

I notice you query the word ""cuspidal"" in your question. There are automorphic forms, such as Eisenstein series, which are not cuspidal. Basically this means there is a non-zero constant term in the Fourier expansion. This constant term is closely related to a pole of the $L$-function. To see this, all one needs is Mellin inversion and the residue theorem. Artin $L$-functions can be easily proved meromorphic, as a simple application of the Brauer induction theorem, but they are expected to moreover be holomorphic, and this is not known in generality. This holomorphy is crucial in the application of the so-called converse theorems which would give automorphy of Artin $L$-functions.
"
1906,1906,3038,up sample and down sample,"Let's say that I have a sampled signal x[n], it is being, in this exact order, up sampled by 2, down sampled by4, up sampled by 4 and down sampled by 2 to produce y[n].

It seems to me that it should be pretty self evident that since we up sampled the signal by 2 and down sampled it by 2, then up sampled it by 4 and down sampled by 4, I should just get the original x[n] back. 

Am I right?

So the real question is, can the various up/down sampling pieces be readily swapped?
",D.Zou,https://dsp.stackexchange.com/users/11151,"The downsampling by a factor of 4 can introduce aliasing (because you upsampled only by a factor 2 in the first stage). If this is the case, it cannot be undone by the following upsampling operation. So in general this system will not produce at its output the original input signal $x[n]$.
",Matt L.,https://dsp.stackexchange.com/users/4298,http://dsp.stackexchange.com/questions/18737/up-sample-and-down-sample,TECHNOLOGY,dsp.stackexchange.com,0.6666666666666666,0.3333333333333333,0.0,0.0,1.0,1.0,0.3333333333333333,1.0,0.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.0,1.0,Sample under sampling,"Let's say that I have a sampled signal x[n], it is being, in this exact order, up sampled by 2, down sampled by4, up sampled by 4 and down sampled by 2 to produce y[n].

It seems to me that it should be pretty self evident that since we up sampled the signal by 2 and down sampled it by 2, then up sampled it by 4 and down sampled by 4, I should just get the original x[n] back. 

Am I right?

So the real question is, can the various up/down sampling pieces be readily swapped?
","The downsampling by a factor of 4 can introduce aliasing (because you upsampled only by a factor 2 in the first stage). If this is the case, it cannot be undone by the following upsampling operation. So in general this system will not produce at its output the original input signal $x[n]$.
"
3283,3283,5235,Native Browser Automation using Appium 1.2.0.1 on Windows 7 Android real device: Could not find a connected Android device,"I have looked many forums for this issue, there are quite a few answers on this topic but none of these have worked for me/match my criteria.

I recently took up Mobile Automation task and hence am completely new  to Appium. I am working with Appium 1.2.0.1 on Windows 7 and trying to automate the native Android Browser(not Chrome or an App) on an Android v4.3 real device. 
I have installed everything according to the instructions. I am using Selenium in Maven Build in JUnit Framework to execute the scripts through Appium. I use Appuim.exe in Admin mode and use the GUI to start the node. Then I run my scripts. 

My issue is that when I try ""adb devices"" in cmd, I am able to see the device. Whereas, during execution, Appium is throwing an Error ""Failed to start an Appium session, err was: Error: Could not find a connected Android device."" I tried many troubleshooting options and verified if everything is in place. No luck. Please help.

Below is the trace of Error:

&gt; Checking if an update is available
&gt; Update not available
&gt; Starting Node Server
&gt; info: Welcome to Appium v1.2.0 (REV e53f49c706a25242e66d36685c268b599cc18da5)
&gt; debug: Non-default server args: {""address"":""127.0.0.1"",""fullReset"":true,""logNoColors"":true,""platformName"":""Android"",""platformVersion"":""18"",""automationName"":""Appium"",""browserName"":""Browser""}
&gt; info: Appium REST http interface listener started on 127.0.0.1:4723
&gt; info: LogLevel: debug
&gt; info: --&gt; POST /wd/hub/session {""desiredCapabilities"":{""platformVersion"":""4.3"",""browserName"":""Browser"",""platformName"":""Android"",""device"":""Android"",""deviceName"":""Android""}}
&gt; debug: Appium request initiated at /wd/hub/session
&gt; info: Retrieving device
&gt; warn:  code=ENOENT, errno=ENOENT, syscall=spawn
&gt; debug: Request received with params: {""desiredCapabilities"":{""platformVersion"":""4.3"",""browserName"":""Browser"",""platformName"":""Android"",""device"":""Android"",""deviceName"":""Android""}}
&gt; debug: The following desired capabilities were provided, but not recognized by appium. They will be passed on to any other services running on this server. : device
&gt; debug: Looks like we want chrome on android
&gt; debug: Creating new appium session fa19e382-c178-4e6b-8150-a386a51bee39
&gt; debug: Preparing device for session
&gt; debug: Not checking whether app is present since we are assuming it's already on the device
&gt; debug: Checking whether adb is present
&gt; debug: Using adb from C:\Android\android-sdk\platform-tools\adb.exe
&gt; debug: Trying to find a connected android device
&gt; debug: Getting connected devices...
&gt; debug: executing: ""C:\Android\android-sdk\platform-tools\adb.exe"" devices
&gt; debug: Could not find devices, restarting adb server...
&gt; debug: executing: ""C:\Android\android-sdk\platform-tools\adb.exe"" kill-server
&gt; warn:  code=ENOENT, errno=ENOENT, syscall=spawn
&gt; warn:  code=ENOENT, errno=ENOENT, syscall=spawn
&gt; debug: Getting connected devices...
&gt; debug: executing: ""C:\Android\android-sdk\platform-tools\adb.exe"" devices
&gt; debug: Could not find devices, restarting adb server...
&gt; debug: executing: ""C:\Android\android-sdk\platform-tools\adb.exe"" kill-server
&gt; error: Error killing ADB server, going to see if it's online anyway
&gt; debug: Getting connected devices...
&gt; debug: executing: ""C:\Android\android-sdk\platform-tools\adb.exe"" devices
&gt; debug: Could not find devices, restarting adb server...
&gt; warn:  code=ENOENT, errno=ENOENT, syscall=spawn
&gt; warn:  code=ENOENT, errno=ENOENT, syscall=spawn
&gt; debug: executing: ""C:\Android\android-sdk\platform-tools\adb.exe"" kill-server
&gt; warn:  code=ENOENT, errno=ENOENT, syscall=spawn
&gt; error: Error killing ADB server, going to see if it's online anyway
&gt; warn:  code=ENOENT, errno=ENOENT, syscall=spawn
&gt; info: &lt;-- POST /wd/hub/session 500 20314.056 ms - 206 
&gt; debug: Getting connected devices...
&gt; debug: executing: ""C:\Android\android-sdk\platform-tools\adb.exe"" devices
&gt; debug: Cleaning up appium session
&gt; error: Failed to start an Appium session, err was: Error: Could not find a connected Android device.
&gt; debug: Error: Could not find a connected Android device.
&gt;     at ADB.getDevicesWithRetry (C:\Selenium\AppiumForWindows-1.2.0.1\Appium\node_modules\appium\node_modules\appium-adb\lib\adb.js:600:15)
&gt;     at androidCommon.prepareActiveDevice (C:\Selenium\AppiumForWindows-1.2.0.1\Appium\node_modules\appium\lib\devices\android\android-common.js:349:12)
&gt;     at null.&lt;anonymous&gt; (C:\Selenium\AppiumForWindows-1.2.0.1\Appium\node_modules\appium\lib\devices\android\android-common.js:289:26)
&gt;     at C:\Selenium\AppiumForWindows-1.2.0.1\Appium\node_modules\appium\node_modules\async\lib\async.js:610:21
&gt;     at C:\Selenium\AppiumForWindows-1.2.0.1\Appium\node_modules\appium\node_modules\async\lib\async.js:249:17
&gt;     at iterate (C:\Selenium\AppiumForWindows-1.2.0.1\Appium\node_modules\appium\node_modules\async\lib\async.js:149:13)
&gt;     at C:\Selenium\AppiumForWindows-1.2.0.1\Appium\node_modules\appium\node_modules\async\lib\async.js:160:25
&gt;     at C:\Selenium\AppiumForWindows-1.2.0.1\Appium\node_modules\appium\node_modules\async\lib\async.js:251:21
&gt;     at C:\Selenium\AppiumForWindows-1.2.0.1\Appium\node_modules\appium\node_modules\async\lib\async.js:615:34
&gt;     at androidCommon.prepareEmulator (C:\Selenium\AppiumForWindows-1.2.0.1\Appium\node_modules\appium\lib\devices\android\android-common.js:339:5)
&gt; debug: Responding to client with error: {""status"":33,""value"":{""message"":""A new session could not be created. (Original error: Could not find a connected Android device.)"",""origValue"":""Could not find a connected Android device.""},""sessionId"":null}


And here is my code:

if (runEnv.equals(""Android"")) 
        {
            DesiredCapabilities capabilities = new DesiredCapabilities();
              capabilities.setCapability(""device"",""Android"");
              capabilities.setCapability(""deviceName"",""Android"");
              capabilities.setCapability(""platformName"",""Android"");
              capabilities.setCapability(""browserName"", ""Browser"");
              capabilities.setCapability(""platformVersion"", ""4.3"");

              try {
                driver = new RemoteWebDriver(new URL(""http://127.0.0.1:4723/wd/hub""), capabilities);
            } catch (MalformedURLException e) {
                e.printStackTrace();
            }

            driver.manage().timeouts().implicitlyWait(80, TimeUnit.SECONDS);
        }


Please help!

Thanks,
Arpitha
",Arpitha Keshav,https://stackoverflow.com/users/4017740,"Try this code

DesiredCapabilities capabilities = new DesiredCapabilities();
capabilities.setCapability(MobileCapabilityType.PLATFORM_NAME, ""Android"");
capabilities.setCapability(MobileCapabilityType.PLATFORM_VERSION, ""4.4"");
capabilities.setCapability(MobileCapabilityType.DEVICE_NAME, ""Android Emulator"");
capabilities.setCapability(MobileCapabilityType.BROWSER_NAME, ""Chrome"");


Change the Device_Name to ""Android"", this might work.
",Vignesh,https://stackoverflow.com/users/3668078,http://stackoverflow.com/questions/25717961/native-browser-automation-using-appium-1-2-0-1-on-windows-7-android-real-device,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.5555555555555556,0.0,1.0,0.6666666666666666,1.0,0.4444444444444444,0.4444444444444444,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.4444444444444444,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.7,1.0,0.0,0.0,0.8888888888888888,Native browser automation using appium 1.2.0.1 on Windows 7 Android real devices: no connected Android devices found,"I have looked many forums for this issue, there are quite a few answers on this topic but none of these have worked for me/match my criteria.

I recently took up Mobile Automation task and hence am completely new  to Appium. I am working with Appium 1.2.0.1 on Windows 7 and trying to automate the native Android Browser(not Chrome or an App) on an Android v4.3 real device. 
I have installed everything according to the instructions. I am using Selenium in Maven Build in JUnit Framework to execute the scripts through Appium. I use Appuim.exe in Admin mode and use the GUI to start the node. Then I run my scripts. 

My issue is that when I try ""adb devices"" in cmd, I am able to see the device. Whereas, during execution, Appium is throwing an Error ""Failed to start an Appium session, err was: Error: Could not find a connected Android device."" I tried many troubleshooting options and verified if everything is in place. No luck. Please help.

Below is the trace of Error:

&gt; Checking if an update is available
&gt; Update not available
&gt; Starting Node Server
&gt; info: Welcome to Appium v1.2.0 (REV e53f49c706a25242e66d36685c268b599cc18da5)
&gt; debug: Non-default server args: {""address"":""127.0.0.1"",""fullReset"":true,""logNoColors"":true,""platformName"":""Android"",""platformVersion"":""18"",""automationName"":""Appium"",""browserName"":""Browser""}
&gt; info: Appium REST http interface listener started on 127.0.0.1:4723
&gt; info: LogLevel: debug
&gt; info: --&gt; POST /wd/hub/session {""desiredCapabilities"":{""platformVersion"":""4.3"",""browserName"":""Browser"",""platformName"":""Android"",""device"":""Android"",""deviceName"":""Android""}}
&gt; debug: Appium request initiated at /wd/hub/session
&gt; info: Retrieving device
&gt; warn:  code=ENOENT, errno=ENOENT, syscall=spawn
&gt; debug: Request received with params: {""desiredCapabilities"":{""platformVersion"":""4.3"",""browserName"":""Browser"",""platformName"":""Android"",""device"":""Android"",""deviceName"":""Android""}}
&gt; debug: The following desired capabilities were provided, but not recognized by appium. They will be passed on to any other services running on this server. : device
&gt; debug: Looks like we want chrome on android
&gt; debug: Creating new appium session fa19e382-c178-4e6b-8150-a386a51bee39
&gt; debug: Preparing device for session
&gt; debug: Not checking whether app is present since we are assuming it's already on the device
&gt; debug: Checking whether adb is present
&gt; debug: Using adb from C:\Android\android-sdk\platform-tools\adb.exe
&gt; debug: Trying to find a connected android device
&gt; debug: Getting connected devices...
&gt; debug: executing: ""C:\Android\android-sdk\platform-tools\adb.exe"" devices
&gt; debug: Could not find devices, restarting adb server...
&gt; debug: executing: ""C:\Android\android-sdk\platform-tools\adb.exe"" kill-server
&gt; warn:  code=ENOENT, errno=ENOENT, syscall=spawn
&gt; warn:  code=ENOENT, errno=ENOENT, syscall=spawn
&gt; debug: Getting connected devices...
&gt; debug: executing: ""C:\Android\android-sdk\platform-tools\adb.exe"" devices
&gt; debug: Could not find devices, restarting adb server...
&gt; debug: executing: ""C:\Android\android-sdk\platform-tools\adb.exe"" kill-server
&gt; error: Error killing ADB server, going to see if it's online anyway
&gt; debug: Getting connected devices...
&gt; debug: executing: ""C:\Android\android-sdk\platform-tools\adb.exe"" devices
&gt; debug: Could not find devices, restarting adb server...
&gt; warn:  code=ENOENT, errno=ENOENT, syscall=spawn
&gt; warn:  code=ENOENT, errno=ENOENT, syscall=spawn
&gt; debug: executing: ""C:\Android\android-sdk\platform-tools\adb.exe"" kill-server
&gt; warn:  code=ENOENT, errno=ENOENT, syscall=spawn
&gt; error: Error killing ADB server, going to see if it's online anyway
&gt; warn:  code=ENOENT, errno=ENOENT, syscall=spawn
&gt; info: &lt;-- POST /wd/hub/session 500 20314.056 ms - 206 
&gt; debug: Getting connected devices...
&gt; debug: executing: ""C:\Android\android-sdk\platform-tools\adb.exe"" devices
&gt; debug: Cleaning up appium session
&gt; error: Failed to start an Appium session, err was: Error: Could not find a connected Android device.
&gt; debug: Error: Could not find a connected Android device.
&gt;     at ADB.getDevicesWithRetry (C:\Selenium\AppiumForWindows-1.2.0.1\Appium\node_modules\appium\node_modules\appium-adb\lib\adb.js:600:15)
&gt;     at androidCommon.prepareActiveDevice (C:\Selenium\AppiumForWindows-1.2.0.1\Appium\node_modules\appium\lib\devices\android\android-common.js:349:12)
&gt;     at null.&lt;anonymous&gt; (C:\Selenium\AppiumForWindows-1.2.0.1\Appium\node_modules\appium\lib\devices\android\android-common.js:289:26)
&gt;     at C:\Selenium\AppiumForWindows-1.2.0.1\Appium\node_modules\appium\node_modules\async\lib\async.js:610:21
&gt;     at C:\Selenium\AppiumForWindows-1.2.0.1\Appium\node_modules\appium\node_modules\async\lib\async.js:249:17
&gt;     at iterate (C:\Selenium\AppiumForWindows-1.2.0.1\Appium\node_modules\appium\node_modules\async\lib\async.js:149:13)
&gt;     at C:\Selenium\AppiumForWindows-1.2.0.1\Appium\node_modules\appium\node_modules\async\lib\async.js:160:25
&gt;     at C:\Selenium\AppiumForWindows-1.2.0.1\Appium\node_modules\appium\node_modules\async\lib\async.js:251:21
&gt;     at C:\Selenium\AppiumForWindows-1.2.0.1\Appium\node_modules\appium\node_modules\async\lib\async.js:615:34
&gt;     at androidCommon.prepareEmulator (C:\Selenium\AppiumForWindows-1.2.0.1\Appium\node_modules\appium\lib\devices\android\android-common.js:339:5)
&gt; debug: Responding to client with error: {""status"":33,""value"":{""message"":""A new session could not be created. (Original error: Could not find a connected Android device.)"",""origValue"":""Could not find a connected Android device.""},""sessionId"":null}


And here is my code:

if (runEnv.equals(""Android"")) 
        {
            DesiredCapabilities capabilities = new DesiredCapabilities();
              capabilities.setCapability(""device"",""Android"");
              capabilities.setCapability(""deviceName"",""Android"");
              capabilities.setCapability(""platformName"",""Android"");
              capabilities.setCapability(""browserName"", ""Browser"");
              capabilities.setCapability(""platformVersion"", ""4.3"");

              try {
                driver = new RemoteWebDriver(new URL(""http://127.0.0.1:4723/wd/hub""), capabilities);
            } catch (MalformedURLException e) {
                e.printStackTrace();
            }

            driver.manage().timeouts().implicitlyWait(80, TimeUnit.SECONDS);
        }


Please help!

Thanks,
Arpitha
","Try this code

DesiredCapabilities capabilities = new DesiredCapabilities();
capabilities.setCapability(MobileCapabilityType.PLATFORM_NAME, ""Android"");
capabilities.setCapability(MobileCapabilityType.PLATFORM_VERSION, ""4.4"");
capabilities.setCapability(MobileCapabilityType.DEVICE_NAME, ""Android Emulator"");
capabilities.setCapability(MobileCapabilityType.BROWSER_NAME, ""Chrome"");


Change the Device_Name to ""Android"", this might work.
"
5031,5031,8008,Using video ports 'backwards',"If I want to connect my laptop, which has a VGA output, to a monitor, I plug a VGA cable into both ends. The output being my laptop, and the input the monitor

VGA output sockets are the same as VGA input sockets however, so what if I want to use my laptop as the monitor, with the video being outputted from somewhere else?

As I said, VGA's output is the same as input, so in theory, I have the hardware in my laptop to do this. But presumably I need some software.

So can I use the VGA port on a laptop as a video input?

(And also, can this be done with HDMI?)
",ACarter,https://superuser.com/users/167983,"It depends on your laptops hardware, but in at least 99% of all cases: No. You can not.

Just because a plug fits does not mean it has the functionality.

[Edit]: the only way I can ever imagine this working is is your ""VGA connector"" is of the displayport type. And that assumed you used VGA connector as a term for ""plug/cable to the monitor"" and not as ""DB 15 cable, once used for VGA and now commonly but incorrectly referred to as a VGA connector"".
",Hennes,https://superuser.com/users/121352,http://superuser.com/questions/510358,TECHNOLOGY,superuser.com,0.7777777777777778,0.3333333333333333,0.0,1.0,0.6666666666666666,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,1.0,Use video port backward,"If I want to connect my laptop, which has a VGA output, to a monitor, I plug a VGA cable into both ends. The output being my laptop, and the input the monitor

VGA output sockets are the same as VGA input sockets however, so what if I want to use my laptop as the monitor, with the video being outputted from somewhere else?

As I said, VGA's output is the same as input, so in theory, I have the hardware in my laptop to do this. But presumably I need some software.

So can I use the VGA port on a laptop as a video input?

(And also, can this be done with HDMI?)
","It depends on your laptops hardware, but in at least 99% of all cases: No. You can not.

Just because a plug fits does not mean it has the functionality.

[Edit]: the only way I can ever imagine this working is is your ""VGA connector"" is of the displayport type. And that assumed you used VGA connector as a term for ""plug/cable to the monitor"" and not as ""DB 15 cable, once used for VGA and now commonly but incorrectly referred to as a VGA connector"".
"
1393,1393,2197,Expectation of drawing the second color from an urn,"My urn contains 3 red, 2 green and 1 white ball. I pick a ball with replacement until I pick the second color. 

What is the average number of picks for picking the second color?

With the expected value formula I got the following.

$EX=\sum\limits_{k=2}^\infty k[\frac{1}{2}r^{k-1}+\frac{2}{3}g^{k-1}+\frac{5}{6}w^{k-1}]$

Where r, g and w are the probabilites of drawing a red, green, or white ball.

I don't know how to calculate this sum, and I am not sure this is the right way to solve this excercise.
",user010010001,https://math.stackexchange.com/users/137425,"We discuss the probability based on the color of ball you first picked up. Then you continue to pick up the same color for totally $k-1$ time until you pick up another color at $k$th.

$E(X)=\sum\limits_{k=2}^\infty k[(\frac{1}{2})^{k-1}\frac{1}{2}+(\frac{2}{6})^{k-1}\frac{4}{6}+(\frac{1}{6})^{k-1}\frac{5}{6}]$

To calculate the sum, the easiest way is to make use of the fact:  for $|r|&lt;1$, $\sum\limits_{k=0}^\infty r^k=\frac{1}{1-r}$. Differentiate both sides, $\sum\limits_{k=1}^\infty kr^{k-1}=\frac{1}{(1-r)^2}$. Then $\sum\limits_{k=2}^\infty kr^{k-1}=\frac{1}{(1-r)^2}-1$
",John,https://math.stackexchange.com/users/105625,http://math.stackexchange.com/questions/970034/expectation-of-drawing-the-second-color-from-an-urn,SCIENCE,math.stackexchange.com,1.0,0.3333333333333333,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,1.0,0.0,0.5555555555555556,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8666666666666666,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.8888888888888888,Expectation of painting the second color from the urn,"My urn contains 3 red, 2 green and 1 white ball. I pick a ball with replacement until I pick the second color. 

What is the average number of picks for picking the second color?

With the expected value formula I got the following.

$EX=\sum\limits_{k=2}^\infty k[\frac{1}{2}r^{k-1}+\frac{2}{3}g^{k-1}+\frac{5}{6}w^{k-1}]$

Where r, g and w are the probabilites of drawing a red, green, or white ball.

I don't know how to calculate this sum, and I am not sure this is the right way to solve this excercise.
","We discuss the probability based on the color of ball you first picked up. Then you continue to pick up the same color for totally $k-1$ time until you pick up another color at $k$th.

$E(X)=\sum\limits_{k=2}^\infty k[(\frac{1}{2})^{k-1}\frac{1}{2}+(\frac{2}{6})^{k-1}\frac{4}{6}+(\frac{1}{6})^{k-1}\frac{5}{6}]$

To calculate the sum, the easiest way is to make use of the fact:  for $|r|&lt;1$, $\sum\limits_{k=0}^\infty r^k=\frac{1}{1-r}$. Differentiate both sides, $\sum\limits_{k=1}^\infty kr^{k-1}=\frac{1}{(1-r)^2}$. Then $\sum\limits_{k=2}^\infty kr^{k-1}=\frac{1}{(1-r)^2}-1$
"
605,605,947,"What's the difference in meaning between ""emigrate"" and ""immigrate""?","What's the difference between emigrate and immigrate? They seem to have the same definitions in the dictionary but they are antonyms...

&nbsp;
",JFW,https://english.stackexchange.com/users/482,"Emigration &amp; immigration are almost  equal to product movement internationally:

Export: leaving this country and go to another country — emigration 

Import: Leaving another country &amp; arriving in to this country — immigration
",Madhusudhana,https://english.stackexchange.com/users/64230,http://english.stackexchange.com/questions/16781/whats-the-difference-in-meaning-between-emigrate-and-immigrate,CULTURE,english.stackexchange.com,1.0,0.8888888888888888,0.0,0.3333333333333333,1.0,1.0,0.4444444444444444,0.4444444444444444,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.8888888888888888,0.8888888888888888,0.6666666666666666,0.8888888888888888,1.0,0.9333333333333332,0.0,0.0,0.0,1.0,"What's the difference between ""immigrants"" and ""immigrants""?","What's the difference between immigrants and immigrants? The dictionary seems to have the same definition, but they are antonyms...","Emigration &amp; immigration are almost  equal to product movement internationally:

Export: leaving this country and go to another country — emigration 

Import: Leaving another country &amp; arriving in to this country — immigration
"
510,510,796,How does owning a home and paying on a mortgage fit into family savings and investment?,"I'm in my mid-20's, and so I am aiming at long-term growth with higher risk in my portfolio.  My financial adviser is showing me some investment allocations that put my money in some growth, mid, and value-retention locations.  He doesn't seem to be taking into the equation the fact that I am putting a huge percentage of my paycheck into my home.

I know home values fluctuate, but long term, it seems to be a pretty good way to at least retain value, and at best make a small return.  If I am already contributing so much to my ""home"" investment, why would I also invest in stocks or bonds with a low rate of return, even though they are considered a ""safe"" part of my portfolio?

Update: I think the question really has two parts.

1) How does owning a home fit into my financial portfolio?  Most seem to agree that at best it is a hedge against rent or dollar inflation, and at worst it should be viewed as a liability, and has no place alongside other real investments.

2) How should one view payments on a home mortgage?  How are they similar or different to investing in low-risk low-reward investments?
",Cory Klein,https://money.stackexchange.com/users/6310,"Unless you plan to sell your home and live in a box during your retirement I wouldn't consider it an investment that is a viable replacement for a retirement account.

Consider this: Even if housing prices DO go way up, you still need a place to live. When you sell that house and try to buy another one to live in, you will find that the other houses went up in price too, negating your gain.

The only way this might work is if you buy a much bigger house than you will need later and trade down to pull out some equity, or consider a reverse-mortgage for retirement income.
",JohnFx,https://money.stackexchange.com/users/149,http://money.stackexchange.com/questions/16077/how-does-owning-a-home-and-paying-on-a-mortgage-fit-into-family-savings-and-inve,LIFE_ARTS,money.stackexchange.com,0.8888888888888888,0.4444444444444444,0.0,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.6666666666666666,1.0,0.0,0.3333333333333333,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.7333333333333333,0.6666666666666666,0.0,0.3333333333333333,0.6666666666666666,How does owning a house and paying for a mortgage fit with household savings and investment?,"I'm in my mid-20's, and so I am aiming at long-term growth with higher risk in my portfolio.  My financial adviser is showing me some investment allocations that put my money in some growth, mid, and value-retention locations.  He doesn't seem to be taking into the equation the fact that I am putting a huge percentage of my paycheck into my home.

I know home values fluctuate, but long term, it seems to be a pretty good way to at least retain value, and at best make a small return.  If I am already contributing so much to my ""home"" investment, why would I also invest in stocks or bonds with a low rate of return, even though they are considered a ""safe"" part of my portfolio?

Update: I think the question really has two parts.

1) How does owning a home fit into my financial portfolio?  Most seem to agree that at best it is a hedge against rent or dollar inflation, and at worst it should be viewed as a liability, and has no place alongside other real investments.

2) How should one view payments on a home mortgage?  How are they similar or different to investing in low-risk low-reward investments?
","Unless you plan to sell your home and live in a box during your retirement I wouldn't consider it an investment that is a viable replacement for a retirement account.

Consider this: Even if housing prices DO go way up, you still need a place to live. When you sell that house and try to buy another one to live in, you will find that the other houses went up in price too, negating your gain.

The only way this might work is if you buy a much bigger house than you will need later and trade down to pull out some equity, or consider a reverse-mortgage for retirement income.
"
35,35,54,Is there a general term for a single note or a chord?,"Take a passage like this:



Fill in the blank: Each of these boxes denote a ______

Is there a single general term for these that's better than note or chord? Or maybe there's a term for ""anything that has a duration"" that also encompasses rests? It seems like enough of a fundamental concept that it should have a name.
",Trillian,https://music.stackexchange.com/users/16,"For formal, technical purposes (e.g. when discussing musical audiation and other aspects of musical cognition) the terms ""acoustic event"" or ""notated event"" or ""vertical event"" is pretty much standard terminology within psychology of music for referring broadly to any individual single tone or simultaneosly experienced combination of tones (i.e. an individual chord) within a passage or composition. An acoustic event can also include a silence. Really useful all-inclusive terms, (though not yet in  musicians' common parlance)!

So, I'd  use the term ""notated event""  (or the more generalized ""vertical event"") to fill in the blank in the OP's question.
",RichT,https://music.stackexchange.com/users/13338,http://music.stackexchange.com/questions/17282/is-there-a-general-term-for-a-single-note-or-a-chord,LIFE_ARTS,music.stackexchange.com,0.8888888888888888,0.8888888888888888,0.0,1.0,0.6666666666666666,0.3333333333333333,0.7777777777777778,0.7777777777777778,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,1.0,1.0,0.7777777777777778,0.8888888888888888,1.0,0.9333333333333332,0.0,0.0,0.6666666666666666,1.0,Is there a general term for a single note or chord?,"Take a passage like this:



Fill in the blank: Each of these boxes denote a ______

Is there a single general term for these that's better than note or chord? Or maybe there's a term for ""anything that has a duration"" that also encompasses rests? It seems like enough of a fundamental concept that it should have a name.
","For formal occasions, the term ""acoustic event"" or ""marker event"" or ""vertical event"" is a basic standard term in music psychology for technical purposes (for example, when discussing other aspects of music hearing and music cognition), which generally refers to any single tone or combination of tones experienced at the same time (i.e., a single (chord) in a paragraph or music. Acoustic events can also include silence. Really useful all encompassing terms (though not yet in the musician's common parlance)!"
1951,1951,3110,Shared memory: shmget fails: No space left on device -- how to increase limits?,"I call shmget many times in my program, to get shm of of average size 85840 bytes. I obtain about 32771 shm ok, then shmget doesn't return a shm, but the error: ""No space left on device"".

I have increased the kernel limits to:

$ sysctl -A|grep shm
kernel.shmmax = 33554432
kernel.shmall = 1677721600
kernel.shmmni = 409600


But still get the issue. Why?

Do I have to put something into /etc/security/limits.conf too? I only have
""user             -       nofile          1000000""
because the program also opens about as many files as shms.

This is the output of free

$ free
          total       used       free     shared    buffers     cached
Mem:       8150236    7261676     888560          0     488100    3270792
-/+ buffers/cache:    3502784    4647452 
Swap:     12287992     554692   11733300


And ipcs

$ ipcs -lm                                                                         

------ Shared Memory Limits --------
max number of segments = 409600
max seg size (kbytes) = 1638400
max total shared memory (kbytes) = 6710886400
min seg size (bytes) = 1


Since I assume shm is capable of being swapped out, there should be enough space.
",j13r,https://serverfault.com/users/64249,"It turns out shmmni is limited to 32768 in the kernel:

define IPCMNI 32768  /* &lt;= MAX_INT limit for ipc arrays (including sysctl changes) */

in the file  ...version.../include/linux/ipc.h

So short of recompiling the kernel, that is the hard limit on the number of shared memory segments. Sorry.  
",ramruma,https://serverfault.com/users/28126,http://serverfault.com/questions/371068,TECHNOLOGY,serverfault.com,0.8888888888888888,0.4444444444444444,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.3333333333333333,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.3333333333333333,0.0,1.0,1.0,Shared memory: shmget failed: there is no space left on the device -- how to increase the limit?,"I call shmget many times in my program, to get shm of of average size 85840 bytes. I obtain about 32771 shm ok, then shmget doesn't return a shm, but the error: ""No space left on device"".

I have increased the kernel limits to:

$ sysctl -A|grep shm
kernel.shmmax = 33554432
kernel.shmall = 1677721600
kernel.shmmni = 409600


But still get the issue. Why?

Do I have to put something into /etc/security/limits.conf too? I only have
""user             -       nofile          1000000""
because the program also opens about as many files as shms.

This is the output of free

$ free
          total       used       free     shared    buffers     cached
Mem:       8150236    7261676     888560          0     488100    3270792
-/+ buffers/cache:    3502784    4647452 
Swap:     12287992     554692   11733300


And ipcs

$ ipcs -lm                                                                         

------ Shared Memory Limits --------
max number of segments = 409600
max seg size (kbytes) = 1638400
max total shared memory (kbytes) = 6710886400
min seg size (bytes) = 1


Since I assume shm is capable of being swapped out, there should be enough space.
","It turns out shmmni is limited to 32768 in the kernel:

define IPCMNI 32768  /* &lt;= MAX_INT limit for ipc arrays (including sysctl changes) */

in the file  ...version.../include/linux/ipc.h

So short of recompiling the kernel, that is the hard limit on the number of shared memory segments. Sorry.  
"
5512,5512,8745,How to divide the controller?,"My View-Controller

public class MainForm implements java.util.Observer{
@Override
    public void update(Observable o, Object arg) {
        System.err.println(""update View ...."");
        this.textField_15.setText(String.valueOf(model.getThermalConductivity()));
            /*
*****
*/


    }
}


In the model I use methods

setChanged();
notifyObservers();


All events model updates are processed in the method ""update""

How to divide the controller? 
",BILL,https://stackoverflow.com/users/494657,"You might enjoy trying this example. For simplicity, the model extends Observable, but several other approaches are mentioned with links to examples. 
",trashgod,https://stackoverflow.com/users/230513,http://stackoverflow.com/questions/6179185/how-to-divide-the-controller,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.4444444444444444,0.0,0.6666666666666666,0.6666666666666666,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.6666666666666666,0.8888888888888888,0.5555555555555556,0.8888888888888888,0.8888888888888888,0.6666666666666667,1.0,0.0,0.0,0.8888888888888888,How to divide the controller?,"My View-Controller

public class MainForm implements java.util.Observer{
@Override
    public void update(Observable o, Object arg) {
        System.err.println(""update View ...."");
        this.textField_15.setText(String.valueOf(model.getThermalConductivity()));
            /*
*****
*/


    }
}


In the model I use methods

setChanged();
notifyObservers();


All events model updates are processed in the method ""update""

How to divide the controller? 
","You may like to try this example. For simplicity, the model extends observability, but several other methods are mentioned, along with links to examples."
5179,5179,8229,Why are these files in an ext4 volume fragmented?,"I have a 900GB ext4 partition on a (magnetic) hard drive that has no defects and no bad sectors. The partition is completely empty except for an empty lost+found directory. The partition was formatted using default parameters except that I set the number of reserved filesystem blocks to 1%.

I downloaded the ~900MB file xubuntu-15.04-desktop-amd64.iso to the partition's mount point directory using wget. When the download was finished, I found that the file was split into four fragments:

filefrag -v /media/emma/red/xubuntu-15.04-desktop-amd64.iso
Filesystem type is: ef53
File size of /media/emma/red/xubuntu-15.04-desktop-amd64.iso is 1009778688 (246528 blocks of 4096 bytes)
 ext:     logical_offset:        physical_offset: length:   expected: flags:
   0:        0..   32767:      34816..     67583:  32768:            
   1:    32768..   63487:      67584..     98303:  30720:            
   2:    63488..   96255:     100352..    133119:  32768:      98304:
   3:    96256..  126975:     133120..    163839:  30720:            
   4:   126976..  159743:     165888..    198655:  32768:     163840:
   5:   159744..  190463:     198656..    229375:  30720:            
   6:   190464..  223231:     231424..    264191:  32768:     229376:
   7:   223232..  246527:     264192..    287487:  23296:             eof
/media/emma/red/xubuntu-15.04-desktop-amd64.iso: 4 extents found


Thinking this might be releated to wget somehow, I removed the ISO file from the partition, making it empty again, then I copied the ~700MB file v1.mp4 to the partition using cp. This file was fragmented too. It was split into three fragments:

filefrag -v /media/emma/red/v1.mp4
Filesystem type is: ef53
File size of /media/emma/red/v1.mp4 is 737904458 (180153 blocks of 4096 bytes)
 ext:     logical_offset:        physical_offset: length:   expected: flags:
   0:        0..   32767:      34816..     67583:  32768:            
   1:    32768..   63487:      67584..     98303:  30720:            
   2:    63488..   96255:     100352..    133119:  32768:      98304:
   3:    96256..  126975:     133120..    163839:  30720:            
   4:   126976..  159743:     165888..    198655:  32768:     163840:
   5:   159744..  180152:     198656..    219064:  20409:             eof
/media/emma/red/v1.mp4: 3 extents found


Why is this happening? And is there a way to prevent it from happening? I thought ext4 was meant to be resistant to fragmentation. Instead I find that it immediately fragments a solitary file when all the rest of the volume is unused. This seems to be worse than both FAT32 and NTFS.
",EmmaV,https://unix.stackexchange.com/users/85900,"3 or 4 fragments in a 900mb file is very good.  Fragmentation becomes a problem when a file of that size has more like 100+ fragments.  It isn't uncommon for fat or ntfs to fragment such a file into several hundred pieces.

You generally won't see better than that at least on older ext4 filesystems because the maximum size of a block group is 128 MB, and so every 128 MB the contiguous space is broken by a few blocks for the allocation bitmaps and inode tables for the next block group.  A more recent ext4 feature called flex_bg allows packing a number of ( typically 16 ) block groups' worth of these tables together, leaving longer runs of allocatable blocks but depending on your distribution and what version of e2fsprogs was used to format it, this option may not have been used.

You can use tune2fs -l to check the features enabled when your filesystem was formatted.
",psusi,https://unix.stackexchange.com/users/7285,http://unix.stackexchange.com/questions/203980/why-are-these-files-in-an-ext4-volume-fragmented,TECHNOLOGY,unix.stackexchange.com,0.7777777777777778,0.5555555555555556,0.0,1.0,1.0,1.0,0.4444444444444444,0.5555555555555556,1.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.6666666666666666,1.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,1.0,1.0,Why are these files in ext4 volumes fragmented?,"I have a 900GB ext4 partition on a (magnetic) hard drive that has no defects and no bad sectors. The partition is completely empty except for an empty lost+found directory. The partition was formatted using default parameters except that I set the number of reserved filesystem blocks to 1%.

I downloaded the ~900MB file xubuntu-15.04-desktop-amd64.iso to the partition's mount point directory using wget. When the download was finished, I found that the file was split into four fragments:

filefrag -v /media/emma/red/xubuntu-15.04-desktop-amd64.iso
Filesystem type is: ef53
File size of /media/emma/red/xubuntu-15.04-desktop-amd64.iso is 1009778688 (246528 blocks of 4096 bytes)
 ext:     logical_offset:        physical_offset: length:   expected: flags:
   0:        0..   32767:      34816..     67583:  32768:            
   1:    32768..   63487:      67584..     98303:  30720:            
   2:    63488..   96255:     100352..    133119:  32768:      98304:
   3:    96256..  126975:     133120..    163839:  30720:            
   4:   126976..  159743:     165888..    198655:  32768:     163840:
   5:   159744..  190463:     198656..    229375:  30720:            
   6:   190464..  223231:     231424..    264191:  32768:     229376:
   7:   223232..  246527:     264192..    287487:  23296:             eof
/media/emma/red/xubuntu-15.04-desktop-amd64.iso: 4 extents found


Thinking this might be releated to wget somehow, I removed the ISO file from the partition, making it empty again, then I copied the ~700MB file v1.mp4 to the partition using cp. This file was fragmented too. It was split into three fragments:

filefrag -v /media/emma/red/v1.mp4
Filesystem type is: ef53
File size of /media/emma/red/v1.mp4 is 737904458 (180153 blocks of 4096 bytes)
 ext:     logical_offset:        physical_offset: length:   expected: flags:
   0:        0..   32767:      34816..     67583:  32768:            
   1:    32768..   63487:      67584..     98303:  30720:            
   2:    63488..   96255:     100352..    133119:  32768:      98304:
   3:    96256..  126975:     133120..    163839:  30720:            
   4:   126976..  159743:     165888..    198655:  32768:     163840:
   5:   159744..  180152:     198656..    219064:  20409:             eof
/media/emma/red/v1.mp4: 3 extents found


Why is this happening? And is there a way to prevent it from happening? I thought ext4 was meant to be resistant to fragmentation. Instead I find that it immediately fragments a solitary file when all the rest of the volume is unused. This seems to be worse than both FAT32 and NTFS.
","3 or 4 fragments in a 900mb file is very good.  Fragmentation becomes a problem when a file of that size has more like 100+ fragments.  It isn't uncommon for fat or ntfs to fragment such a file into several hundred pieces.

You generally won't see better than that at least on older ext4 filesystems because the maximum size of a block group is 128 MB, and so every 128 MB the contiguous space is broken by a few blocks for the allocation bitmaps and inode tables for the next block group.  A more recent ext4 feature called flex_bg allows packing a number of ( typically 16 ) block groups' worth of these tables together, leaving longer runs of allocatable blocks but depending on your distribution and what version of e2fsprogs was used to format it, this option may not have been used.

You can use tune2fs -l to check the features enabled when your filesystem was formatted.
"
5239,5239,8328,What is the best introductory Bayesian statistics textbook?,"Which is the best introductory textbook for Bayesian statistics?

One book per answer, please.
",Shane,https://stats.stackexchange.com/users/5,"I read:

Gelman et al (2013). Bayesian Data Analysis. CRC Press LLC. 3rd ed.

Hoff, Peter D (2009). A First Course in Bayesian Statistical Methods. Springer Texts in Statistics.

Kruschke, Doing Bayesian Data Analysis: A Tutorial with R and Bugs, 2011. Academic Press / Elsevier.

and I think that the better one to start with is Kruschke's book. It's perfect for a first approach to Bayesian thinking: concepts are explained very clearly, there is not too much mathematics, and there are lots of nice examples!

Gelman et al. is a great book, but it is more advanced and I suggest to read it after the Kruschke's one.

Conversely, I did not like Hoff's book because it is an introductory book, but concepts (and Bayesian thinking) are not explained in a clear way. I suggest to pass over. 
",stochazesthai,https://stats.stackexchange.com/users/44171,http://stats.stackexchange.com/questions/125/what-is-the-best-introductory-bayesian-statistics-textbook,SCIENCE,stats.stackexchange.com,1.0,1.0,0.6666666666666666,1.0,0.0,0.0,0.5555555555555556,0.4444444444444444,0.0,0.0,1.0,0.0,0.6666666666666666,0.0,0.0,1.0,0.0,0.0,0.0,0.0,1.0,0.7777777777777778,0.7777777777777778,0.8888888888888888,1.0,0.8666666666666666,0.0,0.0,0.0,1.0,What is the best introduction to Bayesian statistics?,Which is the best introduction to Bayesian statistics?,"I read:

Gelman et al (2013). Bayesian Data Analysis. CRC Press LLC. 3rd ed.

Hoff, Peter D (2009). A First Course in Bayesian Statistical Methods. Springer Texts in Statistics.

Kruschke, Doing Bayesian Data Analysis: A Tutorial with R and Bugs, 2011. Academic Press / Elsevier.

and I think that the better one to start with is Kruschke's book. It's perfect for a first approach to Bayesian thinking: concepts are explained very clearly, there is not too much mathematics, and there are lots of nice examples!

Gelman et al. is a great book, but it is more advanced and I suggest to read it after the Kruschke's one.

Conversely, I did not like Hoff's book because it is an introductory book, but concepts (and Bayesian thinking) are not explained in a clear way. I suggest to pass over. 
"
3311,3311,5281,1/4 to 1/8 jack problem,"I was planning to record months ago, with my electric guitar, and yesterday I got myself a guitar rig software and bought some 1/4 to 1/8 adapter jack so that I can plug in unto my laptop's mic hole.

Whenever I plug my guitar cable to the 1/4 to 1/8 adapter then to the laptop I can't hear any sound (past the clicking sound you hear) but when I plug the cable almost halfway of the adapter's body (before the clicking sound) I can hear sound when I play and there's some loud buzzing sound involved.

Any explanations as to why this is happening? 
",user3736846,https://music.stackexchange.com/users/13524,"If you want to record better sounding guitar tracks, getting an audio interface is the way to go, as others have mentioned.  You also want to think about shielding, interference, and turning off electrically noisy overhead lights. 

However, to say ""You can't just use an adapter to plug your guitar directly into your laptop"" isn't true.  I do this without a problem on my computers, its just not going to give you ideal signal levels. The  problem you might be seeing is that there is a mono-stereo mismatch between your mono guitar cable, your 1/4 to 1/8 inch adapter, and your input on the laptop.  I have both mono and stereo 1/4 to 1/8 adapters and laptops with both mono and stereo input jacks. Depending on my configuration, the input signal is reduced by half because of the way I've hooked it up, i.e. the incorrect conversion of a mono signal results in half of it being lost. 

At least, this is the issue that comes to mind when I read your  sentence, ""when I plug the cable almost halfway of the adapter's body ... I can hear sound when I play and there's some loud buzzing sound involved.""  There are likely multiple issues at play here.
",foundling,https://music.stackexchange.com/users/15388,http://music.stackexchange.com/questions/25070/1-4-to-1-8-jack-problem,LIFE_ARTS,music.stackexchange.com,1.0,0.4444444444444444,0.0,1.0,1.0,1.0,0.6666666666666666,0.7777777777777778,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.6666666666666666,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,1.0,1.0,0.9,0.3333333333333333,0.0,0.6666666666666666,0.8888888888888888,1 / 4 to 1 / 8 Jack problem,"I was planning to record months ago, with my electric guitar, and yesterday I got myself a guitar rig software and bought some 1/4 to 1/8 adapter jack so that I can plug in unto my laptop's mic hole.

Whenever I plug my guitar cable to the 1/4 to 1/8 adapter then to the laptop I can't hear any sound (past the clicking sound you hear) but when I plug the cable almost halfway of the adapter's body (before the clicking sound) I can hear sound when I play and there's some loud buzzing sound involved.

Any explanations as to why this is happening? 
","If you want to record better sounding guitar tracks, getting an audio interface is the way to go, as others have mentioned.  You also want to think about shielding, interference, and turning off electrically noisy overhead lights. 

However, to say ""You can't just use an adapter to plug your guitar directly into your laptop"" isn't true.  I do this without a problem on my computers, its just not going to give you ideal signal levels. The  problem you might be seeing is that there is a mono-stereo mismatch between your mono guitar cable, your 1/4 to 1/8 inch adapter, and your input on the laptop.  I have both mono and stereo 1/4 to 1/8 adapters and laptops with both mono and stereo input jacks. Depending on my configuration, the input signal is reduced by half because of the way I've hooked it up, i.e. the incorrect conversion of a mono signal results in half of it being lost. 

At least, this is the issue that comes to mind when I read your  sentence, ""when I plug the cable almost halfway of the adapter's body ... I can hear sound when I play and there's some loud buzzing sound involved.""  There are likely multiple issues at play here.
"
247,247,398,Freeform timing out on return page,"I have EE v2.5.3 and Freeform Pro 4.0.10 among other things. 

When submitting forms with admin notify turned on I get a server timeout error. The form data still submits to the db and I still get a notification email but the server hangs and eventually times out instead of loading the return page. 

If I turn on admin notify it works properly, but obviously no notification, which I very much need.
",Allan Kukral,https://expressionengine.stackexchange.com/users/357,"This sounds like it's an issue on your server since it was working and now is not.

I'd first test to see if you are having timeouts when sending from the Communicate page in EE. If you can't send from the Communicate page, enable Email Debugging to see what's going on.

Also check your PHP error logs to see what you see. An error related to the timeout may exist there.

If necessary, contact your host to see if they have changed anything on the server related to PHPMail/SMTP (I'm not clear from your comment which one you are using exactly)... Send them the info you find in the debugging and logs.
",Anna_MediaGirl,https://expressionengine.stackexchange.com/users/28,http://expressionengine.stackexchange.com/questions/5291/freeform-timing-out-on-return-page,TECHNOLOGY,expressionengine.stackexchange.com,1.0,0.3333333333333333,0.0,0.0,1.0,0.0,0.6666666666666666,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,1.0,1.0,Freeform timeout on return page,"I have EE v2.5.3 and Freeform Pro 4.0.10 among other things. 

When submitting forms with admin notify turned on I get a server timeout error. The form data still submits to the db and I still get a notification email but the server hangs and eventually times out instead of loading the return page. 

If I turn on admin notify it works properly, but obviously no notification, which I very much need.
","This sounds like it's an issue on your server since it was working and now is not.

I'd first test to see if you are having timeouts when sending from the Communicate page in EE. If you can't send from the Communicate page, enable Email Debugging to see what's going on.

Also check your PHP error logs to see what you see. An error related to the timeout may exist there.

If necessary, contact your host to see if they have changed anything on the server related to PHPMail/SMTP (I'm not clear from your comment which one you are using exactly)... Send them the info you find in the debugging and logs.
"
5876,5876,9310,How can you (anybody) find out the IP address of a single computer inside college,"How can you find out the IP address of a single computer inside a college network.

Every computer has the same public IP address on the network. How is it possible, after discovering that the IP is from that college, to find the computer from which the attack/request/etc originated?
",João Gonçalves,https://security.stackexchange.com/users/12730,"I suppose that our situation is the following: you have detected some undesirable network traffic and you are looking for the perpetrator, so as to, more or less metaphorically, convey to him the inherent unwisdom of his villainous behaviour. The source address of the offending IP packets points to a college; the college uses Network Address Translation so that outgoing traffic from all their students is seen, from the outside, as coming from a single IP address.

(Or, possibly, you are the wannabe evildoer and you want to know what the Long Arm of the Law could do to trace you back. It does not change the technical situation.)

Strictly speaking, the college acts as a kind of anonymizer, since it blocks the actual (internal) IP information. So you should ask the college. They may have detailed logs on network activity, which may help pinpoint the uncivilized individual; for instance, the DHCP logs within the college network could give some information on who had their computer up and running at the time of the indelicacy. There are various sources of such information, which depend a lot on the structure of the internal college network.

Be sure to bring all the information you have on your side; network traces obtained with a network monitor application (like Wireshark or the aptly named Network Monitor) are a must. Also, bring all logs, especially Web server logs, because Web browsers tend to produce a lot of information which can be quite specific to the specific computer which sends the requests (see this page for details).
",Thomas Pornin,https://security.stackexchange.com/users/655,http://security.stackexchange.com/questions/19840/how-can-you-anybody-find-out-the-ip-address-of-a-single-computer-inside-colleg,TECHNOLOGY,security.stackexchange.com,1.0,1.0,0.0,0.0,1.0,1.0,0.5555555555555556,0.5555555555555556,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.3333333333333333,0.6666666666666666,1.0,How can you (anyone) find out the IP address of a computer in the University,"How can you find out the IP address of a single computer inside a college network.

Every computer has the same public IP address on the network. How is it possible, after discovering that the IP is from that college, to find the computer from which the attack/request/etc originated?
","I suppose that our situation is the following: you have detected some undesirable network traffic and you are looking for the perpetrator, so as to, more or less metaphorically, convey to him the inherent unwisdom of his villainous behaviour. The source address of the offending IP packets points to a college; the college uses Network Address Translation so that outgoing traffic from all their students is seen, from the outside, as coming from a single IP address.

(Or, possibly, you are the wannabe evildoer and you want to know what the Long Arm of the Law could do to trace you back. It does not change the technical situation.)

Strictly speaking, the college acts as a kind of anonymizer, since it blocks the actual (internal) IP information. So you should ask the college. They may have detailed logs on network activity, which may help pinpoint the uncivilized individual; for instance, the DHCP logs within the college network could give some information on who had their computer up and running at the time of the indelicacy. There are various sources of such information, which depend a lot on the structure of the internal college network.

Be sure to bring all the information you have on your side; network traces obtained with a network monitor application (like Wireshark or the aptly named Network Monitor) are a must. Also, bring all logs, especially Web server logs, because Web browsers tend to produce a lot of information which can be quite specific to the specific computer which sends the requests (see this page for details).
"
98,98,160,Two Field Problem,"Ella Mental has $600$ ft of fencing to enclose two fields. One is to be a rectangle twice as long as it is wide and the other is to be a square. The square field must contain at least $100$ ft squared. The rectangular one must contain at least $800$ ft squared.

a. If $x$ is the width of the rectangular field, what is the domain of $x$?

b. Plot the graph of the total area contained in the two fields as a function of $x$.

c. What is the greatest area that can be contained in the two fields? Justify your answer

By the way, the answers to a, b, c are...(according to the textbook)

a. domain: $20\le x\le 93.333333\dots$

b. $A(x) = 22500 -450x + 4.25x$ squared

c. greatest area $= 17522.2222$

I keep getting the wrong answer for the greatest area.
Please provide me with explanations to each 
",user37600,https://math.stackexchange.com/users/37600,"Since $x$ is the length (in feet) of the short side of the rectangular field, then the area of the rectangular field is $2x^2$, and its perimeter is $6x$. Thus, the side length of the square field is $(600-6x)/4=150-\frac32x$, so its area is $22500-450x+\frac94x^2$, and the total area is $$A(x)=22500-450x+\frac{17}4x^2,$$ as desired.

We know in particular that we need $2x^2\geq 800$, from which $x\geq 20$ (since $x$ is positive). Also, since the square field needs area at least $100$ square feet, then its side length is at least $10$ feet, meaning $150-\frac32x\geq 10,$ from which $x\leq\frac{280}3$, as desired.

As for the last part, observe that the graph of $A(x)$ is a portion of a parabola that opens up. This will necessarily be maximized at one of its endpoints (if it opened down, it might maximize at its vertex, if in the domain). It is easy to check which of $x=20$ or $x=\frac{280}3$ maximizes $A(x)$, and what that maximum area is.
",Cameron Buie,https://math.stackexchange.com/users/28900,http://math.stackexchange.com/questions/180820/two-field-problem,SCIENCE,math.stackexchange.com,1.0,0.3333333333333333,0.0,0.3333333333333333,1.0,1.0,0.6666666666666666,0.5555555555555556,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.6666666666666666,0.0,0.7777777777777778,1.0,0.5555555555555556,0.8888888888888888,1.0,0.8666666666666666,0.3333333333333333,0.3333333333333333,1.0,0.8888888888888888,Two field problem,"Ella Mental has $600$ ft of fencing to enclose two fields. One is to be a rectangle twice as long as it is wide and the other is to be a square. The square field must contain at least $100$ ft squared. The rectangular one must contain at least $800$ ft squared.

a. If $x$ is the width of the rectangular field, what is the domain of $x$?

b. Plot the graph of the total area contained in the two fields as a function of $x$.

c. What is the greatest area that can be contained in the two fields? Justify your answer

By the way, the answers to a, b, c are...(according to the textbook)

a. domain: $20\le x\le 93.333333\dots$

b. $A(x) = 22500 -450x + 4.25x$ squared

c. greatest area $= 17522.2222$

I keep getting the wrong answer for the greatest area.
Please provide me with explanations to each 
","Since $x$ is the length (in feet) of the short side of the rectangular field, then the area of the rectangular field is $2x^2$, and its perimeter is $6x$. Thus, the side length of the square field is $(600-6x)/4=150-\frac32x$, so its area is $22500-450x+\frac94x^2$, and the total area is $$A(x)=22500-450x+\frac{17}4x^2,$$ as desired.

We know in particular that we need $2x^2\geq 800$, from which $x\geq 20$ (since $x$ is positive). Also, since the square field needs area at least $100$ square feet, then its side length is at least $10$ feet, meaning $150-\frac32x\geq 10,$ from which $x\leq\frac{280}3$, as desired.

As for the last part, observe that the graph of $A(x)$ is a portion of a parabola that opens up. This will necessarily be maximized at one of its endpoints (if it opened down, it might maximize at its vertex, if in the domain). It is easy to check which of $x=20$ or $x=\frac{280}3$ maximizes $A(x)$, and what that maximum area is.
"
340,340,543,rsync partial LVM volume to Remote Directory,"Can I rsync a full hdd partition (which is inaccessible) to a remote directory?

Inaccessible means it cannot be mounted, it was part of LV volume merged with other HDD which is faulty and removed from the server. I tried to mount it but not working unknown filesystem type 'LVM2_member' so I'm using rsync to mount it on remote desktop. Advise me what's the best solution?

rsync -avz /dev/sda1 user@ip:/backup/


I want to copy all files and directories of /dev/sda1 to remote device at the directory backup.
",Zaher,https://unix.stackexchange.com/users/116021,"rsync -avz /dev/sda1 user@ip:/backup/ would attempt to copy the device node, not the disk content.

You can make an image of the partition as a remote file:

ssh -C user@ip:/backup/sda1.img &lt;/dev/sda1


This makes an image of the partition. It won't give you access to your files. In order to access your files, you need to mount the partition or the image: that's what mounting means.

If you only have one disk in a two-disk volume group, you won't be able to get your files from it, because you only have half a filesystem. Half a filesystem doesn't mean you have half the files, any more than having half a car doesn't mean you can travel on half the roads. If you have half a car, you can use it for parts, but you can't drive it. If you have half a filesystem, you may be able to use forensic techniques to recover some of the data, but it's hard work and individual files and directories are likely to be split over the two disks anyway.

If your volume group is split over two disks and one of the disk fails, your whole volume group is effectively lost.
",Gilles,https://unix.stackexchange.com/users/885,http://unix.stackexchange.com/questions/205093/rsync-partial-lvm-volume-to-remote-directory,TECHNOLOGY,unix.stackexchange.com,0.7777777777777778,0.5555555555555556,0.0,0.3333333333333333,1.0,0.6666666666666666,0.6666666666666666,0.4444444444444444,0.6666666666666666,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,0.0,0.7777777777777778,0.7777777777777778,0.8333333333333334,0.7777777777777778,0.8333333333333334,0.8,1.0,0.5,0.5,0.7777777777777778,Rsync part LVM volume to remote directory,"Can I rsync a full hdd partition (which is inaccessible) to a remote directory?

Inaccessible means it cannot be mounted, it was part of LV volume merged with other HDD which is faulty and removed from the server. I tried to mount it but not working unknown filesystem type 'LVM2_member' so I'm using rsync to mount it on remote desktop. Advise me what's the best solution?

rsync -avz /dev/sda1 user@ip:/backup/


I want to copy all files and directories of /dev/sda1 to remote device at the directory backup.
","rsync -avz /dev/sda1 user@ip:/backup/ would attempt to copy the device node, not the disk content.

You can make an image of the partition as a remote file:

ssh -C user@ip:/backup/sda1.img &lt;/dev/sda1


This makes an image of the partition. It won't give you access to your files. In order to access your files, you need to mount the partition or the image: that's what mounting means.

If you only have one disk in a two-disk volume group, you won't be able to get your files from it, because you only have half a filesystem. Half a filesystem doesn't mean you have half the files, any more than having half a car doesn't mean you can travel on half the roads. If you have half a car, you can use it for parts, but you can't drive it. If you have half a filesystem, you may be able to use forensic techniques to recover some of the data, but it's hard work and individual files and directories are likely to be split over the two disks anyway.

If your volume group is split over two disks and one of the disk fails, your whole volume group is effectively lost.
"
1,1,1,What is the distinction between a city and a sprawl/metroplex... between downtown and a commercial district?,"I am trying to understand what kinds of places the spam values on p 231 refer to in the 5th Edition main book for Shadowrun.

Per p 15, a sprawl is a plex, a plex is a ""metropolitan complex, short for metroplex"". Per Google a metroplex is "" a very large metropolitan area, especially one that is an aggregation of two or more cities"".  A city downtown and sprawl downtown would tend to have similar densities, but for some reason the sprawl (which includes suburbs?) has a higher spam zone noise rating (p 231).  Similarly, I'd think of a downtown as being more dense and noisy (e.g. Office buildings and street vendors) than a commercial district, e.g. an outdoor mall.  The noise ratings make me think that I am thinking about this incorrectly. What is a better way of thinking of them?
",russellpierce,https://rpg.stackexchange.com/users/8774,"It might be helpful to look into the definition of spam zone:

(p.216) spam zone: An area flooded with invasive and/or viral AR advertising, causing noise.

Because a metroplex has so many marketing targets, it seems a safe assumption that marketers would drown the plex with spam. Spam from the less dense areas would bleed into the urban cores. A smaller city with less urban/suburban territory surrounding it ostensibly wouldn't have as much spam.
",Erik Schmidt,https://rpg.stackexchange.com/users/1871,http://rpg.stackexchange.com/questions/47820/what-is-the-distinction-between-a-city-and-a-sprawl-metroplex-between-downtow,CULTURE,rpg.stackexchange.com,1.0,1.0,0.0,0.5,1.0,1.0,0.4444444444444444,0.4444444444444444,0.6666666666666666,0.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.0,0.8888888888888888,0.8888888888888888,0.5555555555555556,0.8888888888888888,0.8888888888888888,0.6666666666666667,0.0,0.0,0.6666666666666666,0.8888888888888888,What's the difference between a city and an expanding metropolis... Between downtown and downtown?,"I am trying to understand what kinds of places the spam values on p 231 refer to in the 5th Edition main book for Shadowrun.

Per p 15, a sprawl is a plex, a plex is a ""metropolitan complex, short for metroplex"". Per Google a metroplex is "" a very large metropolitan area, especially one that is an aggregation of two or more cities"".  A city downtown and sprawl downtown would tend to have similar densities, but for some reason the sprawl (which includes suburbs?) has a higher spam zone noise rating (p 231).  Similarly, I'd think of a downtown as being more dense and noisy (e.g. Office buildings and street vendors) than a commercial district, e.g. an outdoor mall.  The noise ratings make me think that I am thinking about this incorrectly. What is a better way of thinking of them?
","It might be helpful to look into the definition of spam zone:

(p.216) spam zone: An area flooded with invasive and/or viral AR advertising, causing noise.

Because a metroplex has so many marketing targets, it seems a safe assumption that marketers would drown the plex with spam. Spam from the less dense areas would bleed into the urban cores. A smaller city with less urban/suburban territory surrounding it ostensibly wouldn't have as much spam.
"
3575,3575,5715,Why does Membership not show up in Mysite?,"We just upgraded to 2010. When I provision a new SharePoint site, it is now not populating in the SharePoint Site Lists on My Site. (Formerly Memberships in 2007).

I have rerun the profile sync and spun around in my chair several times, but no look.

Any Ideas?
",Bryan Smith,https://sharepoint.stackexchange.com/users/4416,"Just migrating doesn't actuall ensure that MySite is working. you have to go for the full run, and besides, configure the Membership provider properly.

Btw: Did you enabled Claims on your Web Application??
",Marius Constantinescu - MVP,https://sharepoint.stackexchange.com/users/5306,http://sharepoint.stackexchange.com/questions/17726/why-does-membership-not-show-up-in-mysite,TECHNOLOGY,sharepoint.stackexchange.com,1.0,0.6666666666666666,0.0,1.0,1.0,1.0,0.5,0.5,0.0,0.0,0.5,0.5,0.0,0.0,0.0,0.0,0.5,0.0,1.0,0.0,0.8333333333333334,0.6666666666666666,0.5,1.0,1.0,0.7,0.0,0.0,1.0,0.6666666666666666,Why doesn't membership appear in MySite?,"We just upgraded to 2010. When I set up a new SharePoint site, it will not now populate the list of SharePoint sites on my site. (member before 2007).","Just migrating doesn't actuall ensure that MySite is working. you have to go for the full run, and besides, configure the Membership provider properly.

Btw: Did you enabled Claims on your Web Application??
"
5024,5024,8000,After what period of time does a PhD position count towards the two possible attempts in Germany?,"I am not sure if this holds true everywhere, but here in Germany you only get two attemps at getting your PhD. I am currently wondering at which point it counts towards those two attempts. If I were to start a position and quit during the first few weeks, would it still count?
",Simon Eismann,https://academia.stackexchange.com/users/33688,"I don't think this is quite true in Germany either - or at least not in the generality that I read into your question.  

Here is example 1 (Promotionsordnung (PhD bylaws) for psychology and sport, Muenster), and another randomly selected example 2 (Promotionsordnung math, Bonn).  Both stipulate much more restrictive conditions that relate to your question. They somewhat overlap, but not completely - so there is also no uniform answer for Germany. Simply stepping away from a PhD early on would not be a problem in either case. The restrictions on the number of attempts to be successfully awarded a PhD are as follows:  

Example 1: you get one and one only attempt to resubmit a declined thesis, and to re-take the oral defense each    

Example 2: no restrictions are mentioned on the number of failed thesis attempts. You get one attempt to re-take a failed defense  

In particular given that even these two sources don't agree, you just need to pull your program's Promotionsordnung, and confirm which rules apply to you. 
",gnometorule,https://academia.stackexchange.com/users/4384,http://academia.stackexchange.com/questions/44283/after-what-period-of-time-does-a-phd-position-count-towards-the-two-possible-att,LIFE_ARTS,academia.stackexchange.com,1.0,0.6666666666666666,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,1.0,1.0,0.7777777777777778,1.0,1.0,0.8666666666666666,0.3333333333333333,0.0,0.6666666666666666,1.0,"In Germany, after what period of time can a doctor's degree be counted as two possible attempts?","I'm not sure if this applies anywhere, but in Germany, you only have two attempts to get a PhD. Now I want to know where these two attempts count. If I start a job and quit in the first few weeks, will that count?","I don't think this is quite true in Germany either - or at least not in the generality that I read into your question.  

Here is example 1 (Promotionsordnung (PhD bylaws) for psychology and sport, Muenster), and another randomly selected example 2 (Promotionsordnung math, Bonn).  Both stipulate much more restrictive conditions that relate to your question. They somewhat overlap, but not completely - so there is also no uniform answer for Germany. Simply stepping away from a PhD early on would not be a problem in either case. The restrictions on the number of attempts to be successfully awarded a PhD are as follows:  

Example 1: you get one and one only attempt to resubmit a declined thesis, and to re-take the oral defense each    

Example 2: no restrictions are mentioned on the number of failed thesis attempts. You get one attempt to re-take a failed defense  

In particular given that even these two sources don't agree, you just need to pull your program's Promotionsordnung, and confirm which rules apply to you. 
"
5461,5461,8670,"Heathrow Customs - ""Arrivals from the EU"" exit","At Heathrow, after collecting your baggage, there are three exits.


  Green - nothing to declare
  
  Red - something to declare (not sure of text)
  
  Blue - arrivals from the EU


What is the blue one for? Is it if you have something to declare, and have come from an EU country? I saw no signage to tell me when I was there last week.
",VictorySaber,https://travel.stackexchange.com/users/11354,"You're referring to the three customs exits at Heathrow Airport:


(photo: Diane Phillips)

Blue is for arrivals from the EU with nothing to declare. People who can use this queue will see a green stripe around their luggage tag. Yes, this is slightly confusing.

Green is for arrivals outside the EU with nothing to declare.

These are based on the country where your air journey originated.

Red is for arrivals from anywhere who need to make a customs declaration.

Taken from Heathrow Airport: UK Customs processes at Heathrow

The UK has significantly different procedures for admitting people from the EU and from outside the EU. Since Heathrow has the largest amount of international air traffic of any airport in the world, it's important to not make people wait any longer than necessary. Separating them here helps keep the queues moving faster.
",Michael Hampton,https://travel.stackexchange.com/users/3221,http://travel.stackexchange.com/questions/30251/heathrow-customs-arrivals-from-the-eu-exit,CULTURE,travel.stackexchange.com,1.0,0.3333333333333333,0.0,1.0,1.0,1.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,1.0,Heathrow customs - export from EU,"At Heathrow, after collecting your baggage, there are three exits.


  Green - nothing to declare
  
  Red - something to declare (not sure of text)
  
  Blue - arrivals from the EU


What is the blue one for? Is it if you have something to declare, and have come from an EU country? I saw no signage to tell me when I was there last week.
","You're referring to the three customs exits at Heathrow Airport:


(photo: Diane Phillips)

Blue is for arrivals from the EU with nothing to declare. People who can use this queue will see a green stripe around their luggage tag. Yes, this is slightly confusing.

Green is for arrivals outside the EU with nothing to declare.

These are based on the country where your air journey originated.

Red is for arrivals from anywhere who need to make a customs declaration.

Taken from Heathrow Airport: UK Customs processes at Heathrow

The UK has significantly different procedures for admitting people from the EU and from outside the EU. Since Heathrow has the largest amount of international air traffic of any airport in the world, it's important to not make people wait any longer than necessary. Separating them here helps keep the queues moving faster.
"
5301,5301,8419,How does owning a home and paying on a mortgage fit into family savings and investment?,"I'm in my mid-20's, and so I am aiming at long-term growth with higher risk in my portfolio.  My financial adviser is showing me some investment allocations that put my money in some growth, mid, and value-retention locations.  He doesn't seem to be taking into the equation the fact that I am putting a huge percentage of my paycheck into my home.

I know home values fluctuate, but long term, it seems to be a pretty good way to at least retain value, and at best make a small return.  If I am already contributing so much to my ""home"" investment, why would I also invest in stocks or bonds with a low rate of return, even though they are considered a ""safe"" part of my portfolio?

Update: I think the question really has two parts.

1) How does owning a home fit into my financial portfolio?  Most seem to agree that at best it is a hedge against rent or dollar inflation, and at worst it should be viewed as a liability, and has no place alongside other real investments.

2) How should one view payments on a home mortgage?  How are they similar or different to investing in low-risk low-reward investments?
",Cory Klein,https://money.stackexchange.com/users/6310,"Have you ever tried adding up all your mortgage payments over the years? That sum, plus all the money that you put as a down payment (including various fees
paid at closing) plus all the repair and maintenance work etc) is the amount that you have ""invested"" in your house. (Yes, you can account for mortgage interest
deductions if you like to lower the total a bit).  Do you still feel that 
you made a good ""investment""?
",Dilip Sarwate,https://money.stackexchange.com/users/5760,http://money.stackexchange.com/questions/16077/how-does-owning-a-home-and-paying-on-a-mortgage-fit-into-family-savings-and-inve,LIFE_ARTS,money.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,0.0,1.0,0.0,0.5555555555555556,0.5555555555555556,1.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.6666666666666666,0.5,0.7777777777777778,0.8888888888888888,0.6,0.0,0.6666666666666666,1.0,0.7777777777777778,How does owning a house and paying for a mortgage fit with household savings and investment?,"I'm in my mid-20's, and so I am aiming at long-term growth with higher risk in my portfolio.  My financial adviser is showing me some investment allocations that put my money in some growth, mid, and value-retention locations.  He doesn't seem to be taking into the equation the fact that I am putting a huge percentage of my paycheck into my home.

I know home values fluctuate, but long term, it seems to be a pretty good way to at least retain value, and at best make a small return.  If I am already contributing so much to my ""home"" investment, why would I also invest in stocks or bonds with a low rate of return, even though they are considered a ""safe"" part of my portfolio?

Update: I think the question really has two parts.

1) How does owning a home fit into my financial portfolio?  Most seem to agree that at best it is a hedge against rent or dollar inflation, and at worst it should be viewed as a liability, and has no place alongside other real investments.

2) How should one view payments on a home mortgage?  How are they similar or different to investing in low-risk low-reward investments?
","Have you ever tried adding up all your mortgage payments over the years? That sum, plus all the money that you put as a down payment (including various fees
paid at closing) plus all the repair and maintenance work etc) is the amount that you have ""invested"" in your house. (Yes, you can account for mortgage interest
deductions if you like to lower the total a bit).  Do you still feel that 
you made a good ""investment""?
"
4881,4881,7770,Getting Value Of Radio Button And Label Text Put Into Two TextField,"I'm trying to get value form label (radio) and value of radio button. When I click label or radio button, they value input into their respective textfield

o 1
• 2
o 3
o 4

 value radio    value label
____________   ______________
|    72    |   |     2      |
|__________|   |____________|


I try create on jsfiddle but not working, only value radio button insert into text field.

See FIDDLE

How do I create function?
",rails_id,https://stackoverflow.com/users/1297435,"The change doesn't occur on the label. You need to use the change of the radio for both.

$('input[name=""20""]').on('change', function() {
        $('input[class=""20""]').val($(this).val());
        $('input[class=""1_20""]').val($(this).parent().text());
        });

",nadavge,https://stackoverflow.com/users/1860376,http://stackoverflow.com/questions/16318795/getting-value-of-radio-button-and-label-text-put-into-two-textfield,STACKOVERFLOW,stackoverflow.com,0.7777777777777778,0.3333333333333333,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,0.8888888888888888,0.8666666666666666,1.0,0.3333333333333333,0.6666666666666666,1.0,Gets the value of the radio button and places the label text in two text fields,"I'm trying to get value form label (radio) and value of radio button. When I click label or radio button, they value input into their respective textfield

o 1
• 2
o 3
o 4

 value radio    value label
____________   ______________
|    72    |   |     2      |
|__________|   |____________|


I try create on jsfiddle but not working, only value radio button insert into text field.

See FIDDLE

How do I create function?
","The change doesn't occur on the label. You need to use the change of the radio for both.

$('input[name=""20""]').on('change', function() {
        $('input[class=""20""]').val($(this).val());
        $('input[class=""1_20""]').val($(this).parent().text());
        });

"
3400,3400,5421,The process cannot access the file - after disposing InputStream,"I perform some image uploads on my server. The image save operation looks like:

 var image = Request.Files[0];
 image.SaveAs(gFilePath);
 image.InputStream.Flush();
 image.InputStream.Close();
 image.InputStream.Dispose();


but, even after disposing the InputStream sometimes I get the error The process cannot access the file because it is being used by another process. The only process which has the acces to that image is the project instance. So, what's going on ?
",Tony,https://stackoverflow.com/users/106616,"In your code it is not ensured that the stream is closed properly. If an error is occurred before calling Close or Dispose, the resource remains blocked. Use try-catch-finally and release resources in the finally block, log failures in the catch block - do not use Close and Dispose too, Dispose is enough.
",user3636971,https://stackoverflow.com/users/3636971,http://stackoverflow.com/questions/23994350/the-process-cannot-access-the-file-after-disposing-inputstream,STACKOVERFLOW,stackoverflow.com,1.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.6666666666666666,0.8333333333333334,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,0.0,1.0,"After processing the InputStream, the process cannot access the file","I perform some image uploads on my server. The image save operation looks like:

 var image = Request.Files[0];
 image.SaveAs(gFilePath);
 image.InputStream.Flush();
 image.InputStream.Close();
 image.InputStream.Dispose();


but, even after disposing the InputStream sometimes I get the error The process cannot access the file because it is being used by another process. The only process which has the acces to that image is the project instance. So, what's going on ?
","In your code it is not ensured that the stream is closed properly. If an error is occurred before calling Close or Dispose, the resource remains blocked. Use try-catch-finally and release resources in the finally block, log failures in the catch block - do not use Close and Dispose too, Dispose is enough.
"
5384,5384,8553,How get running squid3 with a local datase user?,"I want get running squid3 and obligate users to authenticate again a local and simple database users-pass file. Can be user-pass file of the system or a simple .txt file, whatever is more easy. 
",gsi-frank,https://stackoverflow.com/users/1785721,"Here is a more comprehensive guide to setting up a Squid 3 server with htdigest authentication: http://dabase.com/blog/Minimal_squid3_proxy_configuration/
",hendry,https://stackoverflow.com/users/4534,http://stackoverflow.com/questions/10559954/how-get-running-squid3-with-a-local-datase-user,STACKOVERFLOW,stackoverflow.com,0.6666666666666666,1.0,0.0,1.0,1.0,1.0,0.6666666666666666,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.3333333333333333,1.0,0.6666666666666666,1.0,1.0,0.8,1.0,0.0,0.0,1.0,How do I run squid3 with a local data user?,I want to run squid3 and force the user to verify the local and simple database user delivery files again. It can be a system user password file or a simple. TXT file.,Here is a more comprehensive guide to setting up a squid3 server using htdigest authentication: http://dabase.com/blog/minimal \ u squid3 \ u proxy \ u configuration/
3337,3337,5326,Is it safe to truncate a field revision table?,"I noticed D7 creates a field_revision table for every field, and duplicates the content from its field table counterpart even if one has revisions turned off.

I have a big text table and it is taking up a lot of space (several GBs).

Would it be safe to truncate the revision table?

PS: Meanwhile, I have also reported this as a bug.
",giorgio79,https://drupal.stackexchange.com/users/1916,"You should have a look at this How I can delete all node/field revisions?, and perhaps subscribe to http://drupal.org/node/1063266#comment-5268252
",Cyclonecode,https://drupal.stackexchange.com/users/4090,http://drupal.stackexchange.com/questions/17364/is-it-safe-to-truncate-a-field-revision-table,TECHNOLOGY,drupal.stackexchange.com,1.0,0.7777777777777778,0.0,1.0,0.6666666666666666,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.0,0.0,1.0,Is it safe to truncate the field revision table?,"I noticed D7 creates a field_revision table for every field, and duplicates the content from its field table counterpart even if one has revisions turned off.

I have a big text table and it is taking up a lot of space (several GBs).

Would it be safe to truncate the revision table?

PS: Meanwhile, I have also reported this as a bug.
","You should have a look at this How I can delete all node/field revisions?, and perhaps subscribe to http://drupal.org/node/1063266#comment-5268252
"
529,529,833,Can you match a Windows XP product key to a service pack release?,"I have a Windows XP product key on my PC, but I'm not sure which release of Windows XP it belongs to SP1, SP2, or SP3.

Is there a way I can tell without trying each one?

Note: 
In this case, I have an old PC which had an OEM XP Pro license. I don't have the media for it any more. However, I do have a media for XP Pro (off the shelf non-OEM). 

The Product Key on the case doesn't want to validate. So I'm presuming that there is something encoded in it as to the release it works with. I can get media, I just don't want to try each one.
",BIBD,https://superuser.com/users/815,"You need to download or get access to OEM XP Pro media. The service pack version does not matter in the least.

I've had good success downloading this media from torrent sites. Some others would say this is unwise, but so long as you download a file that is highly rated, you're unlikely to have issues.

Non-OEM media will not recognize or validate your product key.
",music2myear,https://superuser.com/users/74026,http://superuser.com/questions/186405,TECHNOLOGY,superuser.com,0.8888888888888888,0.8888888888888888,0.0,1.0,0.6666666666666666,1.0,0.6666666666666666,0.4444444444444444,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.3333333333333333,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.7,1.0,0.0,0.0,1.0,Can you match the Windows XP product key to the service pack version?,"I have a Windows XP product key on my PC, but I'm not sure which release of Windows XP it belongs to SP1, SP2, or SP3.

Is there a way I can tell without trying each one?

Note: 
In this case, I have an old PC which had an OEM XP Pro license. I don't have the media for it any more. However, I do have a media for XP Pro (off the shelf non-OEM). 

The Product Key on the case doesn't want to validate. So I'm presuming that there is something encoded in it as to the release it works with. I can get media, I just don't want to try each one.
","You need to download or get access to OEM XP Pro media. The service pack version does not matter in the least.

I've had good success downloading this media from torrent sites. Some others would say this is unwise, but so long as you download a file that is highly rated, you're unlikely to have issues.

Non-OEM media will not recognize or validate your product key.
"
3658,3658,5836,Does Spider-Man shoot spider silk?,"In the comics, Spider-Man shoots synthetic 'webbing' that he created from wrist devices called web-shooters. Is this the same (but scaled up) as spider silk, or is it stronger/different in anyway?
",AncientSwordRage,https://scifi.stackexchange.com/users/3804,"The Marvel Wiki entry on Spider-Man's Web-Shooters says this about the web fluid:


  The web fluid is a shear-thinning liquid (virtually solid until a shearing force is applied to it, rendering it fluid) whose exact formula is as yet unknown, but is related to nylon. On contact with air, the long-chain polymer knits and forms an extremely tough, flexible fiber with extraordinary adhesive properties. The web fluid's adhesive quality diminishes rapidly with exposure to air. (Where it does not make contact with air, such as the attachment disk of the web-shooter, it remains very adhesive.) After about one to two hours, certain imbibed esters cause the solid form of the web fluid to dissolve into a powder. Because the fluid almost instantly sublimates from solid to liquid when under shear pressure, and is not adhesive in its anaerobic liquid/solid phase transition point, there is no clogging of the web-shooter's parts.


The Marvel Directory entry on Spider-Man says that Peter Parker intended to imitate spider's silk.


  Parker used equipment borrowed from his high school to fabricate a fluid that imitated a spider's silk web, and spinneret devices to project that fluid from his wrists in the form of a web strand.

",Brett White,https://scifi.stackexchange.com/users/2383,http://scifi.stackexchange.com/questions/10614/does-spider-man-shoot-spider-silk,LIFE_ARTS,scifi.stackexchange.com,1.0,1.0,0.3333333333333333,1.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.4444444444444444,0.0,0.0,1.0,1.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,1.0,1.0,1.0,1.0,1.0,0.8666666666666666,0.0,0.6666666666666666,0.6666666666666666,1.0,Spiderman shoot spider silk?,"In the cartoon, Spiderman uses a wrist device called a cyber shooter to photograph synthetic ""webbing."". Is this the same as spider silk (but magnified), or stronger / different?","The Marvel Wiki entry on Spider-Man's Web-Shooters says this about the web fluid:


  The web fluid is a shear-thinning liquid (virtually solid until a shearing force is applied to it, rendering it fluid) whose exact formula is as yet unknown, but is related to nylon. On contact with air, the long-chain polymer knits and forms an extremely tough, flexible fiber with extraordinary adhesive properties. The web fluid's adhesive quality diminishes rapidly with exposure to air. (Where it does not make contact with air, such as the attachment disk of the web-shooter, it remains very adhesive.) After about one to two hours, certain imbibed esters cause the solid form of the web fluid to dissolve into a powder. Because the fluid almost instantly sublimates from solid to liquid when under shear pressure, and is not adhesive in its anaerobic liquid/solid phase transition point, there is no clogging of the web-shooter's parts.


The Marvel Directory entry on Spider-Man says that Peter Parker intended to imitate spider's silk.


  Parker used equipment borrowed from his high school to fabricate a fluid that imitated a spider's silk web, and spinneret devices to project that fluid from his wrists in the form of a web strand.

"
3415,3415,5438,Experience with direct data access components,"I would like to know as to what has been the experience of using direct data access components like devart's MyDAC which allows a direct connection to the mysql server rather than through the client library or ODBC.
",Vinayak Mahadevan,https://stackoverflow.com/users/366347,"I've never used MyDAC before. My experience is with DAC for MySQL from http://www.microolap.com/.

So far so good. Pretty easy to drop onto my Delphi projects, set the values of various properties, and then ready to connect. It has quite a number of useful components that allows you to retrieve data in several ways and you can use it easily with TDataSource.

No issues with deployment as well. All compiled nicely into one EXE.

Hope this helps!
",SharkMan,https://stackoverflow.com/users/366873,http://stackoverflow.com/questions/3042008/experience-with-direct-data-access-components,STACKOVERFLOW,stackoverflow.com,1.0,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8,0.0,0.0,0.0,1.0,Experience with direct data access components,"I'd like to know about the experience of using direct data access components such as devirt's mydac, which allows direct connections to MySQL servers, rather than through client libraries or ODBC.","I've never used MyDAC before. My experience is with DAC for MySQL from http://www.microolap.com/.

So far so good. Pretty easy to drop onto my Delphi projects, set the values of various properties, and then ready to connect. It has quite a number of useful components that allows you to retrieve data in several ways and you can use it easily with TDataSource.

No issues with deployment as well. All compiled nicely into one EXE.

Hope this helps!
"
2311,2311,3687,Google Apps login in wordpress,"I manage a google apps domain with plenty of users;

I would like to join Google apps with a Wordpress based intranet app we're creating. 

Which level of integration could I expect to achieve?

Our hope is to create users in wordpress using their google apps email and let them login using their google apps password, so that they don't need to remember two different passwords.

How would you suggest we should implement this?
",Bakaburg,https://wordpress.stackexchange.com/users/10100,"Use the plugin Wordpress Social Login:

http://wordpress.org/extend/plugins/wordpress-social-login/

Does exactly what you want except the user doesn't actually have to type in their username and password if they are already logged in to Google Apps - they just click the Google icon and it will log them in to WordPress using Google Apps. 

And yes, you can create users in WordPress first tied to Google Apps email addresses and then the users can login without needing a registration step.

It provides other auth options (FB, Twitter, etc.) if you'd like.
",anderly,https://wordpress.stackexchange.com/users/13756,http://wordpress.stackexchange.com/questions/47265/google-apps-login-in-wordpress,TECHNOLOGY,wordpress.stackexchange.com,1.0,0.3333333333333333,0.0,1.0,0.3333333333333333,1.0,0.4444444444444444,0.3333333333333333,0.3333333333333333,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,1.0,Google App log in to WordPress,"I manage a google apps domain with plenty of users;

I would like to join Google apps with a Wordpress based intranet app we're creating. 

Which level of integration could I expect to achieve?

Our hope is to create users in wordpress using their google apps email and let them login using their google apps password, so that they don't need to remember two different passwords.

How would you suggest we should implement this?
","Use the plugin Wordpress Social Login:

http://wordpress.org/extend/plugins/wordpress-social-login/

Does exactly what you want except the user doesn't actually have to type in their username and password if they are already logged in to Google Apps - they just click the Google icon and it will log them in to WordPress using Google Apps. 

And yes, you can create users in WordPress first tied to Google Apps email addresses and then the users can login without needing a registration step.

It provides other auth options (FB, Twitter, etc.) if you'd like.
"
5694,5694,9025,Riemann-Lebesgue equivalence for n-dimensional integration,"""Lebesgue's Theorem"" states that for any bounded $f:[a,b] \to \mathbb{R}$, $f$ is Riemann Integrable iff $m\{x:f  \text{ is not continuous at x }\}=0$, and if so Riemann's integral coincides with Lebesgue's. ($m$ is Lebesgue's measure).

Does there exist a generalization of this theorem for higher dimensions? Can I have a proof or a reference please?
",user1337,https://math.stackexchange.com/users/62839,"First note that the Lebesgue-Riemann theorem states that $f:[a,b]\to \mathbb R$ is Riemann integrable if, and only if, $f$ is bounded and is continuous almost everywhere (if a function is not bounded, it can't be Riemann integrable). 

A proof of the more general result for multivariable functions can be found in volume 1 of ""Real Analysis"" by Duistermaat. A better exercise in fact will be to take this wiki proof and adapt it to $\mathbb R^n$. 
",Ittay Weiss,https://math.stackexchange.com/users/30953,http://math.stackexchange.com/questions/324047/riemann-lebesgue-equivalence-for-n-dimensional-integration,SCIENCE,math.stackexchange.com,1.0,0.4444444444444444,0.0,0.3333333333333333,1.0,1.0,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.8,0.3333333333333333,0.3333333333333333,1.0,1.0,Riemann Lebesgue equivalence of n-dimensional integral,"""Lebesgue theorem"" indicates that for any bounded $f: [a, b] \ to \ mathbb {r} $, $f $is Riemann integrable if $m {X: F \ text {is not continuous at x} \} = 0 $. If so, Riemann's integral is consistent with Lebesgue's. ($M $is a measure of Lebesgue).","First of all, Lebesgue Riemann theorem points out that $f: [a, b] \ mathbb R $is Riemann integrable if and only if $f $is bounded and almost everywhere continuous (if a function is unbounded, it cannot be Riemann integrable)."
3883,3883,6188,What is the cardinality of the family of unlabelled bipartite graphs on n vertices?,"I have attempted to calculate the number of unlabelled bipartite graphs as follows:


  Let $G = (V_1, V_2, E)$ be a bipartite graph on $n$ vertices with $|V_1| = m$ and $|V_2| = n-m$. Assume without loss of generality that $|V_1| \leq |V_2|$ so $m \leq \left\lfloor \frac{n}{2} \right\rfloor$. If $G$ is complete bipartite then it has $m(n-m)$ edges since each of the vertices in $V_1$ is connected to each in $V_2$. Thus, the total number of bipartite graphs with parts of size $m$ and $n-m$ is $2^{m(n-m)}$. In order to find the total number of possible bipartite graphs on $n$ vertices we sum over all possible $m$:
  \begin{align}
\sum^{\left\lfloor \frac{n}{2} \right\rfloor}_{m=1} 2^{m(n-m)}
\end{align}


However, I notice that I have counted labelled bipartite graphs where I need the number of unlabelled graphs. I'm struggling to see how to account for this.
",Andrew,https://mathoverflow.net/users/31128,"In the formalism of species of structure. The species $Bip(X,Y)$ of bipartite graphs on two sorts of vertex $X$ and $Y$ can be described as,
$$
Bip(X,Y) \simeq E^2 \circ (E^\bullet(X) E^\bullet(Y)) \simeq E^2 \circ (XY E(X + Y))
$$
where $E$ is the species of sets, $\circ$ is the functorial composition of species and $\bullet$ is the pointing operator.

If I make no mistake the series you search is,
$$
Bip(x,y) = \prod_{k \ge 1}\exp\left[\frac{2}{k}x^ky^k\prod_{l \ge 1} \exp\left(\frac{1}{l}(x^{kl}+y^{kl}) \right)\right]
$$

Hope this helps.

Edit : Doing the computations I find,
\begin{align*}
Bip(xt,yt) &amp;=
1+2xy{t}^{2}+ \left( 2y{x}^{2}+2{y}^{2}x \right) {t}^{3}+
 \left( 5{y}^{2}{x}^{2}+2y{x}^{3}+2{y}^{3}x \right) {t}^{4} + ...
\end{align*}
which is wrong. For example we should have $x^2 + y^2 +2xy$ in front of $t^2$, a $xt$ term as well as a $yt$ term..
",Samuel Vidal,https://mathoverflow.net/users/20997,http://mathoverflow.net/questions/120674,SCIENCE,mathoverflow.net,1.0,0.5555555555555556,0.0,0.3333333333333333,1.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.8888888888888888,What is the cardinality of a family of unmarked bipartite graphs on n vertices?,"I have attempted to calculate the number of unlabelled bipartite graphs as follows:


  Let $G = (V_1, V_2, E)$ be a bipartite graph on $n$ vertices with $|V_1| = m$ and $|V_2| = n-m$. Assume without loss of generality that $|V_1| \leq |V_2|$ so $m \leq \left\lfloor \frac{n}{2} \right\rfloor$. If $G$ is complete bipartite then it has $m(n-m)$ edges since each of the vertices in $V_1$ is connected to each in $V_2$. Thus, the total number of bipartite graphs with parts of size $m$ and $n-m$ is $2^{m(n-m)}$. In order to find the total number of possible bipartite graphs on $n$ vertices we sum over all possible $m$:
  \begin{align}
\sum^{\left\lfloor \frac{n}{2} \right\rfloor}_{m=1} 2^{m(n-m)}
\end{align}


However, I notice that I have counted labelled bipartite graphs where I need the number of unlabelled graphs. I'm struggling to see how to account for this.
","In the formalism of species of structure. The species $Bip(X,Y)$ of bipartite graphs on two sorts of vertex $X$ and $Y$ can be described as,
$$
Bip(X,Y) \simeq E^2 \circ (E^\bullet(X) E^\bullet(Y)) \simeq E^2 \circ (XY E(X + Y))
$$
where $E$ is the species of sets, $\circ$ is the functorial composition of species and $\bullet$ is the pointing operator.

If I make no mistake the series you search is,
$$
Bip(x,y) = \prod_{k \ge 1}\exp\left[\frac{2}{k}x^ky^k\prod_{l \ge 1} \exp\left(\frac{1}{l}(x^{kl}+y^{kl}) \right)\right]
$$

Hope this helps.

Edit : Doing the computations I find,
\begin{align*}
Bip(xt,yt) &amp;=
1+2xy{t}^{2}+ \left( 2y{x}^{2}+2{y}^{2}x \right) {t}^{3}+
 \left( 5{y}^{2}{x}^{2}+2y{x}^{3}+2{y}^{3}x \right) {t}^{4} + ...
\end{align*}
which is wrong. For example we should have $x^2 + y^2 +2xy$ in front of $t^2$, a $xt$ term as well as a $yt$ term..
"
5588,5588,8869,Do cold blooded animals generate any heat?,"In explaining energy and work to an 8 year-old I said that all conversion of energy generates heat as a by-product.  For example, cars generate heat in their engines and running generates heat in our bodies.  Then the 8 year-old said, except for cold-blooded animals.

So my question is, do cold-blooded animals generate any heat in their conversion of stored energy (food, fat, etc) into motion?  If they generate heat, why are they cold-blooded?
",Jeff,https://biology.stackexchange.com/users/3031,"As the others have said, animals and insects (and even plants) generate heat through metabolism and can regulate their temperature this way.  

Just wanted to add a third point that mammals have developed brown fat, fat tissue which is dark with extra mitochondria which burn energy to generate heat.  These are rich with uncoupling protein (a particular uncoupling protein called thermogenin) which passes protons through the mitochondrial membrane to generate heat rather than generate ATP. 

Most of the heat generated by mammals is not from brown adipose tissue, but it is a particular adaptation to generate heat that endotherms have evolved.  The brain alone is responsible for 16% of the heat generated by human bodies.  
",shigeta,https://biology.stackexchange.com/users/3632,http://biology.stackexchange.com/questions/7076/do-cold-blooded-animals-generate-any-heat,SCIENCE,biology.stackexchange.com,1.0,0.6666666666666666,0.0,0.5,1.0,1.0,0.8333333333333334,0.8333333333333334,0.5,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.8333333333333334,0.6666666666666666,1.0,1.0,0.7,0.0,0.0,1.0,0.8333333333333334,Can cold-blooded animals produce heat?,"When explaining energy and work to an 8-year-old, I said that all energy conversion is a by-product of heat generation. For example, cars generate heat in the engine, while running in our bodies generates heat. Then the 8-year-old said, except for cold-blooded animals.","As the others have said, animals and insects (and even plants) generate heat through metabolism and can regulate their temperature this way.  

Just wanted to add a third point that mammals have developed brown fat, fat tissue which is dark with extra mitochondria which burn energy to generate heat.  These are rich with uncoupling protein (a particular uncoupling protein called thermogenin) which passes protons through the mitochondrial membrane to generate heat rather than generate ATP. 

Most of the heat generated by mammals is not from brown adipose tissue, but it is a particular adaptation to generate heat that endotherms have evolved.  The brain alone is responsible for 16% of the heat generated by human bodies.  
"
856,856,1364,How to expire cache part using rake task in rails3?,"I am creating a application, rails3 with ruby 1.9.2. I have a left menu with some blog posts. This is displaying in every page in my application, so I am using cache concept in views. That blog posts update in database every day using rake task. 

In rake task database update everyday first hour, after update database I want to clear that cache part from rake task. Any one help how to write rake task for expiring cache.
",Durga Prasad,https://stackoverflow.com/users/748172,"use a cronjob for your rake tast: https://github.com/javan/whenever

expire fragments with a sweeper: http://guides.rubyonrails.org/caching_with_rails.html#sweepers
",phoet,https://stackoverflow.com/users/100731,http://stackoverflow.com/questions/14010750/how-to-expire-cache-part-using-rake-task-in-rails3,STACKOVERFLOW,stackoverflow.com,0.8333333333333334,0.6666666666666666,0.0,1.0,1.0,1.0,0.5,0.5,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.5,1.0,0.6666666666666666,1.0,1.0,0.9,1.0,0.0,0.0,0.8333333333333334,How to use the rake task in rails 3 to expire the cache part?,"I'm creating an application called rails 3 in Ruby 1.9.2. I have a left menu and some blog posts. This will appear on every page of the application, so I use the caching concept in the view. That blog uses rake tasks to update the database every day.","use a cronjob for your rake tast: https://github.com/javan/whenever

expire fragments with a sweeper: http://guides.rubyonrails.org/caching_with_rails.html#sweepers
"
1454,1454,2290,Tic Tac Toe implementation in Objective-C,"First off, here's the code:

main.m

#import &lt;Foundation/Foundation.h&gt;
#import ""PSBoard.h""
#import ""PSPlayer.h""
#import ""PSInputHandler.h""

int main(int argc, const char * argv[]) {

    @autoreleasepool {

        NSLog(@""Enter Player 1 Name:"");
        NSString *playerOneName = [PSInputHandler getString];
        NSLog(@""Enter Player 2 Name:"");
        NSString *playerTwoName = [PSInputHandler getString];

        NSLog(@""How many rows and columns will you play with?"");
        NSUInteger numberOfRowsAndColumns = [PSInputHandler getInteger];

        PSPlayer *playerOne = [[PSPlayer alloc] initWithSymbol:PSBoardSymbolX name:playerOneName];
        PSPlayer *playerTwo = [[PSPlayer alloc] initWithSymbol:PSBoardSymbolO name:playerTwoName];
        PSBoard  *board = [[PSBoard alloc] initWithRows:numberOfRowsAndColumns columns:numberOfRowsAndColumns players:@[playerOne, playerTwo]];

        do {
            PSPlayer *currentPlayer = [board playerUp];
            BOOL validInputEntered = NO;

            //Loop until valid input is entered
            while(!validInputEntered) {
                //Get input coordinates
                NSLog(@""%@, enter a row (1-%lu)."", currentPlayer.name, (unsigned long)numberOfRowsAndColumns);
                NSUInteger row = [PSInputHandler getInteger];
                NSLog(@""Now enter a column (1-%lu)."", (unsigned long)numberOfRowsAndColumns);
                NSUInteger column = [PSInputHandler getInteger];

                //Verify that nothing is already placed there
                PSBoardSymbol symbolOfPlayerAtCoordinates = [board playerAtRow:row-1 column:column-1].symbol;

                if((symbolOfPlayerAtCoordinates != PSBoardSymbolX &amp;&amp; symbolOfPlayerAtCoordinates != PSBoardSymbolO) &amp;&amp;
                   row &gt; 0 &amp;&amp; row &lt;= numberOfRowsAndColumns &amp;&amp; column &gt; 0 &amp;&amp; column &lt;= numberOfRowsAndColumns) {
                    [board setPlayer:currentPlayer atRow:(row-1) column:(column-1)];
                    validInputEntered = YES;
                }
            }

            //Show the board
            [board display];

        } while(!board.winner);

        NSLog(@""Congrats %@! You won."", [board winner].name);
    }

    return 0;
}


PSBoard.h

#import &lt;Foundation/Foundation.h&gt;

@class PSPlayer;

@interface PSBoard : NSObject

@property (nonatomic) NSUInteger        rows;
@property (nonatomic) NSUInteger        columns;
@property (nonatomic, strong) PSPlayer *winner;

-(instancetype)initWithRows:(NSUInteger)rows columns:(NSUInteger)columns players:(NSArray *)players;
-(PSPlayer *)playerAtRow:(NSUInteger)row column:(NSUInteger)column;
-(void)setPlayer:(PSPlayer *)player atRow:(NSUInteger)row column:(NSUInteger)column;
-(void)display;
-(PSPlayer *)playerUp;

@end


PSBoard.m

#import ""PSBoard.h""
#import ""PSPlayer.h""

@interface PSBoard ()

@property (nonatomic, strong) NSMutableArray *internalBoardRepresentation;
@property (nonatomic, strong) NSArray *players;
@property (nonatomic, strong) PSPlayer *oldPlayerUp;

@end

@implementation PSBoard

-(instancetype)initWithRows:(NSUInteger)rows columns:(NSUInteger)columns players:(NSArray *)players {

    if(self = [super init]) {

        self.rows = rows;
        self.columns = columns;
        self.players = players;
        self.internalBoardRepresentation = [[NSMutableArray alloc] initWithCapacity:rows];

        PSPlayer *null = [[PSPlayer alloc] initWithSymbol:PSBoardSymbolNone name:nil];

        for(NSUInteger row = 0; row &lt; rows; row++) {

            NSMutableArray *currentColumn = [NSMutableArray array];
            for(NSUInteger column = 0; column &lt; columns; column++) {
                [currentColumn addObject:null];
            }
            [self.internalBoardRepresentation addObject:currentColumn];
        }

        self.oldPlayerUp = players[0];
    }

    return self;
}
-(PSPlayer *)playerAtRow:(NSUInteger)row column:(NSUInteger)column {
    return self.internalBoardRepresentation[row][column];
}
-(void)setPlayer:(PSPlayer *)player atRow:(NSUInteger)row column:(NSUInteger)column {
    self.internalBoardRepresentation[row][column] = player;
    [self checkForWinner];
}
-(void)checkForWinner {

    NSUInteger numberOfPiecesInARowToWin = MAX(self.rows, self.columns);

    //Check horizontal lines
    for(NSUInteger row = 0; row &lt; self.rows; row++) {

        PSPlayer *playerInFirstColumn = [self playerAtRow:row column:0];
        NSUInteger playerPiecesInRow = 0;

        for(NSUInteger column = 0; column &lt; self.columns; column++) {
            if([[self playerAtRow:row column:column] isEqualTo:playerInFirstColumn]) {
                playerPiecesInRow++;
            }
        }

        if(playerPiecesInRow &gt;= numberOfPiecesInARowToWin &amp;&amp; playerInFirstColumn.symbol != PSBoardSymbolNone) {
            self.winner = playerInFirstColumn;
            return;
        }
    }

    //Check vertical lines
    for(NSUInteger column = 0; column &lt; self.columns; column++) {

        PSPlayer *playerInFirstRow = [self playerAtRow:0 column:column];
        NSUInteger playerPiecesInColumn = 0;

        for(NSUInteger row = 0; row &lt; self.rows; row++) {
            if([[self playerAtRow:row column:column] isEqualTo:playerInFirstRow]) {
                playerPiecesInColumn++;
            }
        }

        if(playerPiecesInColumn &gt;= numberOfPiecesInARowToWin &amp;&amp; playerInFirstRow.symbol != PSBoardSymbolNone) {
            self.winner = playerInFirstRow;
            return;
        }
    }

    //Check top left to bottom right diagonal
    PSPlayer *playerInFirstSlotOfLeftDiagonal = [self playerAtRow:0 column:0];
    NSUInteger playerPiecesInLeftDiagonal = 0;

    for(NSUInteger row = 0, column = 0; row &lt; self.rows; column++, row++) {
        if([[self playerAtRow:row column:column] isEqualTo:playerInFirstSlotOfLeftDiagonal]) {
            playerPiecesInLeftDiagonal++;
        }
    }

    if(playerPiecesInLeftDiagonal &gt;= numberOfPiecesInARowToWin &amp;&amp; playerInFirstSlotOfLeftDiagonal.symbol != PSBoardSymbolNone) {
        self.winner = playerInFirstSlotOfLeftDiagonal;
        return;
    }

    //Check bottom left to top right diagonal
    PSPlayer *playerInFirstSlotOfRightDiagonal = [self playerAtRow:self.rows-1 column:0];
    NSUInteger playerPiecesInRightDiagonal = 0;

    for(NSInteger row = self.rows-1, column = 0; row &gt;= 0; row--, column++) {
        if([[self playerAtRow:row column:column] isEqualTo:playerInFirstSlotOfRightDiagonal]) {
            playerPiecesInRightDiagonal++;
        }
    }

    if(playerPiecesInRightDiagonal &gt;= numberOfPiecesInARowToWin &amp;&amp; playerInFirstSlotOfRightDiagonal.symbol != PSBoardSymbolNone) {
        self.winner = playerInFirstSlotOfRightDiagonal;
        return;
    }
}
-(void)display {

    NSMutableString *displayString = [NSMutableString stringWithFormat:@""\n""];

    for(NSUInteger row = 0; row &lt; self.rows; row++) {

        NSMutableString *rowDisplayString = [[NSMutableString alloc] init];
        NSString *innerFillerString = (row == self.rows-1) ? @"" "" : @""_"";

        for(NSUInteger column = 0; column &lt; self.columns; column++) {
            NSString *columnSeparator = (column == self.columns-1) ? @"" "" : @""|"";
            NSString *playerSymbol = ([self playerAtRow:row column:column].symbolStringRepresentation);

            if(playerSymbol.length == 0) {
                playerSymbol = innerFillerString;
            }

            [rowDisplayString appendString:[NSString stringWithFormat:@""%@%@%@%@"", innerFillerString, playerSymbol, innerFillerString, columnSeparator]];
        }

        [displayString appendString:[NSString stringWithFormat:@""%@\n"", rowDisplayString]];
        [rowDisplayString setString:@""""];
    }

    NSLog(@""%@"", displayString);
}
-(PSPlayer *)playerUp {

    PSPlayer *nextPlayerUp = self.players[1-([self.players indexOfObjectIdenticalTo:self.oldPlayerUp])];
    PSPlayer *previousPlayerUp = self.oldPlayerUp;
    self.oldPlayerUp = nextPlayerUp;
    return previousPlayerUp;
}

@end


PSPlayer.h

#import &lt;Foundation/Foundation.h&gt;

typedef NS_ENUM(NSInteger, PSBoardSymbol) {

    PSBoardSymbolX = 0,
    PSBoardSymbolO,
    PSBoardSymbolNone
};

@interface PSPlayer : NSObject

-(instancetype)initWithSymbol:(PSBoardSymbol)symbol name:(NSString *)name;

@property (nonatomic)  PSBoardSymbol    symbol;
@property (nonatomic)  NSString        *symbolStringRepresentation;
@property (nonatomic, strong) NSString *name;

@end


PSPlayer.m

#import ""PSPlayer.h""

@implementation PSPlayer

-(instancetype)initWithSymbol:(PSBoardSymbol)symbol name:(NSString *)name{

    if(self = [super init]) {

        self.symbol = symbol;
        self.symbolStringRepresentation = (symbol == PSBoardSymbolO) ? @""O"" : ((symbol == PSBoardSymbolX) ? @""X"" : @"""");
        self.name = name;
    }

    return self;
}

@end


PSInputHandler.h

#import &lt;Foundation/Foundation.h&gt;

@interface PSInputHandler : NSObject

+(NSString *)getString;
+(NSInteger)getInteger;

@end


PSInputHandler.m

#import ""PSInputHandler.h""

@implementation PSInputHandler

+(NSInteger)getInteger {
    int temp;
    scanf(""%i"", &amp;temp);
    return (NSInteger)temp;
}
+(NSString *)getString {
    char input[256];
    scanf(""%s"", input);
    return [NSString stringWithUTF8String:input];
}

@end


So my questions are:


In the PSInputHandler.m class, I wasn't so sure about how to get input from the command line. I read that fgets() is a potential alternative to scanf(), but is there any reason for me to use one over the other?
The method in PSBoard.m that checks for a winner, checkForWinner, is very long. Is there a simplified design I can use to shorten it?
I struggled to name the playerUp method, which returns the player whose turn it is. Is there a more suitable name?
When the user inputs which row and column to place an X or O in, I made it so that the coordinates they enter are from 1 to the number of rows and not 0 to the number of rows minus one (like with zero-based array indexing). Is this more user-friendly, or should I change it to zero-based indexing?
In PSPlayer.m, I use nested ternary operators. Is this too hard to understand? Should I change it to if statements?

When getting the user's input for how many rows and columns to use, which I expect to be an integer, how can I sanitize the input so that the program doesn't crash when a string (for example) is inputted?



Any other critique welcome!
",pasawaya,https://codereview.stackexchange.com/users/24129,"I will update this post over the weekend as I go through your question more and come up with some examples to iterate over my points, but I thought for now, I'd answer some of the easier questions.



Question 1.

I'm not sure and cannot remember (I will try to find out).  At the end of the day, you might consider implementing this with a GUI.  If you're using Xcode, it's quite easy to develop a GUI for either OSX or iOS, and most of your logic is already in place.  You'd just have to write the logic to hook the GUI up to the business logic.



Question 2.

One immediate thought on speeding up this process would be to use a flag to mark whether or not a row/column is a potential winner.  AND, if you do find a row that's a winner, immediately return the winner.

For a row to be a winner, every piece in the row must belong to the same player, correct?  So set the owner of the piece in the first box, and check every box.  As soon as you get to a box that doesn't match the first box, break;.  You don't need to check any more boxes in that row/column/diagonal.  You can move to the next row/column/diagonal.  And if you get to the end of the inner loop and haven't had to break; because you've found the winner, then you can set the winner and return; and stop checking.  

So basically, refactor into something more like this:

for(NSUInteger row = 0; row &lt; self.rows; row++) {

    PSPlayer *playerInFirstColumn = [self playerAtRow:row column:0];
    BOOL winnerFound;

    for(NSUInteger column = 0; column &lt; self.columns; column++) {
        if(![[self playerAtRow:row column:column] isEqualTo:playerInFirstColumn]) {
            winnerFound = false;
            break;
        } else {
            winnerFound = true;
        }
    }

    if (winnerFound) {
        self.winner = playerInFirstColumn;
        return;
    }
}


This will improve performance some.  You can probably still do better, but this is still a drastic improvement, especially for exceptionally large boards.

Now... the BEST performance improvement I can think of would actually mean you're running this check after every turn (which you're already doing, right?).  In this case, you only need to check ONE row, ONE column, and ZERO, ONE, or TWO diagonals.  And this would be a massive performance boost.  You only need to check a the row the piece was played in, the column the piece was played in, and the diagonal the piece was played in.  Every other row, column, and diagonal has been checked on a previous turn and a winner was not found otherwise the game would be over and we wouldn't've had this turn. 

AND, even if we modified the rules to continue playing after a winner has been found, you can just use an array to keep track of each row and column and diagonal and who won that row/column/diagonal, and still only need to check the relevant rows (and only check them for the player who played the piece).



Question 3.

playerUp is probably an alright method name.  Maybe activePlayer?  If you feel it's not descriptive enough, don't hesitate to leave a comment explaining it.  // returns the player whose turn it is



Question 4.

As a programmer, I am used to 0-based indexing systems, but your assumption is correct.  Most people who use programs aren't programs and would be more comfortable with a 1-based coordinate system.  Though... back to question 1... if this were given a GUI, it wouldn't matter.  ;)



Question 5.

Personally, I hate the ternary operators and never use them.  Whether or not they're acceptable would depend largely on who you're working with though.  In this case, it's a simple one.  Again, personally, I hate them and I wouldn't use it, because I never use it, but this one is simple enough that if you and everyone working on the project are comfortable with them, then go ahead and keep it.

Question 5.1.

The exact way you want to handle non-number input is an implementation detail that'd be up to you.  Do you want to request another input?  Do you want to just strip out the non-numbers and use the numbers that are there?

But as for actually checking the string itself, once you've got it into an NSString, it's quite easy:

NSCharacterSet *nonNumbers = [[NSCharacterSet 
    decimalDigitCharacterSet] invertedSet];

if([yourString rangeOfCharactersFromSet:nonNumbers].location == NSNotFound) {
    // string is all numbers and is good to go
} else {
    // string contains non-number characters
}

",nhgrif,https://codereview.stackexchange.com/users/36366,http://codereview.stackexchange.com/questions/40820/tic-tac-toe-implementation-in-objective-c,TECHNOLOGY,codereview.stackexchange.com,0.6666666666666666,0.3333333333333333,0.0,0.0,1.0,0.6666666666666666,0.6666666666666666,0.4444444444444444,1.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.7777777777777778,0.8888888888888888,0.5555555555555556,1.0,1.0,0.7333333333333333,0.6666666666666666,0.3333333333333333,1.0,0.8888888888888888,Implementing tic tac toe in Objective-C,"First off, here's the code:

main.m

#import &lt;Foundation/Foundation.h&gt;
#import ""PSBoard.h""
#import ""PSPlayer.h""
#import ""PSInputHandler.h""

int main(int argc, const char * argv[]) {

    @autoreleasepool {

        NSLog(@""Enter Player 1 Name:"");
        NSString *playerOneName = [PSInputHandler getString];
        NSLog(@""Enter Player 2 Name:"");
        NSString *playerTwoName = [PSInputHandler getString];

        NSLog(@""How many rows and columns will you play with?"");
        NSUInteger numberOfRowsAndColumns = [PSInputHandler getInteger];

        PSPlayer *playerOne = [[PSPlayer alloc] initWithSymbol:PSBoardSymbolX name:playerOneName];
        PSPlayer *playerTwo = [[PSPlayer alloc] initWithSymbol:PSBoardSymbolO name:playerTwoName];
        PSBoard  *board = [[PSBoard alloc] initWithRows:numberOfRowsAndColumns columns:numberOfRowsAndColumns players:@[playerOne, playerTwo]];

        do {
            PSPlayer *currentPlayer = [board playerUp];
            BOOL validInputEntered = NO;

            //Loop until valid input is entered
            while(!validInputEntered) {
                //Get input coordinates
                NSLog(@""%@, enter a row (1-%lu)."", currentPlayer.name, (unsigned long)numberOfRowsAndColumns);
                NSUInteger row = [PSInputHandler getInteger];
                NSLog(@""Now enter a column (1-%lu)."", (unsigned long)numberOfRowsAndColumns);
                NSUInteger column = [PSInputHandler getInteger];

                //Verify that nothing is already placed there
                PSBoardSymbol symbolOfPlayerAtCoordinates = [board playerAtRow:row-1 column:column-1].symbol;

                if((symbolOfPlayerAtCoordinates != PSBoardSymbolX &amp;&amp; symbolOfPlayerAtCoordinates != PSBoardSymbolO) &amp;&amp;
                   row &gt; 0 &amp;&amp; row &lt;= numberOfRowsAndColumns &amp;&amp; column &gt; 0 &amp;&amp; column &lt;= numberOfRowsAndColumns) {
                    [board setPlayer:currentPlayer atRow:(row-1) column:(column-1)];
                    validInputEntered = YES;
                }
            }

            //Show the board
            [board display];

        } while(!board.winner);

        NSLog(@""Congrats %@! You won."", [board winner].name);
    }

    return 0;
}


PSBoard.h

#import &lt;Foundation/Foundation.h&gt;

@class PSPlayer;

@interface PSBoard : NSObject

@property (nonatomic) NSUInteger        rows;
@property (nonatomic) NSUInteger        columns;
@property (nonatomic, strong) PSPlayer *winner;

-(instancetype)initWithRows:(NSUInteger)rows columns:(NSUInteger)columns players:(NSArray *)players;
-(PSPlayer *)playerAtRow:(NSUInteger)row column:(NSUInteger)column;
-(void)setPlayer:(PSPlayer *)player atRow:(NSUInteger)row column:(NSUInteger)column;
-(void)display;
-(PSPlayer *)playerUp;

@end


PSBoard.m

#import ""PSBoard.h""
#import ""PSPlayer.h""

@interface PSBoard ()

@property (nonatomic, strong) NSMutableArray *internalBoardRepresentation;
@property (nonatomic, strong) NSArray *players;
@property (nonatomic, strong) PSPlayer *oldPlayerUp;

@end

@implementation PSBoard

-(instancetype)initWithRows:(NSUInteger)rows columns:(NSUInteger)columns players:(NSArray *)players {

    if(self = [super init]) {

        self.rows = rows;
        self.columns = columns;
        self.players = players;
        self.internalBoardRepresentation = [[NSMutableArray alloc] initWithCapacity:rows];

        PSPlayer *null = [[PSPlayer alloc] initWithSymbol:PSBoardSymbolNone name:nil];

        for(NSUInteger row = 0; row &lt; rows; row++) {

            NSMutableArray *currentColumn = [NSMutableArray array];
            for(NSUInteger column = 0; column &lt; columns; column++) {
                [currentColumn addObject:null];
            }
            [self.internalBoardRepresentation addObject:currentColumn];
        }

        self.oldPlayerUp = players[0];
    }

    return self;
}
-(PSPlayer *)playerAtRow:(NSUInteger)row column:(NSUInteger)column {
    return self.internalBoardRepresentation[row][column];
}
-(void)setPlayer:(PSPlayer *)player atRow:(NSUInteger)row column:(NSUInteger)column {
    self.internalBoardRepresentation[row][column] = player;
    [self checkForWinner];
}
-(void)checkForWinner {

    NSUInteger numberOfPiecesInARowToWin = MAX(self.rows, self.columns);

    //Check horizontal lines
    for(NSUInteger row = 0; row &lt; self.rows; row++) {

        PSPlayer *playerInFirstColumn = [self playerAtRow:row column:0];
        NSUInteger playerPiecesInRow = 0;

        for(NSUInteger column = 0; column &lt; self.columns; column++) {
            if([[self playerAtRow:row column:column] isEqualTo:playerInFirstColumn]) {
                playerPiecesInRow++;
            }
        }

        if(playerPiecesInRow &gt;= numberOfPiecesInARowToWin &amp;&amp; playerInFirstColumn.symbol != PSBoardSymbolNone) {
            self.winner = playerInFirstColumn;
            return;
        }
    }

    //Check vertical lines
    for(NSUInteger column = 0; column &lt; self.columns; column++) {

        PSPlayer *playerInFirstRow = [self playerAtRow:0 column:column];
        NSUInteger playerPiecesInColumn = 0;

        for(NSUInteger row = 0; row &lt; self.rows; row++) {
            if([[self playerAtRow:row column:column] isEqualTo:playerInFirstRow]) {
                playerPiecesInColumn++;
            }
        }

        if(playerPiecesInColumn &gt;= numberOfPiecesInARowToWin &amp;&amp; playerInFirstRow.symbol != PSBoardSymbolNone) {
            self.winner = playerInFirstRow;
            return;
        }
    }

    //Check top left to bottom right diagonal
    PSPlayer *playerInFirstSlotOfLeftDiagonal = [self playerAtRow:0 column:0];
    NSUInteger playerPiecesInLeftDiagonal = 0;

    for(NSUInteger row = 0, column = 0; row &lt; self.rows; column++, row++) {
        if([[self playerAtRow:row column:column] isEqualTo:playerInFirstSlotOfLeftDiagonal]) {
            playerPiecesInLeftDiagonal++;
        }
    }

    if(playerPiecesInLeftDiagonal &gt;= numberOfPiecesInARowToWin &amp;&amp; playerInFirstSlotOfLeftDiagonal.symbol != PSBoardSymbolNone) {
        self.winner = playerInFirstSlotOfLeftDiagonal;
        return;
    }

    //Check bottom left to top right diagonal
    PSPlayer *playerInFirstSlotOfRightDiagonal = [self playerAtRow:self.rows-1 column:0];
    NSUInteger playerPiecesInRightDiagonal = 0;

    for(NSInteger row = self.rows-1, column = 0; row &gt;= 0; row--, column++) {
        if([[self playerAtRow:row column:column] isEqualTo:playerInFirstSlotOfRightDiagonal]) {
            playerPiecesInRightDiagonal++;
        }
    }

    if(playerPiecesInRightDiagonal &gt;= numberOfPiecesInARowToWin &amp;&amp; playerInFirstSlotOfRightDiagonal.symbol != PSBoardSymbolNone) {
        self.winner = playerInFirstSlotOfRightDiagonal;
        return;
    }
}
-(void)display {

    NSMutableString *displayString = [NSMutableString stringWithFormat:@""\n""];

    for(NSUInteger row = 0; row &lt; self.rows; row++) {

        NSMutableString *rowDisplayString = [[NSMutableString alloc] init];
        NSString *innerFillerString = (row == self.rows-1) ? @"" "" : @""_"";

        for(NSUInteger column = 0; column &lt; self.columns; column++) {
            NSString *columnSeparator = (column == self.columns-1) ? @"" "" : @""|"";
            NSString *playerSymbol = ([self playerAtRow:row column:column].symbolStringRepresentation);

            if(playerSymbol.length == 0) {
                playerSymbol = innerFillerString;
            }

            [rowDisplayString appendString:[NSString stringWithFormat:@""%@%@%@%@"", innerFillerString, playerSymbol, innerFillerString, columnSeparator]];
        }

        [displayString appendString:[NSString stringWithFormat:@""%@\n"", rowDisplayString]];
        [rowDisplayString setString:@""""];
    }

    NSLog(@""%@"", displayString);
}
-(PSPlayer *)playerUp {

    PSPlayer *nextPlayerUp = self.players[1-([self.players indexOfObjectIdenticalTo:self.oldPlayerUp])];
    PSPlayer *previousPlayerUp = self.oldPlayerUp;
    self.oldPlayerUp = nextPlayerUp;
    return previousPlayerUp;
}

@end


PSPlayer.h

#import &lt;Foundation/Foundation.h&gt;

typedef NS_ENUM(NSInteger, PSBoardSymbol) {

    PSBoardSymbolX = 0,
    PSBoardSymbolO,
    PSBoardSymbolNone
};

@interface PSPlayer : NSObject

-(instancetype)initWithSymbol:(PSBoardSymbol)symbol name:(NSString *)name;

@property (nonatomic)  PSBoardSymbol    symbol;
@property (nonatomic)  NSString        *symbolStringRepresentation;
@property (nonatomic, strong) NSString *name;

@end


PSPlayer.m

#import ""PSPlayer.h""

@implementation PSPlayer

-(instancetype)initWithSymbol:(PSBoardSymbol)symbol name:(NSString *)name{

    if(self = [super init]) {

        self.symbol = symbol;
        self.symbolStringRepresentation = (symbol == PSBoardSymbolO) ? @""O"" : ((symbol == PSBoardSymbolX) ? @""X"" : @"""");
        self.name = name;
    }

    return self;
}

@end


PSInputHandler.h

#import &lt;Foundation/Foundation.h&gt;

@interface PSInputHandler : NSObject

+(NSString *)getString;
+(NSInteger)getInteger;

@end


PSInputHandler.m

#import ""PSInputHandler.h""

@implementation PSInputHandler

+(NSInteger)getInteger {
    int temp;
    scanf(""%i"", &amp;temp);
    return (NSInteger)temp;
}
+(NSString *)getString {
    char input[256];
    scanf(""%s"", input);
    return [NSString stringWithUTF8String:input];
}

@end


So my questions are:


In the PSInputHandler.m class, I wasn't so sure about how to get input from the command line. I read that fgets() is a potential alternative to scanf(), but is there any reason for me to use one over the other?
The method in PSBoard.m that checks for a winner, checkForWinner, is very long. Is there a simplified design I can use to shorten it?
I struggled to name the playerUp method, which returns the player whose turn it is. Is there a more suitable name?
When the user inputs which row and column to place an X or O in, I made it so that the coordinates they enter are from 1 to the number of rows and not 0 to the number of rows minus one (like with zero-based array indexing). Is this more user-friendly, or should I change it to zero-based indexing?
In PSPlayer.m, I use nested ternary operators. Is this too hard to understand? Should I change it to if statements?

When getting the user's input for how many rows and columns to use, which I expect to be an integer, how can I sanitize the input so that the program doesn't crash when a string (for example) is inputted?



Any other critique welcome!
","I will update this post over the weekend as I go through your question more and come up with some examples to iterate over my points, but I thought for now, I'd answer some of the easier questions.



Question 1.

I'm not sure and cannot remember (I will try to find out).  At the end of the day, you might consider implementing this with a GUI.  If you're using Xcode, it's quite easy to develop a GUI for either OSX or iOS, and most of your logic is already in place.  You'd just have to write the logic to hook the GUI up to the business logic.



Question 2.

One immediate thought on speeding up this process would be to use a flag to mark whether or not a row/column is a potential winner.  AND, if you do find a row that's a winner, immediately return the winner.

For a row to be a winner, every piece in the row must belong to the same player, correct?  So set the owner of the piece in the first box, and check every box.  As soon as you get to a box that doesn't match the first box, break;.  You don't need to check any more boxes in that row/column/diagonal.  You can move to the next row/column/diagonal.  And if you get to the end of the inner loop and haven't had to break; because you've found the winner, then you can set the winner and return; and stop checking.  

So basically, refactor into something more like this:

for(NSUInteger row = 0; row &lt; self.rows; row++) {

    PSPlayer *playerInFirstColumn = [self playerAtRow:row column:0];
    BOOL winnerFound;

    for(NSUInteger column = 0; column &lt; self.columns; column++) {
        if(![[self playerAtRow:row column:column] isEqualTo:playerInFirstColumn]) {
            winnerFound = false;
            break;
        } else {
            winnerFound = true;
        }
    }

    if (winnerFound) {
        self.winner = playerInFirstColumn;
        return;
    }
}


This will improve performance some.  You can probably still do better, but this is still a drastic improvement, especially for exceptionally large boards.

Now... the BEST performance improvement I can think of would actually mean you're running this check after every turn (which you're already doing, right?).  In this case, you only need to check ONE row, ONE column, and ZERO, ONE, or TWO diagonals.  And this would be a massive performance boost.  You only need to check a the row the piece was played in, the column the piece was played in, and the diagonal the piece was played in.  Every other row, column, and diagonal has been checked on a previous turn and a winner was not found otherwise the game would be over and we wouldn't've had this turn. 

AND, even if we modified the rules to continue playing after a winner has been found, you can just use an array to keep track of each row and column and diagonal and who won that row/column/diagonal, and still only need to check the relevant rows (and only check them for the player who played the piece).



Question 3.

playerUp is probably an alright method name.  Maybe activePlayer?  If you feel it's not descriptive enough, don't hesitate to leave a comment explaining it.  // returns the player whose turn it is



Question 4.

As a programmer, I am used to 0-based indexing systems, but your assumption is correct.  Most people who use programs aren't programs and would be more comfortable with a 1-based coordinate system.  Though... back to question 1... if this were given a GUI, it wouldn't matter.  ;)



Question 5.

Personally, I hate the ternary operators and never use them.  Whether or not they're acceptable would depend largely on who you're working with though.  In this case, it's a simple one.  Again, personally, I hate them and I wouldn't use it, because I never use it, but this one is simple enough that if you and everyone working on the project are comfortable with them, then go ahead and keep it.

Question 5.1.

The exact way you want to handle non-number input is an implementation detail that'd be up to you.  Do you want to request another input?  Do you want to just strip out the non-numbers and use the numbers that are there?

But as for actually checking the string itself, once you've got it into an NSString, it's quite easy:

NSCharacterSet *nonNumbers = [[NSCharacterSet 
    decimalDigitCharacterSet] invertedSet];

if([yourString rangeOfCharactersFromSet:nonNumbers].location == NSNotFound) {
    // string is all numbers and is good to go
} else {
    // string contains non-number characters
}

"
3919,3919,6249,Random Forest to estimate land use in past with Landsat,"I am new in Machine Learning and in R. I am working in my Master thesis. I am trying to estimate the LULC of the years 1984, 1990, 2000, 2011, 2014 for characterizing the forest dynamics. I have for each year the bands corresponding to Landsat imageries. The images were corrected and I have calculated vegetation index (NDVI, EVI, SR) and Tasseled Cap Components(Brightness, Greenness, Wetness). All this was performed using  i.landsat.toar, i.vi and i.tasscap commands in Grass 7, respectivelly. 

I have as reference the year 2009 since there is a orthophoto and LiDAR data. Using the orthophoto I digitized training polygons for 5 classes (1. Crops, artificial, bareland; 2. pinus forest; 3. Mixed forest; 4. Quercus and 5. Shrubs). 

I fitted a model using Random forest and my intention is to classify the other year datasets  wich have 5 reflective bands, 3 vegetation indexes and 3 tasseled Cap Components as predictor variables. 

The performance of the model is quite good, OOB 10.45% but within classes the Mixed forest achieved about 30 % of error. Thus, when I use the model to classify the other years the misclassification is very high. 

Am I doing anything worng? Is the Random forest useful for this purpose? Is there any software, method or algorithm that i could use to estimate the landuse?
",Juan Jose Mena,https://gis.stackexchange.com/users/52026,"I would look at the support of you individual classes. If support for a given class is marginal in your fit model, the error may propagate in very undesirable ways. 

I would also consider fitting a series of binary models and predicting probabilities of each class separately. You could then perform a sensitivity test on the probabilities and evaluate if there is multiple pixel membership (eg., pine forest transitioning into mixed). 

You may be having issues with trying to validate a hard-boundary classification where fuzziness exists in the class margins. A probabilistic approach may allow you to evaluate the changes in the ecological gradients.
",Jeffrey Evans,https://gis.stackexchange.com/users/8520,http://gis.stackexchange.com/questions/147076/random-forest-to-estimate-land-use-in-past-with-landsat,TECHNOLOGY,gis.stackexchange.com,0.8888888888888888,0.3333333333333333,0.3333333333333333,1.0,0.3333333333333333,1.0,0.5555555555555556,0.3333333333333333,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.6666666666666666,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.8888888888888888,Using Landsat to estimate the random forest of land use in the past,"I am new in Machine Learning and in R. I am working in my Master thesis. I am trying to estimate the LULC of the years 1984, 1990, 2000, 2011, 2014 for characterizing the forest dynamics. I have for each year the bands corresponding to Landsat imageries. The images were corrected and I have calculated vegetation index (NDVI, EVI, SR) and Tasseled Cap Components(Brightness, Greenness, Wetness). All this was performed using  i.landsat.toar, i.vi and i.tasscap commands in Grass 7, respectivelly. 

I have as reference the year 2009 since there is a orthophoto and LiDAR data. Using the orthophoto I digitized training polygons for 5 classes (1. Crops, artificial, bareland; 2. pinus forest; 3. Mixed forest; 4. Quercus and 5. Shrubs). 

I fitted a model using Random forest and my intention is to classify the other year datasets  wich have 5 reflective bands, 3 vegetation indexes and 3 tasseled Cap Components as predictor variables. 

The performance of the model is quite good, OOB 10.45% but within classes the Mixed forest achieved about 30 % of error. Thus, when I use the model to classify the other years the misclassification is very high. 

Am I doing anything worng? Is the Random forest useful for this purpose? Is there any software, method or algorithm that i could use to estimate the landuse?
","I would look at the support of you individual classes. If support for a given class is marginal in your fit model, the error may propagate in very undesirable ways. 

I would also consider fitting a series of binary models and predicting probabilities of each class separately. You could then perform a sensitivity test on the probabilities and evaluate if there is multiple pixel membership (eg., pine forest transitioning into mixed). 

You may be having issues with trying to validate a hard-boundary classification where fuzziness exists in the class margins. A probabilistic approach may allow you to evaluate the changes in the ecological gradients.
"
1878,1878,2981,Rate-limiting in transition state theory,"Suppose an initial state $A$ can transition to either state $C$ or state $D$. Suppose further that both of these two processes are rate-limited by a transition to the same intermediate state $B$, as follows:



Note that $\Delta G_{AB}&gt; \Delta G_{BC}&gt;\Delta G_{BD}$.

According to transition state theory, rates are determined by the rate-limiting step. So the rate of each process will be the same,

\begin{align}
r_{A\to C}&amp;=r_{A\to B} \\
r_{A\to D}&amp;=r_{A\to B}
\end{align}

from which it follows that the number of transitions made during some large $\Delta t$ will also be the same,

\begin{align}
N_{A\to C}&amp;=r_{A\to B}\Delta t \\
N_{A\to D}&amp;=r_{A\to B}\Delta t
\end{align}

However, if we were to consider the two pathways collectively then we would predict more transitions to be made to state $D$ than $B$ since $\Delta G_{BD}&lt;\Delta G_{BC}$.

How do we resolve this apparent discrepancy?
",lemon,https://chemistry.stackexchange.com/users/7265,"In transition state theory (TST, goldbook) one of the necessary assumptions is that reactants and products are in equilibrium. In principle this gives us
\begin{align}\ce{
A &amp;&lt;=&gt; [AB]^{\ddagger} -&gt; B\\
B &amp;&lt;=&gt; [AB]^{\ddagger} -&gt;A\\
A &amp;&lt;=&gt; B,
}\end{align}
and in addition to this, also
\begin{align}\ce{
B &amp;&lt;=&gt; [BC]^{\ddagger} -&gt; C &amp; B &amp;&lt;=&gt; [BD]^{\ddagger} -&gt; D\\
C &amp;&lt;=&gt; [BC]^{\ddagger} -&gt; B &amp; D &amp;&lt;=&gt; [BD]^{\ddagger} -&gt; B\\
B &amp;&lt;=&gt; C                    &amp; B &amp;&lt;=&gt; D,
}\end{align}
as well as
\begin{align}\ce{
C &lt;=&gt; [BC]^{\ddagger} -&gt; &amp; B &lt;=&gt; [BD]^{\ddagger} -&gt; D\\
D &lt;=&gt; [BD]^{\ddagger} -&gt; &amp; B &lt;=&gt; [BC]^{\ddagger} -&gt; C\\
C &lt;=&gt; &amp; B &lt;=&gt; D,
}\end{align}
and 
$$\ce{
C &lt;=&gt; A &lt;=&gt; D\\
[AB]^{\ddagger}&lt;=&gt; [BC]^{\ddagger}&lt;=&gt; [BD]^{\ddagger}
}.$$

You can use TST to estimate rate constants.
$$k = \frac{\mathcal{k}_\mathrm{B} T}{\mathrm{h}} \exp\left\{ −\frac{\Delta^\ddagger{}G^\circ}{\mathcal{R} T}\right\}$$

Since all components have to be in equilibrium, you can predict a ratio between them via Boltzmann statistics, hence:
$$\frac{N([BC]^{\ddagger})}{N([BD]^{\ddagger})} =  \exp\left\{ −\frac{\Delta^\ddagger{}G^\circ([BC]^{\ddagger})-\Delta^\ddagger{}G^\circ([BD]^{\ddagger})}{\mathcal{R} T}\right\}=\frac{N(C)}{N(D)} $$

The preceding equilibrium does not need to be considered to determine the ratio of the products. However, it is important to note, that there are many assumptions necessary for TST to work. For example, at higher temperatures, anharmonic corrections have to be considered. More crucial is the assumption, that the transition can be described as a translatory movement, i.e. it is treated with classical mechanics. 

For a system with a preceding equilibrium, it is well possible, that the TST approximation breaks down completely.
",Martin - マーチン,https://chemistry.stackexchange.com/users/4945,http://chemistry.stackexchange.com/questions/14815/rate-limiting-in-transition-state-theory,SCIENCE,chemistry.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,0.6666666666666666,1.0,1.0,0.6666666666666666,0.4444444444444444,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.3333333333333333,0.0,1.0,0.8333333333333334,0.8333333333333334,0.8333333333333334,1.0,0.8,0.0,0.3333333333333333,1.0,1.0,Rate limitation in transition state theory,"Suppose an initial state $A$ can transition to either state $C$ or state $D$. Suppose further that both of these two processes are rate-limited by a transition to the same intermediate state $B$, as follows:



Note that $\Delta G_{AB}&gt; \Delta G_{BC}&gt;\Delta G_{BD}$.

According to transition state theory, rates are determined by the rate-limiting step. So the rate of each process will be the same,

\begin{align}
r_{A\to C}&amp;=r_{A\to B} \\
r_{A\to D}&amp;=r_{A\to B}
\end{align}

from which it follows that the number of transitions made during some large $\Delta t$ will also be the same,

\begin{align}
N_{A\to C}&amp;=r_{A\to B}\Delta t \\
N_{A\to D}&amp;=r_{A\to B}\Delta t
\end{align}

However, if we were to consider the two pathways collectively then we would predict more transitions to be made to state $D$ than $B$ since $\Delta G_{BD}&lt;\Delta G_{BC}$.

How do we resolve this apparent discrepancy?
","In transition state theory (TST, goldbook) one of the necessary assumptions is that reactants and products are in equilibrium. In principle this gives us
\begin{align}\ce{
A &amp;&lt;=&gt; [AB]^{\ddagger} -&gt; B\\
B &amp;&lt;=&gt; [AB]^{\ddagger} -&gt;A\\
A &amp;&lt;=&gt; B,
}\end{align}
and in addition to this, also
\begin{align}\ce{
B &amp;&lt;=&gt; [BC]^{\ddagger} -&gt; C &amp; B &amp;&lt;=&gt; [BD]^{\ddagger} -&gt; D\\
C &amp;&lt;=&gt; [BC]^{\ddagger} -&gt; B &amp; D &amp;&lt;=&gt; [BD]^{\ddagger} -&gt; B\\
B &amp;&lt;=&gt; C                    &amp; B &amp;&lt;=&gt; D,
}\end{align}
as well as
\begin{align}\ce{
C &lt;=&gt; [BC]^{\ddagger} -&gt; &amp; B &lt;=&gt; [BD]^{\ddagger} -&gt; D\\
D &lt;=&gt; [BD]^{\ddagger} -&gt; &amp; B &lt;=&gt; [BC]^{\ddagger} -&gt; C\\
C &lt;=&gt; &amp; B &lt;=&gt; D,
}\end{align}
and 
$$\ce{
C &lt;=&gt; A &lt;=&gt; D\\
[AB]^{\ddagger}&lt;=&gt; [BC]^{\ddagger}&lt;=&gt; [BD]^{\ddagger}
}.$$

You can use TST to estimate rate constants.
$$k = \frac{\mathcal{k}_\mathrm{B} T}{\mathrm{h}} \exp\left\{ −\frac{\Delta^\ddagger{}G^\circ}{\mathcal{R} T}\right\}$$

Since all components have to be in equilibrium, you can predict a ratio between them via Boltzmann statistics, hence:
$$\frac{N([BC]^{\ddagger})}{N([BD]^{\ddagger})} =  \exp\left\{ −\frac{\Delta^\ddagger{}G^\circ([BC]^{\ddagger})-\Delta^\ddagger{}G^\circ([BD]^{\ddagger})}{\mathcal{R} T}\right\}=\frac{N(C)}{N(D)} $$

The preceding equilibrium does not need to be considered to determine the ratio of the products. However, it is important to note, that there are many assumptions necessary for TST to work. For example, at higher temperatures, anharmonic corrections have to be considered. More crucial is the assumption, that the transition can be described as a translatory movement, i.e. it is treated with classical mechanics. 

For a system with a preceding equilibrium, it is well possible, that the TST approximation breaks down completely.
"
4503,4503,7138,Reverse iteration from a given map iterator,"I want to find an element in the map using map::find(key), and then iterate the map in reverse order from the point where I found the element, till the beginning (i.e. until  map::rend()).

However, I get a compile error when I try to assign my iterator to a reverse_iterator.  How do I solve this?
",OverTheEdge,https://stackoverflow.com/users/120481,"Make the conversion explicit:

std::map&lt;int, int&gt; SomeMap;

for ( int i = 0; i &lt; 10; i++)
    SomeMap[ i ] = i;

std::map&lt;int, int&gt;::iterator it = SomeMap.find( 5 );
std::map&lt;int, int&gt;::reverse_iterator itr( it );

for ( itr; itr != SomeMap.rend( ); itr++ )
    std::cout &lt;&lt; itr-&gt;first &lt;&lt; std::endl;

",Björn Pollex,https://stackoverflow.com/users/160206,http://stackoverflow.com/questions/2310656/reverse-iteration-from-a-given-map-iterator,STACKOVERFLOW,stackoverflow.com,0.8888888888888888,0.4444444444444444,0.0,0.5,1.0,1.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,1.0,0.8888888888888888,0.5555555555555556,0.8888888888888888,1.0,0.8,0.6666666666666666,0.3333333333333333,0.0,0.8888888888888888,Reverse iteration from a given map iterator,"I want to use map:: find (key) to find an element in the map, and then iterate the map from the point where the element was found to the beginning (that is, until map:: rend()).","Make the conversion explicit:

std::map&lt;int, int&gt; SomeMap;

for ( int i = 0; i &lt; 10; i++)
    SomeMap[ i ] = i;

std::map&lt;int, int&gt;::iterator it = SomeMap.find( 5 );
std::map&lt;int, int&gt;::reverse_iterator itr( it );

for ( itr; itr != SomeMap.rend( ); itr++ )
    std::cout &lt;&lt; itr-&gt;first &lt;&lt; std::endl;

"
1439,1439,2266,What's the highest character level in Torchlight?,"I was googling quite a lot for this question, but I couldn't find an answer. But what is the highest reachable character level in Torchlight?
",RoflcoptrException,https://gaming.stackexchange.com/users/7232,"The highest level attainable without the use of mods, is: 100.

With the use of mods, you can reach level 999 (Link to the mod:LVL&amp;SkillMod)
",mordi2k,https://gaming.stackexchange.com/users/5521,http://gaming.stackexchange.com/questions/16931/whats-the-highest-character-level-in-torchlight,CULTURE,gaming.stackexchange.com,1.0,1.0,0.0,1.0,1.0,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.0,0.6666666666666666,1.0,What is the highest character level in the torchlight?,"I searched Google for a lot of information about this problem, but I couldn't find the answer. But what is the highest character level in the torchlight?","The highest level attainable without the use of mods, is: 100.

With the use of mods, you can reach level 999 (Link to the mod:LVL&amp;SkillMod)
"
525,525,827,Why do direct limits preserve exactness?,"I've heard that taking direct limits is an exact functor in the category of modules, and I'm trying to figure out why, as I couldn't find a proof.

Suppose you have homomorphisms $\varphi_i: K_i\to N_i$ and $\psi_i: N_i\to M_i$ for $(K_i,h^i_j)$, $(N_i,g^i_j)$, and $(M_i,f^i_j)$ directed systems of modules such that $0\to K_i\to N_i\to M_i\to 0$ is exact for every $i$. 


  Why is $0\to\varinjlim K_i\to\varinjlim N_i\to\varinjlim M_i\to 0$ also exact?




So I let $\varphi:\varinjlim K_i\to\varinjlim N_i$ and $\psi:\varinjlim N_i\to\varinjlim M_i$ be the natural homomorphisms. Take $x\in\ker\psi$. Then $x=g^i(x_i)$ for some $x_i\in N_i$. Then $0=\psi(g^i(x_i))=f^i(g^i(x_i))$. I know there exists some $j\geq i$ such that $f^i_j(g^i(x_i))=0$ in $M_j$. But $f^i_j\circ\psi_i=\psi_j\circ g^i_j$, so $g^i_j(x_i)\in\ker\psi_j=\text{im}(\varphi_j)$. Then $g^i_j(x_i)=\varphi_j(y_j)$ for some $y_j\in K_j$, so
$$
x=g^i(x_i)=g^j(g^i_j(x_i))=g^j(\varphi_j(y_j))=\varphi(h^j(y_j))
$$
and so $\ker\psi\subseteq\text{im}\varphi$. 

Conversely, suppose $x\in\text{im}\varphi$. Then $x=\varphi(y)$ for some $y=h^i(y_i)$ and $y_i\in K_i$. So $x=\varphi(h^i(y_i))=g^i(\varphi_i(y_i))$. Thus 
$$
\psi(x)=\psi(g^i(\varphi_i(y_i)))=f^i(\psi_i(\varphi_i(y_i)))=0
$$
since $\psi_i\circ\varphi=0$. Then $\ker\psi=\text{im}\varphi$. (Please let me know if I've written nonsense, too many maps can cause me to get lost!) 

What is bugging me is, is $\varphi$ injective and $\psi$ surjective to see that the short exact sequence is in fact exact? Is there some obvious fact I'm missing? If possible, is there an explanation in the same vein as the above (i.e. using the maps and manipulating the elements without relying on more general facts from category theory? I'm not too knowledgeable about the latter.) Thanks.
",Jacqueline Pauwels,https://math.stackexchange.com/users/24624,"It suffices to show that if $K_i\to M_i\to N_i$ is exact at $M_i$ for each $i$ (and the appropriate squares commute), then $\varinjlim K_i\to \varinjlim M_i\to \varinjlim N_i$ is exact at $\varinjlim M_i$. 

(To get that $\varinjlim$ sends short exact sequences to short exact sequences from this, simply apply the argument to $0\to K_i\to M_i$, exact at $K_i$; to $K_i\to M_i\to N_i$; and then to $M_i\to N_i\to 0$). 

Call the first map $f_i$ (with induced map of limits $f$), the second $g_i$ (with induced map $g$); use $\kappa$, $\mu$, and $\nu$ for the structure maps. 

Given $[(k,i)]$, we have $g(f([(k,i)])) = g([f_i(k),i]) = [g_i(f_i(k)),i] = [0,i]$, so the composition is trivial. That is, $\mathrm{Im}(f)\subseteq \mathrm{Ker}(g)$.

Now assume that $g([(m,i)]) = [(0,j)]$. Then there exists $t\geq i$ such that $\nu_{it}(g_i(m)) = 0$; hence $g_t(\mu_{it}(m)) = 0$, so by exactness of the original diagram we know that there exists $k\in K_t$ such that $f_t(k) = \mu_{it}(m)$. Therefore,
$$f([k,t]) = [(f(k),t)] = [(\mu_{it}(m),t)] = [(m,i)],$$ so $[(m,i)]$ lies in the image of $f$. Thus, $\mathrm{Im}(f)\supseteq \mathrm{Ker}(g)$, proving equality.

Now, this proves that $\varinjlim$ is exact; as to ""why"" it is exact (is there some deep why it is exact)? I don't know if I can answer.
",Arturo Magidin,https://math.stackexchange.com/users/742,http://math.stackexchange.com/questions/121122/why-do-direct-limits-preserve-exactness,SCIENCE,math.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,0.6666666666666666,1.0,1.0,0.4444444444444444,0.3333333333333333,0.6666666666666666,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,1.0,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,1.0,0.8888888888888888,0.8,0.3333333333333333,0.3333333333333333,1.0,0.7777777777777778,Why do direct limits maintain accuracy?,"I've heard that taking direct limits is an exact functor in the category of modules, and I'm trying to figure out why, as I couldn't find a proof.

Suppose you have homomorphisms $\varphi_i: K_i\to N_i$ and $\psi_i: N_i\to M_i$ for $(K_i,h^i_j)$, $(N_i,g^i_j)$, and $(M_i,f^i_j)$ directed systems of modules such that $0\to K_i\to N_i\to M_i\to 0$ is exact for every $i$. 


  Why is $0\to\varinjlim K_i\to\varinjlim N_i\to\varinjlim M_i\to 0$ also exact?




So I let $\varphi:\varinjlim K_i\to\varinjlim N_i$ and $\psi:\varinjlim N_i\to\varinjlim M_i$ be the natural homomorphisms. Take $x\in\ker\psi$. Then $x=g^i(x_i)$ for some $x_i\in N_i$. Then $0=\psi(g^i(x_i))=f^i(g^i(x_i))$. I know there exists some $j\geq i$ such that $f^i_j(g^i(x_i))=0$ in $M_j$. But $f^i_j\circ\psi_i=\psi_j\circ g^i_j$, so $g^i_j(x_i)\in\ker\psi_j=\text{im}(\varphi_j)$. Then $g^i_j(x_i)=\varphi_j(y_j)$ for some $y_j\in K_j$, so
$$
x=g^i(x_i)=g^j(g^i_j(x_i))=g^j(\varphi_j(y_j))=\varphi(h^j(y_j))
$$
and so $\ker\psi\subseteq\text{im}\varphi$. 

Conversely, suppose $x\in\text{im}\varphi$. Then $x=\varphi(y)$ for some $y=h^i(y_i)$ and $y_i\in K_i$. So $x=\varphi(h^i(y_i))=g^i(\varphi_i(y_i))$. Thus 
$$
\psi(x)=\psi(g^i(\varphi_i(y_i)))=f^i(\psi_i(\varphi_i(y_i)))=0
$$
since $\psi_i\circ\varphi=0$. Then $\ker\psi=\text{im}\varphi$. (Please let me know if I've written nonsense, too many maps can cause me to get lost!) 

What is bugging me is, is $\varphi$ injective and $\psi$ surjective to see that the short exact sequence is in fact exact? Is there some obvious fact I'm missing? If possible, is there an explanation in the same vein as the above (i.e. using the maps and manipulating the elements without relying on more general facts from category theory? I'm not too knowledgeable about the latter.) Thanks.
","It suffices to show that if $K_i\to M_i\to N_i$ is exact at $M_i$ for each $i$ (and the appropriate squares commute), then $\varinjlim K_i\to \varinjlim M_i\to \varinjlim N_i$ is exact at $\varinjlim M_i$. 

(To get that $\varinjlim$ sends short exact sequences to short exact sequences from this, simply apply the argument to $0\to K_i\to M_i$, exact at $K_i$; to $K_i\to M_i\to N_i$; and then to $M_i\to N_i\to 0$). 

Call the first map $f_i$ (with induced map of limits $f$), the second $g_i$ (with induced map $g$); use $\kappa$, $\mu$, and $\nu$ for the structure maps. 

Given $[(k,i)]$, we have $g(f([(k,i)])) = g([f_i(k),i]) = [g_i(f_i(k)),i] = [0,i]$, so the composition is trivial. That is, $\mathrm{Im}(f)\subseteq \mathrm{Ker}(g)$.

Now assume that $g([(m,i)]) = [(0,j)]$. Then there exists $t\geq i$ such that $\nu_{it}(g_i(m)) = 0$; hence $g_t(\mu_{it}(m)) = 0$, so by exactness of the original diagram we know that there exists $k\in K_t$ such that $f_t(k) = \mu_{it}(m)$. Therefore,
$$f([k,t]) = [(f(k),t)] = [(\mu_{it}(m),t)] = [(m,i)],$$ so $[(m,i)]$ lies in the image of $f$. Thus, $\mathrm{Im}(f)\supseteq \mathrm{Ker}(g)$, proving equality.

Now, this proves that $\varinjlim$ is exact; as to ""why"" it is exact (is there some deep why it is exact)? I don't know if I can answer.
"
2941,2941,4682,How can toddlers expend seemingly boundless energy when they eat so little?,"A toddler's food intake seems very little: only milk and water and some solid food. Therefore, from where does this energy come?
",Jack,https://biology.stackexchange.com/users/6589,"Just to add to the answer from @buzrw:

Using data from here and here I have estimated recommended calorie intake per kg for a 2 yr old and for an adult. I've used figures for males and assumed 70 kg for the adult weight which is the ""international standard man"":


  toddler: 120 Cal kg-1
  
  adult: 40 Cal kg-1


So yes, the energy intake of toddlers is higher than that of an adult.
",Alan Boyd,https://biology.stackexchange.com/users/1320,http://biology.stackexchange.com/questions/17117/how-can-toddlers-expend-seemingly-boundless-energy-when-they-eat-so-little,SCIENCE,biology.stackexchange.com,1.0,1.0,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.8888888888888888,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.8888888888888888,0.5555555555555556,0.8888888888888888,1.0,0.8,0.0,0.0,1.0,0.8888888888888888,"Children eat so little, how can you consume seemingly endless energy?","Children's food intake seems to be small: only milk, water and some solid food. So where does this energy come from?","Just to add to the answer from @buzrw:

Using data from here and here I have estimated recommended calorie intake per kg for a 2 yr old and for an adult. I've used figures for males and assumed 70 kg for the adult weight which is the ""international standard man"":


  toddler: 120 Cal kg-1
  
  adult: 40 Cal kg-1


So yes, the energy intake of toddlers is higher than that of an adult.
"
329,329,528,What are the best tips for saving money as a university student?,"What are the best tips for saving money as a university student?

I will be attending university this coming semester and am planning on maintaining a sustainable financial situation right now, but would like any good tips or suggestions to saving money as a student.
",JFW,https://money.stackexchange.com/users/1408,"Spend less.  

As @jldugger said, shop around for textbooks.  Make sure to look for used books: you can sometimes save a lot of money there.

Be smart about food money.  I could go to our on-campus grill and get a sandwich and a salad for lunch.  If I packed both with toppings, the salad could be a 2nd meal for the same day.  If you have the option, get a meal plan that is just 1 meal a day, and eat a lot that meal.

Don't do the starbucks ""pay several dollars for a coffee each day"" thing.  Small-ish regular expenses add up quickly.  

Quit smoking (if applicable).

Ditch your car if possible.  Some colleges are in cities with good public transportation or are small enough that a bike will do.  Cars are very expensive. 

Try to find free activities to do in your free time.  Usually college towns are great places to find free fun.  Pick-up sports, student concerts/art shows, playing board/card/video games.

Make sure to track how you're spending money to look for areas where you could be spending less.  There are plenty of tools available to help with this.  

Some on-campus jobs involve sitting around and occasionally doing something: IE working the checkout desk at the library.  A job like this (if you can find one) can effectively pay you for doing our homework.

One other very important college-related financial tip is to not take out more loans than you can afford.  I've heard a good rule of thumb is not take our more loans than you expect to earn your first year after graduating.  Look up average starting salaries for the career you realistically expect to have after you graduate.  If you would need to borrow much more than that to get your degree, rethink your plans.  Being a slave to a bank for years is a crappy way to spend your life.
",David Oneill,https://money.stackexchange.com/users/2640,http://money.stackexchange.com/questions/6455/what-are-the-best-tips-for-saving-money-as-a-university-student,LIFE_ARTS,money.stackexchange.com,1.0,1.0,0.6666666666666666,0.0,0.0,0.0,0.7777777777777778,0.6666666666666666,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8888888888888888,1.0,0.8888888888888888,1.0,1.0,0.8666666666666666,0.0,0.0,0.0,0.7777777777777778,"As a college student, what is the best way to save money?","What are the best tips for saving money as a university student?

I will be attending university this coming semester and am planning on maintaining a sustainable financial situation right now, but would like any good tips or suggestions to saving money as a student.
","Spend less.  

As @jldugger said, shop around for textbooks.  Make sure to look for used books: you can sometimes save a lot of money there.

Be smart about food money.  I could go to our on-campus grill and get a sandwich and a salad for lunch.  If I packed both with toppings, the salad could be a 2nd meal for the same day.  If you have the option, get a meal plan that is just 1 meal a day, and eat a lot that meal.

Don't do the starbucks ""pay several dollars for a coffee each day"" thing.  Small-ish regular expenses add up quickly.  

Quit smoking (if applicable).

Ditch your car if possible.  Some colleges are in cities with good public transportation or are small enough that a bike will do.  Cars are very expensive. 

Try to find free activities to do in your free time.  Usually college towns are great places to find free fun.  Pick-up sports, student concerts/art shows, playing board/card/video games.

Make sure to track how you're spending money to look for areas where you could be spending less.  There are plenty of tools available to help with this.  

Some on-campus jobs involve sitting around and occasionally doing something: IE working the checkout desk at the library.  A job like this (if you can find one) can effectively pay you for doing our homework.

One other very important college-related financial tip is to not take out more loans than you can afford.  I've heard a good rule of thumb is not take our more loans than you expect to earn your first year after graduating.  Look up average starting salaries for the career you realistically expect to have after you graduate.  If you would need to borrow much more than that to get your degree, rethink your plans.  Being a slave to a bank for years is a crappy way to spend your life.
"
3762,3762,5989,What is the best introductory Bayesian statistics textbook?,"Which is the best introductory textbook for Bayesian statistics?

One book per answer, please.
",Shane,https://stats.stackexchange.com/users/5,"If I had to choose a single text for a beginner, it would be 

              Sivia DS and Skilling J (2006) book (see below). 


Of all the books listed below it strives hardest to give an intuitive grasp of the essential ideas, but it still requires some mathematical sophistication from page 1.

Below is a list of Further Readings from my book, with comments on each publication.

Bernardo, JM and Smith, A, (2000) 4 . Bayesian Theory A rigorous account of Bayesin methods, with many real-world examples. 

Bishop, C (2006) 5 . Pattern Recognition and Machine Learning. As the title suggests, this is mainly about machine learning, but it provides a lucid and comprehensive account of Bayesian methods. 

Cowan G (1998) 6 . Statistical Data Analysis. An excellent non-Bayesian introduction to statistical analysis. 

Dienes, Z (2008) 8 . Understanding Psychology as a Science: An Introduction to Scientiﬁc and Statistical Inference. Provides tutorial material on Bayes’ rule and a lucid analysis of the 
distinction between Bayesian and frequentist statistics. 

Gelman A, Carlin J, Stern H, and Rubin D. (2003) 14 . Bayesian Data Analysis. A rigorous and comprehensive account of Bayesian analysis, with many real-world examples. 

Jaynes E and Bretthorst G (2003) 18 . Probability Theory: The Logic of Science. The modern classic of Bayesian analysis. It is comprehensive and wise. Its discursive style makes it long (600 pages) but never dull,and it is packed ful l of insights. 

Khan, S, 2012, Introduction to Bayes’ Theorem. Salman Khan’s online mathematics videos make a good introduction to various topics, including Bayes’ rule. 

Lee PM (2004) 27 . Bayesian Statistics: An Introduction. A rigorous and comprehensive text with a strident Bayesian style. 

MacKay DJC (2003) 28 . Information theory, inference, and learning algorithms. The modern classic on information theory. A very readable text that roams far and wide over many topics, almost all of which make use of Bayes’ rule. 

Migon, HS and Gamerman, D (1999) 30. Statistical Inference: An Integrated Approach. A straightforward (and clearly laid out) account of inference, which compares Bayesian and non-Bayesian approaches. Despite being fairly advanced, the writing style is tutorial in nature. 

Pierce JR (1980) 34 2nd Edition. An introduction to information theory: symbols, signals and noise. Pierce writes with an informal, tutorial  style of writing, but does not ﬂinch from presenting the fundamental theorems of information theory. 

Reza, FM (1961) 35 . An introduction to information theory. A more comprehensive and mathematical ly rigorous book than the Pierce book above, and should ideally be read only after ﬁrst reading Pierce’s more informal text. 

Sivia DS and Skilling J (2006) 38 . Data Analysis: A Bayesian Tutorial. This is an excellent tutorial style introduction to Bayesian methods. 

Spiegelhalter, D and Rice, K (2009) 36 . Bayesian statistics. Scholarpedia, 4(8):5230. 
http://www.scholarpedia.org/article/Bayesian_statistics 
A reliable and comprehensive summary of the current status of Bayesian 
statistics. 

And, here is my book, published June 2013.

Bayes' Rule: A Tutorial Introduction to Bayesian Analysis,
Dr James V Stone, ISBN 978-0956372840

Chapter 1 can be downloaded from: 
http://jim-stone.staff.shef.ac.uk/BookBayes2012/BayesRuleBookMain.html

Description:
Discovered by an 18th century mathematician and preacher, Bayes' rule is a cornerstone of modern probability theory. In this richly illustrated book, a range of accessible examples are used to show how Bayes' rule is actually a natural consequence of commonsense reasoning. Bayes' rule is derived using intuitive graphical representations of probability, and Bayesian analysis is applied to parameter estimation using the MatLab programs provided. The tutorial style of writing, combined with a comprehensive glossary, makes this an ideal primer for the novice who wishes to become familiar with the basic principles of Bayesian analysis.
",Jim Stone,https://stats.stackexchange.com/users/26779,http://stats.stackexchange.com/questions/125/what-is-the-best-introductory-bayesian-statistics-textbook,SCIENCE,stats.stackexchange.com,1.0,1.0,1.0,1.0,0.0,0.3333333333333333,0.6666666666666666,0.5555555555555556,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.6666666666666666,0.0,1.0,1.0,1.0,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,1.0,What is the best introduction to Bayesian statistics?,Which is the best introduction to Bayesian statistics?,"If I had to choose a single text for a beginner, it would be 

              Sivia DS and Skilling J (2006) book (see below). 


Of all the books listed below it strives hardest to give an intuitive grasp of the essential ideas, but it still requires some mathematical sophistication from page 1.

Below is a list of Further Readings from my book, with comments on each publication.

Bernardo, JM and Smith, A, (2000) 4 . Bayesian Theory A rigorous account of Bayesin methods, with many real-world examples. 

Bishop, C (2006) 5 . Pattern Recognition and Machine Learning. As the title suggests, this is mainly about machine learning, but it provides a lucid and comprehensive account of Bayesian methods. 

Cowan G (1998) 6 . Statistical Data Analysis. An excellent non-Bayesian introduction to statistical analysis. 

Dienes, Z (2008) 8 . Understanding Psychology as a Science: An Introduction to Scientiﬁc and Statistical Inference. Provides tutorial material on Bayes’ rule and a lucid analysis of the 
distinction between Bayesian and frequentist statistics. 

Gelman A, Carlin J, Stern H, and Rubin D. (2003) 14 . Bayesian Data Analysis. A rigorous and comprehensive account of Bayesian analysis, with many real-world examples. 

Jaynes E and Bretthorst G (2003) 18 . Probability Theory: The Logic of Science. The modern classic of Bayesian analysis. It is comprehensive and wise. Its discursive style makes it long (600 pages) but never dull,and it is packed ful l of insights. 

Khan, S, 2012, Introduction to Bayes’ Theorem. Salman Khan’s online mathematics videos make a good introduction to various topics, including Bayes’ rule. 

Lee PM (2004) 27 . Bayesian Statistics: An Introduction. A rigorous and comprehensive text with a strident Bayesian style. 

MacKay DJC (2003) 28 . Information theory, inference, and learning algorithms. The modern classic on information theory. A very readable text that roams far and wide over many topics, almost all of which make use of Bayes’ rule. 

Migon, HS and Gamerman, D (1999) 30. Statistical Inference: An Integrated Approach. A straightforward (and clearly laid out) account of inference, which compares Bayesian and non-Bayesian approaches. Despite being fairly advanced, the writing style is tutorial in nature. 

Pierce JR (1980) 34 2nd Edition. An introduction to information theory: symbols, signals and noise. Pierce writes with an informal, tutorial  style of writing, but does not ﬂinch from presenting the fundamental theorems of information theory. 

Reza, FM (1961) 35 . An introduction to information theory. A more comprehensive and mathematical ly rigorous book than the Pierce book above, and should ideally be read only after ﬁrst reading Pierce’s more informal text. 

Sivia DS and Skilling J (2006) 38 . Data Analysis: A Bayesian Tutorial. This is an excellent tutorial style introduction to Bayesian methods. 

Spiegelhalter, D and Rice, K (2009) 36 . Bayesian statistics. Scholarpedia, 4(8):5230. 
http://www.scholarpedia.org/article/Bayesian_statistics 
A reliable and comprehensive summary of the current status of Bayesian 
statistics. 

And, here is my book, published June 2013.

Bayes' Rule: A Tutorial Introduction to Bayesian Analysis,
Dr James V Stone, ISBN 978-0956372840

Chapter 1 can be downloaded from: 
http://jim-stone.staff.shef.ac.uk/BookBayes2012/BayesRuleBookMain.html

Description:
Discovered by an 18th century mathematician and preacher, Bayes' rule is a cornerstone of modern probability theory. In this richly illustrated book, a range of accessible examples are used to show how Bayes' rule is actually a natural consequence of commonsense reasoning. Bayes' rule is derived using intuitive graphical representations of probability, and Bayesian analysis is applied to parameter estimation using the MatLab programs provided. The tutorial style of writing, combined with a comprehensive glossary, makes this an ideal primer for the novice who wishes to become familiar with the basic principles of Bayesian analysis.
"
229,229,366,What is the best introductory Bayesian statistics textbook?,"Which is the best introductory textbook for Bayesian statistics?

One book per answer, please.
",Shane,https://stats.stackexchange.com/users/5,"""Bayesian Core: A Practical Approach to Computational Bayesian Statistics"" by Marin and Robert, Springer-Verlag (2007)
",gappy,https://stats.stackexchange.com/users/30,http://stats.stackexchange.com/questions/125/what-is-the-best-introductory-bayesian-statistics-textbook,SCIENCE,stats.stackexchange.com,1.0,1.0,0.0,1.0,0.0,0.0,0.7777777777777778,0.5555555555555556,0.0,0.0,1.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,1.0,0.7777777777777778,0.6666666666666666,1.0,1.0,0.9333333333333332,0.0,0.0,0.0,1.0,What is the best introduction to Bayesian statistics?,Which is the best introduction to Bayesian statistics?,"""Bayesian core: a practical method to calculate Bayesian statistics"", Marin and Robert, Springer Verlag (2007)"
3354,3354,5351,What happens if a player exiles Wurmcoil Engine when it dies with Mimic Vat?,"My guess is that the player who controlled Wurmcoil Engine doesn't get the tokens because Mimic Vat's exile resolves first and the creature doesn't land in the graveyard. Am I correct?
",Adam Arold,https://boardgames.stackexchange.com/users/1735,"If and when a Wurmcoil Engine dies and goes to the graveyard, its ability will trigger and go on the stack. If it was a non-token creature at the time it died, Mimics Vat will also trigger at the same time and go on the stack. The active player decides the order in which they are put on the stack, but either way, both effects will resolve unless countered. Meaning: for a non-token Wurmcoil Engine, 2 tokens will be created and it can be exiled with the Vat.

A Wurmcoil Engine (or a token copy thereof) that gets exiled neither gives tokens nor triggers the Vat. However, if you have a way to destroy or sacc a Wurmcoil Engine token before it is exiled, the token Engine will also create its 2 smaller tokens, though still not trigger the Vat.
",Hackworth,https://boardgames.stackexchange.com/users/1718,http://boardgames.stackexchange.com/questions/5133/what-happens-if-a-player-exiles-wurmcoil-engine-when-it-dies-with-mimic-vat,CULTURE,boardgames.stackexchange.com,1.0,0.6666666666666666,0.0,1.0,1.0,1.0,0.5,0.5,0.0,0.0,1.0,1.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,0.5,1.0,What happens if players banish the wurmclink engine after mic VAT's death?,"I suspect that players who control the wurmlink engine will not be able to get the token, because the simulated VAT banishment solved the problem first, and the creature did not land in the graveyard. am I correct?","If and when a Wurmcoil Engine dies and goes to the graveyard, its ability will trigger and go on the stack. If it was a non-token creature at the time it died, Mimics Vat will also trigger at the same time and go on the stack. The active player decides the order in which they are put on the stack, but either way, both effects will resolve unless countered. Meaning: for a non-token Wurmcoil Engine, 2 tokens will be created and it can be exiled with the Vat.

A Wurmcoil Engine (or a token copy thereof) that gets exiled neither gives tokens nor triggers the Vat. However, if you have a way to destroy or sacc a Wurmcoil Engine token before it is exiled, the token Engine will also create its 2 smaller tokens, though still not trigger the Vat.
"
5009,5009,7976,How to edit error messages in devise,"I need to modify the error messages of devise. I want to change the message ""is Invalid"" to ""Es inválido"" . The problem is that I have to go to change these messages in the gem. Can I overwrite these messages in the model User

Rails console

1.9.3-p547 :014 &gt; user.save
 =&gt; false 
1.9.3-p547 :015 &gt; user.errors
 =&gt; {:email=&gt;[""is invalid""], :password=&gt;[""is too short (minimum is 6 characters)""]} 
1.9.3-p547 :016 &gt; 


User model

class User &lt; ActiveRecord::Base
  # Include default devise modules. Others available are:
  # :token_authenticatable, :confirmable, :lockable and :timeoutable
  devise :database_authenticatable, :registerable,
         :recoverable, :rememberable, :trackable, :validatable

  # Setup accessible (or protected) attributes for your model
  attr_accessible :email, :password, :password_confirmation, :remember_me
end

",juan perez,https://stackoverflow.com/users/3602688,"You can do the devise specific translations using the 
devise.es.yml in your config/locales folder

List of all the different translations is given here in official devise wiki
",uday,https://stackoverflow.com/users/981616,http://stackoverflow.com/questions/29787884/how-to-edit-error-messages-in-devise,STACKOVERFLOW,stackoverflow.com,1.0,1.0,0.0,1.0,1.0,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.8,0.6666666666666666,0.0,0.0,1.0,How to edit error messages in design,"I need to modify the error messages of devise. I want to change the message ""is Invalid"" to ""Es inválido"" . The problem is that I have to go to change these messages in the gem. Can I overwrite these messages in the model User

Rails console

1.9.3-p547 :014 &gt; user.save
 =&gt; false 
1.9.3-p547 :015 &gt; user.errors
 =&gt; {:email=&gt;[""is invalid""], :password=&gt;[""is too short (minimum is 6 characters)""]} 
1.9.3-p547 :016 &gt; 


User model

class User &lt; ActiveRecord::Base
  # Include default devise modules. Others available are:
  # :token_authenticatable, :confirmable, :lockable and :timeoutable
  devise :database_authenticatable, :registerable,
         :recoverable, :rememberable, :trackable, :validatable

  # Setup accessible (or protected) attributes for your model
  attr_accessible :email, :password, :password_confirmation, :remember_me
end

","You can do the devise specific translations using the 
devise.es.yml in your config/locales folder

List of all the different translations is given here in official devise wiki
"
3825,3825,6084,C compiler supported by Windows 7,"I'm having a problem finding which compiler can support Windows7 for C or C++ programming.
I had installed Turbo but it does not work in full screen on Windows 7.
Please let me know which compiler will be appropriate.
",shruti bansal,https://superuser.com/users/52642,"GCC from either MinGW or Cygwin should work fine under Windows 7.
",Ignacio Vazquez-Abrams,https://superuser.com/users/26316,http://superuser.com/questions/200435,TECHNOLOGY,superuser.com,0.6666666666666666,0.3333333333333333,0.0,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,1.0,0.6666666666666666,1.0,1.0,0.8,0.0,0.0,0.0,0.6666666666666666,C compiler supported by Windows 7,"I'm having a problem finding which compiler can support Windows7 for C or C++ programming.
I had installed Turbo but it does not work in full screen on Windows 7.
Please let me know which compiler will be appropriate.
","GCC from either MinGW or Cygwin should work fine under Windows 7.
"
4682,4682,7421,How to change all the blue colors of RWD theme to another color?,"How to change all the blue colors of RWD theme to another color?Actually this question may be duplicate but please help me none of the methods worked for me in Google or in MSE.
",dhoni7,https://magento.stackexchange.com/users/16373,"I don't care if this is the worst answer ever written here. It is beyond preposterous that to edit something as simple as a background color, not only do you have to install ruby, and install compass, just to edit one line of a SASS file? I guess editing the precious little .scss file in Textwrangler and replacing it in the proper folder just can't work can it? We have to RECOMPILE?!? Thanks EBAY also, for bringing this on board.
",Mal Quat,https://magento.stackexchange.com/users/28551,http://magento.stackexchange.com/questions/44440/how-to-change-all-the-blue-colors-of-rwd-theme-to-another-color,TECHNOLOGY,magento.stackexchange.com,0.3333333333333333,1.0,0.0,0.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.5,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.8,0.0,0.0,0.0,0.6666666666666666,How do I change all the blue of RWD themes to another color?,"How do I change all the blue of RWD themes to another color? In fact, this problem may be repetitive, but please help me no way to work for me in Google or small and medium enterprises.","I don't care if this is the worst answer ever written here. To edit something as simple as background color, you need not only install ruby, but also compass. You only need to edit one line of SASS file, which is ridiculous? I don't think it's going to work in textwrangler to edit the precious little. SCSS file and replace it in the right folder, is it? We have to recompile? !? And thanks to eBay for bringing this online."
2146,2146,3418,Good backup options for Mac pre-TimeMachine,"I have a friend with an iBook G4 who is looking for a cheap backup option for her Mac running OS 10.4.  Money is tight, so getting 10.5 is not really an option (in addition to buy a backup drive etc, yes money is really that tight).

What suggestions can you offer for backups that's better than trying to remember to burn a CD once a month?
",acrosman,https://superuser.com/users/8908,"For free incremental backup on a Mac - or almost any *nix box for that matter - rsync is hard to beat. It should already be installed, and at its simplest will do an incremental copy - set up Launchd or cron to run it automatically at a convenient interval and it'll copy only what has changed over to the backup disk (or a remote machine over the network for that matter).

With a bit of prodding it can even be set up to emulate Time Machine pretty closely, with the exception of the fancy restore interface.
",Scott,https://superuser.com/users/44268,http://superuser.com/questions/176211,TECHNOLOGY,superuser.com,0.7777777777777778,0.5555555555555556,0.3333333333333333,1.0,0.3333333333333333,0.0,0.6666666666666666,0.4444444444444444,0.0,0.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,1.0,0.6666666666666666,0.0,0.0,0.8888888888888888,Good backup options for Mac pre timemachine,"I have a friend with an ibookg4 who is looking for a cheap backup option for a Mac running OS 10.4. Money is tight, so getting 10.5 is not a real choice (except for buying a backup drive, etc., yes, money is really tight).","For free incremental backup on a Mac - or almost any *nix box for that matter - rsync is hard to beat. It should already be installed, and at its simplest will do an incremental copy - set up Launchd or cron to run it automatically at a convenient interval and it'll copy only what has changed over to the backup disk (or a remote machine over the network for that matter).

With a bit of prodding it can even be set up to emulate Time Machine pretty closely, with the exception of the fancy restore interface.
"
3636,3636,5804,"Relationship between user story, feature, and epic?","As someone whose still new to agile, I'm not sure I completely understand the relationship or difference between a user story, feature, and epic.

According to this question, a feature is a collection of stories.  One of the answers suggest that a feature is actually an epic.  

So are features and epics considered the same thing, which is basically a collection of related user stories?

Our project manager insists that there's a hierarchical structure:

Epic -> Features -> User stories

... basically all user stories must fall within this structure.  Therefore all user stories must fall under an umbrella feature and all features must fall under an epic.

To me, that sounds awkward.  Can someone please clarify how user stories, features, and epics are related?  Or is there an article that clearly outlines the differences?
",nivlam,https://programmers.stackexchange.com/users/45,"I agree like many responses that there are really no right answers since these are just terms which can be varied depending on which Agile camp you are based on and you can definitely make up your own camp as long as everyone in your team including the external stakeholders understand what they mean. It is just a way of organizing your requirement.

The answer I like is from Mike Cohn's camp and it is fairly simple.

http://www.mountaingoatsoftware.com/blog/stories-epics-and-themes


Epic is just a big Story (hierarchical)
Theme is just a group of Stories (pretty much like tag)


He actually avoids the term ""Feature"". I assume that it is mainly because it was a common term in the traditional waterfall world. Many Agile camp tends to use different terms to emphasize the differences.

So in your PM's definition, Feature is somewhere in the middle of the Epic-Story hierarchy.

Here is my info-graphic of this definition from my InfoQ article http://www.infoq.com/articles/visualize-big-picture-agile ;-)


",Kulawat The Eidos,https://programmers.stackexchange.com/users/78431,http://programmers.stackexchange.com/questions/182158/relationship-between-user-story-feature-and-epic,TECHNOLOGY,programmers.stackexchange.com,0.7777777777777778,0.6666666666666666,0.0,0.6666666666666666,1.0,1.0,0.5555555555555556,0.6666666666666666,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.8888888888888888,1.0,0.7777777777777778,1.0,1.0,0.9333333333333332,0.0,0.0,1.0,1.0,"What is the relationship between user stories, features, and epics?","As someone whose still new to agile, I'm not sure I completely understand the relationship or difference between a user story, feature, and epic.

According to this question, a feature is a collection of stories.  One of the answers suggest that a feature is actually an epic.  

So are features and epics considered the same thing, which is basically a collection of related user stories?

Our project manager insists that there's a hierarchical structure:

Epic -> Features -> User stories

... basically all user stories must fall within this structure.  Therefore all user stories must fall under an umbrella feature and all features must fall under an epic.

To me, that sounds awkward.  Can someone please clarify how user stories, features, and epics are related?  Or is there an article that clearly outlines the differences?
","I agree like many responses that there are really no right answers since these are just terms which can be varied depending on which Agile camp you are based on and you can definitely make up your own camp as long as everyone in your team including the external stakeholders understand what they mean. It is just a way of organizing your requirement.

The answer I like is from Mike Cohn's camp and it is fairly simple.

http://www.mountaingoatsoftware.com/blog/stories-epics-and-themes


Epic is just a big Story (hierarchical)
Theme is just a group of Stories (pretty much like tag)


He actually avoids the term ""Feature"". I assume that it is mainly because it was a common term in the traditional waterfall world. Many Agile camp tends to use different terms to emphasize the differences.

So in your PM's definition, Feature is somewhere in the middle of the Epic-Story hierarchy.

Here is my info-graphic of this definition from my InfoQ article http://www.infoq.com/articles/visualize-big-picture-agile ;-)


"
3801,3801,6041,What is the best introductory Bayesian statistics textbook?,"Which is the best introductory textbook for Bayesian statistics?

One book per answer, please.
",Shane,https://stats.stackexchange.com/users/5,"Take a look at ""The Bayesian Choice"". It has the full package: foundations, applications and computation. Clearly written.
",Zen,https://stats.stackexchange.com/users/9394,http://stats.stackexchange.com/questions/125/what-is-the-best-introductory-bayesian-statistics-textbook,SCIENCE,stats.stackexchange.com,0.7777777777777778,1.0,0.6666666666666666,1.0,0.0,0.0,0.6666666666666666,0.6666666666666666,0.0,0.0,1.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,0.0,1.0,What is the best introduction to Bayesian statistics?,Which is the best introduction to Bayesian statistics?,"Take a look at ""The Bayesian Choice"". It has the full package: foundations, applications and computation. Clearly written.
"
4837,4837,7695,Indexing encrypted data for efficient searching,"I have implemented encryption for certain columns in a database. In some cases it may be necessary to search by these columns, either for exact matches or for substrings. At the moment, there is less than 10000 rows to search through (at most). However this will probably change in the future so I am anticipating efficency problems. 

The data will remain encrypted in the database, but when retrieved by the application, it can then be decrypted. This means that the retrieval does not have to be 100% accurate, it can retrieve more records than actually match the query, and the application itself can discard the non-matching records. 

With this in mind I came up with the following solutions:


For exact text match, hash the encrypted data and modulo this with a relatively low number (2^16 perhaps), and store that value in an additional column. When querying the database, it is only necessary to perform the same operation on the input string, and retrieve all records with matching hash value.
For finding substrings, hash each letter and mod 32 the result. Then set the corresponding bit in an integer. Perform the same operation on the query string. Thus it is only necessary to retrieve records where the result of a binary AND on the query with the stored value is greater than 0. This could also be done using each pair of letters, perhaps with a 64-bit or longer integer to allow for more records to be discarded.


My question is, would either of these techniques have a real impact on the security of the data in the encrypted columns? The encryption scheme is AES-256.
",Slicedpan,https://security.stackexchange.com/users/28559,"Ability to narrow searches tends to be in direct opposition with the confidentiality that you seek through encryption. For instance, if you store your ""16-bit hash"" in an extra column then that hash reveals 16 bits of the data -- 16 indirect bits, but 16 bits nonetheless. An attacker who sees the database may try to guess (brute force) the record contents, and the 16 bits will allow him to detect 65535/65536th of bad guesses: this is a substantial advantage.

Ability to do substring searches is even worse, since it necessarily reveals information that allows the brute force attack to proceed in gradual steps (this is in fact the same problem as partial password authentication).

At best, what you could do is to implement deterministic encryption, such that encryption of a given record value always yields the same encrypted result. This leaks a modicus of information (if two records have the same contents then this will show, despite the encryption layer); on the other hand, it allows for exact searches: you encrypt the value to search, and use the index on the encrypted values. Substring searches, however, should be avoided at all costs.



I think a better method would be to revisit your assumptions:


  However this will probably change in the future so I am anticipating efficency problems.


Usually, performance issues don't exist until having been actually encountered (at least in a test platform, if not in production) and duly measured. As Donald Knuth once wrote: premature optimization is the root of all evil.

Even if the envisioned performance issue is real and you know how much it will cost, some alternate methods might be applicable. For instance, you could read all the records in the RAM of the application, decrypt them all, and keep them in RAM. This would allow very fast searches without even going to the SQL level. Modern servers have a lot of RAM. As an example, the servers that maintain the StackExchange sites (all of them) are reputed to have been sufficiently boosted in RAM (a few hundred gigabytes) so that all the data can be cached, and the servers can perform all read accesses at RAM speed.

If your records are, say, no longer than 100 bytes (e.g. they are the names of some people), then you can store 10 millions of value in a mere gigabyte of RAM. What is a gigabyte ? Even your phone has more RAM than that.
",Tom Leek,https://security.stackexchange.com/users/5411,http://security.stackexchange.com/questions/72432/indexing-encrypted-data-for-efficient-searching,TECHNOLOGY,security.stackexchange.com,1.0,0.3333333333333333,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.5555555555555556,0.4444444444444444,0.0,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.6666666666666666,1.0,0.7777777777777778,1.0,1.0,0.9333333333333332,0.6666666666666666,0.3333333333333333,1.0,1.0,Index encrypts data for efficient search,"I have implemented encryption for certain columns in a database. In some cases it may be necessary to search by these columns, either for exact matches or for substrings. At the moment, there is less than 10000 rows to search through (at most). However this will probably change in the future so I am anticipating efficency problems. 

The data will remain encrypted in the database, but when retrieved by the application, it can then be decrypted. This means that the retrieval does not have to be 100% accurate, it can retrieve more records than actually match the query, and the application itself can discard the non-matching records. 

With this in mind I came up with the following solutions:


For exact text match, hash the encrypted data and modulo this with a relatively low number (2^16 perhaps), and store that value in an additional column. When querying the database, it is only necessary to perform the same operation on the input string, and retrieve all records with matching hash value.
For finding substrings, hash each letter and mod 32 the result. Then set the corresponding bit in an integer. Perform the same operation on the query string. Thus it is only necessary to retrieve records where the result of a binary AND on the query with the stored value is greater than 0. This could also be done using each pair of letters, perhaps with a 64-bit or longer integer to allow for more records to be discarded.


My question is, would either of these techniques have a real impact on the security of the data in the encrypted columns? The encryption scheme is AES-256.
","Ability to narrow searches tends to be in direct opposition with the confidentiality that you seek through encryption. For instance, if you store your ""16-bit hash"" in an extra column then that hash reveals 16 bits of the data -- 16 indirect bits, but 16 bits nonetheless. An attacker who sees the database may try to guess (brute force) the record contents, and the 16 bits will allow him to detect 65535/65536th of bad guesses: this is a substantial advantage.

Ability to do substring searches is even worse, since it necessarily reveals information that allows the brute force attack to proceed in gradual steps (this is in fact the same problem as partial password authentication).

At best, what you could do is to implement deterministic encryption, such that encryption of a given record value always yields the same encrypted result. This leaks a modicus of information (if two records have the same contents then this will show, despite the encryption layer); on the other hand, it allows for exact searches: you encrypt the value to search, and use the index on the encrypted values. Substring searches, however, should be avoided at all costs.



I think a better method would be to revisit your assumptions:


  However this will probably change in the future so I am anticipating efficency problems.


Usually, performance issues don't exist until having been actually encountered (at least in a test platform, if not in production) and duly measured. As Donald Knuth once wrote: premature optimization is the root of all evil.

Even if the envisioned performance issue is real and you know how much it will cost, some alternate methods might be applicable. For instance, you could read all the records in the RAM of the application, decrypt them all, and keep them in RAM. This would allow very fast searches without even going to the SQL level. Modern servers have a lot of RAM. As an example, the servers that maintain the StackExchange sites (all of them) are reputed to have been sufficiently boosted in RAM (a few hundred gigabytes) so that all the data can be cached, and the servers can perform all read accesses at RAM speed.

If your records are, say, no longer than 100 bytes (e.g. they are the names of some people), then you can store 10 millions of value in a mere gigabyte of RAM. What is a gigabyte ? Even your phone has more RAM than that.
"
6070,6070,9635,How to clip by inidividual polygon shapes rather than by an aggregated shape consisting of all polygons in the shapefile.,"I have a shapefile with overlapping polygons - network buffers around people's homes. I am trying to clip features such as tree canopy polygons and street polylines so that I can join the set of clipped features contained within each buffer to each network buffer polygon. Unfortunately I cannot get the Clip tool to clip the input feature polygons at the edge of the clip feature polygons if the latter overlaps with another clip feature polygon. How can I get the Clip tool to treat each of my clip features separately? Or is there another approach?  I'm working in ArcGIS 10.
",Eileen Nehme,https://gis.stackexchange.com/users/8547,"Intersect will  give you (a mess of) output polygons (for the tree canopy) and polylines (for the streets), and all the attributes of interest can be used in Dissolve to give you the 'clipped' sets of polygons or polylines.

Make sure that each of your layers has a unique ID field that can be used to group them back together; e.g. HomeBufferID.

A computationally faster alternative to Dissolve is Summary Statistics to collect all the attributes of interest along with a Count_FieldOfInterest, Sum_Area, Sum_Length, or other statistic, and then use the Join Field tool to permanently join in the fields of interest to the original buffer layer.

Note: If areas/lengths are of interest in your analyses then you may have to calculate this geometry into the intersect output before running the dissolve or summary/join.
",ccn,https://gis.stackexchange.com/users/9217,http://gis.stackexchange.com/questions/28580/how-to-clip-by-inidividual-polygon-shapes-rather-than-by-an-aggregated-shape-con,TECHNOLOGY,gis.stackexchange.com,0.8888888888888888,0.7777777777777778,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.3333333333333333,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9333333333333332,1.0,0.0,0.0,1.0,How to clip by a single polygon instead of an aggregate shape composed of all polygons in a shape file.,"I have a polygon overlapping shape file - People's home around the network buffer. I'm trying clipping features like crown polygons and street polylines so I can connect the clipping feature set contained in each buffer to each network buffer polygon. Unfortunately, if the clip function polygon overlaps another clip function polygon, you cannot use the clip tool to clip in the function polygon at the edge of the clip function polygon. How to let the editing tool handle each clip function separately? Or something else? I work at ArcGIS 10.","Intersect will  give you (a mess of) output polygons (for the tree canopy) and polylines (for the streets), and all the attributes of interest can be used in Dissolve to give you the 'clipped' sets of polygons or polylines.

Make sure that each of your layers has a unique ID field that can be used to group them back together; e.g. HomeBufferID.

A computationally faster alternative to Dissolve is Summary Statistics to collect all the attributes of interest along with a Count_FieldOfInterest, Sum_Area, Sum_Length, or other statistic, and then use the Join Field tool to permanently join in the fields of interest to the original buffer layer.

Note: If areas/lengths are of interest in your analyses then you may have to calculate this geometry into the intersect output before running the dissolve or summary/join.
"
1196,1196,1880,Changing PhD topic and effect on career,"I'm a PhD student in my third year (4-6 is common in my country) and seriously consider abandoning my current topic. 
The new topic is in the same general field (CS related), yet in a vastly different domain and would need a quite different methods. My advisor suggested this switch, he could keep me funded in both cases, yet probably better with the new topic.

Arguments for switching are both personal interest in the new topic (it's recently trending, I was interested from the beginning, yet few positions were available) and lack of progress in the current area:


I could produce some publications, yet not up to my advisors expectations (should be easier with the new topic, given the impact factors of the journals my advisor suggested)
For the last 6-8 month I made barely any progress (lots of failed experiments)
I would probably have to abandon my current methods anyway due to 1./2., so half a year or so will be lost learning new methods no matter how I decide


Yet I shy away from switching, mainly due to already being quite old (combination of personal problems and a switch of my major as an undergraduate) and fearing how my C.V. would look if I did take about a year longer and had this second switch...

Thanks for any input.
",throwAway,https://academia.stackexchange.com/users/35361,"Most people won't care.

The time to PhD isn't really considered all that important unless it's highly anomalous (much shorter or longer than standard), and if you get good publications out of it, nobody is going to make a big deal about switching topics. It happens for all kinds of reasons—funding changes, or because the original project doesn't pan out for whatever reason (technical or logistical). 

It will also not impact your career much, unless you're planning to continue studying one of those areas as your post-graduation career. Again, the overall quality tends to matter much more than the actual topic in most cases (particularly if you're moving into a different area from your graduate work).
",aeismail,https://academia.stackexchange.com/users/53,http://academia.stackexchange.com/questions/46479/changing-phd-topic-and-effect-on-career,LIFE_ARTS,academia.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,0.6666666666666666,0.0,0.0,0.5555555555555556,0.7777777777777778,0.0,0.0,1.0,1.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,1.0,1.0,The change of doctoral topic and its influence on career,"I'm a PhD student in my third year (4-6 is common in my country) and seriously consider abandoning my current topic. 
The new topic is in the same general field (CS related), yet in a vastly different domain and would need a quite different methods. My advisor suggested this switch, he could keep me funded in both cases, yet probably better with the new topic.

Arguments for switching are both personal interest in the new topic (it's recently trending, I was interested from the beginning, yet few positions were available) and lack of progress in the current area:


I could produce some publications, yet not up to my advisors expectations (should be easier with the new topic, given the impact factors of the journals my advisor suggested)
For the last 6-8 month I made barely any progress (lots of failed experiments)
I would probably have to abandon my current methods anyway due to 1./2., so half a year or so will be lost learning new methods no matter how I decide


Yet I shy away from switching, mainly due to already being quite old (combination of personal problems and a switch of my major as an undergraduate) and fearing how my C.V. would look if I did take about a year longer and had this second switch...

Thanks for any input.
","Most people won't care.

The time to PhD isn't really considered all that important unless it's highly anomalous (much shorter or longer than standard), and if you get good publications out of it, nobody is going to make a big deal about switching topics. It happens for all kinds of reasons—funding changes, or because the original project doesn't pan out for whatever reason (technical or logistical). 

It will also not impact your career much, unless you're planning to continue studying one of those areas as your post-graduation career. Again, the overall quality tends to matter much more than the actual topic in most cases (particularly if you're moving into a different area from your graduate work).
"
2010,2010,3206,Good/functional but can do better,"I'm looking for an aphorism communicating the thought that ""this works, but we can do better"". Some high-falutin language like Shakespeare or Blake would be ideal.
",numberwang,https://english.stackexchange.com/users/94532,"Not quite Shakespearean, but you could say


  Although the &lt;product&gt; is good as it is, there is still room for improvement.

",Armen Ծիրունյան,https://english.stackexchange.com/users/11268,http://english.stackexchange.com/questions/202584/good-functional-but-can-do-better,CULTURE,english.stackexchange.com,1.0,0.3333333333333333,0.0,1.0,0.3333333333333333,0.0,0.5555555555555556,0.4444444444444444,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7777777777777778,0.7777777777777778,0.6666666666666666,0.7777777777777778,1.0,0.8,0.0,0.0,0.0,0.7777777777777778,"Good / practical, but can do better","I am looking for a maxim to express the idea: ""it works, but we can do better."". A difficult language like Shakespeare or Blake is ideal.","Not quite Shakespearean, but you could say


  Although the &lt;product&gt; is good as it is, there is still room for improvement.

"
657,657,1044,Good backup options for Mac pre-TimeMachine,"I have a friend with an iBook G4 who is looking for a cheap backup option for her Mac running OS 10.4.  Money is tight, so getting 10.5 is not really an option (in addition to buy a backup drive etc, yes money is really that tight).

What suggestions can you offer for backups that's better than trying to remember to burn a CD once a month?
",acrosman,https://superuser.com/users/8908,"Assuming you can get a backup drive or separate volume, try Crashplan.  It's free if you're backing up to an external HD.
",churnd,https://superuser.com/users/4503,http://superuser.com/questions/176211,TECHNOLOGY,superuser.com,1.0,0.5555555555555556,0.0,1.0,0.6666666666666666,0.0,0.7777777777777778,0.7777777777777778,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.0,0.0,0.0,1.0,Good backup options for Mac pre timemachine,"I have a friend with an ibookg4 who is looking for a cheap backup option for a Mac running OS 10.4. Money is tight, so getting 10.5 is not a real choice (except for buying a backup drive, etc., yes, money is really tight).","Assuming you can get a backup drive or separate volume, try Crashplan.  It's free if you're backing up to an external HD.
"
5439,5439,8633,Is a Photoshop EPS file a vector format?,"If I save my file from Photoshop as a Photoshop EPS is that going to be okay as a vector across the board (ie will it be resizeable in whatever it's opened in)? I know if you open a .psd in Photoshop and resize the image, it holds it's quality, so that's fine, but when people need an EPS file because they might want to print it on the side of a building one day (or whatever) is a Photoshop EPS going to be okay? Or is there something else I need to be doing? 

All my designs are always vectors within Photoshop, so text/shapes/designs done with the pen tool - I just need to know that they'll still be a vector for people who don't have Photoshop and can't open it in there to resize it.
",Willow,https://graphicdesign.stackexchange.com/users/3494,"EPS, is an acronym for Encapsulated Post Script - it is a package of information (vector and raster elements) used for cross-platform print documents.  Most would considered this a legacy format, well supported for print. In terms of vector information - it is probably the best choice for what you describe, Willow. 

The EPS format can be used for RGB images - but in fact EPS will never be efficient for rgb, as it is designed for post-script print files.

Your vector images will always be printable as EPS, but it's not a particularly efficient file format and if you do include raster images, the transparency is not well accomodated (as you may have to save the alpha channel separately)

There should be a go-to summary of file formats and their strengths and weaknesses.
For example, you are incorrect about PSD files and resizing. All raster images will pixelate when enlarged.
",WildOutWest,https://graphicdesign.stackexchange.com/users/9583,http://graphicdesign.stackexchange.com/questions/7726/is-a-photoshop-eps-file-a-vector-format,LIFE_ARTS,graphicdesign.stackexchange.com,1.0,0.6666666666666666,0.0,1.0,1.0,1.0,0.4444444444444444,0.4444444444444444,0.3333333333333333,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.3333333333333333,0.0,1.0,1.0,Is Photoshop EPS file in vector format?,"If I save the files in Photoshop as Photoshop's EPS, then, as a vector, can it be resized in all open files? I know if you open a. PSD in Photoshop and resize the image, it will keep the quality of the image, so that's good, but when people need an EPS file, because they may want to print it one day on one side of the building (or somewhere else), will Photoshop EPS be good? Or do I have anything else to do?","EPS, is an acronym for Encapsulated Post Script - it is a package of information (vector and raster elements) used for cross-platform print documents.  Most would considered this a legacy format, well supported for print. In terms of vector information - it is probably the best choice for what you describe, Willow. 

The EPS format can be used for RGB images - but in fact EPS will never be efficient for rgb, as it is designed for post-script print files.

Your vector images will always be printable as EPS, but it's not a particularly efficient file format and if you do include raster images, the transparency is not well accomodated (as you may have to save the alpha channel separately)

There should be a go-to summary of file formats and their strengths and weaknesses.
For example, you are incorrect about PSD files and resizing. All raster images will pixelate when enlarged.
"
5902,5902,9348,"Sharing JavaScript model code between server and client, is this approach valid?","I'm beginning learning Node.js and Backbone. I'd like to share some code between the server and the client (related to [1] and [2]). More in deep:


Share defaults values for a model. Defaults are used to populate forms (client-side), while they are enforced server-side
Share validation rules in order to be DRY and perform client/server validation
Share instance methods


So my idea is to use a factory object to encapsulate common code (defaults, validation rules, public instance methods) and adapt the factory object based on the environment (Node.js or AMD module).

This code is quick&amp;dirty and may not work. Is this a good approach or just a waste of time?

(function (factory) {
    if (typeof exports === 'object') { // Node.js
        var config    = require('../config/config.json'),
            Sequelize = require('sequelize'),
                    _ = require('underscore');

        var User = {
            receiveSms: {
                type: Sequelize.BOOLEAN, allowNull: false
            },
            receiveNewsletter: {
                type: Sequelize.BOOLEAN, allowNull: false
            }
        };

        // Add defaultValue for each returned by 
        _.each(factory.defaults, function (value, key) {
            if(_.has(User, key)) {
                User[key].defaultValue = value;
            }
        });

        module.exports = function () {
            (new Sequelize(config.database, config.username, config.password))
                .define('User', User);
        };
    } else if (typeof define === 'function' &amp;&amp; define.amd) { // AMD
        define(['backbone', 'uderscore'], function (Backbone, _) {
            return Backbone.Model.extend(factory);
        });
    }
}(function () {
    return { // To be adapted
        defaults: {
            receiveSms: false,
            receiveNewsletter: true
        }
    }
}));

",gremo,https://stackoverflow.com/users/220180,"I think it's a better solution to use require.js (especially for using frameworks like underscore in multiple files). You should use a factory only for objects that change during the runtime. A shopping cart for example (but even in this example i think it's more appropriate to use a backbone collection that is given to your function as an argument when instantiated).
See more information here: http://requirejs.org/docs/node.html
",tmuecksch,https://stackoverflow.com/users/1646019,http://stackoverflow.com/questions/14789183/sharing-javascript-model-code-between-server-and-client-is-this-approach-valid,STACKOVERFLOW,stackoverflow.com,1.0,0.5555555555555556,0.0,1.0,0.3333333333333333,1.0,0.7777777777777778,0.4444444444444444,0.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.6666666666666666,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,0.0,0.6666666666666666,0.8888888888888888,Is it effective to share JavaScript model code between the server and the client?,"I'm beginning learning Node.js and Backbone. I'd like to share some code between the server and the client (related to [1] and [2]). More in deep:


Share defaults values for a model. Defaults are used to populate forms (client-side), while they are enforced server-side
Share validation rules in order to be DRY and perform client/server validation
Share instance methods


So my idea is to use a factory object to encapsulate common code (defaults, validation rules, public instance methods) and adapt the factory object based on the environment (Node.js or AMD module).

This code is quick&amp;dirty and may not work. Is this a good approach or just a waste of time?

(function (factory) {
    if (typeof exports === 'object') { // Node.js
        var config    = require('../config/config.json'),
            Sequelize = require('sequelize'),
                    _ = require('underscore');

        var User = {
            receiveSms: {
                type: Sequelize.BOOLEAN, allowNull: false
            },
            receiveNewsletter: {
                type: Sequelize.BOOLEAN, allowNull: false
            }
        };

        // Add defaultValue for each returned by 
        _.each(factory.defaults, function (value, key) {
            if(_.has(User, key)) {
                User[key].defaultValue = value;
            }
        });

        module.exports = function () {
            (new Sequelize(config.database, config.username, config.password))
                .define('User', User);
        };
    } else if (typeof define === 'function' &amp;&amp; define.amd) { // AMD
        define(['backbone', 'uderscore'], function (Backbone, _) {
            return Backbone.Model.extend(factory);
        });
    }
}(function () {
    return { // To be adapted
        defaults: {
            receiveSms: false,
            receiveNewsletter: true
        }
    }
}));

","I think using require.js is a better solution (especially for frameworks like underscores in multiple files). Factories should only be used for objects that change at run time. For example, a shopping cart (but even in this case, I think it's more appropriate to use a skeleton collection that is provided as an argument to a function at instantiation time)."
1620,1620,2542,How TCP/IP server listens to several clients?,"I'm setting up a small tcp/ip connection using GSM/GPRS modems, I have a server PC which runs a server (listener) program, and have several (more than 100) modems located in different places, they send small packets of data to the server in specific periods.  

I have tested system with one client, but how can I test it with several clients? how will my server respond to several clients?  

Here is my server code:

    private TcpListener tcpListener;
    private Thread listenThread;
    public static TcpClient client;

    public Form1()
    {
        InitializeComponent();
        this.tcpListener = new TcpListener(IPAddress.Any, 2020);
        this.listenThread = new Thread(new ThreadStart(ListenForClients));
        this.listenThread.Start();
    }
    private void ListenForClients()
    {
        this.tcpListener.Start();

        while (true)
        {
            //blocks until a client has connected to the server
            client = this.tcpListener.AcceptTcpClient();


            //create a thread to handle communication
            //with connected client
            Thread clientThread = new Thread(new ParameterizedThreadStart(HandleClientComm));
            clientThread.Start(client);
        }
    }
    private void HandleClientComm(object client)
    {
        TcpClient tcpClient = (TcpClient)client;
        NetworkStream clientStream = tcpClient.GetStream();

        //TcpClient client = new TcpClient(servername or ip , port);
        //IpEndPoint ipend = tcpClient.RemoteEndPoint;
        //Console.WriteLine(IPAddress.Parse(ipend.Address.ToString());

        //label3.Text = IPAddress.Parse(((IPEndPoint)tcpClient.Client.RemoteEndPoint).Address.ToString()).ToString();
        SetControlPropertyThreadSafe(label3, ""Text"", IPAddress.Parse(((IPEndPoint)tcpClient.Client.RemoteEndPoint).Address.ToString()).ToString());

        byte[] message = new byte[4096];
        int bytesRead;

        while (true)
        {
            bytesRead = 0;

            try
            {
                //blocks until a client sends a message
                bytesRead = clientStream.Read(message, 0, 4096);
            }
            catch
            {
                //a socket error has occured
                break;
            }

            if (bytesRead == 0)
            {
                //the client has disconnected from the server
                break;
            }

            //message has successfully been received
            ASCIIEncoding encoder = new ASCIIEncoding();
            //System.Diagnostics.Debug.WriteLine(encoder.GetString(message, 0, bytesRead));

            string received_text = encoder.GetString(message, 0, bytesRead).ToString();

            SetControlPropertyThreadSafe(label1, ""Text"", received_text);

            if (received_text == ""cmdtim"")
            {
                SendData(DateTime.Now.ToString());
            }
        }

        tcpClient.Close();
    }


As you see I've created a separate thread for listening clients, how can I listen to several clients?

Should I create a thread for each client?
I don't know how many clients will I have in each moment, will the server buffer data of other clients when it listens to a specific client?  

What is the best strategy for listening to several clients and also sending all of them data?
",Ali_dotNet,https://stackoverflow.com/users/833139,"Some advise:

Remove:

public static TcpClient client;


Replace:

client = this.tcpListener.AcceptTcpClient();


with

TcpClient client = this.tcpListener.AcceptTcpClient();

",Vladimir,https://stackoverflow.com/users/697887,http://stackoverflow.com/questions/7096586/how-tcp-ip-server-listens-to-several-clients,STACKOVERFLOW,stackoverflow.com,0.6666666666666666,0.3333333333333333,0.0,0.0,1.0,0.5,0.6666666666666666,0.5,1.0,0.0,1.0,0.0,0.0,0.5,0.0,0.0,1.0,1.0,0.5,0.0,0.8333333333333334,1.0,0.6666666666666666,1.0,1.0,0.8,0.5,0.0,0.5,0.8333333333333334,How can a TCP / IP server listen to multiple clients?,"I'm setting up a small tcp/ip connection using GSM/GPRS modems, I have a server PC which runs a server (listener) program, and have several (more than 100) modems located in different places, they send small packets of data to the server in specific periods.  

I have tested system with one client, but how can I test it with several clients? how will my server respond to several clients?  

Here is my server code:

    private TcpListener tcpListener;
    private Thread listenThread;
    public static TcpClient client;

    public Form1()
    {
        InitializeComponent();
        this.tcpListener = new TcpListener(IPAddress.Any, 2020);
        this.listenThread = new Thread(new ThreadStart(ListenForClients));
        this.listenThread.Start();
    }
    private void ListenForClients()
    {
        this.tcpListener.Start();

        while (true)
        {
            //blocks until a client has connected to the server
            client = this.tcpListener.AcceptTcpClient();


            //create a thread to handle communication
            //with connected client
            Thread clientThread = new Thread(new ParameterizedThreadStart(HandleClientComm));
            clientThread.Start(client);
        }
    }
    private void HandleClientComm(object client)
    {
        TcpClient tcpClient = (TcpClient)client;
        NetworkStream clientStream = tcpClient.GetStream();

        //TcpClient client = new TcpClient(servername or ip , port);
        //IpEndPoint ipend = tcpClient.RemoteEndPoint;
        //Console.WriteLine(IPAddress.Parse(ipend.Address.ToString());

        //label3.Text = IPAddress.Parse(((IPEndPoint)tcpClient.Client.RemoteEndPoint).Address.ToString()).ToString();
        SetControlPropertyThreadSafe(label3, ""Text"", IPAddress.Parse(((IPEndPoint)tcpClient.Client.RemoteEndPoint).Address.ToString()).ToString());

        byte[] message = new byte[4096];
        int bytesRead;

        while (true)
        {
            bytesRead = 0;

            try
            {
                //blocks until a client sends a message
                bytesRead = clientStream.Read(message, 0, 4096);
            }
            catch
            {
                //a socket error has occured
                break;
            }

            if (bytesRead == 0)
            {
                //the client has disconnected from the server
                break;
            }

            //message has successfully been received
            ASCIIEncoding encoder = new ASCIIEncoding();
            //System.Diagnostics.Debug.WriteLine(encoder.GetString(message, 0, bytesRead));

            string received_text = encoder.GetString(message, 0, bytesRead).ToString();

            SetControlPropertyThreadSafe(label1, ""Text"", received_text);

            if (received_text == ""cmdtim"")
            {
                SendData(DateTime.Now.ToString());
            }
        }

        tcpClient.Close();
    }


As you see I've created a separate thread for listening clients, how can I listen to several clients?

Should I create a thread for each client?
I don't know how many clients will I have in each moment, will the server buffer data of other clients when it listens to a specific client?  

What is the best strategy for listening to several clients and also sending all of them data?
","Some advise:

Remove:

public static TcpClient client;


Replace:

client = this.tcpListener.AcceptTcpClient();


with

TcpClient client = this.tcpListener.AcceptTcpClient();

"
2721,2721,4336,What's a common mechanism for emailing in the background?,"When users sign up to my site, the connection from my server to our 3rd-party SMTP provider is very bad and the app takes from a few seconds to a few minutes to connect. While it is trying to connect and send, users are forced to wait there and sometimes they would just give up and leave the site.

This is horrible user experience. What is a good way to make this seem instantaneous (having to host our own mailserver is not an option at this point)? Some way to execute this in the background? Maybe using some type of queuing mechanism?

I'm using the LNAMP stack on a CentOS 5 x64 machine. App is using CodeIgniter.

EDIT:

It seems using a local mailserver to use as a relay is a common solution. But how does one log or track whether or not email was delivered correctly by using this method? 

Sidenote: Some ESPs provide a REST API for email delivery (ours do too). We currently use SMTP and not their REST API. 
",lamp_scaler,https://serverfault.com/users/87326,"Run a local sendmail/qmail/postfix - whatever, set the smtp server to localhost. The local MTA will queue and deliver when it can (right away or at the next queue run).

On your system:

# yum -y install sendmail
# chkconfig sendmail on
# service sendmail start


shoudl suffice.

I know bubke about CodeIgniter, so I cant help you there.
",Alien Life Form,https://serverfault.com/users/79674,http://serverfault.com/questions/318374,TECHNOLOGY,serverfault.com,1.0,0.3333333333333333,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.4444444444444444,0.4444444444444444,0.3333333333333333,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.7,1.0,0.3333333333333333,0.0,0.8888888888888888,What is the common mechanism for sending mail in the background?,"When users sign up to my site, the connection from my server to our 3rd-party SMTP provider is very bad and the app takes from a few seconds to a few minutes to connect. While it is trying to connect and send, users are forced to wait there and sometimes they would just give up and leave the site.

This is horrible user experience. What is a good way to make this seem instantaneous (having to host our own mailserver is not an option at this point)? Some way to execute this in the background? Maybe using some type of queuing mechanism?

I'm using the LNAMP stack on a CentOS 5 x64 machine. App is using CodeIgniter.

EDIT:

It seems using a local mailserver to use as a relay is a common solution. But how does one log or track whether or not email was delivered correctly by using this method? 

Sidenote: Some ESPs provide a REST API for email delivery (ours do too). We currently use SMTP and not their REST API. 
","Run a local sendmail/qmail/postfix - whatever, set the smtp server to localhost. The local MTA will queue and deliver when it can (right away or at the next queue run).

On your system:

# yum -y install sendmail
# chkconfig sendmail on
# service sendmail start


shoudl suffice.

I know bubke about CodeIgniter, so I cant help you there.
"
5517,5517,8751,Displaying additional User Contact Information,"I have been advised how to add additional contact info fields to the User admin area here (Click here).

However, I am not entirely sure how I can display the the field contents in a link within my template files.

Here is the code in my functions.php:

add_filter( 'user_contactmethods', 'more_contactmethods' );
function more_contactmethods( $contactmethods ) {
    $contactmethods['twitter'] = 'Twitter URL';
    $contactmethods['facebook'] = 'Facebook URL';
    $contactmethods['linkedin'] = 'LinkedIn URL';
    return $contactmethods;
}


And here's the code in one of my template files, but it doesn't seem to work, so I wonder whether I can actually do it this way?

&lt;?php 
    $twitter = get_usermeta( $user_id, 'facebook' ); 
    $facebook = get_usermeta( $user_id, 'twitter' );
    $linkedin = get_usermeta( $user_id, 'linkedin' );
?&gt;

    &lt;a href=""&lt;?php echo $twitter ?&gt;"" id=""twitterBtn"" title=""Visit our Twitter page""&gt;Visit our Twitter page&lt;/a&gt;

",remi90,https://wordpress.stackexchange.com/users/5883,"// Add/Remove Contact Methods
function add_remove_contactmethods( $contactmethods ) {
    $contactmethods['twitter'] = 'Twitter';
    $contactmethods['facebook'] = 'Facebook';
    $contactmethods['Youtube'] = 'YouTube';
    $contactmethods['linkedin'] = 'LinkedIn';
        $contactmethods['skype'] = 'Skype';
    // Remove Contact Methods
    unset($contactmethods['aim']);
    unset($contactmethods['yim']);
    return $contactmethods;
}
add_filter('user_contactmethods','add_remove_contactmethods',10,1);


This works fine in Thesis. Here's the full tutorial

http://wpsites.net/how-to-wordpress/how-to-addremove-custom-user-profile-contact-info-links-to-your-author-box/
",Brad Dalton,https://wordpress.stackexchange.com/users/9884,http://wordpress.stackexchange.com/questions/32505/displaying-additional-user-contact-information,TECHNOLOGY,wordpress.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,0.6666666666666666,1.0,0.6666666666666666,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.7777777777777778,0.6666666666666666,0.6666666666666666,0.8888888888888888,1.0,0.8,0.6666666666666666,0.3333333333333333,0.0,0.7777777777777778,Show other user contact information,"I have been advised how to add additional contact info fields to the User admin area here (Click here).

However, I am not entirely sure how I can display the the field contents in a link within my template files.

Here is the code in my functions.php:

add_filter( 'user_contactmethods', 'more_contactmethods' );
function more_contactmethods( $contactmethods ) {
    $contactmethods['twitter'] = 'Twitter URL';
    $contactmethods['facebook'] = 'Facebook URL';
    $contactmethods['linkedin'] = 'LinkedIn URL';
    return $contactmethods;
}


And here's the code in one of my template files, but it doesn't seem to work, so I wonder whether I can actually do it this way?

&lt;?php 
    $twitter = get_usermeta( $user_id, 'facebook' ); 
    $facebook = get_usermeta( $user_id, 'twitter' );
    $linkedin = get_usermeta( $user_id, 'linkedin' );
?&gt;

    &lt;a href=""&lt;?php echo $twitter ?&gt;"" id=""twitterBtn"" title=""Visit our Twitter page""&gt;Visit our Twitter page&lt;/a&gt;

","// Add/Remove Contact Methods
function add_remove_contactmethods( $contactmethods ) {
    $contactmethods['twitter'] = 'Twitter';
    $contactmethods['facebook'] = 'Facebook';
    $contactmethods['Youtube'] = 'YouTube';
    $contactmethods['linkedin'] = 'LinkedIn';
        $contactmethods['skype'] = 'Skype';
    // Remove Contact Methods
    unset($contactmethods['aim']);
    unset($contactmethods['yim']);
    return $contactmethods;
}
add_filter('user_contactmethods','add_remove_contactmethods',10,1);


This works fine in Thesis. Here's the full tutorial

http://wpsites.net/how-to-wordpress/how-to-addremove-custom-user-profile-contact-info-links-to-your-author-box/
"
2498,2498,3984,What is the likelihood of ever discovering the graviton?,"How would one look for and confirm existence of a graviton?

Someone was speaking to me about perhaps one day discovering the graviton, but to me it seems unlikely, although I'm young and essentially quite naive, so am coming to you physicists to ask 


What actually is the likelihood of finding it? 
How would we find it?

",ODP,https://physics.stackexchange.com/users/8082,"This depends on graviton energy and wavelength.

Given a source of a beam of high-frequency gravitons with high luminocity, it would not be difficult to detect one. 

The problem is that nature has little sources of high-energy gravitons.
",Anixx,https://physics.stackexchange.com/users/1186,http://physics.stackexchange.com/questions/34118/what-is-the-likelihood-of-ever-discovering-the-graviton,SCIENCE,physics.stackexchange.com,1.0,1.0,1.0,0.0,0.0,0.0,1.0,1.0,1.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.8,0.0,0.0,1.0,1.0,How likely is it to find a graviton?,"How would one look for and confirm existence of a graviton?

Someone was speaking to me about perhaps one day discovering the graviton, but to me it seems unlikely, although I'm young and essentially quite naive, so am coming to you physicists to ask 


What actually is the likelihood of finding it? 
How would we find it?

","This depends on graviton energy and wavelength.

Given a source of a beam of high-frequency gravitons with high luminocity, it would not be difficult to detect one. 

The problem is that nature has little sources of high-energy gravitons.
"
4010,4010,6403,"Loading and unloading ""chunks"" of tiles in a 2d tile engine with 2d camera","I am making a 2d tile based game in C# and XNA 4.0. I am having trouble loading and unloading ""chunks"" of tiles(blocks). The whole world is randomly generated and is infinate on both axis. How would I go about loading and unloading chunks of tile data in the camera's view?

A pastebin to the pastebin links(I still have the 2 link cap):

http://pastebin.com/9PYr8cvC
",ceriosNerd,https://gamedev.stackexchange.com/users/14120,"Basically you want to have a range around your camera. When chunks come into this range, you load/generate them. When chunks leave this range, you save/unload. Keep in mind you'll want to keep the loaded range larger than the visible range, so your chunk loading isn't seen.

At the moment it looks like you're storing your chunks in a dictionary. That's kind of a strange choice, and it may be a little more work for you to maintain your chunks with that data structure.

It looks like you've got a lot of the functions you need already, nice work. You'll want a list of chunk positions that should be loaded, your loaded list. Your update loop is going to maintain that list. As the camera moves, you update the list to include all the chunks in the range of the camera.

This is where the dictionary choice is a little strange. Essentially you'd have to loop through all your dictionary entries, unload the chunks that aren't in your loaded list and load the ones that aren't in your dictionary but are in your loaded list. The alternative is to have some sort of linked list structure. Where you can add/remove chunks from either end. This does get a little tricky when dealing with 2D linked lists, but I think you can make it work.

It would look something like this:

Starting with this scenario, where the red dot is the camera, moving in the X plus direction. All the grid squares (chunks) touching the green area are currently loaded.



Then the camera moves far enough to get some new chunks:



All the blue chunks will be loaded/generated. All the red chunks will be unloaded/saved.

As for maintaining the list, you can update whenever the camera moves past a chunk boundary. Like if it moves past the X plus boundary of the chunk it's currently over, like in the example above, the chunks to be added or removed from the list could be found like this:

for(int y = Camera.Position.Y + LoadRange.Y; y &gt;= Camera.Position.Y - LoadRange.Y; y--){
    AddToLoadedList(GetChunkRootPositionAt(Camera.Position.X + LoadRange.X, y));
    RemoveFromLoadedList(GetChunkRootPositionAt(Camera.Position.X - LoadRange.X, y));
}


Where GetChunkRootPositionAt converts a world position into the root position of the chunk that contains that location. And the LoadedList functions take a Vector2 to add/remove from the loaded list.

Finally, you may find adding in a buffer for unloading could be nice. If someone is moving the camera around a lot right on a chunk boundary, you can save a lot of loading/unloading by just keeping it loaded. Essentially, you may find that unloading at the same time as loading isn't necessarily the best option.
",MichaelHouse,https://gamedev.stackexchange.com/users/7191,http://gamedev.stackexchange.com/questions/25030/loading-and-unloading-chunks-of-tiles-in-a-2d-tile-engine-with-2d-camera,TECHNOLOGY,gamedev.stackexchange.com,0.7777777777777778,0.6666666666666666,0.0,1.0,0.6666666666666666,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.7777777777777778,1.0,0.7777777777777778,1.0,1.0,1.0,1.0,0.0,0.3333333333333333,0.8888888888888888,Using a 2D camera to load and unload block tiling in the 2D tiling engine,"I'm making a two-dimensional tile based game in C and XNA 4.0. I have problems loading and unloading ""block"" tiles (blocks). The whole world is randomly generated and infinite on both axes. How do I load and unload block tile data in camera view?","Basically you want to have a range around your camera. When chunks come into this range, you load/generate them. When chunks leave this range, you save/unload. Keep in mind you'll want to keep the loaded range larger than the visible range, so your chunk loading isn't seen.

At the moment it looks like you're storing your chunks in a dictionary. That's kind of a strange choice, and it may be a little more work for you to maintain your chunks with that data structure.

It looks like you've got a lot of the functions you need already, nice work. You'll want a list of chunk positions that should be loaded, your loaded list. Your update loop is going to maintain that list. As the camera moves, you update the list to include all the chunks in the range of the camera.

This is where the dictionary choice is a little strange. Essentially you'd have to loop through all your dictionary entries, unload the chunks that aren't in your loaded list and load the ones that aren't in your dictionary but are in your loaded list. The alternative is to have some sort of linked list structure. Where you can add/remove chunks from either end. This does get a little tricky when dealing with 2D linked lists, but I think you can make it work.

It would look something like this:

Starting with this scenario, where the red dot is the camera, moving in the X plus direction. All the grid squares (chunks) touching the green area are currently loaded.



Then the camera moves far enough to get some new chunks:



All the blue chunks will be loaded/generated. All the red chunks will be unloaded/saved.

As for maintaining the list, you can update whenever the camera moves past a chunk boundary. Like if it moves past the X plus boundary of the chunk it's currently over, like in the example above, the chunks to be added or removed from the list could be found like this:

for(int y = Camera.Position.Y + LoadRange.Y; y &gt;= Camera.Position.Y - LoadRange.Y; y--){
    AddToLoadedList(GetChunkRootPositionAt(Camera.Position.X + LoadRange.X, y));
    RemoveFromLoadedList(GetChunkRootPositionAt(Camera.Position.X - LoadRange.X, y));
}


Where GetChunkRootPositionAt converts a world position into the root position of the chunk that contains that location. And the LoadedList functions take a Vector2 to add/remove from the loaded list.

Finally, you may find adding in a buffer for unloading could be nice. If someone is moving the camera around a lot right on a chunk boundary, you can save a lot of loading/unloading by just keeping it loaded. Essentially, you may find that unloading at the same time as loading isn't necessarily the best option.
"
2062,2062,3285,ERR_SSL_PROTOCOL_ERROR in chrome 39 and 40 but works in chrome 36.Help fix in chrome 39,"I am able to access a URL in Chrome 36 and IE8 but in Chrome 39 or 40 or Firefox 35 it throws the error:


  Unable to make a secure connection to the server.  This may be a
  problem with the server, or it may be requiring a client
  authentication certificate that you don't have.
  
  Error code: ERR_SSL_PROTOCOL_ERROR}. 


It seems that it is an issue related to the SSL certificate. How can I fix this?
",Swati Mishra,https://stackoverflow.com/users/4468846,"Google announced that they would begin removing support for SHA-1 cryptographic hash algorithm beginning with Chrome 39. According to Google:


  HTTPS sites whose certificate chains use SHA-1 and are valid past 1 January 2017 will no longer appear to be fully trustworthy in Chrome’s user interface.


There are several sites which can provide detailed analysis of your SSL certificate chain, such as Qualys SSL Labs' SSL Test.

Google Chrome does have a highly risky command-line option --ignore-certificate-errors which might bypass certain certificate errors. Be aware that ignoring certificate errors puts all of your SSL traffic at risk of being eavesdropped on.

It's also possible that this is a new bug. Google switched from using OpenSSL library to it's own ""BoringSSL"" library in Chrome 38. To report a bug in Chrome visit chrome://help/ and click ""Report an issue"".
",Jonathan Webb,https://stackoverflow.com/users/3684380,http://stackoverflow.com/questions/28019407/err-ssl-protocol-error-in-chrome-39-and-40-but-works-in-chrome-36-help-fix-in-ch,STACKOVERFLOW,stackoverflow.com,0.8333333333333334,0.5,0.0,1.0,1.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.5,0.5,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,0.9,0.5,0.5,1.0,1.0,"Err? SSL? Protocol? Error in chrome 39 and chrome 40, but valid in chrome 36. Help fix in chrome 39","I am able to access a URL in Chrome 36 and IE8 but in Chrome 39 or 40 or Firefox 35 it throws the error:


  Unable to make a secure connection to the server.  This may be a
  problem with the server, or it may be requiring a client
  authentication certificate that you don't have.
  
  Error code: ERR_SSL_PROTOCOL_ERROR}. 


It seems that it is an issue related to the SSL certificate. How can I fix this?
","Google announced that they would begin removing support for SHA-1 cryptographic hash algorithm beginning with Chrome 39. According to Google:


  HTTPS sites whose certificate chains use SHA-1 and are valid past 1 January 2017 will no longer appear to be fully trustworthy in Chrome’s user interface.


There are several sites which can provide detailed analysis of your SSL certificate chain, such as Qualys SSL Labs' SSL Test.

Google Chrome does have a highly risky command-line option --ignore-certificate-errors which might bypass certain certificate errors. Be aware that ignoring certificate errors puts all of your SSL traffic at risk of being eavesdropped on.

It's also possible that this is a new bug. Google switched from using OpenSSL library to it's own ""BoringSSL"" library in Chrome 38. To report a bug in Chrome visit chrome://help/ and click ""Report an issue"".
"
3577,3577,5717,Parsing Ids from a string to create detail objects,"I am building a Flow that takes a user through a wizard to create a custom contract object with detail objects that represent the products on that contract (stored as a junction object).  An issue I ran into is that Flow has a known limitation where if you use a Dynamic Choice (i.e. creating a dynamic set of checkboxes to choose Products from based on records from the Product object) it can only store the choices as a long semicolon delimited string in a variable; it cannot create detail objects based on your dynamic selection (even using a loop).

To get around this, I want the flow to just create the parent Contract, then I want an after insert Apex trigger to parse the field where the long string of semicolon separated Product Ids are stored.  The trigger would need to take the string and find each Id to store in a List.  Once I had the List made from the text field I could insert the Product detail records to the parent Contract.

I am very new to Apex, mostly just a point and click admin here.  I am struggling with how to use RIGHT and LEFT to loop through the string field.

trigger AddProductstoSOW on PS_Contract__c (after insert) {
        for(PS_Contract__c c:Trigger.new){
        List&lt;Id&gt; ProductsToInsert = new List&lt;Id&gt;;
        integer n = LEN(c.Initial_Services_Products__c);
      for(p=15,p&lt;n,p+17){
    //How to iterate through Initial_Products_Selected__c?
        thisId = LEFT(p);
        Id product = Id.valueOf(thisId);
        ProductsToInsert.add(product);
        }
    }
    insert ProductsToInsert;
}


Any help is very appreciated.
",Tyler Whitesides,https://salesforce.stackexchange.com/users/16691,"You can use the String split method and split the concatenated string using the delimiter. something like this

 List&lt;String&gt; strProductIds = c.Initial_Services_Products__c.split(';');

",Vamsi Krishna,https://salesforce.stackexchange.com/users/3038,http://salesforce.stackexchange.com/questions/66539/parsing-ids-from-a-string-to-create-detail-objects,TECHNOLOGY,salesforce.stackexchange.com,0.8888888888888888,0.5555555555555556,0.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.5555555555555556,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.3333333333333333,0.0,0.7777777777777778,1.0,0.6666666666666666,1.0,1.0,0.8,1.0,0.3333333333333333,0.0,0.8888888888888888,Parsing ID from string to create detail object,"I am building a Flow that takes a user through a wizard to create a custom contract object with detail objects that represent the products on that contract (stored as a junction object).  An issue I ran into is that Flow has a known limitation where if you use a Dynamic Choice (i.e. creating a dynamic set of checkboxes to choose Products from based on records from the Product object) it can only store the choices as a long semicolon delimited string in a variable; it cannot create detail objects based on your dynamic selection (even using a loop).

To get around this, I want the flow to just create the parent Contract, then I want an after insert Apex trigger to parse the field where the long string of semicolon separated Product Ids are stored.  The trigger would need to take the string and find each Id to store in a List.  Once I had the List made from the text field I could insert the Product detail records to the parent Contract.

I am very new to Apex, mostly just a point and click admin here.  I am struggling with how to use RIGHT and LEFT to loop through the string field.

trigger AddProductstoSOW on PS_Contract__c (after insert) {
        for(PS_Contract__c c:Trigger.new){
        List&lt;Id&gt; ProductsToInsert = new List&lt;Id&gt;;
        integer n = LEN(c.Initial_Services_Products__c);
      for(p=15,p&lt;n,p+17){
    //How to iterate through Initial_Products_Selected__c?
        thisId = LEFT(p);
        Id product = Id.valueOf(thisId);
        ProductsToInsert.add(product);
        }
    }
    insert ProductsToInsert;
}


Any help is very appreciated.
","You can use the String split method and split the concatenated string using the delimiter. something like this

 List&lt;String&gt; strProductIds = c.Initial_Services_Products__c.split(';');

"
1213,1213,1904,House rules to make the cloister less of a game winning tile in Carcassonne?,"In my experience, cloister tiles in Carcassonne are often ""too lucky"". If you draw a cloister tile in the beginning of the game, it will typically still require an investment of quite a bit of ""meeple"" time to obtain the full 9 points, which makes it a fair trade-off. However, after about half of the game, it's relatively likely that you can ""parachute"" a cloister tile in some spot and get 8 or 9 points immediately. This adds a lot of randomness to the game.

What house rules work well to diminish this effect?
",Erik P.,https://boardgames.stackexchange.com/users/30,"There are a couple of expansions that reduce the usefulness of cloisters. You don't get the points until all the surrounding squares are filled, which is a safe bet in 'vanilla' Carcassonne, but not such a sure thing with expansions. The Tower expansion makes it less attractive to leave meeple on the board for any length of time, because they are sitting ducks for capture by a tower. The Catapult expansion makes it possible to remove Meeple from the board, or replace them with your own. The Princess and the Dragon expansion also encourages Monk removal as dragon-food.

You could ban the 'instant cloister' case, disallowing the dropping of a cloister into a hole for an immediate 9 points. I personally don't find this a huge problem though. You have equivalent 'instant city' and 'instant road' cases. Ultimately, there is quite a lot of luck involved in Carcassonne, by design, I think.
",ire_and_curses,https://boardgames.stackexchange.com/users/50,http://boardgames.stackexchange.com/questions/8/house-rules-to-make-the-cloister-less-of-a-game-winning-tile-in-carcassonne,CULTURE,boardgames.stackexchange.com,1.0,0.6666666666666666,0.3333333333333333,1.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.5555555555555556,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,0.0,0.3333333333333333,0.6666666666666666,0.8888888888888888,"In karkasson, let the cloister be less like the winning tile house rule?","In my experience, Carlsson's cloister tiles are usually ""too lucky."". If you draw a cloister tile at the beginning of the game, it usually still takes quite a lot of time to get a full score of 9, which is a fair trade-off. However, after about half of the game, you are likely to ""parachute"" a cloister tile somewhere and get 8 or 9 points immediately. This adds a lot of randomness to the game.","There are a couple of expansions that reduce the usefulness of cloisters. You don't get the points until all the surrounding squares are filled, which is a safe bet in 'vanilla' Carcassonne, but not such a sure thing with expansions. The Tower expansion makes it less attractive to leave meeple on the board for any length of time, because they are sitting ducks for capture by a tower. The Catapult expansion makes it possible to remove Meeple from the board, or replace them with your own. The Princess and the Dragon expansion also encourages Monk removal as dragon-food.

You could ban the 'instant cloister' case, disallowing the dropping of a cloister into a hole for an immediate 9 points. I personally don't find this a huge problem though. You have equivalent 'instant city' and 'instant road' cases. Ultimately, there is quite a lot of luck involved in Carcassonne, by design, I think.
"
4935,4935,7860,Looking for a compound,"TL;DR;
I need a compound that is harmeless to the human body, odorless, tasteless, causes some kind of visible reaction (urine coloration perhaps) AND can be bought without medical recomendation.
LONG VERSION;
Food stealing in my company fridge has become a serious problem. It's not only a recurring issue but a targeted one... our thief has been targeting ""high"" value, particularly coconut water. HR seems to ignore our complains... so I decided to take matters in my own hands... since I have access to timesheets, I thought that if I can scare out thief to leave work or skip it, I can narrow-it-down/point-him-out because we have about 30 people in our office...
",Leonardo,https://chemistry.stackexchange.com/users/9331,"Urine typically is yellow, but in combination with blue dyes, a green colour can be obtained.

Noteworthy compounds are methylene blue, thymol, Cimetidine (antacid), or Mitoxanthrone (used in cancer therapy).

I've mentioned these just for the sake of completeness - I think it is irresponsible and stupid to spike food with anything that doesn't belong there.

Hiding a webcam in a shelf and running zoneminder probably isn't legal either and will get you in trouble with the privacy officer, but at least that doesn't mess around with the health of anybody else.
",Klaus-Dieter Warzecha,https://chemistry.stackexchange.com/users/418,http://chemistry.stackexchange.com/questions/27454/looking-for-a-compound,SCIENCE,chemistry.stackexchange.com,0.7777777777777778,0.3333333333333333,0.0,1.0,1.0,1.0,0.6666666666666666,0.5555555555555556,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.4444444444444444,0.8888888888888888,0.7777777777777778,1.0,1.0,0.9,0.6666666666666666,0.0,0.3333333333333333,0.8888888888888888,Looking for a compound,"TL;DR;
I need a compound that is harmeless to the human body, odorless, tasteless, causes some kind of visible reaction (urine coloration perhaps) AND can be bought without medical recomendation.
LONG VERSION;
Food stealing in my company fridge has become a serious problem. It's not only a recurring issue but a targeted one... our thief has been targeting ""high"" value, particularly coconut water. HR seems to ignore our complains... so I decided to take matters in my own hands... since I have access to timesheets, I thought that if I can scare out thief to leave work or skip it, I can narrow-it-down/point-him-out because we have about 30 people in our office...
","Urine typically is yellow, but in combination with blue dyes, a green colour can be obtained.

Noteworthy compounds are methylene blue, thymol, Cimetidine (antacid), or Mitoxanthrone (used in cancer therapy).

I've mentioned these just for the sake of completeness - I think it is irresponsible and stupid to spike food with anything that doesn't belong there.

Hiding a webcam in a shelf and running zoneminder probably isn't legal either and will get you in trouble with the privacy officer, but at least that doesn't mess around with the health of anybody else.
"
3793,3793,6030,Kendo UI grid popup now working after AJAX data,"I have a kendo grid which has data populated via AJAX. 

If I take out the AJAX all is fine but when I populate the data via AJAX the edit button doesn't bring up the pop up. 

The grid itself looks like this: 

&lt;div id=""DefinedLevelsGridContainer""&gt;
@(Html.Kendo().Grid(Model.Where(x =&gt; x.OrgLevel == 0).First().DefinedFieldsList)
    .Name(""DefinedlevelsGrid"")
    .Columns(columns =&gt;
    {
        columns.Bound(x =&gt; x.FieldName).Title(""Name"");
        columns.Bound(x =&gt; x.FieldTypeText).Title(""Type"");
        columns.Bound(x =&gt; x.isMandatory).Title(""Mandatory"");
        columns.Bound(x =&gt; x.DefaultValue).Title(""Default Value"");
        columns.Bound(x =&gt; x.UpdatedOn).Title(""Updated"");
        columns.Command(command =&gt; { command.Edit(); command.Destroy(); });
    })
    .Editable(editable =&gt; editable.Mode(GridEditMode.PopUp).TemplateName(""_OrgDefinedFieldEdit""))
    .Pageable()
    .Sortable()
    .DataSource(dataSource =&gt; dataSource
    .Server()
    .Model(model =&gt; model.Id(x =&gt; x.FieldId))
    .Update(update =&gt; update.Action(""Update"", ""Home""))
    .Destroy(destroy =&gt; destroy.Action(""Destroy"", ""Home""))
    )
)




As you can see I am populating it, by default, with the first item in a list of data. 

I then have this: 

$(window).load(function () {
    $("".LevelSelector:first"").click();
});


Which calls the following function: 

$("".LevelSelector"").click(function () {
        var rootString = $(this).html();
        var splitString = rootString.split(""-"");
        var levelGuid = $(this).attr(""LevelGuid"").toString();

        $(""#LevelEditName"").text($.trim(splitString[0]));
        $(""#LevelEditInput"").val($.trim(splitString[1]));
        $(""#CreatedOn"").text($(this).attr(""CreatedDate""))
        $(""#CreatedBy"").text($(this).attr(""CreatedBy""))
        $(""#UpdatedOn"").text($(this).attr(""UpdatedDate""))
        $(""#SelectedLevelGuid"").text(levelGuid)

        var Url = '@Url.Action(""GetLevelFields"", ""OrganisationAJAX"")' + '?LevelGuid=' + levelGuid;

        $.ajax({
            url: Url,
            contentType: ""application/json; charset=utf-8"",
            type: 'POST',
            context: this,
            timeout: 60000,
            dataType: 'json',
            tryCount: 0,
            retryLimit: 3,
            success: function (data) {

                var grid = $(""#DefinedlevelsGrid"").data(""kendoGrid"");
                grid.dataSource.data(data);
            },
            error: function (httpRequest, textStatus, errorThrown) {
                $("".Message"").text(""Error: "" + textStatus + "" "" + errorThrown);
            }
        });
    });


The first part is populating another part of the page and then it does an AJAX call to go and get the data. On success it populates the grid. 

That all works. 

But when I click on edit it doesn't load the grid. It does move to the top of the page so I know it is firing. 

If I stop the pre population by AJAX it does load up the template so I know the template isn't at fault. 

Does anyone have any ideas? 

Many thanks in advance. 
",Lex Eichner,https://stackoverflow.com/users/1428069,"In vcase anyone else sees this, I fixed it by changing .Server to .Ajax. 

So it would look like this: 

@(Html.Kendo().Grid(Model.Where(x =&gt; x.OrgLevel == 0).First().DefinedFieldsList)
.Name(""DefinedlevelsGrid"")
.Columns(columns =&gt;
{
    columns.Bound(x =&gt; x.FieldName).Title(""Name"");
    columns.Bound(x =&gt; x.FieldTypeText).Title(""Type"");
    columns.Bound(x =&gt; x.isMandatory).Title(""Mandatory"");
    columns.Bound(x =&gt; x.DefaultValue).Title(""Default Value"");
    columns.Bound(x =&gt; x.UpdatedOn).Title(""Updated"");
    columns.Command(command =&gt; { command.Edit(); command.Destroy(); });
})
.Editable(editable =&gt; editable.Mode(GridEditMode.PopUp).TemplateName(""_OrgDefinedFieldEdit""))
.Pageable()
.Sortable()
.DataSource(dataSource =&gt; dataSource
.Ajax() //&lt;------- Changed to .Ajax()
.Model(model =&gt; model.Id(x =&gt; x.FieldId))
.Update(update =&gt; update.Action(""Update"", ""Home""))
.Destroy(destroy =&gt; destroy.Action(""Destroy"", ""Home""))
)

",Lex Eichner,https://stackoverflow.com/users/1428069,http://stackoverflow.com/questions/26712069/kendo-ui-grid-popup-now-working-after-ajax-data,STACKOVERFLOW,stackoverflow.com,0.8333333333333334,0.3333333333333333,0.5,0.5,1.0,0.5,0.5,0.3333333333333333,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.5,0.0,1.0,1.0,0.6666666666666666,1.0,1.0,1.0,0.5,0.5,0.0,0.8333333333333334,"Kendoui grid pop-up menu, now processing ajax data","I have a kendo grid which has data populated via AJAX. 

If I take out the AJAX all is fine but when I populate the data via AJAX the edit button doesn't bring up the pop up. 

The grid itself looks like this: 

&lt;div id=""DefinedLevelsGridContainer""&gt;
@(Html.Kendo().Grid(Model.Where(x =&gt; x.OrgLevel == 0).First().DefinedFieldsList)
    .Name(""DefinedlevelsGrid"")
    .Columns(columns =&gt;
    {
        columns.Bound(x =&gt; x.FieldName).Title(""Name"");
        columns.Bound(x =&gt; x.FieldTypeText).Title(""Type"");
        columns.Bound(x =&gt; x.isMandatory).Title(""Mandatory"");
        columns.Bound(x =&gt; x.DefaultValue).Title(""Default Value"");
        columns.Bound(x =&gt; x.UpdatedOn).Title(""Updated"");
        columns.Command(command =&gt; { command.Edit(); command.Destroy(); });
    })
    .Editable(editable =&gt; editable.Mode(GridEditMode.PopUp).TemplateName(""_OrgDefinedFieldEdit""))
    .Pageable()
    .Sortable()
    .DataSource(dataSource =&gt; dataSource
    .Server()
    .Model(model =&gt; model.Id(x =&gt; x.FieldId))
    .Update(update =&gt; update.Action(""Update"", ""Home""))
    .Destroy(destroy =&gt; destroy.Action(""Destroy"", ""Home""))
    )
)




As you can see I am populating it, by default, with the first item in a list of data. 

I then have this: 

$(window).load(function () {
    $("".LevelSelector:first"").click();
});


Which calls the following function: 

$("".LevelSelector"").click(function () {
        var rootString = $(this).html();
        var splitString = rootString.split(""-"");
        var levelGuid = $(this).attr(""LevelGuid"").toString();

        $(""#LevelEditName"").text($.trim(splitString[0]));
        $(""#LevelEditInput"").val($.trim(splitString[1]));
        $(""#CreatedOn"").text($(this).attr(""CreatedDate""))
        $(""#CreatedBy"").text($(this).attr(""CreatedBy""))
        $(""#UpdatedOn"").text($(this).attr(""UpdatedDate""))
        $(""#SelectedLevelGuid"").text(levelGuid)

        var Url = '@Url.Action(""GetLevelFields"", ""OrganisationAJAX"")' + '?LevelGuid=' + levelGuid;

        $.ajax({
            url: Url,
            contentType: ""application/json; charset=utf-8"",
            type: 'POST',
            context: this,
            timeout: 60000,
            dataType: 'json',
            tryCount: 0,
            retryLimit: 3,
            success: function (data) {

                var grid = $(""#DefinedlevelsGrid"").data(""kendoGrid"");
                grid.dataSource.data(data);
            },
            error: function (httpRequest, textStatus, errorThrown) {
                $("".Message"").text(""Error: "" + textStatus + "" "" + errorThrown);
            }
        });
    });


The first part is populating another part of the page and then it does an AJAX call to go and get the data. On success it populates the grid. 

That all works. 

But when I click on edit it doesn't load the grid. It does move to the top of the page so I know it is firing. 

If I stop the pre population by AJAX it does load up the template so I know the template isn't at fault. 

Does anyone have any ideas? 

Many thanks in advance. 
","In vcase anyone else sees this, I fixed it by changing .Server to .Ajax. 

So it would look like this: 

@(Html.Kendo().Grid(Model.Where(x =&gt; x.OrgLevel == 0).First().DefinedFieldsList)
.Name(""DefinedlevelsGrid"")
.Columns(columns =&gt;
{
    columns.Bound(x =&gt; x.FieldName).Title(""Name"");
    columns.Bound(x =&gt; x.FieldTypeText).Title(""Type"");
    columns.Bound(x =&gt; x.isMandatory).Title(""Mandatory"");
    columns.Bound(x =&gt; x.DefaultValue).Title(""Default Value"");
    columns.Bound(x =&gt; x.UpdatedOn).Title(""Updated"");
    columns.Command(command =&gt; { command.Edit(); command.Destroy(); });
})
.Editable(editable =&gt; editable.Mode(GridEditMode.PopUp).TemplateName(""_OrgDefinedFieldEdit""))
.Pageable()
.Sortable()
.DataSource(dataSource =&gt; dataSource
.Ajax() //&lt;------- Changed to .Ajax()
.Model(model =&gt; model.Id(x =&gt; x.FieldId))
.Update(update =&gt; update.Action(""Update"", ""Home""))
.Destroy(destroy =&gt; destroy.Action(""Destroy"", ""Home""))
)

"
81,81,131,Random Forest to estimate land use in past with Landsat,"I am new in Machine Learning and in R. I am working in my Master thesis. I am trying to estimate the LULC of the years 1984, 1990, 2000, 2011, 2014 for characterizing the forest dynamics. I have for each year the bands corresponding to Landsat imageries. The images were corrected and I have calculated vegetation index (NDVI, EVI, SR) and Tasseled Cap Components(Brightness, Greenness, Wetness). All this was performed using  i.landsat.toar, i.vi and i.tasscap commands in Grass 7, respectivelly. 

I have as reference the year 2009 since there is a orthophoto and LiDAR data. Using the orthophoto I digitized training polygons for 5 classes (1. Crops, artificial, bareland; 2. pinus forest; 3. Mixed forest; 4. Quercus and 5. Shrubs). 

I fitted a model using Random forest and my intention is to classify the other year datasets  wich have 5 reflective bands, 3 vegetation indexes and 3 tasseled Cap Components as predictor variables. 

The performance of the model is quite good, OOB 10.45% but within classes the Mixed forest achieved about 30 % of error. Thus, when I use the model to classify the other years the misclassification is very high. 

Am I doing anything worng? Is the Random forest useful for this purpose? Is there any software, method or algorithm that i could use to estimate the landuse?
",Juan Jose Mena,https://gis.stackexchange.com/users/52026,"It is a difficult thing that you are attempting. Small subtle changes in reflectances caused by different acquisition dates will cause major errors to arise when using your approach. You will have to do more preprocessing of your data, in order to have your approach be reliable.
Normalizing the other years to your reference will most likely help, but it may not be enough.

Another approach would be to create training areas for each timestep and accept that the images are not directly comparable, but instead compare finished classifications. This obviously adds to the amount of user dependency and thus makes the study less reproducable.
",Mikkel Lydholm Rasmussen,https://gis.stackexchange.com/users/22166,http://gis.stackexchange.com/questions/147076/random-forest-to-estimate-land-use-in-past-with-landsat,TECHNOLOGY,gis.stackexchange.com,0.8888888888888888,0.3333333333333333,0.0,1.0,0.3333333333333333,1.0,0.5555555555555556,0.4444444444444444,1.0,0.0,0.6666666666666666,1.0,0.0,0.0,0.0,0.3333333333333333,0.6666666666666666,0.0,0.3333333333333333,0.0,0.4444444444444444,1.0,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.0,0.6666666666666666,1.0,Using Landsat to estimate the random forest of land use in the past,"I am new in Machine Learning and in R. I am working in my Master thesis. I am trying to estimate the LULC of the years 1984, 1990, 2000, 2011, 2014 for characterizing the forest dynamics. I have for each year the bands corresponding to Landsat imageries. The images were corrected and I have calculated vegetation index (NDVI, EVI, SR) and Tasseled Cap Components(Brightness, Greenness, Wetness). All this was performed using  i.landsat.toar, i.vi and i.tasscap commands in Grass 7, respectivelly. 

I have as reference the year 2009 since there is a orthophoto and LiDAR data. Using the orthophoto I digitized training polygons for 5 classes (1. Crops, artificial, bareland; 2. pinus forest; 3. Mixed forest; 4. Quercus and 5. Shrubs). 

I fitted a model using Random forest and my intention is to classify the other year datasets  wich have 5 reflective bands, 3 vegetation indexes and 3 tasseled Cap Components as predictor variables. 

The performance of the model is quite good, OOB 10.45% but within classes the Mixed forest achieved about 30 % of error. Thus, when I use the model to classify the other years the misclassification is very high. 

Am I doing anything worng? Is the Random forest useful for this purpose? Is there any software, method or algorithm that i could use to estimate the landuse?
","It is a difficult thing that you are attempting. Small subtle changes in reflectances caused by different acquisition dates will cause major errors to arise when using your approach. You will have to do more preprocessing of your data, in order to have your approach be reliable.
Normalizing the other years to your reference will most likely help, but it may not be enough.

Another approach would be to create training areas for each timestep and accept that the images are not directly comparable, but instead compare finished classifications. This obviously adds to the amount of user dependency and thus makes the study less reproducable.
"
45,45,68,How to grep words in a file?,"
  Possible Duplicate:
  Regex for &ldquo;or&rdquo; in grep  




How can I grep for lines with either 'disable' or 'enable' in my file?

I tried 
 $ grep   ""disable|enable"" fail.log 

but that shows up nothing.
",michael,https://superuser.com/users/31500,"Try ""grep ""disable\|enable"" fail.log

The backslash turns the | into the ""or"" metacharacter, otherwise you are grepping for the literal 'disable|enable""
",bdk,https://superuser.com/users/9262,http://superuser.com/questions/436426,TECHNOLOGY,superuser.com,0.8888888888888888,0.6666666666666666,0.0,0.3333333333333333,1.0,1.0,0.6666666666666666,0.4444444444444444,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.6666666666666666,0.3333333333333333,0.0,0.7777777777777778,0.8888888888888888,0.6666666666666666,1.0,1.0,0.8666666666666666,1.0,0.3333333333333333,1.0,0.8888888888888888,How do I add words to a file?,"
  Possible Duplicate:
  Regex for &ldquo;or&rdquo; in grep  




How can I grep for lines with either 'disable' or 'enable' in my file?

I tried 
 $ grep   ""disable|enable"" fail.log 

but that shows up nothing.
","Try ""grep ""disable\|enable"" fail.log

The backslash turns the | into the ""or"" metacharacter, otherwise you are grepping for the literal 'disable|enable""
"
2590,2590,4120,Why does string theory have such a huge landscape?,"I was browsing through Foundations of Space and Time, a compilation of essays on various theories of quantum gravity. The following passage in the introduction intrigued me:


  Each compactification leads to a different vacuum state.... at least one state should describe our Universe in its entirety.... the enormous number (~10^500 at last count) of solutions, with no perturbative mechanism to select mechanism to select among them, leads some critics to question the predictive power of the theory..Even more worrying is that, while the theory is perturbatively finite order by order, the perturbation series does not seem to converge.


I don't know anything about string theory and so I could not make head or tails this. All I know is that ~$10^{500}$    is a very large number. 


What exactly is a 'solution' in string theory? Is it a spacetime metric of some sort or the terms of a S-matrix of some sort?  
Why are there so many 'solutions'? 
I thought string theory was supposed to be finite, why do perturbative series still diverge?
Is there any experimental technique to limit the number of 'solutions'?  
Will experimental techniques be able to pinpoint a solution within present day string theorists' lifetimes too? If not, how long will it take before we can experimentally probe these things? 
Are string theorists completely relaxed about these issues? Or are they in anguish? 

",dj_mummy,https://physics.stackexchange.com/users/28244,"Who wrote that passage? It contains some misunderstandings.


  All I know is that $10^{500}$ is a very large number. 


It is a finite number. How many theories do you know which have a finite number of solutions? Have you tried to count the number of solutions of plain Einstein-Yang-Mills-Dirac-Higgs theory without its string-theoretic UV completion? There are not only infinitely-many solutions, there is a hugely infinite-dimensional space of solutions. This is the usual state of affairs for most every theory of physics ever considered. String theory is special in that it puts many more constraints on the solutions, such as to even leave just a finite number (under some assumptions).


  What exactly is a 'solution' in string theory? 


A background for perturbative string theory is a choice of 2-dimensional superconformal QFT of central charge -15. This can be interpreted as describing an effective target space geometry which is a solution to a higher dimensional supergravity theory with higher curvature corrections. A ""solution"" to string theory is a solution of the equations of motion of that. At least without non-perturbative effects taken into account. 

See on the nLab: landscape of string theory vacua for more.


  I thought string theory was supposed to be finite, why do perturbative series still diverge?


String theory is thought to be loop-wise finite, thus being a renormalized perturbative theory. No sensible remormalized perturbative QFT can have converging perturbation series. The perturbation series must be an asymptotic series to be realistic, and it comes out exactly like this in string perturbation theory. 

See at the String Theory FAQ on the nLab the item Isn’t it fatal that the string perturbation series does not converge?


  Is there any experimental technique to limit the number of 'solutions'? Will experimental techniques be able to pinpoint a solution within present day string theorists' lifetimes too?


Models that have been and are being built in string phenomenology approximate the standard model to more detail than probably most people are aware the standard model even has. Check out some of the references there. Given the slow but continuous flow of new articles on these matter, one sees that some people are slowly but surely working on improving ever further. Check out the references at string phenomenology.

[edit: I have now added a corresponding item to the nLab String Theory FAQ: What does it mean to say that string theory has a “landscape of solutions”?]
",Urs Schreiber,https://physics.stackexchange.com/users/5603,http://physics.stackexchange.com/questions/75441/why-does-string-theory-have-such-a-huge-landscape,SCIENCE,physics.stackexchange.com,1.0,0.5555555555555556,0.0,0.3333333333333333,1.0,0.6666666666666666,0.5555555555555556,0.5555555555555556,0.6666666666666666,0.0,0.6666666666666666,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.3333333333333333,0.3333333333333333,1.0,0.0,1.0,0.8888888888888888,0.5555555555555556,0.8888888888888888,1.0,0.7333333333333333,0.0,0.0,1.0,1.0,Why is string theory so promising?,"I was browsing through Foundations of Space and Time, a compilation of essays on various theories of quantum gravity. The following passage in the introduction intrigued me:


  Each compactification leads to a different vacuum state.... at least one state should describe our Universe in its entirety.... the enormous number (~10^500 at last count) of solutions, with no perturbative mechanism to select mechanism to select among them, leads some critics to question the predictive power of the theory..Even more worrying is that, while the theory is perturbatively finite order by order, the perturbation series does not seem to converge.


I don't know anything about string theory and so I could not make head or tails this. All I know is that ~$10^{500}$    is a very large number. 


What exactly is a 'solution' in string theory? Is it a spacetime metric of some sort or the terms of a S-matrix of some sort?  
Why are there so many 'solutions'? 
I thought string theory was supposed to be finite, why do perturbative series still diverge?
Is there any experimental technique to limit the number of 'solutions'?  
Will experimental techniques be able to pinpoint a solution within present day string theorists' lifetimes too? If not, how long will it take before we can experimentally probe these things? 
Are string theorists completely relaxed about these issues? Or are they in anguish? 

","Who wrote that passage? It contains some misunderstandings.


  All I know is that $10^{500}$ is a very large number. 


It is a finite number. How many theories do you know which have a finite number of solutions? Have you tried to count the number of solutions of plain Einstein-Yang-Mills-Dirac-Higgs theory without its string-theoretic UV completion? There are not only infinitely-many solutions, there is a hugely infinite-dimensional space of solutions. This is the usual state of affairs for most every theory of physics ever considered. String theory is special in that it puts many more constraints on the solutions, such as to even leave just a finite number (under some assumptions).


  What exactly is a 'solution' in string theory? 


A background for perturbative string theory is a choice of 2-dimensional superconformal QFT of central charge -15. This can be interpreted as describing an effective target space geometry which is a solution to a higher dimensional supergravity theory with higher curvature corrections. A ""solution"" to string theory is a solution of the equations of motion of that. At least without non-perturbative effects taken into account. 

See on the nLab: landscape of string theory vacua for more.


  I thought string theory was supposed to be finite, why do perturbative series still diverge?


String theory is thought to be loop-wise finite, thus being a renormalized perturbative theory. No sensible remormalized perturbative QFT can have converging perturbation series. The perturbation series must be an asymptotic series to be realistic, and it comes out exactly like this in string perturbation theory. 

See at the String Theory FAQ on the nLab the item Isn’t it fatal that the string perturbation series does not converge?


  Is there any experimental technique to limit the number of 'solutions'? Will experimental techniques be able to pinpoint a solution within present day string theorists' lifetimes too?


Models that have been and are being built in string phenomenology approximate the standard model to more detail than probably most people are aware the standard model even has. Check out some of the references there. Given the slow but continuous flow of new articles on these matter, one sees that some people are slowly but surely working on improving ever further. Check out the references at string phenomenology.

[edit: I have now added a corresponding item to the nLab String Theory FAQ: What does it mean to say that string theory has a “landscape of solutions”?]
"
5746,5746,9096,Water Supply pressure,"What size supply pipe must be used from a 5000 litre water tank to supply 4 bars of pressure to a house that is 20m below and 300m away from the tank?
",Sandy,https://diy.stackexchange.com/users/35971,"Given that 20 meters of head only equates to 1.96 Bar (1m elevation = 0.0980413943 Bar), no pipe alone will do this - you'll need a pump, or you'll need to accept less than 2 Bar as all the pressure you have available.

Then you need to determine the flow rate you wish to operate at for sizing the pipe - you'll get 1.96 bar with any size pipe and no flow (static head) but as you actually use water the pressure will drop (dynamic head) in relation to to pipe size and rate of flow. That is essentially friction in the pipe resisting flow and reducing the effective head. Calculators are available and the formulas for that are adequately complex that using one is suggested. Aside from size of pipe and flow rate, pipe material enters into it as some types are smoother inside and thus have less friction for a given size of pipe than other types.

For example, if you were sizing for 12 l/min, 25mm plastic pipe would have about 2.7 m dynamic head, leaving you with 17.3m head pressure (delivery pressure = 1.7 Bar), and 50 mm pipe would only lose 0.0925m at that flow rate (delivery pressure = 1.9 Bar). 

Bump the flow up to 120 l/min and the 50 mm pipe costs 6.55m head (delivery pressure = 1.3 Bar) - but the 25mm pipe cannot provide that flow rate at all with 20m head - it tops out at about 35 l/min with no pressure at the house end (20 m static head - 20m dynamic head; delivery pressure = 0 Bar)
",Ecnerwal,https://diy.stackexchange.com/users/18078,http://diy.stackexchange.com/questions/64247/water-supply-pressure,LIFE_ARTS,diy.stackexchange.com,1.0,0.3333333333333333,0.0,0.6666666666666666,1.0,0.6666666666666666,0.5555555555555556,0.5555555555555556,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.5555555555555556,1.0,1.0,1.0,1.0,0.9333333333333332,0.6666666666666666,0.3333333333333333,0.6666666666666666,1.0,Water supply pressure,How much water supply pipe must be used from a 5000 litre tank to provide 4 bar pressure for a house 20 meters below and 300 meters from the tank?,"Given that 20 meters of head only equates to 1.96 Bar (1m elevation = 0.0980413943 Bar), no pipe alone will do this - you'll need a pump, or you'll need to accept less than 2 Bar as all the pressure you have available.

Then you need to determine the flow rate you wish to operate at for sizing the pipe - you'll get 1.96 bar with any size pipe and no flow (static head) but as you actually use water the pressure will drop (dynamic head) in relation to to pipe size and rate of flow. That is essentially friction in the pipe resisting flow and reducing the effective head. Calculators are available and the formulas for that are adequately complex that using one is suggested. Aside from size of pipe and flow rate, pipe material enters into it as some types are smoother inside and thus have less friction for a given size of pipe than other types.

For example, if you were sizing for 12 l/min, 25mm plastic pipe would have about 2.7 m dynamic head, leaving you with 17.3m head pressure (delivery pressure = 1.7 Bar), and 50 mm pipe would only lose 0.0925m at that flow rate (delivery pressure = 1.9 Bar). 

Bump the flow up to 120 l/min and the 50 mm pipe costs 6.55m head (delivery pressure = 1.3 Bar) - but the 25mm pipe cannot provide that flow rate at all with 20m head - it tops out at about 35 l/min with no pressure at the house end (20 m static head - 20m dynamic head; delivery pressure = 0 Bar)
"
3845,3845,6113,GMGridview for MonoDevelop and Android,"Does anyone know of something similar to GMGridview for MonoDevelop and Android?

I am looking for something that will allow me to place about 12 to 15 icons/buttons on the Android that I can swipe/scroll back and forth.  I am using MonoDevelop and am very new to Android Development.

I do not necessarily need the drag and drop functionality, but I cannot even find an example of placing many icons on the screen and allowing me to scroll back and forth.

I am struggling with how the layout should be done so any help is appreciated!!

Thank you for any assistance!!!
",LilMoke,https://stackoverflow.com/users/80088,"GridView... ? 
http://developer.android.com/reference/android/widget/GridView.html

And I have no idea how is it connected with MonoDevelop. 
",Piotr,https://stackoverflow.com/users/846159,http://stackoverflow.com/questions/13609901/gmgridview-for-monodevelop-and-android,STACKOVERFLOW,stackoverflow.com,1.0,0.5555555555555556,0.0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.4444444444444444,0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.5555555555555556,0.7777777777777778,0.5555555555555556,1.0,0.8888888888888888,0.6666666666666667,0.0,0.0,0.0,0.7777777777777778,Gmgridview for MonoDevelop and Android,"Does anyone know of something similar to GMGridview for MonoDevelop and Android?

I am looking for something that will allow me to place about 12 to 15 icons/buttons on the Android that I can swipe/scroll back and forth.  I am using MonoDevelop and am very new to Android Development.

I do not necessarily need the drag and drop functionality, but I cannot even find an example of placing many icons on the screen and allowing me to scroll back and forth.

I am struggling with how the layout should be done so any help is appreciated!!

Thank you for any assistance!!!
","GridView... ? 
http://developer.android.com/reference/android/widget/GridView.html

And I have no idea how is it connected with MonoDevelop. 
"
3280,3280,5225,Are achievements per Steam account or per character?,"Are achievements in Skyrim per character or per account on steam? If the Achievements are per account is there a way I reset them?

When I say per character I mean can the Achievements I earn on one character be re-earned with another character?
",Antonio,https://gaming.stackexchange.com/users/46032,"They are per account.  Once you've earned an achievement with one character, you can't earn it again with another character as its now unlocked for your steam account.

And there is no known legitimate way of resetting steam achievements (From here).


  Resetting Achievements
  Unfortunately, achievements can not be reset at this time.

",l I,https://gaming.stackexchange.com/users/3917,http://gaming.stackexchange.com/questions/114945/are-achievements-per-steam-account-or-per-character,CULTURE,gaming.stackexchange.com,1.0,0.4444444444444444,0.0,1.0,1.0,1.0,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.8888888888888888,1.0,0.6666666666666666,1.0,1.0,1.0,0.3333333333333333,0.0,1.0,0.8888888888888888,Is each steam account or achievement of each character?,"Are achievements in Skyrim per character or per account on steam? If the Achievements are per account is there a way I reset them?

When I say per character I mean can the Achievements I earn on one character be re-earned with another character?
","They are per account.  Once you've earned an achievement with one character, you can't earn it again with another character as its now unlocked for your steam account.

And there is no known legitimate way of resetting steam achievements (From here).


  Resetting Achievements
  Unfortunately, achievements can not be reset at this time.

"

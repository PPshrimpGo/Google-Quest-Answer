{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0130 21:39:40.255348 140695671617280 file_utils.py:38] PyTorch version 1.2.0 available.\n",
      "I0130 21:39:41.047496 140695671617280 file_utils.py:54] TensorFlow version 2.0.0 available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib.get_backend :  TkAgg\n"
     ]
    }
   ],
   "source": [
    "# import os and define graphic card\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "# import common libraries\n",
    "import gc\n",
    "import random\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "\n",
    "# import pytorch related libraries\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.optim.optimizer import Optimizer\n",
    "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
    "from torch.utils.data.sampler import RandomSampler, SequentialSampler\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR, _LRScheduler\n",
    "from tensorboardX import SummaryWriter\n",
    "from pytorch_pretrained_bert.optimization import BertAdam\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# import apex for mix precision training\n",
    "from apex import amp\n",
    "from apex.parallel import DistributedDataParallel as DDP\n",
    "from apex.optimizers import FusedAdam\n",
    "\n",
    "# import dataset class\n",
    "from dataset.dataset import *\n",
    "\n",
    "# import utils\n",
    "from utils.ranger import *\n",
    "from utils.lrs_scheduler import * \n",
    "from utils.loss_function import *\n",
    "from utils.metric import *\n",
    "from utils.file import *\n",
    "\n",
    "# import model\n",
    "from model.model_bert import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0130 21:52:33.749969 140695671617280 filelock.py:274] Lock 140691829489168 acquired on /home/jionie/.cache/torch/transformers/97248896d50e5f71a0bca4f6e45cecc29b3802056a252f08353d40c5d5597fca.431d47beb46d4c737166d5f81333822462ba18e64d76b60314e08f43840e86dc.lock\n",
      "I0130 21:52:33.753069 140695671617280 file_utils.py:413] https://s3.amazonaws.com/models.huggingface.co/bert/flaubert/flaubert_large_cased/config.json not found in cache or force_download set to True, downloading to /home/jionie/.cache/torch/transformers/tmpvjjb4_1m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fa001de0d2546269ae76dda4051d123",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=974, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0130 21:52:34.004426 140695671617280 file_utils.py:423] storing https://s3.amazonaws.com/models.huggingface.co/bert/flaubert/flaubert_large_cased/config.json in cache at /home/jionie/.cache/torch/transformers/97248896d50e5f71a0bca4f6e45cecc29b3802056a252f08353d40c5d5597fca.431d47beb46d4c737166d5f81333822462ba18e64d76b60314e08f43840e86dc\n",
      "I0130 21:52:34.005129 140695671617280 file_utils.py:426] creating metadata file for /home/jionie/.cache/torch/transformers/97248896d50e5f71a0bca4f6e45cecc29b3802056a252f08353d40c5d5597fca.431d47beb46d4c737166d5f81333822462ba18e64d76b60314e08f43840e86dc\n",
      "I0130 21:52:34.006445 140695671617280 filelock.py:318] Lock 140691829489168 released on /home/jionie/.cache/torch/transformers/97248896d50e5f71a0bca4f6e45cecc29b3802056a252f08353d40c5d5597fca.431d47beb46d4c737166d5f81333822462ba18e64d76b60314e08f43840e86dc.lock\n",
      "I0130 21:52:34.007272 140695671617280 configuration_utils.py:254] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/flaubert/flaubert_large_cased/config.json from cache at /home/jionie/.cache/torch/transformers/97248896d50e5f71a0bca4f6e45cecc29b3802056a252f08353d40c5d5597fca.431d47beb46d4c737166d5f81333822462ba18e64d76b60314e08f43840e86dc\n",
      "I0130 21:52:34.008337 140695671617280 configuration_utils.py:290] Model config FlaubertConfig {\n",
      "  \"amp\": 1,\n",
      "  \"architectures\": null,\n",
      "  \"asm\": false,\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_index\": 0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"bptt\": 512,\n",
      "  \"causal\": false,\n",
      "  \"clip_grad_norm\": 5,\n",
      "  \"do_sample\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"emb_dim\": 1024,\n",
      "  \"embed_init_std\": 0.02209708691207961,\n",
      "  \"encoder_only\": true,\n",
      "  \"end_n_top\": 5,\n",
      "  \"eos_index\": 1,\n",
      "  \"eos_token_ids\": 0,\n",
      "  \"finetuning_task\": null,\n",
      "  \"fp16\": true,\n",
      "  \"gelu_activation\": true,\n",
      "  \"group_by_size\": true,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"id2lang\": {\n",
      "    \"0\": \"fr\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"lang2id\": {\n",
      "    \"fr\": 0\n",
      "  },\n",
      "  \"lang_id\": 0,\n",
      "  \"langs\": [\n",
      "    \"fr\"\n",
      "  ],\n",
      "  \"layer_norm_eps\": 1e-06,\n",
      "  \"layerdrop\": 0.2,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"lg_sampling_factor\": -1,\n",
      "  \"lgs\": \"fr\",\n",
      "  \"mask_index\": 5,\n",
      "  \"mask_token_id\": 0,\n",
      "  \"max_batch_size\": 0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_vocab\": -1,\n",
      "  \"mlm_steps\": [\n",
      "    [\n",
      "      \"fr\",\n",
      "      null\n",
      "    ]\n",
      "  ],\n",
      "  \"model_type\": \"flaubert\",\n",
      "  \"n_heads\": 16,\n",
      "  \"n_langs\": 1,\n",
      "  \"n_layers\": 24,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_labels\": 2,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": true,\n",
      "  \"output_past\": true,\n",
      "  \"pad_index\": 2,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pre_norm\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"sample_alpha\": 0,\n",
      "  \"share_inout_emb\": true,\n",
      "  \"sinusoidal_embeddings\": false,\n",
      "  \"start_n_top\": 5,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"tokens_per_batch\": -1,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"unk_index\": 3,\n",
      "  \"use_apex\": true,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"use_lang_emb\": true,\n",
      "  \"vocab_size\": 68729,\n",
      "  \"word_blank\": 0,\n",
      "  \"word_dropout\": 0,\n",
      "  \"word_keep\": 0.1,\n",
      "  \"word_mask\": 0.8,\n",
      "  \"word_mask_keep_rand\": \"0.8,0.1,0.1\",\n",
      "  \"word_pred\": 0.15,\n",
      "  \"word_rand\": 0.1,\n",
      "  \"word_shuffle\": 0\n",
      "}\n",
      "\n",
      "I0130 21:52:34.174247 140695671617280 filelock.py:274] Lock 140691829489000 acquired on /home/jionie/.cache/torch/transformers/434a5601ffb94eb010f8d1ea979f8082a9849b44907798693b07116341d88c48.711513e7dc80b480c11c365177d07ecafe2606c83ba675767ed4a9168af1e1bf.lock\n",
      "I0130 21:52:34.177215 140695671617280 file_utils.py:413] https://s3.amazonaws.com/models.huggingface.co/bert/flaubert/flaubert_large_cased/pytorch_model.bin not found in cache or force_download set to True, downloading to /home/jionie/.cache/torch/transformers/tmp5lvvgqes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7953e9893f4e481ea9ef395cfc2b1b62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=1493194721, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0130 21:53:24.606858 140695671617280 file_utils.py:423] storing https://s3.amazonaws.com/models.huggingface.co/bert/flaubert/flaubert_large_cased/pytorch_model.bin in cache at /home/jionie/.cache/torch/transformers/434a5601ffb94eb010f8d1ea979f8082a9849b44907798693b07116341d88c48.711513e7dc80b480c11c365177d07ecafe2606c83ba675767ed4a9168af1e1bf\n",
      "I0130 21:53:24.607414 140695671617280 file_utils.py:426] creating metadata file for /home/jionie/.cache/torch/transformers/434a5601ffb94eb010f8d1ea979f8082a9849b44907798693b07116341d88c48.711513e7dc80b480c11c365177d07ecafe2606c83ba675767ed4a9168af1e1bf\n",
      "I0130 21:53:24.608362 140695671617280 filelock.py:318] Lock 140691829489000 released on /home/jionie/.cache/torch/transformers/434a5601ffb94eb010f8d1ea979f8082a9849b44907798693b07116341d88c48.711513e7dc80b480c11c365177d07ecafe2606c83ba675767ed4a9168af1e1bf.lock\n",
      "I0130 21:53:24.608781 140695671617280 modeling_utils.py:458] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/flaubert/flaubert_large_cased/pytorch_model.bin from cache at /home/jionie/.cache/torch/transformers/434a5601ffb94eb010f8d1ea979f8082a9849b44907798693b07116341d88c48.711513e7dc80b480c11c365177d07ecafe2606c83ba675767ed4a9168af1e1bf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = QuestNet(model_type=\"flaubert-large-cased\", n_classes=30, hidden_layers=[-1, -3, -5, -7, -9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuestNet(\n",
       "  (flaubert_model): FlaubertModel(\n",
       "    (position_embeddings): Embedding(512, 1024)\n",
       "    (embeddings): Embedding(68729, 1024, padding_idx=2)\n",
       "    (layer_norm_emb): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "    (attentions): ModuleList(\n",
       "      (0): MultiHeadAttention(\n",
       "        (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (1): MultiHeadAttention(\n",
       "        (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (2): MultiHeadAttention(\n",
       "        (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (3): MultiHeadAttention(\n",
       "        (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (4): MultiHeadAttention(\n",
       "        (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (5): MultiHeadAttention(\n",
       "        (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (6): MultiHeadAttention(\n",
       "        (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (7): MultiHeadAttention(\n",
       "        (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (8): MultiHeadAttention(\n",
       "        (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (9): MultiHeadAttention(\n",
       "        (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (10): MultiHeadAttention(\n",
       "        (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (11): MultiHeadAttention(\n",
       "        (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (12): MultiHeadAttention(\n",
       "        (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (13): MultiHeadAttention(\n",
       "        (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (14): MultiHeadAttention(\n",
       "        (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (15): MultiHeadAttention(\n",
       "        (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (16): MultiHeadAttention(\n",
       "        (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (17): MultiHeadAttention(\n",
       "        (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (18): MultiHeadAttention(\n",
       "        (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (19): MultiHeadAttention(\n",
       "        (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (20): MultiHeadAttention(\n",
       "        (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (21): MultiHeadAttention(\n",
       "        (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (22): MultiHeadAttention(\n",
       "        (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (23): MultiHeadAttention(\n",
       "        (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (layer_norm1): ModuleList(\n",
       "      (0): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (3): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (4): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (5): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (6): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (7): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (8): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (9): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (10): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (11): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (12): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (13): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (14): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (15): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (16): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (17): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (18): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (19): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (20): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (21): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (22): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (23): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "    )\n",
       "    (ffns): ModuleList(\n",
       "      (0): TransformerFFN(\n",
       "        (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      )\n",
       "      (1): TransformerFFN(\n",
       "        (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      )\n",
       "      (2): TransformerFFN(\n",
       "        (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      )\n",
       "      (3): TransformerFFN(\n",
       "        (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      )\n",
       "      (4): TransformerFFN(\n",
       "        (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      )\n",
       "      (5): TransformerFFN(\n",
       "        (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      )\n",
       "      (6): TransformerFFN(\n",
       "        (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      )\n",
       "      (7): TransformerFFN(\n",
       "        (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      )\n",
       "      (8): TransformerFFN(\n",
       "        (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      )\n",
       "      (9): TransformerFFN(\n",
       "        (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      )\n",
       "      (10): TransformerFFN(\n",
       "        (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      )\n",
       "      (11): TransformerFFN(\n",
       "        (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      )\n",
       "      (12): TransformerFFN(\n",
       "        (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      )\n",
       "      (13): TransformerFFN(\n",
       "        (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      )\n",
       "      (14): TransformerFFN(\n",
       "        (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      )\n",
       "      (15): TransformerFFN(\n",
       "        (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      )\n",
       "      (16): TransformerFFN(\n",
       "        (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      )\n",
       "      (17): TransformerFFN(\n",
       "        (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      )\n",
       "      (18): TransformerFFN(\n",
       "        (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      )\n",
       "      (19): TransformerFFN(\n",
       "        (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      )\n",
       "      (20): TransformerFFN(\n",
       "        (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      )\n",
       "      (21): TransformerFFN(\n",
       "        (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      )\n",
       "      (22): TransformerFFN(\n",
       "        (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      )\n",
       "      (23): TransformerFFN(\n",
       "        (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (layer_norm2): ModuleList(\n",
       "      (0): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (3): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (4): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (5): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (6): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (7): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (8): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (9): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (10): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (11): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (12): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (13): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (14): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (15): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (16): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (17): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (18): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (19): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (20): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (21): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (22): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (23): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (fc_1): Linear(in_features=5120, out_features=1024, bias=True)\n",
       "  (fc): Linear(in_features=1024, out_features=30, bias=True)\n",
       "  (selu): SELU()\n",
       "  (relu): ReLU()\n",
       "  (tanh): Tanh()\n",
       "  (dropouts): ModuleList(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Dropout(p=0.5, inplace=False)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3env",
   "language": "python",
   "name": "py3env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

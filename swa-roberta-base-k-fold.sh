python swa-k-fold.py --model_name "roberta-base" --content "Question_Answer" --max_len 512 --fold 0 --seed 2345 --n_splits 5 --batch_size 8 --valid_batch_size 32 --accumulation_steps 1 --lr 5e-7 --split "GroupKfold" --loss "bce" --augment --num_epoch 3 --num_workers 4 --load_pretrain
python swa-k-fold.py --model_name "roberta-base" --content "Question_Answer" --max_len 512 --fold 1 --seed 2345 --n_splits 5 --batch_size 8 --valid_batch_size 32 --accumulation_steps 1 --lr 5e-7 --split "GroupKfold" --loss "bce" --augment --num_epoch 3 --num_workers 4 --load_pretrain
python swa-k-fold.py --model_name "roberta-base" --content "Question_Answer" --max_len 512 --fold 2 --seed 2345 --n_splits 5 --batch_size 8 --valid_batch_size 32 --accumulation_steps 1 --lr 5e-7 --split "GroupKfold" --loss "bce" --augment --num_epoch 3 --num_workers 4 --load_pretrain
python swa-k-fold.py --model_name "roberta-base" --content "Question_Answer" --max_len 512 --fold 3 --seed 2345 --n_splits 5 --batch_size 8 --valid_batch_size 32 --accumulation_steps 1 --lr 5e-7 --split "GroupKfold" --loss "bce" --augment --num_epoch 3 --num_workers 4 --load_pretrain
python swa-k-fold.py --model_name "roberta-base" --content "Question_Answer" --max_len 512 --fold 4 --seed 2345 --n_splits 5 --batch_size 8 --valid_batch_size 32 --accumulation_steps 1 --lr 5e-7 --split "GroupKfold" --loss "bce" --augment --num_epoch 3 --num_workers 4 --load_pretrain
